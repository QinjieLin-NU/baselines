[32m[0514 04:56:48 @logger.py:103][0m Log file set to /root/mbbl/log/mbmfrl-rsgym_pendulum_hr_50_mbmf_gym_pendulum_ppo_seed_1234.log/mbmfrl-rsgym_pendulum_hr_50_mbmf_gym_pendulum_ppo_seed_1234.log
[32m[0514 04:56:49 @mbmf_main.py:23][0m Training starts at /root/mbbl
[32m[0514 04:56:49 @base_worker.py:45][0m Worker 0 online
[32m[0514 04:56:49 @base_worker.py:45][0m Worker 1 online
[32m[0514 04:56:49 @base_worker.py:45][0m Worker 2 online
[32m[0514 04:56:49 @base_worker.py:45][0m Worker 3 online
[32m[0514 04:56:49 @base_worker.py:45][0m Worker 4 online
[32m[0514 04:56:49 @base_worker.py:45][0m Worker 5 online
[32m[0514 04:56:49 @base_worker.py:45][0m Worker 6 online
[32m[0514 04:56:49 @base_worker.py:45][0m Worker 7 online
[32m[0514 04:56:49 @base_worker.py:45][0m Worker 8 online
[32m[0514 04:56:49 @base_worker.py:45][0m Worker 9 online
[32m[0514 04:56:49 @base_worker.py:45][0m Worker 10 online
[32m[0514 04:56:49 @base_worker.py:45][0m Worker 11 online
[32m[0514 04:56:49 @base_worker.py:45][0m Worker 12 online
[32m[0514 04:56:49 @base_worker.py:45][0m Worker 13 online
[32m[0514 04:56:49 @base_worker.py:45][0m Worker 14 online
[32m[0514 04:56:49 @base_worker.py:45][0m Worker 15 online
[32m[0514 04:56:49 @base_worker.py:45][0m Worker 16 online
[32m[0514 04:56:49 @base_worker.py:45][0m Worker 17 online
[32m[0514 04:56:49 @base_worker.py:45][0m Worker 18 online
[32m[0514 04:56:49 @base_worker.py:45][0m Worker 19 online
[32m[0514 04:56:51 @base_trainer.py:152][0m Trainer maintains [1] policy network
[32m[0514 04:56:51 @base_trainer.py:152][0m Trainer maintains [1] dynamics network
[32m[0514 04:56:51 @base_trainer.py:152][0m Trainer maintains [1] reward network
[32m[0514 04:56:52 @mbmf_main.py:46][0m Generating 1000 random timesteps
[32m[0514 04:56:52 @mbmf_sampler.py:39][0m done with episode
[32m[0514 04:56:52 @mbmf_sampler.py:39][0m done with episode
[32m[0514 04:56:52 @mbmf_sampler.py:39][0m done with episode
[32m[0514 04:56:52 @mbmf_sampler.py:39][0m done with episode
[32m[0514 04:56:52 @mbmf_sampler.py:39][0m done with episode
[32m[0514 04:56:52 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0514 04:56:52 @base_trainer.py:216][0m Mean reward: -1087.7626042134248
[32m[0514 04:56:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0128819942474365, Train Loss: 1.0142550468444824
[32m[0514 04:56:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0128960609436035, Train Loss: 1.0142393112182617
[32m[0514 04:56:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0129104852676392, Train Loss: 1.014223575592041
[32m[0514 04:56:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0129249095916748, Train Loss: 1.014208197593689
[32m[0514 04:56:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.012939691543579, Train Loss: 1.014192819595337
[32m[0514 04:56:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0129544734954834, Train Loss: 1.0141777992248535
[32m[0514 04:56:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0129694938659668, Train Loss: 1.0141630172729492
[32m[0514 04:56:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0129847526550293, Train Loss: 1.014148473739624
[32m[0514 04:56:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0130001306533813, Train Loss: 1.0141338109970093
[32m[0514 04:56:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.013015866279602, Train Loss: 1.0141197443008423
[32m[0514 04:56:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0130316019058228, Train Loss: 1.0141055583953857
[32m[0514 04:56:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.013047695159912, Train Loss: 1.0140917301177979
[32m[0514 04:56:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0130640268325806, Train Loss: 1.0140780210494995
[32m[0514 04:56:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0130802392959595, Train Loss: 1.0140644311904907
[32m[0514 04:56:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0130970478057861, Train Loss: 1.0140513181686401
[32m[0514 04:56:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0131137371063232, Train Loss: 1.0140380859375
[32m[0514 04:56:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0131309032440186, Train Loss: 1.0140252113342285
[32m[0514 04:56:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0131480693817139, Train Loss: 1.0140125751495361
[32m[0514 04:56:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0131654739379883, Train Loss: 1.0140000581741333
[32m[0514 04:56:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0131829977035522, Train Loss: 1.0139877796173096
[32m[0514 04:56:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0132008790969849, Train Loss: 1.0139756202697754
[32m[0514 04:56:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.013218879699707, Train Loss: 1.0139636993408203
[32m[0514 04:56:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0132372379302979, Train Loss: 1.0139518976211548
[32m[0514 04:56:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0132554769515991, Train Loss: 1.0139403343200684
[32m[0514 04:56:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0132739543914795, Train Loss: 1.0139288902282715
[32m[0514 04:56:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0132927894592285, Train Loss: 1.0139175653457642
[32m[0514 04:56:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.013311505317688, Train Loss: 1.0139063596725464
[32m[0514 04:56:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0133306980133057, Train Loss: 1.0138955116271973
[32m[0514 04:56:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0133498907089233, Train Loss: 1.0138845443725586
[32m[0514 04:56:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0133692026138306, Train Loss: 1.013873815536499
[32m[0514 04:56:54 @base_main.py:38][0m --------------- Iteration 1 ---------------
[32m[0514 04:56:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0000 mins
[32m[0514 04:56:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0043 mins
[32m[0514 04:56:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0217 mins
[32m[0514 04:56:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0060 mins
[32m[0514 04:56:54 @base_main.py:47][0m 1005 total steps have happened
[32m[0514 04:56:54 @base_main.py:52][0m [avg_reward]: -1087.7626042134248
[32m[0514 04:56:54 @base_main.py:52][0m [update_op]: None
[32m[0514 04:56:54 @base_main.py:52][0m [train_loss]: 1.013873815536499
[32m[0514 04:56:54 @base_main.py:52][0m [val_loss]: 1.0133692026138306
[32m[0514 04:56:54 @base_main.py:52][0m [avg_train_loss]: 1.013873815536499
[32m[0514 04:57:33 @mbmf_sampler.py:39][0m done with episode
[32m[0514 04:58:12 @mbmf_sampler.py:39][0m done with episode
[32m[0514 04:58:51 @mbmf_sampler.py:39][0m done with episode
[32m[0514 04:59:28 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:00:06 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:00:06 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:00:06 @base_trainer.py:216][0m Mean reward: -1226.497210995912
[32m[0514 05:00:06 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0031640529632568, Train Loss: 0.9710075259208679
[32m[0514 05:00:06 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.003190517425537, Train Loss: 0.9710084795951843
[32m[0514 05:00:06 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0032153129577637, Train Loss: 0.9710087776184082
[32m[0514 05:00:06 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0032387971878052, Train Loss: 0.9710080623626709
[32m[0514 05:00:06 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0032614469528198, Train Loss: 0.9710066914558411
[32m[0514 05:00:06 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0032832622528076, Train Loss: 0.9710049033164978
[32m[0514 05:00:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.003304362297058, Train Loss: 0.9710025191307068
[32m[0514 05:00:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0033248662948608, Train Loss: 0.9709998965263367
[32m[0514 05:00:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0033448934555054, Train Loss: 0.9709970951080322
[32m[0514 05:00:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0033644437789917, Train Loss: 0.9709944128990173
[32m[0514 05:00:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0033835172653198, Train Loss: 0.9709915518760681
[32m[0514 05:00:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0034022331237793, Train Loss: 0.9709886908531189
[32m[0514 05:00:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.003420352935791, Train Loss: 0.9709858894348145
[32m[0514 05:00:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0034379959106445, Train Loss: 0.9709832072257996
[32m[0514 05:00:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0034550428390503, Train Loss: 0.9709805846214294
[32m[0514 05:00:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.003472089767456, Train Loss: 0.9709780812263489
[32m[0514 05:00:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0034884214401245, Train Loss: 0.9709756970405579
[32m[0514 05:00:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0035043954849243, Train Loss: 0.9709733128547668
[32m[0514 05:00:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.003520131111145, Train Loss: 0.9709711670875549
[32m[0514 05:00:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0035353899002075, Train Loss: 0.9709692001342773
[32m[0514 05:00:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0035502910614014, Train Loss: 0.9709672331809998
[32m[0514 05:00:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0035648345947266, Train Loss: 0.9709653258323669
[32m[0514 05:00:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0035789012908936, Train Loss: 0.9709634780883789
[32m[0514 05:00:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0035927295684814, Train Loss: 0.9709618091583252
[32m[0514 05:00:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0036062002182007, Train Loss: 0.9709603190422058
[32m[0514 05:00:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0036193132400513, Train Loss: 0.9709587693214417
[32m[0514 05:00:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0036320686340332, Train Loss: 0.970957338809967
[32m[0514 05:00:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0036447048187256, Train Loss: 0.970956027507782
[32m[0514 05:00:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0036567449569702, Train Loss: 0.9709546566009521
[32m[0514 05:00:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0036685466766357, Train Loss: 0.9709534645080566
[32m[0514 05:00:09 @base_main.py:38][0m --------------- Iteration 2 ---------------
[32m[0514 05:00:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0323 mins
[32m[0514 05:00:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 3.1992 mins
[32m[0514 05:00:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0357 mins
[32m[0514 05:00:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0073 mins
[32m[0514 05:00:09 @base_main.py:47][0m 2010 total steps have happened
[32m[0514 05:00:09 @base_main.py:52][0m [avg_reward]: -1226.497210995912
[32m[0514 05:00:09 @base_main.py:52][0m [update_op]: None
[32m[0514 05:00:09 @base_main.py:52][0m [train_loss]: 0.849817156791687
[32m[0514 05:00:09 @base_main.py:52][0m [val_loss]: 1.0036685466766357
[32m[0514 05:00:09 @base_main.py:52][0m [avg_train_loss]: 0.9709534645080566
[32m[0514 05:00:46 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:01:25 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:02:03 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:02:40 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:03:18 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:03:18 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:03:18 @base_trainer.py:216][0m Mean reward: -1291.34655619251
[32m[0514 05:03:18 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9385644793510437, Train Loss: 1.0004045963287354
[32m[0514 05:03:18 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.938585638999939, Train Loss: 1.0003986358642578
[32m[0514 05:03:18 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9386201500892639, Train Loss: 1.0003865957260132
[32m[0514 05:03:19 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.938662052154541, Train Loss: 1.0003712177276611
[32m[0514 05:03:19 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9387078285217285, Train Loss: 1.0003548860549927
[32m[0514 05:03:19 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.938755452632904, Train Loss: 1.0003383159637451
[32m[0514 05:03:19 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9388033747673035, Train Loss: 1.0003221035003662
[32m[0514 05:03:19 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9388510584831238, Train Loss: 1.0003070831298828
[32m[0514 05:03:19 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9388979077339172, Train Loss: 1.0002930164337158
[32m[0514 05:03:19 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.93894362449646, Train Loss: 1.0002800226211548
[32m[0514 05:03:19 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9389881491661072, Train Loss: 1.0002681016921997
[32m[0514 05:03:19 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9390314817428589, Train Loss: 1.000257134437561
[32m[0514 05:03:20 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9390733242034912, Train Loss: 1.0002471208572388
[32m[0514 05:03:20 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9391139149665833, Train Loss: 1.0002381801605225
[32m[0514 05:03:20 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9391530752182007, Train Loss: 1.000229835510254
[32m[0514 05:03:20 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9391909837722778, Train Loss: 1.0002224445343018
[32m[0514 05:03:20 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9392275214195251, Train Loss: 1.0002155303955078
[32m[0514 05:03:20 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9392627477645874, Train Loss: 1.0002094507217407
[32m[0514 05:03:20 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9392968416213989, Train Loss: 1.0002038478851318
[32m[0514 05:03:20 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9393296241760254, Train Loss: 1.0001987218856812
[32m[0514 05:03:20 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9393611550331116, Train Loss: 1.0001943111419678
[32m[0514 05:03:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9393916726112366, Train Loss: 1.000190019607544
[32m[0514 05:03:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9394209384918213, Train Loss: 1.0001864433288574
[32m[0514 05:03:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9394491314888, Train Loss: 1.0001829862594604
[32m[0514 05:03:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9394761919975281, Train Loss: 1.0001800060272217
[32m[0514 05:03:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9395022988319397, Train Loss: 1.000177264213562
[32m[0514 05:03:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9395272731781006, Train Loss: 1.000174880027771
[32m[0514 05:03:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9395512938499451, Train Loss: 1.0001726150512695
[32m[0514 05:03:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9395743608474731, Train Loss: 1.0001705884933472
[32m[0514 05:03:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9395965337753296, Train Loss: 1.0001689195632935
[32m[0514 05:03:22 @base_main.py:38][0m --------------- Iteration 3 ---------------
[32m[0514 05:03:22 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 3.2746 mins
[32m[0514 05:03:22 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 3.1594 mins
[32m[0514 05:03:22 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0553 mins
[32m[0514 05:03:22 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0079 mins
[32m[0514 05:03:22 @base_main.py:47][0m 3015 total steps have happened
[32m[0514 05:03:22 @base_main.py:52][0m [avg_reward]: -1291.34655619251
[32m[0514 05:03:22 @base_main.py:52][0m [update_op]: None
[32m[0514 05:03:22 @base_main.py:52][0m [train_loss]: 0.6197681427001953
[32m[0514 05:03:22 @base_main.py:52][0m [val_loss]: 0.9395965337753296
[32m[0514 05:03:22 @base_main.py:52][0m [avg_train_loss]: 1.0001689195632935
[32m[0514 05:04:00 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:04:38 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:05:16 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:05:52 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:06:30 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:06:30 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:06:30 @base_trainer.py:216][0m Mean reward: -1072.1807232035237
[32m[0514 05:06:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.201996088027954, Train Loss: 1.0188559293746948
[32m[0514 05:06:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.202032208442688, Train Loss: 1.018851399421692
[32m[0514 05:06:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.202078938484192, Train Loss: 1.0188419818878174
[32m[0514 05:06:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2021290063858032, Train Loss: 1.0188313722610474
[32m[0514 05:06:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.202178716659546, Train Loss: 1.0188210010528564
[32m[0514 05:06:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2022264003753662, Train Loss: 1.0188114643096924
[32m[0514 05:06:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2022712230682373, Train Loss: 1.0188028812408447
[32m[0514 05:06:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2023124694824219, Train Loss: 1.0187952518463135
[32m[0514 05:06:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2023507356643677, Train Loss: 1.0187888145446777
[32m[0514 05:06:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2023857831954956, Train Loss: 1.0187829732894897
[32m[0514 05:06:32 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2024179697036743, Train Loss: 1.0187780857086182
[32m[0514 05:06:32 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2024476528167725, Train Loss: 1.0187739133834839
[32m[0514 05:06:32 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.20247483253479, Train Loss: 1.0187699794769287
[32m[0514 05:06:32 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2024996280670166, Train Loss: 1.0187667608261108
[32m[0514 05:06:32 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2025223970413208, Train Loss: 1.0187638998031616
[32m[0514 05:06:32 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2025432586669922, Train Loss: 1.018761396408081
[32m[0514 05:06:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2025624513626099, Train Loss: 1.0187591314315796
[32m[0514 05:06:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2025803327560425, Train Loss: 1.0187571048736572
[32m[0514 05:06:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2025965452194214, Train Loss: 1.018755555152893
[32m[0514 05:06:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2026114463806152, Train Loss: 1.0187538862228394
[32m[0514 05:06:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2026251554489136, Train Loss: 1.0187525749206543
[32m[0514 05:06:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2026379108428955, Train Loss: 1.0187513828277588
[32m[0514 05:06:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.202649712562561, Train Loss: 1.0187503099441528
[32m[0514 05:06:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2026604413986206, Train Loss: 1.018749475479126
[32m[0514 05:06:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2026705741882324, Train Loss: 1.0187486410140991
[32m[0514 05:06:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2026798725128174, Train Loss: 1.0187479257583618
[32m[0514 05:06:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.202688217163086, Train Loss: 1.0187472105026245
[32m[0514 05:06:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2026960849761963, Train Loss: 1.0187466144561768
[32m[0514 05:06:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2027034759521484, Train Loss: 1.0187461376190186
[32m[0514 05:06:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.202710509300232, Train Loss: 1.0187455415725708
[32m[0514 05:06:35 @base_main.py:38][0m --------------- Iteration 4 ---------------
[32m[0514 05:06:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 6.4973 mins
[32m[0514 05:06:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 3.1328 mins
[32m[0514 05:06:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0774 mins
[32m[0514 05:06:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0074 mins
[32m[0514 05:06:35 @base_main.py:47][0m 4020 total steps have happened
[32m[0514 05:06:35 @base_main.py:52][0m [avg_reward]: -1072.1807232035237
[32m[0514 05:06:35 @base_main.py:52][0m [update_op]: None
[32m[0514 05:06:35 @base_main.py:52][0m [train_loss]: 0.8147423267364502
[32m[0514 05:06:35 @base_main.py:52][0m [val_loss]: 1.202710509300232
[32m[0514 05:06:35 @base_main.py:52][0m [avg_train_loss]: 1.0187455415725708
[32m[0514 05:07:13 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:07:51 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:08:29 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:09:05 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:09:43 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:09:43 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:09:43 @base_trainer.py:216][0m Mean reward: -1220.559171732351
[32m[0514 05:09:44 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9663960337638855, Train Loss: 0.9910233616828918
[32m[0514 05:09:44 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9663903713226318, Train Loss: 0.9910192489624023
[32m[0514 05:09:44 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.966387152671814, Train Loss: 0.9910142421722412
[32m[0514 05:09:44 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9663851857185364, Train Loss: 0.9910095930099487
[32m[0514 05:09:44 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9663839340209961, Train Loss: 0.9910058975219727
[32m[0514 05:09:45 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9663829803466797, Train Loss: 0.9910030364990234
[32m[0514 05:09:45 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9663819670677185, Train Loss: 0.9910008311271667
[32m[0514 05:09:45 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9663808941841125, Train Loss: 0.9909992218017578
[32m[0514 05:09:45 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9663798809051514, Train Loss: 0.9909980297088623
[32m[0514 05:09:45 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9663788676261902, Train Loss: 0.9909971952438354
[32m[0514 05:09:46 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9663777947425842, Train Loss: 0.9909963607788086
[32m[0514 05:09:46 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9663766026496887, Train Loss: 0.9909958243370056
[32m[0514 05:09:46 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9663754105567932, Train Loss: 0.9909955263137817
[32m[0514 05:09:46 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9663740992546082, Train Loss: 0.9909951686859131
[32m[0514 05:09:46 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9663729071617126, Train Loss: 0.9909949898719788
[32m[0514 05:09:47 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9663716554641724, Train Loss: 0.9909947514533997
[32m[0514 05:09:47 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9663705825805664, Train Loss: 0.9909946918487549
[32m[0514 05:09:47 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9663695096969604, Train Loss: 0.9909945726394653
[32m[0514 05:09:47 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9663683176040649, Train Loss: 0.9909944534301758
[32m[0514 05:09:47 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9663673043251038, Train Loss: 0.9909944534301758
[32m[0514 05:09:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9663663506507874, Train Loss: 0.9909943342208862
[32m[0514 05:09:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9663655757904053, Train Loss: 0.9909942150115967
[32m[0514 05:09:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9663647413253784, Train Loss: 0.9909943342208862
[32m[0514 05:09:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9663637280464172, Train Loss: 0.9909942150115967
[32m[0514 05:09:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9663630723953247, Train Loss: 0.9909943342208862
[32m[0514 05:09:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9663623571395874, Train Loss: 0.9909942150115967
[32m[0514 05:09:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9663616418838501, Train Loss: 0.9909942150115967
[32m[0514 05:09:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9663610458374023, Train Loss: 0.9909942150115967
[32m[0514 05:09:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9663605093955994, Train Loss: 0.9909942150115967
[32m[0514 05:09:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9663599133491516, Train Loss: 0.9909942150115967
[32m[0514 05:09:50 @base_main.py:38][0m --------------- Iteration 5 ---------------
[32m[0514 05:09:50 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 9.7151 mins
[32m[0514 05:09:50 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 3.1396 mins
[32m[0514 05:09:50 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0955 mins
[32m[0514 05:09:50 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0073 mins
[32m[0514 05:09:50 @base_main.py:47][0m 5025 total steps have happened
[32m[0514 05:09:50 @base_main.py:52][0m [avg_reward]: -1220.559171732351
[32m[0514 05:09:50 @base_main.py:52][0m [update_op]: None
[32m[0514 05:09:50 @base_main.py:52][0m [train_loss]: 1.0663433074951172
[32m[0514 05:09:50 @base_main.py:52][0m [val_loss]: 0.9663599133491516
[32m[0514 05:09:50 @base_main.py:52][0m [avg_train_loss]: 0.9909942150115967
[32m[0514 05:10:27 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:11:05 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:11:42 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:12:19 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:12:57 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:12:57 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:12:57 @base_trainer.py:216][0m Mean reward: -1153.835657536831
[32m[0514 05:12:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9810382723808289, Train Loss: 0.9927984476089478
[32m[0514 05:12:58 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9810402393341064, Train Loss: 0.9927976727485657
[32m[0514 05:12:58 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.981042206287384, Train Loss: 0.9927968978881836
[32m[0514 05:12:58 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9810440540313721, Train Loss: 0.9927963614463806
[32m[0514 05:12:58 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9810459613800049, Train Loss: 0.992796003818512
[32m[0514 05:12:59 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9810479879379272, Train Loss: 0.9927957653999329
[32m[0514 05:12:59 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9810498952865601, Train Loss: 0.9927954077720642
[32m[0514 05:12:59 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9810516238212585, Train Loss: 0.9927952289581299
[32m[0514 05:12:59 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.981053352355957, Train Loss: 0.9927951693534851
[32m[0514 05:13:00 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.981054961681366, Train Loss: 0.9927950501441956
[32m[0514 05:13:00 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9810565114021301, Train Loss: 0.9927949905395508
[32m[0514 05:13:00 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9810580015182495, Train Loss: 0.992794930934906
[32m[0514 05:13:00 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9810593724250793, Train Loss: 0.992794930934906
[32m[0514 05:13:00 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9810606241226196, Train Loss: 0.992794930934906
[32m[0514 05:13:01 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9810616970062256, Train Loss: 0.992794930934906
[32m[0514 05:13:01 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9810628294944763, Train Loss: 0.992794930934906
[32m[0514 05:13:01 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9810637831687927, Train Loss: 0.992794930934906
[32m[0514 05:13:01 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9810647964477539, Train Loss: 0.9927947521209717
[32m[0514 05:13:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.981065571308136, Train Loss: 0.9927947521209717
[32m[0514 05:13:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9810664653778076, Train Loss: 0.9927947521209717
[32m[0514 05:13:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9810671210289001, Train Loss: 0.9927948117256165
[32m[0514 05:13:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9810678362846375, Train Loss: 0.9927947521209717
[32m[0514 05:13:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.98106849193573, Train Loss: 0.9927948117256165
[32m[0514 05:13:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9810689687728882, Train Loss: 0.9927948117256165
[32m[0514 05:13:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9810695052146912, Train Loss: 0.9927948117256165
[32m[0514 05:13:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9810699224472046, Train Loss: 0.9927948117256165
[32m[0514 05:13:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9810704588890076, Train Loss: 0.9927948117256165
[32m[0514 05:13:04 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9810708165168762, Train Loss: 0.9927947521209717
[32m[0514 05:13:04 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9810711741447449, Train Loss: 0.9927947521209717
[32m[0514 05:13:04 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.981071412563324, Train Loss: 0.9927947521209717
[32m[0514 05:13:05 @base_main.py:38][0m --------------- Iteration 6 ---------------
[32m[0514 05:13:05 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 12.9576 mins
[32m[0514 05:13:05 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 3.1280 mins
[32m[0514 05:13:05 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.1159 mins
[32m[0514 05:13:05 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0072 mins
[32m[0514 05:13:05 @base_main.py:47][0m 6030 total steps have happened
[32m[0514 05:13:05 @base_main.py:52][0m [avg_reward]: -1153.835657536831
[32m[0514 05:13:05 @base_main.py:52][0m [update_op]: None
[32m[0514 05:13:05 @base_main.py:52][0m [train_loss]: 1.0393093824386597
[32m[0514 05:13:05 @base_main.py:52][0m [val_loss]: 0.981071412563324
[32m[0514 05:13:05 @base_main.py:52][0m [avg_train_loss]: 0.9927947521209717
[32m[0514 05:13:42 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:14:20 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:14:55 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:15:27 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:16:04 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:16:04 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:16:04 @base_trainer.py:216][0m Mean reward: -1177.4641549596463
[32m[0514 05:16:05 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.064619541168213, Train Loss: 0.9911925792694092
[32m[0514 05:16:05 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.064630389213562, Train Loss: 0.9911918640136719
[32m[0514 05:16:05 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0646406412124634, Train Loss: 0.9911912679672241
[32m[0514 05:16:05 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0646493434906006, Train Loss: 0.9911907911300659
[32m[0514 05:16:06 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0646568536758423, Train Loss: 0.991190493106842
[32m[0514 05:16:06 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0646628141403198, Train Loss: 0.9911901950836182
[32m[0514 05:16:06 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0646679401397705, Train Loss: 0.9911900758743286
[32m[0514 05:16:06 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0646723508834839, Train Loss: 0.9911898970603943
[32m[0514 05:16:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0646756887435913, Train Loss: 0.99118971824646
[32m[0514 05:16:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0646785497665405, Train Loss: 0.9911898374557495
[32m[0514 05:16:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0646809339523315, Train Loss: 0.9911896586418152
[32m[0514 05:16:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0646828413009644, Train Loss: 0.99118971824646
[32m[0514 05:16:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.064684510231018, Train Loss: 0.9911896586418152
[32m[0514 05:16:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0646858215332031, Train Loss: 0.9911896586418152
[32m[0514 05:16:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0646867752075195, Train Loss: 0.9911895990371704
[32m[0514 05:16:09 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0646878480911255, Train Loss: 0.9911896586418152
[32m[0514 05:16:09 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0646883249282837, Train Loss: 0.9911895990371704
[32m[0514 05:16:09 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.064689040184021, Train Loss: 0.9911895990371704
[32m[0514 05:16:09 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0646893978118896, Train Loss: 0.9911896586418152
[32m[0514 05:16:10 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0646897554397583, Train Loss: 0.9911895990371704
[32m[0514 05:16:10 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0646902322769165, Train Loss: 0.9911895394325256
[32m[0514 05:16:10 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.064690351486206, Train Loss: 0.9911895990371704
[32m[0514 05:16:10 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0646905899047852, Train Loss: 0.9911895990371704
[32m[0514 05:16:11 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0646907091140747, Train Loss: 0.9911895394325256
[32m[0514 05:16:11 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0646908283233643, Train Loss: 0.9911895394325256
[32m[0514 05:16:11 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0646909475326538, Train Loss: 0.9911895394325256
[32m[0514 05:16:11 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0646910667419434, Train Loss: 0.9911895990371704
[32m[0514 05:16:12 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.064691185951233, Train Loss: 0.9911895990371704
[32m[0514 05:16:12 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.064691185951233, Train Loss: 0.9911896586418152
[32m[0514 05:16:12 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.064691424369812, Train Loss: 0.9911896586418152
[32m[0514 05:16:12 @base_main.py:38][0m --------------- Iteration 7 ---------------
[32m[0514 05:16:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 16.2089 mins
[32m[0514 05:16:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 2.9941 mins
[32m[0514 05:16:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.1289 mins
[32m[0514 05:16:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0068 mins
[32m[0514 05:16:12 @base_main.py:47][0m 7035 total steps have happened
[32m[0514 05:16:12 @base_main.py:52][0m [avg_reward]: -1177.4641549596463
[32m[0514 05:16:12 @base_main.py:52][0m [update_op]: None
[32m[0514 05:16:12 @base_main.py:52][0m [train_loss]: 0.8818060755729675
[32m[0514 05:16:12 @base_main.py:52][0m [val_loss]: 1.064691424369812
[32m[0514 05:16:12 @base_main.py:52][0m [avg_train_loss]: 0.9911896586418152
[32m[0514 05:16:12 @mbmf_trainer.py:160][0m Mean reward: -1175.6637255477426
[32m[0514 05:16:13 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.2951197624206543, Train Loss: 0.3001527786254883
[32m[0514 05:16:13 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.29523932933807373, Train Loss: 0.30001211166381836
[32m[0514 05:16:13 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.29525771737098694, Train Loss: 0.2999950647354126
[32m[0514 05:16:13 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.295204758644104, Train Loss: 0.2999878525733948
[32m[0514 05:16:13 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.29514575004577637, Train Loss: 0.29997745156288147
[32m[0514 05:16:13 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.2951066493988037, Train Loss: 0.299966961145401
[32m[0514 05:16:13 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.2950839698314667, Train Loss: 0.2999582588672638
[32m[0514 05:16:13 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.29506781697273254, Train Loss: 0.299951434135437
[32m[0514 05:16:13 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.2950528562068939, Train Loss: 0.2999459207057953
[32m[0514 05:16:13 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.2950381934642792, Train Loss: 0.2999410927295685
[32m[0514 05:16:13 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.2950246036052704, Train Loss: 0.2999366223812103
[32m[0514 05:16:13 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.295012503862381, Train Loss: 0.29993245005607605
[32m[0514 05:16:13 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.29500171542167664, Train Loss: 0.2999284565448761
[32m[0514 05:16:13 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.2949918508529663, Train Loss: 0.2999247610569
[32m[0514 05:16:13 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.2949826419353485, Train Loss: 0.2999212443828583
[32m[0514 05:16:13 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.2949739992618561, Train Loss: 0.2999178469181061
[32m[0514 05:16:13 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.29496562480926514, Train Loss: 0.29991456866264343
[32m[0514 05:16:13 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.2949577271938324, Train Loss: 0.29991140961647034
[32m[0514 05:16:13 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.29495003819465637, Train Loss: 0.2999083697795868
[32m[0514 05:16:13 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.29494261741638184, Train Loss: 0.299905389547348
[32m[0514 05:16:13 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.294935405254364, Train Loss: 0.2999024987220764
[32m[0514 05:16:14 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.2949283719062805, Train Loss: 0.2998996675014496
[32m[0514 05:16:14 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.2949214279651642, Train Loss: 0.29989686608314514
[32m[0514 05:16:14 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.2949146330356598, Train Loss: 0.29989418387413025
[32m[0514 05:16:14 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.29490795731544495, Train Loss: 0.2998914420604706
[32m[0514 05:16:14 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.2949013411998749, Train Loss: 0.29988887906074524
[32m[0514 05:16:14 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.29489484429359436, Train Loss: 0.2998862862586975
[32m[0514 05:16:14 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.2948884069919586, Train Loss: 0.29988375306129456
[32m[0514 05:16:14 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.29488205909729004, Train Loss: 0.2998812198638916
[32m[0514 05:16:14 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.29487574100494385, Train Loss: 0.2998787760734558
[32m[0514 05:16:14 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.2948695719242096, Train Loss: 0.29987624287605286
[32m[0514 05:16:14 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.29486340284347534, Train Loss: 0.29987385869026184
[32m[0514 05:16:14 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.29485729336738586, Train Loss: 0.29987141489982605
[32m[0514 05:16:14 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.29485127329826355, Train Loss: 0.29986903071403503
[32m[0514 05:16:14 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.294845312833786, Train Loss: 0.299866646528244
[32m[0514 05:16:14 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.29483938217163086, Train Loss: 0.2998642325401306
[32m[0514 05:16:14 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.29483360052108765, Train Loss: 0.299861878156662
[32m[0514 05:16:14 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.29482778906822205, Train Loss: 0.29985955357551575
[32m[0514 05:16:14 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.294822096824646, Train Loss: 0.29985716938972473
[32m[0514 05:16:14 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.29481643438339233, Train Loss: 0.2998548448085785
[32m[0514 05:16:14 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.29481086134910583, Train Loss: 0.29985249042510986
[32m[0514 05:16:14 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.2948053479194641, Train Loss: 0.299850195646286
[32m[0514 05:16:14 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.29479992389678955, Train Loss: 0.299847811460495
[32m[0514 05:16:14 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.294794499874115, Train Loss: 0.29984548687934875
[32m[0514 05:16:15 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.29478922486305237, Train Loss: 0.29984310269355774
[32m[0514 05:16:15 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.29478397965431213, Train Loss: 0.2998407781124115
[32m[0514 05:16:15 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.2947787642478943, Train Loss: 0.29983842372894287
[32m[0514 05:16:15 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.294773668050766, Train Loss: 0.29983606934547424
[32m[0514 05:16:15 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.29476863145828247, Train Loss: 0.2998337149620056
[32m[0514 05:16:15 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.2947636544704437, Train Loss: 0.299831360578537
[32m[0514 05:16:15 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.29475873708724976, Train Loss: 0.29982897639274597
[32m[0514 05:16:15 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.29475390911102295, Train Loss: 0.2998265326023102
[32m[0514 05:16:15 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.2947491407394409, Train Loss: 0.29982417821884155
[32m[0514 05:16:15 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.29474446177482605, Train Loss: 0.29982179403305054
[32m[0514 05:16:15 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.29473984241485596, Train Loss: 0.29981935024261475
[32m[0514 05:16:15 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.2947353422641754, Train Loss: 0.29981693625450134
[32m[0514 05:16:15 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.2947308421134949, Train Loss: 0.29981449246406555
[32m[0514 05:16:15 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.29472649097442627, Train Loss: 0.299811989068985
[32m[0514 05:16:15 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.29472213983535767, Train Loss: 0.2998095750808716
[32m[0514 05:16:15 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.2947179079055786, Train Loss: 0.2998071014881134
[32m[0514 05:16:15 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.29471373558044434, Train Loss: 0.2998046576976776
[32m[0514 05:16:15 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.2947096824645996, Train Loss: 0.29980209469795227
[32m[0514 05:16:15 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.29470565915107727, Train Loss: 0.2997995913028717
[32m[0514 05:16:15 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.2947017550468445, Train Loss: 0.29979705810546875
[32m[0514 05:16:15 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.29469791054725647, Train Loss: 0.2997945249080658
[32m[0514 05:16:15 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.29469409584999084, Train Loss: 0.29979196190834045
[32m[0514 05:16:15 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.29469040036201477, Train Loss: 0.2997893989086151
[32m[0514 05:16:15 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.29468682408332825, Train Loss: 0.29978683590888977
[32m[0514 05:16:16 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.2946832776069641, Train Loss: 0.29978421330451965
[32m[0514 05:16:16 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.29467982053756714, Train Loss: 0.2997816205024719
[32m[0514 05:16:16 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.2946764826774597, Train Loss: 0.2997789680957794
[32m[0514 05:16:16 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.2946731746196747, Train Loss: 0.2997763454914093
[32m[0514 05:16:16 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.2946699559688568, Train Loss: 0.2997736930847168
[32m[0514 05:16:16 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.2946668267250061, Train Loss: 0.2997709810733795
[32m[0514 05:16:16 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.29466378688812256, Train Loss: 0.299768328666687
[32m[0514 05:16:16 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.2946608066558838, Train Loss: 0.29976561665534973
[32m[0514 05:16:16 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.29465794563293457, Train Loss: 0.29976287484169006
[32m[0514 05:16:16 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.29465511441230774, Train Loss: 0.29976019263267517
[32m[0514 05:16:16 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.29465237259864807, Train Loss: 0.2997573912143707
[32m[0514 05:16:16 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.29464972019195557, Train Loss: 0.29975461959838867
[32m[0514 05:16:16 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.2946471571922302, Train Loss: 0.29975181818008423
[32m[0514 05:16:16 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.29464465379714966, Train Loss: 0.2997490465641022
[32m[0514 05:16:16 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.29464223980903625, Train Loss: 0.29974624514579773
[32m[0514 05:16:16 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.2946399450302124, Train Loss: 0.2997433841228485
[32m[0514 05:16:16 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.29463768005371094, Train Loss: 0.29974058270454407
[32m[0514 05:16:16 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.29463547468185425, Train Loss: 0.29973769187927246
[32m[0514 05:16:16 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.2946333885192871, Train Loss: 0.29973480105400085
[32m[0514 05:16:16 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.29463136196136475, Train Loss: 0.29973194003105164
[32m[0514 05:16:16 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.29462945461273193, Train Loss: 0.29972904920578003
[32m[0514 05:16:16 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.2946276068687439, Train Loss: 0.29972612857818604
[32m[0514 05:16:16 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.29462578892707825, Train Loss: 0.29972317814826965
[32m[0514 05:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.29462406039237976, Train Loss: 0.29972022771835327
[32m[0514 05:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.2946224510669708, Train Loss: 0.2997172772884369
[32m[0514 05:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.29462090134620667, Train Loss: 0.2997142970561981
[32m[0514 05:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.29461944103240967, Train Loss: 0.29971131682395935
[32m[0514 05:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.29461801052093506, Train Loss: 0.2997083365917206
[32m[0514 05:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.29461669921875, Train Loss: 0.2997053265571594
[32m[0514 05:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.29461541771888733, Train Loss: 0.29970231652259827
[32m[0514 05:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.2946142554283142, Train Loss: 0.29969924688339233
[32m[0514 05:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.29461315274238586, Train Loss: 0.2996962070465088
[32m[0514 05:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.2946121096611023, Train Loss: 0.29969313740730286
[32m[0514 05:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.2946111857891083, Train Loss: 0.2996900975704193
[32m[0514 05:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.29461032152175903, Train Loss: 0.299686998128891
[32m[0514 05:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.29460951685905457, Train Loss: 0.29968392848968506
[32m[0514 05:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.2946087718009949, Train Loss: 0.29968079924583435
[32m[0514 05:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.29460811614990234, Train Loss: 0.2996777296066284
[32m[0514 05:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.294607549905777, Train Loss: 0.2996746003627777
[32m[0514 05:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.2946069836616516, Train Loss: 0.2996715009212494
[32m[0514 05:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.2946065366268158, Train Loss: 0.2996683418750763
[32m[0514 05:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.29460620880126953, Train Loss: 0.2996651828289032
[32m[0514 05:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.29460588097572327, Train Loss: 0.2996620535850525
[32m[0514 05:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.29460570216178894, Train Loss: 0.299658864736557
[32m[0514 05:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.294605553150177, Train Loss: 0.2996557056903839
[32m[0514 05:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.29460546374320984, Train Loss: 0.2996525466442108
[32m[0514 05:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.29460543394088745, Train Loss: 0.29964932799339294
[32m[0514 05:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.2946054935455322, Train Loss: 0.29964616894721985
[32m[0514 05:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.2946056127548218, Train Loss: 0.299642950296402
[32m[0514 05:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.2946057915687561, Train Loss: 0.2996397614479065
[32m[0514 05:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.2946060597896576, Train Loss: 0.299636572599411
[32m[0514 05:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.29460638761520386, Train Loss: 0.29963335394859314
[32m[0514 05:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.2946068048477173, Train Loss: 0.29963013529777527
[32m[0514 05:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.2946073114871979, Train Loss: 0.299626886844635
[32m[0514 05:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.29460784792900085, Train Loss: 0.2996236979961395
[32m[0514 05:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.2946084439754486, Train Loss: 0.29962047934532166
[32m[0514 05:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.29460909962654114, Train Loss: 0.2996172308921814
[32m[0514 05:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.29460981488227844, Train Loss: 0.2996140420436859
[32m[0514 05:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.2946106195449829, Train Loss: 0.29961076378822327
[32m[0514 05:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.29461154341697693, Train Loss: 0.2996075451374054
[32m[0514 05:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.29461249709129333, Train Loss: 0.2996043264865875
[32m[0514 05:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.29461348056793213, Train Loss: 0.29960107803344727
[32m[0514 05:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.2946145534515381, Train Loss: 0.299597829580307
[32m[0514 05:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.2946156859397888, Train Loss: 0.29959458112716675
[32m[0514 05:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.2946168780326843, Train Loss: 0.2995913624763489
[32m[0514 05:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.2946181297302246, Train Loss: 0.299588143825531
[32m[0514 05:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.29461950063705444, Train Loss: 0.29958489537239075
[32m[0514 05:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.29462090134620667, Train Loss: 0.2995816767215729
[32m[0514 05:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.2946223318576813, Train Loss: 0.299578458070755
[32m[0514 05:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.29462385177612305, Train Loss: 0.29957520961761475
[32m[0514 05:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.2946254312992096, Train Loss: 0.2995719909667969
[32m[0514 05:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.2946271002292633, Train Loss: 0.2995687425136566
[32m[0514 05:16:19 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.294628769159317, Train Loss: 0.2995655834674835
[32m[0514 05:16:19 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.2946305274963379, Train Loss: 0.2995623052120209
[32m[0514 05:16:19 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.2946323752403259, Train Loss: 0.2995591163635254
[32m[0514 05:16:19 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.29463422298431396, Train Loss: 0.2995558977127075
[32m[0514 05:16:19 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.29463618993759155, Train Loss: 0.29955270886421204
[32m[0514 05:16:19 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.29463815689086914, Train Loss: 0.29954954981803894
[32m[0514 05:16:19 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.2946402132511139, Train Loss: 0.29954636096954346
[32m[0514 05:16:19 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.2946423888206482, Train Loss: 0.2995431423187256
[32m[0514 05:16:19 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.2946445345878601, Train Loss: 0.2995399832725525
[32m[0514 05:16:19 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.2946467399597168, Train Loss: 0.2995368540287018
[32m[0514 05:16:19 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.29464900493621826, Train Loss: 0.2995336949825287
[32m[0514 05:16:19 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.2946513295173645, Train Loss: 0.2995305359363556
[32m[0514 05:16:19 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.2946537137031555, Train Loss: 0.2995273172855377
[32m[0514 05:16:19 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.2946561574935913, Train Loss: 0.2995242476463318
[32m[0514 05:16:19 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.2946586608886719, Train Loss: 0.2995210886001587
[32m[0514 05:16:19 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.2946612238883972, Train Loss: 0.299517959356308
[32m[0514 05:16:19 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.29466378688812256, Train Loss: 0.29951485991477966
[32m[0514 05:16:19 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.29466643929481506, Train Loss: 0.29951176047325134
[32m[0514 05:16:19 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.29466915130615234, Train Loss: 0.2995086908340454
[32m[0514 05:16:19 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.294671893119812, Train Loss: 0.2995056211948395
[32m[0514 05:16:19 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.29467469453811646, Train Loss: 0.29950255155563354
[32m[0514 05:16:19 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.2946775257587433, Train Loss: 0.29949951171875
[32m[0514 05:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.2946804165840149, Train Loss: 0.29949644207954407
[32m[0514 05:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.2946833670139313, Train Loss: 0.2994934022426605
[32m[0514 05:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.29468631744384766, Train Loss: 0.29949039220809937
[32m[0514 05:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.2946893572807312, Train Loss: 0.2994873821735382
[32m[0514 05:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.29469239711761475, Train Loss: 0.29948437213897705
[32m[0514 05:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.29469549655914307, Train Loss: 0.29948142170906067
[32m[0514 05:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.29469868540763855, Train Loss: 0.2994784414768219
[32m[0514 05:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.29470187425613403, Train Loss: 0.29947546124458313
[32m[0514 05:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.2947051227092743, Train Loss: 0.29947254061698914
[32m[0514 05:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.2947084307670593, Train Loss: 0.29946959018707275
[32m[0514 05:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.29471173882484436, Train Loss: 0.29946663975715637
[32m[0514 05:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.2947150766849518, Train Loss: 0.29946374893188477
[32m[0514 05:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.29471850395202637, Train Loss: 0.29946085810661316
[32m[0514 05:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.29472193121910095, Train Loss: 0.29945799708366394
[32m[0514 05:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.2947253882884979, Train Loss: 0.2994551360607147
[32m[0514 05:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.29472893476486206, Train Loss: 0.2994522750377655
[32m[0514 05:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.2947324812412262, Train Loss: 0.29944947361946106
[32m[0514 05:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.29473602771759033, Train Loss: 0.29944661259651184
[32m[0514 05:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.294739693403244, Train Loss: 0.2994438111782074
[32m[0514 05:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.2947433590888977, Train Loss: 0.29944100975990295
[32m[0514 05:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.2947470247745514, Train Loss: 0.2994382679462433
[32m[0514 05:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.29475075006484985, Train Loss: 0.29943549633026123
[32m[0514 05:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.2947544753551483, Train Loss: 0.29943278431892395
[32m[0514 05:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.29475829005241394, Train Loss: 0.2994300425052643
[32m[0514 05:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.29476210474967957, Train Loss: 0.2994273006916046
[32m[0514 05:16:21 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.2947659492492676, Train Loss: 0.2994246184825897
[32m[0514 05:16:21 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.2947697937488556, Train Loss: 0.29942193627357483
[32m[0514 05:16:21 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.2947736978530884, Train Loss: 0.29941925406455994
[32m[0514 05:16:21 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.29477763175964355, Train Loss: 0.2994166314601898
[32m[0514 05:16:21 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.29478156566619873, Train Loss: 0.2994139492511749
[32m[0514 05:16:21 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.29478558897972107, Train Loss: 0.2994113862514496
[32m[0514 05:16:21 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.2947896122932434, Train Loss: 0.29940876364707947
[32m[0514 05:16:21 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.29479363560676575, Train Loss: 0.29940617084503174
[32m[0514 05:16:21 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.2947976887226105, Train Loss: 0.299403578042984
[32m[0514 05:16:21 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.2948017716407776, Train Loss: 0.29940101504325867
[32m[0514 05:16:21 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.2948058843612671, Train Loss: 0.2993985116481781
[32m[0514 05:16:21 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.294810026884079, Train Loss: 0.29939597845077515
[32m[0514 05:16:21 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.29481416940689087, Train Loss: 0.2993934750556946
[32m[0514 05:16:21 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.29481834173202515, Train Loss: 0.299390971660614
[32m[0514 05:16:21 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.2948225438594818, Train Loss: 0.29938849806785583
[32m[0514 05:16:21 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.29482677578926086, Train Loss: 0.29938605427742004
[32m[0514 05:16:21 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.2948310077190399, Train Loss: 0.29938361048698425
[32m[0514 05:16:21 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.29483526945114136, Train Loss: 0.29938119649887085
[32m[0514 05:16:21 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.2948395609855652, Train Loss: 0.29937875270843506
[32m[0514 05:16:21 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.294843852519989, Train Loss: 0.29937636852264404
[32m[0514 05:16:21 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.29484814405441284, Train Loss: 0.2993740141391754
[32m[0514 05:16:21 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.29485249519348145, Train Loss: 0.2993716299533844
[32m[0514 05:16:21 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.29485684633255005, Train Loss: 0.29936927556991577
[32m[0514 05:16:21 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.29486119747161865, Train Loss: 0.29936695098876953
[32m[0514 05:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.29486557841300964, Train Loss: 0.2993645966053009
[32m[0514 05:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.294869989156723, Train Loss: 0.29936233162879944
[32m[0514 05:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.294874370098114, Train Loss: 0.2993600070476532
[32m[0514 05:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.2948787808418274, Train Loss: 0.29935771226882935
[32m[0514 05:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.29488319158554077, Train Loss: 0.29935547709465027
[32m[0514 05:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.2948876917362213, Train Loss: 0.2993532419204712
[32m[0514 05:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.2948921322822571, Train Loss: 0.2993510067462921
[32m[0514 05:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.29489660263061523, Train Loss: 0.2993488013744354
[32m[0514 05:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.2949010729789734, Train Loss: 0.29934659600257874
[32m[0514 05:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.29490557312965393, Train Loss: 0.2993444502353668
[32m[0514 05:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.29491010308265686, Train Loss: 0.2993422746658325
[32m[0514 05:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.294914573431015, Train Loss: 0.2993400990962982
[32m[0514 05:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.29491913318634033, Train Loss: 0.2993379235267639
[32m[0514 05:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.29492366313934326, Train Loss: 0.2993358075618744
[32m[0514 05:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.2949282228946686, Train Loss: 0.29933372139930725
[32m[0514 05:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.2949327528476715, Train Loss: 0.2993316352367401
[32m[0514 05:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.2949373126029968, Train Loss: 0.299329549074173
[32m[0514 05:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.29494187235832214, Train Loss: 0.2993274927139282
[32m[0514 05:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.29494643211364746, Train Loss: 0.29932543635368347
[32m[0514 05:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.29495102167129517, Train Loss: 0.2993233799934387
[32m[0514 05:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.2949555814266205, Train Loss: 0.29932138323783875
[32m[0514 05:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.2949602007865906, Train Loss: 0.2993193566799164
[32m[0514 05:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.29496482014656067, Train Loss: 0.299317330121994
[32m[0514 05:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.294969379901886, Train Loss: 0.29931536316871643
[32m[0514 05:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.2949739992618561, Train Loss: 0.29931339621543884
[32m[0514 05:16:23 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.29497864842414856, Train Loss: 0.29931142926216125
[32m[0514 05:16:23 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.2949832081794739, Train Loss: 0.29930949211120605
[32m[0514 05:16:23 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.29498782753944397, Train Loss: 0.29930755496025085
[32m[0514 05:16:23 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.29499244689941406, Train Loss: 0.29930564761161804
[32m[0514 05:16:23 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.29499709606170654, Train Loss: 0.29930374026298523
[32m[0514 05:16:23 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.29500168561935425, Train Loss: 0.29930180311203003
[32m[0514 05:16:23 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.2950063645839691, Train Loss: 0.2992999255657196
[32m[0514 05:16:23 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.29501092433929443, Train Loss: 0.29929807782173157
[32m[0514 05:16:23 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.2950155735015869, Train Loss: 0.29929623007774353
[32m[0514 05:16:23 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.295020192861557, Train Loss: 0.2992943823337555
[32m[0514 05:16:23 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.2950248420238495, Train Loss: 0.29929253458976746
[32m[0514 05:16:23 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.2950294315814972, Train Loss: 0.2992906868457794
[32m[0514 05:16:23 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.2950340807437897, Train Loss: 0.29928889870643616
[32m[0514 05:16:23 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.29503870010375977, Train Loss: 0.2992870807647705
[32m[0514 05:16:23 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.29504334926605225, Train Loss: 0.29928532242774963
[32m[0514 05:16:23 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.29504796862602234, Train Loss: 0.29928353428840637
[32m[0514 05:16:23 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.2950526177883148, Train Loss: 0.2992817759513855
[32m[0514 05:16:23 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.2950572073459625, Train Loss: 0.2992800176143646
[32m[0514 05:16:23 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.2950618267059326, Train Loss: 0.29927825927734375
[32m[0514 05:16:23 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.2950664460659027, Train Loss: 0.29927653074264526
[32m[0514 05:16:23 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.2950710654258728, Train Loss: 0.2992748022079468
[32m[0514 05:16:23 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.2950756847858429, Train Loss: 0.2992730736732483
[32m[0514 05:16:23 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.2950802743434906, Train Loss: 0.2992713749408722
[32m[0514 05:16:23 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.2950848937034607, Train Loss: 0.2992696762084961
[32m[0514 05:16:23 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.2950895130634308, Train Loss: 0.2992680072784424
[32m[0514 05:16:24 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.2950941026210785, Train Loss: 0.2992663085460663
[32m[0514 05:16:24 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.2950987219810486, Train Loss: 0.2992646396160126
[32m[0514 05:16:24 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.2951032817363739, Train Loss: 0.29926300048828125
[32m[0514 05:16:24 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.295107901096344, Train Loss: 0.29926133155822754
[32m[0514 05:16:24 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.2951124906539917, Train Loss: 0.299259752035141
[32m[0514 05:16:24 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.2951170802116394, Train Loss: 0.2992580831050873
[32m[0514 05:16:24 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.2951216399669647, Train Loss: 0.29925647377967834
[32m[0514 05:16:24 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.29512619972229004, Train Loss: 0.2992548644542694
[32m[0514 05:16:24 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.29513078927993774, Train Loss: 0.2992532551288605
[32m[0514 05:16:24 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.29513534903526306, Train Loss: 0.2992517054080963
[32m[0514 05:16:24 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.2951399087905884, Train Loss: 0.2992500960826874
[32m[0514 05:16:24 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.2951444685459137, Train Loss: 0.2992485463619232
[32m[0514 05:16:24 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.2951489984989166, Train Loss: 0.29924696683883667
[32m[0514 05:16:24 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.29515349864959717, Train Loss: 0.2992454171180725
[32m[0514 05:16:24 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.2951580584049225, Train Loss: 0.29924386739730835
[32m[0514 05:16:24 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.295162558555603, Train Loss: 0.2992423474788666
[32m[0514 05:16:24 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.29516711831092834, Train Loss: 0.29924073815345764
[32m[0514 05:16:24 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.2951715886592865, Train Loss: 0.29923921823501587
[32m[0514 05:16:24 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.29517611861228943, Train Loss: 0.2992377281188965
[32m[0514 05:16:24 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.29518061876296997, Train Loss: 0.2992362082004547
[32m[0514 05:16:24 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.2951851189136505, Train Loss: 0.2992347180843353
[32m[0514 05:16:24 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.29518958926200867, Train Loss: 0.29923322796821594
[32m[0514 05:16:24 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.2951940894126892, Train Loss: 0.29923173785209656
[32m[0514 05:16:24 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.29519855976104736, Train Loss: 0.2992302477359772
[32m[0514 05:16:25 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.2952030301094055, Train Loss: 0.29922881722450256
[32m[0514 05:16:25 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.2952074408531189, Train Loss: 0.2992272973060608
[32m[0514 05:16:25 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.29521191120147705, Train Loss: 0.2992258369922638
[32m[0514 05:16:25 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.2952163815498352, Train Loss: 0.2992244064807892
[32m[0514 05:16:25 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.2952207922935486, Train Loss: 0.2992229759693146
[32m[0514 05:16:25 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.29522523283958435, Train Loss: 0.29922154545783997
[32m[0514 05:16:25 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.29522964358329773, Train Loss: 0.29922011494636536
[32m[0514 05:16:25 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.2952340543270111, Train Loss: 0.29921868443489075
[32m[0514 05:16:25 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.2952384650707245, Train Loss: 0.29921725392341614
[32m[0514 05:16:25 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.29524287581443787, Train Loss: 0.29921582341194153
[32m[0514 05:16:25 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.29524725675582886, Train Loss: 0.2992144525051117
[32m[0514 05:16:25 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.29525163769721985, Train Loss: 0.2992130517959595
[32m[0514 05:16:25 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.29525601863861084, Train Loss: 0.29921165108680725
[32m[0514 05:16:25 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.29526036977767944, Train Loss: 0.29921025037765503
[32m[0514 05:16:25 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.29526472091674805, Train Loss: 0.2992088794708252
[32m[0514 05:16:25 @mbmf_sampler.py:98][0m Finished 9th episode
[32m[0514 05:16:25 @mbmf_sampler.py:102][0m 1809 timesteps from 9 episodes collected
[32m[0514 05:21:59 @mbmf_trainer.py:160][0m Mean reward: -1174.9491615553336
[32m[0514 05:21:59 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.30706721544265747, Train Loss: 0.2985462248325348
[32m[0514 05:21:59 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.30703648924827576, Train Loss: 0.29848381876945496
[32m[0514 05:21:59 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.30701497197151184, Train Loss: 0.29845765233039856
[32m[0514 05:21:59 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.30703604221343994, Train Loss: 0.29845282435417175
[32m[0514 05:21:59 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.307049036026001, Train Loss: 0.2984469532966614
[32m[0514 05:21:59 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.30704984068870544, Train Loss: 0.2984412610530853
[32m[0514 05:21:59 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.3070508539676666, Train Loss: 0.29843708872795105
[32m[0514 05:21:59 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.3070530593395233, Train Loss: 0.29843324422836304
[32m[0514 05:21:59 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.30705463886260986, Train Loss: 0.29842934012413025
[32m[0514 05:21:59 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.30705586075782776, Train Loss: 0.2984255254268646
[32m[0514 05:22:00 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.3070571720600128, Train Loss: 0.2984219193458557
[32m[0514 05:22:00 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.3070586621761322, Train Loss: 0.2984185218811035
[32m[0514 05:22:00 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.30706000328063965, Train Loss: 0.2984152138233185
[32m[0514 05:22:00 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.3070613741874695, Train Loss: 0.298412024974823
[32m[0514 05:22:00 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.3070627748966217, Train Loss: 0.29840895533561707
[32m[0514 05:22:00 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.3070642352104187, Train Loss: 0.29840603470802307
[32m[0514 05:22:00 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.3070656955242157, Train Loss: 0.29840317368507385
[32m[0514 05:22:00 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.3070671260356903, Train Loss: 0.298400342464447
[32m[0514 05:22:00 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.3070685565471649, Train Loss: 0.29839763045310974
[32m[0514 05:22:00 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.3070700764656067, Train Loss: 0.29839494824409485
[32m[0514 05:22:00 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.30707162618637085, Train Loss: 0.2983923554420471
[32m[0514 05:22:00 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.30707308650016785, Train Loss: 0.29838985204696655
[32m[0514 05:22:00 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.30707457661628723, Train Loss: 0.2983873188495636
[32m[0514 05:22:00 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.3070761561393738, Train Loss: 0.2983848750591278
[32m[0514 05:22:00 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.30707764625549316, Train Loss: 0.2983824610710144
[32m[0514 05:22:00 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.3070792555809021, Train Loss: 0.298380047082901
[32m[0514 05:22:00 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.3070807456970215, Train Loss: 0.29837778210639954
[32m[0514 05:22:00 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.3070823848247528, Train Loss: 0.29837551712989807
[32m[0514 05:22:00 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.3070838451385498, Train Loss: 0.2983732223510742
[32m[0514 05:22:00 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.30708539485931396, Train Loss: 0.29837098717689514
[32m[0514 05:22:01 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.30708691477775574, Train Loss: 0.29836881160736084
[32m[0514 05:22:01 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.3070885241031647, Train Loss: 0.29836663603782654
[32m[0514 05:22:01 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.30709007382392883, Train Loss: 0.298364520072937
[32m[0514 05:22:01 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.3070915639400482, Train Loss: 0.2983623743057251
[32m[0514 05:22:01 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.3070931136608124, Train Loss: 0.29836031794548035
[32m[0514 05:22:01 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.30709460377693176, Train Loss: 0.2983582615852356
[32m[0514 05:22:01 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.30709612369537354, Train Loss: 0.29835617542266846
[32m[0514 05:22:01 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.3070976734161377, Train Loss: 0.29835420846939087
[32m[0514 05:22:01 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.3070991039276123, Train Loss: 0.2983521819114685
[32m[0514 05:22:01 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.3071005940437317, Train Loss: 0.29835018515586853
[32m[0514 05:22:01 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.3071020543575287, Train Loss: 0.29834821820259094
[32m[0514 05:22:01 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.3071034848690033, Train Loss: 0.29834631085395813
[32m[0514 05:22:01 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.3071049451828003, Train Loss: 0.29834434390068054
[32m[0514 05:22:01 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.3071063160896301, Train Loss: 0.29834243655204773
[32m[0514 05:22:01 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.30710774660110474, Train Loss: 0.29834049940109253
[32m[0514 05:22:01 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.30710914731025696, Train Loss: 0.2983386218547821
[32m[0514 05:22:01 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.307110458612442, Train Loss: 0.29833680391311646
[32m[0514 05:22:01 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.30711182951927185, Train Loss: 0.29833489656448364
[32m[0514 05:22:02 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.3071131706237793, Train Loss: 0.2983330488204956
[32m[0514 05:22:02 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.30711448192596436, Train Loss: 0.29833123087882996
[32m[0514 05:22:02 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.3071157932281494, Train Loss: 0.2983293831348419
[32m[0514 05:22:02 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.3071170747280121, Train Loss: 0.29832756519317627
[32m[0514 05:22:02 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.30711835622787476, Train Loss: 0.2983258068561554
[32m[0514 05:22:02 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.30711954832077026, Train Loss: 0.29832398891448975
[32m[0514 05:22:02 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.30712080001831055, Train Loss: 0.29832223057746887
[32m[0514 05:22:02 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.3071220815181732, Train Loss: 0.2983204424381256
[32m[0514 05:22:02 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.30712324380874634, Train Loss: 0.29831868410110474
[32m[0514 05:22:02 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.30712440609931946, Train Loss: 0.29831692576408386
[32m[0514 05:22:02 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.30712559819221497, Train Loss: 0.298315167427063
[32m[0514 05:22:02 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.3071267306804657, Train Loss: 0.2983134686946869
[32m[0514 05:22:02 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.30712783336639404, Train Loss: 0.2983117401599884
[32m[0514 05:22:02 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.3071289658546448, Train Loss: 0.29830998182296753
[32m[0514 05:22:02 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.3071300685405731, Train Loss: 0.2983083128929138
[32m[0514 05:22:02 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.3071311414241791, Train Loss: 0.29830658435821533
[32m[0514 05:22:02 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.30713221430778503, Train Loss: 0.29830488562583923
[32m[0514 05:22:02 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.307133287191391, Train Loss: 0.29830318689346313
[32m[0514 05:22:03 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.3071342706680298, Train Loss: 0.2983015179634094
[32m[0514 05:22:03 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.30713528394699097, Train Loss: 0.2982998490333557
[32m[0514 05:22:03 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.30713632702827454, Train Loss: 0.298298180103302
[32m[0514 05:22:03 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.30713728070259094, Train Loss: 0.2982964813709259
[32m[0514 05:22:03 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.3071382939815521, Train Loss: 0.2982948422431946
[32m[0514 05:22:03 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.3071392774581909, Train Loss: 0.29829317331314087
[32m[0514 05:22:03 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.30714017152786255, Train Loss: 0.29829150438308716
[32m[0514 05:22:03 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.30714112520217896, Train Loss: 0.29828986525535583
[32m[0514 05:22:03 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.3071420192718506, Train Loss: 0.2982882559299469
[32m[0514 05:22:03 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.3071429431438446, Train Loss: 0.2982866168022156
[32m[0514 05:22:03 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.3071438670158386, Train Loss: 0.29828497767448425
[32m[0514 05:22:03 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.30714473128318787, Train Loss: 0.2982833981513977
[32m[0514 05:22:03 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.3071455657482147, Train Loss: 0.2982816994190216
[32m[0514 05:22:03 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.30714648962020874, Train Loss: 0.29828011989593506
[32m[0514 05:22:03 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.3071472942829132, Train Loss: 0.29827848076820374
[32m[0514 05:22:03 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.30714812874794006, Train Loss: 0.2982768714427948
[32m[0514 05:22:03 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.3071489930152893, Train Loss: 0.29827526211738586
[32m[0514 05:22:03 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.3071497976779938, Train Loss: 0.29827362298965454
[32m[0514 05:22:03 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.30715063214302063, Train Loss: 0.2982720732688904
[32m[0514 05:22:04 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.3071514070034027, Train Loss: 0.29827043414115906
[32m[0514 05:22:04 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.3071521818637848, Train Loss: 0.2982688546180725
[32m[0514 05:22:04 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.30715301632881165, Train Loss: 0.29826727509498596
[32m[0514 05:22:04 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.30715373158454895, Train Loss: 0.29826563596725464
[32m[0514 05:22:04 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.3071545362472534, Train Loss: 0.2982640862464905
[32m[0514 05:22:04 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.3071552515029907, Train Loss: 0.29826250672340393
[32m[0514 05:22:04 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.307155966758728, Train Loss: 0.2982608675956726
[32m[0514 05:22:04 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.3071567416191101, Train Loss: 0.29825931787490845
[32m[0514 05:22:04 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.3071574866771698, Train Loss: 0.2982577681541443
[32m[0514 05:22:04 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.3071581721305847, Train Loss: 0.29825618863105774
[32m[0514 05:22:04 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.30715885758399963, Train Loss: 0.2982545793056488
[32m[0514 05:22:04 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.3071596026420593, Train Loss: 0.29825302958488464
[32m[0514 05:22:04 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.30716031789779663, Train Loss: 0.2982514798641205
[32m[0514 05:22:04 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.30716097354888916, Train Loss: 0.29824987053871155
[32m[0514 05:22:04 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.3071616590023041, Train Loss: 0.2982483506202698
[32m[0514 05:22:04 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.307162344455719, Train Loss: 0.2982467710971832
[32m[0514 05:22:04 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.3071630597114563, Train Loss: 0.29824522137641907
[32m[0514 05:22:04 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.30716371536254883, Train Loss: 0.2982436418533325
[32m[0514 05:22:04 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.30716437101364136, Train Loss: 0.29824212193489075
[32m[0514 05:22:05 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.3071650564670563, Train Loss: 0.2982405424118042
[32m[0514 05:22:05 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.3071657121181488, Train Loss: 0.2982390224933624
[32m[0514 05:22:05 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.30716636776924133, Train Loss: 0.2982374429702759
[32m[0514 05:22:05 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.3071669936180115, Train Loss: 0.2982358932495117
[32m[0514 05:22:05 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.307167649269104, Train Loss: 0.29823434352874756
[32m[0514 05:22:05 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.30716827511787415, Train Loss: 0.298232764005661
[32m[0514 05:22:05 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.3071689307689667, Train Loss: 0.29823124408721924
[32m[0514 05:22:05 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.30716952681541443, Train Loss: 0.29822972416877747
[32m[0514 05:22:05 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.30717018246650696, Train Loss: 0.2982282042503357
[32m[0514 05:22:05 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.3071707785129547, Train Loss: 0.29822662472724915
[32m[0514 05:22:05 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.30717140436172485, Train Loss: 0.298225075006485
[32m[0514 05:22:05 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.307172030210495, Train Loss: 0.2982235252857208
[32m[0514 05:22:05 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.3071726858615875, Train Loss: 0.29822203516960144
[32m[0514 05:22:05 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.3071732223033905, Train Loss: 0.2982204854488373
[32m[0514 05:22:05 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.30717384815216064, Train Loss: 0.29821890592575073
[32m[0514 05:22:05 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.3071744740009308, Train Loss: 0.29821738600730896
[32m[0514 05:22:05 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.3071750998497009, Train Loss: 0.2982158660888672
[32m[0514 05:22:05 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.3071756958961487, Train Loss: 0.2982143461704254
[32m[0514 05:22:05 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.30717626214027405, Train Loss: 0.29821282625198364
[32m[0514 05:22:06 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.3071768581867218, Train Loss: 0.2982112765312195
[32m[0514 05:22:06 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.30717748403549194, Train Loss: 0.2982097566127777
[32m[0514 05:22:06 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.3071780800819397, Train Loss: 0.29820823669433594
[32m[0514 05:22:06 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.30717864632606506, Train Loss: 0.29820671677589417
[32m[0514 05:22:06 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.3071792423725128, Train Loss: 0.2982051968574524
[32m[0514 05:22:06 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.30717986822128296, Train Loss: 0.29820364713668823
[32m[0514 05:22:06 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.30718040466308594, Train Loss: 0.29820212721824646
[32m[0514 05:22:06 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.3071810007095337, Train Loss: 0.2982006371021271
[32m[0514 05:22:06 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.30718162655830383, Train Loss: 0.2981991171836853
[32m[0514 05:22:06 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.3071821630001068, Train Loss: 0.2981976270675659
[32m[0514 05:22:06 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.30718275904655457, Train Loss: 0.29819604754447937
[32m[0514 05:22:06 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.30718332529067993, Train Loss: 0.2981945276260376
[32m[0514 05:22:06 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.3071839213371277, Train Loss: 0.2981930375099182
[32m[0514 05:22:06 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.30718451738357544, Train Loss: 0.29819151759147644
[32m[0514 05:22:06 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.3071851134300232, Train Loss: 0.29818999767303467
[32m[0514 05:22:06 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.30718564987182617, Train Loss: 0.2981885075569153
[32m[0514 05:22:06 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.3071862459182739, Train Loss: 0.2981869578361511
[32m[0514 05:22:06 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.3071868419647217, Train Loss: 0.29818543791770935
[32m[0514 05:22:06 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.30718737840652466, Train Loss: 0.29818394780158997
[32m[0514 05:22:06 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.3071880042552948, Train Loss: 0.2981824576854706
[32m[0514 05:22:07 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.30718857049942017, Train Loss: 0.2981809675693512
[32m[0514 05:22:07 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.30718913674354553, Train Loss: 0.2981794774532318
[32m[0514 05:22:07 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.3071897327899933, Train Loss: 0.29817789793014526
[32m[0514 05:22:07 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.30719032883644104, Train Loss: 0.2981764078140259
[32m[0514 05:22:07 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.3071908950805664, Train Loss: 0.2981748878955841
[32m[0514 05:22:07 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.3071914613246918, Train Loss: 0.29817336797714233
[32m[0514 05:22:07 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.3071920871734619, Train Loss: 0.29817190766334534
[32m[0514 05:22:07 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.3071926236152649, Train Loss: 0.29817041754722595
[32m[0514 05:22:07 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.30719324946403503, Train Loss: 0.29816892743110657
[32m[0514 05:22:07 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.307193785905838, Train Loss: 0.2981674075126648
[32m[0514 05:22:07 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.30719438195228577, Train Loss: 0.298165887594223
[32m[0514 05:22:07 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.3071949779987335, Train Loss: 0.29816439747810364
[32m[0514 05:22:07 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.3071955740451813, Train Loss: 0.29816290736198425
[32m[0514 05:22:07 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.30719611048698425, Train Loss: 0.2981613576412201
[32m[0514 05:22:07 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.307196706533432, Train Loss: 0.2981598973274231
[32m[0514 05:22:07 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.30719736218452454, Train Loss: 0.29815834760665894
[32m[0514 05:22:07 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.3071978688240051, Train Loss: 0.29815685749053955
[32m[0514 05:22:07 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.3071984648704529, Train Loss: 0.29815536737442017
[32m[0514 05:22:07 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.3071991205215454, Train Loss: 0.2981538772583008
[32m[0514 05:22:08 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.3071996867656708, Train Loss: 0.2981523871421814
[32m[0514 05:22:08 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.30720025300979614, Train Loss: 0.298150897026062
[32m[0514 05:22:08 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.3072008490562439, Train Loss: 0.2981494069099426
[32m[0514 05:22:08 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.30720144510269165, Train Loss: 0.29814788699150085
[32m[0514 05:22:08 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.307202011346817, Train Loss: 0.29814639687538147
[32m[0514 05:22:08 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.30720260739326477, Train Loss: 0.2981449067592621
[32m[0514 05:22:08 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.3072032034397125, Train Loss: 0.2981434166431427
[32m[0514 05:22:08 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.30720382928848267, Train Loss: 0.2981419265270233
[32m[0514 05:22:08 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.30720436573028564, Train Loss: 0.29814043641090393
[32m[0514 05:22:08 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.3072050213813782, Train Loss: 0.29813897609710693
[32m[0514 05:22:08 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.30720558762550354, Train Loss: 0.29813748598098755
[32m[0514 05:22:08 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.3072062134742737, Train Loss: 0.2981359362602234
[32m[0514 05:22:08 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.30720677971839905, Train Loss: 0.2981344759464264
[32m[0514 05:22:08 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.3072074055671692, Train Loss: 0.298132985830307
[32m[0514 05:22:08 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.30720797181129456, Train Loss: 0.2981314957141876
[32m[0514 05:22:08 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.3072086274623871, Train Loss: 0.29813000559806824
[32m[0514 05:22:08 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.30720916390419006, Train Loss: 0.29812851548194885
[32m[0514 05:22:08 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.3072097897529602, Train Loss: 0.29812705516815186
[32m[0514 05:22:08 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.30721041560173035, Train Loss: 0.2981255352497101
[32m[0514 05:22:09 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.3072110116481781, Train Loss: 0.2981240451335907
[32m[0514 05:22:09 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.30721160769462585, Train Loss: 0.2981225550174713
[32m[0514 05:22:09 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.3072122037410736, Train Loss: 0.29812106490135193
[32m[0514 05:22:09 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.30721279978752136, Train Loss: 0.29811960458755493
[32m[0514 05:22:09 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.3072133958339691, Train Loss: 0.29811814427375793
[32m[0514 05:22:09 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.30721405148506165, Train Loss: 0.29811662435531616
[32m[0514 05:22:09 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.3072145879268646, Train Loss: 0.29811516404151917
[32m[0514 05:22:09 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.30721521377563477, Train Loss: 0.29811370372772217
[32m[0514 05:22:09 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.3072158396244049, Train Loss: 0.2981122136116028
[32m[0514 05:22:09 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.30721646547317505, Train Loss: 0.298110693693161
[32m[0514 05:22:09 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.3072170317173004, Train Loss: 0.2981092035770416
[32m[0514 05:22:09 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.30721768736839294, Train Loss: 0.29810771346092224
[32m[0514 05:22:09 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.3072182536125183, Train Loss: 0.29810625314712524
[32m[0514 05:22:09 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.30721890926361084, Train Loss: 0.29810476303100586
[32m[0514 05:22:09 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.307219535112381, Train Loss: 0.2981032729148865
[32m[0514 05:22:09 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.30722007155418396, Train Loss: 0.2981018126010895
[32m[0514 05:22:09 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.3072206974029541, Train Loss: 0.2981003224849701
[32m[0514 05:22:09 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.30722135305404663, Train Loss: 0.2980988323688507
[32m[0514 05:22:09 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.3072219789028168, Train Loss: 0.2980973422527313
[32m[0514 05:22:09 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.30722254514694214, Train Loss: 0.2980958819389343
[32m[0514 05:22:10 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.30722320079803467, Train Loss: 0.29809442162513733
[32m[0514 05:22:10 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.3072237968444824, Train Loss: 0.29809293150901794
[32m[0514 05:22:10 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.3072243630886078, Train Loss: 0.29809144139289856
[32m[0514 05:22:10 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.3072250187397003, Train Loss: 0.2980899512767792
[32m[0514 05:22:10 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.30722564458847046, Train Loss: 0.2980884909629822
[32m[0514 05:22:10 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.3072262704372406, Train Loss: 0.29808706045150757
[32m[0514 05:22:10 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.30722686648368835, Train Loss: 0.2980855703353882
[32m[0514 05:22:10 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.3072274625301361, Train Loss: 0.2980840802192688
[32m[0514 05:22:10 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.30722811818122864, Train Loss: 0.298082560300827
[32m[0514 05:22:10 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.3072287142276764, Train Loss: 0.29808109998703003
[32m[0514 05:22:10 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.3072293698787689, Train Loss: 0.29807963967323303
[32m[0514 05:22:10 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.30722999572753906, Train Loss: 0.29807817935943604
[32m[0514 05:22:10 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.30723056197166443, Train Loss: 0.29807668924331665
[32m[0514 05:22:10 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.30723118782043457, Train Loss: 0.29807522892951965
[32m[0514 05:22:10 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.3072317838668823, Train Loss: 0.29807376861572266
[32m[0514 05:22:10 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.30723240971565247, Train Loss: 0.29807230830192566
[32m[0514 05:22:10 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.30723312497138977, Train Loss: 0.2980707883834839
[32m[0514 05:22:10 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.30723369121551514, Train Loss: 0.2980693280696869
[32m[0514 05:22:10 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.3072343170642853, Train Loss: 0.2980678975582123
[32m[0514 05:22:10 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.30723488330841064, Train Loss: 0.2980664074420929
[32m[0514 05:22:11 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.3072355091571808, Train Loss: 0.2980649173259735
[32m[0514 05:22:11 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.3072361350059509, Train Loss: 0.2980634570121765
[32m[0514 05:22:11 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.30723679065704346, Train Loss: 0.2980619966983795
[32m[0514 05:22:11 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.3072374165058136, Train Loss: 0.29806050658226013
[32m[0514 05:22:11 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.30723798274993896, Train Loss: 0.29805904626846313
[32m[0514 05:22:11 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.3072386085987091, Train Loss: 0.29805758595466614
[32m[0514 05:22:11 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.30723923444747925, Train Loss: 0.29805612564086914
[32m[0514 05:22:11 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.3072398602962494, Train Loss: 0.29805466532707214
[32m[0514 05:22:11 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.30724045634269714, Train Loss: 0.29805317521095276
[32m[0514 05:22:11 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.3072411119937897, Train Loss: 0.29805174469947815
[32m[0514 05:22:11 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.30724167823791504, Train Loss: 0.29805025458335876
[32m[0514 05:22:11 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.30724239349365234, Train Loss: 0.29804879426956177
[32m[0514 05:22:11 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.3072429299354553, Train Loss: 0.29804736375808716
[32m[0514 05:22:11 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.30724355578422546, Train Loss: 0.2980458438396454
[32m[0514 05:22:11 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.307244211435318, Train Loss: 0.2980443835258484
[32m[0514 05:22:11 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.30724483728408813, Train Loss: 0.2980429232120514
[32m[0514 05:22:11 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.3072454333305359, Train Loss: 0.2980414628982544
[32m[0514 05:22:11 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.30724602937698364, Train Loss: 0.298039972782135
[32m[0514 05:22:11 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.3072466552257538, Train Loss: 0.2980385720729828
[32m[0514 05:22:12 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.30724725127220154, Train Loss: 0.2980370819568634
[32m[0514 05:22:12 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.3072478473186493, Train Loss: 0.2980356216430664
[32m[0514 05:22:12 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.30724844336509705, Train Loss: 0.2980341613292694
[32m[0514 05:22:12 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.3072490692138672, Train Loss: 0.2980327010154724
[32m[0514 05:22:12 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.3072497248649597, Train Loss: 0.2980312407016754
[32m[0514 05:22:12 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.30725032091140747, Train Loss: 0.2980298101902008
[32m[0514 05:22:12 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.3072509467601776, Train Loss: 0.2980283200740814
[32m[0514 05:22:12 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.30725157260894775, Train Loss: 0.2980268895626068
[32m[0514 05:22:12 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.3072521984577179, Train Loss: 0.2980254292488098
[32m[0514 05:22:12 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.30725276470184326, Train Loss: 0.2980239689350128
[32m[0514 05:22:12 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.3072533905506134, Train Loss: 0.29802247881889343
[32m[0514 05:22:12 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.30725398659706116, Train Loss: 0.2980210483074188
[32m[0514 05:22:12 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.3072545528411865, Train Loss: 0.29801955819129944
[32m[0514 05:22:12 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.30725520849227905, Train Loss: 0.2980181574821472
[32m[0514 05:22:12 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.3072558045387268, Train Loss: 0.29801666736602783
[32m[0514 05:22:12 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.30725643038749695, Train Loss: 0.2980152368545532
[32m[0514 05:22:12 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.3072570264339447, Train Loss: 0.2980137765407562
[32m[0514 05:22:12 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.30725759267807007, Train Loss: 0.2980123460292816
[32m[0514 05:22:12 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.3072582185268402, Train Loss: 0.2980108857154846
[32m[0514 05:22:12 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.30725881457328796, Train Loss: 0.2980094254016876
[32m[0514 05:22:13 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.3072594404220581, Train Loss: 0.298007994890213
[32m[0514 05:22:13 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.30726000666618347, Train Loss: 0.2980065643787384
[32m[0514 05:22:13 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.3072606325149536, Train Loss: 0.298005074262619
[32m[0514 05:22:13 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.30726122856140137, Train Loss: 0.2980036437511444
[32m[0514 05:22:13 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.30726179480552673, Train Loss: 0.2980022132396698
[32m[0514 05:22:13 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.3072623908519745, Train Loss: 0.2980007231235504
[32m[0514 05:22:13 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.30726298689842224, Train Loss: 0.2979993224143982
[32m[0514 05:22:13 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.3072636127471924, Train Loss: 0.2979978621006012
[32m[0514 05:22:13 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.30726420879364014, Train Loss: 0.2979964017868042
[32m[0514 05:22:13 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.3072647750377655, Train Loss: 0.2979949712753296
[32m[0514 05:22:13 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.30726537108421326, Train Loss: 0.297993540763855
[32m[0514 05:22:13 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.3072659969329834, Train Loss: 0.29799211025238037
[32m[0514 05:22:13 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.3072665333747864, Train Loss: 0.2979906499385834
[32m[0514 05:22:13 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.3072671592235565, Train Loss: 0.29798921942710876
[32m[0514 05:22:13 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.3072677254676819, Train Loss: 0.29798778891563416
[32m[0514 05:22:13 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.307268351316452, Train Loss: 0.29798632860183716
[32m[0514 05:22:13 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.3072689175605774, Train Loss: 0.29798489809036255
[32m[0514 05:22:13 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.30726951360702515, Train Loss: 0.2979834973812103
[32m[0514 05:22:13 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.3072701394557953, Train Loss: 0.29798200726509094
[32m[0514 05:22:13 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.30727067589759827, Train Loss: 0.29798057675361633
[32m[0514 05:22:14 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.30727124214172363, Train Loss: 0.2979791462421417
[32m[0514 05:22:14 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.3072718381881714, Train Loss: 0.2979777455329895
[32m[0514 05:22:14 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.30727246403694153, Train Loss: 0.2979763150215149
[32m[0514 05:22:14 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.3072730302810669, Train Loss: 0.2979748845100403
[32m[0514 05:22:14 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.30727362632751465, Train Loss: 0.2979734241962433
[32m[0514 05:22:14 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.3072741627693176, Train Loss: 0.2979719936847687
[32m[0514 05:22:14 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.3072747588157654, Train Loss: 0.2979705035686493
[32m[0514 05:22:14 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.30727535486221313, Train Loss: 0.29796913266181946
[32m[0514 05:22:14 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.3072758913040161, Train Loss: 0.2979676425457001
[32m[0514 05:22:14 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.30727648735046387, Train Loss: 0.29796621203422546
[32m[0514 05:22:14 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.30727705359458923, Train Loss: 0.29796478152275085
[32m[0514 05:22:14 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.3072776198387146, Train Loss: 0.29796335101127625
[32m[0514 05:22:14 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.30727821588516235, Train Loss: 0.2979619801044464
[32m[0514 05:22:14 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.30727875232696533, Train Loss: 0.297960489988327
[32m[0514 05:22:14 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.3072793483734131, Train Loss: 0.2979591190814972
[32m[0514 05:22:14 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.30727991461753845, Train Loss: 0.2979576289653778
[32m[0514 05:22:14 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.3072804808616638, Train Loss: 0.29795628786087036
[32m[0514 05:22:14 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.3072810471057892, Train Loss: 0.29795482754707336
[32m[0514 05:22:14 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.30728158354759216, Train Loss: 0.29795342683792114
[32m[0514 05:22:14 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.30728214979171753, Train Loss: 0.2979520261287689
[32m[0514 05:22:15 @mbmf_sampler.py:98][0m Finished 9th episode
[32m[0514 05:22:15 @mbmf_sampler.py:102][0m 1809 timesteps from 9 episodes collected
[32m[0514 05:27:48 @mbmf_trainer.py:160][0m Mean reward: -1180.2846522265243
[32m[0514 05:27:48 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.2983395457267761, Train Loss: 0.29757454991340637
[32m[0514 05:27:48 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.2983950078487396, Train Loss: 0.2975436747074127
[32m[0514 05:27:48 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.2983839213848114, Train Loss: 0.29751497507095337
[32m[0514 05:27:48 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.2983752489089966, Train Loss: 0.29750096797943115
[32m[0514 05:27:48 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.29836446046829224, Train Loss: 0.2974921464920044
[32m[0514 05:27:48 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.29835864901542664, Train Loss: 0.29748407006263733
[32m[0514 05:27:48 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.2983537018299103, Train Loss: 0.2974770665168762
[32m[0514 05:27:48 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.29834896326065063, Train Loss: 0.29747048020362854
[32m[0514 05:27:48 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.29834455251693726, Train Loss: 0.2974644601345062
[32m[0514 05:27:48 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.2983402609825134, Train Loss: 0.2974588871002197
[32m[0514 05:27:49 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.29833629727363586, Train Loss: 0.2974536418914795
[32m[0514 05:27:49 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.298332542181015, Train Loss: 0.2974487245082855
[32m[0514 05:27:49 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.2983289659023285, Train Loss: 0.29744410514831543
[32m[0514 05:27:49 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.2983255982398987, Train Loss: 0.29743972420692444
[32m[0514 05:27:49 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.2983224391937256, Train Loss: 0.2974355220794678
[32m[0514 05:27:49 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.29831939935684204, Train Loss: 0.2974315583705902
[32m[0514 05:27:49 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.29831650853157043, Train Loss: 0.2974277138710022
[32m[0514 05:27:49 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.29831379652023315, Train Loss: 0.29742392897605896
[32m[0514 05:27:49 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.2983112037181854, Train Loss: 0.2974203824996948
[32m[0514 05:27:49 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.29830875992774963, Train Loss: 0.29741692543029785
[32m[0514 05:27:49 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.2983064353466034, Train Loss: 0.29741355776786804
[32m[0514 05:27:49 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.29830414056777954, Train Loss: 0.2974102795124054
[32m[0514 05:27:49 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.2983020842075348, Train Loss: 0.2974070906639099
[32m[0514 05:27:49 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.29830002784729004, Train Loss: 0.2974039912223816
[32m[0514 05:27:49 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.29829809069633484, Train Loss: 0.29740095138549805
[32m[0514 05:27:49 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.2982962727546692, Train Loss: 0.29739800095558167
[32m[0514 05:27:50 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.2982944846153259, Train Loss: 0.29739511013031006
[32m[0514 05:27:50 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.29829278588294983, Train Loss: 0.2973922789096832
[32m[0514 05:27:50 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.29829123616218567, Train Loss: 0.2973894774913788
[32m[0514 05:27:50 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.2982896864414215, Train Loss: 0.2973867654800415
[32m[0514 05:27:50 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.2982882559299469, Train Loss: 0.2973840832710266
[32m[0514 05:27:50 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.2982868552207947, Train Loss: 0.2973814606666565
[32m[0514 05:27:50 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.29828551411628723, Train Loss: 0.29737889766693115
[32m[0514 05:27:50 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.29828423261642456, Train Loss: 0.2973763346672058
[32m[0514 05:27:50 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.29828304052352905, Train Loss: 0.29737383127212524
[32m[0514 05:27:50 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.29828187823295593, Train Loss: 0.29737135767936707
[32m[0514 05:27:50 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.2982807457447052, Train Loss: 0.29736894369125366
[32m[0514 05:27:50 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.298279732465744, Train Loss: 0.29736652970314026
[32m[0514 05:27:50 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.29827871918678284, Train Loss: 0.29736417531967163
[32m[0514 05:27:50 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.29827773571014404, Train Loss: 0.2973618507385254
[32m[0514 05:27:50 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.2982768416404724, Train Loss: 0.29735955595970154
[32m[0514 05:27:50 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.29827597737312317, Train Loss: 0.2973572611808777
[32m[0514 05:27:51 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.2982751429080963, Train Loss: 0.2973550260066986
[32m[0514 05:27:51 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.29827436804771423, Train Loss: 0.2973528504371643
[32m[0514 05:27:51 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.29827362298965454, Train Loss: 0.2973506450653076
[32m[0514 05:27:51 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.29827284812927246, Train Loss: 0.29734840989112854
[32m[0514 05:27:51 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.29827216267585754, Train Loss: 0.297346293926239
[32m[0514 05:27:51 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.2982715368270874, Train Loss: 0.2973441779613495
[32m[0514 05:27:51 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.29827094078063965, Train Loss: 0.29734209179878235
[32m[0514 05:27:51 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.2982703447341919, Train Loss: 0.2973400056362152
[32m[0514 05:27:51 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.29826977849006653, Train Loss: 0.29733791947364807
[32m[0514 05:27:51 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.29826924204826355, Train Loss: 0.2973358631134033
[32m[0514 05:27:51 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.29826873540878296, Train Loss: 0.29733380675315857
[32m[0514 05:27:51 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.29826825857162476, Train Loss: 0.2973318099975586
[32m[0514 05:27:51 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.29826784133911133, Train Loss: 0.2973298132419586
[32m[0514 05:27:51 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.2982673645019531, Train Loss: 0.29732781648635864
[32m[0514 05:27:51 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.2982670068740845, Train Loss: 0.29732584953308105
[32m[0514 05:27:52 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.29826658964157104, Train Loss: 0.29732391238212585
[32m[0514 05:27:52 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.2982662618160248, Train Loss: 0.29732197523117065
[32m[0514 05:27:52 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.2982659339904785, Train Loss: 0.29732003808021545
[32m[0514 05:27:52 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.298265665769577, Train Loss: 0.29731816053390503
[32m[0514 05:27:52 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.29826533794403076, Train Loss: 0.2973162829875946
[32m[0514 05:27:52 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.2982650399208069, Train Loss: 0.2973144054412842
[32m[0514 05:27:52 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.2982648015022278, Train Loss: 0.29731249809265137
[32m[0514 05:27:52 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.2982645332813263, Train Loss: 0.29731062054634094
[32m[0514 05:27:52 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.2982643246650696, Train Loss: 0.2973088324069977
[32m[0514 05:27:52 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.29826417565345764, Train Loss: 0.29730692505836487
[32m[0514 05:27:52 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.29826393723487854, Train Loss: 0.297305166721344
[32m[0514 05:27:52 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.2982637286186218, Train Loss: 0.29730334877967834
[32m[0514 05:27:52 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.2982635498046875, Train Loss: 0.2973015308380127
[32m[0514 05:27:52 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.29826346039772034, Train Loss: 0.2972997725009918
[32m[0514 05:27:52 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.2982633411884308, Train Loss: 0.29729795455932617
[32m[0514 05:27:52 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.29826319217681885, Train Loss: 0.2972961664199829
[32m[0514 05:27:52 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.2982630729675293, Train Loss: 0.2972944378852844
[32m[0514 05:27:53 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.2982630133628845, Train Loss: 0.29729267954826355
[32m[0514 05:27:53 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.29826289415359497, Train Loss: 0.2972908914089203
[32m[0514 05:27:53 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.2982628345489502, Train Loss: 0.2972891628742218
[32m[0514 05:27:53 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.2982628047466278, Train Loss: 0.2972874045372009
[32m[0514 05:27:53 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.29826271533966064, Train Loss: 0.2972857356071472
[32m[0514 05:27:53 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.29826265573501587, Train Loss: 0.29728400707244873
[32m[0514 05:27:53 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.29826265573501587, Train Loss: 0.29728230834007263
[32m[0514 05:27:53 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.2982626259326935, Train Loss: 0.29728055000305176
[32m[0514 05:27:53 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.2982626259326935, Train Loss: 0.29727891087532043
[32m[0514 05:27:53 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.2982625961303711, Train Loss: 0.29727721214294434
[32m[0514 05:27:53 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.2982625961303711, Train Loss: 0.297275573015213
[32m[0514 05:27:53 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.2982626259326935, Train Loss: 0.2972739040851593
[32m[0514 05:27:53 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.29826265573501587, Train Loss: 0.2972722053527832
[32m[0514 05:27:53 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.29826271533966064, Train Loss: 0.2972705364227295
[32m[0514 05:27:53 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.29826271533966064, Train Loss: 0.29726892709732056
[32m[0514 05:27:54 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.2982627749443054, Train Loss: 0.2972673177719116
[32m[0514 05:27:54 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.2982628047466278, Train Loss: 0.2972656190395355
[32m[0514 05:27:54 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.2982628643512726, Train Loss: 0.2972640097141266
[32m[0514 05:27:54 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.29826292395591736, Train Loss: 0.29726237058639526
[32m[0514 05:27:54 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.29826298356056213, Train Loss: 0.2972607910633087
[32m[0514 05:27:54 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.2982631027698517, Train Loss: 0.297259122133255
[32m[0514 05:27:54 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.29826316237449646, Train Loss: 0.29725757241249084
[32m[0514 05:27:54 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.298263281583786, Train Loss: 0.2972559630870819
[32m[0514 05:27:54 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.2982633411884308, Train Loss: 0.29725438356399536
[32m[0514 05:27:54 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.29826346039772034, Train Loss: 0.2972527742385864
[32m[0514 05:27:54 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.2982635498046875, Train Loss: 0.2972511649131775
[32m[0514 05:27:54 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.29826366901397705, Train Loss: 0.29724958539009094
[32m[0514 05:27:54 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.2982637882232666, Train Loss: 0.2972480058670044
[32m[0514 05:27:54 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.29826390743255615, Train Loss: 0.2972464859485626
[32m[0514 05:27:54 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.2982639968395233, Train Loss: 0.29724493622779846
[32m[0514 05:27:54 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.29826417565345764, Train Loss: 0.2972433865070343
[32m[0514 05:27:54 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.2982642948627472, Train Loss: 0.29724177718162537
[32m[0514 05:27:55 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.29826444387435913, Train Loss: 0.2972402572631836
[32m[0514 05:27:55 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.29826459288597107, Train Loss: 0.2972387373447418
[32m[0514 05:27:55 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.2982647120952606, Train Loss: 0.2972371578216553
[32m[0514 05:27:55 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.29826489090919495, Train Loss: 0.2972356677055359
[32m[0514 05:27:55 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.2982650399208069, Train Loss: 0.29723411798477173
[32m[0514 05:27:55 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.2982652485370636, Train Loss: 0.29723259806632996
[32m[0514 05:27:55 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.29826536774635315, Train Loss: 0.29723110795021057
[32m[0514 05:27:55 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.2982655465602875, Train Loss: 0.2972295582294464
[32m[0514 05:27:55 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.2982657253742218, Train Loss: 0.2972280979156494
[32m[0514 05:27:55 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.29826590418815613, Train Loss: 0.29722654819488525
[32m[0514 05:27:55 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.29826608300209045, Train Loss: 0.29722505807876587
[32m[0514 05:27:55 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.29826629161834717, Train Loss: 0.2972235679626465
[32m[0514 05:27:55 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.2982664704322815, Train Loss: 0.2972220778465271
[32m[0514 05:27:55 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.2982666790485382, Train Loss: 0.2972206175327301
[32m[0514 05:27:55 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.29826685786247253, Train Loss: 0.2972191274166107
[32m[0514 05:27:56 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.29826706647872925, Train Loss: 0.29721760749816895
[32m[0514 05:27:56 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.29826727509498596, Train Loss: 0.29721617698669434
[32m[0514 05:27:56 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.2982674837112427, Train Loss: 0.29721471667289734
[32m[0514 05:27:56 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.2982676923274994, Train Loss: 0.29721322655677795
[32m[0514 05:27:56 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.2982678711414337, Train Loss: 0.29721173644065857
[32m[0514 05:27:56 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.2982681095600128, Train Loss: 0.29721030592918396
[32m[0514 05:27:56 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.2982683479785919, Train Loss: 0.2972087860107422
[32m[0514 05:27:56 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.298268586397171, Train Loss: 0.2972073554992676
[32m[0514 05:27:56 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.29826876521110535, Train Loss: 0.29720595479011536
[32m[0514 05:27:56 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.29826903343200684, Train Loss: 0.29720446467399597
[32m[0514 05:27:56 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.29826921224594116, Train Loss: 0.297203004360199
[32m[0514 05:27:56 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.29826951026916504, Train Loss: 0.29720160365104675
[32m[0514 05:27:56 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.29826968908309937, Train Loss: 0.29720017313957214
[32m[0514 05:27:56 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.29826995730400085, Train Loss: 0.29719868302345276
[32m[0514 05:27:56 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.29827019572257996, Train Loss: 0.2971973121166229
[32m[0514 05:27:56 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.29827046394348145, Train Loss: 0.2971958816051483
[32m[0514 05:27:57 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.29827067255973816, Train Loss: 0.2971944510936737
[32m[0514 05:27:57 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.29827094078063965, Train Loss: 0.2971929907798767
[32m[0514 05:27:57 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.29827120900154114, Train Loss: 0.2971916198730469
[32m[0514 05:27:57 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.29827144742012024, Train Loss: 0.2971901595592499
[32m[0514 05:27:57 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.29827168583869934, Train Loss: 0.29718878865242004
[32m[0514 05:27:57 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.29827195405960083, Train Loss: 0.29718735814094543
[32m[0514 05:27:57 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.2982722222805023, Train Loss: 0.2971859872341156
[32m[0514 05:27:57 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.2982724905014038, Train Loss: 0.297184556722641
[32m[0514 05:27:57 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.2982727587223053, Train Loss: 0.29718318581581116
[32m[0514 05:27:57 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.2982730269432068, Train Loss: 0.29718178510665894
[32m[0514 05:27:57 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.2982732355594635, Train Loss: 0.2971804141998291
[32m[0514 05:27:57 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.298273503780365, Train Loss: 0.2971790134906769
[32m[0514 05:27:57 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.29827383160591125, Train Loss: 0.29717761278152466
[32m[0514 05:27:57 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.29827407002449036, Train Loss: 0.29717621207237244
[32m[0514 05:27:57 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.29827436804771423, Train Loss: 0.2971748411655426
[32m[0514 05:27:57 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.2982746660709381, Train Loss: 0.29717350006103516
[32m[0514 05:27:58 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.2982749342918396, Train Loss: 0.29717206954956055
[32m[0514 05:27:58 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.2982751727104187, Train Loss: 0.2971707284450531
[32m[0514 05:27:58 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.2982754707336426, Train Loss: 0.2971693277359009
[32m[0514 05:27:58 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.29827573895454407, Train Loss: 0.2971680164337158
[32m[0514 05:27:58 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.29827600717544556, Train Loss: 0.2971666157245636
[32m[0514 05:27:58 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.2982763350009918, Train Loss: 0.29716530442237854
[32m[0514 05:27:58 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.2982766330242157, Train Loss: 0.2971639335155487
[32m[0514 05:27:58 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.2982769012451172, Train Loss: 0.2971625328063965
[32m[0514 05:27:58 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.2982771694660187, Train Loss: 0.29716119170188904
[32m[0514 05:27:58 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.29827746748924255, Train Loss: 0.297159880399704
[32m[0514 05:27:58 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.29827776551246643, Train Loss: 0.29715850949287415
[32m[0514 05:27:58 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.2982780635356903, Train Loss: 0.2971571683883667
[32m[0514 05:27:58 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.2982783615589142, Train Loss: 0.29715582728385925
[32m[0514 05:27:58 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.29827868938446045, Train Loss: 0.2971545159816742
[32m[0514 05:27:58 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.29827895760536194, Train Loss: 0.29715314507484436
[32m[0514 05:27:59 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.2982792854309082, Train Loss: 0.2971518039703369
[32m[0514 05:27:59 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.2982795834541321, Train Loss: 0.29715052247047424
[32m[0514 05:27:59 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.29827988147735596, Train Loss: 0.2971491813659668
[32m[0514 05:27:59 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.29828017950057983, Train Loss: 0.29714784026145935
[32m[0514 05:27:59 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.2982804775238037, Train Loss: 0.2971465587615967
[32m[0514 05:27:59 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.2982807755470276, Train Loss: 0.29714521765708923
[32m[0514 05:27:59 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.29828110337257385, Train Loss: 0.2971438467502594
[32m[0514 05:27:59 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.29828140139579773, Train Loss: 0.2971425950527191
[32m[0514 05:27:59 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.298281729221344, Train Loss: 0.29714125394821167
[32m[0514 05:27:59 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.29828208684921265, Train Loss: 0.2971399426460266
[32m[0514 05:27:59 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.29828235507011414, Train Loss: 0.29713863134384155
[32m[0514 05:27:59 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.2982826828956604, Train Loss: 0.2971373498439789
[32m[0514 05:27:59 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.2982829809188843, Train Loss: 0.2971360385417938
[32m[0514 05:27:59 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.29828330874443054, Train Loss: 0.29713475704193115
[32m[0514 05:27:59 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.2982836365699768, Train Loss: 0.2971334159374237
[32m[0514 05:28:00 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.29828396439552307, Train Loss: 0.2971321642398834
[32m[0514 05:28:00 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.29828429222106934, Train Loss: 0.297130823135376
[32m[0514 05:28:00 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.2982845604419708, Train Loss: 0.2971295714378357
[32m[0514 05:28:00 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.2982849180698395, Train Loss: 0.297128289937973
[32m[0514 05:28:00 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.29828524589538574, Train Loss: 0.29712700843811035
[32m[0514 05:28:00 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.298285573720932, Train Loss: 0.2971257269382477
[32m[0514 05:28:00 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.2982858717441559, Train Loss: 0.2971244752407074
[32m[0514 05:28:00 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.29828619956970215, Train Loss: 0.2971231937408447
[32m[0514 05:28:00 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.2982865869998932, Train Loss: 0.29712191224098206
[32m[0514 05:28:00 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.29828688502311707, Train Loss: 0.2971206307411194
[32m[0514 05:28:00 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.29828721284866333, Train Loss: 0.2971193790435791
[32m[0514 05:28:00 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.298287570476532, Train Loss: 0.29711809754371643
[32m[0514 05:28:00 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.29828786849975586, Train Loss: 0.29711681604385376
[32m[0514 05:28:00 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.2982882261276245, Train Loss: 0.2971155643463135
[32m[0514 05:28:00 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.2982885241508484, Train Loss: 0.2971142828464508
[32m[0514 05:28:00 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.29828885197639465, Train Loss: 0.2971130609512329
[32m[0514 05:28:01 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.2982892096042633, Train Loss: 0.2971118092536926
[32m[0514 05:28:01 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.29828956723213196, Train Loss: 0.29711052775382996
[32m[0514 05:28:01 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.29828986525535583, Train Loss: 0.29710930585861206
[32m[0514 05:28:01 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.2982902526855469, Train Loss: 0.2971080541610718
[32m[0514 05:28:01 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.29829055070877075, Train Loss: 0.2971068024635315
[32m[0514 05:28:01 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.2982909381389618, Train Loss: 0.2971055507659912
[32m[0514 05:28:01 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.29829123616218567, Train Loss: 0.2971043288707733
[32m[0514 05:28:01 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.2982915937900543, Train Loss: 0.2971031069755554
[32m[0514 05:28:01 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.298291951417923, Train Loss: 0.2971018850803375
[32m[0514 05:28:01 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.298292338848114, Train Loss: 0.29710063338279724
[32m[0514 05:28:01 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.2982926368713379, Train Loss: 0.29709938168525696
[32m[0514 05:28:01 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.29829302430152893, Train Loss: 0.2970981299877167
[32m[0514 05:28:01 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.2982933521270752, Train Loss: 0.2970969080924988
[32m[0514 05:28:01 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.29829367995262146, Train Loss: 0.2970956861972809
[32m[0514 05:28:01 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.2982940673828125, Train Loss: 0.2970944941043854
[32m[0514 05:28:02 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.2982943654060364, Train Loss: 0.29709330201148987
[32m[0514 05:28:02 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.29829472303390503, Train Loss: 0.2970920503139496
[32m[0514 05:28:02 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.2982950806617737, Train Loss: 0.2970908284187317
[32m[0514 05:28:02 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.29829543828964233, Train Loss: 0.2970896363258362
[32m[0514 05:28:02 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.2982957661151886, Train Loss: 0.2970883846282959
[32m[0514 05:28:02 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.298296183347702, Train Loss: 0.2970871925354004
[32m[0514 05:28:02 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.2982964813709259, Train Loss: 0.2970860004425049
[32m[0514 05:28:02 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.29829686880111694, Train Loss: 0.297084778547287
[32m[0514 05:28:02 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.2982971966266632, Train Loss: 0.29708361625671387
[32m[0514 05:28:02 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.29829758405685425, Train Loss: 0.29708239436149597
[32m[0514 05:28:02 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.2982979118824005, Train Loss: 0.29708123207092285
[32m[0514 05:28:02 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.29829832911491394, Train Loss: 0.29708001017570496
[32m[0514 05:28:02 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.2982986569404602, Train Loss: 0.29707878828048706
[32m[0514 05:28:02 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.29829901456832886, Train Loss: 0.29707756638526917
[32m[0514 05:28:02 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.2982993423938751, Train Loss: 0.29707643389701843
[32m[0514 05:28:02 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.29829975962638855, Train Loss: 0.2970752418041229
[32m[0514 05:28:02 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.2983000874519348, Train Loss: 0.2970740795135498
[32m[0514 05:28:03 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.29830047488212585, Train Loss: 0.2970728874206543
[32m[0514 05:28:03 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.2983008325099945, Train Loss: 0.2970717251300812
[32m[0514 05:28:03 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.29830116033554077, Train Loss: 0.29707053303718567
[32m[0514 05:28:03 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.2983015477657318, Train Loss: 0.29706934094429016
[32m[0514 05:28:03 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.29830193519592285, Train Loss: 0.29706820845603943
[32m[0514 05:28:03 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.2983022630214691, Train Loss: 0.29706698656082153
[32m[0514 05:28:03 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.29830265045166016, Train Loss: 0.2970658242702484
[32m[0514 05:28:03 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.2983030378818512, Train Loss: 0.2970646917819977
[32m[0514 05:28:03 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.29830339550971985, Train Loss: 0.2970634996891022
[32m[0514 05:28:03 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.2983037531375885, Train Loss: 0.29706233739852905
[32m[0514 05:28:03 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.29830414056777954, Train Loss: 0.2970612049102783
[32m[0514 05:28:03 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.2983044981956482, Train Loss: 0.2970600128173828
[32m[0514 05:28:03 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.29830485582351685, Train Loss: 0.2970588803291321
[32m[0514 05:28:03 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.2983052432537079, Train Loss: 0.29705771803855896
[32m[0514 05:28:03 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.2983056306838989, Train Loss: 0.2970565855503082
[32m[0514 05:28:04 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.2983059883117676, Train Loss: 0.2970554530620575
[32m[0514 05:28:04 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.29830634593963623, Train Loss: 0.297054260969162
[32m[0514 05:28:04 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.29830676317214966, Train Loss: 0.29705312848091125
[32m[0514 05:28:04 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.2983071208000183, Train Loss: 0.2970519959926605
[32m[0514 05:28:04 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.29830747842788696, Train Loss: 0.297050803899765
[32m[0514 05:28:04 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.298307865858078, Train Loss: 0.2970496416091919
[32m[0514 05:28:04 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.29830825328826904, Train Loss: 0.29704853892326355
[32m[0514 05:28:04 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.2983086109161377, Train Loss: 0.2970474064350128
[32m[0514 05:28:04 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.29830899834632874, Train Loss: 0.2970462441444397
[32m[0514 05:28:04 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.2983093857765198, Train Loss: 0.29704511165618896
[32m[0514 05:28:04 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.2983097732067108, Train Loss: 0.2970440089702606
[32m[0514 05:28:04 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.29831013083457947, Train Loss: 0.2970428466796875
[32m[0514 05:28:04 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.2983105182647705, Train Loss: 0.29704171419143677
[32m[0514 05:28:04 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.29831090569496155, Train Loss: 0.2970406115055084
[32m[0514 05:28:04 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.2983112931251526, Train Loss: 0.2970394790172577
[32m[0514 05:28:04 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.29831168055534363, Train Loss: 0.29703834652900696
[32m[0514 05:28:05 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.29831206798553467, Train Loss: 0.2970372140407562
[32m[0514 05:28:05 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.2983124554157257, Train Loss: 0.2970361113548279
[32m[0514 05:28:05 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.29831284284591675, Train Loss: 0.29703500866889954
[32m[0514 05:28:05 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.2983132302761078, Train Loss: 0.2970338761806488
[32m[0514 05:28:05 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.29831358790397644, Train Loss: 0.29703277349472046
[32m[0514 05:28:05 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.2983139753341675, Train Loss: 0.29703161120414734
[32m[0514 05:28:05 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.2983143627643585, Train Loss: 0.2970305383205414
[32m[0514 05:28:05 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.29831477999687195, Train Loss: 0.29702940583229065
[32m[0514 05:28:05 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.298315167427063, Train Loss: 0.2970283031463623
[32m[0514 05:28:05 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.29831552505493164, Train Loss: 0.29702720046043396
[32m[0514 05:28:05 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.29831594228744507, Train Loss: 0.2970260679721832
[32m[0514 05:28:05 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.2983163297176361, Train Loss: 0.29702499508857727
[32m[0514 05:28:05 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.29831671714782715, Train Loss: 0.29702386260032654
[32m[0514 05:28:05 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.2983170747756958, Train Loss: 0.2970227897167206
[32m[0514 05:28:05 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.29831749200820923, Train Loss: 0.29702165722846985
[32m[0514 05:28:06 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.29831787943840027, Train Loss: 0.2970205843448639
[32m[0514 05:28:06 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.2983182668685913, Train Loss: 0.29701945185661316
[32m[0514 05:28:06 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.29831868410110474, Train Loss: 0.2970184087753296
[32m[0514 05:28:06 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.2983190715312958, Train Loss: 0.29701733589172363
[32m[0514 05:28:06 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.2983194589614868, Train Loss: 0.2970162332057953
[32m[0514 05:28:06 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.29831984639167786, Train Loss: 0.29701513051986694
[32m[0514 05:28:06 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.2983202338218689, Train Loss: 0.2970140278339386
[32m[0514 05:28:06 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.29832062125205994, Train Loss: 0.29701292514801025
[32m[0514 05:28:06 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.298321008682251, Train Loss: 0.2970118522644043
[32m[0514 05:28:06 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.2983214259147644, Train Loss: 0.29701074957847595
[32m[0514 05:28:06 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.29832181334495544, Train Loss: 0.2970097064971924
[32m[0514 05:28:06 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.29832223057746887, Train Loss: 0.29700860381126404
[32m[0514 05:28:06 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.2983225882053375, Train Loss: 0.29700756072998047
[32m[0514 05:28:06 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.29832297563552856, Train Loss: 0.2970064878463745
[32m[0514 05:28:06 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.298323392868042, Train Loss: 0.29700538516044617
[32m[0514 05:28:07 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.29832378029823303, Train Loss: 0.2970043122768402
[32m[0514 05:28:07 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.2983241677284241, Train Loss: 0.29700323939323425
[32m[0514 05:28:07 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.2983245849609375, Train Loss: 0.2970021665096283
[32m[0514 05:28:07 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.2983250021934509, Train Loss: 0.29700109362602234
[32m[0514 05:28:07 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.2983253598213196, Train Loss: 0.2970000207424164
[32m[0514 05:28:07 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.298325777053833, Train Loss: 0.2969989776611328
[32m[0514 05:28:07 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.29832613468170166, Train Loss: 0.29699787497520447
[32m[0514 05:28:07 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.2983265817165375, Train Loss: 0.2969968318939209
[32m[0514 05:28:07 @mbmf_sampler.py:98][0m Finished 9th episode
[32m[0514 05:28:07 @mbmf_sampler.py:102][0m 1809 timesteps from 9 episodes collected
[32m[0514 05:33:10 @mbmf_trainer.py:160][0m Mean reward: -1191.394824548897
[32m[0514 05:33:10 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.29150259494781494, Train Loss: 0.2989572286605835
[32m[0514 05:33:10 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.2914623022079468, Train Loss: 0.2988988161087036
[32m[0514 05:33:10 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.29145967960357666, Train Loss: 0.29887422919273376
[32m[0514 05:33:10 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.29146429896354675, Train Loss: 0.2988578975200653
[32m[0514 05:33:10 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.2914729118347168, Train Loss: 0.2988448143005371
[32m[0514 05:33:10 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.29148396849632263, Train Loss: 0.29883337020874023
[32m[0514 05:33:10 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.29149511456489563, Train Loss: 0.2988232970237732
[32m[0514 05:33:10 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.2915066182613373, Train Loss: 0.29881441593170166
[32m[0514 05:33:10 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.29151812195777893, Train Loss: 0.2988065779209137
[32m[0514 05:33:10 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.29152944684028625, Train Loss: 0.29879939556121826
[32m[0514 05:33:10 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.29154059290885925, Train Loss: 0.29879289865493774
[32m[0514 05:33:10 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.2915514409542084, Train Loss: 0.29878681898117065
[32m[0514 05:33:10 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.291562020778656, Train Loss: 0.2987811863422394
[32m[0514 05:33:10 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.2915722131729126, Train Loss: 0.29877591133117676
[32m[0514 05:33:10 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.2915821373462677, Train Loss: 0.29877087473869324
[32m[0514 05:33:10 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.2915917932987213, Train Loss: 0.2987661361694336
[32m[0514 05:33:10 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.2916010618209839, Train Loss: 0.29876160621643066
[32m[0514 05:33:10 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.29161012172698975, Train Loss: 0.2987572252750397
[32m[0514 05:33:10 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.2916189730167389, Train Loss: 0.2987530529499054
[32m[0514 05:33:10 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.29162752628326416, Train Loss: 0.29874899983406067
[32m[0514 05:33:11 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.2916359305381775, Train Loss: 0.29874512553215027
[32m[0514 05:33:11 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.29164406657218933, Train Loss: 0.2987413704395294
[32m[0514 05:33:11 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.29165202379226685, Train Loss: 0.29873767495155334
[32m[0514 05:33:11 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.2916598618030548, Train Loss: 0.2987341284751892
[32m[0514 05:33:11 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.29166752099990845, Train Loss: 0.2987307012081146
[32m[0514 05:33:11 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.29167497158050537, Train Loss: 0.2987273335456848
[32m[0514 05:33:11 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.2916823625564575, Train Loss: 0.29872405529022217
[32m[0514 05:33:11 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.29168954491615295, Train Loss: 0.2987208366394043
[32m[0514 05:33:11 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.2916966676712036, Train Loss: 0.2987177073955536
[32m[0514 05:33:11 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.29170358180999756, Train Loss: 0.29871460795402527
[32m[0514 05:33:11 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.2917104661464691, Train Loss: 0.2987115681171417
[32m[0514 05:33:11 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.29171720147132874, Train Loss: 0.29870864748954773
[32m[0514 05:33:11 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.2917238473892212, Train Loss: 0.29870572686195374
[32m[0514 05:33:11 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.2917303740978241, Train Loss: 0.2987028658390045
[32m[0514 05:33:11 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.2917368412017822, Train Loss: 0.2987000644207001
[32m[0514 05:33:11 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.2917431592941284, Train Loss: 0.298697292804718
[32m[0514 05:33:11 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.2917494475841522, Train Loss: 0.2986946403980255
[32m[0514 05:33:11 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.2917555868625641, Train Loss: 0.29869192838668823
[32m[0514 05:33:11 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.2917616665363312, Train Loss: 0.2986893057823181
[32m[0514 05:33:11 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.2917676866054535, Train Loss: 0.298686683177948
[32m[0514 05:33:11 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.29177358746528625, Train Loss: 0.29868409037590027
[32m[0514 05:33:11 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.29177945852279663, Train Loss: 0.2986816167831421
[32m[0514 05:33:12 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.29178524017333984, Train Loss: 0.2986791133880615
[32m[0514 05:33:12 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.2917908728122711, Train Loss: 0.29867660999298096
[32m[0514 05:33:12 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.2917965352535248, Train Loss: 0.29867419600486755
[32m[0514 05:33:12 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.2918021082878113, Train Loss: 0.29867178201675415
[32m[0514 05:33:12 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.2918075919151306, Train Loss: 0.29866939783096313
[32m[0514 05:33:12 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.2918129861354828, Train Loss: 0.29866698384284973
[32m[0514 05:33:12 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.2918183505535126, Train Loss: 0.29866471886634827
[32m[0514 05:33:12 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.2918236553668976, Train Loss: 0.298662394285202
[32m[0514 05:33:12 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.2918289005756378, Train Loss: 0.2986600995063782
[32m[0514 05:33:12 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.2918340861797333, Train Loss: 0.2986578345298767
[32m[0514 05:33:12 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.2918391823768616, Train Loss: 0.29865553975105286
[32m[0514 05:33:12 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.29184427857398987, Train Loss: 0.2986533045768738
[32m[0514 05:33:12 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.2918492555618286, Train Loss: 0.29865115880966187
[32m[0514 05:33:12 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.29185420274734497, Train Loss: 0.2986489534378052
[32m[0514 05:33:12 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.29185912013053894, Train Loss: 0.2986467778682709
[32m[0514 05:33:12 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.29186397790908813, Train Loss: 0.29864463210105896
[32m[0514 05:33:12 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.29186880588531494, Train Loss: 0.29864251613616943
[32m[0514 05:33:12 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.291873574256897, Train Loss: 0.2986403703689575
[32m[0514 05:33:12 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.29187825322151184, Train Loss: 0.2986382842063904
[32m[0514 05:33:12 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.2918829023838043, Train Loss: 0.29863616824150085
[32m[0514 05:33:12 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.291887491941452, Train Loss: 0.2986340820789337
[32m[0514 05:33:12 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.29189205169677734, Train Loss: 0.29863202571868896
[32m[0514 05:33:13 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.2918965816497803, Train Loss: 0.298630028963089
[32m[0514 05:33:13 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.2919011116027832, Train Loss: 0.29862797260284424
[32m[0514 05:33:13 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.29190555214881897, Train Loss: 0.29862597584724426
[32m[0514 05:33:13 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.29190996289253235, Train Loss: 0.2986239790916443
[32m[0514 05:33:13 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.29191434383392334, Train Loss: 0.2986219525337219
[32m[0514 05:33:13 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.29191869497299194, Train Loss: 0.29861998558044434
[32m[0514 05:33:13 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.29192298650741577, Train Loss: 0.29861804842948914
[32m[0514 05:33:13 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.29192718863487244, Train Loss: 0.29861608147621155
[32m[0514 05:33:13 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.29193148016929626, Train Loss: 0.29861411452293396
[32m[0514 05:33:13 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.29193565249443054, Train Loss: 0.29861217737197876
[32m[0514 05:33:13 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.29193976521492004, Train Loss: 0.29861027002334595
[32m[0514 05:33:13 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.29194390773773193, Train Loss: 0.2986083924770355
[32m[0514 05:33:13 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.29194802045822144, Train Loss: 0.2986064553260803
[32m[0514 05:33:13 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.29195207357406616, Train Loss: 0.2986045479774475
[32m[0514 05:33:13 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.2919560968875885, Train Loss: 0.2986027002334595
[32m[0514 05:33:13 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.29196009039878845, Train Loss: 0.29860082268714905
[32m[0514 05:33:13 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.2919640839099884, Train Loss: 0.2985989451408386
[32m[0514 05:33:13 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.2919680178165436, Train Loss: 0.2985970675945282
[32m[0514 05:33:13 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.29197192192077637, Train Loss: 0.2985953092575073
[32m[0514 05:33:13 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.29197585582733154, Train Loss: 0.2985934615135193
[32m[0514 05:33:13 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.29197970032691956, Train Loss: 0.29859164357185364
[32m[0514 05:33:13 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.2919834852218628, Train Loss: 0.2985898554325104
[32m[0514 05:33:14 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.2919872999191284, Train Loss: 0.29858800768852234
[32m[0514 05:33:14 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.29199108481407166, Train Loss: 0.2985862195491791
[32m[0514 05:33:14 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.2919948697090149, Train Loss: 0.2985844612121582
[32m[0514 05:33:14 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.29199856519699097, Train Loss: 0.29858267307281494
[32m[0514 05:33:14 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.2920023202896118, Train Loss: 0.29858094453811646
[32m[0514 05:33:14 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.2920059859752655, Train Loss: 0.2985791265964508
[32m[0514 05:33:14 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.2920096814632416, Train Loss: 0.2985773980617523
[32m[0514 05:33:14 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.2920132875442505, Train Loss: 0.29857563972473145
[32m[0514 05:33:14 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.2920169234275818, Train Loss: 0.29857394099235535
[32m[0514 05:33:14 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.2920204997062683, Train Loss: 0.29857224225997925
[32m[0514 05:33:14 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.29202404618263245, Train Loss: 0.298570454120636
[32m[0514 05:33:14 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.2920275926589966, Train Loss: 0.2985687553882599
[32m[0514 05:33:14 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.2920311689376831, Train Loss: 0.2985670566558838
[32m[0514 05:33:14 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.29203465580940247, Train Loss: 0.2985653579235077
[32m[0514 05:33:14 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.2920381426811218, Train Loss: 0.2985636591911316
[32m[0514 05:33:14 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.2920416295528412, Train Loss: 0.2985619604587555
[32m[0514 05:33:14 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.29204505681991577, Train Loss: 0.29856032133102417
[32m[0514 05:33:14 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.29204851388931274, Train Loss: 0.29855865240097046
[32m[0514 05:33:14 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.29205191135406494, Train Loss: 0.29855701327323914
[32m[0514 05:33:14 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.29205530881881714, Train Loss: 0.2985553443431854
[32m[0514 05:33:14 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.29205867648124695, Train Loss: 0.2985536754131317
[32m[0514 05:33:14 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.29206210374832153, Train Loss: 0.298552006483078
[32m[0514 05:33:15 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.29206541180610657, Train Loss: 0.2985503673553467
[32m[0514 05:33:15 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.2920687198638916, Train Loss: 0.29854875802993774
[32m[0514 05:33:15 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.29207199811935425, Train Loss: 0.2985471487045288
[32m[0514 05:33:15 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.2920752763748169, Train Loss: 0.2985454797744751
[32m[0514 05:33:15 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.29207858443260193, Train Loss: 0.29854387044906616
[32m[0514 05:33:15 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.2920818328857422, Train Loss: 0.2985422909259796
[32m[0514 05:33:15 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.29208505153656006, Train Loss: 0.2985406816005707
[32m[0514 05:33:15 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.2920882999897003, Train Loss: 0.29853907227516174
[32m[0514 05:33:15 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.2920915186405182, Train Loss: 0.2985374629497528
[32m[0514 05:33:15 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.2920946776866913, Train Loss: 0.29853594303131104
[32m[0514 05:33:15 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.29209786653518677, Train Loss: 0.2985343337059021
[32m[0514 05:33:15 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.29210102558135986, Train Loss: 0.29853275418281555
[32m[0514 05:33:15 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.29210418462753296, Train Loss: 0.2985311448574066
[32m[0514 05:33:15 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.29210731387138367, Train Loss: 0.29852959513664246
[32m[0514 05:33:15 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.2921104431152344, Train Loss: 0.2985280156135559
[32m[0514 05:33:15 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.2921135127544403, Train Loss: 0.29852643609046936
[32m[0514 05:33:15 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.292116641998291, Train Loss: 0.29852494597435
[32m[0514 05:33:15 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.29211968183517456, Train Loss: 0.2985233962535858
[32m[0514 05:33:15 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.2921227216720581, Train Loss: 0.29852181673049927
[32m[0514 05:33:15 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.29212579131126404, Train Loss: 0.2985202968120575
[32m[0514 05:33:15 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.2921288311481476, Train Loss: 0.29851874709129333
[32m[0514 05:33:15 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.29213184118270874, Train Loss: 0.29851722717285156
[32m[0514 05:33:16 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.2921348512172699, Train Loss: 0.2985157370567322
[32m[0514 05:33:16 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.29213783144950867, Train Loss: 0.2985142171382904
[32m[0514 05:33:16 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.29214081168174744, Train Loss: 0.29851266741752625
[32m[0514 05:33:16 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.29214373230934143, Train Loss: 0.29851120710372925
[32m[0514 05:33:16 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.2921467125415802, Train Loss: 0.2985096871852875
[32m[0514 05:33:16 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.2921496629714966, Train Loss: 0.2985081970691681
[32m[0514 05:33:16 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.2921525537967682, Train Loss: 0.2985067069530487
[32m[0514 05:33:16 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.2921554744243622, Train Loss: 0.29850518703460693
[32m[0514 05:33:16 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.2921583950519562, Train Loss: 0.29850369691848755
[32m[0514 05:33:16 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.2921612560749054, Train Loss: 0.29850220680236816
[32m[0514 05:33:16 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.2921641767024994, Train Loss: 0.2985007166862488
[32m[0514 05:33:16 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.29216697812080383, Train Loss: 0.29849928617477417
[32m[0514 05:33:16 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.29216986894607544, Train Loss: 0.2984977960586548
[32m[0514 05:33:16 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.2921726703643799, Train Loss: 0.2984963059425354
[32m[0514 05:33:16 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.2921755015850067, Train Loss: 0.2984948456287384
[32m[0514 05:33:16 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.29217836260795593, Train Loss: 0.2984933853149414
[32m[0514 05:33:16 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.292181134223938, Train Loss: 0.2984919548034668
[32m[0514 05:33:16 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.29218393564224243, Train Loss: 0.2984904646873474
[32m[0514 05:33:16 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.2921867072582245, Train Loss: 0.2984890341758728
[32m[0514 05:33:16 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.29218947887420654, Train Loss: 0.2984876036643982
[32m[0514 05:33:16 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.2921922206878662, Train Loss: 0.2984861135482788
[32m[0514 05:33:16 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.2921949326992035, Train Loss: 0.2984847128391266
[32m[0514 05:33:17 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.29219767451286316, Train Loss: 0.2984832525253296
[32m[0514 05:33:17 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.29220038652420044, Train Loss: 0.298481822013855
[32m[0514 05:33:17 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.2922031283378601, Train Loss: 0.29848042130470276
[32m[0514 05:33:17 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.292205810546875, Train Loss: 0.29847902059555054
[32m[0514 05:33:17 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.2922084927558899, Train Loss: 0.2984775900840759
[32m[0514 05:33:17 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.2922112047672272, Train Loss: 0.29847612977027893
[32m[0514 05:33:17 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.2922138571739197, Train Loss: 0.2984747290611267
[32m[0514 05:33:17 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.2922165095806122, Train Loss: 0.2984733283519745
[32m[0514 05:33:17 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.2922191619873047, Train Loss: 0.29847192764282227
[32m[0514 05:33:17 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.2922218143939972, Train Loss: 0.29847052693367004
[32m[0514 05:33:17 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.2922244369983673, Train Loss: 0.29846909642219543
[32m[0514 05:33:17 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.2922270596027374, Train Loss: 0.2984676957130432
[32m[0514 05:33:17 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.29222965240478516, Train Loss: 0.2984663248062134
[32m[0514 05:33:17 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.2922322452068329, Train Loss: 0.29846489429473877
[32m[0514 05:33:17 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.2922348380088806, Train Loss: 0.2984635531902313
[32m[0514 05:33:17 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.29223740100860596, Train Loss: 0.2984621524810791
[32m[0514 05:33:17 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.2922399640083313, Train Loss: 0.2984607517719269
[32m[0514 05:33:17 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.29224252700805664, Train Loss: 0.29845935106277466
[32m[0514 05:33:17 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.2922450602054596, Train Loss: 0.2984579801559448
[32m[0514 05:33:17 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.29224762320518494, Train Loss: 0.2984566390514374
[32m[0514 05:33:17 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.2922501266002655, Train Loss: 0.29845526814460754
[32m[0514 05:33:17 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.29225265979766846, Train Loss: 0.2984538972377777
[32m[0514 05:33:17 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.292255163192749, Train Loss: 0.2984524965286255
[32m[0514 05:33:18 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.2922576665878296, Train Loss: 0.29845115542411804
[32m[0514 05:33:18 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.29226016998291016, Train Loss: 0.2984497845172882
[32m[0514 05:33:18 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.29226264357566833, Train Loss: 0.29844844341278076
[32m[0514 05:33:18 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.2922651171684265, Train Loss: 0.2984471023082733
[32m[0514 05:33:18 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.2922675907611847, Train Loss: 0.29844576120376587
[32m[0514 05:33:18 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.2922700047492981, Train Loss: 0.29844439029693604
[32m[0514 05:33:18 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.2922724485397339, Train Loss: 0.2984430193901062
[32m[0514 05:33:18 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.2922748923301697, Train Loss: 0.29844170808792114
[32m[0514 05:33:18 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.29227733612060547, Train Loss: 0.2984403371810913
[32m[0514 05:33:18 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.2922797203063965, Train Loss: 0.29843902587890625
[32m[0514 05:33:18 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.2922821640968323, Train Loss: 0.2984376549720764
[32m[0514 05:33:18 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.2922845482826233, Train Loss: 0.29843637347221375
[32m[0514 05:33:18 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.2922869622707367, Train Loss: 0.2984350323677063
[32m[0514 05:33:18 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.2922893166542053, Train Loss: 0.29843366146087646
[32m[0514 05:33:18 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.29229170083999634, Train Loss: 0.2984323501586914
[32m[0514 05:33:18 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.29229408502578735, Train Loss: 0.29843100905418396
[32m[0514 05:33:18 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.292296439409256, Train Loss: 0.2984296977519989
[32m[0514 05:33:18 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.2922987937927246, Train Loss: 0.29842838644981384
[32m[0514 05:33:18 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.29230114817619324, Train Loss: 0.2984270453453064
[32m[0514 05:33:18 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.2923034429550171, Train Loss: 0.2984257936477661
[32m[0514 05:33:18 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.2923057973384857, Train Loss: 0.29842445254325867
[32m[0514 05:33:19 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.29230812191963196, Train Loss: 0.2984231114387512
[32m[0514 05:33:19 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.2923104166984558, Train Loss: 0.29842182993888855
[32m[0514 05:33:19 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.29231271147727966, Train Loss: 0.2984205186367035
[32m[0514 05:33:19 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.2923150062561035, Train Loss: 0.29841920733451843
[32m[0514 05:33:19 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.29231730103492737, Train Loss: 0.29841792583465576
[32m[0514 05:33:19 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.29231956601142883, Train Loss: 0.2984166145324707
[32m[0514 05:33:19 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.2923218607902527, Train Loss: 0.29841530323028564
[32m[0514 05:33:19 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.29232409596443176, Train Loss: 0.298414021730423
[32m[0514 05:33:19 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.2923263609409332, Train Loss: 0.2984127700328827
[32m[0514 05:33:19 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.2923286259174347, Train Loss: 0.29841142892837524
[32m[0514 05:33:19 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.2923308312892914, Train Loss: 0.2984101474285126
[32m[0514 05:33:19 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.29233306646347046, Train Loss: 0.2984088659286499
[32m[0514 05:33:19 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.29233527183532715, Train Loss: 0.298407644033432
[32m[0514 05:33:19 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.29233747720718384, Train Loss: 0.29840630292892456
[32m[0514 05:33:19 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.2923397421836853, Train Loss: 0.2984049916267395
[32m[0514 05:33:19 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.2923419177532196, Train Loss: 0.2984037399291992
[32m[0514 05:33:19 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.2923441529273987, Train Loss: 0.29840245842933655
[32m[0514 05:33:19 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.2923462986946106, Train Loss: 0.2984011471271515
[32m[0514 05:33:19 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.2923484742641449, Train Loss: 0.2983999252319336
[32m[0514 05:33:19 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.2923506498336792, Train Loss: 0.2983986437320709
[32m[0514 05:33:19 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.2923528254032135, Train Loss: 0.29839736223220825
[32m[0514 05:33:19 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.2923550009727478, Train Loss: 0.29839611053466797
[32m[0514 05:33:19 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.2923571467399597, Train Loss: 0.2983948886394501
[32m[0514 05:33:20 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.29235929250717163, Train Loss: 0.2983936071395874
[32m[0514 05:33:20 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.29236146807670593, Train Loss: 0.2983923554420471
[32m[0514 05:33:20 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.29236355423927307, Train Loss: 0.29839107394218445
[32m[0514 05:33:20 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.292365700006485, Train Loss: 0.29838982224464417
[32m[0514 05:33:20 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.2923678159713745, Train Loss: 0.29838860034942627
[32m[0514 05:33:20 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.29236993193626404, Train Loss: 0.2983872890472412
[32m[0514 05:33:20 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.29237204790115356, Train Loss: 0.2983860671520233
[32m[0514 05:33:20 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.2923741340637207, Train Loss: 0.2983848452568054
[32m[0514 05:33:20 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.29237622022628784, Train Loss: 0.29838356375694275
[32m[0514 05:33:20 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.292378306388855, Train Loss: 0.29838231205940247
[32m[0514 05:33:20 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.2923803925514221, Train Loss: 0.29838109016418457
[32m[0514 05:33:20 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.29238247871398926, Train Loss: 0.2983798682689667
[32m[0514 05:33:20 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.292384535074234, Train Loss: 0.298378586769104
[32m[0514 05:33:20 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.29238656163215637, Train Loss: 0.2983773946762085
[32m[0514 05:33:20 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.2923886179924011, Train Loss: 0.2983761727809906
[32m[0514 05:33:20 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.29239070415496826, Train Loss: 0.2983749210834503
[32m[0514 05:33:20 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.29239270091056824, Train Loss: 0.2983736991882324
[32m[0514 05:33:20 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.2923947870731354, Train Loss: 0.2983724772930145
[32m[0514 05:33:20 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.29239681363105774, Train Loss: 0.29837122559547424
[32m[0514 05:33:20 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.2923988103866577, Train Loss: 0.29837003350257874
[32m[0514 05:33:20 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.2924008071422577, Train Loss: 0.29836881160736084
[32m[0514 05:33:20 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.29240286350250244, Train Loss: 0.29836758971214294
[32m[0514 05:33:21 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.2924048602581024, Train Loss: 0.29836636781692505
[32m[0514 05:33:21 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.2924068868160248, Train Loss: 0.29836514592170715
[32m[0514 05:33:21 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.29240885376930237, Train Loss: 0.29836389422416687
[32m[0514 05:33:21 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.29241085052490234, Train Loss: 0.29836270213127136
[32m[0514 05:33:21 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.29241281747817993, Train Loss: 0.29836151003837585
[32m[0514 05:33:21 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.2924148142337799, Train Loss: 0.29836025834083557
[32m[0514 05:33:21 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.2924167811870575, Train Loss: 0.29835912585258484
[32m[0514 05:33:21 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.2924187481403351, Train Loss: 0.29835787415504456
[32m[0514 05:33:21 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.2924206852912903, Train Loss: 0.29835668206214905
[32m[0514 05:33:21 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.29242265224456787, Train Loss: 0.29835546016693115
[32m[0514 05:33:21 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.29242461919784546, Train Loss: 0.29835426807403564
[32m[0514 05:33:21 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.29242655634880066, Train Loss: 0.29835307598114014
[32m[0514 05:33:21 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.29242849349975586, Train Loss: 0.29835188388824463
[32m[0514 05:33:21 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.29243040084838867, Train Loss: 0.2983507215976715
[32m[0514 05:33:21 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.29243233799934387, Train Loss: 0.2983494997024536
[32m[0514 05:33:21 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.2924342751502991, Train Loss: 0.2983483374118805
[32m[0514 05:33:21 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.29243624210357666, Train Loss: 0.2983471155166626
[32m[0514 05:33:21 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.2924380898475647, Train Loss: 0.2983459532260895
[32m[0514 05:33:21 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.2924399971961975, Train Loss: 0.2983447313308716
[32m[0514 05:33:21 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.2924419045448303, Train Loss: 0.29834359884262085
[32m[0514 05:33:21 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.2924438416957855, Train Loss: 0.29834240674972534
[32m[0514 05:33:21 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.29244571924209595, Train Loss: 0.29834121465682983
[32m[0514 05:33:22 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.292447566986084, Train Loss: 0.2983400225639343
[32m[0514 05:33:22 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.2924494743347168, Train Loss: 0.2983388304710388
[32m[0514 05:33:22 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.2924513518810272, Train Loss: 0.2983376681804657
[32m[0514 05:33:22 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.29245319962501526, Train Loss: 0.2983365058898926
[32m[0514 05:33:22 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.29245510697364807, Train Loss: 0.29833531379699707
[32m[0514 05:33:22 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.2924569547176361, Train Loss: 0.29833415150642395
[32m[0514 05:33:22 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.29245883226394653, Train Loss: 0.29833295941352844
[32m[0514 05:33:22 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.2924606204032898, Train Loss: 0.2983317971229553
[32m[0514 05:33:22 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.2924625277519226, Train Loss: 0.2983306348323822
[32m[0514 05:33:22 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.29246434569358826, Train Loss: 0.2983294725418091
[32m[0514 05:33:22 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.2924661934375763, Train Loss: 0.29832831025123596
[32m[0514 05:33:22 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.29246804118156433, Train Loss: 0.29832717776298523
[32m[0514 05:33:22 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.29246988892555237, Train Loss: 0.2983259856700897
[32m[0514 05:33:22 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.292471706867218, Train Loss: 0.298324853181839
[32m[0514 05:33:22 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.29247352480888367, Train Loss: 0.29832369089126587
[32m[0514 05:33:22 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.29247531294822693, Train Loss: 0.29832249879837036
[32m[0514 05:33:22 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.29247716069221497, Train Loss: 0.29832136631011963
[32m[0514 05:33:22 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.29247891902923584, Train Loss: 0.2983202636241913
[32m[0514 05:33:22 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.2924807667732239, Train Loss: 0.2983190715312958
[32m[0514 05:33:22 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.29248255491256714, Train Loss: 0.29831793904304504
[32m[0514 05:33:22 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.292484313249588, Train Loss: 0.2983167767524719
[32m[0514 05:33:22 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.29248616099357605, Train Loss: 0.2983156442642212
[32m[0514 05:33:23 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.2924879491329193, Train Loss: 0.29831451177597046
[32m[0514 05:33:23 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.2924897074699402, Train Loss: 0.29831334948539734
[32m[0514 05:33:23 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.29249149560928345, Train Loss: 0.2983121871948242
[32m[0514 05:33:23 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.2924932539463043, Train Loss: 0.29831111431121826
[32m[0514 05:33:23 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.2924950420856476, Train Loss: 0.29830995202064514
[32m[0514 05:33:23 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.29249680042266846, Train Loss: 0.2983088195323944
[32m[0514 05:33:23 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.29249852895736694, Train Loss: 0.29830771684646606
[32m[0514 05:33:23 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.2925003170967102, Train Loss: 0.29830655455589294
[32m[0514 05:33:23 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.2925020754337311, Train Loss: 0.2983054518699646
[32m[0514 05:33:23 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.2925037741661072, Train Loss: 0.29830434918403625
[32m[0514 05:33:23 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.29250556230545044, Train Loss: 0.29830315709114075
[32m[0514 05:33:23 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.2925072908401489, Train Loss: 0.2983020842075348
[32m[0514 05:33:23 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.292508989572525, Train Loss: 0.29830092191696167
[32m[0514 05:33:23 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.2925107479095459, Train Loss: 0.2982998192310333
[32m[0514 05:33:23 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.2925124764442444, Train Loss: 0.298298716545105
[32m[0514 05:33:23 @mbmf_main.py:227][0m batch size for trpo is 1000
[32m[0514 05:33:23 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 05:33:23 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 05:33:23 @mbmf_main.py:132][0m Training starts at /root/mbbl
[32m[0514 05:33:23 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 05:33:23 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 05:33:23 @base_worker.py:45][0m Worker 0 online
[32m[0514 05:33:23 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 05:33:23 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 05:33:23 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 05:33:23 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 05:33:23 @base_worker.py:45][0m Worker 1 online
[32m[0514 05:33:23 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 05:33:23 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 05:33:23 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 05:33:23 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 05:33:23 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 05:33:23 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 05:33:23 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 05:33:23 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 05:33:23 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 05:33:23 @base_worker.py:45][0m Worker 2 online
[32m[0514 05:33:23 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 05:33:23 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 05:33:23 @base_worker.py:45][0m Worker 3 online
[32m[0514 05:33:23 @base_worker.py:45][0m Worker 4 online
[32m[0514 05:33:23 @base_worker.py:45][0m Worker 5 online
[32m[0514 05:33:23 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 05:33:23 @base_worker.py:45][0m Worker 6 online
[32m[0514 05:33:23 @base_worker.py:45][0m Worker 7 online
[32m[0514 05:33:23 @base_worker.py:45][0m Worker 8 online
[32m[0514 05:33:23 @base_worker.py:45][0m Worker 9 online
[32m[0514 05:33:23 @base_worker.py:45][0m Worker 10 online
[32m[0514 05:33:23 @base_worker.py:45][0m Worker 11 online
[32m[0514 05:33:23 @base_worker.py:45][0m Worker 12 online
[32m[0514 05:33:23 @base_worker.py:45][0m Worker 13 online
[32m[0514 05:33:23 @base_worker.py:45][0m Worker 14 online
[32m[0514 05:33:23 @base_worker.py:45][0m Worker 15 online
[32m[0514 05:33:23 @base_worker.py:45][0m Worker 16 online
[32m[0514 05:33:23 @base_worker.py:45][0m Worker 17 online
[32m[0514 05:33:23 @base_worker.py:45][0m Worker 18 online
[32m[0514 05:33:23 @base_worker.py:45][0m Worker 19 online
[32m[0514 05:33:24 @base_trainer.py:152][0m Trainer maintains [1] policy network
[32m[0514 05:33:24 @base_trainer.py:152][0m Trainer maintains [1] dynamics network
[32m[0514 05:33:24 @base_trainer.py:152][0m Trainer maintains [1] reward network
[32m[0514 05:33:24 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:24 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:24 @base_trainer.py:216][0m Mean reward: -1386.6321354174806
[32m[0514 05:33:25 @base_main.py:38][0m --------------- Iteration 1 ---------------
[32m[0514 05:33:25 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0000 mins
[32m[0514 05:33:25 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 05:33:25 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0142 mins
[32m[0514 05:33:25 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:25 @base_main.py:47][0m 1005 total steps have happened
[32m[0514 05:33:25 @base_main.py:52][0m [avg_reward]: -1386.6321354174806
[32m[0514 05:33:25 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:25 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:25 @base_trainer.py:216][0m Mean reward: -1207.6860061210166
[32m[0514 05:33:26 @base_main.py:38][0m --------------- Iteration 2 ---------------
[32m[0514 05:33:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0173 mins
[32m[0514 05:33:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0032 mins
[32m[0514 05:33:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 05:33:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:26 @base_main.py:47][0m 2010 total steps have happened
[32m[0514 05:33:26 @base_main.py:52][0m [avg_reward]: -1207.6860061210166
[32m[0514 05:33:26 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:26 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:26 @base_trainer.py:216][0m Mean reward: -1511.4800383141494
[32m[0514 05:33:27 @base_main.py:38][0m --------------- Iteration 3 ---------------
[32m[0514 05:33:27 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0295 mins
[32m[0514 05:33:27 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 05:33:27 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 05:33:27 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:27 @base_main.py:47][0m 3015 total steps have happened
[32m[0514 05:33:27 @base_main.py:52][0m [avg_reward]: -1511.4800383141494
[32m[0514 05:33:27 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:27 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:27 @base_trainer.py:216][0m Mean reward: -1385.7295713951305
[32m[0514 05:33:27 @base_main.py:38][0m --------------- Iteration 4 ---------------
[32m[0514 05:33:27 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0417 mins
[32m[0514 05:33:27 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0514 05:33:27 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0081 mins
[32m[0514 05:33:27 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:27 @base_main.py:47][0m 4020 total steps have happened
[32m[0514 05:33:27 @base_main.py:52][0m [avg_reward]: -1385.7295713951305
[32m[0514 05:33:28 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:28 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:28 @base_trainer.py:216][0m Mean reward: -1491.210561853087
[32m[0514 05:33:28 @base_main.py:38][0m --------------- Iteration 5 ---------------
[32m[0514 05:33:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0530 mins
[32m[0514 05:33:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 05:33:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 05:33:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:28 @base_main.py:47][0m 5025 total steps have happened
[32m[0514 05:33:28 @base_main.py:52][0m [avg_reward]: -1491.210561853087
[32m[0514 05:33:28 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:28 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:28 @base_trainer.py:216][0m Mean reward: -1213.2881936166605
[32m[0514 05:33:29 @base_main.py:38][0m --------------- Iteration 6 ---------------
[32m[0514 05:33:29 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0648 mins
[32m[0514 05:33:29 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 05:33:29 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 05:33:29 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:29 @base_main.py:47][0m 6030 total steps have happened
[32m[0514 05:33:29 @base_main.py:52][0m [avg_reward]: -1213.2881936166605
[32m[0514 05:33:29 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:29 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:29 @base_trainer.py:216][0m Mean reward: -1283.564591554355
[32m[0514 05:33:29 @base_main.py:38][0m --------------- Iteration 7 ---------------
[32m[0514 05:33:29 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0764 mins
[32m[0514 05:33:29 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 05:33:29 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 05:33:29 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:29 @base_main.py:47][0m 7035 total steps have happened
[32m[0514 05:33:29 @base_main.py:52][0m [avg_reward]: -1283.564591554355
[32m[0514 05:33:30 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:30 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:30 @base_trainer.py:216][0m Mean reward: -1272.4263992983565
[32m[0514 05:33:30 @base_main.py:38][0m --------------- Iteration 8 ---------------
[32m[0514 05:33:30 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0883 mins
[32m[0514 05:33:30 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 05:33:30 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 05:33:30 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:30 @base_main.py:47][0m 8040 total steps have happened
[32m[0514 05:33:30 @base_main.py:52][0m [avg_reward]: -1272.4263992983565
[32m[0514 05:33:30 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:30 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:30 @base_trainer.py:216][0m Mean reward: -1221.05949564736
[32m[0514 05:33:31 @base_main.py:38][0m --------------- Iteration 9 ---------------
[32m[0514 05:33:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1002 mins
[32m[0514 05:33:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0514 05:33:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 05:33:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:31 @base_main.py:47][0m 9045 total steps have happened
[32m[0514 05:33:31 @base_main.py:52][0m [avg_reward]: -1221.05949564736
[32m[0514 05:33:31 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:31 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:31 @base_trainer.py:216][0m Mean reward: -1142.9305341421727
[32m[0514 05:33:32 @base_main.py:38][0m --------------- Iteration 10 ---------------
[32m[0514 05:33:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1117 mins
[32m[0514 05:33:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0514 05:33:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 05:33:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:32 @base_main.py:47][0m 10050 total steps have happened
[32m[0514 05:33:32 @base_main.py:52][0m [avg_reward]: -1142.9305341421727
[32m[0514 05:33:32 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:32 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:32 @base_trainer.py:216][0m Mean reward: -1016.7201474372862
[32m[0514 05:33:32 @base_main.py:38][0m --------------- Iteration 11 ---------------
[32m[0514 05:33:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1232 mins
[32m[0514 05:33:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0514 05:33:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 05:33:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:32 @base_main.py:47][0m 11055 total steps have happened
[32m[0514 05:33:32 @base_main.py:52][0m [avg_reward]: -1016.7201474372862
[32m[0514 05:33:32 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:32 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:32 @base_trainer.py:216][0m Mean reward: -1270.4339510470058
[32m[0514 05:33:33 @base_main.py:38][0m --------------- Iteration 12 ---------------
[32m[0514 05:33:33 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1347 mins
[32m[0514 05:33:33 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 05:33:33 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 05:33:33 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:33 @base_main.py:47][0m 12060 total steps have happened
[32m[0514 05:33:33 @base_main.py:52][0m [avg_reward]: -1270.4339510470058
[32m[0514 05:33:33 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:33 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:33 @base_trainer.py:216][0m Mean reward: -1281.7602241978393
[32m[0514 05:33:34 @base_main.py:38][0m --------------- Iteration 13 ---------------
[32m[0514 05:33:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1462 mins
[32m[0514 05:33:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 05:33:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 05:33:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:34 @base_main.py:47][0m 13065 total steps have happened
[32m[0514 05:33:34 @base_main.py:52][0m [avg_reward]: -1281.7602241978393
[32m[0514 05:33:34 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:34 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:34 @base_trainer.py:216][0m Mean reward: -1049.7600096017673
[32m[0514 05:33:34 @base_main.py:38][0m --------------- Iteration 14 ---------------
[32m[0514 05:33:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1574 mins
[32m[0514 05:33:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 05:33:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 05:33:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:34 @base_main.py:47][0m 14070 total steps have happened
[32m[0514 05:33:34 @base_main.py:52][0m [avg_reward]: -1049.7600096017673
[32m[0514 05:33:34 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:34 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:34 @base_trainer.py:216][0m Mean reward: -1232.3854233630075
[32m[0514 05:33:35 @base_main.py:38][0m --------------- Iteration 15 ---------------
[32m[0514 05:33:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1692 mins
[32m[0514 05:33:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 05:33:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 05:33:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:35 @base_main.py:47][0m 15075 total steps have happened
[32m[0514 05:33:35 @base_main.py:52][0m [avg_reward]: -1232.3854233630075
[32m[0514 05:33:35 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:35 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:35 @base_trainer.py:216][0m Mean reward: -1426.4510326088603
[32m[0514 05:33:36 @base_main.py:38][0m --------------- Iteration 16 ---------------
[32m[0514 05:33:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1807 mins
[32m[0514 05:33:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 05:33:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0080 mins
[32m[0514 05:33:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:36 @base_main.py:47][0m 16080 total steps have happened
[32m[0514 05:33:36 @base_main.py:52][0m [avg_reward]: -1426.4510326088603
[32m[0514 05:33:36 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:36 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:36 @base_trainer.py:216][0m Mean reward: -1118.919230616395
[32m[0514 05:33:36 @base_main.py:38][0m --------------- Iteration 17 ---------------
[32m[0514 05:33:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1914 mins
[32m[0514 05:33:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 05:33:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0514 05:33:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:36 @base_main.py:47][0m 17085 total steps have happened
[32m[0514 05:33:36 @base_main.py:52][0m [avg_reward]: -1118.919230616395
[32m[0514 05:33:36 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:36 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:36 @base_trainer.py:216][0m Mean reward: -1251.464188574222
[32m[0514 05:33:37 @base_main.py:38][0m --------------- Iteration 18 ---------------
[32m[0514 05:33:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2027 mins
[32m[0514 05:33:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 05:33:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 05:33:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:37 @base_main.py:47][0m 18090 total steps have happened
[32m[0514 05:33:37 @base_main.py:52][0m [avg_reward]: -1251.464188574222
[32m[0514 05:33:37 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:37 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:37 @base_trainer.py:216][0m Mean reward: -1304.4921797580737
[32m[0514 05:33:38 @base_main.py:38][0m --------------- Iteration 19 ---------------
[32m[0514 05:33:38 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2140 mins
[32m[0514 05:33:38 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 05:33:38 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 05:33:38 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:38 @base_main.py:47][0m 19095 total steps have happened
[32m[0514 05:33:38 @base_main.py:52][0m [avg_reward]: -1304.4921797580737
[32m[0514 05:33:38 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:38 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:38 @base_trainer.py:216][0m Mean reward: -1198.236864376348
[32m[0514 05:33:38 @base_main.py:38][0m --------------- Iteration 20 ---------------
[32m[0514 05:33:38 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2253 mins
[32m[0514 05:33:38 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 05:33:38 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 05:33:38 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:38 @base_main.py:47][0m 20100 total steps have happened
[32m[0514 05:33:38 @base_main.py:52][0m [avg_reward]: -1198.236864376348
[32m[0514 05:33:38 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:38 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:38 @base_trainer.py:216][0m Mean reward: -1334.2581107406268
[32m[0514 05:33:39 @base_main.py:38][0m --------------- Iteration 21 ---------------
[32m[0514 05:33:39 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2367 mins
[32m[0514 05:33:39 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0514 05:33:39 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 05:33:39 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:39 @base_main.py:47][0m 21105 total steps have happened
[32m[0514 05:33:39 @base_main.py:52][0m [avg_reward]: -1334.2581107406268
[32m[0514 05:33:39 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:39 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:39 @base_trainer.py:216][0m Mean reward: -1393.4592255660584
[32m[0514 05:33:40 @base_main.py:38][0m --------------- Iteration 22 ---------------
[32m[0514 05:33:40 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2481 mins
[32m[0514 05:33:40 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 05:33:40 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0514 05:33:40 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:40 @base_main.py:47][0m 22110 total steps have happened
[32m[0514 05:33:40 @base_main.py:52][0m [avg_reward]: -1393.4592255660584
[32m[0514 05:33:40 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:40 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:40 @base_trainer.py:216][0m Mean reward: -1124.4658284223594
[32m[0514 05:33:40 @base_main.py:38][0m --------------- Iteration 23 ---------------
[32m[0514 05:33:40 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2594 mins
[32m[0514 05:33:40 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 05:33:40 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0514 05:33:40 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:40 @base_main.py:47][0m 23115 total steps have happened
[32m[0514 05:33:40 @base_main.py:52][0m [avg_reward]: -1124.4658284223594
[32m[0514 05:33:41 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:41 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:41 @base_trainer.py:216][0m Mean reward: -1118.216644545764
[32m[0514 05:33:41 @base_main.py:38][0m --------------- Iteration 24 ---------------
[32m[0514 05:33:41 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2714 mins
[32m[0514 05:33:41 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 05:33:41 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 05:33:41 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:41 @base_main.py:47][0m 24120 total steps have happened
[32m[0514 05:33:41 @base_main.py:52][0m [avg_reward]: -1118.216644545764
[32m[0514 05:33:41 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:41 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:41 @base_trainer.py:216][0m Mean reward: -1201.8974317041082
[32m[0514 05:33:42 @base_main.py:38][0m --------------- Iteration 25 ---------------
[32m[0514 05:33:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2829 mins
[32m[0514 05:33:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 05:33:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 05:33:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:42 @base_main.py:47][0m 25125 total steps have happened
[32m[0514 05:33:42 @base_main.py:52][0m [avg_reward]: -1201.8974317041082
[32m[0514 05:33:42 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:42 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:42 @base_trainer.py:216][0m Mean reward: -1124.5984597993452
[32m[0514 05:33:43 @base_main.py:38][0m --------------- Iteration 26 ---------------
[32m[0514 05:33:43 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2943 mins
[32m[0514 05:33:43 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 05:33:43 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 05:33:43 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:43 @base_main.py:47][0m 26130 total steps have happened
[32m[0514 05:33:43 @base_main.py:52][0m [avg_reward]: -1124.5984597993452
[32m[0514 05:33:43 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:43 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:43 @base_trainer.py:216][0m Mean reward: -1406.9660843589654
[32m[0514 05:33:43 @base_main.py:38][0m --------------- Iteration 27 ---------------
[32m[0514 05:33:43 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3060 mins
[32m[0514 05:33:43 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0514 05:33:43 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0514 05:33:43 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:43 @base_main.py:47][0m 27135 total steps have happened
[32m[0514 05:33:43 @base_main.py:52][0m [avg_reward]: -1406.9660843589654
[32m[0514 05:33:43 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:43 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:43 @base_trainer.py:216][0m Mean reward: -1398.7729781931941
[32m[0514 05:33:44 @base_main.py:38][0m --------------- Iteration 28 ---------------
[32m[0514 05:33:44 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3177 mins
[32m[0514 05:33:44 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0514 05:33:44 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 05:33:44 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:44 @base_main.py:47][0m 28140 total steps have happened
[32m[0514 05:33:44 @base_main.py:52][0m [avg_reward]: -1398.7729781931941
[32m[0514 05:33:44 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:44 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:44 @base_trainer.py:216][0m Mean reward: -1221.9667408327161
[32m[0514 05:33:45 @base_main.py:38][0m --------------- Iteration 29 ---------------
[32m[0514 05:33:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3290 mins
[32m[0514 05:33:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0514 05:33:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 05:33:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:45 @base_main.py:47][0m 29145 total steps have happened
[32m[0514 05:33:45 @base_main.py:52][0m [avg_reward]: -1221.9667408327161
[32m[0514 05:33:45 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:45 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:45 @base_trainer.py:216][0m Mean reward: -1192.5875551199726
[32m[0514 05:33:45 @base_main.py:38][0m --------------- Iteration 30 ---------------
[32m[0514 05:33:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3407 mins
[32m[0514 05:33:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 05:33:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 05:33:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:45 @base_main.py:47][0m 30150 total steps have happened
[32m[0514 05:33:45 @base_main.py:52][0m [avg_reward]: -1192.5875551199726
[32m[0514 05:33:45 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:45 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:45 @base_trainer.py:216][0m Mean reward: -1112.0140368916198
[32m[0514 05:33:46 @base_main.py:38][0m --------------- Iteration 31 ---------------
[32m[0514 05:33:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3523 mins
[32m[0514 05:33:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 05:33:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 05:33:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:46 @base_main.py:47][0m 31155 total steps have happened
[32m[0514 05:33:46 @base_main.py:52][0m [avg_reward]: -1112.0140368916198
[32m[0514 05:33:46 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:46 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:46 @base_trainer.py:216][0m Mean reward: -1002.3261153089622
[32m[0514 05:33:47 @base_main.py:38][0m --------------- Iteration 32 ---------------
[32m[0514 05:33:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3637 mins
[32m[0514 05:33:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 05:33:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 05:33:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:47 @base_main.py:47][0m 32160 total steps have happened
[32m[0514 05:33:47 @base_main.py:52][0m [avg_reward]: -1002.3261153089622
[32m[0514 05:33:47 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:47 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:47 @base_trainer.py:216][0m Mean reward: -1179.4416497810948
[32m[0514 05:33:47 @base_main.py:38][0m --------------- Iteration 33 ---------------
[32m[0514 05:33:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3751 mins
[32m[0514 05:33:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 05:33:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0514 05:33:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:47 @base_main.py:47][0m 33165 total steps have happened
[32m[0514 05:33:47 @base_main.py:52][0m [avg_reward]: -1179.4416497810948
[32m[0514 05:33:47 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:47 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:47 @base_trainer.py:216][0m Mean reward: -1222.7942313106412
[32m[0514 05:33:48 @base_main.py:38][0m --------------- Iteration 34 ---------------
[32m[0514 05:33:48 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3862 mins
[32m[0514 05:33:48 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 05:33:48 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 05:33:48 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:48 @base_main.py:47][0m 34170 total steps have happened
[32m[0514 05:33:48 @base_main.py:52][0m [avg_reward]: -1222.7942313106412
[32m[0514 05:33:48 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:48 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:48 @base_trainer.py:216][0m Mean reward: -1174.7872658275542
[32m[0514 05:33:49 @base_main.py:38][0m --------------- Iteration 35 ---------------
[32m[0514 05:33:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3978 mins
[32m[0514 05:33:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 05:33:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 05:33:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:49 @base_main.py:47][0m 35175 total steps have happened
[32m[0514 05:33:49 @base_main.py:52][0m [avg_reward]: -1174.7872658275542
[32m[0514 05:33:49 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:49 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:49 @base_trainer.py:216][0m Mean reward: -1383.9809063637467
[32m[0514 05:33:49 @base_main.py:38][0m --------------- Iteration 36 ---------------
[32m[0514 05:33:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4093 mins
[32m[0514 05:33:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 05:33:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0514 05:33:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:49 @base_main.py:47][0m 36180 total steps have happened
[32m[0514 05:33:49 @base_main.py:52][0m [avg_reward]: -1383.9809063637467
[32m[0514 05:33:50 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:50 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:50 @base_trainer.py:216][0m Mean reward: -1243.986552399142
[32m[0514 05:33:50 @base_main.py:38][0m --------------- Iteration 37 ---------------
[32m[0514 05:33:50 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4205 mins
[32m[0514 05:33:50 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 05:33:50 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0084 mins
[32m[0514 05:33:50 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:50 @base_main.py:47][0m 37185 total steps have happened
[32m[0514 05:33:50 @base_main.py:52][0m [avg_reward]: -1243.986552399142
[32m[0514 05:33:50 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:50 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:50 @base_trainer.py:216][0m Mean reward: -1268.1910599012285
[32m[0514 05:33:51 @base_main.py:38][0m --------------- Iteration 38 ---------------
[32m[0514 05:33:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4313 mins
[32m[0514 05:33:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 05:33:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 05:33:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:51 @base_main.py:47][0m 38190 total steps have happened
[32m[0514 05:33:51 @base_main.py:52][0m [avg_reward]: -1268.1910599012285
[32m[0514 05:33:51 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:51 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:51 @base_trainer.py:216][0m Mean reward: -1066.3244460837925
[32m[0514 05:33:51 @base_main.py:38][0m --------------- Iteration 39 ---------------
[32m[0514 05:33:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4429 mins
[32m[0514 05:33:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 05:33:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0514 05:33:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:51 @base_main.py:47][0m 39195 total steps have happened
[32m[0514 05:33:51 @base_main.py:52][0m [avg_reward]: -1066.3244460837925
[32m[0514 05:33:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:52 @base_trainer.py:216][0m Mean reward: -1258.0393100745646
[32m[0514 05:33:52 @base_main.py:38][0m --------------- Iteration 40 ---------------
[32m[0514 05:33:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4543 mins
[32m[0514 05:33:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 05:33:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0514 05:33:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:52 @base_main.py:47][0m 40200 total steps have happened
[32m[0514 05:33:52 @base_main.py:52][0m [avg_reward]: -1258.0393100745646
[32m[0514 05:33:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:52 @base_trainer.py:216][0m Mean reward: -1226.2335588772398
[32m[0514 05:33:53 @base_main.py:38][0m --------------- Iteration 41 ---------------
[32m[0514 05:33:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4656 mins
[32m[0514 05:33:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0514 05:33:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 05:33:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:53 @base_main.py:47][0m 41205 total steps have happened
[32m[0514 05:33:53 @base_main.py:52][0m [avg_reward]: -1226.2335588772398
[32m[0514 05:33:53 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:53 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:53 @base_trainer.py:216][0m Mean reward: -1121.0641225579411
[32m[0514 05:33:53 @base_main.py:38][0m --------------- Iteration 42 ---------------
[32m[0514 05:33:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4770 mins
[32m[0514 05:33:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0514 05:33:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0514 05:33:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:53 @base_main.py:47][0m 42210 total steps have happened
[32m[0514 05:33:53 @base_main.py:52][0m [avg_reward]: -1121.0641225579411
[32m[0514 05:33:54 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:54 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:54 @base_trainer.py:216][0m Mean reward: -909.015826926379
[32m[0514 05:33:54 @base_main.py:38][0m --------------- Iteration 43 ---------------
[32m[0514 05:33:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4879 mins
[32m[0514 05:33:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0514 05:33:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0514 05:33:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:54 @base_main.py:47][0m 43215 total steps have happened
[32m[0514 05:33:54 @base_main.py:52][0m [avg_reward]: -909.015826926379
[32m[0514 05:33:54 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:54 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:54 @base_trainer.py:216][0m Mean reward: -1097.3818816914686
[32m[0514 05:33:55 @base_main.py:38][0m --------------- Iteration 44 ---------------
[32m[0514 05:33:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4995 mins
[32m[0514 05:33:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0514 05:33:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 05:33:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:55 @base_main.py:47][0m 44220 total steps have happened
[32m[0514 05:33:55 @base_main.py:52][0m [avg_reward]: -1097.3818816914686
[32m[0514 05:33:55 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:55 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:55 @base_trainer.py:216][0m Mean reward: -1167.3355567635365
[32m[0514 05:33:56 @base_main.py:38][0m --------------- Iteration 45 ---------------
[32m[0514 05:33:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5110 mins
[32m[0514 05:33:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0514 05:33:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0514 05:33:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:56 @base_main.py:47][0m 45225 total steps have happened
[32m[0514 05:33:56 @base_main.py:52][0m [avg_reward]: -1167.3355567635365
[32m[0514 05:33:56 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:56 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:56 @base_trainer.py:216][0m Mean reward: -1033.6025326635454
[32m[0514 05:33:56 @base_main.py:38][0m --------------- Iteration 46 ---------------
[32m[0514 05:33:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5227 mins
[32m[0514 05:33:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 05:33:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 05:33:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:56 @base_main.py:47][0m 46230 total steps have happened
[32m[0514 05:33:56 @base_main.py:52][0m [avg_reward]: -1033.6025326635454
[32m[0514 05:33:56 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:56 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:56 @base_trainer.py:216][0m Mean reward: -1160.5517016894166
[32m[0514 05:33:57 @base_main.py:38][0m --------------- Iteration 47 ---------------
[32m[0514 05:33:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5343 mins
[32m[0514 05:33:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0514 05:33:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 05:33:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:57 @base_main.py:47][0m 47235 total steps have happened
[32m[0514 05:33:57 @base_main.py:52][0m [avg_reward]: -1160.5517016894166
[32m[0514 05:33:57 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:57 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:57 @base_trainer.py:216][0m Mean reward: -1164.6369976267267
[32m[0514 05:33:58 @base_main.py:38][0m --------------- Iteration 48 ---------------
[32m[0514 05:33:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5454 mins
[32m[0514 05:33:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 05:33:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 05:33:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:58 @base_main.py:47][0m 48240 total steps have happened
[32m[0514 05:33:58 @base_main.py:52][0m [avg_reward]: -1164.6369976267267
[32m[0514 05:33:58 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:58 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:58 @base_trainer.py:216][0m Mean reward: -1094.8508911076392
[32m[0514 05:33:58 @base_main.py:38][0m --------------- Iteration 49 ---------------
[32m[0514 05:33:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5570 mins
[32m[0514 05:33:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 05:33:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0083 mins
[32m[0514 05:33:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:33:58 @base_main.py:47][0m 49245 total steps have happened
[32m[0514 05:33:58 @base_main.py:52][0m [avg_reward]: -1094.8508911076392
[32m[0514 05:33:58 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:58 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:58 @base_trainer.py:216][0m Mean reward: -1263.5725898693638
[32m[0514 05:33:59 @base_main.py:38][0m --------------- Iteration 50 ---------------
[32m[0514 05:33:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5680 mins
[32m[0514 05:33:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0514 05:33:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 05:33:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:59 @base_main.py:47][0m 50250 total steps have happened
[32m[0514 05:33:59 @base_main.py:52][0m [avg_reward]: -1263.5725898693638
[32m[0514 05:33:59 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:59 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:59 @base_trainer.py:216][0m Mean reward: -1283.722067974489
[32m[0514 05:34:00 @base_main.py:38][0m --------------- Iteration 51 ---------------
[32m[0514 05:34:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5794 mins
[32m[0514 05:34:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 05:34:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0084 mins
[32m[0514 05:34:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:00 @base_main.py:47][0m 51255 total steps have happened
[32m[0514 05:34:00 @base_main.py:52][0m [avg_reward]: -1283.722067974489
[32m[0514 05:34:00 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:00 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:00 @base_trainer.py:216][0m Mean reward: -991.9236845357424
[32m[0514 05:34:00 @base_main.py:38][0m --------------- Iteration 52 ---------------
[32m[0514 05:34:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5904 mins
[32m[0514 05:34:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 05:34:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 05:34:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:34:00 @base_main.py:47][0m 52260 total steps have happened
[32m[0514 05:34:00 @base_main.py:52][0m [avg_reward]: -991.9236845357424
[32m[0514 05:34:00 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:00 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:00 @base_trainer.py:216][0m Mean reward: -975.2733877834519
[32m[0514 05:34:01 @base_main.py:38][0m --------------- Iteration 53 ---------------
[32m[0514 05:34:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6021 mins
[32m[0514 05:34:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 05:34:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0514 05:34:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:01 @base_main.py:47][0m 53265 total steps have happened
[32m[0514 05:34:01 @base_main.py:52][0m [avg_reward]: -975.2733877834519
[32m[0514 05:34:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:01 @base_trainer.py:216][0m Mean reward: -1028.6726163767803
[32m[0514 05:34:02 @base_main.py:38][0m --------------- Iteration 54 ---------------
[32m[0514 05:34:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6135 mins
[32m[0514 05:34:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 05:34:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0514 05:34:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:02 @base_main.py:47][0m 54270 total steps have happened
[32m[0514 05:34:02 @base_main.py:52][0m [avg_reward]: -1028.6726163767803
[32m[0514 05:34:02 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:02 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:02 @base_trainer.py:216][0m Mean reward: -944.6173138099472
[32m[0514 05:34:02 @base_main.py:38][0m --------------- Iteration 55 ---------------
[32m[0514 05:34:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6248 mins
[32m[0514 05:34:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 05:34:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 05:34:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:02 @base_main.py:47][0m 55275 total steps have happened
[32m[0514 05:34:02 @base_main.py:52][0m [avg_reward]: -944.6173138099472
[32m[0514 05:34:02 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:02 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:02 @base_trainer.py:216][0m Mean reward: -1194.8289653568845
[32m[0514 05:34:03 @base_main.py:38][0m --------------- Iteration 56 ---------------
[32m[0514 05:34:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6362 mins
[32m[0514 05:34:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 05:34:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 05:34:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:03 @base_main.py:47][0m 56280 total steps have happened
[32m[0514 05:34:03 @base_main.py:52][0m [avg_reward]: -1194.8289653568845
[32m[0514 05:34:03 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:03 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:03 @base_trainer.py:216][0m Mean reward: -1324.6505337856051
[32m[0514 05:34:04 @base_main.py:38][0m --------------- Iteration 57 ---------------
[32m[0514 05:34:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6476 mins
[32m[0514 05:34:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 05:34:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0514 05:34:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:04 @base_main.py:47][0m 57285 total steps have happened
[32m[0514 05:34:04 @base_main.py:52][0m [avg_reward]: -1324.6505337856051
[32m[0514 05:34:04 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:04 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:04 @base_trainer.py:216][0m Mean reward: -1127.4919174144204
[32m[0514 05:34:04 @base_main.py:38][0m --------------- Iteration 58 ---------------
[32m[0514 05:34:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6587 mins
[32m[0514 05:34:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 05:34:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 05:34:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:04 @base_main.py:47][0m 58290 total steps have happened
[32m[0514 05:34:04 @base_main.py:52][0m [avg_reward]: -1127.4919174144204
[32m[0514 05:34:04 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:04 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:04 @base_trainer.py:216][0m Mean reward: -1180.624437769869
[32m[0514 05:34:05 @base_main.py:38][0m --------------- Iteration 59 ---------------
[32m[0514 05:34:05 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6701 mins
[32m[0514 05:34:05 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0514 05:34:05 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 05:34:05 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:05 @base_main.py:47][0m 59295 total steps have happened
[32m[0514 05:34:05 @base_main.py:52][0m [avg_reward]: -1180.624437769869
[32m[0514 05:34:05 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:05 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:05 @base_trainer.py:216][0m Mean reward: -1072.8276465759918
[32m[0514 05:34:06 @base_main.py:38][0m --------------- Iteration 60 ---------------
[32m[0514 05:34:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6815 mins
[32m[0514 05:34:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 05:34:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 05:34:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:06 @base_main.py:47][0m 60300 total steps have happened
[32m[0514 05:34:06 @base_main.py:52][0m [avg_reward]: -1072.8276465759918
[32m[0514 05:34:06 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:06 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:06 @base_trainer.py:216][0m Mean reward: -1103.7776877802448
[32m[0514 05:34:06 @base_main.py:38][0m --------------- Iteration 61 ---------------
[32m[0514 05:34:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6931 mins
[32m[0514 05:34:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 05:34:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0514 05:34:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:06 @base_main.py:47][0m 61305 total steps have happened
[32m[0514 05:34:06 @base_main.py:52][0m [avg_reward]: -1103.7776877802448
[32m[0514 05:34:07 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:07 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:07 @base_trainer.py:216][0m Mean reward: -897.6646657455
[32m[0514 05:34:07 @base_main.py:38][0m --------------- Iteration 62 ---------------
[32m[0514 05:34:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7052 mins
[32m[0514 05:34:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 05:34:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0514 05:34:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:07 @base_main.py:47][0m 62310 total steps have happened
[32m[0514 05:34:07 @base_main.py:52][0m [avg_reward]: -897.6646657455
[32m[0514 05:34:07 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:07 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:07 @base_trainer.py:216][0m Mean reward: -1196.1690721143675
[32m[0514 05:34:08 @base_main.py:38][0m --------------- Iteration 63 ---------------
[32m[0514 05:34:08 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7165 mins
[32m[0514 05:34:08 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 05:34:08 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 05:34:08 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:08 @base_main.py:47][0m 63315 total steps have happened
[32m[0514 05:34:08 @base_main.py:52][0m [avg_reward]: -1196.1690721143675
[32m[0514 05:34:08 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:08 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:08 @base_trainer.py:216][0m Mean reward: -1171.0723018612418
[32m[0514 05:34:09 @base_main.py:38][0m --------------- Iteration 64 ---------------
[32m[0514 05:34:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7279 mins
[32m[0514 05:34:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 05:34:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 05:34:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:09 @base_main.py:47][0m 64320 total steps have happened
[32m[0514 05:34:09 @base_main.py:52][0m [avg_reward]: -1171.0723018612418
[32m[0514 05:34:09 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:09 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:09 @base_trainer.py:216][0m Mean reward: -1201.2213770855326
[32m[0514 05:34:09 @base_main.py:38][0m --------------- Iteration 65 ---------------
[32m[0514 05:34:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7396 mins
[32m[0514 05:34:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0514 05:34:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0514 05:34:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:09 @base_main.py:47][0m 65325 total steps have happened
[32m[0514 05:34:09 @base_main.py:52][0m [avg_reward]: -1201.2213770855326
[32m[0514 05:34:09 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:09 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:09 @base_trainer.py:216][0m Mean reward: -1224.8881259490443
[32m[0514 05:34:10 @base_main.py:38][0m --------------- Iteration 66 ---------------
[32m[0514 05:34:10 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7505 mins
[32m[0514 05:34:10 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0514 05:34:10 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 05:34:10 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:10 @base_main.py:47][0m 66330 total steps have happened
[32m[0514 05:34:10 @base_main.py:52][0m [avg_reward]: -1224.8881259490443
[32m[0514 05:34:10 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:10 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:10 @base_trainer.py:216][0m Mean reward: -940.6008825204368
[32m[0514 05:34:11 @base_main.py:38][0m --------------- Iteration 67 ---------------
[32m[0514 05:34:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7618 mins
[32m[0514 05:34:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 05:34:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 05:34:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:34:11 @base_main.py:47][0m 67335 total steps have happened
[32m[0514 05:34:11 @base_main.py:52][0m [avg_reward]: -940.6008825204368
[32m[0514 05:34:11 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:11 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:11 @base_trainer.py:216][0m Mean reward: -1165.7825601666334
[32m[0514 05:34:11 @base_main.py:38][0m --------------- Iteration 68 ---------------
[32m[0514 05:34:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7734 mins
[32m[0514 05:34:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 05:34:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 05:34:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:11 @base_main.py:47][0m 68340 total steps have happened
[32m[0514 05:34:11 @base_main.py:52][0m [avg_reward]: -1165.7825601666334
[32m[0514 05:34:11 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:11 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:11 @base_trainer.py:216][0m Mean reward: -996.5421011950946
[32m[0514 05:34:12 @base_main.py:38][0m --------------- Iteration 69 ---------------
[32m[0514 05:34:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7853 mins
[32m[0514 05:34:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0514 05:34:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 05:34:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:12 @base_main.py:47][0m 69345 total steps have happened
[32m[0514 05:34:12 @base_main.py:52][0m [avg_reward]: -996.5421011950946
[32m[0514 05:34:12 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:12 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:12 @base_trainer.py:216][0m Mean reward: -1224.4658599489583
[32m[0514 05:34:13 @base_main.py:38][0m --------------- Iteration 70 ---------------
[32m[0514 05:34:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7968 mins
[32m[0514 05:34:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 05:34:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0514 05:34:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:13 @base_main.py:47][0m 70350 total steps have happened
[32m[0514 05:34:13 @base_main.py:52][0m [avg_reward]: -1224.4658599489583
[32m[0514 05:34:13 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:13 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:13 @base_trainer.py:216][0m Mean reward: -1009.6904877604309
[32m[0514 05:34:13 @base_main.py:38][0m --------------- Iteration 71 ---------------
[32m[0514 05:34:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8093 mins
[32m[0514 05:34:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0514 05:34:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0514 05:34:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:13 @base_main.py:47][0m 71355 total steps have happened
[32m[0514 05:34:13 @base_main.py:52][0m [avg_reward]: -1009.6904877604309
[32m[0514 05:34:14 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:14 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:14 @base_trainer.py:216][0m Mean reward: -1049.782455834094
[32m[0514 05:34:14 @base_main.py:38][0m --------------- Iteration 72 ---------------
[32m[0514 05:34:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8204 mins
[32m[0514 05:34:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 05:34:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0084 mins
[32m[0514 05:34:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:14 @base_main.py:47][0m 72360 total steps have happened
[32m[0514 05:34:14 @base_main.py:52][0m [avg_reward]: -1049.782455834094
[32m[0514 05:34:14 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:14 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:14 @base_trainer.py:216][0m Mean reward: -1045.6028070142445
[32m[0514 05:34:15 @base_main.py:38][0m --------------- Iteration 73 ---------------
[32m[0514 05:34:15 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8313 mins
[32m[0514 05:34:15 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 05:34:15 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0084 mins
[32m[0514 05:34:15 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:15 @base_main.py:47][0m 73365 total steps have happened
[32m[0514 05:34:15 @base_main.py:52][0m [avg_reward]: -1045.6028070142445
[32m[0514 05:34:15 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:15 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:15 @base_trainer.py:216][0m Mean reward: -895.4677787671162
[32m[0514 05:34:15 @base_main.py:38][0m --------------- Iteration 74 ---------------
[32m[0514 05:34:15 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8425 mins
[32m[0514 05:34:15 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 05:34:15 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 05:34:15 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:15 @base_main.py:47][0m 74370 total steps have happened
[32m[0514 05:34:15 @base_main.py:52][0m [avg_reward]: -895.4677787671162
[32m[0514 05:34:16 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:16 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:16 @base_trainer.py:216][0m Mean reward: -1071.330016934971
[32m[0514 05:34:16 @base_main.py:38][0m --------------- Iteration 75 ---------------
[32m[0514 05:34:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8541 mins
[32m[0514 05:34:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 05:34:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 05:34:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:16 @base_main.py:47][0m 75375 total steps have happened
[32m[0514 05:34:16 @base_main.py:52][0m [avg_reward]: -1071.330016934971
[32m[0514 05:34:16 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:16 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:16 @base_trainer.py:216][0m Mean reward: -1113.1508960822648
[32m[0514 05:34:17 @base_main.py:38][0m --------------- Iteration 76 ---------------
[32m[0514 05:34:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8657 mins
[32m[0514 05:34:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 05:34:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 05:34:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:17 @base_main.py:47][0m 76380 total steps have happened
[32m[0514 05:34:17 @base_main.py:52][0m [avg_reward]: -1113.1508960822648
[32m[0514 05:34:17 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:17 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:17 @base_trainer.py:216][0m Mean reward: -1077.3989673634637
[32m[0514 05:34:18 @base_main.py:38][0m --------------- Iteration 77 ---------------
[32m[0514 05:34:18 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8774 mins
[32m[0514 05:34:18 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 05:34:18 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0514 05:34:18 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:18 @base_main.py:47][0m 77385 total steps have happened
[32m[0514 05:34:18 @base_main.py:52][0m [avg_reward]: -1077.3989673634637
[32m[0514 05:34:18 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:18 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:18 @base_trainer.py:216][0m Mean reward: -1066.942053678596
[32m[0514 05:34:18 @base_main.py:38][0m --------------- Iteration 78 ---------------
[32m[0514 05:34:18 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8895 mins
[32m[0514 05:34:18 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 05:34:18 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 05:34:18 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:18 @base_main.py:47][0m 78390 total steps have happened
[32m[0514 05:34:18 @base_main.py:52][0m [avg_reward]: -1066.942053678596
[32m[0514 05:34:18 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:18 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:18 @base_trainer.py:216][0m Mean reward: -1065.9621987025153
[32m[0514 05:34:19 @base_main.py:38][0m --------------- Iteration 79 ---------------
[32m[0514 05:34:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9010 mins
[32m[0514 05:34:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 05:34:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 05:34:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:19 @base_main.py:47][0m 79395 total steps have happened
[32m[0514 05:34:19 @base_main.py:52][0m [avg_reward]: -1065.9621987025153
[32m[0514 05:34:19 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:19 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:19 @base_trainer.py:216][0m Mean reward: -1099.9526403593286
[32m[0514 05:34:20 @base_main.py:38][0m --------------- Iteration 80 ---------------
[32m[0514 05:34:20 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9128 mins
[32m[0514 05:34:20 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 05:34:20 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 05:34:20 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:20 @base_main.py:47][0m 80400 total steps have happened
[32m[0514 05:34:20 @base_main.py:52][0m [avg_reward]: -1099.9526403593286
[32m[0514 05:34:20 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:20 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:20 @base_trainer.py:216][0m Mean reward: -1017.3218160977046
[32m[0514 05:34:20 @base_main.py:38][0m --------------- Iteration 81 ---------------
[32m[0514 05:34:20 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9244 mins
[32m[0514 05:34:20 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 05:34:20 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 05:34:20 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:20 @base_main.py:47][0m 81405 total steps have happened
[32m[0514 05:34:20 @base_main.py:52][0m [avg_reward]: -1017.3218160977046
[32m[0514 05:34:20 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:20 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:20 @base_trainer.py:216][0m Mean reward: -1160.4286392490308
[32m[0514 05:34:21 @base_main.py:38][0m --------------- Iteration 82 ---------------
[32m[0514 05:34:21 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9358 mins
[32m[0514 05:34:21 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 05:34:21 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0514 05:34:21 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:21 @base_main.py:47][0m 82410 total steps have happened
[32m[0514 05:34:21 @base_main.py:52][0m [avg_reward]: -1160.4286392490308
[32m[0514 05:34:21 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:21 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:21 @base_trainer.py:216][0m Mean reward: -1037.7331791101135
[32m[0514 05:34:22 @base_main.py:38][0m --------------- Iteration 83 ---------------
[32m[0514 05:34:22 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9469 mins
[32m[0514 05:34:22 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 05:34:22 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 05:34:22 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:22 @base_main.py:47][0m 83415 total steps have happened
[32m[0514 05:34:22 @base_main.py:52][0m [avg_reward]: -1037.7331791101135
[32m[0514 05:34:22 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:22 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:22 @base_trainer.py:216][0m Mean reward: -1169.5116556878029
[32m[0514 05:34:22 @base_main.py:38][0m --------------- Iteration 84 ---------------
[32m[0514 05:34:22 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9585 mins
[32m[0514 05:34:22 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 05:34:22 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0514 05:34:22 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:22 @base_main.py:47][0m 84420 total steps have happened
[32m[0514 05:34:22 @base_main.py:52][0m [avg_reward]: -1169.5116556878029
[32m[0514 05:34:22 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:22 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:22 @base_trainer.py:216][0m Mean reward: -1042.289749311878
[32m[0514 05:34:23 @base_main.py:38][0m --------------- Iteration 85 ---------------
[32m[0514 05:34:23 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9700 mins
[32m[0514 05:34:23 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0514 05:34:23 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 05:34:23 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:23 @base_main.py:47][0m 85425 total steps have happened
[32m[0514 05:34:23 @base_main.py:52][0m [avg_reward]: -1042.289749311878
[32m[0514 05:34:23 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:23 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:23 @base_trainer.py:216][0m Mean reward: -1088.995420353486
[32m[0514 05:34:24 @base_main.py:38][0m --------------- Iteration 86 ---------------
[32m[0514 05:34:24 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9813 mins
[32m[0514 05:34:24 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 05:34:24 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0514 05:34:24 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:24 @base_main.py:47][0m 86430 total steps have happened
[32m[0514 05:34:24 @base_main.py:52][0m [avg_reward]: -1088.995420353486
[32m[0514 05:34:24 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:24 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:24 @base_trainer.py:216][0m Mean reward: -856.837373152251
[32m[0514 05:34:24 @base_main.py:38][0m --------------- Iteration 87 ---------------
[32m[0514 05:34:24 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9924 mins
[32m[0514 05:34:24 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 05:34:24 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 05:34:24 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:24 @base_main.py:47][0m 87435 total steps have happened
[32m[0514 05:34:24 @base_main.py:52][0m [avg_reward]: -856.837373152251
[32m[0514 05:34:25 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:25 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:25 @base_trainer.py:216][0m Mean reward: -1035.856661383372
[32m[0514 05:34:25 @base_main.py:38][0m --------------- Iteration 88 ---------------
[32m[0514 05:34:25 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0039 mins
[32m[0514 05:34:25 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 05:34:25 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 05:34:25 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:25 @base_main.py:47][0m 88440 total steps have happened
[32m[0514 05:34:25 @base_main.py:52][0m [avg_reward]: -1035.856661383372
[32m[0514 05:34:25 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:25 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:25 @base_trainer.py:216][0m Mean reward: -920.8420863392901
[32m[0514 05:34:26 @base_main.py:38][0m --------------- Iteration 89 ---------------
[32m[0514 05:34:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0152 mins
[32m[0514 05:34:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0514 05:34:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 05:34:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:26 @base_main.py:47][0m 89445 total steps have happened
[32m[0514 05:34:26 @base_main.py:52][0m [avg_reward]: -920.8420863392901
[32m[0514 05:34:26 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:26 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:26 @base_trainer.py:216][0m Mean reward: -1034.053039903413
[32m[0514 05:34:26 @base_main.py:38][0m --------------- Iteration 90 ---------------
[32m[0514 05:34:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0266 mins
[32m[0514 05:34:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0514 05:34:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 05:34:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:26 @base_main.py:47][0m 90450 total steps have happened
[32m[0514 05:34:26 @base_main.py:52][0m [avg_reward]: -1034.053039903413
[32m[0514 05:34:27 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:27 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:27 @base_trainer.py:216][0m Mean reward: -1103.59778620484
[32m[0514 05:34:27 @base_main.py:38][0m --------------- Iteration 91 ---------------
[32m[0514 05:34:27 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0380 mins
[32m[0514 05:34:27 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0514 05:34:27 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0514 05:34:27 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:27 @base_main.py:47][0m 91455 total steps have happened
[32m[0514 05:34:27 @base_main.py:52][0m [avg_reward]: -1103.59778620484
[32m[0514 05:34:27 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:27 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:27 @base_trainer.py:216][0m Mean reward: -1040.0083603866046
[32m[0514 05:34:28 @base_main.py:38][0m --------------- Iteration 92 ---------------
[32m[0514 05:34:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0500 mins
[32m[0514 05:34:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 05:34:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0514 05:34:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:28 @base_main.py:47][0m 92460 total steps have happened
[32m[0514 05:34:28 @base_main.py:52][0m [avg_reward]: -1040.0083603866046
[32m[0514 05:34:28 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:28 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:28 @base_trainer.py:216][0m Mean reward: -1082.698462304198
[32m[0514 05:34:29 @base_main.py:38][0m --------------- Iteration 93 ---------------
[32m[0514 05:34:29 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0620 mins
[32m[0514 05:34:29 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 05:34:29 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 05:34:29 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:29 @base_main.py:47][0m 93465 total steps have happened
[32m[0514 05:34:29 @base_main.py:52][0m [avg_reward]: -1082.698462304198
[32m[0514 05:34:29 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:29 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:29 @base_trainer.py:216][0m Mean reward: -1085.5937241686388
[32m[0514 05:34:29 @base_main.py:38][0m --------------- Iteration 94 ---------------
[32m[0514 05:34:29 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0733 mins
[32m[0514 05:34:29 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 05:34:29 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 05:34:29 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:29 @base_main.py:47][0m 94470 total steps have happened
[32m[0514 05:34:29 @base_main.py:52][0m [avg_reward]: -1085.5937241686388
[32m[0514 05:34:29 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:29 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:29 @base_trainer.py:216][0m Mean reward: -1068.1044571193877
[32m[0514 05:34:30 @base_main.py:38][0m --------------- Iteration 95 ---------------
[32m[0514 05:34:30 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0849 mins
[32m[0514 05:34:30 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 05:34:30 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0514 05:34:30 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:30 @base_main.py:47][0m 95475 total steps have happened
[32m[0514 05:34:30 @base_main.py:52][0m [avg_reward]: -1068.1044571193877
[32m[0514 05:34:30 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:30 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:30 @base_trainer.py:216][0m Mean reward: -1146.5147928120225
[32m[0514 05:34:31 @base_main.py:38][0m --------------- Iteration 96 ---------------
[32m[0514 05:34:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0960 mins
[32m[0514 05:34:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 05:34:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0514 05:34:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:31 @base_main.py:47][0m 96480 total steps have happened
[32m[0514 05:34:31 @base_main.py:52][0m [avg_reward]: -1146.5147928120225
[32m[0514 05:34:31 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:31 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:31 @base_trainer.py:216][0m Mean reward: -1054.5337977855474
[32m[0514 05:34:31 @base_main.py:38][0m --------------- Iteration 97 ---------------
[32m[0514 05:34:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1072 mins
[32m[0514 05:34:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 05:34:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0514 05:34:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:31 @base_main.py:47][0m 97485 total steps have happened
[32m[0514 05:34:31 @base_main.py:52][0m [avg_reward]: -1054.5337977855474
[32m[0514 05:34:31 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:31 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:31 @base_trainer.py:216][0m Mean reward: -1306.1372072340034
[32m[0514 05:34:32 @base_main.py:38][0m --------------- Iteration 98 ---------------
[32m[0514 05:34:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1183 mins
[32m[0514 05:34:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0514 05:34:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 05:34:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:32 @base_main.py:47][0m 98490 total steps have happened
[32m[0514 05:34:32 @base_main.py:52][0m [avg_reward]: -1306.1372072340034
[32m[0514 05:34:32 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:32 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:32 @base_trainer.py:216][0m Mean reward: -1180.8577701079917
[32m[0514 05:34:33 @base_main.py:38][0m --------------- Iteration 99 ---------------
[32m[0514 05:34:33 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1296 mins
[32m[0514 05:34:33 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 05:34:33 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 05:34:33 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:33 @base_main.py:47][0m 99495 total steps have happened
[32m[0514 05:34:33 @base_main.py:52][0m [avg_reward]: -1180.8577701079917
[32m[0514 05:34:33 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:33 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:33 @base_trainer.py:216][0m Mean reward: -1077.825902927827
[32m[0514 05:34:33 @base_main.py:38][0m --------------- Iteration 100 ---------------
[32m[0514 05:34:33 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1413 mins
[32m[0514 05:34:33 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 05:34:33 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 05:34:33 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:33 @base_main.py:47][0m 100500 total steps have happened
[32m[0514 05:34:33 @base_main.py:52][0m [avg_reward]: -1077.825902927827
[32m[0514 05:34:33 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:33 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:33 @base_trainer.py:216][0m Mean reward: -1031.7595256294037
[32m[0514 05:34:34 @base_main.py:38][0m --------------- Iteration 101 ---------------
[32m[0514 05:34:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1528 mins
[32m[0514 05:34:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 05:34:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 05:34:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:34 @base_main.py:47][0m 101505 total steps have happened
[32m[0514 05:34:34 @base_main.py:52][0m [avg_reward]: -1031.7595256294037
[32m[0514 05:34:34 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:34 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:34 @base_trainer.py:216][0m Mean reward: -1146.0556867600149
[32m[0514 05:34:35 @base_main.py:38][0m --------------- Iteration 102 ---------------
[32m[0514 05:34:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1643 mins
[32m[0514 05:34:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 05:34:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0514 05:34:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:35 @base_main.py:47][0m 102510 total steps have happened
[32m[0514 05:34:35 @base_main.py:52][0m [avg_reward]: -1146.0556867600149
[32m[0514 05:34:35 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:35 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:35 @base_trainer.py:216][0m Mean reward: -1154.6664675623847
[32m[0514 05:34:35 @base_main.py:38][0m --------------- Iteration 103 ---------------
[32m[0514 05:34:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1754 mins
[32m[0514 05:34:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 05:34:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 05:34:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:35 @base_main.py:47][0m 103515 total steps have happened
[32m[0514 05:34:35 @base_main.py:52][0m [avg_reward]: -1154.6664675623847
[32m[0514 05:34:36 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:36 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:36 @base_trainer.py:216][0m Mean reward: -1128.2100097991395
[32m[0514 05:34:36 @base_main.py:38][0m --------------- Iteration 104 ---------------
[32m[0514 05:34:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1872 mins
[32m[0514 05:34:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 05:34:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 05:34:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:36 @base_main.py:47][0m 104520 total steps have happened
[32m[0514 05:34:36 @base_main.py:52][0m [avg_reward]: -1128.2100097991395
[32m[0514 05:34:36 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:36 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:36 @base_trainer.py:216][0m Mean reward: -1301.4888838056972
[32m[0514 05:34:37 @base_main.py:38][0m --------------- Iteration 105 ---------------
[32m[0514 05:34:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1988 mins
[32m[0514 05:34:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 05:34:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 05:34:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:37 @base_main.py:47][0m 105525 total steps have happened
[32m[0514 05:34:37 @base_main.py:52][0m [avg_reward]: -1301.4888838056972
[32m[0514 05:34:37 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:37 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:37 @base_trainer.py:216][0m Mean reward: -1208.6521080665414
[32m[0514 05:34:37 @base_main.py:38][0m --------------- Iteration 106 ---------------
[32m[0514 05:34:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2103 mins
[32m[0514 05:34:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 05:34:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0514 05:34:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:37 @base_main.py:47][0m 106530 total steps have happened
[32m[0514 05:34:37 @base_main.py:52][0m [avg_reward]: -1208.6521080665414
[32m[0514 05:34:38 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:38 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:38 @base_trainer.py:216][0m Mean reward: -1132.7116331819684
[32m[0514 05:34:38 @base_main.py:38][0m --------------- Iteration 107 ---------------
[32m[0514 05:34:38 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2215 mins
[32m[0514 05:34:38 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 05:34:38 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 05:34:38 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:38 @base_main.py:47][0m 107535 total steps have happened
[32m[0514 05:34:38 @base_main.py:52][0m [avg_reward]: -1132.7116331819684
[32m[0514 05:34:38 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:38 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:38 @base_trainer.py:216][0m Mean reward: -1037.4686722897
[32m[0514 05:34:39 @base_main.py:38][0m --------------- Iteration 108 ---------------
[32m[0514 05:34:39 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2333 mins
[32m[0514 05:34:39 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 05:34:39 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 05:34:39 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:39 @base_main.py:47][0m 108540 total steps have happened
[32m[0514 05:34:39 @base_main.py:52][0m [avg_reward]: -1037.4686722897
[32m[0514 05:34:39 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:39 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:39 @base_trainer.py:216][0m Mean reward: -1273.5371881054482
[32m[0514 05:34:40 @base_main.py:38][0m --------------- Iteration 109 ---------------
[32m[0514 05:34:40 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2447 mins
[32m[0514 05:34:40 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 05:34:40 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 05:34:40 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:40 @base_main.py:47][0m 109545 total steps have happened
[32m[0514 05:34:40 @base_main.py:52][0m [avg_reward]: -1273.5371881054482
[32m[0514 05:34:40 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:40 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:40 @base_trainer.py:216][0m Mean reward: -1113.2903812531354
[32m[0514 05:34:40 @base_main.py:38][0m --------------- Iteration 110 ---------------
[32m[0514 05:34:40 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2564 mins
[32m[0514 05:34:40 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0514 05:34:40 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 05:34:40 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:40 @base_main.py:47][0m 110550 total steps have happened
[32m[0514 05:34:40 @base_main.py:52][0m [avg_reward]: -1113.2903812531354
[32m[0514 05:34:40 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:40 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:40 @base_trainer.py:216][0m Mean reward: -1196.518142060852
[32m[0514 05:34:41 @base_main.py:38][0m --------------- Iteration 111 ---------------
[32m[0514 05:34:41 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2676 mins
[32m[0514 05:34:41 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0514 05:34:41 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 05:34:41 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:34:41 @base_main.py:47][0m 111555 total steps have happened
[32m[0514 05:34:41 @base_main.py:52][0m [avg_reward]: -1196.518142060852
[32m[0514 05:34:41 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:41 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:41 @base_trainer.py:216][0m Mean reward: -1124.6320492096877
[32m[0514 05:34:42 @base_main.py:38][0m --------------- Iteration 112 ---------------
[32m[0514 05:34:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2792 mins
[32m[0514 05:34:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 05:34:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 05:34:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:42 @base_main.py:47][0m 112560 total steps have happened
[32m[0514 05:34:42 @base_main.py:52][0m [avg_reward]: -1124.6320492096877
[32m[0514 05:34:42 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:42 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:42 @base_trainer.py:216][0m Mean reward: -1115.8043297342224
[32m[0514 05:34:42 @base_main.py:38][0m --------------- Iteration 113 ---------------
[32m[0514 05:34:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2906 mins
[32m[0514 05:34:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 05:34:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 05:34:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:42 @base_main.py:47][0m 113565 total steps have happened
[32m[0514 05:34:42 @base_main.py:52][0m [avg_reward]: -1115.8043297342224
[32m[0514 05:34:42 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:42 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:42 @base_trainer.py:216][0m Mean reward: -1251.6112267611352
[32m[0514 05:34:43 @base_main.py:38][0m --------------- Iteration 114 ---------------
[32m[0514 05:34:43 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3021 mins
[32m[0514 05:34:43 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 05:34:43 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 05:34:43 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:43 @base_main.py:47][0m 114570 total steps have happened
[32m[0514 05:34:43 @base_main.py:52][0m [avg_reward]: -1251.6112267611352
[32m[0514 05:34:43 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:43 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:43 @base_trainer.py:216][0m Mean reward: -1070.526272002558
[32m[0514 05:34:44 @base_main.py:38][0m --------------- Iteration 115 ---------------
[32m[0514 05:34:44 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3134 mins
[32m[0514 05:34:44 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 05:34:44 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 05:34:44 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:44 @base_main.py:47][0m 115575 total steps have happened
[32m[0514 05:34:44 @base_main.py:52][0m [avg_reward]: -1070.526272002558
[32m[0514 05:34:44 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:44 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:44 @base_trainer.py:216][0m Mean reward: -1136.1017745742352
[32m[0514 05:34:44 @base_main.py:38][0m --------------- Iteration 116 ---------------
[32m[0514 05:34:44 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3250 mins
[32m[0514 05:34:44 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 05:34:44 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0083 mins
[32m[0514 05:34:44 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:44 @base_main.py:47][0m 116580 total steps have happened
[32m[0514 05:34:44 @base_main.py:52][0m [avg_reward]: -1136.1017745742352
[32m[0514 05:34:44 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:44 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:44 @base_trainer.py:216][0m Mean reward: -1329.7292089629277
[32m[0514 05:34:45 @base_main.py:38][0m --------------- Iteration 117 ---------------
[32m[0514 05:34:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3361 mins
[32m[0514 05:34:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 05:34:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0084 mins
[32m[0514 05:34:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:45 @base_main.py:47][0m 117585 total steps have happened
[32m[0514 05:34:45 @base_main.py:52][0m [avg_reward]: -1329.7292089629277
[32m[0514 05:34:45 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:45 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:45 @base_trainer.py:216][0m Mean reward: -939.4136168668425
[32m[0514 05:34:46 @base_main.py:38][0m --------------- Iteration 118 ---------------
[32m[0514 05:34:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3473 mins
[32m[0514 05:34:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 05:34:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 05:34:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:46 @base_main.py:47][0m 118590 total steps have happened
[32m[0514 05:34:46 @base_main.py:52][0m [avg_reward]: -939.4136168668425
[32m[0514 05:34:46 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:46 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:46 @base_trainer.py:216][0m Mean reward: -1023.2313530573314
[32m[0514 05:34:46 @base_main.py:38][0m --------------- Iteration 119 ---------------
[32m[0514 05:34:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3591 mins
[32m[0514 05:34:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 05:34:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0083 mins
[32m[0514 05:34:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:46 @base_main.py:47][0m 119595 total steps have happened
[32m[0514 05:34:46 @base_main.py:52][0m [avg_reward]: -1023.2313530573314
[32m[0514 05:34:46 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:46 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:46 @base_trainer.py:216][0m Mean reward: -827.4857091649935
[32m[0514 05:34:47 @base_main.py:38][0m --------------- Iteration 120 ---------------
[32m[0514 05:34:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3702 mins
[32m[0514 05:34:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 05:34:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 05:34:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:47 @base_main.py:47][0m 120600 total steps have happened
[32m[0514 05:34:47 @base_main.py:52][0m [avg_reward]: -827.4857091649935
[32m[0514 05:34:47 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:47 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:47 @base_trainer.py:216][0m Mean reward: -1179.4580073340499
[32m[0514 05:34:48 @base_main.py:38][0m --------------- Iteration 121 ---------------
[32m[0514 05:34:48 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3815 mins
[32m[0514 05:34:48 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 05:34:48 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0082 mins
[32m[0514 05:34:48 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:48 @base_main.py:47][0m 121605 total steps have happened
[32m[0514 05:34:48 @base_main.py:52][0m [avg_reward]: -1179.4580073340499
[32m[0514 05:34:48 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:48 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:48 @base_trainer.py:216][0m Mean reward: -866.3551991591142
[32m[0514 05:34:48 @base_main.py:38][0m --------------- Iteration 122 ---------------
[32m[0514 05:34:48 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3923 mins
[32m[0514 05:34:48 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 05:34:48 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0514 05:34:48 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:48 @base_main.py:47][0m 122610 total steps have happened
[32m[0514 05:34:48 @base_main.py:52][0m [avg_reward]: -866.3551991591142
[32m[0514 05:34:49 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:49 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:49 @base_trainer.py:216][0m Mean reward: -1238.5005980657015
[32m[0514 05:34:49 @base_main.py:38][0m --------------- Iteration 123 ---------------
[32m[0514 05:34:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4038 mins
[32m[0514 05:34:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 05:34:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 05:34:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:49 @base_main.py:47][0m 123615 total steps have happened
[32m[0514 05:34:49 @base_main.py:52][0m [avg_reward]: -1238.5005980657015
[32m[0514 05:34:49 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:49 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:49 @base_trainer.py:216][0m Mean reward: -930.7351960812754
[32m[0514 05:34:50 @base_main.py:38][0m --------------- Iteration 124 ---------------
[32m[0514 05:34:50 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4156 mins
[32m[0514 05:34:50 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 05:34:50 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 05:34:50 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:50 @base_main.py:47][0m 124620 total steps have happened
[32m[0514 05:34:50 @base_main.py:52][0m [avg_reward]: -930.7351960812754
[32m[0514 05:34:50 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:50 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:50 @base_trainer.py:216][0m Mean reward: -987.7093630984516
[32m[0514 05:34:50 @base_main.py:38][0m --------------- Iteration 125 ---------------
[32m[0514 05:34:50 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4271 mins
[32m[0514 05:34:50 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 05:34:50 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 05:34:50 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:50 @base_main.py:47][0m 125625 total steps have happened
[32m[0514 05:34:50 @base_main.py:52][0m [avg_reward]: -987.7093630984516
[32m[0514 05:34:51 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:51 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:51 @base_trainer.py:216][0m Mean reward: -1311.4531309695026
[32m[0514 05:34:51 @base_main.py:38][0m --------------- Iteration 126 ---------------
[32m[0514 05:34:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4384 mins
[32m[0514 05:34:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 05:34:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0084 mins
[32m[0514 05:34:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:51 @base_main.py:47][0m 126630 total steps have happened
[32m[0514 05:34:51 @base_main.py:52][0m [avg_reward]: -1311.4531309695026
[32m[0514 05:34:51 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:51 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:51 @base_trainer.py:216][0m Mean reward: -1113.67415139364
[32m[0514 05:34:52 @base_main.py:38][0m --------------- Iteration 127 ---------------
[32m[0514 05:34:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4494 mins
[32m[0514 05:34:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 05:34:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 05:34:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:52 @base_main.py:47][0m 127635 total steps have happened
[32m[0514 05:34:52 @base_main.py:52][0m [avg_reward]: -1113.67415139364
[32m[0514 05:34:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:52 @base_trainer.py:216][0m Mean reward: -1221.4344799006108
[32m[0514 05:34:53 @base_main.py:38][0m --------------- Iteration 128 ---------------
[32m[0514 05:34:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4612 mins
[32m[0514 05:34:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 05:34:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0514 05:34:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:53 @base_main.py:47][0m 128640 total steps have happened
[32m[0514 05:34:53 @base_main.py:52][0m [avg_reward]: -1221.4344799006108
[32m[0514 05:34:53 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:53 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:53 @base_trainer.py:216][0m Mean reward: -895.6497417468563
[32m[0514 05:34:53 @base_main.py:38][0m --------------- Iteration 129 ---------------
[32m[0514 05:34:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4733 mins
[32m[0514 05:34:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 05:34:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0514 05:34:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:53 @base_main.py:47][0m 129645 total steps have happened
[32m[0514 05:34:53 @base_main.py:52][0m [avg_reward]: -895.6497417468563
[32m[0514 05:34:53 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:53 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:53 @base_trainer.py:216][0m Mean reward: -1088.9656746923592
[32m[0514 05:34:54 @base_main.py:38][0m --------------- Iteration 130 ---------------
[32m[0514 05:34:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4846 mins
[32m[0514 05:34:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 05:34:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 05:34:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:54 @base_main.py:47][0m 130650 total steps have happened
[32m[0514 05:34:54 @base_main.py:52][0m [avg_reward]: -1088.9656746923592
[32m[0514 05:34:54 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:54 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:54 @base_trainer.py:216][0m Mean reward: -925.5151911425708
[32m[0514 05:34:55 @base_main.py:38][0m --------------- Iteration 131 ---------------
[32m[0514 05:34:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4959 mins
[32m[0514 05:34:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 05:34:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 05:34:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:55 @base_main.py:47][0m 131655 total steps have happened
[32m[0514 05:34:55 @base_main.py:52][0m [avg_reward]: -925.5151911425708
[32m[0514 05:34:55 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:55 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:55 @base_trainer.py:216][0m Mean reward: -1305.9377478741776
[32m[0514 05:34:55 @base_main.py:38][0m --------------- Iteration 132 ---------------
[32m[0514 05:34:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5072 mins
[32m[0514 05:34:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 05:34:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 05:34:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:55 @base_main.py:47][0m 132660 total steps have happened
[32m[0514 05:34:55 @base_main.py:52][0m [avg_reward]: -1305.9377478741776
[32m[0514 05:34:55 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:55 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:55 @base_trainer.py:216][0m Mean reward: -1263.851035878932
[32m[0514 05:34:56 @base_main.py:38][0m --------------- Iteration 133 ---------------
[32m[0514 05:34:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5189 mins
[32m[0514 05:34:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0514 05:34:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 05:34:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:34:56 @base_main.py:47][0m 133665 total steps have happened
[32m[0514 05:34:56 @base_main.py:52][0m [avg_reward]: -1263.851035878932
[32m[0514 05:34:56 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:56 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:56 @base_trainer.py:216][0m Mean reward: -1076.1383387619164
[32m[0514 05:34:57 @base_main.py:38][0m --------------- Iteration 134 ---------------
[32m[0514 05:34:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5304 mins
[32m[0514 05:34:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 05:34:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 05:34:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:57 @base_main.py:47][0m 134670 total steps have happened
[32m[0514 05:34:57 @base_main.py:52][0m [avg_reward]: -1076.1383387619164
[32m[0514 05:34:57 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:57 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:57 @base_trainer.py:216][0m Mean reward: -1048.6743523665314
[32m[0514 05:34:57 @base_main.py:38][0m --------------- Iteration 135 ---------------
[32m[0514 05:34:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5418 mins
[32m[0514 05:34:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 05:34:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0514 05:34:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:57 @base_main.py:47][0m 135675 total steps have happened
[32m[0514 05:34:57 @base_main.py:52][0m [avg_reward]: -1048.6743523665314
[32m[0514 05:34:57 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:57 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:57 @base_trainer.py:216][0m Mean reward: -1010.0921015883496
[32m[0514 05:34:58 @base_main.py:38][0m --------------- Iteration 136 ---------------
[32m[0514 05:34:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5531 mins
[32m[0514 05:34:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 05:34:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 05:34:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:58 @base_main.py:47][0m 136680 total steps have happened
[32m[0514 05:34:58 @base_main.py:52][0m [avg_reward]: -1010.0921015883496
[32m[0514 05:34:58 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:58 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:58 @base_trainer.py:216][0m Mean reward: -981.1946931541727
[32m[0514 05:34:59 @base_main.py:38][0m --------------- Iteration 137 ---------------
[32m[0514 05:34:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5649 mins
[32m[0514 05:34:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 05:34:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 05:34:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:59 @base_main.py:47][0m 137685 total steps have happened
[32m[0514 05:34:59 @base_main.py:52][0m [avg_reward]: -981.1946931541727
[32m[0514 05:34:59 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:59 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:59 @base_trainer.py:216][0m Mean reward: -1015.2853603136558
[32m[0514 05:34:59 @base_main.py:38][0m --------------- Iteration 138 ---------------
[32m[0514 05:34:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5764 mins
[32m[0514 05:34:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 05:34:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 05:34:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:59 @base_main.py:47][0m 138690 total steps have happened
[32m[0514 05:34:59 @base_main.py:52][0m [avg_reward]: -1015.2853603136558
[32m[0514 05:35:00 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:00 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:00 @base_trainer.py:216][0m Mean reward: -1101.2301951182314
[32m[0514 05:35:00 @base_main.py:38][0m --------------- Iteration 139 ---------------
[32m[0514 05:35:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5884 mins
[32m[0514 05:35:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0514 05:35:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 05:35:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:35:00 @base_main.py:47][0m 139695 total steps have happened
[32m[0514 05:35:00 @base_main.py:52][0m [avg_reward]: -1101.2301951182314
[32m[0514 05:35:00 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:00 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:00 @base_trainer.py:216][0m Mean reward: -1105.7883835014873
[32m[0514 05:35:01 @base_main.py:38][0m --------------- Iteration 140 ---------------
[32m[0514 05:35:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5999 mins
[32m[0514 05:35:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 05:35:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 05:35:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:35:01 @base_main.py:47][0m 140700 total steps have happened
[32m[0514 05:35:01 @base_main.py:52][0m [avg_reward]: -1105.7883835014873
[32m[0514 05:35:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:01 @base_trainer.py:216][0m Mean reward: -1019.6088698701653
[32m[0514 05:35:02 @base_main.py:38][0m --------------- Iteration 141 ---------------
[32m[0514 05:35:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6115 mins
[32m[0514 05:35:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 05:35:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 05:35:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:35:02 @base_main.py:47][0m 141705 total steps have happened
[32m[0514 05:35:02 @base_main.py:52][0m [avg_reward]: -1019.6088698701653
[32m[0514 05:35:02 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:02 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:02 @base_trainer.py:216][0m Mean reward: -1001.8992215269722
[32m[0514 05:35:02 @base_main.py:38][0m --------------- Iteration 142 ---------------
[32m[0514 05:35:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6232 mins
[32m[0514 05:35:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 05:35:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 05:35:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:35:02 @base_main.py:47][0m 142710 total steps have happened
[32m[0514 05:35:02 @base_main.py:52][0m [avg_reward]: -1001.8992215269722
[32m[0514 05:35:02 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:02 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:02 @base_trainer.py:216][0m Mean reward: -926.771148081238
[32m[0514 05:35:03 @base_main.py:38][0m --------------- Iteration 143 ---------------
[32m[0514 05:35:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6349 mins
[32m[0514 05:35:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 05:35:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0514 05:35:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:35:03 @base_main.py:47][0m 143715 total steps have happened
[32m[0514 05:35:03 @base_main.py:52][0m [avg_reward]: -926.771148081238
[32m[0514 05:35:03 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:03 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:03 @base_trainer.py:216][0m Mean reward: -1000.6316054566571
[32m[0514 05:35:04 @base_main.py:38][0m --------------- Iteration 144 ---------------
[32m[0514 05:35:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6461 mins
[32m[0514 05:35:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0514 05:35:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 05:35:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:35:04 @base_main.py:47][0m 144720 total steps have happened
[32m[0514 05:35:04 @base_main.py:52][0m [avg_reward]: -1000.6316054566571
[32m[0514 05:35:04 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:04 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:04 @base_trainer.py:216][0m Mean reward: -1202.4737391081937
[32m[0514 05:35:04 @base_main.py:38][0m --------------- Iteration 145 ---------------
[32m[0514 05:35:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6575 mins
[32m[0514 05:35:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0514 05:35:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 05:35:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:35:04 @base_main.py:47][0m 145725 total steps have happened
[32m[0514 05:35:04 @base_main.py:52][0m [avg_reward]: -1202.4737391081937
[32m[0514 05:35:04 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:04 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:04 @base_trainer.py:216][0m Mean reward: -1166.278847500536
[32m[0514 05:35:05 @base_main.py:38][0m --------------- Iteration 146 ---------------
[32m[0514 05:35:05 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6691 mins
[32m[0514 05:35:05 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0514 05:35:05 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 05:35:05 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:35:05 @base_main.py:47][0m 146730 total steps have happened
[32m[0514 05:35:05 @base_main.py:52][0m [avg_reward]: -1166.278847500536
[32m[0514 05:35:05 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:05 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:05 @base_trainer.py:216][0m Mean reward: -857.8704923804682
[32m[0514 05:35:06 @base_main.py:38][0m --------------- Iteration 147 ---------------
[32m[0514 05:35:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6802 mins
[32m[0514 05:35:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0514 05:35:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0514 05:35:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:35:06 @base_main.py:47][0m 147735 total steps have happened
[32m[0514 05:35:06 @base_main.py:52][0m [avg_reward]: -857.8704923804682
[32m[0514 05:35:06 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:06 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:06 @base_trainer.py:216][0m Mean reward: -1150.1754089137823
[32m[0514 05:35:06 @base_main.py:38][0m --------------- Iteration 148 ---------------
[32m[0514 05:35:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6913 mins
[32m[0514 05:35:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0514 05:35:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0084 mins
[32m[0514 05:35:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:35:06 @base_main.py:47][0m 148740 total steps have happened
[32m[0514 05:35:06 @base_main.py:52][0m [avg_reward]: -1150.1754089137823
[32m[0514 05:35:06 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:06 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:06 @base_trainer.py:216][0m Mean reward: -971.3758268716123
[32m[0514 05:35:07 @base_main.py:38][0m --------------- Iteration 149 ---------------
[32m[0514 05:35:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7022 mins
[32m[0514 05:35:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0514 05:35:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 05:35:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:35:07 @base_main.py:47][0m 149745 total steps have happened
[32m[0514 05:35:07 @base_main.py:52][0m [avg_reward]: -971.3758268716123
[32m[0514 05:35:07 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:07 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:07 @base_trainer.py:216][0m Mean reward: -1222.9434447900287
[32m[0514 05:35:08 @base_main.py:38][0m --------------- Iteration 150 ---------------
[32m[0514 05:35:08 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7133 mins
[32m[0514 05:35:08 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0514 05:35:08 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0514 05:35:08 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:35:08 @base_main.py:47][0m 150750 total steps have happened
[32m[0514 05:35:08 @base_main.py:52][0m [avg_reward]: -1222.9434447900287
[32m[0514 05:35:08 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:08 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:08 @base_trainer.py:216][0m Mean reward: -1114.0969053637011
[32m[0514 05:35:08 @base_main.py:38][0m --------------- Iteration 151 ---------------
[32m[0514 05:35:08 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7242 mins
[32m[0514 05:35:08 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 05:35:08 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0514 05:35:08 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:35:08 @base_main.py:47][0m 151755 total steps have happened
[32m[0514 05:35:08 @base_main.py:52][0m [avg_reward]: -1114.0969053637011
[32m[0514 05:35:08 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:08 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:08 @base_trainer.py:216][0m Mean reward: -1102.7433909055358
[32m[0514 05:35:09 @base_main.py:38][0m --------------- Iteration 152 ---------------
[32m[0514 05:35:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7366 mins
[32m[0514 05:35:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0514 05:35:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0125 mins
[32m[0514 05:35:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:35:09 @base_main.py:47][0m 152760 total steps have happened
[32m[0514 05:35:09 @base_main.py:52][0m [avg_reward]: -1102.7433909055358
[32m[0514 05:35:10 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:10 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:10 @base_trainer.py:216][0m Mean reward: -1129.7533734884414
[32m[0514 05:35:10 @base_main.py:38][0m --------------- Iteration 153 ---------------
[32m[0514 05:35:10 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7516 mins
[32m[0514 05:35:10 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0046 mins
[32m[0514 05:35:10 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0136 mins
[32m[0514 05:35:10 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:35:10 @base_main.py:47][0m 153765 total steps have happened
[32m[0514 05:35:10 @base_main.py:52][0m [avg_reward]: -1129.7533734884414
[32m[0514 05:35:11 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:11 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:11 @base_trainer.py:216][0m Mean reward: -1001.5608246165597
[32m[0514 05:35:11 @base_main.py:38][0m --------------- Iteration 154 ---------------
[32m[0514 05:35:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7701 mins
[32m[0514 05:35:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0514 05:35:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0135 mins
[32m[0514 05:35:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:35:11 @base_main.py:47][0m 154770 total steps have happened
[32m[0514 05:35:11 @base_main.py:52][0m [avg_reward]: -1001.5608246165597
[32m[0514 05:35:12 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:12 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:12 @base_trainer.py:216][0m Mean reward: -907.3811480839101
[32m[0514 05:35:12 @base_main.py:38][0m --------------- Iteration 155 ---------------
[32m[0514 05:35:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7879 mins
[32m[0514 05:35:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0036 mins
[32m[0514 05:35:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0140 mins
[32m[0514 05:35:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:35:12 @base_main.py:47][0m 155775 total steps have happened
[32m[0514 05:35:12 @base_main.py:52][0m [avg_reward]: -907.3811480839101
[32m[0514 05:35:13 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:13 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:13 @base_trainer.py:216][0m Mean reward: -1206.0078923091494
[32m[0514 05:35:14 @base_main.py:38][0m --------------- Iteration 156 ---------------
[32m[0514 05:35:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8058 mins
[32m[0514 05:35:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0514 05:35:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0132 mins
[32m[0514 05:35:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:35:14 @base_main.py:47][0m 156780 total steps have happened
[32m[0514 05:35:14 @base_main.py:52][0m [avg_reward]: -1206.0078923091494
[32m[0514 05:35:14 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:14 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:14 @base_trainer.py:216][0m Mean reward: -1053.5794338573044
[32m[0514 05:35:15 @base_main.py:38][0m --------------- Iteration 157 ---------------
[32m[0514 05:35:15 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8234 mins
[32m[0514 05:35:15 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0045 mins
[32m[0514 05:35:15 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0131 mins
[32m[0514 05:35:15 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:35:15 @base_main.py:47][0m 157785 total steps have happened
[32m[0514 05:35:15 @base_main.py:52][0m [avg_reward]: -1053.5794338573044
[32m[0514 05:35:15 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:15 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:15 @base_trainer.py:216][0m Mean reward: -1079.849475794649
[32m[0514 05:35:16 @base_main.py:38][0m --------------- Iteration 158 ---------------
[32m[0514 05:35:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8413 mins
[32m[0514 05:35:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0514 05:35:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0141 mins
[32m[0514 05:35:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:35:16 @base_main.py:47][0m 158790 total steps have happened
[32m[0514 05:35:16 @base_main.py:52][0m [avg_reward]: -1079.849475794649
[32m[0514 05:35:16 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:16 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:16 @base_trainer.py:216][0m Mean reward: -1194.8047735091588
[32m[0514 05:35:17 @base_main.py:38][0m --------------- Iteration 159 ---------------
[32m[0514 05:35:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8597 mins
[32m[0514 05:35:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0049 mins
[32m[0514 05:35:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0136 mins
[32m[0514 05:35:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:35:17 @base_main.py:47][0m 159795 total steps have happened
[32m[0514 05:35:17 @base_main.py:52][0m [avg_reward]: -1194.8047735091588
[32m[0514 05:35:17 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:17 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:17 @base_trainer.py:216][0m Mean reward: -1103.726415455497
[32m[0514 05:35:18 @base_main.py:38][0m --------------- Iteration 160 ---------------
[32m[0514 05:35:18 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8783 mins
[32m[0514 05:35:18 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0046 mins
[32m[0514 05:35:18 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0138 mins
[32m[0514 05:35:18 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:35:18 @base_main.py:47][0m 160800 total steps have happened
[32m[0514 05:35:18 @base_main.py:52][0m [avg_reward]: -1103.726415455497
[32m[0514 05:35:18 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:18 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:18 @base_trainer.py:216][0m Mean reward: -1167.6680026116956
[32m[0514 05:35:19 @base_main.py:38][0m --------------- Iteration 161 ---------------
[32m[0514 05:35:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8968 mins
[32m[0514 05:35:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0044 mins
[32m[0514 05:35:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0137 mins
[32m[0514 05:35:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:35:19 @base_main.py:47][0m 161805 total steps have happened
[32m[0514 05:35:19 @base_main.py:52][0m [avg_reward]: -1167.6680026116956
[32m[0514 05:35:19 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:19 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:19 @base_trainer.py:216][0m Mean reward: -1016.9494221106088
[32m[0514 05:35:20 @base_main.py:38][0m --------------- Iteration 162 ---------------
[32m[0514 05:35:20 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9152 mins
[32m[0514 05:35:20 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0048 mins
[32m[0514 05:35:20 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0135 mins
[32m[0514 05:35:20 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:35:20 @base_main.py:47][0m 162810 total steps have happened
[32m[0514 05:35:20 @base_main.py:52][0m [avg_reward]: -1016.9494221106088
[32m[0514 05:35:20 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:20 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:20 @base_trainer.py:216][0m Mean reward: -1007.7022272582074
[32m[0514 05:35:21 @base_main.py:38][0m --------------- Iteration 163 ---------------
[32m[0514 05:35:21 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9336 mins
[32m[0514 05:35:21 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0046 mins
[32m[0514 05:35:21 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0136 mins
[32m[0514 05:35:21 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:35:21 @base_main.py:47][0m 163815 total steps have happened
[32m[0514 05:35:21 @base_main.py:52][0m [avg_reward]: -1007.7022272582074
[32m[0514 05:35:22 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:22 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:22 @base_trainer.py:216][0m Mean reward: -864.6086910943613
[32m[0514 05:35:22 @base_main.py:38][0m --------------- Iteration 164 ---------------
[32m[0514 05:35:22 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9519 mins
[32m[0514 05:35:22 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0045 mins
[32m[0514 05:35:22 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0129 mins
[32m[0514 05:35:22 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:35:22 @base_main.py:47][0m 164820 total steps have happened
[32m[0514 05:35:22 @base_main.py:52][0m [avg_reward]: -864.6086910943613
[32m[0514 05:35:23 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:23 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:23 @base_trainer.py:216][0m Mean reward: -859.9465690284029
[32m[0514 05:35:23 @base_main.py:38][0m --------------- Iteration 165 ---------------
[32m[0514 05:35:23 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9695 mins
[32m[0514 05:35:23 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0047 mins
[32m[0514 05:35:23 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0136 mins
[32m[0514 05:35:23 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:35:23 @base_main.py:47][0m 165825 total steps have happened
[32m[0514 05:35:23 @base_main.py:52][0m [avg_reward]: -859.9465690284029
[32m[0514 05:35:24 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:24 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:24 @base_trainer.py:216][0m Mean reward: -982.5634764021466
[32m[0514 05:35:25 @base_main.py:38][0m --------------- Iteration 166 ---------------
[32m[0514 05:35:25 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9881 mins
[32m[0514 05:35:25 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0048 mins
[32m[0514 05:35:25 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0143 mins
[32m[0514 05:35:25 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:35:25 @base_main.py:47][0m 166830 total steps have happened
[32m[0514 05:35:25 @base_main.py:52][0m [avg_reward]: -982.5634764021466
[32m[0514 05:35:25 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:25 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:25 @base_trainer.py:216][0m Mean reward: -958.4806265310539
[32m[0514 05:35:26 @base_main.py:38][0m --------------- Iteration 167 ---------------
[32m[0514 05:35:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0073 mins
[32m[0514 05:35:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0050 mins
[32m[0514 05:35:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0136 mins
[32m[0514 05:35:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:35:26 @base_main.py:47][0m 167835 total steps have happened
[32m[0514 05:35:26 @base_main.py:52][0m [avg_reward]: -958.4806265310539
[32m[0514 05:35:26 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:26 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:26 @base_trainer.py:216][0m Mean reward: -1161.2307718636982
[32m[0514 05:35:27 @base_main.py:38][0m --------------- Iteration 168 ---------------
[32m[0514 05:35:27 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0261 mins
[32m[0514 05:35:27 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0049 mins
[32m[0514 05:35:27 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0153 mins
[32m[0514 05:35:27 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:35:27 @base_main.py:47][0m 168840 total steps have happened
[32m[0514 05:35:27 @base_main.py:52][0m [avg_reward]: -1161.2307718636982
[32m[0514 05:35:27 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:27 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:27 @base_trainer.py:216][0m Mean reward: -1066.7557785048284
[32m[0514 05:35:28 @base_main.py:38][0m --------------- Iteration 169 ---------------
[32m[0514 05:35:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0465 mins
[32m[0514 05:35:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0045 mins
[32m[0514 05:35:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0135 mins
[32m[0514 05:35:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:35:28 @base_main.py:47][0m 169845 total steps have happened
[32m[0514 05:35:28 @base_main.py:52][0m [avg_reward]: -1066.7557785048284
[32m[0514 05:35:28 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:28 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:28 @base_trainer.py:216][0m Mean reward: -854.566890407863
[32m[0514 05:35:29 @base_main.py:38][0m --------------- Iteration 170 ---------------
[32m[0514 05:35:29 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0650 mins
[32m[0514 05:35:29 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0047 mins
[32m[0514 05:35:29 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0129 mins
[32m[0514 05:35:29 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 05:35:29 @base_main.py:47][0m 170850 total steps have happened
[32m[0514 05:35:29 @base_main.py:52][0m [avg_reward]: -854.566890407863
[32m[0514 05:35:29 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:29 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:29 @base_trainer.py:216][0m Mean reward: -836.8380611210457
[32m[0514 05:35:30 @base_main.py:38][0m --------------- Iteration 171 ---------------
[32m[0514 05:35:30 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0829 mins
[32m[0514 05:35:30 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0044 mins
[32m[0514 05:35:30 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0137 mins
[32m[0514 05:35:30 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:35:30 @base_main.py:47][0m 171855 total steps have happened
[32m[0514 05:35:30 @base_main.py:52][0m [avg_reward]: -836.8380611210457
[32m[0514 05:35:30 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:30 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:30 @base_trainer.py:216][0m Mean reward: -989.3506518549335
[32m[0514 05:35:31 @base_main.py:38][0m --------------- Iteration 172 ---------------
[32m[0514 05:35:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1014 mins
[32m[0514 05:35:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0043 mins
[32m[0514 05:35:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0131 mins
[32m[0514 05:35:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:35:31 @base_main.py:47][0m 172860 total steps have happened
[32m[0514 05:35:31 @base_main.py:52][0m [avg_reward]: -989.3506518549335
[32m[0514 05:35:32 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:32 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:32 @base_trainer.py:216][0m Mean reward: -982.6488254614262
[32m[0514 05:35:32 @base_main.py:38][0m --------------- Iteration 173 ---------------
[32m[0514 05:35:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1190 mins
[32m[0514 05:35:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0047 mins
[32m[0514 05:35:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0132 mins
[32m[0514 05:35:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 05:35:32 @base_main.py:47][0m 173865 total steps have happened
[32m[0514 05:35:32 @base_main.py:52][0m [avg_reward]: -982.6488254614262
[32m[0514 05:35:33 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:33 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:33 @base_trainer.py:216][0m Mean reward: -870.1052648374047
[32m[0514 05:35:34 @base_main.py:38][0m --------------- Iteration 174 ---------------
[32m[0514 05:35:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1372 mins
[32m[0514 05:35:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0048 mins
[32m[0514 05:35:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0141 mins
[32m[0514 05:35:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:35:34 @base_main.py:47][0m 174870 total steps have happened
[32m[0514 05:35:34 @base_main.py:52][0m [avg_reward]: -870.1052648374047
[32m[0514 05:35:34 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:34 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:34 @base_trainer.py:216][0m Mean reward: -920.2264230249099
[32m[0514 05:35:35 @base_main.py:38][0m --------------- Iteration 175 ---------------
[32m[0514 05:35:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1564 mins
[32m[0514 05:35:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0050 mins
[32m[0514 05:35:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0143 mins
[32m[0514 05:35:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 05:35:35 @base_main.py:47][0m 175875 total steps have happened
[32m[0514 05:35:35 @base_main.py:52][0m [avg_reward]: -920.2264230249099
[32m[0514 05:35:35 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:35 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:35 @base_trainer.py:216][0m Mean reward: -1000.2270093096822
[32m[0514 05:35:36 @base_main.py:38][0m --------------- Iteration 176 ---------------
[32m[0514 05:35:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1759 mins
[32m[0514 05:35:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0049 mins
[32m[0514 05:35:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0146 mins
[32m[0514 05:35:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 05:35:36 @base_main.py:47][0m 176880 total steps have happened
[32m[0514 05:35:36 @base_main.py:52][0m [avg_reward]: -1000.2270093096822
[32m[0514 05:35:36 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:36 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:36 @base_trainer.py:216][0m Mean reward: -1108.7212130236562
[32m[0514 05:35:37 @base_main.py:38][0m --------------- Iteration 177 ---------------
[32m[0514 05:35:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1957 mins
[32m[0514 05:35:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0514 05:35:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0147 mins
[32m[0514 05:35:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:35:37 @base_main.py:47][0m 177885 total steps have happened
[32m[0514 05:35:37 @base_main.py:52][0m [avg_reward]: -1108.7212130236562
[32m[0514 05:35:37 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:37 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:37 @base_trainer.py:216][0m Mean reward: -995.4596729240382
[32m[0514 05:35:38 @base_main.py:38][0m --------------- Iteration 178 ---------------
[32m[0514 05:35:38 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2148 mins
[32m[0514 05:35:38 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0046 mins
[32m[0514 05:35:38 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0137 mins
[32m[0514 05:35:38 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:35:38 @base_main.py:47][0m 178890 total steps have happened
[32m[0514 05:35:38 @base_main.py:52][0m [avg_reward]: -995.4596729240382
[32m[0514 05:35:38 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:38 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:38 @base_trainer.py:216][0m Mean reward: -950.8276122070704
[32m[0514 05:35:39 @base_main.py:38][0m --------------- Iteration 179 ---------------
[32m[0514 05:35:39 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2333 mins
[32m[0514 05:35:39 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0055 mins
[32m[0514 05:35:39 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0142 mins
[32m[0514 05:35:39 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:35:39 @base_main.py:47][0m 179895 total steps have happened
[32m[0514 05:35:39 @base_main.py:52][0m [avg_reward]: -950.8276122070704
[32m[0514 05:35:40 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:40 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:40 @base_trainer.py:216][0m Mean reward: -1100.6636794733681
[32m[0514 05:35:40 @base_main.py:38][0m --------------- Iteration 180 ---------------
[32m[0514 05:35:40 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2532 mins
[32m[0514 05:35:40 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0045 mins
[32m[0514 05:35:40 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0142 mins
[32m[0514 05:35:40 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:35:40 @base_main.py:47][0m 180900 total steps have happened
[32m[0514 05:35:40 @base_main.py:52][0m [avg_reward]: -1100.6636794733681
[32m[0514 05:35:41 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:41 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:41 @base_trainer.py:216][0m Mean reward: -1034.806763205597
[32m[0514 05:35:42 @base_main.py:38][0m --------------- Iteration 181 ---------------
[32m[0514 05:35:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2722 mins
[32m[0514 05:35:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0043 mins
[32m[0514 05:35:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0136 mins
[32m[0514 05:35:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:35:42 @base_main.py:47][0m 181905 total steps have happened
[32m[0514 05:35:42 @base_main.py:52][0m [avg_reward]: -1034.806763205597
[32m[0514 05:35:42 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:42 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:42 @base_trainer.py:216][0m Mean reward: -1269.7061121915604
[32m[0514 05:35:43 @base_main.py:38][0m --------------- Iteration 182 ---------------
[32m[0514 05:35:43 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2903 mins
[32m[0514 05:35:43 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0514 05:35:43 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0139 mins
[32m[0514 05:35:43 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:35:43 @base_main.py:47][0m 182910 total steps have happened
[32m[0514 05:35:43 @base_main.py:52][0m [avg_reward]: -1269.7061121915604
[32m[0514 05:35:43 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:43 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:43 @base_trainer.py:216][0m Mean reward: -1017.0531004486762
[32m[0514 05:35:44 @base_main.py:38][0m --------------- Iteration 183 ---------------
[32m[0514 05:35:44 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3084 mins
[32m[0514 05:35:44 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0045 mins
[32m[0514 05:35:44 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0139 mins
[32m[0514 05:35:44 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:35:44 @base_main.py:47][0m 183915 total steps have happened
[32m[0514 05:35:44 @base_main.py:52][0m [avg_reward]: -1017.0531004486762
[32m[0514 05:35:44 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:44 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:44 @base_trainer.py:216][0m Mean reward: -869.8569437532211
[32m[0514 05:35:45 @base_main.py:38][0m --------------- Iteration 184 ---------------
[32m[0514 05:35:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3269 mins
[32m[0514 05:35:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0049 mins
[32m[0514 05:35:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0148 mins
[32m[0514 05:35:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:35:45 @base_main.py:47][0m 184920 total steps have happened
[32m[0514 05:35:45 @base_main.py:52][0m [avg_reward]: -869.8569437532211
[32m[0514 05:35:45 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:45 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:45 @base_trainer.py:216][0m Mean reward: -923.6123931924419
[32m[0514 05:35:46 @base_main.py:38][0m --------------- Iteration 185 ---------------
[32m[0514 05:35:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3468 mins
[32m[0514 05:35:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0045 mins
[32m[0514 05:35:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0133 mins
[32m[0514 05:35:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:35:46 @base_main.py:47][0m 185925 total steps have happened
[32m[0514 05:35:46 @base_main.py:52][0m [avg_reward]: -923.6123931924419
[32m[0514 05:35:46 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:46 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:46 @base_trainer.py:216][0m Mean reward: -1145.8829620256595
[32m[0514 05:35:47 @base_main.py:38][0m --------------- Iteration 186 ---------------
[32m[0514 05:35:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3647 mins
[32m[0514 05:35:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0050 mins
[32m[0514 05:35:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0145 mins
[32m[0514 05:35:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:35:47 @base_main.py:47][0m 186930 total steps have happened
[32m[0514 05:35:47 @base_main.py:52][0m [avg_reward]: -1145.8829620256595
[32m[0514 05:35:48 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:48 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:48 @base_trainer.py:216][0m Mean reward: -891.0289759107276
[32m[0514 05:35:48 @base_main.py:38][0m --------------- Iteration 187 ---------------
[32m[0514 05:35:48 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3844 mins
[32m[0514 05:35:48 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0049 mins
[32m[0514 05:35:48 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0143 mins
[32m[0514 05:35:48 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:35:48 @base_main.py:47][0m 187935 total steps have happened
[32m[0514 05:35:48 @base_main.py:52][0m [avg_reward]: -891.0289759107276
[32m[0514 05:35:49 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:49 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:49 @base_trainer.py:216][0m Mean reward: -989.0427480428207
[32m[0514 05:35:49 @base_main.py:38][0m --------------- Iteration 188 ---------------
[32m[0514 05:35:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4037 mins
[32m[0514 05:35:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0047 mins
[32m[0514 05:35:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0137 mins
[32m[0514 05:35:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:35:49 @base_main.py:47][0m 188940 total steps have happened
[32m[0514 05:35:49 @base_main.py:52][0m [avg_reward]: -989.0427480428207
[32m[0514 05:35:50 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:50 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:50 @base_trainer.py:216][0m Mean reward: -945.774201208058
[32m[0514 05:35:51 @base_main.py:38][0m --------------- Iteration 189 ---------------
[32m[0514 05:35:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4222 mins
[32m[0514 05:35:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0049 mins
[32m[0514 05:35:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0142 mins
[32m[0514 05:35:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:35:51 @base_main.py:47][0m 189945 total steps have happened
[32m[0514 05:35:51 @base_main.py:52][0m [avg_reward]: -945.774201208058
[32m[0514 05:35:51 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:51 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:51 @base_trainer.py:216][0m Mean reward: -789.6268926680397
[32m[0514 05:35:52 @base_main.py:38][0m --------------- Iteration 190 ---------------
[32m[0514 05:35:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4415 mins
[32m[0514 05:35:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0049 mins
[32m[0514 05:35:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0130 mins
[32m[0514 05:35:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:35:52 @base_main.py:47][0m 190950 total steps have happened
[32m[0514 05:35:52 @base_main.py:52][0m [avg_reward]: -789.6268926680397
[32m[0514 05:35:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:52 @base_trainer.py:216][0m Mean reward: -1288.1049835493693
[32m[0514 05:35:53 @base_main.py:38][0m --------------- Iteration 191 ---------------
[32m[0514 05:35:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4595 mins
[32m[0514 05:35:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0049 mins
[32m[0514 05:35:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0133 mins
[32m[0514 05:35:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:35:53 @base_main.py:47][0m 191955 total steps have happened
[32m[0514 05:35:53 @base_main.py:52][0m [avg_reward]: -1288.1049835493693
[32m[0514 05:35:53 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:53 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:53 @base_trainer.py:216][0m Mean reward: -965.7537468029219
[32m[0514 05:35:54 @base_main.py:38][0m --------------- Iteration 192 ---------------
[32m[0514 05:35:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4780 mins
[32m[0514 05:35:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0046 mins
[32m[0514 05:35:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0132 mins
[32m[0514 05:35:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:35:54 @base_main.py:47][0m 192960 total steps have happened
[32m[0514 05:35:54 @base_main.py:52][0m [avg_reward]: -965.7537468029219
[32m[0514 05:35:54 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:54 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:54 @base_trainer.py:216][0m Mean reward: -979.343355915451
[32m[0514 05:35:55 @base_main.py:38][0m --------------- Iteration 193 ---------------
[32m[0514 05:35:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4960 mins
[32m[0514 05:35:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0049 mins
[32m[0514 05:35:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0140 mins
[32m[0514 05:35:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:35:55 @base_main.py:47][0m 193965 total steps have happened
[32m[0514 05:35:55 @base_main.py:52][0m [avg_reward]: -979.343355915451
[32m[0514 05:35:55 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:55 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:55 @base_trainer.py:216][0m Mean reward: -935.4583521442652
[32m[0514 05:35:56 @base_main.py:38][0m --------------- Iteration 194 ---------------
[32m[0514 05:35:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.5150 mins
[32m[0514 05:35:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0046 mins
[32m[0514 05:35:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0140 mins
[32m[0514 05:35:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 05:35:56 @base_main.py:47][0m 194970 total steps have happened
[32m[0514 05:35:56 @base_main.py:52][0m [avg_reward]: -935.4583521442652
[32m[0514 05:35:56 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:56 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:56 @base_trainer.py:216][0m Mean reward: -968.4484674856012
[32m[0514 05:35:57 @base_main.py:38][0m --------------- Iteration 195 ---------------
[32m[0514 05:35:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.5340 mins
[32m[0514 05:35:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0043 mins
[32m[0514 05:35:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0138 mins
[32m[0514 05:35:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:35:57 @base_main.py:47][0m 195975 total steps have happened
[32m[0514 05:35:57 @base_main.py:52][0m [avg_reward]: -968.4484674856012
[32m[0514 05:35:58 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:58 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:58 @base_trainer.py:216][0m Mean reward: -930.5184967851135
[32m[0514 05:35:58 @base_main.py:38][0m --------------- Iteration 196 ---------------
[32m[0514 05:35:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.5523 mins
[32m[0514 05:35:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0052 mins
[32m[0514 05:35:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0135 mins
[32m[0514 05:35:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:35:58 @base_main.py:47][0m 196980 total steps have happened
[32m[0514 05:35:58 @base_main.py:52][0m [avg_reward]: -930.5184967851135
[32m[0514 05:35:59 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:59 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:59 @base_trainer.py:216][0m Mean reward: -854.9713577876279
[32m[0514 05:36:00 @base_main.py:38][0m --------------- Iteration 197 ---------------
[32m[0514 05:36:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.5712 mins
[32m[0514 05:36:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0043 mins
[32m[0514 05:36:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0139 mins
[32m[0514 05:36:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:36:00 @base_main.py:47][0m 197985 total steps have happened
[32m[0514 05:36:00 @base_main.py:52][0m [avg_reward]: -854.9713577876279
[32m[0514 05:36:00 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:36:00 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:36:00 @base_trainer.py:216][0m Mean reward: -876.590876554466
[32m[0514 05:36:01 @base_main.py:38][0m --------------- Iteration 198 ---------------
[32m[0514 05:36:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.5897 mins
[32m[0514 05:36:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0046 mins
[32m[0514 05:36:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0128 mins
[32m[0514 05:36:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:36:01 @base_main.py:47][0m 198990 total steps have happened
[32m[0514 05:36:01 @base_main.py:52][0m [avg_reward]: -876.590876554466
[32m[0514 05:36:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:36:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:36:01 @base_trainer.py:216][0m Mean reward: -1030.5369566104505
[32m[0514 05:36:02 @base_main.py:38][0m --------------- Iteration 199 ---------------
[32m[0514 05:36:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.6073 mins
[32m[0514 05:36:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0045 mins
[32m[0514 05:36:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0140 mins
[32m[0514 05:36:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 05:36:02 @base_main.py:47][0m 199995 total steps have happened
[32m[0514 05:36:02 @base_main.py:52][0m [avg_reward]: -1030.5369566104505
[32m[0514 05:36:02 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:36:02 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:36:02 @base_trainer.py:216][0m Mean reward: -1029.7374763547352
[32m[0514 05:36:03 @base_main.py:38][0m --------------- Iteration 200 ---------------
[32m[0514 05:36:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.6261 mins
[32m[0514 05:36:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0048 mins
[32m[0514 05:36:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0150 mins
[32m[0514 05:36:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:36:03 @base_main.py:47][0m 201000 total steps have happened
[32m[0514 05:36:03 @base_main.py:52][0m [avg_reward]: -1029.7374763547352
[32m[0514 05:36:03 @base_worker.py:111][0m kill message for worker 17
[32m[0514 05:36:03 @base_worker.py:111][0m kill message for worker 13
[32m[0514 05:36:03 @base_worker.py:111][0m kill message for worker 3
[32m[0514 05:36:03 @base_worker.py:111][0m kill message for worker 14
[32m[0514 05:36:03 @base_worker.py:111][0m kill message for worker 18
[32m[0514 05:36:03 @base_worker.py:111][0m kill message for worker 15
[32m[0514 05:36:03 @base_worker.py:111][0m kill message for worker 7
[32m[0514 05:36:03 @base_worker.py:111][0m kill message for worker 9
[32m[0514 05:36:03 @base_worker.py:111][0m kill message for worker 16
[32m[0514 05:36:03 @base_worker.py:111][0m kill message for worker 11
[32m[0514 05:36:03 @base_worker.py:111][0m kill message for worker 4
[32m[0514 05:36:03 @base_worker.py:111][0m kill message for worker 19
[32m[0514 05:36:03 @base_worker.py:111][0m kill message for worker 10
[32m[0514 05:36:03 @base_worker.py:111][0m kill message for worker 6
[32m[0514 05:36:03 @base_worker.py:111][0m kill message for worker 5
[32m[0514 05:36:03 @base_worker.py:111][0m kill message for worker 8
[32m[0514 05:36:03 @base_worker.py:111][0m kill message for worker 2
[32m[0514 05:36:03 @base_worker.py:111][0m kill message for worker 1
[32m[0514 05:36:03 @base_worker.py:111][0m kill message for worker 0
[32m[0514 05:36:03 @base_worker.py:111][0m kill message for worker 12
