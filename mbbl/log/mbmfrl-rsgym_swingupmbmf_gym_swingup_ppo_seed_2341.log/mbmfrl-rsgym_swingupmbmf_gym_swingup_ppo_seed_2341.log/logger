[32m[0511 19:24:20 @logger.py:103][0m Log file set to /root/mbbl/log/mbmfrl-rsgym_swingupmbmf_gym_swingup_ppo_seed_2341.log/mbmfrl-rsgym_swingupmbmf_gym_swingup_ppo_seed_2341.log
[32m[0511 19:24:21 @mbmf_main.py:23][0m Training starts at /root/mbbl
[32m[0511 19:24:21 @base_worker.py:45][0m Worker 0 online
[32m[0511 19:24:21 @base_worker.py:45][0m Worker 1 online
[32m[0511 19:24:21 @base_worker.py:45][0m Worker 2 online
[32m[0511 19:24:21 @base_worker.py:45][0m Worker 3 online
[32m[0511 19:24:21 @base_worker.py:45][0m Worker 4 online
[32m[0511 19:24:21 @base_worker.py:45][0m Worker 5 online
[32m[0511 19:24:21 @base_worker.py:45][0m Worker 6 online
[32m[0511 19:24:21 @base_worker.py:45][0m Worker 7 online
[32m[0511 19:24:21 @base_worker.py:45][0m Worker 8 online
[32m[0511 19:24:21 @base_worker.py:45][0m Worker 9 online
[32m[0511 19:24:21 @base_worker.py:45][0m Worker 10 online
[32m[0511 19:24:21 @base_worker.py:45][0m Worker 11 online
[32m[0511 19:24:21 @base_worker.py:45][0m Worker 12 online
[32m[0511 19:24:21 @base_worker.py:45][0m Worker 13 online
[32m[0511 19:24:21 @base_worker.py:45][0m Worker 14 online
[32m[0511 19:24:21 @base_worker.py:45][0m Worker 15 online
[32m[0511 19:24:21 @base_worker.py:45][0m Worker 16 online
[32m[0511 19:24:21 @base_worker.py:45][0m Worker 17 online
[32m[0511 19:24:21 @base_worker.py:45][0m Worker 18 online
[32m[0511 19:24:21 @base_worker.py:45][0m Worker 19 online
[32m[0511 19:24:22 @base_trainer.py:152][0m Trainer maintains [1] policy network
[32m[0511 19:24:23 @base_trainer.py:152][0m Trainer maintains [1] dynamics network
[32m[0511 19:24:23 @base_trainer.py:152][0m Trainer maintains [1] reward network
[32m[0511 19:24:23 @mbmf_main.py:46][0m Generating 1000 random timesteps
[32m[0511 19:24:23 @mbmf_sampler.py:39][0m done with episode
[32m[0511 19:24:23 @mbmf_sampler.py:39][0m done with episode
[32m[0511 19:24:23 @mbmf_sampler.py:50][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:24:23 @base_trainer.py:216][0m Mean reward: -282.59060791405557
[32m[0511 19:24:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5011958479881287, Train Loss: 0.5102444291114807
[32m[0511 19:24:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5012181401252747, Train Loss: 0.510237991809845
[32m[0511 19:24:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5012398362159729, Train Loss: 0.5102316737174988
[32m[0511 19:24:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5012617111206055, Train Loss: 0.5102254152297974
[32m[0511 19:24:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5012840032577515, Train Loss: 0.5102193355560303
[32m[0511 19:24:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5013067722320557, Train Loss: 0.5102134943008423
[32m[0511 19:24:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5013296604156494, Train Loss: 0.5102076530456543
[32m[0511 19:24:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5013527274131775, Train Loss: 0.5102019906044006
[32m[0511 19:24:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5013754367828369, Train Loss: 0.5101963877677917
[32m[0511 19:24:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5013979077339172, Train Loss: 0.5101909637451172
[32m[0511 19:24:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.501420259475708, Train Loss: 0.5101855397224426
[32m[0511 19:24:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5014426112174988, Train Loss: 0.5101801753044128
[32m[0511 19:24:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.50146484375, Train Loss: 0.5101749897003174
[32m[0511 19:24:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5014873147010803, Train Loss: 0.5101698637008667
[32m[0511 19:24:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.501509964466095, Train Loss: 0.5101648569107056
[32m[0511 19:24:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5015326738357544, Train Loss: 0.510159969329834
[32m[0511 19:24:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5015554428100586, Train Loss: 0.5101551413536072
[32m[0511 19:24:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5015779733657837, Train Loss: 0.5101505517959595
[32m[0511 19:24:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5016003847122192, Train Loss: 0.5101460218429565
[32m[0511 19:24:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5016226768493652, Train Loss: 0.5101415514945984
[32m[0511 19:24:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5016448497772217, Train Loss: 0.5101372003555298
[32m[0511 19:24:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5016670227050781, Train Loss: 0.510132908821106
[32m[0511 19:24:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5016891956329346, Train Loss: 0.5101287961006165
[32m[0511 19:24:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.501711368560791, Train Loss: 0.5101248025894165
[32m[0511 19:24:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5017335414886475, Train Loss: 0.5101208090782166
[32m[0511 19:24:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5017557144165039, Train Loss: 0.5101169943809509
[32m[0511 19:24:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5017776489257812, Train Loss: 0.5101132392883301
[32m[0511 19:24:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5017993450164795, Train Loss: 0.5101096630096436
[32m[0511 19:24:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.501820981502533, Train Loss: 0.510106086730957
[32m[0511 19:24:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5018423795700073, Train Loss: 0.5101027488708496
[32m[0511 19:24:24 @base_main.py:38][0m --------------- Iteration 1 ---------------
[32m[0511 19:24:24 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0000 mins
[32m[0511 19:24:24 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0016 mins
[32m[0511 19:24:24 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0112 mins
[32m[0511 19:24:24 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0037 mins
[32m[0511 19:24:24 @base_main.py:47][0m 1002 total steps have happened
[32m[0511 19:24:24 @base_main.py:52][0m [avg_reward]: -282.59060791405557
[32m[0511 19:24:24 @base_main.py:52][0m [update_op]: None
[32m[0511 19:24:24 @base_main.py:52][0m [train_loss]: 0.5101027488708496
[32m[0511 19:24:24 @base_main.py:52][0m [val_loss]: 0.5018423795700073
[32m[0511 19:24:24 @base_main.py:52][0m [avg_train_loss]: 0.5101027488708496
[32m[0511 19:30:58 @mbmf_sampler.py:39][0m done with episode
[32m[0511 19:37:30 @mbmf_sampler.py:39][0m done with episode
[32m[0511 19:37:30 @mbmf_sampler.py:50][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:37:30 @base_trainer.py:216][0m Mean reward: -457.8549980840985
[32m[0511 19:37:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4354289174079895, Train Loss: 0.5273762941360474
[32m[0511 19:37:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4354385733604431, Train Loss: 0.5273741483688354
[32m[0511 19:37:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4354513883590698, Train Loss: 0.5273728370666504
[32m[0511 19:37:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4354647994041443, Train Loss: 0.5273706912994385
[32m[0511 19:37:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.43547821044921875, Train Loss: 0.527367889881134
[32m[0511 19:37:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4354912042617798, Train Loss: 0.5273645520210266
[32m[0511 19:37:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4355037808418274, Train Loss: 0.5273608565330505
[32m[0511 19:37:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4355159401893616, Train Loss: 0.5273570418357849
[32m[0511 19:37:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.43552783131599426, Train Loss: 0.5273532271385193
[32m[0511 19:37:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.43553948402404785, Train Loss: 0.5273494124412537
[32m[0511 19:37:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.43555089831352234, Train Loss: 0.5273456573486328
[32m[0511 19:37:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4355621337890625, Train Loss: 0.5273420214653015
[32m[0511 19:37:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4355732798576355, Train Loss: 0.5273385643959045
[32m[0511 19:37:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.43558433651924133, Train Loss: 0.5273352265357971
[32m[0511 19:37:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.43559542298316956, Train Loss: 0.527332067489624
[32m[0511 19:37:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4356064796447754, Train Loss: 0.5273290276527405
[32m[0511 19:37:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.43561744689941406, Train Loss: 0.527326226234436
[32m[0511 19:37:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.43562838435173035, Train Loss: 0.5273234248161316
[32m[0511 19:37:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4356394112110138, Train Loss: 0.5273208022117615
[32m[0511 19:37:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.43565040826797485, Train Loss: 0.5273182392120361
[32m[0511 19:37:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4356613755226135, Train Loss: 0.5273159146308899
[32m[0511 19:37:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.435672402381897, Train Loss: 0.5273137092590332
[32m[0511 19:37:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4356834590435028, Train Loss: 0.5273115038871765
[32m[0511 19:37:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.43569445610046387, Train Loss: 0.5273094177246094
[32m[0511 19:37:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4357055127620697, Train Loss: 0.5273074507713318
[32m[0511 19:37:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.43571653962135315, Train Loss: 0.5273054838180542
[32m[0511 19:37:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.43572762608528137, Train Loss: 0.5273036360740662
[32m[0511 19:37:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.43573862314224243, Train Loss: 0.5273018479347229
[32m[0511 19:37:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.43574976921081543, Train Loss: 0.5273001194000244
[32m[0511 19:37:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4357607364654541, Train Loss: 0.5272984504699707
[32m[0511 19:37:32 @base_main.py:38][0m --------------- Iteration 2 ---------------
[32m[0511 19:37:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0165 mins
[32m[0511 19:37:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 13.1005 mins
[32m[0511 19:37:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0184 mins
[32m[0511 19:37:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0051 mins
[32m[0511 19:37:32 @base_main.py:47][0m 2004 total steps have happened
[32m[0511 19:37:32 @base_main.py:52][0m [avg_reward]: -457.8549980840985
[32m[0511 19:37:32 @base_main.py:52][0m [update_op]: None
[32m[0511 19:37:32 @base_main.py:52][0m [train_loss]: 0.5772984623908997
[32m[0511 19:37:32 @base_main.py:52][0m [val_loss]: 0.4357607364654541
[32m[0511 19:37:32 @base_main.py:52][0m [avg_train_loss]: 0.5272984504699707
[32m[0511 19:44:13 @mbmf_sampler.py:39][0m done with episode
[32m[0511 19:51:06 @mbmf_sampler.py:39][0m done with episode
[32m[0511 19:51:06 @mbmf_sampler.py:50][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:51:06 @base_trainer.py:216][0m Mean reward: -454.1307857496864
[32m[0511 19:51:06 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.47837135195732117, Train Loss: 0.5496885776519775
[32m[0511 19:51:06 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.47836142778396606, Train Loss: 0.5496701002120972
[32m[0511 19:51:06 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4784006178379059, Train Loss: 0.5496546030044556
[32m[0511 19:51:06 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4784642457962036, Train Loss: 0.5496410131454468
[32m[0511 19:51:06 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.47853949666023254, Train Loss: 0.5496292114257812
[32m[0511 19:51:06 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4786190688610077, Train Loss: 0.5496187210083008
[32m[0511 19:51:06 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4786995053291321, Train Loss: 0.549609363079071
[32m[0511 19:51:06 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.47877877950668335, Train Loss: 0.5496010184288025
[32m[0511 19:51:06 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.47885602712631226, Train Loss: 0.5495935082435608
[32m[0511 19:51:06 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.47893086075782776, Train Loss: 0.5495866537094116
[32m[0511 19:51:06 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.47900304198265076, Train Loss: 0.549580454826355
[32m[0511 19:51:06 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4790727198123932, Train Loss: 0.5495747923851013
[32m[0511 19:51:06 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4791399836540222, Train Loss: 0.5495694875717163
[32m[0511 19:51:06 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.47920486330986023, Train Loss: 0.5495646595954895
[32m[0511 19:51:06 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4792676568031311, Train Loss: 0.5495600700378418
[32m[0511 19:51:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4793284237384796, Train Loss: 0.5495558977127075
[32m[0511 19:51:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4793873131275177, Train Loss: 0.5495518445968628
[32m[0511 19:51:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.47944432497024536, Train Loss: 0.5495480895042419
[32m[0511 19:51:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4794999659061432, Train Loss: 0.5495445132255554
[32m[0511 19:51:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.47955387830734253, Train Loss: 0.549541175365448
[32m[0511 19:51:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4796064794063568, Train Loss: 0.5495379567146301
[32m[0511 19:51:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.47965776920318604, Train Loss: 0.5495348572731018
[32m[0511 19:51:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4797077178955078, Train Loss: 0.549531877040863
[32m[0511 19:51:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.47975659370422363, Train Loss: 0.5495290756225586
[32m[0511 19:51:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.47980430722236633, Train Loss: 0.5495263338088989
[32m[0511 19:51:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.47985100746154785, Train Loss: 0.5495237112045288
[32m[0511 19:51:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4798966944217682, Train Loss: 0.549521267414093
[32m[0511 19:51:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.47994139790534973, Train Loss: 0.5495188236236572
[32m[0511 19:51:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.47998517751693726, Train Loss: 0.5495165586471558
[32m[0511 19:51:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4800281822681427, Train Loss: 0.5495141744613647
[32m[0511 19:51:08 @base_main.py:38][0m --------------- Iteration 3 ---------------
[32m[0511 19:51:08 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 13.1405 mins
[32m[0511 19:51:08 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 13.5674 mins
[32m[0511 19:51:08 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0273 mins
[32m[0511 19:51:08 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0052 mins
[32m[0511 19:51:08 @base_main.py:47][0m 3006 total steps have happened
[32m[0511 19:51:08 @base_main.py:52][0m [avg_reward]: -454.1307857496864
[32m[0511 19:51:08 @base_main.py:52][0m [update_op]: None
[32m[0511 19:51:08 @base_main.py:52][0m [train_loss]: 0.4962654113769531
[32m[0511 19:51:08 @base_main.py:52][0m [val_loss]: 0.4800281822681427
[32m[0511 19:51:08 @base_main.py:52][0m [avg_train_loss]: 0.5495141744613647
[32m[0511 19:57:49 @mbmf_sampler.py:39][0m done with episode
[32m[0511 20:04:20 @mbmf_sampler.py:39][0m done with episode
[32m[0511 20:04:20 @mbmf_sampler.py:50][0m 1002 timesteps from 2 episodes collected
[32m[0511 20:04:20 @base_trainer.py:216][0m Mean reward: -455.65721651144474
[32m[0511 20:04:20 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.487621933221817, Train Loss: 0.5382749438285828
[32m[0511 20:04:20 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.48762866854667664, Train Loss: 0.5382663011550903
[32m[0511 20:04:20 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.48763903975486755, Train Loss: 0.5382583737373352
[32m[0511 20:04:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.48765063285827637, Train Loss: 0.5382510423660278
[32m[0511 20:04:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.487662672996521, Train Loss: 0.5382447242736816
[32m[0511 20:04:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4876742362976074, Train Loss: 0.538239061832428
[32m[0511 20:04:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4876852333545685, Train Loss: 0.5382340550422668
[32m[0511 20:04:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.48769545555114746, Train Loss: 0.5382294654846191
[32m[0511 20:04:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.48770496249198914, Train Loss: 0.5382253527641296
[32m[0511 20:04:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4877137243747711, Train Loss: 0.5382216572761536
[32m[0511 20:04:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.48772189021110535, Train Loss: 0.5382181406021118
[32m[0511 20:04:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.48772940039634705, Train Loss: 0.5382148623466492
[32m[0511 20:04:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.48773637413978577, Train Loss: 0.5382118821144104
[32m[0511 20:04:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.48774290084838867, Train Loss: 0.5382089018821716
[32m[0511 20:04:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4877489507198334, Train Loss: 0.5382062196731567
[32m[0511 20:04:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4877546429634094, Train Loss: 0.5382035970687866
[32m[0511 20:04:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.48775994777679443, Train Loss: 0.5382011532783508
[32m[0511 20:04:22 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.48776504397392273, Train Loss: 0.5381987690925598
[32m[0511 20:04:22 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.48776975274086, Train Loss: 0.5381963849067688
[32m[0511 20:04:22 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4877742826938629, Train Loss: 0.5381941795349121
[32m[0511 20:04:22 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4877784848213196, Train Loss: 0.5381920337677002
[32m[0511 20:04:22 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4877825975418091, Train Loss: 0.5381899476051331
[32m[0511 20:04:22 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.48778650164604187, Train Loss: 0.5381879210472107
[32m[0511 20:04:22 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.48779022693634033, Train Loss: 0.5381859540939331
[32m[0511 20:04:22 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.48779383301734924, Train Loss: 0.5381841063499451
[32m[0511 20:04:22 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.48779723048210144, Train Loss: 0.538182258605957
[32m[0511 20:04:22 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4878005087375641, Train Loss: 0.5381804704666138
[32m[0511 20:04:22 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.48780378699302673, Train Loss: 0.5381788015365601
[32m[0511 20:04:22 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.48780688643455505, Train Loss: 0.5381770730018616
[32m[0511 20:04:22 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.48780983686447144, Train Loss: 0.5381754636764526
[32m[0511 20:04:23 @base_main.py:38][0m --------------- Iteration 4 ---------------
[32m[0511 20:04:23 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 26.7405 mins
[32m[0511 20:04:23 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 13.2102 mins
[32m[0511 20:04:23 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0367 mins
[32m[0511 20:04:23 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0051 mins
[32m[0511 20:04:23 @base_main.py:47][0m 4008 total steps have happened
[32m[0511 20:04:23 @base_main.py:52][0m [avg_reward]: -455.65721651144474
[32m[0511 20:04:23 @base_main.py:52][0m [update_op]: None
[32m[0511 20:04:23 @base_main.py:52][0m [train_loss]: 0.5031147003173828
[32m[0511 20:04:23 @base_main.py:52][0m [val_loss]: 0.48780983686447144
[32m[0511 20:04:23 @base_main.py:52][0m [avg_train_loss]: 0.5381754636764526
[32m[0511 20:10:53 @mbmf_sampler.py:39][0m done with episode
[32m[0511 20:17:24 @mbmf_sampler.py:39][0m done with episode
[32m[0511 20:17:24 @mbmf_sampler.py:50][0m 1002 timesteps from 2 episodes collected
[32m[0511 20:17:24 @base_trainer.py:216][0m Mean reward: -457.4641092046775
[32m[0511 20:17:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.498945951461792, Train Loss: 0.533417820930481
[32m[0511 20:17:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.49895352125167847, Train Loss: 0.5334133505821228
[32m[0511 20:17:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4989621341228485, Train Loss: 0.5334081649780273
[32m[0511 20:17:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4989705979824066, Train Loss: 0.5334030985832214
[32m[0511 20:17:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.49897831678390503, Train Loss: 0.5333983302116394
[32m[0511 20:17:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4989851415157318, Train Loss: 0.5333939790725708
[32m[0511 20:17:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4989911615848541, Train Loss: 0.5333899855613708
[32m[0511 20:17:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4989962577819824, Train Loss: 0.53338623046875
[32m[0511 20:17:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4990006387233734, Train Loss: 0.5333827137947083
[32m[0511 20:17:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.49900439381599426, Train Loss: 0.533379316329956
[32m[0511 20:17:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.49900752305984497, Train Loss: 0.5333762168884277
[32m[0511 20:17:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4990101754665375, Train Loss: 0.5333730578422546
[32m[0511 20:17:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.49901244044303894, Train Loss: 0.5333701968193054
[32m[0511 20:17:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.49901431798934937, Train Loss: 0.5333673357963562
[32m[0511 20:17:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4990158975124359, Train Loss: 0.5333645343780518
[32m[0511 20:17:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.49901729822158813, Train Loss: 0.5333618521690369
[32m[0511 20:17:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.49901843070983887, Train Loss: 0.5333592891693115
[32m[0511 20:17:26 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.49901941418647766, Train Loss: 0.533356785774231
[32m[0511 20:17:26 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4990202784538269, Train Loss: 0.5333543419837952
[32m[0511 20:17:26 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4990209937095642, Train Loss: 0.5333518981933594
[32m[0511 20:17:26 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4990215301513672, Train Loss: 0.5333495736122131
[32m[0511 20:17:26 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4990220367908478, Train Loss: 0.5333473086357117
[32m[0511 20:17:26 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.49902260303497314, Train Loss: 0.5333449840545654
[32m[0511 20:17:26 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4990229606628418, Train Loss: 0.5333428978919983
[32m[0511 20:17:26 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4990233778953552, Train Loss: 0.5333406925201416
[32m[0511 20:17:26 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4990236759185791, Train Loss: 0.5333386659622192
[32m[0511 20:17:26 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.49902403354644775, Train Loss: 0.5333366990089417
[32m[0511 20:17:27 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.49902430176734924, Train Loss: 0.5333346724510193
[32m[0511 20:17:27 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4990245997905731, Train Loss: 0.5333327054977417
[32m[0511 20:17:27 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4990248680114746, Train Loss: 0.5333307981491089
[32m[0511 20:17:27 @base_main.py:38][0m --------------- Iteration 5 ---------------
[32m[0511 20:17:27 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 39.9925 mins
[32m[0511 20:17:27 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 13.0203 mins
[32m[0511 20:17:27 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0472 mins
[32m[0511 20:17:27 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0052 mins
[32m[0511 20:17:27 @base_main.py:47][0m 5010 total steps have happened
[32m[0511 20:17:27 @base_main.py:52][0m [avg_reward]: -457.4641092046775
[32m[0511 20:17:27 @base_main.py:52][0m [update_op]: None
[32m[0511 20:17:27 @base_main.py:52][0m [train_loss]: 0.4707709550857544
[32m[0511 20:17:27 @base_main.py:52][0m [val_loss]: 0.4990248680114746
[32m[0511 20:17:27 @base_main.py:52][0m [avg_train_loss]: 0.5333307981491089
[32m[0511 20:23:57 @mbmf_sampler.py:39][0m done with episode
[32m[0511 20:30:29 @mbmf_sampler.py:39][0m done with episode
[32m[0511 20:30:29 @mbmf_sampler.py:50][0m 1002 timesteps from 2 episodes collected
[32m[0511 20:30:29 @base_trainer.py:216][0m Mean reward: -455.50730817974187
[32m[0511 20:30:29 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5715945363044739, Train Loss: 0.5298702120780945
[32m[0511 20:30:29 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5716018676757812, Train Loss: 0.5298710465431213
[32m[0511 20:30:29 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5716074705123901, Train Loss: 0.5298702120780945
[32m[0511 20:30:29 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5716121792793274, Train Loss: 0.5298687219619751
[32m[0511 20:30:29 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5716162323951721, Train Loss: 0.5298672318458557
[32m[0511 20:30:29 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.571619987487793, Train Loss: 0.5298656821250916
[32m[0511 20:30:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5716232657432556, Train Loss: 0.5298641920089722
[32m[0511 20:30:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5716262459754944, Train Loss: 0.5298627614974976
[32m[0511 20:30:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5716289281845093, Train Loss: 0.529861330986023
[32m[0511 20:30:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5716314315795898, Train Loss: 0.5298599600791931
[32m[0511 20:30:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5716337561607361, Train Loss: 0.5298585891723633
[32m[0511 20:30:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.571635901927948, Train Loss: 0.5298573970794678
[32m[0511 20:30:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5716379284858704, Train Loss: 0.5298561453819275
[32m[0511 20:30:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5716398358345032, Train Loss: 0.5298550128936768
[32m[0511 20:30:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5716415643692017, Train Loss: 0.5298537611961365
[32m[0511 20:30:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5716432332992554, Train Loss: 0.5298526287078857
[32m[0511 20:30:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5716447234153748, Train Loss: 0.5298516154289246
[32m[0511 20:30:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5716462731361389, Train Loss: 0.5298504829406738
[32m[0511 20:30:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5716475248336792, Train Loss: 0.5298494100570679
[32m[0511 20:30:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5716489553451538, Train Loss: 0.5298485159873962
[32m[0511 20:30:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5716501474380493, Train Loss: 0.5298475027084351
[32m[0511 20:30:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5716513395309448, Train Loss: 0.5298464298248291
[32m[0511 20:30:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5716524720191956, Train Loss: 0.5298455953598022
[32m[0511 20:30:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5716535449028015, Train Loss: 0.5298447608947754
[32m[0511 20:30:32 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5716545581817627, Train Loss: 0.529843807220459
[32m[0511 20:30:32 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5716554522514343, Train Loss: 0.5298429131507874
[32m[0511 20:30:32 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5716564059257507, Train Loss: 0.5298421382904053
[32m[0511 20:30:32 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5716572999954224, Train Loss: 0.5298413634300232
[32m[0511 20:30:32 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5716581344604492, Train Loss: 0.5298405885696411
[32m[0511 20:30:32 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5716589689254761, Train Loss: 0.5298398733139038
[32m[0511 20:30:32 @base_main.py:38][0m --------------- Iteration 6 ---------------
[32m[0511 20:30:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 53.0653 mins
[32m[0511 20:30:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 13.0275 mins
[32m[0511 20:30:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0567 mins
[32m[0511 20:30:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0053 mins
[32m[0511 20:30:32 @base_main.py:47][0m 6012 total steps have happened
[32m[0511 20:30:32 @base_main.py:52][0m [avg_reward]: -455.50730817974187
[32m[0511 20:30:32 @base_main.py:52][0m [update_op]: None
[32m[0511 20:30:32 @base_main.py:52][0m [train_loss]: 0.5075592994689941
[32m[0511 20:30:32 @base_main.py:52][0m [val_loss]: 0.5716589689254761
[32m[0511 20:30:32 @base_main.py:52][0m [avg_train_loss]: 0.5298398733139038
[32m[0511 20:37:03 @mbmf_sampler.py:39][0m done with episode
[32m[0511 20:43:33 @mbmf_sampler.py:39][0m done with episode
[32m[0511 20:43:33 @mbmf_sampler.py:50][0m 1002 timesteps from 2 episodes collected
[32m[0511 20:43:33 @base_trainer.py:216][0m Mean reward: -412.78246135574693
[32m[0511 20:43:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5781916975975037, Train Loss: 0.530403196811676
[32m[0511 20:43:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5782099962234497, Train Loss: 0.5303992629051208
[32m[0511 20:43:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5782361030578613, Train Loss: 0.5303975939750671
[32m[0511 20:43:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.578262209892273, Train Loss: 0.5303965210914612
[32m[0511 20:43:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.578286349773407, Train Loss: 0.5303958058357239
[32m[0511 20:43:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5783084034919739, Train Loss: 0.5303952693939209
[32m[0511 20:43:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5783283114433289, Train Loss: 0.5303946733474731
[32m[0511 20:43:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5783467888832092, Train Loss: 0.5303941965103149
[32m[0511 20:43:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5783637762069702, Train Loss: 0.5303938388824463
[32m[0511 20:43:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5783795118331909, Train Loss: 0.5303934216499329
[32m[0511 20:43:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5783941745758057, Train Loss: 0.5303930640220642
[32m[0511 20:43:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5784078240394592, Train Loss: 0.5303927659988403
[32m[0511 20:43:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5784209370613098, Train Loss: 0.5303925275802612
[32m[0511 20:43:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5784332156181335, Train Loss: 0.5303922891616821
[32m[0511 20:43:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5784450173377991, Train Loss: 0.5303921103477478
[32m[0511 20:43:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5784562826156616, Train Loss: 0.5303918123245239
[32m[0511 20:43:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5784670114517212, Train Loss: 0.5303916335105896
[32m[0511 20:43:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5784774422645569, Train Loss: 0.5303914546966553
[32m[0511 20:43:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5784874558448792, Train Loss: 0.530391275882721
[32m[0511 20:43:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5784972310066223, Train Loss: 0.5303911566734314
[32m[0511 20:43:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5785066485404968, Train Loss: 0.5303909778594971
[32m[0511 20:43:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5785158276557922, Train Loss: 0.5303907990455627
[32m[0511 20:43:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5785248279571533, Train Loss: 0.5303906798362732
[32m[0511 20:43:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5785335302352905, Train Loss: 0.5303905606269836
[32m[0511 20:43:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5785420536994934, Train Loss: 0.5303904414176941
[32m[0511 20:43:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.578550398349762, Train Loss: 0.5303903818130493
[32m[0511 20:43:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5785585641860962, Train Loss: 0.530390202999115
[32m[0511 20:43:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5785664916038513, Train Loss: 0.5303901433944702
[32m[0511 20:43:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5785742998123169, Train Loss: 0.5303900837898254
[32m[0511 20:43:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5785818696022034, Train Loss: 0.5303900241851807
[32m[0511 20:43:37 @base_main.py:38][0m --------------- Iteration 7 ---------------
[32m[0511 20:43:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 66.1549 mins
[32m[0511 20:43:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 13.0144 mins
[32m[0511 20:43:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0638 mins
[32m[0511 20:43:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0054 mins
[32m[0511 20:43:37 @base_main.py:47][0m 7014 total steps have happened
[32m[0511 20:43:37 @base_main.py:52][0m [avg_reward]: -412.78246135574693
[32m[0511 20:43:37 @base_main.py:52][0m [update_op]: None
[32m[0511 20:43:37 @base_main.py:52][0m [train_loss]: 0.5212324261665344
[32m[0511 20:43:37 @base_main.py:52][0m [val_loss]: 0.5785818696022034
[32m[0511 20:43:37 @base_main.py:52][0m [avg_train_loss]: 0.5303900241851807
[32m[0511 20:43:37 @mbmf_trainer.py:160][0m Mean reward: -425.1410695713502
[32m[0511 20:43:38 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.2977243959903717, Train Loss: 0.2945076823234558
[32m[0511 20:43:38 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.2948843836784363, Train Loss: 0.29136261343955994
[32m[0511 20:43:38 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.29261523485183716, Train Loss: 0.288911372423172
[32m[0511 20:43:38 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.2906935214996338, Train Loss: 0.2868303954601288
[32m[0511 20:43:38 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.2890598773956299, Train Loss: 0.2849908769130707
[32m[0511 20:43:38 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.28769853711128235, Train Loss: 0.2833981215953827
[32m[0511 20:43:38 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.28657588362693787, Train Loss: 0.28206679224967957
[32m[0511 20:43:38 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.2856484651565552, Train Loss: 0.2809792757034302
[32m[0511 20:43:38 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.2848675847053528, Train Loss: 0.2800920903682709
[32m[0511 20:43:38 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.2841847538948059, Train Loss: 0.27935102581977844
[32m[0511 20:43:38 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.283561110496521, Train Loss: 0.278707355260849
[32m[0511 20:43:38 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.28297242522239685, Train Loss: 0.2781260013580322
[32m[0511 20:43:38 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.28240710496902466, Train Loss: 0.2775857150554657
[32m[0511 20:43:38 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.28186091780662537, Train Loss: 0.27707499265670776
[32m[0511 20:43:38 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.2813328206539154, Train Loss: 0.27658811211586
[32m[0511 20:43:38 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.2808231711387634, Train Loss: 0.2761227786540985
[32m[0511 20:43:38 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.28033289313316345, Train Loss: 0.27567845582962036
[32m[0511 20:43:38 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.27986326813697815, Train Loss: 0.27525538206100464
[32m[0511 20:43:38 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.2794155776500702, Train Loss: 0.2748540937900543
[32m[0511 20:43:38 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.2789907455444336, Train Loss: 0.2744750678539276
[32m[0511 20:43:38 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.2785894274711609, Train Loss: 0.274118572473526
[32m[0511 20:43:38 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.2782119810581207, Train Loss: 0.2737846076488495
[32m[0511 20:43:38 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.2778581976890564, Train Loss: 0.2734729051589966
[32m[0511 20:43:38 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.27752751111984253, Train Loss: 0.2731827199459076
[32m[0511 20:43:38 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.27721908688545227, Train Loss: 0.27291297912597656
[32m[0511 20:43:38 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.2769317030906677, Train Loss: 0.27266255021095276
[32m[0511 20:43:38 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.2766638696193695, Train Loss: 0.27242985367774963
[32m[0511 20:43:38 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.27641424536705017, Train Loss: 0.2722133696079254
[32m[0511 20:43:38 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.2761812210083008, Train Loss: 0.27201154828071594
[32m[0511 20:43:38 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.2759631872177124, Train Loss: 0.2718227505683899
[32m[0511 20:43:38 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.2757587432861328, Train Loss: 0.27164560556411743
[32m[0511 20:43:38 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.2755664885044098, Train Loss: 0.2714786231517792
[32m[0511 20:43:38 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.2753850817680359, Train Loss: 0.2713206708431244
[32m[0511 20:43:39 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.27521347999572754, Train Loss: 0.27117058634757996
[32m[0511 20:43:39 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.2750506103038788, Train Loss: 0.2710273861885071
[32m[0511 20:43:39 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.2748955488204956, Train Loss: 0.2708902657032013
[32m[0511 20:43:39 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.27474746108055115, Train Loss: 0.2707585394382477
[32m[0511 20:43:39 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.27460572123527527, Train Loss: 0.27063149213790894
[32m[0511 20:43:39 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.27446967363357544, Train Loss: 0.27050867676734924
[32m[0511 20:43:39 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.2743387818336487, Train Loss: 0.2703896462917328
[32m[0511 20:43:39 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.2742125391960144, Train Loss: 0.27027395367622375
[32m[0511 20:43:39 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.27409064769744873, Train Loss: 0.27016130089759827
[32m[0511 20:43:39 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.27397263050079346, Train Loss: 0.270051509141922
[32m[0511 20:43:39 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.2738582491874695, Train Loss: 0.2699441611766815
[32m[0511 20:43:39 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.27374720573425293, Train Loss: 0.26983919739723206
[32m[0511 20:43:39 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.2736392021179199, Train Loss: 0.26973631978034973
[32m[0511 20:43:39 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.2735340893268585, Train Loss: 0.26963546872138977
[32m[0511 20:43:39 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.2734316289424896, Train Loss: 0.26953646540641785
[32m[0511 20:43:39 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.2733316421508789, Train Loss: 0.2694391906261444
[32m[0511 20:43:39 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.27323397994041443, Train Loss: 0.26934340596199036
[32m[0511 20:43:39 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.27313849329948425, Train Loss: 0.26924920082092285
[32m[0511 20:43:39 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.27304503321647644, Train Loss: 0.2691563665866852
[32m[0511 20:43:39 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.2729535400867462, Train Loss: 0.2690648138523102
[32m[0511 20:43:39 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.2728637754917145, Train Loss: 0.26897454261779785
[32m[0511 20:43:39 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.272775799036026, Train Loss: 0.26888540387153625
[32m[0511 20:43:39 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.2726893723011017, Train Loss: 0.268797367811203
[32m[0511 20:43:39 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.2726045250892639, Train Loss: 0.26871034502983093
[32m[0511 20:43:39 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.27252110838890076, Train Loss: 0.26862430572509766
[32m[0511 20:43:39 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.2724391222000122, Train Loss: 0.2685392200946808
[32m[0511 20:43:39 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.2723584473133087, Train Loss: 0.26845499873161316
[32m[0511 20:43:39 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.2722789943218231, Train Loss: 0.2683716118335724
[32m[0511 20:43:39 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.2722008526325226, Train Loss: 0.2682890295982361
[32m[0511 20:43:39 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.2721238136291504, Train Loss: 0.26820722222328186
[32m[0511 20:43:39 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.27204790711402893, Train Loss: 0.26812615990638733
[32m[0511 20:43:39 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.2719731330871582, Train Loss: 0.2680458128452301
[32m[0511 20:43:39 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.27189943194389343, Train Loss: 0.2679661512374878
[32m[0511 20:43:39 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.27182671427726746, Train Loss: 0.2678872048854828
[32m[0511 20:43:39 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.27175506949424744, Train Loss: 0.26780885457992554
[32m[0511 20:43:39 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.2716844081878662, Train Loss: 0.2677311599254608
[32m[0511 20:43:40 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.2716147303581238, Train Loss: 0.26765409111976624
[32m[0511 20:43:40 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.27154600620269775, Train Loss: 0.2675776183605194
[32m[0511 20:43:40 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.27147820591926575, Train Loss: 0.2675018012523651
[32m[0511 20:43:40 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.2714114189147949, Train Loss: 0.2674265205860138
[32m[0511 20:43:40 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.27134549617767334, Train Loss: 0.2673518657684326
[32m[0511 20:43:40 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.27128055691719055, Train Loss: 0.2672777473926544
[32m[0511 20:43:40 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.2712165415287018, Train Loss: 0.267204225063324
[32m[0511 20:43:40 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.27115345001220703, Train Loss: 0.2671312987804413
[32m[0511 20:43:40 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.2710912525653839, Train Loss: 0.2670589089393616
[32m[0511 20:43:40 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.2710300385951996, Train Loss: 0.266987144947052
[32m[0511 20:43:40 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.2709697484970093, Train Loss: 0.266915887594223
[32m[0511 20:43:40 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.270910382270813, Train Loss: 0.2668452858924866
[32m[0511 20:43:40 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.2708519399166107, Train Loss: 0.2667752206325531
[32m[0511 20:43:40 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.27079448103904724, Train Loss: 0.26670578122138977
[32m[0511 20:43:40 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.2707379460334778, Train Loss: 0.2666369378566742
[32m[0511 20:43:40 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.2706824243068695, Train Loss: 0.26656869053840637
[32m[0511 20:43:40 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.27062779664993286, Train Loss: 0.2665010392665863
[32m[0511 20:43:40 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.2705741822719574, Train Loss: 0.26643407344818115
[32m[0511 20:43:40 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.2705215513706207, Train Loss: 0.26636770367622375
[32m[0511 20:43:40 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.27046990394592285, Train Loss: 0.2663019597530365
[32m[0511 20:43:40 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.2704192101955414, Train Loss: 0.26623693108558655
[32m[0511 20:43:40 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.2703695297241211, Train Loss: 0.2661725878715515
[32m[0511 20:43:40 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.270320862531662, Train Loss: 0.266108900308609
[32m[0511 20:43:40 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.27027323842048645, Train Loss: 0.2660459578037262
[32m[0511 20:43:40 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.2702266275882721, Train Loss: 0.2659836709499359
[32m[0511 20:43:40 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.2701810300350189, Train Loss: 0.2659221589565277
[32m[0511 20:43:40 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.27013644576072693, Train Loss: 0.265861451625824
[32m[0511 20:43:40 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.2700928747653961, Train Loss: 0.26580142974853516
[32m[0511 20:43:40 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.2700503468513489, Train Loss: 0.2657422721385956
[32m[0511 20:43:40 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.2700088620185852, Train Loss: 0.2656838595867157
[32m[0511 20:43:40 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.2699683904647827, Train Loss: 0.26562628149986267
[32m[0511 20:43:40 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.2699289321899414, Train Loss: 0.26556944847106934
[32m[0511 20:43:40 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.2698904871940613, Train Loss: 0.26551344990730286
[32m[0511 20:43:40 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.2698530852794647, Train Loss: 0.2654583156108856
[32m[0511 20:43:40 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.26981663703918457, Train Loss: 0.26540401577949524
[32m[0511 20:43:40 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.269781231880188, Train Loss: 0.2653505802154541
[32m[0511 20:43:40 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.2697467803955078, Train Loss: 0.26529791951179504
[32m[0511 20:43:41 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.26971331238746643, Train Loss: 0.26524618268013
[32m[0511 20:43:41 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.26968079805374146, Train Loss: 0.26519522070884705
[32m[0511 20:43:41 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.2696492671966553, Train Loss: 0.2651451826095581
[32m[0511 20:43:41 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.2696186304092407, Train Loss: 0.26509591937065125
[32m[0511 20:43:41 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.2695889174938202, Train Loss: 0.265047550201416
[32m[0511 20:43:41 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.2695600986480713, Train Loss: 0.26500001549720764
[32m[0511 20:43:41 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.2695322036743164, Train Loss: 0.26495328545570374
[32m[0511 20:43:41 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.2695051431655884, Train Loss: 0.2649073898792267
[32m[0511 20:43:41 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.2694789171218872, Train Loss: 0.2648623585700989
[32m[0511 20:43:41 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.2694535553455353, Train Loss: 0.26481810212135315
[32m[0511 20:43:41 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.26942896842956543, Train Loss: 0.2647746503353119
[32m[0511 20:43:41 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.26940518617630005, Train Loss: 0.2647320032119751
[32m[0511 20:43:41 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.26938217878341675, Train Loss: 0.2646900713443756
[32m[0511 20:43:41 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.26935991644859314, Train Loss: 0.26464900374412537
[32m[0511 20:43:41 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.2693383991718292, Train Loss: 0.2646086513996124
[32m[0511 20:43:41 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.2693175971508026, Train Loss: 0.2645690143108368
[32m[0511 20:43:41 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.26929745078086853, Train Loss: 0.26453015208244324
[32m[0511 20:43:41 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.26927801966667175, Train Loss: 0.264492005109787
[32m[0511 20:43:41 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.2692592144012451, Train Loss: 0.26445457339286804
[32m[0511 20:43:41 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.269241064786911, Train Loss: 0.264417827129364
[32m[0511 20:43:41 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.26922348141670227, Train Loss: 0.2643817961215973
[32m[0511 20:43:41 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.2692064940929413, Train Loss: 0.2643463909626007
[32m[0511 20:43:41 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.26919010281562805, Train Loss: 0.26431161165237427
[32m[0511 20:43:41 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.2691742777824402, Train Loss: 0.26427748799324036
[32m[0511 20:43:41 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.2691589593887329, Train Loss: 0.26424404978752136
[32m[0511 20:43:41 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.2691441774368286, Train Loss: 0.26421117782592773
[32m[0511 20:43:41 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.2691298723220825, Train Loss: 0.26417890191078186
[32m[0511 20:43:41 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.26911604404449463, Train Loss: 0.26414719223976135
[32m[0511 20:43:41 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.26910269260406494, Train Loss: 0.2641160786151886
[32m[0511 20:43:41 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.26908978819847107, Train Loss: 0.2640855014324188
[32m[0511 20:43:41 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.269077330827713, Train Loss: 0.264055460691452
[32m[0511 20:43:41 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.2690652906894684, Train Loss: 0.2640259563922882
[32m[0511 20:43:41 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.2690536081790924, Train Loss: 0.26399698853492737
[32m[0511 20:43:41 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.26904231309890747, Train Loss: 0.26396846771240234
[32m[0511 20:43:41 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.26903143525123596, Train Loss: 0.2639404833316803
[32m[0511 20:43:42 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.26902082562446594, Train Loss: 0.2639129161834717
[32m[0511 20:43:42 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.26901063323020935, Train Loss: 0.26388582587242126
[32m[0511 20:43:42 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.26900070905685425, Train Loss: 0.26385924220085144
[32m[0511 20:43:42 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.2689911425113678, Train Loss: 0.26383307576179504
[32m[0511 20:43:42 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.26898181438446045, Train Loss: 0.2638072371482849
[32m[0511 20:43:42 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.26897284388542175, Train Loss: 0.263781875371933
[32m[0511 20:43:42 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.2689640522003174, Train Loss: 0.2637569308280945
[32m[0511 20:43:42 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.26895561814308167, Train Loss: 0.263732373714447
[32m[0511 20:43:42 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.26894739270210266, Train Loss: 0.2637082040309906
[32m[0511 20:43:42 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.26893937587738037, Train Loss: 0.26368436217308044
[32m[0511 20:43:42 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.26893162727355957, Train Loss: 0.26366090774536133
[32m[0511 20:43:42 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.26892411708831787, Train Loss: 0.2636377513408661
[32m[0511 20:43:42 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.2689168155193329, Train Loss: 0.2636149227619171
[32m[0511 20:43:42 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.26890963315963745, Train Loss: 0.2635924518108368
[32m[0511 20:43:42 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.2689026892185211, Train Loss: 0.26357030868530273
[32m[0511 20:43:42 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.2688959538936615, Train Loss: 0.26354846358299255
[32m[0511 20:43:42 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.2688893675804138, Train Loss: 0.26352688670158386
[32m[0511 20:43:42 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.2688829302787781, Train Loss: 0.26350563764572144
[32m[0511 20:43:42 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.2688766419887543, Train Loss: 0.2634846270084381
[32m[0511 20:43:42 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.2688705027103424, Train Loss: 0.26346391439437866
[32m[0511 20:43:42 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.26886454224586487, Train Loss: 0.2634434401988983
[32m[0511 20:43:42 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.2688587009906769, Train Loss: 0.26342323422431946
[32m[0511 20:43:42 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.26885297894477844, Train Loss: 0.2634032368659973
[32m[0511 20:43:42 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.26884737610816956, Train Loss: 0.26338353753089905
[32m[0511 20:43:42 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.2688418924808502, Train Loss: 0.2633640468120575
[32m[0511 20:43:42 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.26883652806282043, Train Loss: 0.26334476470947266
[32m[0511 20:43:42 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.2688312530517578, Train Loss: 0.2633257210254669
[32m[0511 20:43:42 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.26882606744766235, Train Loss: 0.2633068561553955
[32m[0511 20:43:42 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.26882100105285645, Train Loss: 0.2632881999015808
[32m[0511 20:43:42 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.2688159942626953, Train Loss: 0.2632697522640228
[32m[0511 20:43:42 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.26881107687950134, Train Loss: 0.2632514536380768
[32m[0511 20:43:42 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.26880624890327454, Train Loss: 0.26323339343070984
[32m[0511 20:43:42 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.2688014805316925, Train Loss: 0.2632155418395996
[32m[0511 20:43:42 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.26879677176475525, Train Loss: 0.26319777965545654
[32m[0511 20:43:42 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.26879215240478516, Train Loss: 0.2631802260875702
[32m[0511 20:43:42 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.26878756284713745, Train Loss: 0.2631628215312958
[32m[0511 20:43:42 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.2687830626964569, Train Loss: 0.2631455957889557
[32m[0511 20:43:43 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.26877859234809875, Train Loss: 0.26312848925590515
[32m[0511 20:43:43 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.2687741816043854, Train Loss: 0.26311153173446655
[32m[0511 20:43:43 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.2687698006629944, Train Loss: 0.2630947232246399
[32m[0511 20:43:43 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.2687654495239258, Train Loss: 0.26307806372642517
[32m[0511 20:43:43 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.26876118779182434, Train Loss: 0.2630615234375
[32m[0511 20:43:43 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.2687568962574005, Train Loss: 0.26304516196250916
[32m[0511 20:43:43 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.26875269412994385, Train Loss: 0.2630288898944855
[32m[0511 20:43:43 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.2687484920024872, Train Loss: 0.26301273703575134
[32m[0511 20:43:43 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.2687443494796753, Train Loss: 0.26299670338630676
[32m[0511 20:43:43 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.2687402069568634, Train Loss: 0.26298078894615173
[32m[0511 20:43:43 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.2687361240386963, Train Loss: 0.26296499371528625
[32m[0511 20:43:43 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.2687320113182068, Train Loss: 0.26294928789138794
[32m[0511 20:43:43 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.26872795820236206, Train Loss: 0.26293373107910156
[32m[0511 20:43:43 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.26872390508651733, Train Loss: 0.26291823387145996
[32m[0511 20:43:43 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.268719881772995, Train Loss: 0.2629028558731079
[32m[0511 20:43:43 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.26871585845947266, Train Loss: 0.262887567281723
[32m[0511 20:43:43 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.2687118649482727, Train Loss: 0.2628723978996277
[32m[0511 20:43:43 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.26870787143707275, Train Loss: 0.2628573179244995
[32m[0511 20:43:43 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.2687039375305176, Train Loss: 0.2628422677516937
[32m[0511 20:43:43 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.26869997382164, Train Loss: 0.2628273665904999
[32m[0511 20:43:43 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.26869603991508484, Train Loss: 0.2628125846385956
[32m[0511 20:43:43 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.2686920762062073, Train Loss: 0.26279783248901367
[32m[0511 20:43:43 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.2686881721019745, Train Loss: 0.2627831697463989
[32m[0511 20:43:43 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.2686842381954193, Train Loss: 0.26276859641075134
[32m[0511 20:43:43 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.2686803638935089, Train Loss: 0.2627541124820709
[32m[0511 20:43:43 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.26867640018463135, Train Loss: 0.26273971796035767
[32m[0511 20:43:43 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.2686725854873657, Train Loss: 0.2627253830432892
[32m[0511 20:43:43 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.26866865158081055, Train Loss: 0.2627111077308655
[32m[0511 20:43:43 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.26866480708122253, Train Loss: 0.2626969516277313
[32m[0511 20:43:43 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.26866090297698975, Train Loss: 0.26268288493156433
[32m[0511 20:43:43 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.26865702867507935, Train Loss: 0.26266881823539734
[32m[0511 20:43:43 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.26865318417549133, Train Loss: 0.2626548409461975
[32m[0511 20:43:43 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.2686493396759033, Train Loss: 0.26264095306396484
[32m[0511 20:43:43 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.2686454653739929, Train Loss: 0.26262712478637695
[32m[0511 20:43:43 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.2686416208744049, Train Loss: 0.26261335611343384
[32m[0511 20:43:43 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.2686378061771393, Train Loss: 0.2625996768474579
[32m[0511 20:43:44 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.26863396167755127, Train Loss: 0.2625860273838043
[32m[0511 20:43:44 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.26863008737564087, Train Loss: 0.2625724971294403
[32m[0511 20:43:44 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.26862627267837524, Train Loss: 0.2625589668750763
[32m[0511 20:43:44 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.2686224579811096, Train Loss: 0.26254549622535706
[32m[0511 20:43:44 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.2686185836791992, Train Loss: 0.26253214478492737
[32m[0511 20:43:44 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.268614798784256, Train Loss: 0.26251885294914246
[32m[0511 20:43:44 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.26861098408699036, Train Loss: 0.26250553131103516
[32m[0511 20:43:44 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.26860713958740234, Train Loss: 0.2624923288822174
[32m[0511 20:43:44 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.2686033546924591, Train Loss: 0.26247915625572205
[32m[0511 20:43:44 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.2685995399951935, Train Loss: 0.26246604323387146
[32m[0511 20:43:44 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.26859572529792786, Train Loss: 0.26245298981666565
[32m[0511 20:43:44 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.26859185099601746, Train Loss: 0.26243993639945984
[32m[0511 20:43:44 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.2685880661010742, Train Loss: 0.2624270021915436
[32m[0511 20:43:44 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.2685842514038086, Train Loss: 0.2624140977859497
[32m[0511 20:43:44 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.2685804069042206, Train Loss: 0.2624012529850006
[32m[0511 20:43:44 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.26857659220695496, Train Loss: 0.2623884081840515
[32m[0511 20:43:44 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.26857274770736694, Train Loss: 0.26237568259239197
[32m[0511 20:43:44 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.2685689330101013, Train Loss: 0.26236292719841003
[32m[0511 20:43:44 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.2685650885105133, Train Loss: 0.26235026121139526
[32m[0511 20:43:44 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.2685612738132477, Train Loss: 0.2623375952243805
[32m[0511 20:43:44 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.2685573995113373, Train Loss: 0.2623250186443329
[32m[0511 20:43:44 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.26855358481407166, Train Loss: 0.2623124420642853
[32m[0511 20:43:44 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.26854971051216125, Train Loss: 0.2622999846935272
[32m[0511 20:43:44 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.26854583621025085, Train Loss: 0.2622874677181244
[32m[0511 20:43:44 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.26854199171066284, Train Loss: 0.2622750699520111
[32m[0511 20:43:44 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.26853811740875244, Train Loss: 0.26226264238357544
[32m[0511 20:43:44 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.26853427290916443, Train Loss: 0.26225027441978455
[32m[0511 20:43:44 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.26853039860725403, Train Loss: 0.2622379660606384
[32m[0511 20:43:44 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.26852649450302124, Train Loss: 0.2622257173061371
[32m[0511 20:43:44 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.26852262020111084, Train Loss: 0.26221340894699097
[32m[0511 20:43:44 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.26851871609687805, Train Loss: 0.262201189994812
[32m[0511 20:43:44 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.26851484179496765, Train Loss: 0.26218900084495544
[32m[0511 20:43:44 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.2685109078884125, Train Loss: 0.26217687129974365
[32m[0511 20:43:44 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.2685070037841797, Train Loss: 0.26216474175453186
[32m[0511 20:43:44 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.2685030698776245, Train Loss: 0.26215264201164246
[32m[0511 20:43:44 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.2684991657733917, Train Loss: 0.2621406018733978
[32m[0511 20:43:44 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.26849523186683655, Train Loss: 0.2621285319328308
[32m[0511 20:43:44 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.268491268157959, Train Loss: 0.26211652159690857
[32m[0511 20:43:45 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.2684873044490814, Train Loss: 0.2621046006679535
[32m[0511 20:43:45 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.26848337054252625, Train Loss: 0.26209262013435364
[32m[0511 20:43:45 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.2684794068336487, Train Loss: 0.26208075881004333
[32m[0511 20:43:45 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.26847541332244873, Train Loss: 0.26206883788108826
[32m[0511 20:43:45 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.2684714198112488, Train Loss: 0.26205694675445557
[32m[0511 20:43:45 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.2684674561023712, Train Loss: 0.26204511523246765
[32m[0511 20:43:45 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.2684634327888489, Train Loss: 0.2620333135128021
[32m[0511 20:43:45 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.26845940947532654, Train Loss: 0.2620215117931366
[32m[0511 20:43:45 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.2684554159641266, Train Loss: 0.26200973987579346
[32m[0511 20:43:45 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.26845136284828186, Train Loss: 0.2619979679584503
[32m[0511 20:43:45 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.2684473395347595, Train Loss: 0.26198622584342957
[32m[0511 20:43:45 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.2684432864189148, Train Loss: 0.2619745433330536
[32m[0511 20:43:45 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.26843923330307007, Train Loss: 0.261962890625
[32m[0511 20:43:45 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.26843520998954773, Train Loss: 0.261951208114624
[32m[0511 20:43:45 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.2684311270713806, Train Loss: 0.26193955540657043
[32m[0511 20:43:45 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.2684270739555359, Train Loss: 0.2619279623031616
[32m[0511 20:43:45 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.2684229612350464, Train Loss: 0.2619163691997528
[32m[0511 20:43:45 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.2684188485145569, Train Loss: 0.2619048058986664
[32m[0511 20:43:45 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.26841476559638977, Train Loss: 0.26189324259757996
[32m[0511 20:43:45 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.26841068267822266, Train Loss: 0.2618817090988159
[32m[0511 20:43:45 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.26840654015541077, Train Loss: 0.26187020540237427
[32m[0511 20:43:45 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.2684023976325989, Train Loss: 0.2618587017059326
[32m[0511 20:43:45 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.2683982849121094, Train Loss: 0.26184722781181335
[32m[0511 20:43:45 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.2683941423892975, Train Loss: 0.2618357837200165
[32m[0511 20:43:45 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.2683899998664856, Train Loss: 0.2618243098258972
[32m[0511 20:43:45 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.2683858275413513, Train Loss: 0.26181286573410034
[32m[0511 20:43:45 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.26838168501853943, Train Loss: 0.26180148124694824
[32m[0511 20:43:45 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.26837751269340515, Train Loss: 0.26179006695747375
[32m[0511 20:43:45 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.2683733403682709, Train Loss: 0.26177868247032166
[32m[0511 20:43:45 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.2683691680431366, Train Loss: 0.26176729798316956
[32m[0511 20:43:45 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.26836496591567993, Train Loss: 0.26175597310066223
[32m[0511 20:43:45 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.26836076378822327, Train Loss: 0.2617446184158325
[32m[0511 20:43:45 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.268356591463089, Train Loss: 0.2617332935333252
[32m[0511 20:43:45 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.2683523893356323, Train Loss: 0.26172199845314026
[32m[0511 20:43:45 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.26834818720817566, Train Loss: 0.2617107331752777
[32m[0511 20:43:45 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.268343985080719, Train Loss: 0.2616994380950928
[32m[0511 20:43:45 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.26833975315093994, Train Loss: 0.2616882026195526
[32m[0511 20:43:46 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.2683355212211609, Train Loss: 0.26167696714401245
[32m[0511 20:43:46 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.26833128929138184, Train Loss: 0.2616657316684723
[32m[0511 20:43:46 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.26832708716392517, Train Loss: 0.26165449619293213
[32m[0511 20:43:46 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.2683228552341461, Train Loss: 0.26164329051971436
[32m[0511 20:43:46 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.2683185935020447, Train Loss: 0.2616320848464966
[32m[0511 20:43:46 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.2683143615722656, Train Loss: 0.2616209089756012
[32m[0511 20:43:46 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.2683101296424866, Train Loss: 0.2616097629070282
[32m[0511 20:43:46 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.26830586791038513, Train Loss: 0.2615985870361328
[32m[0511 20:43:46 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.2683016359806061, Train Loss: 0.2615874111652374
[32m[0511 20:43:46 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.26829734444618225, Train Loss: 0.2615763247013092
[32m[0511 20:43:46 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.2682930827140808, Train Loss: 0.2615652084350586
[32m[0511 20:43:46 @mbmf_sampler.py:98][0m Finished 4th episode
[32m[0511 20:43:46 @mbmf_sampler.py:102][0m 2004 timesteps from 4 episodes collected
[32m[0511 21:09:54 @mbmf_trainer.py:160][0m Mean reward: -427.12455720566004
[32m[0511 21:09:54 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.27434536814689636, Train Loss: 0.2850852310657501
[32m[0511 21:09:54 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.2709622383117676, Train Loss: 0.28064486384391785
[32m[0511 21:09:54 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.2703845500946045, Train Loss: 0.28004053235054016
[32m[0511 21:09:54 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.2700762450695038, Train Loss: 0.2794021964073181
[32m[0511 21:09:54 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.26972150802612305, Train Loss: 0.27887582778930664
[32m[0511 21:09:55 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.26925358176231384, Train Loss: 0.2784394919872284
[32m[0511 21:09:55 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.2688591182231903, Train Loss: 0.2780691981315613
[32m[0511 21:09:55 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.2685166299343109, Train Loss: 0.2777332067489624
[32m[0511 21:09:55 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.26820623874664307, Train Loss: 0.2774224877357483
[32m[0511 21:09:55 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.2679176926612854, Train Loss: 0.2771354913711548
[32m[0511 21:09:55 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.2676496207714081, Train Loss: 0.27687007188796997
[32m[0511 21:09:55 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.26740214228630066, Train Loss: 0.27662384510040283
[32m[0511 21:09:55 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.26717278361320496, Train Loss: 0.2763943076133728
[32m[0511 21:09:55 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.26695966720581055, Train Loss: 0.2761797606945038
[32m[0511 21:09:55 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.26676106452941895, Train Loss: 0.275978684425354
[32m[0511 21:09:55 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.26657575368881226, Train Loss: 0.275789737701416
[32m[0511 21:09:55 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.26640257239341736, Train Loss: 0.27561187744140625
[32m[0511 21:09:55 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.2662403881549835, Train Loss: 0.27544403076171875
[32m[0511 21:09:55 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.2660883963108063, Train Loss: 0.27528536319732666
[32m[0511 21:09:55 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.265945702791214, Train Loss: 0.2751350402832031
[32m[0511 21:09:55 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.26581162214279175, Train Loss: 0.2749924063682556
[32m[0511 21:09:55 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.26568546891212463, Train Loss: 0.274856835603714
[32m[0511 21:09:55 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.2655666172504425, Train Loss: 0.2747277617454529
[32m[0511 21:09:55 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.26545462012290955, Train Loss: 0.2746046781539917
[32m[0511 21:09:55 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.265348881483078, Train Loss: 0.2744871973991394
[32m[0511 21:09:55 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.2652490437030792, Train Loss: 0.2743748128414154
[32m[0511 21:09:55 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.265154629945755, Train Loss: 0.27426719665527344
[32m[0511 21:09:55 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.2650653123855591, Train Loss: 0.27416402101516724
[32m[0511 21:09:55 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.2649807333946228, Train Loss: 0.2740649878978729
[32m[0511 21:09:55 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.2649005651473999, Train Loss: 0.27396976947784424
[32m[0511 21:09:55 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.2648245394229889, Train Loss: 0.27387818694114685
[32m[0511 21:09:55 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.26475241780281067, Train Loss: 0.2737899124622345
[32m[0511 21:09:55 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.2646838426589966, Train Loss: 0.27370476722717285
[32m[0511 21:09:56 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.26461872458457947, Train Loss: 0.2736225128173828
[32m[0511 21:09:56 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.26455673575401306, Train Loss: 0.27354303002357483
[32m[0511 21:09:56 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.2644977271556854, Train Loss: 0.2734661102294922
[32m[0511 21:09:56 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.2644415497779846, Train Loss: 0.2733915448188782
[32m[0511 21:09:56 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.26438796520233154, Train Loss: 0.273319274187088
[32m[0511 21:09:56 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.26433679461479187, Train Loss: 0.273249089717865
[32m[0511 21:09:56 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.2642880082130432, Train Loss: 0.27318090200424194
[32m[0511 21:09:56 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.26424136757850647, Train Loss: 0.27311456203460693
[32m[0511 21:09:56 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.2641967236995697, Train Loss: 0.2730499505996704
[32m[0511 21:09:56 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.2641540467739105, Train Loss: 0.2729870080947876
[32m[0511 21:09:56 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.2641131579875946, Train Loss: 0.27292558550834656
[32m[0511 21:09:56 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.2640739977359772, Train Loss: 0.2728656530380249
[32m[0511 21:09:56 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.2640364170074463, Train Loss: 0.2728070914745331
[32m[0511 21:09:56 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.2640003561973572, Train Loss: 0.27274978160858154
[32m[0511 21:09:56 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.2639656960964203, Train Loss: 0.2726937234401703
[32m[0511 21:09:56 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.26393240690231323, Train Loss: 0.27263879776000977
[32m[0511 21:09:56 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.2639003396034241, Train Loss: 0.2725849747657776
[32m[0511 21:09:56 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.2638695240020752, Train Loss: 0.2725321650505066
[32m[0511 21:09:56 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.2638397812843323, Train Loss: 0.2724803388118744
[32m[0511 21:09:56 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.2638111412525177, Train Loss: 0.2724294364452362
[32m[0511 21:09:56 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.2637834846973419, Train Loss: 0.27237939834594727
[32m[0511 21:09:56 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.26375681161880493, Train Loss: 0.2723301649093628
[32m[0511 21:09:56 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.2637310028076172, Train Loss: 0.2722817063331604
[32m[0511 21:09:56 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.2637060582637787, Train Loss: 0.2722340226173401
[32m[0511 21:09:56 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.26368194818496704, Train Loss: 0.2721870541572571
[32m[0511 21:09:56 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.2636585831642151, Train Loss: 0.2721407413482666
[32m[0511 21:09:56 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.26363593339920044, Train Loss: 0.27209505438804626
[32m[0511 21:09:57 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.2636139690876007, Train Loss: 0.2720499634742737
[32m[0511 21:09:57 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.2635926604270935, Train Loss: 0.27200546860694885
[32m[0511 21:09:57 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.26357194781303406, Train Loss: 0.271961510181427
[32m[0511 21:09:57 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.26355186104774475, Train Loss: 0.27191805839538574
[32m[0511 21:09:57 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.26353228092193604, Train Loss: 0.27187514305114746
[32m[0511 21:09:57 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.2635132670402527, Train Loss: 0.2718327045440674
[32m[0511 21:09:57 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.2634947597980499, Train Loss: 0.2717907130718231
[32m[0511 21:09:57 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.263476699590683, Train Loss: 0.2717491388320923
[32m[0511 21:09:57 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.26345914602279663, Train Loss: 0.27170801162719727
[32m[0511 21:09:57 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.2634419798851013, Train Loss: 0.2716672718524933
[32m[0511 21:09:57 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.2634252607822418, Train Loss: 0.27162694931030273
[32m[0511 21:09:57 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.263408899307251, Train Loss: 0.27158698439598083
[32m[0511 21:09:57 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.26339292526245117, Train Loss: 0.2715473175048828
[32m[0511 21:09:57 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.26337730884552, Train Loss: 0.27150803804397583
[32m[0511 21:09:57 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.26336202025413513, Train Loss: 0.2714691162109375
[32m[0511 21:09:57 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.2633470594882965, Train Loss: 0.27143049240112305
[32m[0511 21:09:57 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.26333242654800415, Train Loss: 0.27139216661453247
[32m[0511 21:09:57 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.26331809163093567, Train Loss: 0.2713541090488434
[32m[0511 21:09:57 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.2633039951324463, Train Loss: 0.2713163495063782
[32m[0511 21:09:57 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.2632901966571808, Train Loss: 0.27127891778945923
[32m[0511 21:09:57 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.26327669620513916, Train Loss: 0.2712416648864746
[32m[0511 21:09:57 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.26326340436935425, Train Loss: 0.27120471000671387
[32m[0511 21:09:57 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.26325035095214844, Train Loss: 0.2711679935455322
[32m[0511 21:09:57 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.26323750615119934, Train Loss: 0.27113157510757446
[32m[0511 21:09:57 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.26322486996650696, Train Loss: 0.271095335483551
[32m[0511 21:09:57 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.26321250200271606, Train Loss: 0.2710593342781067
[32m[0511 21:09:57 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.2632002830505371, Train Loss: 0.2710235118865967
[32m[0511 21:09:57 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.26318830251693726, Train Loss: 0.27098795771598816
[32m[0511 21:09:58 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.26317647099494934, Train Loss: 0.27095258235931396
[32m[0511 21:09:58 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.26316481828689575, Train Loss: 0.2709174156188965
[32m[0511 21:09:58 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.2631533443927765, Train Loss: 0.2708824574947357
[32m[0511 21:09:58 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.26314201951026917, Train Loss: 0.2708476781845093
[32m[0511 21:09:58 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.2631308436393738, Train Loss: 0.27081310749053955
[32m[0511 21:09:58 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.2631198763847351, Train Loss: 0.27077871561050415
[32m[0511 21:09:58 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.2631089985370636, Train Loss: 0.2707444429397583
[32m[0511 21:09:58 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.2630982995033264, Train Loss: 0.27071040868759155
[32m[0511 21:09:58 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.2630876898765564, Train Loss: 0.27067652344703674
[32m[0511 21:09:58 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.2630772590637207, Train Loss: 0.2706427574157715
[32m[0511 21:09:58 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.2630669176578522, Train Loss: 0.27060920000076294
[32m[0511 21:09:58 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.26305675506591797, Train Loss: 0.27057579159736633
[32m[0511 21:09:58 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.26304665207862854, Train Loss: 0.27054256200790405
[32m[0511 21:09:58 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.26303666830062866, Train Loss: 0.2705094516277313
[32m[0511 21:09:58 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.26302680373191833, Train Loss: 0.2704765200614929
[32m[0511 21:09:58 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.26301705837249756, Train Loss: 0.27044370770454407
[32m[0511 21:09:58 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.26300743222236633, Train Loss: 0.27041101455688477
[32m[0511 21:09:58 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.2629978656768799, Train Loss: 0.2703785300254822
[32m[0511 21:09:58 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.2629883885383606, Train Loss: 0.27034613490104675
[32m[0511 21:09:58 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.26297903060913086, Train Loss: 0.27031388878822327
[32m[0511 21:09:58 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.2629697620868683, Train Loss: 0.2702817916870117
[32m[0511 21:09:58 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.2629605829715729, Train Loss: 0.27024978399276733
[32m[0511 21:09:58 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.26295146346092224, Train Loss: 0.2702179253101349
[32m[0511 21:09:58 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.26294246315956116, Train Loss: 0.2701862156391144
[32m[0511 21:09:58 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.26293352246284485, Train Loss: 0.27015459537506104
[32m[0511 21:09:58 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.2629246413707733, Train Loss: 0.27012312412261963
[32m[0511 21:09:58 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.2629159092903137, Train Loss: 0.2700917720794678
[32m[0511 21:09:59 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.2629071772098541, Train Loss: 0.27006053924560547
[32m[0511 21:09:59 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.2628985643386841, Train Loss: 0.2700294256210327
[32m[0511 21:09:59 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.2628900110721588, Train Loss: 0.2699984312057495
[32m[0511 21:09:59 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.26288148760795593, Train Loss: 0.26996755599975586
[32m[0511 21:09:59 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.2628730535507202, Train Loss: 0.26993677020072937
[32m[0511 21:09:59 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.26286473870277405, Train Loss: 0.26990610361099243
[32m[0511 21:09:59 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.2628564238548279, Train Loss: 0.26987558603286743
[32m[0511 21:09:59 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.2628481686115265, Train Loss: 0.2698451578617096
[32m[0511 21:09:59 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.26284000277519226, Train Loss: 0.2698148190975189
[32m[0511 21:09:59 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.2628318667411804, Train Loss: 0.2697846293449402
[32m[0511 21:09:59 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.26282382011413574, Train Loss: 0.2697545289993286
[32m[0511 21:09:59 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.26281583309173584, Train Loss: 0.2697245478630066
[32m[0511 21:09:59 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.26280784606933594, Train Loss: 0.26969462633132935
[32m[0511 21:09:59 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.2627999484539032, Train Loss: 0.2696648836135864
[32m[0511 21:09:59 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.26279211044311523, Train Loss: 0.2696351706981659
[32m[0511 21:09:59 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.26278427243232727, Train Loss: 0.2696056365966797
[32m[0511 21:09:59 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.26277655363082886, Train Loss: 0.26957613229751587
[32m[0511 21:09:59 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.26276883482933044, Train Loss: 0.269546777009964
[32m[0511 21:09:59 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.2627611458301544, Train Loss: 0.2695175111293793
[32m[0511 21:09:59 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.26275354623794556, Train Loss: 0.2694883346557617
[32m[0511 21:09:59 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.26274600625038147, Train Loss: 0.2694593071937561
[32m[0511 21:09:59 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.262738436460495, Train Loss: 0.26943033933639526
[32m[0511 21:09:59 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.2627309560775757, Train Loss: 0.269401490688324
[32m[0511 21:09:59 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.26272353529930115, Train Loss: 0.26937270164489746
[32m[0511 21:09:59 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.2627161145210266, Train Loss: 0.2693440318107605
[32m[0511 21:09:59 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.26270878314971924, Train Loss: 0.2693154811859131
[32m[0511 21:09:59 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.2627014219760895, Train Loss: 0.26928699016571045
[32m[0511 21:09:59 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.2626941204071045, Train Loss: 0.26925861835479736
[32m[0511 21:09:59 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.26268690824508667, Train Loss: 0.26923033595085144
[32m[0511 21:10:00 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.26267966628074646, Train Loss: 0.26920217275619507
[32m[0511 21:10:00 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.26267245411872864, Train Loss: 0.26917409896850586
[32m[0511 21:10:00 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.2626653015613556, Train Loss: 0.2691460847854614
[32m[0511 21:10:00 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.2626582086086273, Train Loss: 0.26911818981170654
[32m[0511 21:10:00 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.26265111565589905, Train Loss: 0.26909035444259644
[32m[0511 21:10:00 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.2626440227031708, Train Loss: 0.26906266808509827
[32m[0511 21:10:00 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.26263701915740967, Train Loss: 0.2690350413322449
[32m[0511 21:10:00 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.26263001561164856, Train Loss: 0.26900750398635864
[32m[0511 21:10:00 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.2626230716705322, Train Loss: 0.26898008584976196
[32m[0511 21:10:00 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.2626160979270935, Train Loss: 0.26895272731781006
[32m[0511 21:10:00 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.26260918378829956, Train Loss: 0.2689254879951477
[32m[0511 21:10:00 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.262602299451828, Train Loss: 0.2688983082771301
[32m[0511 21:10:00 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.26259544491767883, Train Loss: 0.2688712179660797
[32m[0511 21:10:00 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.26258859038352966, Train Loss: 0.26884421706199646
[32m[0511 21:10:00 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.2625817656517029, Train Loss: 0.26881730556488037
[32m[0511 21:10:00 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.2625750005245209, Train Loss: 0.26879051327705383
[32m[0511 21:10:00 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.26256823539733887, Train Loss: 0.26876378059387207
[32m[0511 21:10:00 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.26256147027015686, Train Loss: 0.26873713731765747
[32m[0511 21:10:00 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.26255476474761963, Train Loss: 0.26871055364608765
[32m[0511 21:10:00 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.2625480592250824, Train Loss: 0.2686840891838074
[32m[0511 21:10:00 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.26254135370254517, Train Loss: 0.2686576843261719
[32m[0511 21:10:00 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.2625347077846527, Train Loss: 0.2686313986778259
[32m[0511 21:10:00 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.26252806186676025, Train Loss: 0.26860517263412476
[32m[0511 21:10:00 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.2625214159488678, Train Loss: 0.26857900619506836
[32m[0511 21:10:00 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.2625148296356201, Train Loss: 0.2685529589653015
[32m[0511 21:10:00 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.26250821352005005, Train Loss: 0.26852697134017944
[32m[0511 21:10:00 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.26250165700912476, Train Loss: 0.26850107312202454
[32m[0511 21:10:01 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.26249513030052185, Train Loss: 0.2684752643108368
[32m[0511 21:10:01 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.26248857378959656, Train Loss: 0.2684495449066162
[32m[0511 21:10:01 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.26248201727867126, Train Loss: 0.268423855304718
[32m[0511 21:10:01 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.26247552037239075, Train Loss: 0.2683982849121094
[32m[0511 21:10:01 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.2624690532684326, Train Loss: 0.2683727741241455
[32m[0511 21:10:01 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.2624625563621521, Train Loss: 0.2683473229408264
[32m[0511 21:10:01 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.26245608925819397, Train Loss: 0.2683219909667969
[32m[0511 21:10:01 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.26244962215423584, Train Loss: 0.2682966887950897
[32m[0511 21:10:01 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.2624431550502777, Train Loss: 0.2682715058326721
[32m[0511 21:10:01 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.26243674755096436, Train Loss: 0.2682463824748993
[32m[0511 21:10:01 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.262430340051651, Train Loss: 0.26822131872177124
[32m[0511 21:10:01 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.26242393255233765, Train Loss: 0.26819634437561035
[32m[0511 21:10:01 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.2624175250530243, Train Loss: 0.26817142963409424
[32m[0511 21:10:01 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.26241111755371094, Train Loss: 0.2681465744972229
[32m[0511 21:10:01 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.26240473985671997, Train Loss: 0.2681218087673187
[32m[0511 21:10:01 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.262398362159729, Train Loss: 0.2680971026420593
[32m[0511 21:10:01 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.2623920440673828, Train Loss: 0.2680724859237671
[32m[0511 21:10:01 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.26238569617271423, Train Loss: 0.26804792881011963
[32m[0511 21:10:01 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.26237931847572327, Train Loss: 0.26802343130111694
[32m[0511 21:10:01 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.2623730003833771, Train Loss: 0.26799899339675903
[32m[0511 21:10:01 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.2623666524887085, Train Loss: 0.2679746747016907
[32m[0511 21:10:01 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.2623603343963623, Train Loss: 0.2679504156112671
[32m[0511 21:10:01 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.2623540163040161, Train Loss: 0.2679262161254883
[32m[0511 21:10:01 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.2623477280139923, Train Loss: 0.26790204644203186
[32m[0511 21:10:01 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.2623414099216461, Train Loss: 0.2678779363632202
[32m[0511 21:10:01 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.2623351216316223, Train Loss: 0.2678539454936981
[32m[0511 21:10:01 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.2623288631439209, Train Loss: 0.267829954624176
[32m[0511 21:10:01 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.2623225450515747, Train Loss: 0.26780611276626587
[32m[0511 21:10:02 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.2623162567615509, Train Loss: 0.2677822709083557
[32m[0511 21:10:02 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.2623099982738495, Train Loss: 0.2677585184574127
[32m[0511 21:10:02 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.26230373978614807, Train Loss: 0.2677348256111145
[32m[0511 21:10:02 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.26229745149612427, Train Loss: 0.26771119236946106
[32m[0511 21:10:02 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.26229122281074524, Train Loss: 0.2676876187324524
[32m[0511 21:10:02 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.2622849643230438, Train Loss: 0.2676641345024109
[32m[0511 21:10:02 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.2622787058353424, Train Loss: 0.2676406800746918
[32m[0511 21:10:02 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.2622724771499634, Train Loss: 0.26761728525161743
[32m[0511 21:10:02 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.26226624846458435, Train Loss: 0.26759397983551025
[32m[0511 21:10:02 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.26225996017456055, Train Loss: 0.26757073402404785
[32m[0511 21:10:02 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.2622537314891815, Train Loss: 0.26754751801490784
[32m[0511 21:10:02 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.2622475028038025, Train Loss: 0.267524391412735
[32m[0511 21:10:02 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.26224127411842346, Train Loss: 0.2675012946128845
[32m[0511 21:10:02 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.26223504543304443, Train Loss: 0.2674782872200012
[32m[0511 21:10:02 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.262228786945343, Train Loss: 0.2674552798271179
[32m[0511 21:10:02 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.2622225880622864, Train Loss: 0.26743239164352417
[32m[0511 21:10:02 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.26221632957458496, Train Loss: 0.2674095630645752
[32m[0511 21:10:02 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.2622101306915283, Train Loss: 0.2673867344856262
[32m[0511 21:10:02 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.2622038722038269, Train Loss: 0.2673640251159668
[32m[0511 21:10:02 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.26219767332077026, Train Loss: 0.26734137535095215
[32m[0511 21:10:02 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.26219144463539124, Train Loss: 0.2673187255859375
[32m[0511 21:10:02 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.2621852457523346, Train Loss: 0.2672961950302124
[32m[0511 21:10:02 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.26217901706695557, Train Loss: 0.2672736644744873
[32m[0511 21:10:02 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.2621728181838989, Train Loss: 0.26725122332572937
[32m[0511 21:10:02 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.2621665596961975, Train Loss: 0.2672288119792938
[32m[0511 21:10:02 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.26216036081314087, Train Loss: 0.26720649003982544
[32m[0511 21:10:02 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.26215416193008423, Train Loss: 0.26718422770500183
[32m[0511 21:10:02 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.2621479332447052, Train Loss: 0.2671619653701782
[32m[0511 21:10:03 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.26214173436164856, Train Loss: 0.26713982224464417
[32m[0511 21:10:03 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.26213550567626953, Train Loss: 0.2671177089214325
[32m[0511 21:10:03 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.2621293067932129, Train Loss: 0.2670956254005432
[32m[0511 21:10:03 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.26212310791015625, Train Loss: 0.2670736312866211
[32m[0511 21:10:03 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.26211684942245483, Train Loss: 0.267051637172699
[32m[0511 21:10:03 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.2621106505393982, Train Loss: 0.2670297622680664
[32m[0511 21:10:03 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.26210442185401917, Train Loss: 0.26700788736343384
[32m[0511 21:10:03 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.26209819316864014, Train Loss: 0.26698610186576843
[32m[0511 21:10:03 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.2620919942855835, Train Loss: 0.2669643461704254
[32m[0511 21:10:03 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.26208576560020447, Train Loss: 0.26694267988204956
[32m[0511 21:10:03 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.26207953691482544, Train Loss: 0.2669210433959961
[32m[0511 21:10:03 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.2620733082294464, Train Loss: 0.2668994665145874
[32m[0511 21:10:03 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.26206710934638977, Train Loss: 0.2668779492378235
[32m[0511 21:10:03 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.26206088066101074, Train Loss: 0.26685646176338196
[32m[0511 21:10:03 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.2620546519756317, Train Loss: 0.2668350338935852
[32m[0511 21:10:03 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.2620484232902527, Train Loss: 0.26681363582611084
[32m[0511 21:10:03 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.26204222440719604, Train Loss: 0.26679229736328125
[32m[0511 21:10:03 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.262035995721817, Train Loss: 0.2667710483074188
[32m[0511 21:10:03 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.2620297372341156, Train Loss: 0.2667498290538788
[32m[0511 21:10:03 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.2620235085487366, Train Loss: 0.26672863960266113
[32m[0511 21:10:03 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.26201727986335754, Train Loss: 0.26670753955841064
[32m[0511 21:10:03 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.2620110511779785, Train Loss: 0.26668649911880493
[32m[0511 21:10:03 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.2620048224925995, Train Loss: 0.2666654586791992
[32m[0511 21:10:03 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.26199856400489807, Train Loss: 0.2666444778442383
[32m[0511 21:10:03 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.26199236512184143, Train Loss: 0.2666235566139221
[32m[0511 21:10:03 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.26198610663414, Train Loss: 0.26660269498825073
[32m[0511 21:10:03 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.2619799077510834, Train Loss: 0.2665818929672241
[32m[0511 21:10:04 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.26197361946105957, Train Loss: 0.2665611207485199
[32m[0511 21:10:04 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.26196739077568054, Train Loss: 0.26654040813446045
[32m[0511 21:10:04 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.2619611322879791, Train Loss: 0.2665197551250458
[32m[0511 21:10:04 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.2619549036026001, Train Loss: 0.2664991021156311
[32m[0511 21:10:04 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.2619486451148987, Train Loss: 0.266478568315506
[32m[0511 21:10:04 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.26194238662719727, Train Loss: 0.26645806431770325
[32m[0511 21:10:04 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.26193612813949585, Train Loss: 0.2664375901222229
[32m[0511 21:10:04 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.26192986965179443, Train Loss: 0.26641717553138733
[32m[0511 21:10:04 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.2619236409664154, Train Loss: 0.26639682054519653
[32m[0511 21:10:04 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.261917382478714, Train Loss: 0.2663764953613281
[32m[0511 21:10:04 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.2619110941886902, Train Loss: 0.2663562297821045
[32m[0511 21:10:04 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.26190486550331116, Train Loss: 0.26633602380752563
[32m[0511 21:10:04 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.26189860701560974, Train Loss: 0.26631584763526917
[32m[0511 21:10:04 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.2618923485279083, Train Loss: 0.26629573106765747
[32m[0511 21:10:04 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.2618860602378845, Train Loss: 0.26627564430236816
[32m[0511 21:10:04 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.2618798315525055, Train Loss: 0.2662556767463684
[32m[0511 21:10:04 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.2618735432624817, Train Loss: 0.26623567938804626
[32m[0511 21:10:04 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.2618672847747803, Train Loss: 0.2662157714366913
[32m[0511 21:10:04 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.26186099648475647, Train Loss: 0.2661958932876587
[32m[0511 21:10:04 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.26185473799705505, Train Loss: 0.2661760747432709
[32m[0511 21:10:04 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.26184847950935364, Train Loss: 0.26615628600120544
[32m[0511 21:10:04 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.2618422210216522, Train Loss: 0.2661365866661072
[32m[0511 21:10:04 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.2618359327316284, Train Loss: 0.2661169171333313
[32m[0511 21:10:04 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.261829674243927, Train Loss: 0.2660972476005554
[32m[0511 21:10:04 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.2618234157562256, Train Loss: 0.2660776972770691
[32m[0511 21:10:04 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.2618171274662018, Train Loss: 0.26605817675590515
[32m[0511 21:10:04 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.26181086897850037, Train Loss: 0.266038715839386
[32m[0511 21:10:04 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.26180458068847656, Train Loss: 0.2660192549228668
[32m[0511 21:10:05 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.26179835200309753, Train Loss: 0.2659998834133148
[32m[0511 21:10:05 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.26179206371307373, Train Loss: 0.2659805417060852
[32m[0511 21:10:05 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.2617858052253723, Train Loss: 0.265961229801178
[32m[0511 21:10:05 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.2617795169353485, Train Loss: 0.2659420371055603
[32m[0511 21:10:05 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.2617732882499695, Train Loss: 0.26592281460762024
[32m[0511 21:10:05 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.26176702976226807, Train Loss: 0.26590368151664734
[32m[0511 21:10:05 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.26176074147224426, Train Loss: 0.2658845782279968
[32m[0511 21:10:05 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.26175448298454285, Train Loss: 0.2658655345439911
[32m[0511 21:10:05 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.26174822449684143, Train Loss: 0.2658465504646301
[32m[0511 21:10:05 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.26174196600914, Train Loss: 0.26582759618759155
[32m[0511 21:10:05 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.2617357075214386, Train Loss: 0.26580870151519775
[32m[0511 21:10:05 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.2617294490337372, Train Loss: 0.26578986644744873
[32m[0511 21:10:05 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.26172319054603577, Train Loss: 0.2657710611820221
[32m[0511 21:10:05 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.26171696186065674, Train Loss: 0.26575228571891785
[32m[0511 21:10:05 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.2617107331752777, Train Loss: 0.2657335698604584
[32m[0511 21:10:05 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.2617045044898987, Train Loss: 0.2657149136066437
[32m[0511 21:10:05 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.26169824600219727, Train Loss: 0.26569628715515137
[32m[0511 21:10:05 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.26169198751449585, Train Loss: 0.2656777501106262
[32m[0511 21:10:05 @mbmf_sampler.py:98][0m Finished 4th episode
[32m[0511 21:10:05 @mbmf_sampler.py:102][0m 2004 timesteps from 4 episodes collected
[32m[0511 21:36:09 @mbmf_trainer.py:160][0m Mean reward: -424.5591240360076
[32m[0511 21:36:09 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.27114707231521606, Train Loss: 0.2833152115345001
[32m[0511 21:36:09 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.2708059847354889, Train Loss: 0.282422810792923
[32m[0511 21:36:09 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.2706198990345001, Train Loss: 0.2818744480609894
[32m[0511 21:36:09 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.27039793133735657, Train Loss: 0.28142401576042175
[32m[0511 21:36:09 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.27016350626945496, Train Loss: 0.28103551268577576
[32m[0511 21:36:09 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.2699587345123291, Train Loss: 0.28070032596588135
[32m[0511 21:36:10 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.2697683870792389, Train Loss: 0.28039366006851196
[32m[0511 21:36:10 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.2695958614349365, Train Loss: 0.2801194190979004
[32m[0511 21:36:10 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.2694370746612549, Train Loss: 0.2798697054386139
[32m[0511 21:36:10 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.26929014921188354, Train Loss: 0.27964064478874207
[32m[0511 21:36:10 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.26915374398231506, Train Loss: 0.2794298231601715
[32m[0511 21:36:10 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.269026517868042, Train Loss: 0.2792345881462097
[32m[0511 21:36:10 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.26890748739242554, Train Loss: 0.27905288338661194
[32m[0511 21:36:10 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.26879581809043884, Train Loss: 0.27888306975364685
[32m[0511 21:36:10 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.26869070529937744, Train Loss: 0.278723806142807
[32m[0511 21:36:10 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.2685915529727936, Train Loss: 0.27857378125190735
[32m[0511 21:36:10 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.26849764585494995, Train Loss: 0.27843210101127625
[32m[0511 21:36:10 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.26840856671333313, Train Loss: 0.2782977521419525
[32m[0511 21:36:10 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.26832374930381775, Train Loss: 0.27817001938819885
[32m[0511 21:36:10 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.26824283599853516, Train Loss: 0.27804824709892273
[32m[0511 21:36:10 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.2681654691696167, Train Loss: 0.2779318392276764
[32m[0511 21:36:10 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.2680912911891937, Train Loss: 0.27782028913497925
[32m[0511 21:36:10 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.26802003383636475, Train Loss: 0.2777131199836731
[32m[0511 21:36:10 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.2679513692855835, Train Loss: 0.27761000394821167
[32m[0511 21:36:10 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.26788511872291565, Train Loss: 0.27751052379608154
[32m[0511 21:36:10 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.26782113313674927, Train Loss: 0.2774144113063812
[32m[0511 21:36:10 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.2677591145038605, Train Loss: 0.27732139825820923
[32m[0511 21:36:10 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.2676990032196045, Train Loss: 0.2772311270236969
[32m[0511 21:36:10 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.2676405608654022, Train Loss: 0.27714356780052185
[32m[0511 21:36:11 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.2675837278366089, Train Loss: 0.2770583927631378
[32m[0511 21:36:11 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.26752835512161255, Train Loss: 0.27697548270225525
[32m[0511 21:36:11 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.26747435331344604, Train Loss: 0.27689462900161743
[32m[0511 21:36:11 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.2674216032028198, Train Loss: 0.2768157124519348
[32m[0511 21:36:11 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.2673700153827667, Train Loss: 0.27673864364624023
[32m[0511 21:36:11 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.26731958985328674, Train Loss: 0.27666327357292175
[32m[0511 21:36:11 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.26727014780044556, Train Loss: 0.2765894830226898
[32m[0511 21:36:11 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.26722168922424316, Train Loss: 0.27651724219322205
[32m[0511 21:36:11 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.26717421412467957, Train Loss: 0.2764463722705841
[32m[0511 21:36:11 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.26712754368782043, Train Loss: 0.276376873254776
[32m[0511 21:36:11 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.2670817971229553, Train Loss: 0.2763085961341858
[32m[0511 21:36:11 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.2670367658138275, Train Loss: 0.2762415409088135
[32m[0511 21:36:11 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.2669925093650818, Train Loss: 0.2761755883693695
[32m[0511 21:36:11 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.26694899797439575, Train Loss: 0.27611076831817627
[32m[0511 21:36:11 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.266906201839447, Train Loss: 0.2760470509529114
[32m[0511 21:36:11 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.2668640613555908, Train Loss: 0.2759841978549957
[32m[0511 21:36:11 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.26682260632514954, Train Loss: 0.27592235803604126
[32m[0511 21:36:11 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.2667817175388336, Train Loss: 0.2758614122867584
[32m[0511 21:36:11 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.26674145460128784, Train Loss: 0.2758013904094696
[32m[0511 21:36:11 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.2667018175125122, Train Loss: 0.2757421135902405
[32m[0511 21:36:11 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.26666274666786194, Train Loss: 0.2756836712360382
[32m[0511 21:36:11 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.26662421226501465, Train Loss: 0.2756260335445404
[32m[0511 21:36:11 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.26658621430397034, Train Loss: 0.2755691111087799
[32m[0511 21:36:11 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.2665488123893738, Train Loss: 0.2755129039287567
[32m[0511 21:36:12 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.26651185750961304, Train Loss: 0.27545738220214844
[32m[0511 21:36:12 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.26647546887397766, Train Loss: 0.2754025459289551
[32m[0511 21:36:12 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.2664395868778229, Train Loss: 0.27534836530685425
[32m[0511 21:36:12 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.2664041221141815, Train Loss: 0.27529484033584595
[32m[0511 21:36:12 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.26636919379234314, Train Loss: 0.2752419114112854
[32m[0511 21:36:12 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.2663347125053406, Train Loss: 0.27518948912620544
[32m[0511 21:36:12 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.26630067825317383, Train Loss: 0.2751377522945404
[32m[0511 21:36:12 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.26626715064048767, Train Loss: 0.27508655190467834
[32m[0511 21:36:12 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.26623398065567017, Train Loss: 0.2750358581542969
[32m[0511 21:36:12 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.26620134711265564, Train Loss: 0.2749857008457184
[32m[0511 21:36:12 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.26616910099983215, Train Loss: 0.2749360203742981
[32m[0511 21:36:12 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.2661373019218445, Train Loss: 0.2748868763446808
[32m[0511 21:36:12 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.26610589027404785, Train Loss: 0.2748382091522217
[32m[0511 21:36:12 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.26607489585876465, Train Loss: 0.27479004859924316
[32m[0511 21:36:12 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.2660442888736725, Train Loss: 0.2747423052787781
[32m[0511 21:36:12 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.26601409912109375, Train Loss: 0.27469494938850403
[32m[0511 21:36:12 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.26598429679870605, Train Loss: 0.27464810013771057
[32m[0511 21:36:12 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.2659548819065094, Train Loss: 0.27460166811943054
[32m[0511 21:36:12 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.2659257650375366, Train Loss: 0.27455568313598633
[32m[0511 21:36:12 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.26589712500572205, Train Loss: 0.27451008558273315
[32m[0511 21:36:12 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.26586878299713135, Train Loss: 0.27446484565734863
[32m[0511 21:36:12 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.2658407688140869, Train Loss: 0.27442002296447754
[32m[0511 21:36:12 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.2658131718635559, Train Loss: 0.2743755578994751
[32m[0511 21:36:13 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.2657858729362488, Train Loss: 0.2743314206600189
[32m[0511 21:36:13 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.2657589316368103, Train Loss: 0.2742876708507538
[32m[0511 21:36:13 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.2657323181629181, Train Loss: 0.2742443084716797
[32m[0511 21:36:13 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.26570606231689453, Train Loss: 0.27420124411582947
[32m[0511 21:36:13 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.2656800448894501, Train Loss: 0.2741585671901703
[32m[0511 21:36:13 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.26565444469451904, Train Loss: 0.2741161286830902
[32m[0511 21:36:13 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.2656290829181671, Train Loss: 0.27407407760620117
[32m[0511 21:36:13 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.26560401916503906, Train Loss: 0.2740323543548584
[32m[0511 21:36:13 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.2655792832374573, Train Loss: 0.2739908695220947
[32m[0511 21:36:13 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.265554815530777, Train Loss: 0.2739497125148773
[32m[0511 21:36:13 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.26553061604499817, Train Loss: 0.2739088833332062
[32m[0511 21:36:13 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.2655067443847656, Train Loss: 0.27386829257011414
[32m[0511 21:36:13 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.26548317074775696, Train Loss: 0.27382805943489075
[32m[0511 21:36:13 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.2654598355293274, Train Loss: 0.27378806471824646
[32m[0511 21:36:13 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.2654367685317993, Train Loss: 0.2737482786178589
[32m[0511 21:36:13 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.26541393995285034, Train Loss: 0.2737087607383728
[32m[0511 21:36:13 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.26539137959480286, Train Loss: 0.2736695408821106
[32m[0511 21:36:13 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.26536911725997925, Train Loss: 0.2736305296421051
[32m[0511 21:36:13 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.26534703373908997, Train Loss: 0.2735918462276459
[32m[0511 21:36:13 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.26532527804374695, Train Loss: 0.27355334162712097
[32m[0511 21:36:13 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.26530370116233826, Train Loss: 0.27351513504981995
[32m[0511 21:36:13 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.26528239250183105, Train Loss: 0.27347713708877563
[32m[0511 21:36:13 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.26526129245758057, Train Loss: 0.27343931794166565
[32m[0511 21:36:14 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.2652404308319092, Train Loss: 0.27340179681777954
[32m[0511 21:36:14 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.2652197778224945, Train Loss: 0.27336445450782776
[32m[0511 21:36:14 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.26519936323165894, Train Loss: 0.2733273506164551
[32m[0511 21:36:14 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.2651791572570801, Train Loss: 0.2732904553413391
[32m[0511 21:36:14 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.2651591897010803, Train Loss: 0.27325373888015747
[32m[0511 21:36:14 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.2651394009590149, Train Loss: 0.27321726083755493
[32m[0511 21:36:14 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.2651197612285614, Train Loss: 0.2731809914112091
[32m[0511 21:36:14 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.2651004493236542, Train Loss: 0.2731449007987976
[32m[0511 21:36:14 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.2650812864303589, Train Loss: 0.2731090486049652
[32m[0511 21:36:14 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.26506227254867554, Train Loss: 0.27307334542274475
[32m[0511 21:36:14 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.2650434970855713, Train Loss: 0.2730378210544586
[32m[0511 21:36:14 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.26502490043640137, Train Loss: 0.2730025053024292
[32m[0511 21:36:14 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.26500648260116577, Train Loss: 0.2729673683643341
[32m[0511 21:36:14 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.2649882435798645, Train Loss: 0.27293241024017334
[32m[0511 21:36:14 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.26497021317481995, Train Loss: 0.2728976309299469
[32m[0511 21:36:14 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.2649523615837097, Train Loss: 0.2728630006313324
[32m[0511 21:36:14 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.2649346590042114, Train Loss: 0.272828608751297
[32m[0511 21:36:14 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.26491713523864746, Train Loss: 0.27279433608055115
[32m[0511 21:36:14 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.2648998200893402, Train Loss: 0.27276021242141724
[32m[0511 21:36:14 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.2648825943470001, Train Loss: 0.27272629737854004
[32m[0511 21:36:14 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.26486560702323914, Train Loss: 0.2726925313472748
[32m[0511 21:36:14 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.2648487687110901, Train Loss: 0.27265891432762146
[32m[0511 21:36:14 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.26483210921287537, Train Loss: 0.27262550592422485
[32m[0511 21:36:14 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.26481562852859497, Train Loss: 0.272592157125473
[32m[0511 21:36:15 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.26479923725128174, Train Loss: 0.2725590467453003
[32m[0511 21:36:15 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.26478302478790283, Train Loss: 0.2725260257720947
[32m[0511 21:36:15 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.26476702094078064, Train Loss: 0.2724931836128235
[32m[0511 21:36:15 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.2647510766983032, Train Loss: 0.27246055006980896
[32m[0511 21:36:15 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.26473531126976013, Train Loss: 0.2724279761314392
[32m[0511 21:36:15 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.264719694852829, Train Loss: 0.2723955810070038
[32m[0511 21:36:15 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.26470425724983215, Train Loss: 0.2723633050918579
[32m[0511 21:36:15 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.26468896865844727, Train Loss: 0.27233120799064636
[32m[0511 21:36:15 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.26467379927635193, Train Loss: 0.272299200296402
[32m[0511 21:36:15 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.26465877890586853, Train Loss: 0.2722673714160919
[32m[0511 21:36:15 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.2646438777446747, Train Loss: 0.272235631942749
[32m[0511 21:36:15 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.2646291255950928, Train Loss: 0.27220410108566284
[32m[0511 21:36:15 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.2646144926548004, Train Loss: 0.27217262983322144
[32m[0511 21:36:15 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.26460000872612, Train Loss: 0.27214136719703674
[32m[0511 21:36:15 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.2645856440067291, Train Loss: 0.2721101641654968
[32m[0511 21:36:15 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.2645714581012726, Train Loss: 0.27207911014556885
[32m[0511 21:36:15 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.2645573318004608, Train Loss: 0.2720482349395752
[32m[0511 21:36:15 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.2645433843135834, Train Loss: 0.27201738953590393
[32m[0511 21:36:15 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.2645295262336731, Train Loss: 0.271986722946167
[32m[0511 21:36:15 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.26451584696769714, Train Loss: 0.2719561457633972
[32m[0511 21:36:15 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.26450225710868835, Train Loss: 0.27192577719688416
[32m[0511 21:36:15 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.2644887864589691, Train Loss: 0.2718954384326935
[32m[0511 21:36:15 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.26447540521621704, Train Loss: 0.27186524868011475
[32m[0511 21:36:15 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.2644621729850769, Train Loss: 0.27183517813682556
[32m[0511 21:36:16 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.2644490897655487, Train Loss: 0.2718052566051483
[32m[0511 21:36:16 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.2644360661506653, Train Loss: 0.27177539467811584
[32m[0511 21:36:16 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.2644231617450714, Train Loss: 0.2717457115650177
[32m[0511 21:36:16 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.2644104063510895, Train Loss: 0.27171608805656433
[32m[0511 21:36:16 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.2643977701663971, Train Loss: 0.2716866433620453
[32m[0511 21:36:16 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.2643851935863495, Train Loss: 0.271657258272171
[32m[0511 21:36:16 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.26437273621559143, Train Loss: 0.2716279923915863
[32m[0511 21:36:16 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.2643603980541229, Train Loss: 0.27159884572029114
[32m[0511 21:36:16 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.2643481492996216, Train Loss: 0.27156978845596313
[32m[0511 21:36:16 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.2643360495567322, Train Loss: 0.27154088020324707
[32m[0511 21:36:16 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.26432403922080994, Train Loss: 0.2715120315551758
[32m[0511 21:36:16 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.26431211829185486, Train Loss: 0.27148333191871643
[32m[0511 21:36:16 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.26430028676986694, Train Loss: 0.27145469188690186
[32m[0511 21:36:16 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.2642885744571686, Train Loss: 0.2714262008666992
[32m[0511 21:36:16 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.2642769515514374, Train Loss: 0.27139782905578613
[32m[0511 21:36:16 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.26426541805267334, Train Loss: 0.27136948704719543
[32m[0511 21:36:16 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.2642539441585541, Train Loss: 0.2713412940502167
[32m[0511 21:36:16 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.26424261927604675, Train Loss: 0.27131322026252747
[32m[0511 21:36:16 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.2642313838005066, Train Loss: 0.27128517627716064
[32m[0511 21:36:16 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.2642202079296112, Train Loss: 0.27125731110572815
[32m[0511 21:36:16 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.26420915126800537, Train Loss: 0.27122950553894043
[32m[0511 21:36:16 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.2641981840133667, Train Loss: 0.27120184898376465
[32m[0511 21:36:16 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.2641873061656952, Train Loss: 0.27117422223091125
[32m[0511 21:36:17 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.2641764283180237, Train Loss: 0.2711467146873474
[32m[0511 21:36:17 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.2641657292842865, Train Loss: 0.2711193263530731
[32m[0511 21:36:17 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.2641550302505493, Train Loss: 0.271092027425766
[32m[0511 21:36:17 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.26414453983306885, Train Loss: 0.271064817905426
[32m[0511 21:36:17 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.264134019613266, Train Loss: 0.2710376977920532
[32m[0511 21:36:17 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.2641235888004303, Train Loss: 0.2710106670856476
[32m[0511 21:36:17 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.26411327719688416, Train Loss: 0.2709837555885315
[32m[0511 21:36:17 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.2641030251979828, Train Loss: 0.27095693349838257
[32m[0511 21:36:17 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.2640928626060486, Train Loss: 0.27093014121055603
[32m[0511 21:36:17 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.26408272981643677, Train Loss: 0.27090349793434143
[32m[0511 21:36:17 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.2640727162361145, Train Loss: 0.270876944065094
[32m[0511 21:36:17 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.264062762260437, Train Loss: 0.2708504796028137
[32m[0511 21:36:17 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.2640528678894043, Train Loss: 0.2708240747451782
[32m[0511 21:36:17 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.2640429735183716, Train Loss: 0.2707977592945099
[32m[0511 21:36:17 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.2640332281589508, Train Loss: 0.2707715928554535
[32m[0511 21:36:17 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.2640235424041748, Train Loss: 0.2707454264163971
[32m[0511 21:36:17 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.2640139162540436, Train Loss: 0.270719438791275
[32m[0511 21:36:17 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.26400431990623474, Train Loss: 0.27069342136383057
[32m[0511 21:36:17 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.26399484276771545, Train Loss: 0.2706676125526428
[32m[0511 21:36:17 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.2639853358268738, Train Loss: 0.2706417739391327
[32m[0511 21:36:17 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.26397597789764404, Train Loss: 0.2706161141395569
[32m[0511 21:36:17 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.2639666795730591, Train Loss: 0.27059048414230347
[32m[0511 21:36:17 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.2639573812484741, Train Loss: 0.2705649435520172
[32m[0511 21:36:18 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.2639481723308563, Train Loss: 0.2705395221710205
[32m[0511 21:36:18 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.2639389634132385, Train Loss: 0.2705141603946686
[32m[0511 21:36:18 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.26392990350723267, Train Loss: 0.27048882842063904
[32m[0511 21:36:18 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.2639208436012268, Train Loss: 0.2704636752605438
[32m[0511 21:36:18 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.26391181349754333, Train Loss: 0.2704385221004486
[32m[0511 21:36:18 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.26390281319618225, Train Loss: 0.27041348814964294
[32m[0511 21:36:18 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.26389390230178833, Train Loss: 0.27038851380348206
[32m[0511 21:36:18 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.2638849914073944, Train Loss: 0.27036362886428833
[32m[0511 21:36:18 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.26387619972229004, Train Loss: 0.270338773727417
[32m[0511 21:36:18 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.2638673782348633, Train Loss: 0.27031409740448
[32m[0511 21:36:18 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.2638586461544037, Train Loss: 0.27028942108154297
[32m[0511 21:36:18 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.26385000348091125, Train Loss: 0.2702648639678955
[32m[0511 21:36:18 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.26384133100509644, Train Loss: 0.2702403664588928
[32m[0511 21:36:18 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.2638327181339264, Train Loss: 0.2702158987522125
[32m[0511 21:36:18 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.26382413506507874, Train Loss: 0.27019158005714417
[32m[0511 21:36:18 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.2638155519962311, Train Loss: 0.2701673209667206
[32m[0511 21:36:18 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.2638070583343506, Train Loss: 0.2701431214809418
[32m[0511 21:36:18 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.26379862427711487, Train Loss: 0.27011895179748535
[32m[0511 21:36:18 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.26379022002220154, Train Loss: 0.27009493112564087
[32m[0511 21:36:18 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.2637818157672882, Train Loss: 0.2700709402561188
[32m[0511 21:36:18 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.26377344131469727, Train Loss: 0.27004703879356384
[32m[0511 21:36:18 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.2637650966644287, Train Loss: 0.2700231969356537
[32m[0511 21:36:18 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.26375681161880493, Train Loss: 0.2699994146823883
[32m[0511 21:36:19 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.26374855637550354, Train Loss: 0.2699757516384125
[32m[0511 21:36:19 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.26374030113220215, Train Loss: 0.26995208859443665
[32m[0511 21:36:19 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.26373210549354553, Train Loss: 0.26992854475975037
[32m[0511 21:36:19 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.2637239396572113, Train Loss: 0.26990512013435364
[32m[0511 21:36:19 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.2637157738208771, Train Loss: 0.2698816657066345
[32m[0511 21:36:19 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.2637076675891876, Train Loss: 0.26985833048820496
[32m[0511 21:36:19 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.26369956135749817, Train Loss: 0.26983505487442017
[32m[0511 21:36:19 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.2636914551258087, Train Loss: 0.26981183886528015
[32m[0511 21:36:19 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.26368340849876404, Train Loss: 0.2697887122631073
[32m[0511 21:36:19 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.26367542147636414, Train Loss: 0.2697656452655792
[32m[0511 21:36:19 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.26366737484931946, Train Loss: 0.2697426676750183
[32m[0511 21:36:19 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.26365941762924194, Train Loss: 0.2697196900844574
[32m[0511 21:36:19 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.26365143060684204, Train Loss: 0.26969683170318604
[32m[0511 21:36:19 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.2636435031890869, Train Loss: 0.26967406272888184
[32m[0511 21:36:19 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.26363563537597656, Train Loss: 0.2696513235569
[32m[0511 21:36:19 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.26362770795822144, Train Loss: 0.269628643989563
[32m[0511 21:36:19 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.2636198103427887, Train Loss: 0.2696060240268707
[32m[0511 21:36:19 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.26361194252967834, Train Loss: 0.26958349347114563
[32m[0511 21:36:19 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.2636041045188904, Train Loss: 0.2695609927177429
[32m[0511 21:36:19 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.2635962963104248, Train Loss: 0.26953864097595215
[32m[0511 21:36:19 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.26358848810195923, Train Loss: 0.2695162892341614
[32m[0511 21:36:19 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.26358067989349365, Train Loss: 0.269493967294693
[32m[0511 21:36:19 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.26357293128967285, Train Loss: 0.26947176456451416
[32m[0511 21:36:20 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.26356518268585205, Train Loss: 0.2694496214389801
[32m[0511 21:36:20 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.26355740427970886, Train Loss: 0.2694275379180908
[32m[0511 21:36:20 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.26354971528053284, Train Loss: 0.2694055140018463
[32m[0511 21:36:20 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.2635420262813568, Train Loss: 0.2693835198879242
[32m[0511 21:36:20 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.2635343074798584, Train Loss: 0.2693616449832916
[32m[0511 21:36:20 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.26352664828300476, Train Loss: 0.26933979988098145
[32m[0511 21:36:20 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.2635189890861511, Train Loss: 0.26931801438331604
[32m[0511 21:36:20 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.2635113000869751, Train Loss: 0.2692962884902954
[32m[0511 21:36:20 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.26350367069244385, Train Loss: 0.26927462220191956
[32m[0511 21:36:20 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.2634960412979126, Train Loss: 0.2692530155181885
[32m[0511 21:36:20 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.26348844170570374, Train Loss: 0.26923149824142456
[32m[0511 21:36:20 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.2634807825088501, Train Loss: 0.26920998096466064
[32m[0511 21:36:20 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.2634732723236084, Train Loss: 0.26918861269950867
[32m[0511 21:36:20 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.26346567273139954, Train Loss: 0.2691672146320343
[32m[0511 21:36:20 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.26345813274383545, Train Loss: 0.2691459059715271
[32m[0511 21:36:20 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.26345059275627136, Train Loss: 0.26912468671798706
[32m[0511 21:36:20 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.2634430527687073, Train Loss: 0.2691035270690918
[32m[0511 21:36:20 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.2634354829788208, Train Loss: 0.2690823972225189
[32m[0511 21:36:20 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.2634280323982239, Train Loss: 0.2690613269805908
[32m[0511 21:36:20 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.2634204924106598, Train Loss: 0.2690403461456299
[32m[0511 21:36:20 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.26341304183006287, Train Loss: 0.26901936531066895
[32m[0511 21:36:20 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.26340556144714355, Train Loss: 0.26899847388267517
[32m[0511 21:36:20 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.26339808106422424, Train Loss: 0.26897764205932617
[32m[0511 21:36:21 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.2633906900882721, Train Loss: 0.26895684003829956
[32m[0511 21:36:21 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.2633831799030304, Train Loss: 0.2689360976219177
[32m[0511 21:36:21 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.26337581872940063, Train Loss: 0.26891547441482544
[32m[0511 21:36:21 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.2633683681488037, Train Loss: 0.26889482140541077
[32m[0511 21:36:21 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.26336097717285156, Train Loss: 0.26887428760528564
[32m[0511 21:36:21 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.2633535861968994, Train Loss: 0.2688537836074829
[32m[0511 21:36:21 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.26334619522094727, Train Loss: 0.26883336901664734
[32m[0511 21:36:21 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.2633388340473175, Train Loss: 0.26881301403045654
[32m[0511 21:36:21 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.26333150267601013, Train Loss: 0.26879262924194336
[32m[0511 21:36:21 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.26332414150238037, Train Loss: 0.2687723636627197
[32m[0511 21:36:21 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.263316810131073, Train Loss: 0.26875215768814087
[32m[0511 21:36:21 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.263309508562088, Train Loss: 0.2687319815158844
[32m[0511 21:36:21 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.263302206993103, Train Loss: 0.2687118649482727
[32m[0511 21:36:21 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.26329490542411804, Train Loss: 0.2686917781829834
[32m[0511 21:36:21 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.26328763365745544, Train Loss: 0.26867178082466125
[32m[0511 21:36:21 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.26328036189079285, Train Loss: 0.2686518132686615
[32m[0511 21:36:21 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.26327311992645264, Train Loss: 0.2686319053173065
[32m[0511 21:36:21 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.2632658779621124, Train Loss: 0.2686121165752411
[32m[0511 21:36:21 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.2632586359977722, Train Loss: 0.26859229803085327
[32m[0511 21:36:21 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.2632514238357544, Train Loss: 0.26857253909111023
[32m[0511 21:36:21 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.2632442116737366, Train Loss: 0.26855283975601196
[32m[0511 21:36:21 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.26323702931404114, Train Loss: 0.26853320002555847
[32m[0511 21:36:21 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.2632298767566681, Train Loss: 0.26851359009742737
[32m[0511 21:36:21 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.26322269439697266, Train Loss: 0.2684940993785858
[32m[0511 21:36:22 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.2632155120372772, Train Loss: 0.26847463846206665
[32m[0511 21:36:22 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.26320841908454895, Train Loss: 0.2684551775455475
[32m[0511 21:36:22 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.2632012665271759, Train Loss: 0.2684358060359955
[32m[0511 21:36:22 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.26319420337677, Train Loss: 0.26841649413108826
[32m[0511 21:36:22 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.263187050819397, Train Loss: 0.26839718222618103
[32m[0511 21:36:22 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.2631800174713135, Train Loss: 0.26837795972824097
[32m[0511 21:36:22 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.2631729245185852, Train Loss: 0.2683587968349457
[32m[0511 21:36:22 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.2631658613681793, Train Loss: 0.2683396637439728
[32m[0511 21:36:22 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.2631588280200958, Train Loss: 0.2683205306529999
[32m[0511 21:36:22 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.26315179467201233, Train Loss: 0.26830151677131653
[32m[0511 21:36:22 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.2631448209285736, Train Loss: 0.2682825028896332
[32m[0511 21:36:22 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.2631377875804901, Train Loss: 0.268263578414917
[32m[0511 21:36:22 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.2631308138370514, Train Loss: 0.2682446837425232
[32m[0511 21:36:22 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.26312384009361267, Train Loss: 0.26822584867477417
[32m[0511 21:36:22 @mbmf_sampler.py:98][0m Finished 4th episode
[32m[0511 21:36:22 @mbmf_sampler.py:102][0m 2004 timesteps from 4 episodes collected
[32m[0511 22:02:29 @mbmf_trainer.py:160][0m Mean reward: -419.64448305785845
[32m[0511 22:02:29 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.294638067483902, Train Loss: 0.2787172794342041
[32m[0511 22:02:29 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.29515334963798523, Train Loss: 0.2788185477256775
[32m[0511 22:02:29 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.29464611411094666, Train Loss: 0.27853935956954956
[32m[0511 22:02:29 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.29442140460014343, Train Loss: 0.27828049659729004
[32m[0511 22:02:29 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.29430708289146423, Train Loss: 0.27811041474342346
[32m[0511 22:02:29 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.2942095100879669, Train Loss: 0.2779775559902191
[32m[0511 22:02:29 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.294121652841568, Train Loss: 0.27785515785217285
[32m[0511 22:02:29 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.2940475642681122, Train Loss: 0.27774274349212646
[32m[0511 22:02:29 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.29398468136787415, Train Loss: 0.27763956785202026
[32m[0511 22:02:30 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.2939305901527405, Train Loss: 0.27754369378089905
[32m[0511 22:02:30 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.29388388991355896, Train Loss: 0.2774536609649658
[32m[0511 22:02:30 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.2938433289527893, Train Loss: 0.27736854553222656
[32m[0511 22:02:30 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.2938079535961151, Train Loss: 0.27728766202926636
[32m[0511 22:02:30 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.2937769591808319, Train Loss: 0.2772103250026703
[32m[0511 22:02:30 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.29374971985816956, Train Loss: 0.2771362364292145
[32m[0511 22:02:30 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.2937256097793579, Train Loss: 0.27706488966941833
[32m[0511 22:02:30 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.29370424151420593, Train Loss: 0.27699610590934753
[32m[0511 22:02:30 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.2936851978302002, Train Loss: 0.2769295275211334
[32m[0511 22:02:30 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.293668270111084, Train Loss: 0.2768650949001312
[32m[0511 22:02:30 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.29365304112434387, Train Loss: 0.27680251002311707
[32m[0511 22:02:30 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.2936393618583679, Train Loss: 0.2767415940761566
[32m[0511 22:02:30 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.2936270236968994, Train Loss: 0.2766822874546051
[32m[0511 22:02:30 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.2936159372329712, Train Loss: 0.27662450075149536
[32m[0511 22:02:30 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.29360583424568176, Train Loss: 0.27656808495521545
[32m[0511 22:02:30 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.29359671473503113, Train Loss: 0.27651292085647583
[32m[0511 22:02:30 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.2935884892940521, Train Loss: 0.27645906805992126
[32m[0511 22:02:30 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.2935810387134552, Train Loss: 0.27640625834465027
[32m[0511 22:02:30 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.2935742437839508, Train Loss: 0.2763545513153076
[32m[0511 22:02:31 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.29356807470321655, Train Loss: 0.27630388736724854
[32m[0511 22:02:31 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.29356247186660767, Train Loss: 0.2762540876865387
[32m[0511 22:02:31 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.29355743527412415, Train Loss: 0.27620530128479004
[32m[0511 22:02:31 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.29355284571647644, Train Loss: 0.2761573791503906
[32m[0511 22:02:31 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.29354870319366455, Train Loss: 0.2761102318763733
[32m[0511 22:02:31 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.2935449779033661, Train Loss: 0.27606385946273804
[32m[0511 22:02:31 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.2935416102409363, Train Loss: 0.27601826190948486
[32m[0511 22:02:31 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.2935386300086975, Train Loss: 0.2759733498096466
[32m[0511 22:02:31 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.29353591799736023, Train Loss: 0.27592915296554565
[32m[0511 22:02:31 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.2935335636138916, Train Loss: 0.2758856415748596
[32m[0511 22:02:31 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.29353147745132446, Train Loss: 0.27584272623062134
[32m[0511 22:02:31 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.2935296595096588, Train Loss: 0.2758004069328308
[32m[0511 22:02:31 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.29352810978889465, Train Loss: 0.2757587134838104
[32m[0511 22:02:31 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.2935267388820648, Train Loss: 0.27571752667427063
[32m[0511 22:02:31 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.2935256361961365, Train Loss: 0.2756769061088562
[32m[0511 22:02:31 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.29352474212646484, Train Loss: 0.27563679218292236
[32m[0511 22:02:31 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.29352402687072754, Train Loss: 0.2755972146987915
[32m[0511 22:02:31 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.29352349042892456, Train Loss: 0.2755580544471741
[32m[0511 22:02:31 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.2935231029987335, Train Loss: 0.27551940083503723
[32m[0511 22:02:32 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.2935228943824768, Train Loss: 0.2754811942577362
[32m[0511 22:02:32 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.2935228645801544, Train Loss: 0.2754434645175934
[32m[0511 22:02:32 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.2935229539871216, Train Loss: 0.2754060626029968
[32m[0511 22:02:32 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.2935231924057007, Train Loss: 0.27536916732788086
[32m[0511 22:02:32 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.2935235798358917, Train Loss: 0.27533262968063354
[32m[0511 22:02:32 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.2935240566730499, Train Loss: 0.2752964198589325
[32m[0511 22:02:32 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.29352468252182007, Train Loss: 0.2752606272697449
[32m[0511 22:02:32 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.2935253977775574, Train Loss: 0.2752251923084259
[32m[0511 22:02:32 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.29352623224258423, Train Loss: 0.2751901149749756
[32m[0511 22:02:32 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.29352718591690063, Train Loss: 0.27515533566474915
[32m[0511 22:02:32 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.29352813959121704, Train Loss: 0.27512097358703613
[32m[0511 22:02:32 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.2935292720794678, Train Loss: 0.27508682012557983
[32m[0511 22:02:32 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.2935304045677185, Train Loss: 0.2750530242919922
[32m[0511 22:02:32 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.29353174567222595, Train Loss: 0.2750195562839508
[32m[0511 22:02:32 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.2935330867767334, Train Loss: 0.2749863564968109
[32m[0511 22:02:32 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.2935344874858856, Train Loss: 0.2749534547328949
[32m[0511 22:02:32 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.2935359477996826, Train Loss: 0.27492085099220276
[32m[0511 22:02:32 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.29353752732276917, Train Loss: 0.2748884856700897
[32m[0511 22:02:32 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.2935391068458557, Train Loss: 0.2748563885688782
[32m[0511 22:02:33 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.29354074597358704, Train Loss: 0.2748245596885681
[32m[0511 22:02:33 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.2935424745082855, Train Loss: 0.27479296922683716
[32m[0511 22:02:33 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.2935442626476288, Train Loss: 0.2747616469860077
[32m[0511 22:02:33 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.29354602098464966, Train Loss: 0.27473050355911255
[32m[0511 22:02:33 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.2935478687286377, Train Loss: 0.2746996581554413
[32m[0511 22:02:33 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.2935498058795929, Train Loss: 0.27466902136802673
[32m[0511 22:02:33 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.2935517132282257, Train Loss: 0.2746386229991913
[32m[0511 22:02:33 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.2935536503791809, Train Loss: 0.2746083736419678
[32m[0511 22:02:33 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.2935556471347809, Train Loss: 0.27457839250564575
[32m[0511 22:02:33 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.29355764389038086, Train Loss: 0.27454861998558044
[32m[0511 22:02:33 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.2935597002506256, Train Loss: 0.27451908588409424
[32m[0511 22:02:33 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.29356178641319275, Train Loss: 0.27448970079421997
[32m[0511 22:02:33 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.2935638725757599, Train Loss: 0.27446049451828003
[32m[0511 22:02:33 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.293565958738327, Train Loss: 0.2744314968585968
[32m[0511 22:02:33 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.29356813430786133, Train Loss: 0.2744027078151703
[32m[0511 22:02:33 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.29357025027275085, Train Loss: 0.2743740379810333
[32m[0511 22:02:33 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.29357245564460754, Train Loss: 0.2743455767631531
[32m[0511 22:02:33 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.29357466101646423, Train Loss: 0.27431735396385193
[32m[0511 22:02:33 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.29357683658599854, Train Loss: 0.27428919076919556
[32m[0511 22:02:33 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.29357901215553284, Train Loss: 0.2742612957954407
[32m[0511 22:02:34 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.2935812473297119, Train Loss: 0.27423349022865295
[32m[0511 22:02:34 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.293583482503891, Train Loss: 0.27420586347579956
[32m[0511 22:02:34 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.2935856878757477, Train Loss: 0.2741784155368805
[32m[0511 22:02:34 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.29358795285224915, Train Loss: 0.27415114641189575
[32m[0511 22:02:34 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.2935901880264282, Train Loss: 0.2741239666938782
[32m[0511 22:02:34 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.2935923933982849, Train Loss: 0.2740969657897949
[32m[0511 22:02:34 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.293594628572464, Train Loss: 0.2740701138973236
[32m[0511 22:02:34 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.2935968339443207, Train Loss: 0.27404332160949707
[32m[0511 22:02:34 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.29359909892082214, Train Loss: 0.274016797542572
[32m[0511 22:02:34 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.2936013340950012, Train Loss: 0.27399033308029175
[32m[0511 22:02:34 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.2936035394668579, Train Loss: 0.2739640772342682
[32m[0511 22:02:34 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.2936058044433594, Train Loss: 0.2739378809928894
[32m[0511 22:02:34 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.29360803961753845, Train Loss: 0.27391186356544495
[32m[0511 22:02:34 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.29361021518707275, Train Loss: 0.27388590574264526
[32m[0511 22:02:34 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.2936124801635742, Train Loss: 0.2738601565361023
[32m[0511 22:02:34 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.29361462593078613, Train Loss: 0.2738344669342041
[32m[0511 22:02:34 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.2936168611049652, Train Loss: 0.27380895614624023
[32m[0511 22:02:34 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.2936190664768219, Train Loss: 0.27378350496292114
[32m[0511 22:02:34 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.2936212122440338, Train Loss: 0.273758202791214
[32m[0511 22:02:34 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.2936234474182129, Train Loss: 0.2737330198287964
[32m[0511 22:02:35 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.2936255633831024, Train Loss: 0.27370792627334595
[32m[0511 22:02:35 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.29362767934799194, Train Loss: 0.27368295192718506
[32m[0511 22:02:35 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.29362988471984863, Train Loss: 0.2736581563949585
[32m[0511 22:02:35 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.29363200068473816, Train Loss: 0.27363333106040955
[32m[0511 22:02:35 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.2936341166496277, Train Loss: 0.2736087143421173
[32m[0511 22:02:35 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.2936362326145172, Train Loss: 0.273584246635437
[32m[0511 22:02:35 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.29363828897476196, Train Loss: 0.2735597789287567
[32m[0511 22:02:35 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.2936404049396515, Train Loss: 0.27353549003601074
[32m[0511 22:02:35 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.29364240169525146, Train Loss: 0.27351123094558716
[32m[0511 22:02:35 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.2936444878578186, Train Loss: 0.2734870910644531
[32m[0511 22:02:35 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.29364651441574097, Train Loss: 0.27346304059028625
[32m[0511 22:02:35 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.29364854097366333, Train Loss: 0.2734391689300537
[32m[0511 22:02:35 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.2936505079269409, Train Loss: 0.27341532707214355
[32m[0511 22:02:35 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.2936525344848633, Train Loss: 0.2733915448188782
[32m[0511 22:02:35 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.2936544716358185, Train Loss: 0.2733679413795471
[32m[0511 22:02:35 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.29365643858909607, Train Loss: 0.27334433794021606
[32m[0511 22:02:35 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.29365840554237366, Train Loss: 0.27332085371017456
[32m[0511 22:02:35 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.29366031289100647, Train Loss: 0.2732975482940674
[32m[0511 22:02:35 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.29366225004196167, Train Loss: 0.2732742130756378
[32m[0511 22:02:36 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.2936641275882721, Train Loss: 0.2732510268688202
[32m[0511 22:02:36 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.29366597533226013, Train Loss: 0.27322787046432495
[32m[0511 22:02:36 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.29366785287857056, Train Loss: 0.27320483326911926
[32m[0511 22:02:36 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.2936696708202362, Train Loss: 0.27318185567855835
[32m[0511 22:02:36 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.29367148876190186, Train Loss: 0.273158997297287
[32m[0511 22:02:36 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.2936733365058899, Train Loss: 0.273136168718338
[32m[0511 22:02:36 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.29367509484291077, Train Loss: 0.273113489151001
[32m[0511 22:02:36 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.2936769127845764, Train Loss: 0.2730908691883087
[32m[0511 22:02:36 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.2936786413192749, Train Loss: 0.2730683386325836
[32m[0511 22:02:36 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.2936803996562958, Train Loss: 0.2730458378791809
[32m[0511 22:02:36 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.29368212819099426, Train Loss: 0.27302342653274536
[32m[0511 22:02:36 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.293683797121048, Train Loss: 0.2730010747909546
[32m[0511 22:02:36 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.2936854958534241, Train Loss: 0.27297884225845337
[32m[0511 22:02:36 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.2936871647834778, Train Loss: 0.2729566693305969
[32m[0511 22:02:36 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.2936888337135315, Train Loss: 0.27293452620506287
[32m[0511 22:02:36 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.2936904728412628, Train Loss: 0.27291247248649597
[32m[0511 22:02:36 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.29369208216667175, Train Loss: 0.27289053797721863
[32m[0511 22:02:36 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.2936936914920807, Train Loss: 0.27286863327026367
[32m[0511 22:02:36 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.2936953008174896, Train Loss: 0.2728467881679535
[32m[0511 22:02:36 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.2936968505382538, Train Loss: 0.27282506227493286
[32m[0511 22:02:37 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.29369843006134033, Train Loss: 0.2728033661842346
[32m[0511 22:02:37 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.2936999499797821, Train Loss: 0.2727817893028259
[32m[0511 22:02:37 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.2937014400959015, Train Loss: 0.27276018261909485
[32m[0511 22:02:37 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.29370298981666565, Train Loss: 0.2727386951446533
[32m[0511 22:02:37 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.2937045097351074, Train Loss: 0.27271729707717896
[32m[0511 22:02:37 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.29370594024658203, Train Loss: 0.272695928812027
[32m[0511 22:02:37 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.29370737075805664, Train Loss: 0.27267464995384216
[32m[0511 22:02:37 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.29370880126953125, Train Loss: 0.2726534307003021
[32m[0511 22:02:37 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.29371026158332825, Train Loss: 0.2726322412490845
[32m[0511 22:02:37 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.29371166229248047, Train Loss: 0.2726111114025116
[32m[0511 22:02:37 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.2937130630016327, Train Loss: 0.2725900709629059
[32m[0511 22:02:37 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.29371440410614014, Train Loss: 0.27256909012794495
[32m[0511 22:02:37 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.2937157452106476, Train Loss: 0.2725481688976288
[32m[0511 22:02:37 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.2937171161174774, Train Loss: 0.272527277469635
[32m[0511 22:02:37 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.2937183976173401, Train Loss: 0.2725065052509308
[32m[0511 22:02:37 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.29371970891952515, Train Loss: 0.2724857032299042
[32m[0511 22:02:37 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.2937209904193878, Train Loss: 0.2724650502204895
[32m[0511 22:02:37 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.2937222719192505, Train Loss: 0.27244439721107483
[32m[0511 22:02:37 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.29372352361679077, Train Loss: 0.2724238336086273
[32m[0511 22:02:38 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.2937247157096863, Train Loss: 0.2724032700061798
[32m[0511 22:02:38 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.29372596740722656, Train Loss: 0.27238282561302185
[32m[0511 22:02:38 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.2937271296977997, Train Loss: 0.2723624110221863
[32m[0511 22:02:38 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.2937283515930176, Train Loss: 0.2723420560359955
[32m[0511 22:02:38 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.2937295138835907, Train Loss: 0.2723217308521271
[32m[0511 22:02:38 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.2937306761741638, Train Loss: 0.27230146527290344
[32m[0511 22:02:38 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.29373177886009216, Train Loss: 0.27228131890296936
[32m[0511 22:02:38 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.2937328517436981, Train Loss: 0.2722611725330353
[32m[0511 22:02:38 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.29373401403427124, Train Loss: 0.27224108576774597
[32m[0511 22:02:38 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.2937350869178772, Train Loss: 0.27222105860710144
[32m[0511 22:02:38 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.29373612999916077, Train Loss: 0.2722010314464569
[32m[0511 22:02:38 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.29373717308044434, Train Loss: 0.27218112349510193
[32m[0511 22:02:38 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.2937382161617279, Train Loss: 0.27216118574142456
[32m[0511 22:02:38 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.2937391996383667, Train Loss: 0.27214136719703674
[32m[0511 22:02:38 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.2937402129173279, Train Loss: 0.2721216082572937
[32m[0511 22:02:38 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.2937411665916443, Train Loss: 0.27210187911987305
[32m[0511 22:02:38 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.2937421202659607, Train Loss: 0.27208220958709717
[32m[0511 22:02:38 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.2937430441379547, Train Loss: 0.27206259965896606
[32m[0511 22:02:38 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.29374396800994873, Train Loss: 0.27204298973083496
[32m[0511 22:02:38 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.29374489188194275, Train Loss: 0.27202343940734863
[32m[0511 22:02:39 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.293745756149292, Train Loss: 0.2720038890838623
[32m[0511 22:02:39 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.29374662041664124, Train Loss: 0.2719844877719879
[32m[0511 22:02:39 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.2937474548816681, Train Loss: 0.27196502685546875
[32m[0511 22:02:39 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.29374825954437256, Train Loss: 0.2719457149505615
[32m[0511 22:02:39 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.293749064207077, Train Loss: 0.2719264030456543
[32m[0511 22:02:39 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.2937498986721039, Train Loss: 0.27190718054771423
[32m[0511 22:02:39 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.2937506139278412, Train Loss: 0.27188795804977417
[32m[0511 22:02:39 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.29375138878822327, Train Loss: 0.2718687355518341
[32m[0511 22:02:39 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.29375213384628296, Train Loss: 0.27184969186782837
[32m[0511 22:02:39 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.2937528192996979, Train Loss: 0.27183055877685547
[32m[0511 22:02:39 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.2937535345554352, Train Loss: 0.2718115448951721
[32m[0511 22:02:39 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.2937542200088501, Train Loss: 0.27179259061813354
[32m[0511 22:02:39 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.293754905462265, Train Loss: 0.27177363634109497
[32m[0511 22:02:39 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.2937554717063904, Train Loss: 0.2717547118663788
[32m[0511 22:02:39 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.2937561273574829, Train Loss: 0.27173587679862976
[32m[0511 22:02:39 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.29375672340393066, Train Loss: 0.2717170715332031
[32m[0511 22:02:39 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.2937573194503784, Train Loss: 0.27169832587242126
[32m[0511 22:02:39 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.2937578558921814, Train Loss: 0.2716796398162842
[32m[0511 22:02:39 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.2937583923339844, Train Loss: 0.2716608941555023
[32m[0511 22:02:39 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.29375889897346497, Train Loss: 0.2716422975063324
[32m[0511 22:02:40 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.29375937581062317, Train Loss: 0.2716237008571625
[32m[0511 22:02:40 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.29375985264778137, Train Loss: 0.27160513401031494
[32m[0511 22:02:40 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.2937602996826172, Train Loss: 0.2715865969657898
[32m[0511 22:02:40 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.2937606871128082, Train Loss: 0.2715681493282318
[32m[0511 22:02:40 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.29376113414764404, Train Loss: 0.2715497314929962
[32m[0511 22:02:40 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.2937614917755127, Train Loss: 0.2715314030647278
[32m[0511 22:02:40 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.29376187920570374, Train Loss: 0.2715130150318146
[32m[0511 22:02:40 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.2937622368335724, Train Loss: 0.27149471640586853
[32m[0511 22:02:40 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.2937625050544739, Train Loss: 0.27147647738456726
[32m[0511 22:02:40 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.29376283288002014, Train Loss: 0.271458238363266
[32m[0511 22:02:40 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.29376310110092163, Train Loss: 0.2714401185512543
[32m[0511 22:02:40 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.2937633693218231, Train Loss: 0.2714219391345978
[32m[0511 22:02:40 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.2937636077404022, Train Loss: 0.2714039087295532
[32m[0511 22:02:40 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.29376381635665894, Train Loss: 0.2713858485221863
[32m[0511 22:02:40 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.29376399517059326, Train Loss: 0.2713678479194641
[32m[0511 22:02:40 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.29376420378685, Train Loss: 0.2713499069213867
[32m[0511 22:02:40 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.2937643229961395, Train Loss: 0.2713319659233093
[32m[0511 22:02:40 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.2937644422054291, Train Loss: 0.2713140845298767
[32m[0511 22:02:40 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.29376456141471863, Train Loss: 0.2712962031364441
[32m[0511 22:02:41 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.2937646210193634, Train Loss: 0.27127841114997864
[32m[0511 22:02:41 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.2937646806240082, Train Loss: 0.27126067876815796
[32m[0511 22:02:41 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.29376471042633057, Train Loss: 0.2712429463863373
[32m[0511 22:02:41 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.29376477003097534, Train Loss: 0.2712252736091614
[32m[0511 22:02:41 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.29376474022865295, Train Loss: 0.27120766043663025
[32m[0511 22:02:41 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.29376471042633057, Train Loss: 0.2711900472640991
[32m[0511 22:02:41 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.2937646806240082, Train Loss: 0.27117249369621277
[32m[0511 22:02:41 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.293764591217041, Train Loss: 0.2711549699306488
[32m[0511 22:02:41 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.29376450181007385, Train Loss: 0.271137535572052
[32m[0511 22:02:41 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.2937643527984619, Train Loss: 0.2711200714111328
[32m[0511 22:02:41 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.29376426339149475, Train Loss: 0.271102637052536
[32m[0511 22:02:41 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.2937641143798828, Train Loss: 0.27108532190322876
[32m[0511 22:02:41 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.2937639057636261, Train Loss: 0.2710679769515991
[32m[0511 22:02:41 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.2937636971473694, Train Loss: 0.27105069160461426
[32m[0511 22:02:41 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.2937634587287903, Train Loss: 0.2710334062576294
[32m[0511 22:02:41 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.29376325011253357, Train Loss: 0.2710162401199341
[32m[0511 22:02:41 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.2937629818916321, Train Loss: 0.27099910378456116
[32m[0511 22:02:41 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.2937626838684082, Train Loss: 0.27098193764686584
[32m[0511 22:02:41 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.2937623858451843, Train Loss: 0.2709648311138153
[32m[0511 22:02:41 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.2937620282173157, Train Loss: 0.2709478437900543
[32m[0511 22:02:42 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.2937617003917694, Train Loss: 0.27093079686164856
[32m[0511 22:02:42 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.293761283159256, Train Loss: 0.27091383934020996
[32m[0511 22:02:42 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.29376092553138733, Train Loss: 0.27089688181877136
[32m[0511 22:02:42 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.2937605082988739, Train Loss: 0.27087998390197754
[32m[0511 22:02:42 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.2937600612640381, Train Loss: 0.2708631157875061
[32m[0511 22:02:42 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.29375961422920227, Train Loss: 0.27084627747535706
[32m[0511 22:02:42 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.2937591075897217, Train Loss: 0.2708294987678528
[32m[0511 22:02:42 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.2937586009502411, Train Loss: 0.2708126902580261
[32m[0511 22:02:42 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.2937580645084381, Train Loss: 0.270796000957489
[32m[0511 22:02:42 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.29375752806663513, Train Loss: 0.2707793116569519
[32m[0511 22:02:42 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.29375699162483215, Train Loss: 0.27076268196105957
[32m[0511 22:02:42 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.2937563955783844, Train Loss: 0.2707460820674896
[32m[0511 22:02:42 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.29375579953193665, Train Loss: 0.27072951197624207
[32m[0511 22:02:42 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.2937551438808441, Train Loss: 0.2707129716873169
[32m[0511 22:02:42 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.293754518032074, Train Loss: 0.2706965208053589
[32m[0511 22:02:42 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.29375386238098145, Train Loss: 0.2706800103187561
[32m[0511 22:02:42 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.29375314712524414, Train Loss: 0.2706635594367981
[32m[0511 22:02:42 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.29375243186950684, Train Loss: 0.2706471383571625
[32m[0511 22:02:42 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.29375171661376953, Train Loss: 0.270630806684494
[32m[0511 22:02:42 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.29375097155570984, Train Loss: 0.27061450481414795
[32m[0511 22:02:43 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.29375022649765015, Train Loss: 0.2705981731414795
[32m[0511 22:02:43 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.2937494218349457, Train Loss: 0.2705819606781006
[32m[0511 22:02:43 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.2937486171722412, Train Loss: 0.2705657184123993
[32m[0511 22:02:43 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.29374781250953674, Train Loss: 0.2705495357513428
[32m[0511 22:02:43 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.2937469482421875, Train Loss: 0.27053335309028625
[32m[0511 22:02:43 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.29374611377716064, Train Loss: 0.2705172300338745
[32m[0511 22:02:43 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.293745219707489, Train Loss: 0.27050113677978516
[32m[0511 22:02:43 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.29374435544013977, Train Loss: 0.2704851031303406
[32m[0511 22:02:43 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.293743371963501, Train Loss: 0.270469069480896
[32m[0511 22:02:43 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.29374244809150696, Train Loss: 0.2704530656337738
[32m[0511 22:02:43 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.29374149441719055, Train Loss: 0.270437091588974
[32m[0511 22:02:43 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.29374054074287415, Train Loss: 0.27042117714881897
[32m[0511 22:02:43 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.29373952746391296, Train Loss: 0.27040529251098633
[32m[0511 22:02:43 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.29373854398727417, Train Loss: 0.2703894078731537
[32m[0511 22:02:43 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.2937374711036682, Train Loss: 0.2703735828399658
[32m[0511 22:02:43 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.29373645782470703, Train Loss: 0.27035775780677795
[32m[0511 22:02:43 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.29373541474342346, Train Loss: 0.27034205198287964
[32m[0511 22:02:43 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.2937343120574951, Train Loss: 0.27032628655433655
[32m[0511 22:02:43 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.29373326897621155, Train Loss: 0.27031058073043823
[32m[0511 22:02:43 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.2937321662902832, Train Loss: 0.2702949047088623
[32m[0511 22:02:44 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.2937310039997101, Train Loss: 0.27027928829193115
[32m[0511 22:02:44 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.29372987151145935, Train Loss: 0.2702636420726776
[32m[0511 22:02:44 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.29372870922088623, Train Loss: 0.27024805545806885
[32m[0511 22:02:44 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.2937275469303131, Train Loss: 0.27023249864578247
[32m[0511 22:02:44 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.2937263548374176, Train Loss: 0.2702169716358185
[32m[0511 22:02:44 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.2937251329421997, Train Loss: 0.27020150423049927
[32m[0511 22:02:44 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.2937239110469818, Train Loss: 0.27018600702285767
[32m[0511 22:02:44 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.29372265934944153, Train Loss: 0.2701705992221832
[32m[0511 22:02:44 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.29372140765190125, Train Loss: 0.2701551914215088
[32m[0511 22:02:44 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.29372015595436096, Train Loss: 0.2701398730278015
[32m[0511 22:02:44 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.2937188744544983, Train Loss: 0.2701244652271271
[32m[0511 22:02:44 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.29371756315231323, Train Loss: 0.2701091170310974
[32m[0511 22:02:44 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.2937162220478058, Train Loss: 0.2700938880443573
[32m[0511 22:02:44 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.29371488094329834, Train Loss: 0.2700785994529724
[32m[0511 22:02:44 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.2937135696411133, Train Loss: 0.2700633704662323
[32m[0511 22:02:44 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.29371219873428345, Train Loss: 0.27004820108413696
[32m[0511 22:02:44 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.2937108278274536, Train Loss: 0.27003300189971924
[32m[0511 22:02:44 @mbmf_main.py:224][0m batch size for trpo is 1000
[32m[0511 22:02:44 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 22:02:44 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 22:02:44 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 22:02:44 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 22:02:44 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 22:02:44 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 22:02:44 @mbmf_main.py:132][0m Training starts at /root/mbbl
[32m[0511 22:02:44 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 22:02:44 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 22:02:44 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 22:02:44 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 22:02:44 @base_worker.py:45][0m Worker 0 online
[32m[0511 22:02:44 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 22:02:44 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 22:02:44 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 22:02:44 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 22:02:44 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 22:02:44 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 22:02:44 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 22:02:44 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 22:02:44 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 22:02:44 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 22:02:44 @base_worker.py:45][0m Worker 1 online
[32m[0511 22:02:44 @base_worker.py:45][0m Worker 2 online
[32m[0511 22:02:44 @base_worker.py:45][0m Worker 3 online
[32m[0511 22:02:44 @base_worker.py:45][0m Worker 4 online
[32m[0511 22:02:44 @base_worker.py:45][0m Worker 5 online
[32m[0511 22:02:44 @base_worker.py:45][0m Worker 6 online
[32m[0511 22:02:44 @base_worker.py:45][0m Worker 7 online
[32m[0511 22:02:44 @base_worker.py:45][0m Worker 8 online
[32m[0511 22:02:44 @base_worker.py:45][0m Worker 9 online
[32m[0511 22:02:44 @base_worker.py:45][0m Worker 10 online
[32m[0511 22:02:44 @base_worker.py:45][0m Worker 11 online
[32m[0511 22:02:44 @base_worker.py:45][0m Worker 12 online
[32m[0511 22:02:44 @base_worker.py:45][0m Worker 13 online
[32m[0511 22:02:44 @base_worker.py:45][0m Worker 14 online
[32m[0511 22:02:44 @base_worker.py:45][0m Worker 15 online
[32m[0511 22:02:44 @base_worker.py:45][0m Worker 16 online
[32m[0511 22:02:44 @base_worker.py:45][0m Worker 17 online
[32m[0511 22:02:44 @base_worker.py:45][0m Worker 18 online
[32m[0511 22:02:44 @base_worker.py:45][0m Worker 19 online
[32m[0511 22:02:45 @base_trainer.py:152][0m Trainer maintains [1] policy network
[32m[0511 22:02:45 @base_trainer.py:152][0m Trainer maintains [1] dynamics network
[32m[0511 22:02:45 @base_trainer.py:152][0m Trainer maintains [1] reward network
[32m[0511 22:02:46 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:02:46 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:02:46 @base_trainer.py:216][0m Mean reward: -457.7720789357646
[32m[0511 22:02:46 @base_main.py:38][0m --------------- Iteration 1 ---------------
[32m[0511 22:02:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0000 mins
[32m[0511 22:02:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0049 mins
[32m[0511 22:02:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0148 mins
[32m[0511 22:02:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:02:46 @base_main.py:47][0m 1002 total steps have happened
[32m[0511 22:02:46 @base_main.py:52][0m [avg_reward]: -457.7720789357646
[32m[0511 22:02:47 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:02:47 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:02:47 @base_trainer.py:216][0m Mean reward: -436.8233333794318
[32m[0511 22:02:47 @base_main.py:38][0m --------------- Iteration 2 ---------------
[32m[0511 22:02:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0198 mins
[32m[0511 22:02:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0053 mins
[32m[0511 22:02:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 22:02:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:02:47 @base_main.py:47][0m 2004 total steps have happened
[32m[0511 22:02:47 @base_main.py:52][0m [avg_reward]: -436.8233333794318
[32m[0511 22:02:48 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:02:48 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:02:48 @base_trainer.py:216][0m Mean reward: -456.43796932989227
[32m[0511 22:02:48 @base_main.py:38][0m --------------- Iteration 3 ---------------
[32m[0511 22:02:48 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0355 mins
[32m[0511 22:02:48 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0046 mins
[32m[0511 22:02:48 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 22:02:48 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:02:48 @base_main.py:47][0m 3006 total steps have happened
[32m[0511 22:02:48 @base_main.py:52][0m [avg_reward]: -456.43796932989227
[32m[0511 22:02:49 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:02:49 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:02:49 @base_trainer.py:216][0m Mean reward: -454.17140818227153
[32m[0511 22:02:49 @base_main.py:38][0m --------------- Iteration 4 ---------------
[32m[0511 22:02:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0505 mins
[32m[0511 22:02:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0037 mins
[32m[0511 22:02:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0511 22:02:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:02:49 @base_main.py:47][0m 4008 total steps have happened
[32m[0511 22:02:49 @base_main.py:52][0m [avg_reward]: -454.17140818227153
[32m[0511 22:02:49 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:02:49 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:02:49 @base_trainer.py:216][0m Mean reward: -454.6563309241
[32m[0511 22:02:50 @base_main.py:38][0m --------------- Iteration 5 ---------------
[32m[0511 22:02:50 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0636 mins
[32m[0511 22:02:50 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0050 mins
[32m[0511 22:02:50 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 22:02:50 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:02:50 @base_main.py:47][0m 5010 total steps have happened
[32m[0511 22:02:50 @base_main.py:52][0m [avg_reward]: -454.6563309241
[32m[0511 22:02:50 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:02:50 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:02:50 @base_trainer.py:216][0m Mean reward: -453.2127629054547
[32m[0511 22:02:51 @base_main.py:38][0m --------------- Iteration 6 ---------------
[32m[0511 22:02:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0793 mins
[32m[0511 22:02:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0511 22:02:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 22:02:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:02:51 @base_main.py:47][0m 6012 total steps have happened
[32m[0511 22:02:51 @base_main.py:52][0m [avg_reward]: -453.2127629054547
[32m[0511 22:02:51 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:02:51 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:02:51 @base_trainer.py:216][0m Mean reward: -454.17299198151653
[32m[0511 22:02:52 @base_main.py:38][0m --------------- Iteration 7 ---------------
[32m[0511 22:02:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0940 mins
[32m[0511 22:02:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0511 22:02:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 22:02:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:02:52 @base_main.py:47][0m 7014 total steps have happened
[32m[0511 22:02:52 @base_main.py:52][0m [avg_reward]: -454.17299198151653
[32m[0511 22:02:52 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:02:52 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:02:52 @base_trainer.py:216][0m Mean reward: -452.78585038177533
[32m[0511 22:02:53 @base_main.py:38][0m --------------- Iteration 8 ---------------
[32m[0511 22:02:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1077 mins
[32m[0511 22:02:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0050 mins
[32m[0511 22:02:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 22:02:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:02:53 @base_main.py:47][0m 8016 total steps have happened
[32m[0511 22:02:53 @base_main.py:52][0m [avg_reward]: -452.78585038177533
[32m[0511 22:02:53 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:02:53 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:02:53 @base_trainer.py:216][0m Mean reward: -451.3347193886702
[32m[0511 22:02:54 @base_main.py:38][0m --------------- Iteration 9 ---------------
[32m[0511 22:02:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1230 mins
[32m[0511 22:02:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0511 22:02:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 22:02:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:02:54 @base_main.py:47][0m 9018 total steps have happened
[32m[0511 22:02:54 @base_main.py:52][0m [avg_reward]: -451.3347193886702
[32m[0511 22:02:54 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:02:54 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:02:54 @base_trainer.py:216][0m Mean reward: -409.31106851961965
[32m[0511 22:02:54 @base_main.py:38][0m --------------- Iteration 10 ---------------
[32m[0511 22:02:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1375 mins
[32m[0511 22:02:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0051 mins
[32m[0511 22:02:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 22:02:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:02:54 @base_main.py:47][0m 10020 total steps have happened
[32m[0511 22:02:54 @base_main.py:52][0m [avg_reward]: -409.31106851961965
[32m[0511 22:02:55 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:02:55 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:02:55 @base_trainer.py:216][0m Mean reward: -452.927835529777
[32m[0511 22:02:55 @base_main.py:38][0m --------------- Iteration 11 ---------------
[32m[0511 22:02:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1527 mins
[32m[0511 22:02:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0056 mins
[32m[0511 22:02:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 22:02:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:02:55 @base_main.py:47][0m 11022 total steps have happened
[32m[0511 22:02:55 @base_main.py:52][0m [avg_reward]: -452.927835529777
[32m[0511 22:02:56 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:02:56 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:02:56 @base_trainer.py:216][0m Mean reward: -448.3637941951064
[32m[0511 22:02:56 @base_main.py:38][0m --------------- Iteration 12 ---------------
[32m[0511 22:02:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1684 mins
[32m[0511 22:02:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0049 mins
[32m[0511 22:02:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 22:02:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:02:56 @base_main.py:47][0m 12024 total steps have happened
[32m[0511 22:02:56 @base_main.py:52][0m [avg_reward]: -448.3637941951064
[32m[0511 22:02:57 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:02:57 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:02:57 @base_trainer.py:216][0m Mean reward: -454.110154536273
[32m[0511 22:02:57 @base_main.py:38][0m --------------- Iteration 13 ---------------
[32m[0511 22:02:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1839 mins
[32m[0511 22:02:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 22:02:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 22:02:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:02:57 @base_main.py:47][0m 13026 total steps have happened
[32m[0511 22:02:57 @base_main.py:52][0m [avg_reward]: -454.110154536273
[32m[0511 22:02:57 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:02:57 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:02:57 @base_trainer.py:216][0m Mean reward: -452.93136125008425
[32m[0511 22:02:58 @base_main.py:38][0m --------------- Iteration 14 ---------------
[32m[0511 22:02:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1985 mins
[32m[0511 22:02:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0045 mins
[32m[0511 22:02:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 22:02:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:02:58 @base_main.py:47][0m 14028 total steps have happened
[32m[0511 22:02:58 @base_main.py:52][0m [avg_reward]: -452.93136125008425
[32m[0511 22:02:58 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:02:58 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:02:58 @base_trainer.py:216][0m Mean reward: -454.70139294873263
[32m[0511 22:02:59 @base_main.py:38][0m --------------- Iteration 15 ---------------
[32m[0511 22:02:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2132 mins
[32m[0511 22:02:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0036 mins
[32m[0511 22:02:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 22:02:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:02:59 @base_main.py:47][0m 15030 total steps have happened
[32m[0511 22:02:59 @base_main.py:52][0m [avg_reward]: -454.70139294873263
[32m[0511 22:02:59 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:02:59 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:02:59 @base_trainer.py:216][0m Mean reward: -451.95735062734786
[32m[0511 22:03:00 @base_main.py:38][0m --------------- Iteration 16 ---------------
[32m[0511 22:03:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2275 mins
[32m[0511 22:03:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0511 22:03:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0511 22:03:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0511 22:03:00 @base_main.py:47][0m 16032 total steps have happened
[32m[0511 22:03:00 @base_main.py:52][0m [avg_reward]: -451.95735062734786
[32m[0511 22:03:00 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:00 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:00 @base_trainer.py:216][0m Mean reward: -455.4421024324464
[32m[0511 22:03:01 @base_main.py:38][0m --------------- Iteration 17 ---------------
[32m[0511 22:03:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2403 mins
[32m[0511 22:03:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0511 22:03:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 22:03:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:01 @base_main.py:47][0m 17034 total steps have happened
[32m[0511 22:03:01 @base_main.py:52][0m [avg_reward]: -455.4421024324464
[32m[0511 22:03:01 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:01 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:01 @base_trainer.py:216][0m Mean reward: -448.39252111270946
[32m[0511 22:03:01 @base_main.py:38][0m --------------- Iteration 18 ---------------
[32m[0511 22:03:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2552 mins
[32m[0511 22:03:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0036 mins
[32m[0511 22:03:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 22:03:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:01 @base_main.py:47][0m 18036 total steps have happened
[32m[0511 22:03:01 @base_main.py:52][0m [avg_reward]: -448.39252111270946
[32m[0511 22:03:02 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:02 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:02 @base_trainer.py:216][0m Mean reward: -437.91328076519596
[32m[0511 22:03:02 @base_main.py:38][0m --------------- Iteration 19 ---------------
[32m[0511 22:03:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2689 mins
[32m[0511 22:03:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0037 mins
[32m[0511 22:03:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 22:03:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:02 @base_main.py:47][0m 19038 total steps have happened
[32m[0511 22:03:02 @base_main.py:52][0m [avg_reward]: -437.91328076519596
[32m[0511 22:03:03 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:03 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:03 @base_trainer.py:216][0m Mean reward: -435.13315218593533
[32m[0511 22:03:03 @base_main.py:38][0m --------------- Iteration 20 ---------------
[32m[0511 22:03:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2831 mins
[32m[0511 22:03:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0511 22:03:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0511 22:03:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:03 @base_main.py:47][0m 20040 total steps have happened
[32m[0511 22:03:03 @base_main.py:52][0m [avg_reward]: -435.13315218593533
[32m[0511 22:03:03 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:03 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:03 @base_trainer.py:216][0m Mean reward: -437.06972263033174
[32m[0511 22:03:04 @base_main.py:38][0m --------------- Iteration 21 ---------------
[32m[0511 22:03:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2967 mins
[32m[0511 22:03:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0511 22:03:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 22:03:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:04 @base_main.py:47][0m 21042 total steps have happened
[32m[0511 22:03:04 @base_main.py:52][0m [avg_reward]: -437.06972263033174
[32m[0511 22:03:04 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:04 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:04 @base_trainer.py:216][0m Mean reward: -440.281013091813
[32m[0511 22:03:05 @base_main.py:38][0m --------------- Iteration 22 ---------------
[32m[0511 22:03:05 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3111 mins
[32m[0511 22:03:05 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0049 mins
[32m[0511 22:03:05 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 22:03:05 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:05 @base_main.py:47][0m 22044 total steps have happened
[32m[0511 22:03:05 @base_main.py:52][0m [avg_reward]: -440.281013091813
[32m[0511 22:03:05 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:05 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:05 @base_trainer.py:216][0m Mean reward: -431.66288574806845
[32m[0511 22:03:06 @base_main.py:38][0m --------------- Iteration 23 ---------------
[32m[0511 22:03:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3261 mins
[32m[0511 22:03:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 22:03:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0511 22:03:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:06 @base_main.py:47][0m 23046 total steps have happened
[32m[0511 22:03:06 @base_main.py:52][0m [avg_reward]: -431.66288574806845
[32m[0511 22:03:06 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:06 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:06 @base_trainer.py:216][0m Mean reward: -436.24189594760287
[32m[0511 22:03:07 @base_main.py:38][0m --------------- Iteration 24 ---------------
[32m[0511 22:03:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3394 mins
[32m[0511 22:03:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0043 mins
[32m[0511 22:03:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 22:03:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:07 @base_main.py:47][0m 24048 total steps have happened
[32m[0511 22:03:07 @base_main.py:52][0m [avg_reward]: -436.24189594760287
[32m[0511 22:03:07 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:07 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:07 @base_trainer.py:216][0m Mean reward: -435.94040874631975
[32m[0511 22:03:07 @base_main.py:38][0m --------------- Iteration 25 ---------------
[32m[0511 22:03:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3543 mins
[32m[0511 22:03:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0045 mins
[32m[0511 22:03:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 22:03:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:07 @base_main.py:47][0m 25050 total steps have happened
[32m[0511 22:03:07 @base_main.py:52][0m [avg_reward]: -435.94040874631975
[32m[0511 22:03:08 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:08 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:08 @base_trainer.py:216][0m Mean reward: -439.62629190833155
[32m[0511 22:03:08 @base_main.py:38][0m --------------- Iteration 26 ---------------
[32m[0511 22:03:08 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3689 mins
[32m[0511 22:03:08 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0044 mins
[32m[0511 22:03:08 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 22:03:08 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:08 @base_main.py:47][0m 26052 total steps have happened
[32m[0511 22:03:08 @base_main.py:52][0m [avg_reward]: -439.62629190833155
[32m[0511 22:03:09 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:09 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:09 @base_trainer.py:216][0m Mean reward: -439.84141287328083
[32m[0511 22:03:09 @base_main.py:38][0m --------------- Iteration 27 ---------------
[32m[0511 22:03:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3835 mins
[32m[0511 22:03:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0037 mins
[32m[0511 22:03:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 22:03:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:09 @base_main.py:47][0m 27054 total steps have happened
[32m[0511 22:03:09 @base_main.py:52][0m [avg_reward]: -439.84141287328083
[32m[0511 22:03:09 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:09 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:09 @base_trainer.py:216][0m Mean reward: -439.88759844899175
[32m[0511 22:03:10 @base_main.py:38][0m --------------- Iteration 28 ---------------
[32m[0511 22:03:10 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3979 mins
[32m[0511 22:03:10 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0047 mins
[32m[0511 22:03:10 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 22:03:10 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:10 @base_main.py:47][0m 28056 total steps have happened
[32m[0511 22:03:10 @base_main.py:52][0m [avg_reward]: -439.88759844899175
[32m[0511 22:03:10 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:10 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:10 @base_trainer.py:216][0m Mean reward: -441.3814507758223
[32m[0511 22:03:11 @base_main.py:38][0m --------------- Iteration 29 ---------------
[32m[0511 22:03:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4131 mins
[32m[0511 22:03:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 22:03:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 22:03:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0511 22:03:11 @base_main.py:47][0m 29058 total steps have happened
[32m[0511 22:03:11 @base_main.py:52][0m [avg_reward]: -441.3814507758223
[32m[0511 22:03:11 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:11 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:11 @base_trainer.py:216][0m Mean reward: -438.414553805678
[32m[0511 22:03:12 @base_main.py:38][0m --------------- Iteration 30 ---------------
[32m[0511 22:03:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4279 mins
[32m[0511 22:03:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0038 mins
[32m[0511 22:03:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 22:03:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:12 @base_main.py:47][0m 30060 total steps have happened
[32m[0511 22:03:12 @base_main.py:52][0m [avg_reward]: -438.414553805678
[32m[0511 22:03:12 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:12 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:12 @base_trainer.py:216][0m Mean reward: -438.8674930395911
[32m[0511 22:03:13 @base_main.py:38][0m --------------- Iteration 31 ---------------
[32m[0511 22:03:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4419 mins
[32m[0511 22:03:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 22:03:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 22:03:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:13 @base_main.py:47][0m 31062 total steps have happened
[32m[0511 22:03:13 @base_main.py:52][0m [avg_reward]: -438.8674930395911
[32m[0511 22:03:13 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:13 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:13 @base_trainer.py:216][0m Mean reward: -438.7844637874768
[32m[0511 22:03:14 @base_main.py:38][0m --------------- Iteration 32 ---------------
[32m[0511 22:03:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4565 mins
[32m[0511 22:03:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0038 mins
[32m[0511 22:03:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0107 mins
[32m[0511 22:03:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:14 @base_main.py:47][0m 32064 total steps have happened
[32m[0511 22:03:14 @base_main.py:52][0m [avg_reward]: -438.7844637874768
[32m[0511 22:03:14 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:14 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:14 @base_trainer.py:216][0m Mean reward: -435.8556988428565
[32m[0511 22:03:14 @base_main.py:38][0m --------------- Iteration 33 ---------------
[32m[0511 22:03:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4712 mins
[32m[0511 22:03:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0043 mins
[32m[0511 22:03:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0107 mins
[32m[0511 22:03:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:14 @base_main.py:47][0m 33066 total steps have happened
[32m[0511 22:03:14 @base_main.py:52][0m [avg_reward]: -435.8556988428565
[32m[0511 22:03:15 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:15 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:15 @base_trainer.py:216][0m Mean reward: -438.62551309740843
[32m[0511 22:03:15 @base_main.py:38][0m --------------- Iteration 34 ---------------
[32m[0511 22:03:15 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4863 mins
[32m[0511 22:03:15 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0037 mins
[32m[0511 22:03:15 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 22:03:15 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:15 @base_main.py:47][0m 34068 total steps have happened
[32m[0511 22:03:15 @base_main.py:52][0m [avg_reward]: -438.62551309740843
[32m[0511 22:03:16 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:16 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:16 @base_trainer.py:216][0m Mean reward: -439.3293682645533
[32m[0511 22:03:16 @base_main.py:38][0m --------------- Iteration 35 ---------------
[32m[0511 22:03:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4998 mins
[32m[0511 22:03:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0044 mins
[32m[0511 22:03:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 22:03:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:16 @base_main.py:47][0m 35070 total steps have happened
[32m[0511 22:03:16 @base_main.py:52][0m [avg_reward]: -439.3293682645533
[32m[0511 22:03:16 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:16 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:16 @base_trainer.py:216][0m Mean reward: -437.3595265838817
[32m[0511 22:03:17 @base_main.py:38][0m --------------- Iteration 36 ---------------
[32m[0511 22:03:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5147 mins
[32m[0511 22:03:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0511 22:03:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 22:03:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:17 @base_main.py:47][0m 36072 total steps have happened
[32m[0511 22:03:17 @base_main.py:52][0m [avg_reward]: -437.3595265838817
[32m[0511 22:03:17 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:17 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:17 @base_trainer.py:216][0m Mean reward: -435.0112777665199
[32m[0511 22:03:18 @base_main.py:38][0m --------------- Iteration 37 ---------------
[32m[0511 22:03:18 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5295 mins
[32m[0511 22:03:18 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0043 mins
[32m[0511 22:03:18 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0109 mins
[32m[0511 22:03:18 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:18 @base_main.py:47][0m 37074 total steps have happened
[32m[0511 22:03:18 @base_main.py:52][0m [avg_reward]: -435.0112777665199
[32m[0511 22:03:18 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:18 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:18 @base_trainer.py:216][0m Mean reward: -437.00228403244535
[32m[0511 22:03:19 @base_main.py:38][0m --------------- Iteration 38 ---------------
[32m[0511 22:03:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5448 mins
[32m[0511 22:03:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0511 22:03:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 22:03:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:19 @base_main.py:47][0m 38076 total steps have happened
[32m[0511 22:03:19 @base_main.py:52][0m [avg_reward]: -437.00228403244535
[32m[0511 22:03:19 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:19 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:19 @base_trainer.py:216][0m Mean reward: -433.71968548468965
[32m[0511 22:03:20 @base_main.py:38][0m --------------- Iteration 39 ---------------
[32m[0511 22:03:20 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5594 mins
[32m[0511 22:03:20 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0511 22:03:20 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 22:03:20 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0511 22:03:20 @base_main.py:47][0m 39078 total steps have happened
[32m[0511 22:03:20 @base_main.py:52][0m [avg_reward]: -433.71968548468965
[32m[0511 22:03:20 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:20 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:20 @base_trainer.py:216][0m Mean reward: -416.3064913053967
[32m[0511 22:03:21 @base_main.py:38][0m --------------- Iteration 40 ---------------
[32m[0511 22:03:21 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5736 mins
[32m[0511 22:03:21 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0037 mins
[32m[0511 22:03:21 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0108 mins
[32m[0511 22:03:21 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:21 @base_main.py:47][0m 40080 total steps have happened
[32m[0511 22:03:21 @base_main.py:52][0m [avg_reward]: -416.3064913053967
[32m[0511 22:03:21 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:21 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:21 @base_trainer.py:216][0m Mean reward: -437.7158911645741
[32m[0511 22:03:21 @base_main.py:38][0m --------------- Iteration 41 ---------------
[32m[0511 22:03:21 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5882 mins
[32m[0511 22:03:21 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0045 mins
[32m[0511 22:03:21 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 22:03:21 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:21 @base_main.py:47][0m 41082 total steps have happened
[32m[0511 22:03:21 @base_main.py:52][0m [avg_reward]: -437.7158911645741
[32m[0511 22:03:22 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:22 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:22 @base_trainer.py:216][0m Mean reward: -403.4838605138703
[32m[0511 22:03:22 @base_main.py:38][0m --------------- Iteration 42 ---------------
[32m[0511 22:03:22 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6032 mins
[32m[0511 22:03:22 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0035 mins
[32m[0511 22:03:22 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 22:03:22 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:22 @base_main.py:47][0m 42084 total steps have happened
[32m[0511 22:03:22 @base_main.py:52][0m [avg_reward]: -403.4838605138703
[32m[0511 22:03:23 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:23 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:23 @base_trainer.py:216][0m Mean reward: -417.50298407554635
[32m[0511 22:03:23 @base_main.py:38][0m --------------- Iteration 43 ---------------
[32m[0511 22:03:23 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6171 mins
[32m[0511 22:03:23 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0048 mins
[32m[0511 22:03:23 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 22:03:23 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:23 @base_main.py:47][0m 43086 total steps have happened
[32m[0511 22:03:23 @base_main.py:52][0m [avg_reward]: -417.50298407554635
[32m[0511 22:03:23 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:23 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:23 @base_trainer.py:216][0m Mean reward: -401.84267582614393
[32m[0511 22:03:24 @base_main.py:38][0m --------------- Iteration 44 ---------------
[32m[0511 22:03:24 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6324 mins
[32m[0511 22:03:24 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0043 mins
[32m[0511 22:03:24 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 22:03:24 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:24 @base_main.py:47][0m 44088 total steps have happened
[32m[0511 22:03:24 @base_main.py:52][0m [avg_reward]: -401.84267582614393
[32m[0511 22:03:24 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:24 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:24 @base_trainer.py:216][0m Mean reward: -405.9307035826906
[32m[0511 22:03:25 @base_main.py:38][0m --------------- Iteration 45 ---------------
[32m[0511 22:03:25 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6472 mins
[32m[0511 22:03:25 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0511 22:03:25 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0511 22:03:25 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:25 @base_main.py:47][0m 45090 total steps have happened
[32m[0511 22:03:25 @base_main.py:52][0m [avg_reward]: -405.9307035826906
[32m[0511 22:03:25 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:25 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:25 @base_trainer.py:216][0m Mean reward: -429.71003319522777
[32m[0511 22:03:26 @base_main.py:38][0m --------------- Iteration 46 ---------------
[32m[0511 22:03:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6608 mins
[32m[0511 22:03:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0511 22:03:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 22:03:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:26 @base_main.py:47][0m 46092 total steps have happened
[32m[0511 22:03:26 @base_main.py:52][0m [avg_reward]: -429.71003319522777
[32m[0511 22:03:26 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:26 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:26 @base_trainer.py:216][0m Mean reward: -430.8665137903588
[32m[0511 22:03:27 @base_main.py:38][0m --------------- Iteration 47 ---------------
[32m[0511 22:03:27 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6750 mins
[32m[0511 22:03:27 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0511 22:03:27 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 22:03:27 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:27 @base_main.py:47][0m 47094 total steps have happened
[32m[0511 22:03:27 @base_main.py:52][0m [avg_reward]: -430.8665137903588
[32m[0511 22:03:27 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:27 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:27 @base_trainer.py:216][0m Mean reward: -420.2126084849942
[32m[0511 22:03:28 @base_main.py:38][0m --------------- Iteration 48 ---------------
[32m[0511 22:03:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6891 mins
[32m[0511 22:03:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0045 mins
[32m[0511 22:03:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0108 mins
[32m[0511 22:03:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:28 @base_main.py:47][0m 48096 total steps have happened
[32m[0511 22:03:28 @base_main.py:52][0m [avg_reward]: -420.2126084849942
[32m[0511 22:03:28 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:28 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:28 @base_trainer.py:216][0m Mean reward: -426.8767323892326
[32m[0511 22:03:28 @base_main.py:38][0m --------------- Iteration 49 ---------------
[32m[0511 22:03:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7044 mins
[32m[0511 22:03:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 22:03:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0107 mins
[32m[0511 22:03:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:28 @base_main.py:47][0m 49098 total steps have happened
[32m[0511 22:03:28 @base_main.py:52][0m [avg_reward]: -426.8767323892326
[32m[0511 22:03:29 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:29 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:29 @base_trainer.py:216][0m Mean reward: -420.56649997286115
[32m[0511 22:03:29 @base_main.py:38][0m --------------- Iteration 50 ---------------
[32m[0511 22:03:29 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7193 mins
[32m[0511 22:03:29 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0045 mins
[32m[0511 22:03:29 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 22:03:29 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:29 @base_main.py:47][0m 50100 total steps have happened
[32m[0511 22:03:29 @base_main.py:52][0m [avg_reward]: -420.56649997286115
[32m[0511 22:03:30 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:30 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:30 @base_trainer.py:216][0m Mean reward: -419.252582035455
[32m[0511 22:03:30 @base_main.py:38][0m --------------- Iteration 51 ---------------
[32m[0511 22:03:30 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7344 mins
[32m[0511 22:03:30 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0038 mins
[32m[0511 22:03:30 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 22:03:30 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:30 @base_main.py:47][0m 51102 total steps have happened
[32m[0511 22:03:30 @base_main.py:52][0m [avg_reward]: -419.252582035455
[32m[0511 22:03:30 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:30 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:30 @base_trainer.py:216][0m Mean reward: -417.10905270733434
[32m[0511 22:03:31 @base_main.py:38][0m --------------- Iteration 52 ---------------
[32m[0511 22:03:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7483 mins
[32m[0511 22:03:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 22:03:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 22:03:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:31 @base_main.py:47][0m 52104 total steps have happened
[32m[0511 22:03:31 @base_main.py:52][0m [avg_reward]: -417.10905270733434
[32m[0511 22:03:31 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:31 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:31 @base_trainer.py:216][0m Mean reward: -391.31311833139273
[32m[0511 22:03:32 @base_main.py:38][0m --------------- Iteration 53 ---------------
[32m[0511 22:03:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7626 mins
[32m[0511 22:03:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0034 mins
[32m[0511 22:03:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 22:03:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:32 @base_main.py:47][0m 53106 total steps have happened
[32m[0511 22:03:32 @base_main.py:52][0m [avg_reward]: -391.31311833139273
[32m[0511 22:03:32 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:32 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:32 @base_trainer.py:216][0m Mean reward: -411.6553931638532
[32m[0511 22:03:33 @base_main.py:38][0m --------------- Iteration 54 ---------------
[32m[0511 22:03:33 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7759 mins
[32m[0511 22:03:33 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0511 22:03:33 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 22:03:33 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:33 @base_main.py:47][0m 54108 total steps have happened
[32m[0511 22:03:33 @base_main.py:52][0m [avg_reward]: -411.6553931638532
[32m[0511 22:03:33 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:33 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:33 @base_trainer.py:216][0m Mean reward: -410.22073926093236
[32m[0511 22:03:34 @base_main.py:38][0m --------------- Iteration 55 ---------------
[32m[0511 22:03:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7901 mins
[32m[0511 22:03:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 22:03:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0511 22:03:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:34 @base_main.py:47][0m 55110 total steps have happened
[32m[0511 22:03:34 @base_main.py:52][0m [avg_reward]: -410.22073926093236
[32m[0511 22:03:34 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:34 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:34 @base_trainer.py:216][0m Mean reward: -393.3851560829724
[32m[0511 22:03:34 @base_main.py:38][0m --------------- Iteration 56 ---------------
[32m[0511 22:03:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8037 mins
[32m[0511 22:03:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0511 22:03:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 22:03:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:34 @base_main.py:47][0m 56112 total steps have happened
[32m[0511 22:03:34 @base_main.py:52][0m [avg_reward]: -393.3851560829724
[32m[0511 22:03:35 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:35 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:35 @base_trainer.py:216][0m Mean reward: -307.76243610179523
[32m[0511 22:03:35 @base_main.py:38][0m --------------- Iteration 57 ---------------
[32m[0511 22:03:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8183 mins
[32m[0511 22:03:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 22:03:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 22:03:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:35 @base_main.py:47][0m 57114 total steps have happened
[32m[0511 22:03:35 @base_main.py:52][0m [avg_reward]: -307.76243610179523
[32m[0511 22:03:36 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:36 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:36 @base_trainer.py:216][0m Mean reward: -341.1927597727534
[32m[0511 22:03:36 @base_main.py:38][0m --------------- Iteration 58 ---------------
[32m[0511 22:03:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8329 mins
[32m[0511 22:03:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0045 mins
[32m[0511 22:03:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 22:03:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:36 @base_main.py:47][0m 58116 total steps have happened
[32m[0511 22:03:36 @base_main.py:52][0m [avg_reward]: -341.1927597727534
[32m[0511 22:03:36 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:36 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:36 @base_trainer.py:216][0m Mean reward: -342.4456290427049
[32m[0511 22:03:37 @base_main.py:38][0m --------------- Iteration 59 ---------------
[32m[0511 22:03:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8478 mins
[32m[0511 22:03:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 22:03:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 22:03:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:37 @base_main.py:47][0m 59118 total steps have happened
[32m[0511 22:03:37 @base_main.py:52][0m [avg_reward]: -342.4456290427049
[32m[0511 22:03:37 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:37 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:37 @base_trainer.py:216][0m Mean reward: -292.8750093762668
[32m[0511 22:03:38 @base_main.py:38][0m --------------- Iteration 60 ---------------
[32m[0511 22:03:38 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8616 mins
[32m[0511 22:03:38 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 22:03:38 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 22:03:38 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:38 @base_main.py:47][0m 60120 total steps have happened
[32m[0511 22:03:38 @base_main.py:52][0m [avg_reward]: -292.8750093762668
[32m[0511 22:03:38 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:38 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:38 @base_trainer.py:216][0m Mean reward: -267.6389726504394
[32m[0511 22:03:39 @base_main.py:38][0m --------------- Iteration 61 ---------------
[32m[0511 22:03:39 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8758 mins
[32m[0511 22:03:39 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0511 22:03:39 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 22:03:39 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:39 @base_main.py:47][0m 61122 total steps have happened
[32m[0511 22:03:39 @base_main.py:52][0m [avg_reward]: -267.6389726504394
[32m[0511 22:03:39 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:39 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:39 @base_trainer.py:216][0m Mean reward: -276.64712363700926
[32m[0511 22:03:40 @base_main.py:38][0m --------------- Iteration 62 ---------------
[32m[0511 22:03:40 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8906 mins
[32m[0511 22:03:40 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0044 mins
[32m[0511 22:03:40 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 22:03:40 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:40 @base_main.py:47][0m 62124 total steps have happened
[32m[0511 22:03:40 @base_main.py:52][0m [avg_reward]: -276.64712363700926
[32m[0511 22:03:40 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:40 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:40 @base_trainer.py:216][0m Mean reward: -242.20258263908067
[32m[0511 22:03:40 @base_main.py:38][0m --------------- Iteration 63 ---------------
[32m[0511 22:03:40 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9052 mins
[32m[0511 22:03:40 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0037 mins
[32m[0511 22:03:40 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 22:03:40 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:40 @base_main.py:47][0m 63126 total steps have happened
[32m[0511 22:03:40 @base_main.py:52][0m [avg_reward]: -242.20258263908067
[32m[0511 22:03:41 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:41 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:41 @base_trainer.py:216][0m Mean reward: -248.8164718627218
[32m[0511 22:03:41 @base_main.py:38][0m --------------- Iteration 64 ---------------
[32m[0511 22:03:41 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9192 mins
[32m[0511 22:03:41 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 22:03:41 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 22:03:41 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:41 @base_main.py:47][0m 64128 total steps have happened
[32m[0511 22:03:41 @base_main.py:52][0m [avg_reward]: -248.8164718627218
[32m[0511 22:03:42 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:42 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:42 @base_trainer.py:216][0m Mean reward: -300.21668266158173
[32m[0511 22:03:42 @base_main.py:38][0m --------------- Iteration 65 ---------------
[32m[0511 22:03:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9331 mins
[32m[0511 22:03:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0511 22:03:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 22:03:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:42 @base_main.py:47][0m 65130 total steps have happened
[32m[0511 22:03:42 @base_main.py:52][0m [avg_reward]: -300.21668266158173
[32m[0511 22:03:42 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:42 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:42 @base_trainer.py:216][0m Mean reward: -301.7863447727309
[32m[0511 22:03:43 @base_main.py:38][0m --------------- Iteration 66 ---------------
[32m[0511 22:03:43 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9475 mins
[32m[0511 22:03:43 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0511 22:03:43 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 22:03:43 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:43 @base_main.py:47][0m 66132 total steps have happened
[32m[0511 22:03:43 @base_main.py:52][0m [avg_reward]: -301.7863447727309
[32m[0511 22:03:43 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:43 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:43 @base_trainer.py:216][0m Mean reward: -302.9549003465039
[32m[0511 22:03:44 @base_main.py:38][0m --------------- Iteration 67 ---------------
[32m[0511 22:03:44 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9619 mins
[32m[0511 22:03:44 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0038 mins
[32m[0511 22:03:44 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 22:03:44 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:44 @base_main.py:47][0m 67134 total steps have happened
[32m[0511 22:03:44 @base_main.py:52][0m [avg_reward]: -302.9549003465039
[32m[0511 22:03:44 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:44 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:44 @base_trainer.py:216][0m Mean reward: -297.7862976620105
[32m[0511 22:03:45 @base_main.py:38][0m --------------- Iteration 68 ---------------
[32m[0511 22:03:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9760 mins
[32m[0511 22:03:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0036 mins
[32m[0511 22:03:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 22:03:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:45 @base_main.py:47][0m 68136 total steps have happened
[32m[0511 22:03:45 @base_main.py:52][0m [avg_reward]: -297.7862976620105
[32m[0511 22:03:45 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:45 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:45 @base_trainer.py:216][0m Mean reward: -265.71814914643426
[32m[0511 22:03:46 @base_main.py:38][0m --------------- Iteration 69 ---------------
[32m[0511 22:03:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9900 mins
[32m[0511 22:03:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0035 mins
[32m[0511 22:03:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 22:03:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0511 22:03:46 @base_main.py:47][0m 69138 total steps have happened
[32m[0511 22:03:46 @base_main.py:52][0m [avg_reward]: -265.71814914643426
[32m[0511 22:03:46 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:46 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:46 @base_trainer.py:216][0m Mean reward: -306.4032602109475
[32m[0511 22:03:46 @base_main.py:38][0m --------------- Iteration 70 ---------------
[32m[0511 22:03:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0040 mins
[32m[0511 22:03:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0047 mins
[32m[0511 22:03:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 22:03:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:46 @base_main.py:47][0m 70140 total steps have happened
[32m[0511 22:03:46 @base_main.py:52][0m [avg_reward]: -306.4032602109475
[32m[0511 22:03:47 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:47 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:47 @base_trainer.py:216][0m Mean reward: -313.6326992998493
[32m[0511 22:03:47 @base_main.py:38][0m --------------- Iteration 71 ---------------
[32m[0511 22:03:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0193 mins
[32m[0511 22:03:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0511 22:03:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 22:03:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:47 @base_main.py:47][0m 71142 total steps have happened
[32m[0511 22:03:47 @base_main.py:52][0m [avg_reward]: -313.6326992998493
[32m[0511 22:03:48 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:48 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:48 @base_trainer.py:216][0m Mean reward: -313.6041967615108
[32m[0511 22:03:48 @base_main.py:38][0m --------------- Iteration 72 ---------------
[32m[0511 22:03:48 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0333 mins
[32m[0511 22:03:48 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0046 mins
[32m[0511 22:03:48 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 22:03:48 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:48 @base_main.py:47][0m 72144 total steps have happened
[32m[0511 22:03:48 @base_main.py:52][0m [avg_reward]: -313.6041967615108
[32m[0511 22:03:48 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:48 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:48 @base_trainer.py:216][0m Mean reward: -331.9425004938596
[32m[0511 22:03:49 @base_main.py:38][0m --------------- Iteration 73 ---------------
[32m[0511 22:03:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0478 mins
[32m[0511 22:03:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0511 22:03:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 22:03:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:49 @base_main.py:47][0m 73146 total steps have happened
[32m[0511 22:03:49 @base_main.py:52][0m [avg_reward]: -331.9425004938596
[32m[0511 22:03:49 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:49 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:49 @base_trainer.py:216][0m Mean reward: -327.3648351348745
[32m[0511 22:03:50 @base_main.py:38][0m --------------- Iteration 74 ---------------
[32m[0511 22:03:50 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0618 mins
[32m[0511 22:03:50 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 22:03:50 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0511 22:03:50 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:50 @base_main.py:47][0m 74148 total steps have happened
[32m[0511 22:03:50 @base_main.py:52][0m [avg_reward]: -327.3648351348745
[32m[0511 22:03:50 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:50 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:50 @base_trainer.py:216][0m Mean reward: -337.23437386833825
[32m[0511 22:03:51 @base_main.py:38][0m --------------- Iteration 75 ---------------
[32m[0511 22:03:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0752 mins
[32m[0511 22:03:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 22:03:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 22:03:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0511 22:03:51 @base_main.py:47][0m 75150 total steps have happened
[32m[0511 22:03:51 @base_main.py:52][0m [avg_reward]: -337.23437386833825
[32m[0511 22:03:51 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:51 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:51 @base_trainer.py:216][0m Mean reward: -348.74666150912856
[32m[0511 22:03:52 @base_main.py:38][0m --------------- Iteration 76 ---------------
[32m[0511 22:03:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0896 mins
[32m[0511 22:03:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0044 mins
[32m[0511 22:03:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0511 22:03:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:52 @base_main.py:47][0m 76152 total steps have happened
[32m[0511 22:03:52 @base_main.py:52][0m [avg_reward]: -348.74666150912856
[32m[0511 22:03:52 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:52 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:52 @base_trainer.py:216][0m Mean reward: -435.8023480833957
[32m[0511 22:03:52 @base_main.py:38][0m --------------- Iteration 77 ---------------
[32m[0511 22:03:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1036 mins
[32m[0511 22:03:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0034 mins
[32m[0511 22:03:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0511 22:03:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:52 @base_main.py:47][0m 77154 total steps have happened
[32m[0511 22:03:52 @base_main.py:52][0m [avg_reward]: -435.8023480833957
[32m[0511 22:03:53 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:53 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:53 @base_trainer.py:216][0m Mean reward: -441.4303576351409
[32m[0511 22:03:53 @base_main.py:38][0m --------------- Iteration 78 ---------------
[32m[0511 22:03:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1166 mins
[32m[0511 22:03:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0043 mins
[32m[0511 22:03:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 22:03:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:53 @base_main.py:47][0m 78156 total steps have happened
[32m[0511 22:03:53 @base_main.py:52][0m [avg_reward]: -441.4303576351409
[32m[0511 22:03:53 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:53 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:53 @base_trainer.py:216][0m Mean reward: -450.3662092213747
[32m[0511 22:03:54 @base_main.py:38][0m --------------- Iteration 79 ---------------
[32m[0511 22:03:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1314 mins
[32m[0511 22:03:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0511 22:03:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 22:03:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:54 @base_main.py:47][0m 79158 total steps have happened
[32m[0511 22:03:54 @base_main.py:52][0m [avg_reward]: -450.3662092213747
[32m[0511 22:03:54 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:54 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:54 @base_trainer.py:216][0m Mean reward: -452.0023979626486
[32m[0511 22:03:55 @base_main.py:38][0m --------------- Iteration 80 ---------------
[32m[0511 22:03:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1464 mins
[32m[0511 22:03:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 22:03:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 22:03:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:55 @base_main.py:47][0m 80160 total steps have happened
[32m[0511 22:03:55 @base_main.py:52][0m [avg_reward]: -452.0023979626486
[32m[0511 22:03:55 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:55 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:55 @base_trainer.py:216][0m Mean reward: -454.7136138611381
[32m[0511 22:03:56 @base_main.py:38][0m --------------- Iteration 81 ---------------
[32m[0511 22:03:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1606 mins
[32m[0511 22:03:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0035 mins
[32m[0511 22:03:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 22:03:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:56 @base_main.py:47][0m 81162 total steps have happened
[32m[0511 22:03:56 @base_main.py:52][0m [avg_reward]: -454.7136138611381
[32m[0511 22:03:56 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:56 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:56 @base_trainer.py:216][0m Mean reward: -456.1260948532388
[32m[0511 22:03:57 @base_main.py:38][0m --------------- Iteration 82 ---------------
[32m[0511 22:03:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1740 mins
[32m[0511 22:03:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0038 mins
[32m[0511 22:03:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 22:03:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:57 @base_main.py:47][0m 82164 total steps have happened
[32m[0511 22:03:57 @base_main.py:52][0m [avg_reward]: -456.1260948532388
[32m[0511 22:03:57 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:57 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:57 @base_trainer.py:216][0m Mean reward: -458.07431657664694
[32m[0511 22:03:57 @base_main.py:38][0m --------------- Iteration 83 ---------------
[32m[0511 22:03:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1881 mins
[32m[0511 22:03:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0046 mins
[32m[0511 22:03:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0107 mins
[32m[0511 22:03:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:58 @base_main.py:47][0m 83166 total steps have happened
[32m[0511 22:03:58 @base_main.py:52][0m [avg_reward]: -458.07431657664694
[32m[0511 22:03:58 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:58 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:58 @base_trainer.py:216][0m Mean reward: -448.38057897942423
[32m[0511 22:03:58 @base_main.py:38][0m --------------- Iteration 84 ---------------
[32m[0511 22:03:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2036 mins
[32m[0511 22:03:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0037 mins
[32m[0511 22:03:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0107 mins
[32m[0511 22:03:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:58 @base_main.py:47][0m 84168 total steps have happened
[32m[0511 22:03:58 @base_main.py:52][0m [avg_reward]: -448.38057897942423
[32m[0511 22:03:59 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:59 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:59 @base_trainer.py:216][0m Mean reward: -447.77239658537343
[32m[0511 22:03:59 @base_main.py:38][0m --------------- Iteration 85 ---------------
[32m[0511 22:03:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2182 mins
[32m[0511 22:03:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0037 mins
[32m[0511 22:03:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0511 22:03:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:03:59 @base_main.py:47][0m 85170 total steps have happened
[32m[0511 22:03:59 @base_main.py:52][0m [avg_reward]: -447.77239658537343
[32m[0511 22:03:59 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:03:59 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:03:59 @base_trainer.py:216][0m Mean reward: -452.5567594846152
[32m[0511 22:04:00 @base_main.py:38][0m --------------- Iteration 86 ---------------
[32m[0511 22:04:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2314 mins
[32m[0511 22:04:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0034 mins
[32m[0511 22:04:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 22:04:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:00 @base_main.py:47][0m 86172 total steps have happened
[32m[0511 22:04:00 @base_main.py:52][0m [avg_reward]: -452.5567594846152
[32m[0511 22:04:00 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:00 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:00 @base_trainer.py:216][0m Mean reward: -452.7873971720278
[32m[0511 22:04:01 @base_main.py:38][0m --------------- Iteration 87 ---------------
[32m[0511 22:04:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2456 mins
[32m[0511 22:04:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0511 22:04:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 22:04:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:01 @base_main.py:47][0m 87174 total steps have happened
[32m[0511 22:04:01 @base_main.py:52][0m [avg_reward]: -452.7873971720278
[32m[0511 22:04:01 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:01 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:01 @base_trainer.py:216][0m Mean reward: -448.5025226105622
[32m[0511 22:04:02 @base_main.py:38][0m --------------- Iteration 88 ---------------
[32m[0511 22:04:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2602 mins
[32m[0511 22:04:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0511 22:04:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 22:04:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:02 @base_main.py:47][0m 88176 total steps have happened
[32m[0511 22:04:02 @base_main.py:52][0m [avg_reward]: -448.5025226105622
[32m[0511 22:04:02 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:02 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:02 @base_trainer.py:216][0m Mean reward: -445.2019152247862
[32m[0511 22:04:03 @base_main.py:38][0m --------------- Iteration 89 ---------------
[32m[0511 22:04:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2746 mins
[32m[0511 22:04:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 22:04:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 22:04:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:03 @base_main.py:47][0m 89178 total steps have happened
[32m[0511 22:04:03 @base_main.py:52][0m [avg_reward]: -445.2019152247862
[32m[0511 22:04:03 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:03 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:03 @base_trainer.py:216][0m Mean reward: -441.9753424077105
[32m[0511 22:04:03 @base_main.py:38][0m --------------- Iteration 90 ---------------
[32m[0511 22:04:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2893 mins
[32m[0511 22:04:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0511 22:04:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 22:04:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:03 @base_main.py:47][0m 90180 total steps have happened
[32m[0511 22:04:03 @base_main.py:52][0m [avg_reward]: -441.9753424077105
[32m[0511 22:04:04 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:04 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:04 @base_trainer.py:216][0m Mean reward: -442.7280768305439
[32m[0511 22:04:04 @base_main.py:38][0m --------------- Iteration 91 ---------------
[32m[0511 22:04:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3032 mins
[32m[0511 22:04:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0037 mins
[32m[0511 22:04:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0511 22:04:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:04 @base_main.py:47][0m 91182 total steps have happened
[32m[0511 22:04:04 @base_main.py:52][0m [avg_reward]: -442.7280768305439
[32m[0511 22:04:04 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:04 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:04 @base_trainer.py:216][0m Mean reward: -444.01738315302816
[32m[0511 22:04:05 @base_main.py:38][0m --------------- Iteration 92 ---------------
[32m[0511 22:04:05 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3162 mins
[32m[0511 22:04:05 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0037 mins
[32m[0511 22:04:05 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 22:04:05 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:05 @base_main.py:47][0m 92184 total steps have happened
[32m[0511 22:04:05 @base_main.py:52][0m [avg_reward]: -444.01738315302816
[32m[0511 22:04:05 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:05 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:05 @base_trainer.py:216][0m Mean reward: -447.4718255009384
[32m[0511 22:04:06 @base_main.py:38][0m --------------- Iteration 93 ---------------
[32m[0511 22:04:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3304 mins
[32m[0511 22:04:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0036 mins
[32m[0511 22:04:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 22:04:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:06 @base_main.py:47][0m 93186 total steps have happened
[32m[0511 22:04:06 @base_main.py:52][0m [avg_reward]: -447.4718255009384
[32m[0511 22:04:06 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:06 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:06 @base_trainer.py:216][0m Mean reward: -437.4736077528571
[32m[0511 22:04:07 @base_main.py:38][0m --------------- Iteration 94 ---------------
[32m[0511 22:04:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3441 mins
[32m[0511 22:04:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0511 22:04:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 22:04:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:07 @base_main.py:47][0m 94188 total steps have happened
[32m[0511 22:04:07 @base_main.py:52][0m [avg_reward]: -437.4736077528571
[32m[0511 22:04:07 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:07 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:07 @base_trainer.py:216][0m Mean reward: -441.993267624064
[32m[0511 22:04:08 @base_main.py:38][0m --------------- Iteration 95 ---------------
[32m[0511 22:04:08 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3590 mins
[32m[0511 22:04:08 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0053 mins
[32m[0511 22:04:08 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 22:04:08 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:08 @base_main.py:47][0m 95190 total steps have happened
[32m[0511 22:04:08 @base_main.py:52][0m [avg_reward]: -441.993267624064
[32m[0511 22:04:08 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:08 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:08 @base_trainer.py:216][0m Mean reward: -440.0948076777728
[32m[0511 22:04:09 @base_main.py:38][0m --------------- Iteration 96 ---------------
[32m[0511 22:04:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3751 mins
[32m[0511 22:04:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0050 mins
[32m[0511 22:04:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 22:04:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:09 @base_main.py:47][0m 96192 total steps have happened
[32m[0511 22:04:09 @base_main.py:52][0m [avg_reward]: -440.0948076777728
[32m[0511 22:04:09 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:09 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:09 @base_trainer.py:216][0m Mean reward: -441.37333180545346
[32m[0511 22:04:10 @base_main.py:38][0m --------------- Iteration 97 ---------------
[32m[0511 22:04:10 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3907 mins
[32m[0511 22:04:10 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0046 mins
[32m[0511 22:04:10 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0107 mins
[32m[0511 22:04:10 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:10 @base_main.py:47][0m 97194 total steps have happened
[32m[0511 22:04:10 @base_main.py:52][0m [avg_reward]: -441.37333180545346
[32m[0511 22:04:10 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:10 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:10 @base_trainer.py:216][0m Mean reward: -439.02990105689594
[32m[0511 22:04:11 @base_main.py:38][0m --------------- Iteration 98 ---------------
[32m[0511 22:04:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4061 mins
[32m[0511 22:04:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0044 mins
[32m[0511 22:04:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 22:04:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:11 @base_main.py:47][0m 98196 total steps have happened
[32m[0511 22:04:11 @base_main.py:52][0m [avg_reward]: -439.02990105689594
[32m[0511 22:04:11 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:11 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:11 @base_trainer.py:216][0m Mean reward: -437.28456817008436
[32m[0511 22:04:11 @base_main.py:38][0m --------------- Iteration 99 ---------------
[32m[0511 22:04:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4211 mins
[32m[0511 22:04:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0047 mins
[32m[0511 22:04:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0511 22:04:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:11 @base_main.py:47][0m 99198 total steps have happened
[32m[0511 22:04:11 @base_main.py:52][0m [avg_reward]: -437.28456817008436
[32m[0511 22:04:12 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:12 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:12 @base_trainer.py:216][0m Mean reward: -410.7894128988981
[32m[0511 22:04:12 @base_main.py:38][0m --------------- Iteration 100 ---------------
[32m[0511 22:04:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4352 mins
[32m[0511 22:04:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0036 mins
[32m[0511 22:04:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 22:04:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:12 @base_main.py:47][0m 100200 total steps have happened
[32m[0511 22:04:12 @base_main.py:52][0m [avg_reward]: -410.7894128988981
[32m[0511 22:04:13 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:13 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:13 @base_trainer.py:216][0m Mean reward: -434.03111701911746
[32m[0511 22:04:13 @base_main.py:38][0m --------------- Iteration 101 ---------------
[32m[0511 22:04:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4494 mins
[32m[0511 22:04:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0043 mins
[32m[0511 22:04:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 22:04:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:13 @base_main.py:47][0m 101202 total steps have happened
[32m[0511 22:04:13 @base_main.py:52][0m [avg_reward]: -434.03111701911746
[32m[0511 22:04:13 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:13 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:13 @base_trainer.py:216][0m Mean reward: -382.1330353324709
[32m[0511 22:04:14 @base_main.py:38][0m --------------- Iteration 102 ---------------
[32m[0511 22:04:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4645 mins
[32m[0511 22:04:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0511 22:04:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 22:04:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:14 @base_main.py:47][0m 102204 total steps have happened
[32m[0511 22:04:14 @base_main.py:52][0m [avg_reward]: -382.1330353324709
[32m[0511 22:04:14 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:14 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:14 @base_trainer.py:216][0m Mean reward: -387.60080383861316
[32m[0511 22:04:15 @base_main.py:38][0m --------------- Iteration 103 ---------------
[32m[0511 22:04:15 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4794 mins
[32m[0511 22:04:15 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0511 22:04:15 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0082 mins
[32m[0511 22:04:15 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:15 @base_main.py:47][0m 103206 total steps have happened
[32m[0511 22:04:15 @base_main.py:52][0m [avg_reward]: -387.60080383861316
[32m[0511 22:04:15 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:15 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:15 @base_trainer.py:216][0m Mean reward: -359.03244828901614
[32m[0511 22:04:16 @base_main.py:38][0m --------------- Iteration 104 ---------------
[32m[0511 22:04:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4917 mins
[32m[0511 22:04:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0044 mins
[32m[0511 22:04:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 22:04:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:16 @base_main.py:47][0m 104208 total steps have happened
[32m[0511 22:04:16 @base_main.py:52][0m [avg_reward]: -359.03244828901614
[32m[0511 22:04:16 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:16 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:16 @base_trainer.py:216][0m Mean reward: -410.80701487855396
[32m[0511 22:04:17 @base_main.py:38][0m --------------- Iteration 105 ---------------
[32m[0511 22:04:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5064 mins
[32m[0511 22:04:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0047 mins
[32m[0511 22:04:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 22:04:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:17 @base_main.py:47][0m 105210 total steps have happened
[32m[0511 22:04:17 @base_main.py:52][0m [avg_reward]: -410.80701487855396
[32m[0511 22:04:17 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:17 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:17 @base_trainer.py:216][0m Mean reward: -412.4507555670227
[32m[0511 22:04:18 @base_main.py:38][0m --------------- Iteration 106 ---------------
[32m[0511 22:04:18 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5218 mins
[32m[0511 22:04:18 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0050 mins
[32m[0511 22:04:18 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 22:04:18 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:18 @base_main.py:47][0m 106212 total steps have happened
[32m[0511 22:04:18 @base_main.py:52][0m [avg_reward]: -412.4507555670227
[32m[0511 22:04:18 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:18 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:18 @base_trainer.py:216][0m Mean reward: -357.45957865095534
[32m[0511 22:04:18 @base_main.py:38][0m --------------- Iteration 107 ---------------
[32m[0511 22:04:18 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5371 mins
[32m[0511 22:04:18 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0511 22:04:18 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 22:04:18 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:18 @base_main.py:47][0m 107214 total steps have happened
[32m[0511 22:04:18 @base_main.py:52][0m [avg_reward]: -357.45957865095534
[32m[0511 22:04:19 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:19 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:19 @base_trainer.py:216][0m Mean reward: -308.6674624805436
[32m[0511 22:04:19 @base_main.py:38][0m --------------- Iteration 108 ---------------
[32m[0511 22:04:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5516 mins
[32m[0511 22:04:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 22:04:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 22:04:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:19 @base_main.py:47][0m 108216 total steps have happened
[32m[0511 22:04:19 @base_main.py:52][0m [avg_reward]: -308.6674624805436
[32m[0511 22:04:19 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:19 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:19 @base_trainer.py:216][0m Mean reward: -284.137678066917
[32m[0511 22:04:20 @base_main.py:38][0m --------------- Iteration 109 ---------------
[32m[0511 22:04:20 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5656 mins
[32m[0511 22:04:20 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0036 mins
[32m[0511 22:04:20 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 22:04:20 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:20 @base_main.py:47][0m 109218 total steps have happened
[32m[0511 22:04:20 @base_main.py:52][0m [avg_reward]: -284.137678066917
[32m[0511 22:04:20 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:20 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:20 @base_trainer.py:216][0m Mean reward: -289.0393757122911
[32m[0511 22:04:21 @base_main.py:38][0m --------------- Iteration 110 ---------------
[32m[0511 22:04:21 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5797 mins
[32m[0511 22:04:21 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0511 22:04:21 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 22:04:21 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:21 @base_main.py:47][0m 110220 total steps have happened
[32m[0511 22:04:21 @base_main.py:52][0m [avg_reward]: -289.0393757122911
[32m[0511 22:04:21 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:21 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:21 @base_trainer.py:216][0m Mean reward: -217.78176579043418
[32m[0511 22:04:22 @base_main.py:38][0m --------------- Iteration 111 ---------------
[32m[0511 22:04:22 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5941 mins
[32m[0511 22:04:22 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0511 22:04:22 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 22:04:22 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:22 @base_main.py:47][0m 111222 total steps have happened
[32m[0511 22:04:22 @base_main.py:52][0m [avg_reward]: -217.78176579043418
[32m[0511 22:04:22 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:22 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:22 @base_trainer.py:216][0m Mean reward: -273.2122234597928
[32m[0511 22:04:23 @base_main.py:38][0m --------------- Iteration 112 ---------------
[32m[0511 22:04:23 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6086 mins
[32m[0511 22:04:23 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0037 mins
[32m[0511 22:04:23 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 22:04:23 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:23 @base_main.py:47][0m 112224 total steps have happened
[32m[0511 22:04:23 @base_main.py:52][0m [avg_reward]: -273.2122234597928
[32m[0511 22:04:23 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:23 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:23 @base_trainer.py:216][0m Mean reward: -271.46361135310246
[32m[0511 22:04:24 @base_main.py:38][0m --------------- Iteration 113 ---------------
[32m[0511 22:04:24 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6229 mins
[32m[0511 22:04:24 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0511 22:04:24 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 22:04:24 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:24 @base_main.py:47][0m 113226 total steps have happened
[32m[0511 22:04:24 @base_main.py:52][0m [avg_reward]: -271.46361135310246
[32m[0511 22:04:24 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:24 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:24 @base_trainer.py:216][0m Mean reward: -340.4833367857558
[32m[0511 22:04:24 @base_main.py:38][0m --------------- Iteration 114 ---------------
[32m[0511 22:04:24 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6371 mins
[32m[0511 22:04:24 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0511 22:04:24 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 22:04:24 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:24 @base_main.py:47][0m 114228 total steps have happened
[32m[0511 22:04:24 @base_main.py:52][0m [avg_reward]: -340.4833367857558
[32m[0511 22:04:25 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:25 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:25 @base_trainer.py:216][0m Mean reward: -358.369873493397
[32m[0511 22:04:25 @base_main.py:38][0m --------------- Iteration 115 ---------------
[32m[0511 22:04:25 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6516 mins
[32m[0511 22:04:25 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0045 mins
[32m[0511 22:04:25 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 22:04:25 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:25 @base_main.py:47][0m 115230 total steps have happened
[32m[0511 22:04:25 @base_main.py:52][0m [avg_reward]: -358.369873493397
[32m[0511 22:04:26 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:26 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:26 @base_trainer.py:216][0m Mean reward: -272.1908942176508
[32m[0511 22:04:26 @base_main.py:38][0m --------------- Iteration 116 ---------------
[32m[0511 22:04:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6662 mins
[32m[0511 22:04:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0044 mins
[32m[0511 22:04:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 22:04:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:26 @base_main.py:47][0m 116232 total steps have happened
[32m[0511 22:04:26 @base_main.py:52][0m [avg_reward]: -272.1908942176508
[32m[0511 22:04:26 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:26 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:26 @base_trainer.py:216][0m Mean reward: -292.26442346936915
[32m[0511 22:04:27 @base_main.py:38][0m --------------- Iteration 117 ---------------
[32m[0511 22:04:27 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6805 mins
[32m[0511 22:04:27 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0511 22:04:27 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0511 22:04:27 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:27 @base_main.py:47][0m 117234 total steps have happened
[32m[0511 22:04:27 @base_main.py:52][0m [avg_reward]: -292.26442346936915
[32m[0511 22:04:27 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:27 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:27 @base_trainer.py:216][0m Mean reward: -299.25912752701913
[32m[0511 22:04:28 @base_main.py:38][0m --------------- Iteration 118 ---------------
[32m[0511 22:04:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6939 mins
[32m[0511 22:04:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0050 mins
[32m[0511 22:04:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 22:04:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:28 @base_main.py:47][0m 118236 total steps have happened
[32m[0511 22:04:28 @base_main.py:52][0m [avg_reward]: -299.25912752701913
[32m[0511 22:04:28 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:28 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:28 @base_trainer.py:216][0m Mean reward: -286.3709627598488
[32m[0511 22:04:29 @base_main.py:38][0m --------------- Iteration 119 ---------------
[32m[0511 22:04:29 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7093 mins
[32m[0511 22:04:29 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0511 22:04:29 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 22:04:29 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:29 @base_main.py:47][0m 119238 total steps have happened
[32m[0511 22:04:29 @base_main.py:52][0m [avg_reward]: -286.3709627598488
[32m[0511 22:04:29 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:29 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:29 @base_trainer.py:216][0m Mean reward: -297.78527901779125
[32m[0511 22:04:30 @base_main.py:38][0m --------------- Iteration 120 ---------------
[32m[0511 22:04:30 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7236 mins
[32m[0511 22:04:30 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0511 22:04:30 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 22:04:30 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:30 @base_main.py:47][0m 120240 total steps have happened
[32m[0511 22:04:30 @base_main.py:52][0m [avg_reward]: -297.78527901779125
[32m[0511 22:04:30 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:30 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:30 @base_trainer.py:216][0m Mean reward: -315.81168221491765
[32m[0511 22:04:30 @base_main.py:38][0m --------------- Iteration 121 ---------------
[32m[0511 22:04:30 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7383 mins
[32m[0511 22:04:30 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 22:04:30 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 22:04:30 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:30 @base_main.py:47][0m 121242 total steps have happened
[32m[0511 22:04:30 @base_main.py:52][0m [avg_reward]: -315.81168221491765
[32m[0511 22:04:31 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:31 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:31 @base_trainer.py:216][0m Mean reward: -255.9264059072048
[32m[0511 22:04:31 @base_main.py:38][0m --------------- Iteration 122 ---------------
[32m[0511 22:04:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7527 mins
[32m[0511 22:04:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0037 mins
[32m[0511 22:04:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0511 22:04:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:31 @base_main.py:47][0m 122244 total steps have happened
[32m[0511 22:04:31 @base_main.py:52][0m [avg_reward]: -255.9264059072048
[32m[0511 22:04:31 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:31 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:31 @base_trainer.py:216][0m Mean reward: -296.0247923065814
[32m[0511 22:04:32 @base_main.py:38][0m --------------- Iteration 123 ---------------
[32m[0511 22:04:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7661 mins
[32m[0511 22:04:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0511 22:04:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 22:04:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:32 @base_main.py:47][0m 123246 total steps have happened
[32m[0511 22:04:32 @base_main.py:52][0m [avg_reward]: -296.0247923065814
[32m[0511 22:04:32 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:32 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:32 @base_trainer.py:216][0m Mean reward: -277.2058146628765
[32m[0511 22:04:33 @base_main.py:38][0m --------------- Iteration 124 ---------------
[32m[0511 22:04:33 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7806 mins
[32m[0511 22:04:33 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0051 mins
[32m[0511 22:04:33 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 22:04:33 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:33 @base_main.py:47][0m 124248 total steps have happened
[32m[0511 22:04:33 @base_main.py:52][0m [avg_reward]: -277.2058146628765
[32m[0511 22:04:33 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:33 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:33 @base_trainer.py:216][0m Mean reward: -302.501544926508
[32m[0511 22:04:34 @base_main.py:38][0m --------------- Iteration 125 ---------------
[32m[0511 22:04:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7962 mins
[32m[0511 22:04:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0037 mins
[32m[0511 22:04:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0511 22:04:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:34 @base_main.py:47][0m 125250 total steps have happened
[32m[0511 22:04:34 @base_main.py:52][0m [avg_reward]: -302.501544926508
[32m[0511 22:04:34 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:34 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:34 @base_trainer.py:216][0m Mean reward: -278.68919105442694
[32m[0511 22:04:35 @base_main.py:38][0m --------------- Iteration 126 ---------------
[32m[0511 22:04:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8095 mins
[32m[0511 22:04:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0511 22:04:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 22:04:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:35 @base_main.py:47][0m 126252 total steps have happened
[32m[0511 22:04:35 @base_main.py:52][0m [avg_reward]: -278.68919105442694
[32m[0511 22:04:35 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:35 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:35 @base_trainer.py:216][0m Mean reward: -318.49611595906475
[32m[0511 22:04:36 @base_main.py:38][0m --------------- Iteration 127 ---------------
[32m[0511 22:04:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8235 mins
[32m[0511 22:04:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0511 22:04:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 22:04:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:36 @base_main.py:47][0m 127254 total steps have happened
[32m[0511 22:04:36 @base_main.py:52][0m [avg_reward]: -318.49611595906475
[32m[0511 22:04:36 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:36 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:36 @base_trainer.py:216][0m Mean reward: -274.7602660915949
[32m[0511 22:04:36 @base_main.py:38][0m --------------- Iteration 128 ---------------
[32m[0511 22:04:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8380 mins
[32m[0511 22:04:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0049 mins
[32m[0511 22:04:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 22:04:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:36 @base_main.py:47][0m 128256 total steps have happened
[32m[0511 22:04:36 @base_main.py:52][0m [avg_reward]: -274.7602660915949
[32m[0511 22:04:37 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:37 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:37 @base_trainer.py:216][0m Mean reward: -307.01885067244996
[32m[0511 22:04:37 @base_main.py:38][0m --------------- Iteration 129 ---------------
[32m[0511 22:04:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8534 mins
[32m[0511 22:04:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0043 mins
[32m[0511 22:04:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 22:04:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:37 @base_main.py:47][0m 129258 total steps have happened
[32m[0511 22:04:37 @base_main.py:52][0m [avg_reward]: -307.01885067244996
[32m[0511 22:04:38 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:38 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:38 @base_trainer.py:216][0m Mean reward: -300.7489779263096
[32m[0511 22:04:38 @base_main.py:38][0m --------------- Iteration 130 ---------------
[32m[0511 22:04:38 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8677 mins
[32m[0511 22:04:38 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0043 mins
[32m[0511 22:04:38 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 22:04:38 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:38 @base_main.py:47][0m 130260 total steps have happened
[32m[0511 22:04:38 @base_main.py:52][0m [avg_reward]: -300.7489779263096
[32m[0511 22:04:38 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:38 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:38 @base_trainer.py:216][0m Mean reward: -324.50583263660445
[32m[0511 22:04:39 @base_main.py:38][0m --------------- Iteration 131 ---------------
[32m[0511 22:04:39 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8825 mins
[32m[0511 22:04:39 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0036 mins
[32m[0511 22:04:39 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 22:04:39 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:39 @base_main.py:47][0m 131262 total steps have happened
[32m[0511 22:04:39 @base_main.py:52][0m [avg_reward]: -324.50583263660445
[32m[0511 22:04:39 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:39 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:39 @base_trainer.py:216][0m Mean reward: -301.180975511052
[32m[0511 22:04:40 @base_main.py:38][0m --------------- Iteration 132 ---------------
[32m[0511 22:04:40 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8963 mins
[32m[0511 22:04:40 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0044 mins
[32m[0511 22:04:40 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 22:04:40 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:40 @base_main.py:47][0m 132264 total steps have happened
[32m[0511 22:04:40 @base_main.py:52][0m [avg_reward]: -301.180975511052
[32m[0511 22:04:40 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:40 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:40 @base_trainer.py:216][0m Mean reward: -298.7857552676188
[32m[0511 22:04:41 @base_main.py:38][0m --------------- Iteration 133 ---------------
[32m[0511 22:04:41 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9113 mins
[32m[0511 22:04:41 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0047 mins
[32m[0511 22:04:41 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 22:04:41 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:41 @base_main.py:47][0m 133266 total steps have happened
[32m[0511 22:04:41 @base_main.py:52][0m [avg_reward]: -298.7857552676188
[32m[0511 22:04:41 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:41 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:41 @base_trainer.py:216][0m Mean reward: -370.3739260426903
[32m[0511 22:04:42 @base_main.py:38][0m --------------- Iteration 134 ---------------
[32m[0511 22:04:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9262 mins
[32m[0511 22:04:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0035 mins
[32m[0511 22:04:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0107 mins
[32m[0511 22:04:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:42 @base_main.py:47][0m 134268 total steps have happened
[32m[0511 22:04:42 @base_main.py:52][0m [avg_reward]: -370.3739260426903
[32m[0511 22:04:42 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:42 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:42 @base_trainer.py:216][0m Mean reward: -333.1049206942868
[32m[0511 22:04:43 @base_main.py:38][0m --------------- Iteration 135 ---------------
[32m[0511 22:04:43 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9406 mins
[32m[0511 22:04:43 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0035 mins
[32m[0511 22:04:43 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 22:04:43 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:43 @base_main.py:47][0m 135270 total steps have happened
[32m[0511 22:04:43 @base_main.py:52][0m [avg_reward]: -333.1049206942868
[32m[0511 22:04:43 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:43 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:43 @base_trainer.py:216][0m Mean reward: -323.61604577836266
[32m[0511 22:04:43 @base_main.py:38][0m --------------- Iteration 136 ---------------
[32m[0511 22:04:43 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9547 mins
[32m[0511 22:04:43 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0043 mins
[32m[0511 22:04:43 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 22:04:43 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:43 @base_main.py:47][0m 136272 total steps have happened
[32m[0511 22:04:43 @base_main.py:52][0m [avg_reward]: -323.61604577836266
[32m[0511 22:04:44 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:44 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:44 @base_trainer.py:216][0m Mean reward: -335.65875878134494
[32m[0511 22:04:44 @base_main.py:38][0m --------------- Iteration 137 ---------------
[32m[0511 22:04:44 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9695 mins
[32m[0511 22:04:44 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0511 22:04:44 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0511 22:04:44 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:44 @base_main.py:47][0m 137274 total steps have happened
[32m[0511 22:04:44 @base_main.py:52][0m [avg_reward]: -335.65875878134494
[32m[0511 22:04:44 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:44 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:44 @base_trainer.py:216][0m Mean reward: -296.17880444249033
[32m[0511 22:04:45 @base_main.py:38][0m --------------- Iteration 138 ---------------
[32m[0511 22:04:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9829 mins
[32m[0511 22:04:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0037 mins
[32m[0511 22:04:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 22:04:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:45 @base_main.py:47][0m 138276 total steps have happened
[32m[0511 22:04:45 @base_main.py:52][0m [avg_reward]: -296.17880444249033
[32m[0511 22:04:45 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:45 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:45 @base_trainer.py:216][0m Mean reward: -320.6244909333219
[32m[0511 22:04:46 @base_main.py:38][0m --------------- Iteration 139 ---------------
[32m[0511 22:04:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9974 mins
[32m[0511 22:04:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 22:04:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 22:04:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:46 @base_main.py:47][0m 139278 total steps have happened
[32m[0511 22:04:46 @base_main.py:52][0m [avg_reward]: -320.6244909333219
[32m[0511 22:04:46 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:46 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:46 @base_trainer.py:216][0m Mean reward: -295.5555393239597
[32m[0511 22:04:47 @base_main.py:38][0m --------------- Iteration 140 ---------------
[32m[0511 22:04:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0111 mins
[32m[0511 22:04:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0045 mins
[32m[0511 22:04:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 22:04:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:47 @base_main.py:47][0m 140280 total steps have happened
[32m[0511 22:04:47 @base_main.py:52][0m [avg_reward]: -295.5555393239597
[32m[0511 22:04:47 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:47 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:47 @base_trainer.py:216][0m Mean reward: -319.3466080777313
[32m[0511 22:04:48 @base_main.py:38][0m --------------- Iteration 141 ---------------
[32m[0511 22:04:48 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0260 mins
[32m[0511 22:04:48 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0046 mins
[32m[0511 22:04:48 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 22:04:48 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0511 22:04:48 @base_main.py:47][0m 141282 total steps have happened
[32m[0511 22:04:48 @base_main.py:52][0m [avg_reward]: -319.3466080777313
[32m[0511 22:04:48 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:48 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:48 @base_trainer.py:216][0m Mean reward: -288.72770396661144
[32m[0511 22:04:49 @base_main.py:38][0m --------------- Iteration 142 ---------------
[32m[0511 22:04:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0409 mins
[32m[0511 22:04:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0511 22:04:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 22:04:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:49 @base_main.py:47][0m 142284 total steps have happened
[32m[0511 22:04:49 @base_main.py:52][0m [avg_reward]: -288.72770396661144
[32m[0511 22:04:49 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:49 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:49 @base_trainer.py:216][0m Mean reward: -284.0720896786597
[32m[0511 22:04:49 @base_main.py:38][0m --------------- Iteration 143 ---------------
[32m[0511 22:04:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0547 mins
[32m[0511 22:04:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0036 mins
[32m[0511 22:04:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 22:04:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:49 @base_main.py:47][0m 143286 total steps have happened
[32m[0511 22:04:49 @base_main.py:52][0m [avg_reward]: -284.0720896786597
[32m[0511 22:04:50 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:50 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:50 @base_trainer.py:216][0m Mean reward: -261.81983349450604
[32m[0511 22:04:50 @base_main.py:38][0m --------------- Iteration 144 ---------------
[32m[0511 22:04:50 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0689 mins
[32m[0511 22:04:50 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0036 mins
[32m[0511 22:04:50 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 22:04:50 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0511 22:04:50 @base_main.py:47][0m 144288 total steps have happened
[32m[0511 22:04:50 @base_main.py:52][0m [avg_reward]: -261.81983349450604
[32m[0511 22:04:51 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:51 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:51 @base_trainer.py:216][0m Mean reward: -272.6297424199654
[32m[0511 22:04:51 @base_main.py:38][0m --------------- Iteration 145 ---------------
[32m[0511 22:04:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0825 mins
[32m[0511 22:04:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0052 mins
[32m[0511 22:04:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 22:04:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:51 @base_main.py:47][0m 145290 total steps have happened
[32m[0511 22:04:51 @base_main.py:52][0m [avg_reward]: -272.6297424199654
[32m[0511 22:04:51 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:51 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:51 @base_trainer.py:216][0m Mean reward: -271.0790575686375
[32m[0511 22:04:52 @base_main.py:38][0m --------------- Iteration 146 ---------------
[32m[0511 22:04:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0977 mins
[32m[0511 22:04:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0045 mins
[32m[0511 22:04:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 22:04:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:52 @base_main.py:47][0m 146292 total steps have happened
[32m[0511 22:04:52 @base_main.py:52][0m [avg_reward]: -271.0790575686375
[32m[0511 22:04:52 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:52 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:52 @base_trainer.py:216][0m Mean reward: -274.5944252136689
[32m[0511 22:04:53 @base_main.py:38][0m --------------- Iteration 147 ---------------
[32m[0511 22:04:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1126 mins
[32m[0511 22:04:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 22:04:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 22:04:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0511 22:04:53 @base_main.py:47][0m 147294 total steps have happened
[32m[0511 22:04:53 @base_main.py:52][0m [avg_reward]: -274.5944252136689
[32m[0511 22:04:53 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:53 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:53 @base_trainer.py:216][0m Mean reward: -329.36113277994394
[32m[0511 22:04:54 @base_main.py:38][0m --------------- Iteration 148 ---------------
[32m[0511 22:04:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1271 mins
[32m[0511 22:04:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0038 mins
[32m[0511 22:04:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 22:04:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:54 @base_main.py:47][0m 148296 total steps have happened
[32m[0511 22:04:54 @base_main.py:52][0m [avg_reward]: -329.36113277994394
[32m[0511 22:04:54 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:54 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:54 @base_trainer.py:216][0m Mean reward: -277.69582617838137
[32m[0511 22:04:55 @base_main.py:38][0m --------------- Iteration 149 ---------------
[32m[0511 22:04:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1409 mins
[32m[0511 22:04:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0511 22:04:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 22:04:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:55 @base_main.py:47][0m 149298 total steps have happened
[32m[0511 22:04:55 @base_main.py:52][0m [avg_reward]: -277.69582617838137
[32m[0511 22:04:55 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:55 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:55 @base_trainer.py:216][0m Mean reward: -334.83286574659917
[32m[0511 22:04:56 @base_main.py:38][0m --------------- Iteration 150 ---------------
[32m[0511 22:04:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1558 mins
[32m[0511 22:04:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0046 mins
[32m[0511 22:04:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 22:04:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:56 @base_main.py:47][0m 150300 total steps have happened
[32m[0511 22:04:56 @base_main.py:52][0m [avg_reward]: -334.83286574659917
[32m[0511 22:04:56 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:56 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:56 @base_trainer.py:216][0m Mean reward: -232.99664446811443
[32m[0511 22:04:56 @base_main.py:38][0m --------------- Iteration 151 ---------------
[32m[0511 22:04:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1708 mins
[32m[0511 22:04:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0035 mins
[32m[0511 22:04:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 22:04:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:56 @base_main.py:47][0m 151302 total steps have happened
[32m[0511 22:04:56 @base_main.py:52][0m [avg_reward]: -232.99664446811443
[32m[0511 22:04:57 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:57 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:57 @base_trainer.py:216][0m Mean reward: -301.35846534632526
[32m[0511 22:04:57 @base_main.py:38][0m --------------- Iteration 152 ---------------
[32m[0511 22:04:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1851 mins
[32m[0511 22:04:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0038 mins
[32m[0511 22:04:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 22:04:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:57 @base_main.py:47][0m 152304 total steps have happened
[32m[0511 22:04:57 @base_main.py:52][0m [avg_reward]: -301.35846534632526
[32m[0511 22:04:58 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:58 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:58 @base_trainer.py:216][0m Mean reward: -317.77365688419627
[32m[0511 22:04:58 @base_main.py:38][0m --------------- Iteration 153 ---------------
[32m[0511 22:04:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1992 mins
[32m[0511 22:04:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0045 mins
[32m[0511 22:04:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0511 22:04:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:58 @base_main.py:47][0m 153306 total steps have happened
[32m[0511 22:04:58 @base_main.py:52][0m [avg_reward]: -317.77365688419627
[32m[0511 22:04:58 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:58 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:58 @base_trainer.py:216][0m Mean reward: -331.4442287970779
[32m[0511 22:04:59 @base_main.py:38][0m --------------- Iteration 154 ---------------
[32m[0511 22:04:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2133 mins
[32m[0511 22:04:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0511 22:04:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 22:04:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:04:59 @base_main.py:47][0m 154308 total steps have happened
[32m[0511 22:04:59 @base_main.py:52][0m [avg_reward]: -331.4442287970779
[32m[0511 22:04:59 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:04:59 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:04:59 @base_trainer.py:216][0m Mean reward: -334.15765499117754
[32m[0511 22:05:00 @base_main.py:38][0m --------------- Iteration 155 ---------------
[32m[0511 22:05:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2272 mins
[32m[0511 22:05:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0043 mins
[32m[0511 22:05:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 22:05:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:05:00 @base_main.py:47][0m 155310 total steps have happened
[32m[0511 22:05:00 @base_main.py:52][0m [avg_reward]: -334.15765499117754
[32m[0511 22:05:00 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:00 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:00 @base_trainer.py:216][0m Mean reward: -282.0507384324514
[32m[0511 22:05:01 @base_main.py:38][0m --------------- Iteration 156 ---------------
[32m[0511 22:05:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2416 mins
[32m[0511 22:05:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0511 22:05:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0107 mins
[32m[0511 22:05:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0511 22:05:01 @base_main.py:47][0m 156312 total steps have happened
[32m[0511 22:05:01 @base_main.py:52][0m [avg_reward]: -282.0507384324514
[32m[0511 22:05:01 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:01 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:01 @base_trainer.py:216][0m Mean reward: -300.80019301734933
[32m[0511 22:05:01 @base_main.py:38][0m --------------- Iteration 157 ---------------
[32m[0511 22:05:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2564 mins
[32m[0511 22:05:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0511 22:05:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 22:05:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:05:01 @base_main.py:47][0m 157314 total steps have happened
[32m[0511 22:05:01 @base_main.py:52][0m [avg_reward]: -300.80019301734933
[32m[0511 22:05:02 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:02 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:02 @base_trainer.py:216][0m Mean reward: -287.20538772178037
[32m[0511 22:05:02 @base_main.py:38][0m --------------- Iteration 158 ---------------
[32m[0511 22:05:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2701 mins
[32m[0511 22:05:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0036 mins
[32m[0511 22:05:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 22:05:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:05:02 @base_main.py:47][0m 158316 total steps have happened
[32m[0511 22:05:02 @base_main.py:52][0m [avg_reward]: -287.20538772178037
[32m[0511 22:05:03 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:03 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:03 @base_trainer.py:216][0m Mean reward: -337.548312006957
[32m[0511 22:05:03 @base_main.py:38][0m --------------- Iteration 159 ---------------
[32m[0511 22:05:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2840 mins
[32m[0511 22:05:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0036 mins
[32m[0511 22:05:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 22:05:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:05:03 @base_main.py:47][0m 159318 total steps have happened
[32m[0511 22:05:03 @base_main.py:52][0m [avg_reward]: -337.548312006957
[32m[0511 22:05:03 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:03 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:03 @base_trainer.py:216][0m Mean reward: -310.9332186260272
[32m[0511 22:05:04 @base_main.py:38][0m --------------- Iteration 160 ---------------
[32m[0511 22:05:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2981 mins
[32m[0511 22:05:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0036 mins
[32m[0511 22:05:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0511 22:05:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:05:04 @base_main.py:47][0m 160320 total steps have happened
[32m[0511 22:05:04 @base_main.py:52][0m [avg_reward]: -310.9332186260272
[32m[0511 22:05:04 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:04 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:04 @base_trainer.py:216][0m Mean reward: -335.1540066936964
[32m[0511 22:05:05 @base_main.py:38][0m --------------- Iteration 161 ---------------
[32m[0511 22:05:05 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3113 mins
[32m[0511 22:05:05 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0043 mins
[32m[0511 22:05:05 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 22:05:05 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:05:05 @base_main.py:47][0m 161322 total steps have happened
[32m[0511 22:05:05 @base_main.py:52][0m [avg_reward]: -335.1540066936964
[32m[0511 22:05:05 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:05 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:05 @base_trainer.py:216][0m Mean reward: -284.4809082697543
[32m[0511 22:05:06 @base_main.py:38][0m --------------- Iteration 162 ---------------
[32m[0511 22:05:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3258 mins
[32m[0511 22:05:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0046 mins
[32m[0511 22:05:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 22:05:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0511 22:05:06 @base_main.py:47][0m 162324 total steps have happened
[32m[0511 22:05:06 @base_main.py:52][0m [avg_reward]: -284.4809082697543
[32m[0511 22:05:06 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:06 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:06 @base_trainer.py:216][0m Mean reward: -327.25486815809643
[32m[0511 22:05:07 @base_main.py:38][0m --------------- Iteration 163 ---------------
[32m[0511 22:05:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3409 mins
[32m[0511 22:05:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0511 22:05:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 22:05:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0511 22:05:07 @base_main.py:47][0m 163326 total steps have happened
[32m[0511 22:05:07 @base_main.py:52][0m [avg_reward]: -327.25486815809643
[32m[0511 22:05:07 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:07 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:07 @base_trainer.py:216][0m Mean reward: -317.25333373792085
[32m[0511 22:05:07 @base_main.py:38][0m --------------- Iteration 164 ---------------
[32m[0511 22:05:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3557 mins
[32m[0511 22:05:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0038 mins
[32m[0511 22:05:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 22:05:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:05:07 @base_main.py:47][0m 164328 total steps have happened
[32m[0511 22:05:07 @base_main.py:52][0m [avg_reward]: -317.25333373792085
[32m[0511 22:05:08 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:08 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:08 @base_trainer.py:216][0m Mean reward: -315.9507111454202
[32m[0511 22:05:08 @base_main.py:38][0m --------------- Iteration 165 ---------------
[32m[0511 22:05:08 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3698 mins
[32m[0511 22:05:08 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 22:05:08 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 22:05:08 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:05:08 @base_main.py:47][0m 165330 total steps have happened
[32m[0511 22:05:08 @base_main.py:52][0m [avg_reward]: -315.9507111454202
[32m[0511 22:05:09 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:09 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:09 @base_trainer.py:216][0m Mean reward: -323.9779833387478
[32m[0511 22:05:09 @base_main.py:38][0m --------------- Iteration 166 ---------------
[32m[0511 22:05:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3843 mins
[32m[0511 22:05:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0048 mins
[32m[0511 22:05:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 22:05:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:05:09 @base_main.py:47][0m 166332 total steps have happened
[32m[0511 22:05:09 @base_main.py:52][0m [avg_reward]: -323.9779833387478
[32m[0511 22:05:10 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:10 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:10 @base_trainer.py:216][0m Mean reward: -322.44368166852
[32m[0511 22:05:10 @base_main.py:38][0m --------------- Iteration 167 ---------------
[32m[0511 22:05:10 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3999 mins
[32m[0511 22:05:10 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0511 22:05:10 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 22:05:10 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:05:10 @base_main.py:47][0m 167334 total steps have happened
[32m[0511 22:05:10 @base_main.py:52][0m [avg_reward]: -322.44368166852
[32m[0511 22:05:10 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:10 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:10 @base_trainer.py:216][0m Mean reward: -341.47773830488035
[32m[0511 22:05:11 @base_main.py:38][0m --------------- Iteration 168 ---------------
[32m[0511 22:05:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4145 mins
[32m[0511 22:05:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0043 mins
[32m[0511 22:05:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 22:05:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:05:11 @base_main.py:47][0m 168336 total steps have happened
[32m[0511 22:05:11 @base_main.py:52][0m [avg_reward]: -341.47773830488035
[32m[0511 22:05:11 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:11 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:11 @base_trainer.py:216][0m Mean reward: -334.469875727016
[32m[0511 22:05:12 @base_main.py:38][0m --------------- Iteration 169 ---------------
[32m[0511 22:05:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4293 mins
[32m[0511 22:05:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0043 mins
[32m[0511 22:05:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 22:05:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:05:12 @base_main.py:47][0m 169338 total steps have happened
[32m[0511 22:05:12 @base_main.py:52][0m [avg_reward]: -334.469875727016
[32m[0511 22:05:12 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:12 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:12 @base_trainer.py:216][0m Mean reward: -338.93530666763894
[32m[0511 22:05:13 @base_main.py:38][0m --------------- Iteration 170 ---------------
[32m[0511 22:05:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4435 mins
[32m[0511 22:05:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0038 mins
[32m[0511 22:05:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0511 22:05:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:05:13 @base_main.py:47][0m 170340 total steps have happened
[32m[0511 22:05:13 @base_main.py:52][0m [avg_reward]: -338.93530666763894
[32m[0511 22:05:13 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:13 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:13 @base_trainer.py:216][0m Mean reward: -334.3666760430913
[32m[0511 22:05:14 @base_main.py:38][0m --------------- Iteration 171 ---------------
[32m[0511 22:05:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4570 mins
[32m[0511 22:05:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0511 22:05:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 22:05:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:05:14 @base_main.py:47][0m 171342 total steps have happened
[32m[0511 22:05:14 @base_main.py:52][0m [avg_reward]: -334.3666760430913
[32m[0511 22:05:14 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:14 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:14 @base_trainer.py:216][0m Mean reward: -371.22241775492535
[32m[0511 22:05:14 @base_main.py:38][0m --------------- Iteration 172 ---------------
[32m[0511 22:05:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4714 mins
[32m[0511 22:05:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0037 mins
[32m[0511 22:05:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0511 22:05:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:05:14 @base_main.py:47][0m 172344 total steps have happened
[32m[0511 22:05:14 @base_main.py:52][0m [avg_reward]: -371.22241775492535
[32m[0511 22:05:15 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:15 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:15 @base_trainer.py:216][0m Mean reward: -328.07777973509945
[32m[0511 22:05:15 @base_main.py:38][0m --------------- Iteration 173 ---------------
[32m[0511 22:05:15 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4848 mins
[32m[0511 22:05:15 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0038 mins
[32m[0511 22:05:15 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 22:05:15 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:05:15 @base_main.py:47][0m 173346 total steps have happened
[32m[0511 22:05:15 @base_main.py:52][0m [avg_reward]: -328.07777973509945
[32m[0511 22:05:15 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:15 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:15 @base_trainer.py:216][0m Mean reward: -344.90381156660055
[32m[0511 22:05:16 @base_main.py:38][0m --------------- Iteration 174 ---------------
[32m[0511 22:05:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4988 mins
[32m[0511 22:05:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 22:05:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 22:05:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:05:16 @base_main.py:47][0m 174348 total steps have happened
[32m[0511 22:05:16 @base_main.py:52][0m [avg_reward]: -344.90381156660055
[32m[0511 22:05:16 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:16 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:16 @base_trainer.py:216][0m Mean reward: -333.16949092403775
[32m[0511 22:05:17 @base_main.py:38][0m --------------- Iteration 175 ---------------
[32m[0511 22:05:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.5130 mins
[32m[0511 22:05:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0511 22:05:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 22:05:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:05:17 @base_main.py:47][0m 175350 total steps have happened
[32m[0511 22:05:17 @base_main.py:52][0m [avg_reward]: -333.16949092403775
[32m[0511 22:05:17 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:17 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:17 @base_trainer.py:216][0m Mean reward: -353.5354141219592
[32m[0511 22:05:18 @base_main.py:38][0m --------------- Iteration 176 ---------------
[32m[0511 22:05:18 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.5273 mins
[32m[0511 22:05:18 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0511 22:05:18 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 22:05:18 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:05:18 @base_main.py:47][0m 176352 total steps have happened
[32m[0511 22:05:18 @base_main.py:52][0m [avg_reward]: -353.5354141219592
[32m[0511 22:05:18 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:18 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:18 @base_trainer.py:216][0m Mean reward: -340.43338450118154
[32m[0511 22:05:19 @base_main.py:38][0m --------------- Iteration 177 ---------------
[32m[0511 22:05:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.5413 mins
[32m[0511 22:05:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0511 22:05:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 22:05:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:05:19 @base_main.py:47][0m 177354 total steps have happened
[32m[0511 22:05:19 @base_main.py:52][0m [avg_reward]: -340.43338450118154
[32m[0511 22:05:19 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:19 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:19 @base_trainer.py:216][0m Mean reward: -322.3869489871681
[32m[0511 22:05:19 @base_main.py:38][0m --------------- Iteration 178 ---------------
[32m[0511 22:05:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.5562 mins
[32m[0511 22:05:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0035 mins
[32m[0511 22:05:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 22:05:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:05:19 @base_main.py:47][0m 178356 total steps have happened
[32m[0511 22:05:19 @base_main.py:52][0m [avg_reward]: -322.3869489871681
[32m[0511 22:05:20 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:20 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:20 @base_trainer.py:216][0m Mean reward: -367.24737838798916
[32m[0511 22:05:20 @base_main.py:38][0m --------------- Iteration 179 ---------------
[32m[0511 22:05:20 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.5701 mins
[32m[0511 22:05:20 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0038 mins
[32m[0511 22:05:20 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 22:05:20 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:05:20 @base_main.py:47][0m 179358 total steps have happened
[32m[0511 22:05:20 @base_main.py:52][0m [avg_reward]: -367.24737838798916
[32m[0511 22:05:21 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:21 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:21 @base_trainer.py:216][0m Mean reward: -362.80017668101004
[32m[0511 22:05:21 @base_main.py:38][0m --------------- Iteration 180 ---------------
[32m[0511 22:05:21 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.5842 mins
[32m[0511 22:05:21 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0036 mins
[32m[0511 22:05:21 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0511 22:05:21 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:05:21 @base_main.py:47][0m 180360 total steps have happened
[32m[0511 22:05:21 @base_main.py:52][0m [avg_reward]: -362.80017668101004
[32m[0511 22:05:21 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:21 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:21 @base_trainer.py:216][0m Mean reward: -344.52592310430737
[32m[0511 22:05:22 @base_main.py:38][0m --------------- Iteration 181 ---------------
[32m[0511 22:05:22 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.5968 mins
[32m[0511 22:05:22 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 22:05:22 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 22:05:22 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:05:22 @base_main.py:47][0m 181362 total steps have happened
[32m[0511 22:05:22 @base_main.py:52][0m [avg_reward]: -344.52592310430737
[32m[0511 22:05:22 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:22 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:22 @base_trainer.py:216][0m Mean reward: -351.08870441093904
[32m[0511 22:05:23 @base_main.py:38][0m --------------- Iteration 182 ---------------
[32m[0511 22:05:23 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.6113 mins
[32m[0511 22:05:23 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0511 22:05:23 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 22:05:23 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:05:23 @base_main.py:47][0m 182364 total steps have happened
[32m[0511 22:05:23 @base_main.py:52][0m [avg_reward]: -351.08870441093904
[32m[0511 22:05:23 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:23 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:23 @base_trainer.py:216][0m Mean reward: -345.53631362593546
[32m[0511 22:05:24 @base_main.py:38][0m --------------- Iteration 183 ---------------
[32m[0511 22:05:24 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.6259 mins
[32m[0511 22:05:24 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0045 mins
[32m[0511 22:05:24 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 22:05:24 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0511 22:05:24 @base_main.py:47][0m 183366 total steps have happened
[32m[0511 22:05:24 @base_main.py:52][0m [avg_reward]: -345.53631362593546
[32m[0511 22:05:24 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:24 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:24 @base_trainer.py:216][0m Mean reward: -344.7342062567901
[32m[0511 22:05:25 @base_main.py:38][0m --------------- Iteration 184 ---------------
[32m[0511 22:05:25 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.6411 mins
[32m[0511 22:05:25 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0511 22:05:25 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0108 mins
[32m[0511 22:05:25 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:05:25 @base_main.py:47][0m 184368 total steps have happened
[32m[0511 22:05:25 @base_main.py:52][0m [avg_reward]: -344.7342062567901
[32m[0511 22:05:25 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:25 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:25 @base_trainer.py:216][0m Mean reward: -288.1785752118768
[32m[0511 22:05:26 @base_main.py:38][0m --------------- Iteration 185 ---------------
[32m[0511 22:05:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.6562 mins
[32m[0511 22:05:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0511 22:05:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 22:05:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:05:26 @base_main.py:47][0m 185370 total steps have happened
[32m[0511 22:05:26 @base_main.py:52][0m [avg_reward]: -288.1785752118768
[32m[0511 22:05:26 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:26 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:26 @base_trainer.py:216][0m Mean reward: -342.3248609982656
[32m[0511 22:05:26 @base_main.py:38][0m --------------- Iteration 186 ---------------
[32m[0511 22:05:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.6707 mins
[32m[0511 22:05:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0511 22:05:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 22:05:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:05:26 @base_main.py:47][0m 186372 total steps have happened
[32m[0511 22:05:26 @base_main.py:52][0m [avg_reward]: -342.3248609982656
[32m[0511 22:05:27 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:27 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:27 @base_trainer.py:216][0m Mean reward: -335.47624579829767
[32m[0511 22:05:27 @base_main.py:38][0m --------------- Iteration 187 ---------------
[32m[0511 22:05:27 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.6850 mins
[32m[0511 22:05:27 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0046 mins
[32m[0511 22:05:27 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 22:05:27 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:05:27 @base_main.py:47][0m 187374 total steps have happened
[32m[0511 22:05:27 @base_main.py:52][0m [avg_reward]: -335.47624579829767
[32m[0511 22:05:28 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:28 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:28 @base_trainer.py:216][0m Mean reward: -323.5060247186416
[32m[0511 22:05:28 @base_main.py:38][0m --------------- Iteration 188 ---------------
[32m[0511 22:05:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.6999 mins
[32m[0511 22:05:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0511 22:05:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 22:05:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:05:28 @base_main.py:47][0m 188376 total steps have happened
[32m[0511 22:05:28 @base_main.py:52][0m [avg_reward]: -323.5060247186416
[32m[0511 22:05:28 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:28 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:28 @base_trainer.py:216][0m Mean reward: -324.5701975108674
[32m[0511 22:05:29 @base_main.py:38][0m --------------- Iteration 189 ---------------
[32m[0511 22:05:29 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.7142 mins
[32m[0511 22:05:29 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0046 mins
[32m[0511 22:05:29 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 22:05:29 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:05:29 @base_main.py:47][0m 189378 total steps have happened
[32m[0511 22:05:29 @base_main.py:52][0m [avg_reward]: -324.5701975108674
[32m[0511 22:05:29 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:29 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:29 @base_trainer.py:216][0m Mean reward: -314.7804735671742
[32m[0511 22:05:30 @base_main.py:38][0m --------------- Iteration 190 ---------------
[32m[0511 22:05:30 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.7291 mins
[32m[0511 22:05:30 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0038 mins
[32m[0511 22:05:30 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 22:05:30 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:05:30 @base_main.py:47][0m 190380 total steps have happened
[32m[0511 22:05:30 @base_main.py:52][0m [avg_reward]: -314.7804735671742
[32m[0511 22:05:30 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:30 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:30 @base_trainer.py:216][0m Mean reward: -303.1793246682623
[32m[0511 22:05:31 @base_main.py:38][0m --------------- Iteration 191 ---------------
[32m[0511 22:05:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.7435 mins
[32m[0511 22:05:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0036 mins
[32m[0511 22:05:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 22:05:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:05:31 @base_main.py:47][0m 191382 total steps have happened
[32m[0511 22:05:31 @base_main.py:52][0m [avg_reward]: -303.1793246682623
[32m[0511 22:05:31 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:31 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:31 @base_trainer.py:216][0m Mean reward: -294.74279738650307
[32m[0511 22:05:32 @base_main.py:38][0m --------------- Iteration 192 ---------------
[32m[0511 22:05:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.7578 mins
[32m[0511 22:05:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0511 22:05:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 22:05:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:05:32 @base_main.py:47][0m 192384 total steps have happened
[32m[0511 22:05:32 @base_main.py:52][0m [avg_reward]: -294.74279738650307
[32m[0511 22:05:32 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:32 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:32 @base_trainer.py:216][0m Mean reward: -288.5041143926375
[32m[0511 22:05:32 @base_main.py:38][0m --------------- Iteration 193 ---------------
[32m[0511 22:05:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.7717 mins
[32m[0511 22:05:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 22:05:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 22:05:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:05:32 @base_main.py:47][0m 193386 total steps have happened
[32m[0511 22:05:32 @base_main.py:52][0m [avg_reward]: -288.5041143926375
[32m[0511 22:05:33 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:33 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:33 @base_trainer.py:216][0m Mean reward: -302.64835704110044
[32m[0511 22:05:33 @base_main.py:38][0m --------------- Iteration 194 ---------------
[32m[0511 22:05:33 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.7860 mins
[32m[0511 22:05:33 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0511 22:05:33 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 22:05:33 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:05:33 @base_main.py:47][0m 194388 total steps have happened
[32m[0511 22:05:33 @base_main.py:52][0m [avg_reward]: -302.64835704110044
[32m[0511 22:05:34 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:34 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:34 @base_trainer.py:216][0m Mean reward: -317.4886334141496
[32m[0511 22:05:34 @base_main.py:38][0m --------------- Iteration 195 ---------------
[32m[0511 22:05:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.8003 mins
[32m[0511 22:05:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 22:05:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 22:05:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:05:34 @base_main.py:47][0m 195390 total steps have happened
[32m[0511 22:05:34 @base_main.py:52][0m [avg_reward]: -317.4886334141496
[32m[0511 22:05:34 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:34 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:34 @base_trainer.py:216][0m Mean reward: -308.6535912462109
[32m[0511 22:05:35 @base_main.py:38][0m --------------- Iteration 196 ---------------
[32m[0511 22:05:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.8144 mins
[32m[0511 22:05:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0511 22:05:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 22:05:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:05:35 @base_main.py:47][0m 196392 total steps have happened
[32m[0511 22:05:35 @base_main.py:52][0m [avg_reward]: -308.6535912462109
[32m[0511 22:05:35 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:35 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:35 @base_trainer.py:216][0m Mean reward: -322.6377227848697
[32m[0511 22:05:36 @base_main.py:38][0m --------------- Iteration 197 ---------------
[32m[0511 22:05:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.8286 mins
[32m[0511 22:05:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 22:05:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 22:05:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:05:36 @base_main.py:47][0m 197394 total steps have happened
[32m[0511 22:05:36 @base_main.py:52][0m [avg_reward]: -322.6377227848697
[32m[0511 22:05:36 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:36 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:36 @base_trainer.py:216][0m Mean reward: -332.07327323332913
[32m[0511 22:05:37 @base_main.py:38][0m --------------- Iteration 198 ---------------
[32m[0511 22:05:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.8432 mins
[32m[0511 22:05:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0511 22:05:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 22:05:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:05:37 @base_main.py:47][0m 198396 total steps have happened
[32m[0511 22:05:37 @base_main.py:52][0m [avg_reward]: -332.07327323332913
[32m[0511 22:05:37 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:37 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:37 @base_trainer.py:216][0m Mean reward: -312.99644867017673
[32m[0511 22:05:38 @base_main.py:38][0m --------------- Iteration 199 ---------------
[32m[0511 22:05:38 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.8578 mins
[32m[0511 22:05:38 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0511 22:05:38 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0107 mins
[32m[0511 22:05:38 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:05:38 @base_main.py:47][0m 199398 total steps have happened
[32m[0511 22:05:38 @base_main.py:52][0m [avg_reward]: -312.99644867017673
[32m[0511 22:05:38 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 22:05:38 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 22:05:38 @base_trainer.py:216][0m Mean reward: -321.9302533501929
[32m[0511 22:05:39 @base_main.py:38][0m --------------- Iteration 200 ---------------
[32m[0511 22:05:39 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.8728 mins
[32m[0511 22:05:39 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0048 mins
[32m[0511 22:05:39 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0511 22:05:39 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 22:05:39 @base_main.py:47][0m 200400 total steps have happened
[32m[0511 22:05:39 @base_main.py:52][0m [avg_reward]: -321.9302533501929
[32m[0511 22:05:39 @base_worker.py:111][0m kill message for worker 2
[32m[0511 22:05:39 @base_worker.py:111][0m kill message for worker 9
[32m[0511 22:05:39 @base_worker.py:111][0m kill message for worker 3
[32m[0511 22:05:39 @base_worker.py:111][0m kill message for worker 12
[32m[0511 22:05:39 @base_worker.py:111][0m kill message for worker 1
[32m[0511 22:05:39 @base_worker.py:111][0m kill message for worker 10
[32m[0511 22:05:39 @base_worker.py:111][0m kill message for worker 6
[32m[0511 22:05:39 @base_worker.py:111][0m kill message for worker 11
[32m[0511 22:05:39 @base_worker.py:111][0m kill message for worker 5
[32m[0511 22:05:39 @base_worker.py:111][0m kill message for worker 14
[32m[0511 22:05:39 @base_worker.py:111][0m kill message for worker 7
[32m[0511 22:05:39 @base_worker.py:111][0m kill message for worker 4
[32m[0511 22:05:39 @base_worker.py:111][0m kill message for worker 18
[32m[0511 22:05:39 @base_worker.py:111][0m kill message for worker 17
[32m[0511 22:05:39 @base_worker.py:111][0m kill message for worker 0
[32m[0511 22:05:39 @base_worker.py:111][0m kill message for worker 8
[32m[0511 22:05:39 @base_worker.py:111][0m kill message for worker 19
[32m[0511 22:05:39 @base_worker.py:111][0m kill message for worker 13
[32m[0511 22:05:39 @base_worker.py:111][0m kill message for worker 16
[32m[0511 22:05:39 @base_worker.py:111][0m kill message for worker 15
