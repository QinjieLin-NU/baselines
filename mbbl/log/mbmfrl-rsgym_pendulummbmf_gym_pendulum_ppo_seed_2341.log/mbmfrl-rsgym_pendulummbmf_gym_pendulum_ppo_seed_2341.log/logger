[32m[0511 05:33:28 @logger.py:103][0m Log file set to /root/mbbl/log/mbmfrl-rsgym_pendulummbmf_gym_pendulum_ppo_seed_2341.log/mbmfrl-rsgym_pendulummbmf_gym_pendulum_ppo_seed_2341.log
[32m[0511 05:33:28 @mbmf_main.py:23][0m Training starts at /root/mbbl
[32m[0511 05:33:28 @base_worker.py:45][0m Worker 0 online
[32m[0511 05:33:28 @base_worker.py:45][0m Worker 1 online
[32m[0511 05:33:28 @base_worker.py:45][0m Worker 2 online
[32m[0511 05:33:28 @base_worker.py:45][0m Worker 3 online
[32m[0511 05:33:28 @base_worker.py:45][0m Worker 4 online
[32m[0511 05:33:28 @base_worker.py:45][0m Worker 5 online
[32m[0511 05:33:28 @base_worker.py:45][0m Worker 6 online
[32m[0511 05:33:28 @base_worker.py:45][0m Worker 7 online
[32m[0511 05:33:28 @base_worker.py:45][0m Worker 8 online
[32m[0511 05:33:28 @base_worker.py:45][0m Worker 9 online
[32m[0511 05:33:28 @base_worker.py:45][0m Worker 10 online
[32m[0511 05:33:28 @base_worker.py:45][0m Worker 11 online
[32m[0511 05:33:28 @base_worker.py:45][0m Worker 12 online
[32m[0511 05:33:28 @base_worker.py:45][0m Worker 13 online
[32m[0511 05:33:28 @base_worker.py:45][0m Worker 14 online
[32m[0511 05:33:28 @base_worker.py:45][0m Worker 15 online
[32m[0511 05:33:28 @base_worker.py:45][0m Worker 16 online
[32m[0511 05:33:28 @base_worker.py:45][0m Worker 17 online
[32m[0511 05:33:28 @base_worker.py:45][0m Worker 18 online
[32m[0511 05:33:28 @base_worker.py:45][0m Worker 19 online
[32m[0511 05:33:29 @base_trainer.py:152][0m Trainer maintains [1] policy network
[32m[0511 05:33:29 @base_trainer.py:152][0m Trainer maintains [1] dynamics network
[32m[0511 05:33:29 @base_trainer.py:152][0m Trainer maintains [1] reward network
[32m[0511 05:33:30 @mbmf_main.py:46][0m Generating 1000 random timesteps
[32m[0511 05:33:30 @mbmf_sampler.py:39][0m done with episode
[32m[0511 05:33:30 @mbmf_sampler.py:39][0m done with episode
[32m[0511 05:33:30 @mbmf_sampler.py:39][0m done with episode
[32m[0511 05:33:30 @mbmf_sampler.py:39][0m done with episode
[32m[0511 05:33:30 @mbmf_sampler.py:39][0m done with episode
[32m[0511 05:33:30 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:33:30 @base_trainer.py:216][0m Mean reward: -1512.2872221410616
[32m[0511 05:33:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8139510750770569, Train Loss: 0.8316690325737
[32m[0511 05:33:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8139612674713135, Train Loss: 0.831659197807312
[32m[0511 05:33:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8139719367027283, Train Loss: 0.8316494822502136
[32m[0511 05:33:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8139824867248535, Train Loss: 0.8316399455070496
[32m[0511 05:33:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8139931559562683, Train Loss: 0.8316305875778198
[32m[0511 05:33:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8140040040016174, Train Loss: 0.8316216468811035
[32m[0511 05:33:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8140148520469666, Train Loss: 0.831612765789032
[32m[0511 05:33:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8140257000923157, Train Loss: 0.8316039443016052
[32m[0511 05:33:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8140366673469543, Train Loss: 0.8315954804420471
[32m[0511 05:33:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.814047634601593, Train Loss: 0.8315871357917786
[32m[0511 05:33:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8140583038330078, Train Loss: 0.8315790295600891
[32m[0511 05:33:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8140689730644226, Train Loss: 0.8315709829330444
[32m[0511 05:33:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8140794634819031, Train Loss: 0.8315631747245789
[32m[0511 05:33:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8140897750854492, Train Loss: 0.8315556049346924
[32m[0511 05:33:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8140998482704163, Train Loss: 0.8315480947494507
[32m[0511 05:33:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8141098022460938, Train Loss: 0.8315407037734985
[32m[0511 05:33:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8141193389892578, Train Loss: 0.8315335512161255
[32m[0511 05:33:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8141286373138428, Train Loss: 0.8315264582633972
[32m[0511 05:33:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8141376972198486, Train Loss: 0.8315195441246033
[32m[0511 05:33:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8141465783119202, Train Loss: 0.8315127491950989
[32m[0511 05:33:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8141550421714783, Train Loss: 0.8315061330795288
[32m[0511 05:33:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8141633868217468, Train Loss: 0.8314995765686035
[32m[0511 05:33:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8141714930534363, Train Loss: 0.8314931392669678
[32m[0511 05:33:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8141794800758362, Train Loss: 0.8314868211746216
[32m[0511 05:33:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8141872882843018, Train Loss: 0.8314806222915649
[32m[0511 05:33:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.814194917678833, Train Loss: 0.8314746022224426
[32m[0511 05:33:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8142024874687195, Train Loss: 0.8314685821533203
[32m[0511 05:33:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8142099380493164, Train Loss: 0.8314629793167114
[32m[0511 05:33:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8142174482345581, Train Loss: 0.8314573764801025
[32m[0511 05:33:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8142247796058655, Train Loss: 0.8314518928527832
[32m[0511 05:33:31 @base_main.py:38][0m --------------- Iteration 1 ---------------
[32m[0511 05:33:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0000 mins
[32m[0511 05:33:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 05:33:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0112 mins
[32m[0511 05:33:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0045 mins
[32m[0511 05:33:31 @base_main.py:47][0m 1005 total steps have happened
[32m[0511 05:33:31 @base_main.py:52][0m [avg_reward]: -1512.2872221410616
[32m[0511 05:33:31 @base_main.py:52][0m [update_op]: None
[32m[0511 05:33:31 @base_main.py:52][0m [train_loss]: 0.8314518928527832
[32m[0511 05:33:31 @base_main.py:52][0m [val_loss]: 0.8142247796058655
[32m[0511 05:33:31 @base_main.py:52][0m [avg_train_loss]: 0.8314518928527832
[32m[0511 05:35:41 @mbmf_sampler.py:39][0m done with episode
[32m[0511 05:37:48 @mbmf_sampler.py:39][0m done with episode
[32m[0511 05:39:55 @mbmf_sampler.py:39][0m done with episode
[32m[0511 05:42:01 @mbmf_sampler.py:39][0m done with episode
[32m[0511 05:44:08 @mbmf_sampler.py:39][0m done with episode
[32m[0511 05:44:08 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:44:08 @base_trainer.py:216][0m Mean reward: -1157.9818316451535
[32m[0511 05:44:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3796945810317993, Train Loss: 1.0242244005203247
[32m[0511 05:44:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3796961307525635, Train Loss: 1.0242269039154053
[32m[0511 05:44:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3796937465667725, Train Loss: 1.0242277383804321
[32m[0511 05:44:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.37968909740448, Train Loss: 1.024227261543274
[32m[0511 05:44:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3796827793121338, Train Loss: 1.0242259502410889
[32m[0511 05:44:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3796757459640503, Train Loss: 1.0242241621017456
[32m[0511 05:44:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3796684741973877, Train Loss: 1.0242218971252441
[32m[0511 05:44:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3796608448028564, Train Loss: 1.0242196321487427
[32m[0511 05:44:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3796533346176147, Train Loss: 1.0242172479629517
[32m[0511 05:44:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3796460628509521, Train Loss: 1.0242148637771606
[32m[0511 05:44:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.379638910293579, Train Loss: 1.0242128372192383
[32m[0511 05:44:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3796322345733643, Train Loss: 1.0242106914520264
[32m[0511 05:44:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.379625916481018, Train Loss: 1.024208664894104
[32m[0511 05:44:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.379619836807251, Train Loss: 1.0242067575454712
[32m[0511 05:44:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.379614233970642, Train Loss: 1.0242050886154175
[32m[0511 05:44:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3796089887619019, Train Loss: 1.0242036581039429
[32m[0511 05:44:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3796039819717407, Train Loss: 1.0242022275924683
[32m[0511 05:44:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3795994520187378, Train Loss: 1.0242007970809937
[32m[0511 05:44:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3795950412750244, Train Loss: 1.0241996049880981
[32m[0511 05:44:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3795908689498901, Train Loss: 1.024198293685913
[32m[0511 05:44:09 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.379587173461914, Train Loss: 1.0241972208023071
[32m[0511 05:44:09 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3795835971832275, Train Loss: 1.0241962671279907
[32m[0511 05:44:09 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3795802593231201, Train Loss: 1.0241954326629639
[32m[0511 05:44:09 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3795771598815918, Train Loss: 1.024194598197937
[32m[0511 05:44:09 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3795742988586426, Train Loss: 1.0241936445236206
[32m[0511 05:44:09 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3795714378356934, Train Loss: 1.0241929292678833
[32m[0511 05:44:09 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3795689344406128, Train Loss: 1.0241923332214355
[32m[0511 05:44:09 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3795665502548218, Train Loss: 1.0241916179656982
[32m[0511 05:44:09 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3795644044876099, Train Loss: 1.0241910219192505
[32m[0511 05:44:09 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3795621395111084, Train Loss: 1.0241904258728027
[32m[0511 05:44:09 @base_main.py:38][0m --------------- Iteration 2 ---------------
[32m[0511 05:44:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0179 mins
[32m[0511 05:44:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 10.6159 mins
[32m[0511 05:44:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0181 mins
[32m[0511 05:44:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0058 mins
[32m[0511 05:44:09 @base_main.py:47][0m 2010 total steps have happened
[32m[0511 05:44:09 @base_main.py:52][0m [avg_reward]: -1157.9818316451535
[32m[0511 05:44:09 @base_main.py:52][0m [update_op]: None
[32m[0511 05:44:09 @base_main.py:52][0m [train_loss]: 0.8320465683937073
[32m[0511 05:44:09 @base_main.py:52][0m [val_loss]: 1.3795621395111084
[32m[0511 05:44:09 @base_main.py:52][0m [avg_train_loss]: 1.0241904258728027
[32m[0511 05:46:16 @mbmf_sampler.py:39][0m done with episode
[32m[0511 05:48:22 @mbmf_sampler.py:39][0m done with episode
[32m[0511 05:50:28 @mbmf_sampler.py:39][0m done with episode
[32m[0511 05:52:35 @mbmf_sampler.py:39][0m done with episode
[32m[0511 05:54:40 @mbmf_sampler.py:39][0m done with episode
[32m[0511 05:54:40 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:54:40 @base_trainer.py:216][0m Mean reward: -1285.6714126123923
[32m[0511 05:54:41 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1190211772918701, Train Loss: 1.0465011596679688
[32m[0511 05:54:41 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1190807819366455, Train Loss: 1.046492576599121
[32m[0511 05:54:41 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1191476583480835, Train Loss: 1.046481966972351
[32m[0511 05:54:41 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1192163228988647, Train Loss: 1.046471118927002
[32m[0511 05:54:41 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1192837953567505, Train Loss: 1.0464608669281006
[32m[0511 05:54:41 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1193482875823975, Train Loss: 1.0464515686035156
[32m[0511 05:54:41 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1194090843200684, Train Loss: 1.046443223953247
[32m[0511 05:54:41 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1194663047790527, Train Loss: 1.046436071395874
[32m[0511 05:54:41 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1195194721221924, Train Loss: 1.0464296340942383
[32m[0511 05:54:41 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1195694208145142, Train Loss: 1.046424150466919
[32m[0511 05:54:41 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1196156740188599, Train Loss: 1.0464192628860474
[32m[0511 05:54:41 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1196588277816772, Train Loss: 1.046414852142334
[32m[0511 05:54:41 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1196991205215454, Train Loss: 1.0464110374450684
[32m[0511 05:54:41 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1197365522384644, Train Loss: 1.0464075803756714
[32m[0511 05:54:41 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1197715997695923, Train Loss: 1.0464046001434326
[32m[0511 05:54:41 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1198046207427979, Train Loss: 1.046401858329773
[32m[0511 05:54:41 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.119835376739502, Train Loss: 1.0463993549346924
[32m[0511 05:54:41 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1198643445968628, Train Loss: 1.0463972091674805
[32m[0511 05:54:42 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1198915243148804, Train Loss: 1.0463953018188477
[32m[0511 05:54:42 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1199171543121338, Train Loss: 1.0463933944702148
[32m[0511 05:54:42 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.119941234588623, Train Loss: 1.0463918447494507
[32m[0511 05:54:42 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1199638843536377, Train Loss: 1.0463902950286865
[32m[0511 05:54:42 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1199854612350464, Train Loss: 1.046389102935791
[32m[0511 05:54:42 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1200056076049805, Train Loss: 1.0463879108428955
[32m[0511 05:54:42 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1200248003005981, Train Loss: 1.0463868379592896
[32m[0511 05:54:42 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1200428009033203, Train Loss: 1.046385645866394
[32m[0511 05:54:42 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1200599670410156, Train Loss: 1.0463848114013672
[32m[0511 05:54:42 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.120076298713684, Train Loss: 1.0463840961456299
[32m[0511 05:54:42 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1200916767120361, Train Loss: 1.046383261680603
[32m[0511 05:54:42 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1201062202453613, Train Loss: 1.0463825464248657
[32m[0511 05:54:42 @base_main.py:38][0m --------------- Iteration 3 ---------------
[32m[0511 05:54:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 10.6577 mins
[32m[0511 05:54:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 10.5207 mins
[32m[0511 05:54:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0287 mins
[32m[0511 05:54:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0053 mins
[32m[0511 05:54:42 @base_main.py:47][0m 3015 total steps have happened
[32m[0511 05:54:42 @base_main.py:52][0m [avg_reward]: -1285.6714126123923
[32m[0511 05:54:42 @base_main.py:52][0m [update_op]: None
[32m[0511 05:54:42 @base_main.py:52][0m [train_loss]: 1.7045061588287354
[32m[0511 05:54:42 @base_main.py:52][0m [val_loss]: 1.1201062202453613
[32m[0511 05:54:42 @base_main.py:52][0m [avg_train_loss]: 1.0463825464248657
[32m[0511 05:56:49 @mbmf_sampler.py:39][0m done with episode
[32m[0511 05:58:55 @mbmf_sampler.py:39][0m done with episode
[32m[0511 06:01:02 @mbmf_sampler.py:39][0m done with episode
[32m[0511 06:03:08 @mbmf_sampler.py:39][0m done with episode
[32m[0511 06:05:14 @mbmf_sampler.py:39][0m done with episode
[32m[0511 06:05:14 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0511 06:05:14 @base_trainer.py:216][0m Mean reward: -1352.2412254218232
[32m[0511 06:05:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8274697065353394, Train Loss: 1.041703224182129
[32m[0511 06:05:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8274536728858948, Train Loss: 1.0417019128799438
[32m[0511 06:05:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8274340033531189, Train Loss: 1.0417002439498901
[32m[0511 06:05:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8274136781692505, Train Loss: 1.041698694229126
[32m[0511 06:05:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8273938894271851, Train Loss: 1.041697382926941
[32m[0511 06:05:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8273753523826599, Train Loss: 1.0416961908340454
[32m[0511 06:05:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8273583650588989, Train Loss: 1.04169499874115
[32m[0511 06:05:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8273427486419678, Train Loss: 1.041694164276123
[32m[0511 06:05:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.827328622341156, Train Loss: 1.0416934490203857
[32m[0511 06:05:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8273158073425293, Train Loss: 1.0416926145553589
[32m[0511 06:05:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8273041844367981, Train Loss: 1.0416920185089111
[32m[0511 06:05:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8272936940193176, Train Loss: 1.0416916608810425
[32m[0511 06:05:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8272841572761536, Train Loss: 1.0416910648345947
[32m[0511 06:05:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8272755742073059, Train Loss: 1.041690707206726
[32m[0511 06:05:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8272677063941956, Train Loss: 1.041690468788147
[32m[0511 06:05:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8272606730461121, Train Loss: 1.0416901111602783
[32m[0511 06:05:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8272542357444763, Train Loss: 1.0416898727416992
[32m[0511 06:05:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8272484540939331, Train Loss: 1.0416897535324097
[32m[0511 06:05:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8272430896759033, Train Loss: 1.0416895151138306
[32m[0511 06:05:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8272383809089661, Train Loss: 1.041689395904541
[32m[0511 06:05:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8272339105606079, Train Loss: 1.0416892766952515
[32m[0511 06:05:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8272299766540527, Train Loss: 1.041689157485962
[32m[0511 06:05:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8272264003753662, Train Loss: 1.041689157485962
[32m[0511 06:05:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8272231221199036, Train Loss: 1.0416890382766724
[32m[0511 06:05:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8272201418876648, Train Loss: 1.0416889190673828
[32m[0511 06:05:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8272173404693604, Train Loss: 1.0416887998580933
[32m[0511 06:05:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8272148370742798, Train Loss: 1.0416887998580933
[32m[0511 06:05:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8272125720977783, Train Loss: 1.0416887998580933
[32m[0511 06:05:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.827210545539856, Train Loss: 1.0416886806488037
[32m[0511 06:05:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8272085785865784, Train Loss: 1.0416886806488037
[32m[0511 06:05:17 @base_main.py:38][0m --------------- Iteration 4 ---------------
[32m[0511 06:05:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 21.2126 mins
[32m[0511 06:05:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 10.5293 mins
[32m[0511 06:05:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0377 mins
[32m[0511 06:05:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0050 mins
[32m[0511 06:05:17 @base_main.py:47][0m 4020 total steps have happened
[32m[0511 06:05:17 @base_main.py:52][0m [avg_reward]: -1352.2412254218232
[32m[0511 06:05:17 @base_main.py:52][0m [update_op]: None
[32m[0511 06:05:17 @base_main.py:52][0m [train_loss]: 1.0050462484359741
[32m[0511 06:05:17 @base_main.py:52][0m [val_loss]: 0.8272085785865784
[32m[0511 06:05:17 @base_main.py:52][0m [avg_train_loss]: 1.0416886806488037
[32m[0511 06:07:23 @mbmf_sampler.py:39][0m done with episode
[32m[0511 06:09:29 @mbmf_sampler.py:39][0m done with episode
[32m[0511 06:11:35 @mbmf_sampler.py:39][0m done with episode
[32m[0511 06:13:42 @mbmf_sampler.py:39][0m done with episode
[32m[0511 06:15:48 @mbmf_sampler.py:39][0m done with episode
[32m[0511 06:15:48 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0511 06:15:48 @base_trainer.py:216][0m Mean reward: -1104.4859465657669
[32m[0511 06:15:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3706039190292358, Train Loss: 1.0119943618774414
[32m[0511 06:15:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3706169128417969, Train Loss: 1.0119909048080444
[32m[0511 06:15:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3706308603286743, Train Loss: 1.0119869709014893
[32m[0511 06:15:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3706443309783936, Train Loss: 1.0119831562042236
[32m[0511 06:15:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.370656967163086, Train Loss: 1.0119802951812744
[32m[0511 06:15:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3706687688827515, Train Loss: 1.0119779109954834
[32m[0511 06:15:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.370679497718811, Train Loss: 1.0119761228561401
[32m[0511 06:15:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3706891536712646, Train Loss: 1.0119746923446655
[32m[0511 06:15:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3706978559494019, Train Loss: 1.0119736194610596
[32m[0511 06:15:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3707060813903809, Train Loss: 1.0119729042053223
[32m[0511 06:15:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3707131147384644, Train Loss: 1.011972188949585
[32m[0511 06:15:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3707195520401, Train Loss: 1.0119717121124268
[32m[0511 06:15:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3707250356674194, Train Loss: 1.011971354484558
[32m[0511 06:15:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3707302808761597, Train Loss: 1.0119709968566895
[32m[0511 06:15:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3707348108291626, Train Loss: 1.0119709968566895
[32m[0511 06:15:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3707389831542969, Train Loss: 1.0119707584381104
[32m[0511 06:15:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3707425594329834, Train Loss: 1.0119706392288208
[32m[0511 06:15:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3707457780838013, Train Loss: 1.0119705200195312
[32m[0511 06:15:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3707486391067505, Train Loss: 1.0119705200195312
[32m[0511 06:15:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3707510232925415, Train Loss: 1.0119702816009521
[32m[0511 06:15:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.370753526687622, Train Loss: 1.0119702816009521
[32m[0511 06:15:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3707553148269653, Train Loss: 1.0119702816009521
[32m[0511 06:15:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.370756983757019, Train Loss: 1.0119702816009521
[32m[0511 06:15:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3707586526870728, Train Loss: 1.0119702816009521
[32m[0511 06:15:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3707600831985474, Train Loss: 1.0119701623916626
[32m[0511 06:15:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3707613945007324, Train Loss: 1.0119702816009521
[32m[0511 06:15:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.370762586593628, Train Loss: 1.0119702816009521
[32m[0511 06:15:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3707634210586548, Train Loss: 1.0119702816009521
[32m[0511 06:15:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.370764136314392, Train Loss: 1.0119701623916626
[32m[0511 06:15:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3707648515701294, Train Loss: 1.0119702816009521
[32m[0511 06:15:51 @base_main.py:38][0m --------------- Iteration 5 ---------------
[32m[0511 06:15:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 31.7847 mins
[32m[0511 06:15:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 10.5120 mins
[32m[0511 06:15:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0486 mins
[32m[0511 06:15:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0052 mins
[32m[0511 06:15:51 @base_main.py:47][0m 5025 total steps have happened
[32m[0511 06:15:51 @base_main.py:52][0m [avg_reward]: -1104.4859465657669
[32m[0511 06:15:51 @base_main.py:52][0m [update_op]: None
[32m[0511 06:15:51 @base_main.py:52][0m [train_loss]: 0.5869148969650269
[32m[0511 06:15:51 @base_main.py:52][0m [val_loss]: 1.3707648515701294
[32m[0511 06:15:51 @base_main.py:52][0m [avg_train_loss]: 1.0119702816009521
[32m[0511 06:17:57 @mbmf_sampler.py:39][0m done with episode
[32m[0511 06:20:03 @mbmf_sampler.py:39][0m done with episode
[32m[0511 06:22:09 @mbmf_sampler.py:39][0m done with episode
[32m[0511 06:24:15 @mbmf_sampler.py:39][0m done with episode
[32m[0511 06:26:21 @mbmf_sampler.py:39][0m done with episode
[32m[0511 06:26:21 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0511 06:26:21 @base_trainer.py:216][0m Mean reward: -1107.6928446408322
[32m[0511 06:26:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1776281595230103, Train Loss: 0.9684605002403259
[32m[0511 06:26:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1777592897415161, Train Loss: 0.9684541821479797
[32m[0511 06:26:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1778786182403564, Train Loss: 0.9684484601020813
[32m[0511 06:26:22 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.177983045578003, Train Loss: 0.9684438109397888
[32m[0511 06:26:22 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1780742406845093, Train Loss: 0.9684401154518127
[32m[0511 06:26:22 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1781527996063232, Train Loss: 0.9684373736381531
[32m[0511 06:26:22 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1782212257385254, Train Loss: 0.9684350490570068
[32m[0511 06:26:22 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1782801151275635, Train Loss: 0.9684335589408875
[32m[0511 06:26:22 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1783310174942017, Train Loss: 0.9684321880340576
[32m[0511 06:26:22 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1783753633499146, Train Loss: 0.968431293964386
[32m[0511 06:26:22 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1784131526947021, Train Loss: 0.9684305191040039
[32m[0511 06:26:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1784465312957764, Train Loss: 0.9684299230575562
[32m[0511 06:26:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.178475260734558, Train Loss: 0.9684293866157532
[32m[0511 06:26:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1785001754760742, Train Loss: 0.9684290289878845
[32m[0511 06:26:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.178521752357483, Train Loss: 0.9684287905693054
[32m[0511 06:26:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1785407066345215, Train Loss: 0.9684285521507263
[32m[0511 06:26:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1785571575164795, Train Loss: 0.968428373336792
[32m[0511 06:26:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.178571343421936, Train Loss: 0.9684281945228577
[32m[0511 06:26:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1785836219787598, Train Loss: 0.9684280753135681
[32m[0511 06:26:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1785945892333984, Train Loss: 0.9684278964996338
[32m[0511 06:26:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.178604006767273, Train Loss: 0.968427836894989
[32m[0511 06:26:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.178612232208252, Train Loss: 0.968427836894989
[32m[0511 06:26:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.178619384765625, Train Loss: 0.9684277176856995
[32m[0511 06:26:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.178625464439392, Train Loss: 0.9684276580810547
[32m[0511 06:26:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.17863130569458, Train Loss: 0.9684276580810547
[32m[0511 06:26:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1786359548568726, Train Loss: 0.9684276580810547
[32m[0511 06:26:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1786400079727173, Train Loss: 0.9684276580810547
[32m[0511 06:26:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1786437034606934, Train Loss: 0.9684274792671204
[32m[0511 06:26:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1786470413208008, Train Loss: 0.9684275984764099
[32m[0511 06:26:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1786497831344604, Train Loss: 0.9684274792671204
[32m[0511 06:26:25 @base_main.py:38][0m --------------- Iteration 6 ---------------
[32m[0511 06:26:25 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 42.3505 mins
[32m[0511 06:26:25 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 10.5056 mins
[32m[0511 06:26:25 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0582 mins
[32m[0511 06:26:25 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0049 mins
[32m[0511 06:26:25 @base_main.py:47][0m 6030 total steps have happened
[32m[0511 06:26:25 @base_main.py:52][0m [avg_reward]: -1107.6928446408322
[32m[0511 06:26:25 @base_main.py:52][0m [update_op]: None
[32m[0511 06:26:25 @base_main.py:52][0m [train_loss]: 1.321512222290039
[32m[0511 06:26:25 @base_main.py:52][0m [val_loss]: 1.1786497831344604
[32m[0511 06:26:25 @base_main.py:52][0m [avg_train_loss]: 0.9684274792671204
[32m[0511 06:28:31 @mbmf_sampler.py:39][0m done with episode
[32m[0511 06:30:37 @mbmf_sampler.py:39][0m done with episode
[32m[0511 06:32:43 @mbmf_sampler.py:39][0m done with episode
[32m[0511 06:34:49 @mbmf_sampler.py:39][0m done with episode
[32m[0511 06:36:55 @mbmf_sampler.py:39][0m done with episode
[32m[0511 06:36:55 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0511 06:36:55 @base_trainer.py:216][0m Mean reward: -1300.8288622491932
[32m[0511 06:36:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0118242502212524, Train Loss: 0.982968270778656
[32m[0511 06:36:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0118197202682495, Train Loss: 0.9829609394073486
[32m[0511 06:36:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0118132829666138, Train Loss: 0.9829549789428711
[32m[0511 06:36:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0118064880371094, Train Loss: 0.9829504489898682
[32m[0511 06:36:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.011799693107605, Train Loss: 0.9829472899436951
[32m[0511 06:36:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0117932558059692, Train Loss: 0.9829450845718384
[32m[0511 06:36:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0117868185043335, Train Loss: 0.9829434752464294
[32m[0511 06:36:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0117809772491455, Train Loss: 0.982942521572113
[32m[0511 06:36:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0117754936218262, Train Loss: 0.9829416275024414
[32m[0511 06:36:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.011770486831665, Train Loss: 0.982941210269928
[32m[0511 06:36:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.011765956878662, Train Loss: 0.982940673828125
[32m[0511 06:36:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0117616653442383, Train Loss: 0.9829405546188354
[32m[0511 06:36:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0117578506469727, Train Loss: 0.9829403162002563
[32m[0511 06:36:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0117546319961548, Train Loss: 0.982940137386322
[32m[0511 06:36:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0117515325546265, Train Loss: 0.982940137386322
[32m[0511 06:36:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0117489099502563, Train Loss: 0.9829400777816772
[32m[0511 06:36:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0117466449737549, Train Loss: 0.9829400777816772
[32m[0511 06:36:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.011744499206543, Train Loss: 0.9829400777816772
[32m[0511 06:36:58 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0117425918579102, Train Loss: 0.9829400181770325
[32m[0511 06:36:58 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.011741042137146, Train Loss: 0.9829400181770325
[32m[0511 06:36:58 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0117394924163818, Train Loss: 0.9829399585723877
[32m[0511 06:36:58 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0117381811141968, Train Loss: 0.9829399585723877
[32m[0511 06:36:58 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0117372274398804, Train Loss: 0.9829400181770325
[32m[0511 06:36:58 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.011736273765564, Train Loss: 0.9829400181770325
[32m[0511 06:36:58 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0117355585098267, Train Loss: 0.9829399585723877
[32m[0511 06:36:59 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0117347240447998, Train Loss: 0.9829400181770325
[32m[0511 06:36:59 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0117340087890625, Train Loss: 0.9829398393630981
[32m[0511 06:36:59 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0117335319519043, Train Loss: 0.9829400181770325
[32m[0511 06:36:59 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0117331743240356, Train Loss: 0.9829399585723877
[32m[0511 06:36:59 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.011732816696167, Train Loss: 0.9829399585723877
[32m[0511 06:36:59 @base_main.py:38][0m --------------- Iteration 7 ---------------
[32m[0511 06:36:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 52.9192 mins
[32m[0511 06:36:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 10.5027 mins
[32m[0511 06:36:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0677 mins
[32m[0511 06:36:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0051 mins
[32m[0511 06:36:59 @base_main.py:47][0m 7035 total steps have happened
[32m[0511 06:36:59 @base_main.py:52][0m [avg_reward]: -1300.8288622491932
[32m[0511 06:36:59 @base_main.py:52][0m [update_op]: None
[32m[0511 06:36:59 @base_main.py:52][0m [train_loss]: 1.108288288116455
[32m[0511 06:36:59 @base_main.py:52][0m [val_loss]: 1.011732816696167
[32m[0511 06:36:59 @base_main.py:52][0m [avg_train_loss]: 0.9829399585723877
[32m[0511 06:36:59 @mbmf_trainer.py:160][0m Mean reward: -1260.1699064680317
[32m[0511 06:37:00 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.17407503724098206, Train Loss: 0.18266034126281738
[32m[0511 06:37:00 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.17403556406497955, Train Loss: 0.18258190155029297
[32m[0511 06:37:00 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.17399613559246063, Train Loss: 0.18255500495433807
[32m[0511 06:37:00 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.17397432029247284, Train Loss: 0.18253739178180695
[32m[0511 06:37:00 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.17396104335784912, Train Loss: 0.1825232356786728
[32m[0511 06:37:00 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.17395013570785522, Train Loss: 0.18251095712184906
[32m[0511 06:37:00 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.17394205927848816, Train Loss: 0.18250000476837158
[32m[0511 06:37:00 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.17393732070922852, Train Loss: 0.18248999118804932
[32m[0511 06:37:00 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.17393462359905243, Train Loss: 0.182480588555336
[32m[0511 06:37:00 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.1739329993724823, Train Loss: 0.1824716478586197
[32m[0511 06:37:00 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.17393219470977783, Train Loss: 0.1824631541967392
[32m[0511 06:37:00 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.17393215000629425, Train Loss: 0.18245498836040497
[32m[0511 06:37:00 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.17393265664577484, Train Loss: 0.1824471801519394
[32m[0511 06:37:00 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.17393356561660767, Train Loss: 0.1824396401643753
[32m[0511 06:37:00 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.17393484711647034, Train Loss: 0.1824323982000351
[32m[0511 06:37:00 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.17393645644187927, Train Loss: 0.18242543935775757
[32m[0511 06:37:00 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.1739383041858673, Train Loss: 0.18241870403289795
[32m[0511 06:37:00 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.17394039034843445, Train Loss: 0.182412251830101
[32m[0511 06:37:00 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.1739426702260971, Train Loss: 0.1824059933423996
[32m[0511 06:37:00 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.17394514381885529, Train Loss: 0.18239998817443848
[32m[0511 06:37:00 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.17394773662090302, Train Loss: 0.18239416182041168
[32m[0511 06:37:00 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.17395049333572388, Train Loss: 0.1823885589838028
[32m[0511 06:37:00 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.1739533692598343, Train Loss: 0.18238312005996704
[32m[0511 06:37:00 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.17395633459091187, Train Loss: 0.182377889752388
[32m[0511 06:37:00 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.1739593893289566, Train Loss: 0.1823728233575821
[32m[0511 06:37:00 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.1739625334739685, Train Loss: 0.1823679357767105
[32m[0511 06:37:00 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.173965722322464, Train Loss: 0.18236316740512848
[32m[0511 06:37:00 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.17396898567676544, Train Loss: 0.18235860764980316
[32m[0511 06:37:00 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.17397230863571167, Train Loss: 0.18235410749912262
[32m[0511 06:37:00 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.1739756464958191, Train Loss: 0.1823497861623764
[32m[0511 06:37:00 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.1739789992570877, Train Loss: 0.18234556913375854
[32m[0511 06:37:00 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.1739824116230011, Train Loss: 0.18234145641326904
[32m[0511 06:37:00 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.1739858090877533, Train Loss: 0.18233747780323029
[32m[0511 06:37:01 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.17398923635482788, Train Loss: 0.1823335886001587
[32m[0511 06:37:01 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.17399266362190247, Train Loss: 0.18232972919940948
[32m[0511 06:37:01 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.17399607598781586, Train Loss: 0.18232601881027222
[32m[0511 06:37:01 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.17399953305721283, Train Loss: 0.18232233822345734
[32m[0511 06:37:01 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.17400294542312622, Train Loss: 0.1823187619447708
[32m[0511 06:37:01 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.1740063726902008, Train Loss: 0.18231523036956787
[32m[0511 06:37:01 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.174009770154953, Train Loss: 0.1823117733001709
[32m[0511 06:37:01 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.1740131825208664, Train Loss: 0.1823083609342575
[32m[0511 06:37:01 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.1740165799856186, Train Loss: 0.18230502307415009
[32m[0511 06:37:01 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.1740199625492096, Train Loss: 0.18230170011520386
[32m[0511 06:37:01 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.1740233302116394, Train Loss: 0.1822984367609024
[32m[0511 06:37:01 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.1740266978740692, Train Loss: 0.18229518830776215
[32m[0511 06:37:01 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.17403002083301544, Train Loss: 0.18229198455810547
[32m[0511 06:37:01 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.17403337359428406, Train Loss: 0.18228881061077118
[32m[0511 06:37:01 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.17403669655323029, Train Loss: 0.18228566646575928
[32m[0511 06:37:01 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.17404000461101532, Train Loss: 0.18228255212306976
[32m[0511 06:37:01 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.17404329776763916, Train Loss: 0.18227946758270264
[32m[0511 06:37:01 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.1740466058254242, Train Loss: 0.1822763830423355
[32m[0511 06:37:01 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.17404988408088684, Train Loss: 0.18227332830429077
[32m[0511 06:37:01 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.1740531623363495, Train Loss: 0.18227028846740723
[32m[0511 06:37:01 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.17405642569065094, Train Loss: 0.18226729333400726
[32m[0511 06:37:01 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.1740596890449524, Train Loss: 0.1822642832994461
[32m[0511 06:37:01 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.17406293749809265, Train Loss: 0.18226130306720734
[32m[0511 06:37:01 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.17406617105007172, Train Loss: 0.18225832283496857
[32m[0511 06:37:01 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.17406943440437317, Train Loss: 0.18225537240505219
[32m[0511 06:37:01 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.17407268285751343, Train Loss: 0.18225239217281342
[32m[0511 06:37:01 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.1740759313106537, Train Loss: 0.18224944174289703
[32m[0511 06:37:01 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.17407919466495514, Train Loss: 0.18224650621414185
[32m[0511 06:37:01 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.1740824282169342, Train Loss: 0.18224357068538666
[32m[0511 06:37:01 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.17408566176891327, Train Loss: 0.18224065005779266
[32m[0511 06:37:01 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.17408891022205353, Train Loss: 0.18223774433135986
[32m[0511 06:37:01 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.17409217357635498, Train Loss: 0.18223480880260468
[32m[0511 06:37:01 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.17409543693065643, Train Loss: 0.18223190307617188
[32m[0511 06:37:01 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.1740986853837967, Train Loss: 0.18222899734973907
[32m[0511 06:37:01 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.17410194873809814, Train Loss: 0.18222607672214508
[32m[0511 06:37:01 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.17410524189472198, Train Loss: 0.18222320079803467
[32m[0511 06:37:01 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.17410852015018463, Train Loss: 0.18222029507160187
[32m[0511 06:37:02 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.17411179840564728, Train Loss: 0.18221741914749146
[32m[0511 06:37:02 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.1741151064634323, Train Loss: 0.18221449851989746
[32m[0511 06:37:02 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.17411841452121735, Train Loss: 0.18221162259578705
[32m[0511 06:37:02 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.17412173748016357, Train Loss: 0.18220873177051544
[32m[0511 06:37:02 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.1741250455379486, Train Loss: 0.18220585584640503
[32m[0511 06:37:02 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.17412839829921722, Train Loss: 0.18220297992229462
[32m[0511 06:37:02 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.17413173615932465, Train Loss: 0.182200089097023
[32m[0511 06:37:02 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.17413510382175446, Train Loss: 0.1821972280740738
[32m[0511 06:37:02 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.17413848638534546, Train Loss: 0.18219435214996338
[32m[0511 06:37:02 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.17414188385009766, Train Loss: 0.18219147622585297
[32m[0511 06:37:02 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.17414528131484985, Train Loss: 0.18218858540058136
[32m[0511 06:37:02 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.17414870858192444, Train Loss: 0.18218572437763214
[32m[0511 06:37:02 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.17415213584899902, Train Loss: 0.18218284845352173
[32m[0511 06:37:02 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.174155592918396, Train Loss: 0.18217997252941132
[32m[0511 06:37:02 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.17415904998779297, Train Loss: 0.1821771264076233
[32m[0511 06:37:02 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.17416252195835114, Train Loss: 0.18217425048351288
[32m[0511 06:37:02 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.1741660088300705, Train Loss: 0.18217138946056366
[32m[0511 06:37:02 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.17416951060295105, Train Loss: 0.18216854333877563
[32m[0511 06:37:02 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.1741730272769928, Train Loss: 0.18216568231582642
[32m[0511 06:37:02 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.17417658865451813, Train Loss: 0.182162806391716
[32m[0511 06:37:02 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.17418013513088226, Train Loss: 0.18215997517108917
[32m[0511 06:37:02 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.1741837114095688, Train Loss: 0.18215711414813995
[32m[0511 06:37:02 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.1741872876882553, Train Loss: 0.18215425312519073
[32m[0511 06:37:02 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.17419090867042542, Train Loss: 0.1821514219045639
[32m[0511 06:37:02 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.17419452965259552, Train Loss: 0.18214857578277588
[32m[0511 06:37:02 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.17419815063476562, Train Loss: 0.18214572966098785
[32m[0511 06:37:02 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.1742018163204193, Train Loss: 0.18214289844036102
[32m[0511 06:37:02 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.1742054969072342, Train Loss: 0.1821400374174118
[32m[0511 06:37:02 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.17420917749404907, Train Loss: 0.18213720619678497
[32m[0511 06:37:02 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.17421288788318634, Train Loss: 0.18213437497615814
[32m[0511 06:37:02 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.1742166131734848, Train Loss: 0.18213151395320892
[32m[0511 06:37:02 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.17422035336494446, Train Loss: 0.18212871253490448
[32m[0511 06:37:02 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.1742241233587265, Train Loss: 0.18212588131427765
[32m[0511 06:37:02 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.17422787845134735, Train Loss: 0.18212305009365082
[32m[0511 06:37:02 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.1742316633462906, Train Loss: 0.182120218873024
[32m[0511 06:37:02 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.1742354929447174, Train Loss: 0.18211741745471954
[32m[0511 06:37:02 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.17423930764198303, Train Loss: 0.1821146011352539
[32m[0511 06:37:03 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.17424316704273224, Train Loss: 0.18211179971694946
[32m[0511 06:37:03 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.17424702644348145, Train Loss: 0.18210898339748383
[32m[0511 06:37:03 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.17425091564655304, Train Loss: 0.18210618197917938
[32m[0511 06:37:03 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.17425478994846344, Train Loss: 0.18210338056087494
[32m[0511 06:37:03 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.17425870895385742, Train Loss: 0.1821005791425705
[32m[0511 06:37:03 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.1742626428604126, Train Loss: 0.18209779262542725
[32m[0511 06:37:03 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.17426657676696777, Train Loss: 0.1820949912071228
[32m[0511 06:37:03 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.17427052557468414, Train Loss: 0.18209220468997955
[32m[0511 06:37:03 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.1742745190858841, Train Loss: 0.1820894330739975
[32m[0511 06:37:03 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.17427851259708405, Train Loss: 0.18208664655685425
[32m[0511 06:37:03 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.17428253591060638, Train Loss: 0.1820838898420334
[32m[0511 06:37:03 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.17428655922412872, Train Loss: 0.18208111822605133
[32m[0511 06:37:03 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.17429059743881226, Train Loss: 0.18207834661006927
[32m[0511 06:37:03 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.17429465055465698, Train Loss: 0.1820756047964096
[32m[0511 06:37:03 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.1742987483739853, Train Loss: 0.18207283318042755
[32m[0511 06:37:03 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.1743028163909912, Train Loss: 0.18207009136676788
[32m[0511 06:37:03 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.1743069291114807, Train Loss: 0.18206734955310822
[32m[0511 06:37:03 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.1743110567331314, Train Loss: 0.18206463754177094
[32m[0511 06:37:03 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.1743151843547821, Train Loss: 0.18206186592578888
[32m[0511 06:37:03 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.1743193417787552, Train Loss: 0.1820591539144516
[32m[0511 06:37:03 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.17432349920272827, Train Loss: 0.18205642700195312
[32m[0511 06:37:03 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.17432768642902374, Train Loss: 0.18205372989177704
[32m[0511 06:37:03 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.1743318885564804, Train Loss: 0.18205100297927856
[32m[0511 06:37:03 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.17433607578277588, Train Loss: 0.18204830586910248
[32m[0511 06:37:03 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.17434030771255493, Train Loss: 0.1820455938577652
[32m[0511 06:37:03 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.17434453964233398, Train Loss: 0.1820429116487503
[32m[0511 06:37:03 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.17434880137443542, Train Loss: 0.1820402294397354
[32m[0511 06:37:03 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.17435304820537567, Train Loss: 0.18203754723072052
[32m[0511 06:37:03 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.1743573248386383, Train Loss: 0.18203486502170563
[32m[0511 06:37:03 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.17436163127422333, Train Loss: 0.18203222751617432
[32m[0511 06:37:03 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.17436595261096954, Train Loss: 0.18202954530715942
[32m[0511 06:37:03 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.17437024414539337, Train Loss: 0.1820269078016281
[32m[0511 06:37:03 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.17437458038330078, Train Loss: 0.1820242553949356
[32m[0511 06:37:03 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.17437893152236938, Train Loss: 0.1820216178894043
[32m[0511 06:37:03 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.174383282661438, Train Loss: 0.18201898038387299
[32m[0511 06:37:04 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.17438764870166779, Train Loss: 0.18201637268066406
[32m[0511 06:37:04 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.17439204454421997, Train Loss: 0.18201375007629395
[32m[0511 06:37:04 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.17439641058444977, Train Loss: 0.18201114237308502
[32m[0511 06:37:04 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.17440082132816315, Train Loss: 0.1820085197687149
[32m[0511 06:37:04 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.17440523207187653, Train Loss: 0.18200592696666718
[32m[0511 06:37:04 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.1744096577167511, Train Loss: 0.18200333416461945
[32m[0511 06:37:04 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.17441409826278687, Train Loss: 0.1820007711648941
[32m[0511 06:37:04 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.17441852390766144, Train Loss: 0.18199819326400757
[32m[0511 06:37:04 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.1744229942560196, Train Loss: 0.18199563026428223
[32m[0511 06:37:04 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.17442746460437775, Train Loss: 0.18199306726455688
[32m[0511 06:37:04 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.1744319349527359, Train Loss: 0.18199051916599274
[32m[0511 06:37:04 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.17443643510341644, Train Loss: 0.18198798596858978
[32m[0511 06:37:04 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.1744409203529358, Train Loss: 0.18198545277118683
[32m[0511 06:37:04 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.17444542050361633, Train Loss: 0.18198291957378387
[32m[0511 06:37:04 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.17444993555545807, Train Loss: 0.18198038637638092
[32m[0511 06:37:04 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.1744544506072998, Train Loss: 0.18197788298130035
[32m[0511 06:37:04 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.17445901036262512, Train Loss: 0.1819753795862198
[32m[0511 06:37:04 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.17446354031562805, Train Loss: 0.18197287619113922
[32m[0511 06:37:04 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.17446810007095337, Train Loss: 0.18197040259838104
[32m[0511 06:37:04 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.1744726449251175, Train Loss: 0.18196791410446167
[32m[0511 06:37:04 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.1744772046804428, Train Loss: 0.18196545541286469
[32m[0511 06:37:04 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.17448179423809052, Train Loss: 0.1819629818201065
[32m[0511 06:37:04 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.17448636889457703, Train Loss: 0.18196053802967072
[32m[0511 06:37:04 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.17449095845222473, Train Loss: 0.18195807933807373
[32m[0511 06:37:04 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.17449554800987244, Train Loss: 0.18195565044879913
[32m[0511 06:37:04 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.17450015246868134, Train Loss: 0.18195323646068573
[32m[0511 06:37:04 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.17450477182865143, Train Loss: 0.18195080757141113
[32m[0511 06:37:04 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.17450937628746033, Train Loss: 0.18194837868213654
[32m[0511 06:37:04 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.1745140105485916, Train Loss: 0.18194597959518433
[32m[0511 06:37:04 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.1745186299085617, Train Loss: 0.1819435954093933
[32m[0511 06:37:04 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.174523264169693, Train Loss: 0.1819411963224411
[32m[0511 06:37:04 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.17452791333198547, Train Loss: 0.18193882703781128
[32m[0511 06:37:04 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.17453256249427795, Train Loss: 0.18193644285202026
[32m[0511 06:37:04 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.17453719675540924, Train Loss: 0.18193410336971283
[32m[0511 06:37:04 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.17454186081886292, Train Loss: 0.181931734085083
[32m[0511 06:37:04 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.17454653978347778, Train Loss: 0.18192939460277557
[32m[0511 06:37:05 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.17455120384693146, Train Loss: 0.18192704021930695
[32m[0511 06:37:05 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.17455585300922394, Train Loss: 0.1819247454404831
[32m[0511 06:37:05 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.1745605319738388, Train Loss: 0.18192243576049805
[32m[0511 06:37:05 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.17456521093845367, Train Loss: 0.1819201111793518
[32m[0511 06:37:05 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.17456990480422974, Train Loss: 0.18191780149936676
[32m[0511 06:37:05 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.1745745837688446, Train Loss: 0.1819155365228653
[32m[0511 06:37:05 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.17457927763462067, Train Loss: 0.18191324174404144
[32m[0511 06:37:05 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.17458398640155792, Train Loss: 0.1819109469652176
[32m[0511 06:37:05 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.1745886653661728, Train Loss: 0.1819087117910385
[32m[0511 06:37:05 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.17459338903427124, Train Loss: 0.18190644681453705
[32m[0511 06:37:05 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.1745980829000473, Train Loss: 0.18190419673919678
[32m[0511 06:37:05 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.17460279166698456, Train Loss: 0.1819019466638565
[32m[0511 06:37:05 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.174607515335083, Train Loss: 0.18189972639083862
[32m[0511 06:37:05 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.17461222410202026, Train Loss: 0.18189750611782074
[32m[0511 06:37:05 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.17461693286895752, Train Loss: 0.18189530074596405
[32m[0511 06:37:05 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.17462164163589478, Train Loss: 0.18189309537410736
[32m[0511 06:37:05 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.17462635040283203, Train Loss: 0.18189089000225067
[32m[0511 06:37:05 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.17463108897209167, Train Loss: 0.18188869953155518
[32m[0511 06:37:05 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.17463581264019012, Train Loss: 0.18188653886318207
[32m[0511 06:37:05 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.17464053630828857, Train Loss: 0.18188439309597015
[32m[0511 06:37:05 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.17464525997638702, Train Loss: 0.18188221752643585
[32m[0511 06:37:05 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.17464998364448547, Train Loss: 0.18188007175922394
[32m[0511 06:37:05 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.17465472221374512, Train Loss: 0.18187791109085083
[32m[0511 06:37:05 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.17465943098068237, Train Loss: 0.1818758100271225
[32m[0511 06:37:05 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.1746641844511032, Train Loss: 0.18187367916107178
[32m[0511 06:37:05 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.17466889321804047, Train Loss: 0.18187154829502106
[32m[0511 06:37:05 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.17467361688613892, Train Loss: 0.18186943233013153
[32m[0511 06:37:05 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.17467835545539856, Train Loss: 0.181867316365242
[32m[0511 06:37:05 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.174683079123497, Train Loss: 0.18186526000499725
[32m[0511 06:37:05 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.17468778789043427, Train Loss: 0.18186317384243011
[32m[0511 06:37:05 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.1746925413608551, Train Loss: 0.18186110258102417
[32m[0511 06:37:05 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.17469725012779236, Train Loss: 0.18185903131961823
[32m[0511 06:37:05 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.174701988697052, Train Loss: 0.18185698986053467
[32m[0511 06:37:05 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.17470671236515045, Train Loss: 0.18185491859912872
[32m[0511 06:37:05 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.1747114360332489, Train Loss: 0.18185289204120636
[32m[0511 06:37:05 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.17471615970134735, Train Loss: 0.1818508505821228
[32m[0511 06:37:06 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.1747208684682846, Train Loss: 0.18184883892536163
[32m[0511 06:37:06 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.17472560703754425, Train Loss: 0.18184684216976166
[32m[0511 06:37:06 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.1747303158044815, Train Loss: 0.1818448305130005
[32m[0511 06:37:06 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.17473503947257996, Train Loss: 0.18184281885623932
[32m[0511 06:37:06 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.17473973333835602, Train Loss: 0.18184085190296173
[32m[0511 06:37:06 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.17474445700645447, Train Loss: 0.18183885514736176
[32m[0511 06:37:06 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.17474915087223053, Train Loss: 0.18183688819408417
[32m[0511 06:37:06 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.17475385963916779, Train Loss: 0.18183492124080658
[32m[0511 06:37:06 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.17475856840610504, Train Loss: 0.18183296918869019
[32m[0511 06:37:06 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.1747632920742035, Train Loss: 0.1818310171365738
[32m[0511 06:37:06 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.17476798593997955, Train Loss: 0.18182909488677979
[32m[0511 06:37:06 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.17477266490459442, Train Loss: 0.1818271428346634
[32m[0511 06:37:06 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.17477735877037048, Train Loss: 0.18182523548603058
[32m[0511 06:37:06 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.17478205263614655, Train Loss: 0.18182332813739777
[32m[0511 06:37:06 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.1747867316007614, Train Loss: 0.18182140588760376
[32m[0511 06:37:06 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.17479141056537628, Train Loss: 0.18181949853897095
[32m[0511 06:37:06 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.17479611933231354, Train Loss: 0.18181763589382172
[32m[0511 06:37:06 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.1748007833957672, Train Loss: 0.1818157434463501
[32m[0511 06:37:06 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.1748054325580597, Train Loss: 0.18181385099887848
[32m[0511 06:37:06 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.17481011152267456, Train Loss: 0.18181198835372925
[32m[0511 06:37:06 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.17481477558612823, Train Loss: 0.18181012570858002
[32m[0511 06:37:06 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.17481942474842072, Train Loss: 0.18180827796459198
[32m[0511 06:37:06 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.1748240888118744, Train Loss: 0.18180644512176514
[32m[0511 06:37:06 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.17482875287532806, Train Loss: 0.1818045973777771
[32m[0511 06:37:06 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.17483338713645935, Train Loss: 0.18180279433727264
[32m[0511 06:37:06 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.17483802139759064, Train Loss: 0.1818009465932846
[32m[0511 06:37:06 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.1748426854610443, Train Loss: 0.18179912865161896
[32m[0511 06:37:06 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.1748472899198532, Train Loss: 0.1817973256111145
[32m[0511 06:37:06 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.1748519241809845, Train Loss: 0.18179553747177124
[32m[0511 06:37:06 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.1748565286397934, Train Loss: 0.18179374933242798
[32m[0511 06:37:06 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.1748611479997635, Train Loss: 0.18179194629192352
[32m[0511 06:37:06 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.17486576735973358, Train Loss: 0.18179017305374146
[32m[0511 06:37:06 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.17487037181854248, Train Loss: 0.1817883998155594
[32m[0511 06:37:06 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.17487496137619019, Train Loss: 0.1817866563796997
[32m[0511 06:37:06 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.1748795509338379, Train Loss: 0.18178488314151764
[32m[0511 06:37:06 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.1748841553926468, Train Loss: 0.18178313970565796
[32m[0511 06:37:07 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.1748887002468109, Train Loss: 0.18178141117095947
[32m[0511 06:37:07 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.17489327490329742, Train Loss: 0.1817796677350998
[32m[0511 06:37:07 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.17489783465862274, Train Loss: 0.1817779392004013
[32m[0511 06:37:07 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.17490240931510925, Train Loss: 0.181776225566864
[32m[0511 06:37:07 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.17490696907043457, Train Loss: 0.18177451193332672
[32m[0511 06:37:07 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.1749114990234375, Train Loss: 0.18177281320095062
[32m[0511 06:37:07 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.174916073679924, Train Loss: 0.18177109956741333
[32m[0511 06:37:07 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.17492058873176575, Train Loss: 0.18176941573619843
[32m[0511 06:37:07 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.17492510378360748, Train Loss: 0.18176774680614471
[32m[0511 06:37:07 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.17492961883544922, Train Loss: 0.18176603317260742
[32m[0511 06:37:07 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.17493414878845215, Train Loss: 0.1817643642425537
[32m[0511 06:37:07 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.1749386340379715, Train Loss: 0.1817626953125
[32m[0511 06:37:07 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.17494314908981323, Train Loss: 0.1817610263824463
[32m[0511 06:37:07 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.17494763433933258, Train Loss: 0.18175940215587616
[32m[0511 06:37:07 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.17495211958885193, Train Loss: 0.18175774812698364
[32m[0511 06:37:07 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.1749565750360489, Train Loss: 0.18175609409809113
[32m[0511 06:37:07 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.17496104538440704, Train Loss: 0.181754469871521
[32m[0511 06:37:07 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.1749655306339264, Train Loss: 0.18175284564495087
[32m[0511 06:37:07 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.17496995627880096, Train Loss: 0.18175123631954193
[32m[0511 06:37:07 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.17497441172599792, Train Loss: 0.1817495971918106
[32m[0511 06:37:07 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.1749788522720337, Train Loss: 0.18174798786640167
[32m[0511 06:37:07 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.17498327791690826, Train Loss: 0.18174637854099274
[32m[0511 06:37:07 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.17498770356178284, Train Loss: 0.18174481391906738
[32m[0511 06:37:07 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.17499209940433502, Train Loss: 0.18174321949481964
[32m[0511 06:37:07 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.1749965101480484, Train Loss: 0.1817416399717331
[32m[0511 06:37:07 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.17500092089176178, Train Loss: 0.18174004554748535
[32m[0511 06:37:07 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.17500527203083038, Train Loss: 0.18173848092556
[32m[0511 06:37:07 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.17500966787338257, Train Loss: 0.18173690140247345
[32m[0511 06:37:07 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.17501403391361237, Train Loss: 0.1817353367805481
[32m[0511 06:37:07 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.17501839995384216, Train Loss: 0.18173380196094513
[32m[0511 06:37:07 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.17502275109291077, Train Loss: 0.18173223733901978
[32m[0511 06:37:07 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.17502708733081818, Train Loss: 0.18173068761825562
[32m[0511 06:37:07 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.17503142356872559, Train Loss: 0.18172915279865265
[32m[0511 06:37:07 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.1750357449054718, Train Loss: 0.1817276030778885
[32m[0511 06:37:07 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.17504005134105682, Train Loss: 0.1817260980606079
[32m[0511 06:37:07 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.17504437267780304, Train Loss: 0.18172456324100494
[32m[0511 06:37:08 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.17504866421222687, Train Loss: 0.18172305822372437
[32m[0511 06:37:08 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.1750529557466507, Train Loss: 0.1817215234041214
[32m[0511 06:37:08 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.17505723237991333, Train Loss: 0.18172001838684082
[32m[0511 06:37:08 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.17506150901317596, Train Loss: 0.18171854317188263
[32m[0511 06:37:08 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.1750657707452774, Train Loss: 0.18171703815460205
[32m[0511 06:37:08 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.17507001757621765, Train Loss: 0.18171554803848267
[32m[0511 06:37:08 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.1750742644071579, Train Loss: 0.1817140430212021
[32m[0511 06:37:08 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.17507849633693695, Train Loss: 0.1817125678062439
[32m[0511 06:37:08 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.175082728266716, Train Loss: 0.1817110925912857
[32m[0511 06:37:08 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.17508691549301147, Train Loss: 0.1817096322774887
[32m[0511 06:37:08 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.17509114742279053, Train Loss: 0.1817081719636917
[32m[0511 06:37:08 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.175095334649086, Train Loss: 0.18170671164989471
[32m[0511 06:37:08 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.17509950697422028, Train Loss: 0.18170525133609772
[32m[0511 06:37:08 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.17510367929935455, Train Loss: 0.18170380592346191
[32m[0511 06:37:08 @mbmf_sampler.py:98][0m Finished 9th episode
[32m[0511 06:37:08 @mbmf_sampler.py:102][0m 1809 timesteps from 9 episodes collected
[32m[0511 06:56:06 @mbmf_trainer.py:160][0m Mean reward: -1277.8806931029296
[32m[0511 06:56:07 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.17998434603214264, Train Loss: 0.17838898301124573
[32m[0511 06:56:07 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.18000487983226776, Train Loss: 0.17837554216384888
[32m[0511 06:56:07 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.1799953281879425, Train Loss: 0.17835871875286102
[32m[0511 06:56:07 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.17999711632728577, Train Loss: 0.17834170162677765
[32m[0511 06:56:07 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.17999963462352753, Train Loss: 0.17833034694194794
[32m[0511 06:56:07 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.18000201880931854, Train Loss: 0.1783193051815033
[32m[0511 06:56:07 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.18000634014606476, Train Loss: 0.17831045389175415
[32m[0511 06:56:07 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.18001046776771545, Train Loss: 0.17830295860767365
[32m[0511 06:56:07 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.18001475930213928, Train Loss: 0.17829637229442596
[32m[0511 06:56:07 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.18001902103424072, Train Loss: 0.1782907396554947
[32m[0511 06:56:07 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.18002310395240784, Train Loss: 0.17828576266765594
[32m[0511 06:56:07 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.180027037858963, Train Loss: 0.17828130722045898
[32m[0511 06:56:07 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.18003074824810028, Train Loss: 0.17827732861042023
[32m[0511 06:56:07 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.18003427982330322, Train Loss: 0.17827372252941132
[32m[0511 06:56:07 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.18003755807876587, Train Loss: 0.17827042937278748
[32m[0511 06:56:07 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.1800406128168106, Train Loss: 0.17826738953590393
[32m[0511 06:56:07 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.18004350364208221, Train Loss: 0.17826460301876068
[32m[0511 06:56:07 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.18004611134529114, Train Loss: 0.17826198041439056
[32m[0511 06:56:07 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.18004857003688812, Train Loss: 0.17825950682163239
[32m[0511 06:56:07 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.1800508052110672, Train Loss: 0.17825718224048615
[32m[0511 06:56:07 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.18005290627479553, Train Loss: 0.17825494706630707
[32m[0511 06:56:07 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.18005481362342834, Train Loss: 0.17825286090373993
[32m[0511 06:56:07 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.18005657196044922, Train Loss: 0.17825084924697876
[32m[0511 06:56:07 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.18005819618701935, Train Loss: 0.17824892699718475
[32m[0511 06:56:07 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.18005968630313873, Train Loss: 0.17824706435203552
[32m[0511 06:56:07 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.18006104230880737, Train Loss: 0.17824527621269226
[32m[0511 06:56:07 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.18006232380867004, Train Loss: 0.17824354767799377
[32m[0511 06:56:07 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.18006348609924316, Train Loss: 0.17824187874794006
[32m[0511 06:56:07 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.18006457388401031, Train Loss: 0.17824023962020874
[32m[0511 06:56:08 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.1800655722618103, Train Loss: 0.178238645195961
[32m[0511 06:56:08 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.18006646633148193, Train Loss: 0.17823711037635803
[32m[0511 06:56:08 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.18006733059883118, Train Loss: 0.17823556065559387
[32m[0511 06:56:08 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.18006812036037445, Train Loss: 0.17823411524295807
[32m[0511 06:56:08 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.18006888031959534, Train Loss: 0.17823265492916107
[32m[0511 06:56:08 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.18006958067417145, Train Loss: 0.17823125422000885
[32m[0511 06:56:08 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.18007025122642517, Train Loss: 0.17822985351085663
[32m[0511 06:56:08 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.18007083237171173, Train Loss: 0.1782284677028656
[32m[0511 06:56:08 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.1800714135169983, Train Loss: 0.17822715640068054
[32m[0511 06:56:08 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.18007199466228485, Train Loss: 0.1782258003950119
[32m[0511 06:56:08 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.18007253110408783, Train Loss: 0.17822453379631042
[32m[0511 06:56:08 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.18007302284240723, Train Loss: 0.17822322249412537
[32m[0511 06:56:08 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.18007351458072662, Train Loss: 0.17822198569774628
[32m[0511 06:56:08 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.18007399141788483, Train Loss: 0.178220734000206
[32m[0511 06:56:08 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.18007445335388184, Train Loss: 0.17821954190731049
[32m[0511 06:56:08 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.18007490038871765, Train Loss: 0.1782183200120926
[32m[0511 06:56:08 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.18007536232471466, Train Loss: 0.1782171130180359
[32m[0511 06:56:08 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.1800757646560669, Train Loss: 0.17821595072746277
[32m[0511 06:56:08 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.1800762265920639, Train Loss: 0.17821477353572845
[32m[0511 06:56:08 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.18007662892341614, Train Loss: 0.17821364104747772
[32m[0511 06:56:08 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.18007707595825195, Train Loss: 0.1782124787569046
[32m[0511 06:56:08 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.1800774782896042, Train Loss: 0.17821137607097626
[32m[0511 06:56:08 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.1800779104232788, Train Loss: 0.17821024358272552
[32m[0511 06:56:08 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.18007834255695343, Train Loss: 0.17820914089679718
[32m[0511 06:56:08 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.18007878959178925, Train Loss: 0.17820806801319122
[32m[0511 06:56:08 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.18007919192314148, Train Loss: 0.17820698022842407
[32m[0511 06:56:08 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.1800796389579773, Train Loss: 0.1782059222459793
[32m[0511 06:56:08 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.1800800859928131, Train Loss: 0.17820484936237335
[32m[0511 06:56:08 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.18008051812648773, Train Loss: 0.1782037764787674
[32m[0511 06:56:08 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.18008098006248474, Train Loss: 0.1782027631998062
[32m[0511 06:56:09 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.18008142709732056, Train Loss: 0.17820170521736145
[32m[0511 06:56:09 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.18008190393447876, Train Loss: 0.17820066213607788
[32m[0511 06:56:09 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.18008236587047577, Train Loss: 0.1781996339559555
[32m[0511 06:56:09 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.18008284270763397, Train Loss: 0.1781986504793167
[32m[0511 06:56:09 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.18008334934711456, Train Loss: 0.17819765210151672
[32m[0511 06:56:09 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.18008387088775635, Train Loss: 0.17819665372371674
[32m[0511 06:56:09 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.18008434772491455, Train Loss: 0.17819565534591675
[32m[0511 06:56:09 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.18008486926555634, Train Loss: 0.17819468677043915
[32m[0511 06:56:09 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.18008536100387573, Train Loss: 0.17819370329380035
[32m[0511 06:56:09 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.1800859272480011, Train Loss: 0.17819271981716156
[32m[0511 06:56:09 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.18008647859096527, Train Loss: 0.17819175124168396
[32m[0511 06:56:09 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.18008704483509064, Train Loss: 0.17819079756736755
[32m[0511 06:56:09 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.18008756637573242, Train Loss: 0.17818982899188995
[32m[0511 06:56:09 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.18008816242218018, Train Loss: 0.17818889021873474
[32m[0511 06:56:09 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.18008872866630554, Train Loss: 0.17818793654441833
[32m[0511 06:56:09 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.1800893247127533, Train Loss: 0.17818699777126312
[32m[0511 06:56:09 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.18008990585803986, Train Loss: 0.1781860738992691
[32m[0511 06:56:09 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.1800905168056488, Train Loss: 0.1781851351261139
[32m[0511 06:56:09 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.18009111285209656, Train Loss: 0.17818421125411987
[32m[0511 06:56:09 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.1800917685031891, Train Loss: 0.17818327248096466
[32m[0511 06:56:09 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.18009239435195923, Train Loss: 0.17818236351013184
[32m[0511 06:56:09 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.18009303510189056, Train Loss: 0.178181454539299
[32m[0511 06:56:09 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.1800937056541443, Train Loss: 0.17818056046962738
[32m[0511 06:56:09 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.18009436130523682, Train Loss: 0.17817963659763336
[32m[0511 06:56:09 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.18009503185749054, Train Loss: 0.17817874252796173
[32m[0511 06:56:09 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.18009571731090546, Train Loss: 0.1781778186559677
[32m[0511 06:56:09 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.18009641766548157, Train Loss: 0.17817693948745728
[32m[0511 06:56:09 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.1800970882177353, Train Loss: 0.17817606031894684
[32m[0511 06:56:09 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.1800977885723114, Train Loss: 0.1781751662492752
[32m[0511 06:56:10 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.1800985038280487, Train Loss: 0.17817427217960358
[32m[0511 06:56:10 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.1800992339849472, Train Loss: 0.17817337810993195
[32m[0511 06:56:10 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.1800999492406845, Train Loss: 0.1781724989414215
[32m[0511 06:56:10 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.1801007091999054, Train Loss: 0.17817160487174988
[32m[0511 06:56:10 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.1801014393568039, Train Loss: 0.17817074060440063
[32m[0511 06:56:10 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.18010219931602478, Train Loss: 0.1781698763370514
[32m[0511 06:56:10 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.18010295927524567, Train Loss: 0.17816899716854095
[32m[0511 06:56:10 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.18010374903678894, Train Loss: 0.1781681329011917
[32m[0511 06:56:10 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.18010450899600983, Train Loss: 0.17816726863384247
[32m[0511 06:56:10 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.1801052689552307, Train Loss: 0.17816640436649323
[32m[0511 06:56:10 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.18010607361793518, Train Loss: 0.1781655251979828
[32m[0511 06:56:10 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.18010687828063965, Train Loss: 0.17816467583179474
[32m[0511 06:56:10 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.18010766804218292, Train Loss: 0.1781638115644455
[32m[0511 06:56:10 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.18010850250720978, Train Loss: 0.17816296219825745
[32m[0511 06:56:10 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.18010932207107544, Train Loss: 0.1781621277332306
[32m[0511 06:56:10 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.1801101267337799, Train Loss: 0.17816124856472015
[32m[0511 06:56:10 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.18011096119880676, Train Loss: 0.1781603991985321
[32m[0511 06:56:10 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.18011179566383362, Train Loss: 0.17815954983234406
[32m[0511 06:56:10 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.18011264503002167, Train Loss: 0.178158700466156
[32m[0511 06:56:10 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.1801135092973709, Train Loss: 0.17815785109996796
[32m[0511 06:56:10 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.18011434376239777, Train Loss: 0.1781570315361023
[32m[0511 06:56:10 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.180115208029747, Train Loss: 0.17815616726875305
[32m[0511 06:56:10 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.18011607229709625, Train Loss: 0.17815528810024261
[32m[0511 06:56:10 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.1801169365644455, Train Loss: 0.17815449833869934
[32m[0511 06:56:10 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.18011783063411713, Train Loss: 0.1781536489725113
[32m[0511 06:56:10 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.18011869490146637, Train Loss: 0.17815279960632324
[32m[0511 06:56:10 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.1801196187734604, Train Loss: 0.178151935338974
[32m[0511 06:56:10 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.18012049794197083, Train Loss: 0.17815111577510834
[32m[0511 06:56:10 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.18012139201164246, Train Loss: 0.17815031111240387
[32m[0511 06:56:10 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.1801222860813141, Train Loss: 0.17814946174621582
[32m[0511 06:56:11 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.1801232099533081, Train Loss: 0.17814859747886658
[32m[0511 06:56:11 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.18012410402297974, Train Loss: 0.17814777791500092
[32m[0511 06:56:11 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.18012502789497375, Train Loss: 0.17814694344997406
[32m[0511 06:56:11 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.18012596666812897, Train Loss: 0.178146094083786
[32m[0511 06:56:11 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.1801268756389618, Train Loss: 0.17814527451992035
[32m[0511 06:56:11 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.180127814412117, Train Loss: 0.1781444400548935
[32m[0511 06:56:11 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.18012873828411102, Train Loss: 0.17814359068870544
[32m[0511 06:56:11 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.18012967705726624, Train Loss: 0.17814278602600098
[32m[0511 06:56:11 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.18013061583042145, Train Loss: 0.17814193665981293
[32m[0511 06:56:11 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.18013156950473785, Train Loss: 0.17814113199710846
[32m[0511 06:56:11 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.18013250827789307, Train Loss: 0.1781402975320816
[32m[0511 06:56:11 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.18013346195220947, Train Loss: 0.17813946306705475
[32m[0511 06:56:11 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.18013443052768707, Train Loss: 0.1781386286020279
[32m[0511 06:56:11 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.18013541400432587, Train Loss: 0.17813780903816223
[32m[0511 06:56:11 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.18013636767864227, Train Loss: 0.17813698947429657
[32m[0511 06:56:11 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.18013733625411987, Train Loss: 0.17813614010810852
[32m[0511 06:56:11 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.18013830482959747, Train Loss: 0.17813533544540405
[32m[0511 06:56:11 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.18013927340507507, Train Loss: 0.1781344711780548
[32m[0511 06:56:11 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.18014025688171387, Train Loss: 0.17813368141651154
[32m[0511 06:56:11 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.18014124035835266, Train Loss: 0.17813284695148468
[32m[0511 06:56:11 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.18014220893383026, Train Loss: 0.17813202738761902
[32m[0511 06:56:11 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.18014319241046906, Train Loss: 0.17813117802143097
[32m[0511 06:56:11 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.18014419078826904, Train Loss: 0.1781303584575653
[32m[0511 06:56:11 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.18014518916606903, Train Loss: 0.17812952399253845
[32m[0511 06:56:11 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.18014617264270782, Train Loss: 0.1781287044286728
[32m[0511 06:56:11 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.18014715611934662, Train Loss: 0.17812786996364594
[32m[0511 06:56:11 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.1801481693983078, Train Loss: 0.17812705039978027
[32m[0511 06:56:11 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.1801491528749466, Train Loss: 0.1781262308359146
[32m[0511 06:56:11 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.18015015125274658, Train Loss: 0.17812539637088776
[32m[0511 06:56:12 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.18015114963054657, Train Loss: 0.1781245768070221
[32m[0511 06:56:12 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.18015219271183014, Train Loss: 0.17812374234199524
[32m[0511 06:56:12 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.18015320599079132, Train Loss: 0.17812292277812958
[32m[0511 06:56:12 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.1801542043685913, Train Loss: 0.17812208831310272
[32m[0511 06:56:12 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.1801552027463913, Train Loss: 0.17812126874923706
[32m[0511 06:56:12 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.18015620112419128, Train Loss: 0.178120419383049
[32m[0511 06:56:12 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.18015725910663605, Train Loss: 0.17811961472034454
[32m[0511 06:56:12 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.18015824258327484, Train Loss: 0.1781187504529953
[32m[0511 06:56:12 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.1801592856645584, Train Loss: 0.17811794579029083
[32m[0511 06:56:12 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.1801602989435196, Train Loss: 0.1781170815229416
[32m[0511 06:56:12 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.18016129732131958, Train Loss: 0.17811626195907593
[32m[0511 06:56:12 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.18016231060028076, Train Loss: 0.17811542749404907
[32m[0511 06:56:12 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.18016333878040314, Train Loss: 0.1781146228313446
[32m[0511 06:56:12 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.1801643818616867, Train Loss: 0.17811377346515656
[32m[0511 06:56:12 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.18016542494297028, Train Loss: 0.1781129539012909
[32m[0511 06:56:12 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.18016645312309265, Train Loss: 0.17811210453510284
[32m[0511 06:56:12 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.18016746640205383, Train Loss: 0.17811129987239838
[32m[0511 06:56:12 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.18016847968101501, Train Loss: 0.17811045050621033
[32m[0511 06:56:12 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.18016952276229858, Train Loss: 0.17810963094234467
[32m[0511 06:56:12 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.18017055094242096, Train Loss: 0.17810876667499542
[32m[0511 06:56:12 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.18017159402370453, Train Loss: 0.17810796201229095
[32m[0511 06:56:12 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.1801726073026657, Train Loss: 0.1781071126461029
[32m[0511 06:56:12 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.18017363548278809, Train Loss: 0.17810626327991486
[32m[0511 06:56:12 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.18017467856407166, Train Loss: 0.1781054437160492
[32m[0511 06:56:12 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.18017570674419403, Train Loss: 0.17810460925102234
[32m[0511 06:56:12 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.1801767498254776, Train Loss: 0.17810377478599548
[32m[0511 06:56:12 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.18017777800559998, Train Loss: 0.17810294032096863
[32m[0511 06:56:12 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.18017882108688354, Train Loss: 0.17810209095478058
[32m[0511 06:56:12 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.18017983436584473, Train Loss: 0.17810125648975372
[32m[0511 06:56:13 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.1801808923482895, Train Loss: 0.17810040712356567
[32m[0511 06:56:13 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.18018192052841187, Train Loss: 0.17809957265853882
[32m[0511 06:56:13 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.18018296360969543, Train Loss: 0.17809872329235077
[32m[0511 06:56:13 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.1801839917898178, Train Loss: 0.1780978888273239
[32m[0511 06:56:13 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.18018503487110138, Train Loss: 0.17809702455997467
[32m[0511 06:56:13 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.18018604815006256, Train Loss: 0.17809619009494781
[32m[0511 06:56:13 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.18018709123134613, Train Loss: 0.17809534072875977
[32m[0511 06:56:13 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.1801881194114685, Train Loss: 0.1780945211648941
[32m[0511 06:56:13 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.18018916249275208, Train Loss: 0.17809365689754486
[32m[0511 06:56:13 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.18019019067287445, Train Loss: 0.17809279263019562
[32m[0511 06:56:13 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.18019123375415802, Train Loss: 0.17809195816516876
[32m[0511 06:56:13 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.1801922619342804, Train Loss: 0.1780911087989807
[32m[0511 06:56:13 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.18019333481788635, Train Loss: 0.17809027433395386
[32m[0511 06:56:13 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.18019433319568634, Train Loss: 0.17808941006660461
[32m[0511 06:56:13 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.18019536137580872, Train Loss: 0.17808857560157776
[32m[0511 06:56:13 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.18019640445709229, Train Loss: 0.17808771133422852
[32m[0511 06:56:13 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.18019744753837585, Train Loss: 0.17808686196804047
[32m[0511 06:56:13 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.18019844591617584, Train Loss: 0.17808601260185242
[32m[0511 06:56:13 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.1801995038986206, Train Loss: 0.17808516323566437
[32m[0511 06:56:13 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.1802005171775818, Train Loss: 0.17808428406715393
[32m[0511 06:56:13 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.18020154535770416, Train Loss: 0.1780834197998047
[32m[0511 06:56:13 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.18020257353782654, Train Loss: 0.17808257043361664
[32m[0511 06:56:13 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.1802036017179489, Train Loss: 0.1780817061662674
[32m[0511 06:56:13 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.1802046298980713, Train Loss: 0.17808085680007935
[32m[0511 06:56:13 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.18020567297935486, Train Loss: 0.1780800223350525
[32m[0511 06:56:13 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.18020667135715485, Train Loss: 0.17807912826538086
[32m[0511 06:56:13 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.18020771443843842, Train Loss: 0.17807826399803162
[32m[0511 06:56:13 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.1802087277173996, Train Loss: 0.17807741463184357
[32m[0511 06:56:13 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.18020975589752197, Train Loss: 0.17807656526565552
[32m[0511 06:56:14 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.18021078407764435, Train Loss: 0.17807571589946747
[32m[0511 06:56:14 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.18021178245544434, Train Loss: 0.17807482182979584
[32m[0511 06:56:14 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.1802128255367279, Train Loss: 0.1780739724636078
[32m[0511 06:56:14 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.1802138388156891, Train Loss: 0.17807312309741974
[32m[0511 06:56:14 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.18021482229232788, Train Loss: 0.1780722290277481
[32m[0511 06:56:14 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.18021586537361145, Train Loss: 0.17807136476039886
[32m[0511 06:56:14 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.18021686375141144, Train Loss: 0.17807050049304962
[32m[0511 06:56:14 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.18021787703037262, Train Loss: 0.178069606423378
[32m[0511 06:56:14 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.180218905210495, Train Loss: 0.17806877195835114
[32m[0511 06:56:14 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.18021990358829498, Train Loss: 0.1780678778886795
[32m[0511 06:56:14 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.18022091686725616, Train Loss: 0.17806701362133026
[32m[0511 06:56:14 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.18022191524505615, Train Loss: 0.17806610465049744
[32m[0511 06:56:14 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.18022292852401733, Train Loss: 0.17806527018547058
[32m[0511 06:56:14 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.18022392690181732, Train Loss: 0.17806437611579895
[32m[0511 06:56:14 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.1802249252796173, Train Loss: 0.17806348204612732
[32m[0511 06:56:14 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.1802259236574173, Train Loss: 0.17806263267993927
[32m[0511 06:56:14 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.18022693693637848, Train Loss: 0.17806175351142883
[32m[0511 06:56:14 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.18022795021533966, Train Loss: 0.1780608594417572
[32m[0511 06:56:14 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.18022893369197845, Train Loss: 0.17805999517440796
[32m[0511 06:56:14 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.18022993206977844, Train Loss: 0.17805911600589752
[32m[0511 06:56:14 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.18023091554641724, Train Loss: 0.17805823683738708
[32m[0511 06:56:14 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.18023189902305603, Train Loss: 0.17805735766887665
[32m[0511 06:56:14 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.18023289740085602, Train Loss: 0.17805646359920502
[32m[0511 06:56:14 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.1802338808774948, Train Loss: 0.17805558443069458
[32m[0511 06:56:14 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.1802348494529724, Train Loss: 0.17805470526218414
[32m[0511 06:56:14 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.1802358478307724, Train Loss: 0.1780538260936737
[32m[0511 06:56:14 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.1802368313074112, Train Loss: 0.17805291712284088
[32m[0511 06:56:14 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.1802377998828888, Train Loss: 0.17805205285549164
[32m[0511 06:56:14 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.1802387833595276, Train Loss: 0.17805115878582
[32m[0511 06:56:14 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.18023976683616638, Train Loss: 0.17805024981498718
[32m[0511 06:56:15 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.18024073541164398, Train Loss: 0.17804937064647675
[32m[0511 06:56:15 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.18024171888828278, Train Loss: 0.1780485063791275
[32m[0511 06:56:15 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.18024268746376038, Train Loss: 0.17804759740829468
[32m[0511 06:56:15 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.18024365603923798, Train Loss: 0.17804670333862305
[32m[0511 06:56:15 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.18024462461471558, Train Loss: 0.17804580926895142
[32m[0511 06:56:15 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.18024560809135437, Train Loss: 0.17804494500160217
[32m[0511 06:56:15 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.18024656176567078, Train Loss: 0.17804403603076935
[32m[0511 06:56:15 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.18024751543998718, Train Loss: 0.17804314196109772
[32m[0511 06:56:15 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.18024848401546478, Train Loss: 0.1780422329902649
[32m[0511 06:56:15 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.18024945259094238, Train Loss: 0.17804132401943207
[32m[0511 06:56:15 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.18025042116641998, Train Loss: 0.17804045975208282
[32m[0511 06:56:15 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.1802513748407364, Train Loss: 0.1780395656824112
[32m[0511 06:56:15 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.1802523136138916, Train Loss: 0.17803865671157837
[32m[0511 06:56:15 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.180253267288208, Train Loss: 0.17803774774074554
[32m[0511 06:56:15 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.18025422096252441, Train Loss: 0.1780368536710739
[32m[0511 06:56:15 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.18025515973567963, Train Loss: 0.17803595960140228
[32m[0511 06:56:15 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.18025611340999603, Train Loss: 0.17803506553173065
[32m[0511 06:56:15 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.18025705218315125, Train Loss: 0.17803414165973663
[32m[0511 06:56:15 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.18025799095630646, Train Loss: 0.1780332773923874
[32m[0511 06:56:15 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.18025894463062286, Train Loss: 0.17803238332271576
[32m[0511 06:56:15 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.18025988340377808, Train Loss: 0.17803147435188293
[32m[0511 06:56:15 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.1802608221769333, Train Loss: 0.1780305653810501
[32m[0511 06:56:15 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.1802617609500885, Train Loss: 0.1780296415090561
[32m[0511 06:56:15 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.18026268482208252, Train Loss: 0.17802874743938446
[32m[0511 06:56:15 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.18026362359523773, Train Loss: 0.17802786827087402
[32m[0511 06:56:15 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.18026456236839294, Train Loss: 0.17802694439888
[32m[0511 06:56:15 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.18026548624038696, Train Loss: 0.17802603542804718
[32m[0511 06:56:15 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.18026642501354218, Train Loss: 0.17802515625953674
[32m[0511 06:56:15 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.1802673488855362, Train Loss: 0.17802424728870392
[32m[0511 06:56:16 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.1802682727575302, Train Loss: 0.1780233383178711
[32m[0511 06:56:16 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.18026918172836304, Train Loss: 0.17802242934703827
[32m[0511 06:56:16 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.18027010560035706, Train Loss: 0.17802150547504425
[32m[0511 06:56:16 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.18027102947235107, Train Loss: 0.17802061140537262
[32m[0511 06:56:16 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.1802719384431839, Train Loss: 0.1780197024345398
[32m[0511 06:56:16 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.18027286231517792, Train Loss: 0.17801880836486816
[32m[0511 06:56:16 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.18027377128601074, Train Loss: 0.17801789939403534
[32m[0511 06:56:16 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.18027468025684357, Train Loss: 0.17801699042320251
[32m[0511 06:56:16 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.18027560412883759, Train Loss: 0.17801611125469208
[32m[0511 06:56:16 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.1802765130996704, Train Loss: 0.17801517248153687
[32m[0511 06:56:16 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.18027743697166443, Train Loss: 0.17801424860954285
[32m[0511 06:56:16 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.18027833104133606, Train Loss: 0.17801335453987122
[32m[0511 06:56:16 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.1802792102098465, Train Loss: 0.1780124455690384
[32m[0511 06:56:16 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.18028011918067932, Train Loss: 0.17801155149936676
[32m[0511 06:56:16 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.18028102815151215, Train Loss: 0.17801064252853394
[32m[0511 06:56:16 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.18028193712234497, Train Loss: 0.17800971865653992
[32m[0511 06:56:16 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.1802828460931778, Train Loss: 0.1780088245868683
[32m[0511 06:56:16 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.18028375506401062, Train Loss: 0.17800788581371307
[32m[0511 06:56:16 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.18028461933135986, Train Loss: 0.17800697684288025
[32m[0511 06:56:16 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.1802855283021927, Train Loss: 0.1780060976743698
[32m[0511 06:56:16 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.18028640747070312, Train Loss: 0.178005188703537
[32m[0511 06:56:16 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.18028731644153595, Train Loss: 0.17800426483154297
[32m[0511 06:56:16 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.1802881956100464, Train Loss: 0.17800335586071014
[32m[0511 06:56:16 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.18028908967971802, Train Loss: 0.17800243198871613
[32m[0511 06:56:16 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.18028996884822845, Train Loss: 0.1780015379190445
[32m[0511 06:56:16 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.18029087781906128, Train Loss: 0.17800062894821167
[32m[0511 06:56:16 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.18029174208641052, Train Loss: 0.17799971997737885
[32m[0511 06:56:16 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.18029263615608215, Train Loss: 0.17799882590770721
[32m[0511 06:56:16 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.1802935153245926, Train Loss: 0.1779979020357132
[32m[0511 06:56:16 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.18029437959194183, Train Loss: 0.17799697816371918
[32m[0511 06:56:17 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.18029530346393585, Train Loss: 0.17799606919288635
[32m[0511 06:56:17 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.1802961826324463, Train Loss: 0.17799516022205353
[32m[0511 06:56:17 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.18029704689979553, Train Loss: 0.1779942512512207
[32m[0511 06:56:17 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.18029792606830597, Train Loss: 0.17799332737922668
[32m[0511 06:56:17 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.1802988052368164, Train Loss: 0.17799243330955505
[32m[0511 06:56:17 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.18029966950416565, Train Loss: 0.17799152433872223
[32m[0511 06:56:17 @mbmf_sampler.py:98][0m Finished 9th episode
[32m[0511 06:56:17 @mbmf_sampler.py:102][0m 1809 timesteps from 9 episodes collected
[32m[0511 07:15:15 @mbmf_trainer.py:160][0m Mean reward: -1281.547210783919
[32m[0511 07:15:16 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.18407107889652252, Train Loss: 0.17367443442344666
[32m[0511 07:15:16 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.1841539740562439, Train Loss: 0.17365030944347382
[32m[0511 07:15:16 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.18420995771884918, Train Loss: 0.173629030585289
[32m[0511 07:15:16 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.18424493074417114, Train Loss: 0.17361561954021454
[32m[0511 07:15:16 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.18427743017673492, Train Loss: 0.17360486090183258
[32m[0511 07:15:16 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.18430843949317932, Train Loss: 0.1735958606004715
[32m[0511 07:15:16 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.18433789908885956, Train Loss: 0.1735881268978119
[32m[0511 07:15:16 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.18436536192893982, Train Loss: 0.1735813170671463
[32m[0511 07:15:16 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.18439067900180817, Train Loss: 0.17357532680034637
[32m[0511 07:15:16 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.18441399931907654, Train Loss: 0.17357002198696136
[32m[0511 07:15:16 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.18443554639816284, Train Loss: 0.17356526851654053
[32m[0511 07:15:16 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.18445545434951782, Train Loss: 0.1735609620809555
[32m[0511 07:15:16 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.18447378277778625, Train Loss: 0.17355705797672272
[32m[0511 07:15:16 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.18449074029922485, Train Loss: 0.173553466796875
[32m[0511 07:15:16 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.18450641632080078, Train Loss: 0.17355015873908997
[32m[0511 07:15:16 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.1845209002494812, Train Loss: 0.17354707419872284
[32m[0511 07:15:16 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.18453428149223328, Train Loss: 0.17354421317577362
[32m[0511 07:15:16 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.18454667925834656, Train Loss: 0.17354150116443634
[32m[0511 07:15:16 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.18455816805362701, Train Loss: 0.173538938164711
[32m[0511 07:15:16 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.18456879258155823, Train Loss: 0.1735364943742752
[32m[0511 07:15:16 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.18457868695259094, Train Loss: 0.17353415489196777
[32m[0511 07:15:16 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.18458783626556396, Train Loss: 0.1735319197177887
[32m[0511 07:15:16 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.18459632992744446, Train Loss: 0.1735297441482544
[32m[0511 07:15:17 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.18460425734519958, Train Loss: 0.17352768778800964
[32m[0511 07:15:17 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.18461160361766815, Train Loss: 0.17352569103240967
[32m[0511 07:15:17 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.18461847305297852, Train Loss: 0.17352372407913208
[32m[0511 07:15:17 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.18462488055229187, Train Loss: 0.17352180182933807
[32m[0511 07:15:17 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.1846308559179306, Train Loss: 0.17351993918418884
[32m[0511 07:15:17 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.1846364438533783, Train Loss: 0.1735181361436844
[32m[0511 07:15:17 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.18464165925979614, Train Loss: 0.17351633310317993
[32m[0511 07:15:17 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.18464656174182892, Train Loss: 0.17351460456848145
[32m[0511 07:15:17 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.18465115129947662, Train Loss: 0.17351289093494415
[32m[0511 07:15:17 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.18465544283390045, Train Loss: 0.17351120710372925
[32m[0511 07:15:17 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.18465951085090637, Train Loss: 0.17350952327251434
[32m[0511 07:15:17 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.1846633404493332, Train Loss: 0.1735078990459442
[32m[0511 07:15:17 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.18466691672801971, Train Loss: 0.1735062599182129
[32m[0511 07:15:17 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.1846703141927719, Train Loss: 0.17350468039512634
[32m[0511 07:15:17 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.18467353284358978, Train Loss: 0.173503115773201
[32m[0511 07:15:17 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.18467657268047333, Train Loss: 0.17350153625011444
[32m[0511 07:15:17 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.18467943370342255, Train Loss: 0.17350000143051147
[32m[0511 07:15:17 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.18468216061592102, Train Loss: 0.1734984815120697
[32m[0511 07:15:17 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.18468476831912994, Train Loss: 0.17349697649478912
[32m[0511 07:15:17 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.18468722701072693, Train Loss: 0.17349548637866974
[32m[0511 07:15:17 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.18468959629535675, Train Loss: 0.17349398136138916
[32m[0511 07:15:17 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.18469184637069702, Train Loss: 0.17349255084991455
[32m[0511 07:15:17 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.18469397723674774, Train Loss: 0.17349106073379517
[32m[0511 07:15:17 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.1846960335969925, Train Loss: 0.17348963022232056
[32m[0511 07:15:18 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.18469800055027008, Train Loss: 0.17348818480968475
[32m[0511 07:15:18 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.1846998929977417, Train Loss: 0.17348678410053253
[32m[0511 07:15:18 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.18470172584056854, Train Loss: 0.17348535358905792
[32m[0511 07:15:18 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.18470345437526703, Train Loss: 0.1734839677810669
[32m[0511 07:15:18 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.18470515310764313, Train Loss: 0.17348255217075348
[32m[0511 07:15:18 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.18470674753189087, Train Loss: 0.17348118126392365
[32m[0511 07:15:18 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.1847083419561386, Train Loss: 0.1734798103570938
[32m[0511 07:15:18 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.1847098469734192, Train Loss: 0.17347845435142517
[32m[0511 07:15:18 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.18471135199069977, Train Loss: 0.17347705364227295
[32m[0511 07:15:18 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.184712752699852, Train Loss: 0.1734757274389267
[32m[0511 07:15:18 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.1847141534090042, Train Loss: 0.17347437143325806
[32m[0511 07:15:18 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.18471549451351166, Train Loss: 0.173473060131073
[32m[0511 07:15:18 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.1847168207168579, Train Loss: 0.17347173392772675
[32m[0511 07:15:18 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.18471810221672058, Train Loss: 0.1734704077243805
[32m[0511 07:15:18 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.18471935391426086, Train Loss: 0.17346908152103424
[32m[0511 07:15:18 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.18472057580947876, Train Loss: 0.17346777021884918
[32m[0511 07:15:18 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.18472178280353546, Train Loss: 0.17346645891666412
[32m[0511 07:15:18 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.18472295999526978, Train Loss: 0.17346517741680145
[32m[0511 07:15:18 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.1847241073846817, Train Loss: 0.1734638810157776
[32m[0511 07:15:18 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.18472523987293243, Train Loss: 0.17346259951591492
[32m[0511 07:15:18 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.18472632765769958, Train Loss: 0.17346131801605225
[32m[0511 07:15:18 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.18472744524478912, Train Loss: 0.17346003651618958
[32m[0511 07:15:18 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.1847284883260727, Train Loss: 0.1734587699174881
[32m[0511 07:15:19 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.18472956120967865, Train Loss: 0.17345751821994781
[32m[0511 07:15:19 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.18473058938980103, Train Loss: 0.17345625162124634
[32m[0511 07:15:19 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.1847316324710846, Train Loss: 0.17345501482486725
[32m[0511 07:15:19 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.18473263084888458, Train Loss: 0.17345376312732697
[32m[0511 07:15:19 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.18473362922668457, Train Loss: 0.17345251142978668
[32m[0511 07:15:19 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.18473461270332336, Train Loss: 0.1734512597322464
[32m[0511 07:15:19 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.18473561108112335, Train Loss: 0.1734500378370285
[32m[0511 07:15:19 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.18473657965660095, Train Loss: 0.17344880104064941
[32m[0511 07:15:19 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.18473754823207855, Train Loss: 0.1734475940465927
[32m[0511 07:15:19 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.18473851680755615, Train Loss: 0.173446387052536
[32m[0511 07:15:19 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.18473945558071136, Train Loss: 0.17344515025615692
[32m[0511 07:15:19 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.18474037945270538, Train Loss: 0.1734439581632614
[32m[0511 07:15:19 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.1847413182258606, Train Loss: 0.17344272136688232
[32m[0511 07:15:19 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.18474224209785461, Train Loss: 0.17344152927398682
[32m[0511 07:15:19 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.18474316596984863, Train Loss: 0.1734403371810913
[32m[0511 07:15:19 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.18474407494068146, Train Loss: 0.1734391450881958
[32m[0511 07:15:19 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.18474498391151428, Train Loss: 0.1734379529953003
[32m[0511 07:15:19 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.1847458779811859, Train Loss: 0.1734367460012436
[32m[0511 07:15:19 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.18474681675434113, Train Loss: 0.17343556880950928
[32m[0511 07:15:19 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.18474768102169037, Train Loss: 0.17343437671661377
[32m[0511 07:15:19 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.1847485899925232, Train Loss: 0.17343321442604065
[32m[0511 07:15:19 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.18474946916103363, Train Loss: 0.17343205213546753
[32m[0511 07:15:19 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.18475034832954407, Train Loss: 0.17343086004257202
[32m[0511 07:15:20 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.1847512423992157, Train Loss: 0.1734296828508377
[32m[0511 07:15:20 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.18475212156772614, Train Loss: 0.17342853546142578
[32m[0511 07:15:20 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.18475300073623657, Train Loss: 0.17342737317085266
[32m[0511 07:15:20 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.18475386500358582, Train Loss: 0.17342621088027954
[32m[0511 07:15:20 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.18475474417209625, Train Loss: 0.17342506349086761
[32m[0511 07:15:20 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.1847556233406067, Train Loss: 0.1734238862991333
[32m[0511 07:15:20 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.18475648760795593, Train Loss: 0.17342275381088257
[32m[0511 07:15:20 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.18475735187530518, Train Loss: 0.17342160642147064
[32m[0511 07:15:20 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.1847582310438156, Train Loss: 0.1734204739332199
[32m[0511 07:15:20 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.18475909531116486, Train Loss: 0.17341934144496918
[32m[0511 07:15:20 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.1847599595785141, Train Loss: 0.17341819405555725
[32m[0511 07:15:20 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.18476083874702454, Train Loss: 0.17341706156730652
[32m[0511 07:15:20 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.18476171791553497, Train Loss: 0.17341594398021698
[32m[0511 07:15:20 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.18476256728172302, Train Loss: 0.17341481149196625
[32m[0511 07:15:20 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.18476343154907227, Train Loss: 0.17341367900371552
[32m[0511 07:15:20 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.1847643256187439, Train Loss: 0.17341256141662598
[32m[0511 07:15:20 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.18476516008377075, Train Loss: 0.17341142892837524
[32m[0511 07:15:20 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.1847660392522812, Train Loss: 0.1734103262424469
[32m[0511 07:15:20 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.18476690351963043, Train Loss: 0.17340920865535736
[32m[0511 07:15:20 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.18476776778697968, Train Loss: 0.17340807616710663
[32m[0511 07:15:20 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.18476863205432892, Train Loss: 0.17340697348117828
[32m[0511 07:15:20 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.18476951122283936, Train Loss: 0.17340585589408875
[32m[0511 07:15:20 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.1847703605890274, Train Loss: 0.1734047681093216
[32m[0511 07:15:21 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.18477125465869904, Train Loss: 0.17340366542339325
[32m[0511 07:15:21 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.18477211892604828, Train Loss: 0.1734025627374649
[32m[0511 07:15:21 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.18477298319339752, Train Loss: 0.17340147495269775
[32m[0511 07:15:21 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.18477386236190796, Train Loss: 0.17340035736560822
[32m[0511 07:15:21 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.1847747415304184, Train Loss: 0.17339926958084106
[32m[0511 07:15:21 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.18477559089660645, Train Loss: 0.1733981966972351
[32m[0511 07:15:21 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.18477649986743927, Train Loss: 0.17339710891246796
[32m[0511 07:15:21 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.18477733433246613, Train Loss: 0.1733960211277008
[32m[0511 07:15:21 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.18477822840213776, Train Loss: 0.17339494824409485
[32m[0511 07:15:21 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.1847791075706482, Train Loss: 0.1733938455581665
[32m[0511 07:15:21 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.18477998673915863, Train Loss: 0.17339277267456055
[32m[0511 07:15:21 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.18478085100650787, Train Loss: 0.1733916997909546
[32m[0511 07:15:21 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.1847817599773407, Train Loss: 0.17339061200618744
[32m[0511 07:15:21 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.18478262424468994, Train Loss: 0.17338955402374268
[32m[0511 07:15:21 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.18478350341320038, Train Loss: 0.17338846623897552
[32m[0511 07:15:21 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.184784397482872, Train Loss: 0.17338742315769196
[32m[0511 07:15:21 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.18478526175022125, Train Loss: 0.173386350274086
[32m[0511 07:15:21 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.18478615581989288, Train Loss: 0.17338529229164124
[32m[0511 07:15:21 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.1847870647907257, Train Loss: 0.17338421940803528
[32m[0511 07:15:21 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.18478792905807495, Train Loss: 0.17338316142559052
[32m[0511 07:15:21 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.18478883802890778, Train Loss: 0.17338211834430695
[32m[0511 07:15:21 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.1847897171974182, Train Loss: 0.173381045460701
[32m[0511 07:15:21 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.18479062616825104, Train Loss: 0.1733800172805786
[32m[0511 07:15:21 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.18479152023792267, Train Loss: 0.17337894439697266
[32m[0511 07:15:22 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.1847923994064331, Train Loss: 0.17337791621685028
[32m[0511 07:15:22 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.18479329347610474, Train Loss: 0.17337684333324432
[32m[0511 07:15:22 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.18479418754577637, Train Loss: 0.17337580025196075
[32m[0511 07:15:22 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.1847950965166092, Train Loss: 0.17337477207183838
[32m[0511 07:15:22 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.18479599058628082, Train Loss: 0.1733737289905548
[32m[0511 07:15:22 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.18479688465595245, Train Loss: 0.17337270081043243
[32m[0511 07:15:22 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.18479779362678528, Train Loss: 0.17337167263031006
[32m[0511 07:15:22 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.1847986876964569, Train Loss: 0.1733706146478653
[32m[0511 07:15:22 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.18479961156845093, Train Loss: 0.17336958646774292
[32m[0511 07:15:22 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.18480050563812256, Train Loss: 0.17336855828762054
[32m[0511 07:15:22 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.18480141460895538, Train Loss: 0.17336753010749817
[32m[0511 07:15:22 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.1848023384809494, Train Loss: 0.1733664870262146
[32m[0511 07:15:22 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.18480326235294342, Train Loss: 0.17336547374725342
[32m[0511 07:15:22 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.18480415642261505, Train Loss: 0.17336444556713104
[32m[0511 07:15:22 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.18480508029460907, Train Loss: 0.17336344718933105
[32m[0511 07:15:22 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.1848059892654419, Train Loss: 0.1733623892068863
[32m[0511 07:15:22 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.18480688333511353, Train Loss: 0.1733613759279251
[32m[0511 07:15:22 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.18480782210826874, Train Loss: 0.17336039245128632
[32m[0511 07:15:22 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.18480871617794037, Train Loss: 0.17335934937000275
[32m[0511 07:15:22 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.18480965495109558, Train Loss: 0.17335836589336395
[32m[0511 07:15:22 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.1848105490207672, Train Loss: 0.17335732281208038
[32m[0511 07:15:22 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.18481148779392242, Train Loss: 0.1733563095331192
[32m[0511 07:15:23 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.18481241166591644, Train Loss: 0.17335529625415802
[32m[0511 07:15:23 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.18481333553791046, Train Loss: 0.17335431277751923
[32m[0511 07:15:23 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.18481425940990448, Train Loss: 0.17335331439971924
[32m[0511 07:15:23 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.1848151683807373, Train Loss: 0.17335231602191925
[32m[0511 07:15:23 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.18481610715389252, Train Loss: 0.17335130274295807
[32m[0511 07:15:23 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.18481703102588654, Train Loss: 0.17335030436515808
[32m[0511 07:15:23 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.18481795489788055, Train Loss: 0.1733493208885193
[32m[0511 07:15:23 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.18481889367103577, Train Loss: 0.1733483076095581
[32m[0511 07:15:23 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.18481983244419098, Train Loss: 0.17334730923175812
[32m[0511 07:15:23 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.184820756316185, Train Loss: 0.17334632575511932
[32m[0511 07:15:23 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.18482168018817902, Train Loss: 0.17334534227848053
[32m[0511 07:15:23 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.18482263386249542, Train Loss: 0.17334434390068054
[32m[0511 07:15:23 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.18482355773448944, Train Loss: 0.17334337532520294
[32m[0511 07:15:23 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.18482446670532227, Train Loss: 0.17334236204624176
[32m[0511 07:15:23 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.18482540547847748, Train Loss: 0.17334139347076416
[32m[0511 07:15:23 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.1848263442516327, Train Loss: 0.17334040999412537
[32m[0511 07:15:23 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.1848272830247879, Train Loss: 0.17333942651748657
[32m[0511 07:15:23 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.18482820689678192, Train Loss: 0.17333845794200897
[32m[0511 07:15:23 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.18482916057109833, Train Loss: 0.17333748936653137
[32m[0511 07:15:23 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.18483009934425354, Train Loss: 0.17333649098873138
[32m[0511 07:15:23 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.18483102321624756, Train Loss: 0.1733355075120926
[32m[0511 07:15:23 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.18483196198940277, Train Loss: 0.173334538936615
[32m[0511 07:15:23 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.18483291566371918, Train Loss: 0.1733335703611374
[32m[0511 07:15:24 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.1848338395357132, Train Loss: 0.1733326017856598
[32m[0511 07:15:24 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.1848347783088684, Train Loss: 0.173331618309021
[32m[0511 07:15:24 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.18483573198318481, Train Loss: 0.1733306646347046
[32m[0511 07:15:24 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.18483667075634003, Train Loss: 0.17332971096038818
[32m[0511 07:15:24 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.18483760952949524, Train Loss: 0.17332874238491058
[32m[0511 07:15:24 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.18483854830265045, Train Loss: 0.17332777380943298
[32m[0511 07:15:24 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.18483948707580566, Train Loss: 0.17332683503627777
[32m[0511 07:15:24 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.18484042584896088, Train Loss: 0.17332585155963898
[32m[0511 07:15:24 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.1848413497209549, Train Loss: 0.17332488298416138
[32m[0511 07:15:24 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.1848423033952713, Train Loss: 0.17332392930984497
[32m[0511 07:15:24 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.1848432570695877, Train Loss: 0.17332297563552856
[32m[0511 07:15:24 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.1848442107439041, Train Loss: 0.17332203686237335
[32m[0511 07:15:24 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.18484513461589813, Train Loss: 0.17332109808921814
[32m[0511 07:15:24 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.18484608829021454, Train Loss: 0.17332012951374054
[32m[0511 07:15:24 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.18484701216220856, Train Loss: 0.17331917583942413
[32m[0511 07:15:24 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.18484796583652496, Train Loss: 0.17331825196743011
[32m[0511 07:15:24 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.18484888970851898, Train Loss: 0.1733172982931137
[32m[0511 07:15:24 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.1848498433828354, Train Loss: 0.1733163446187973
[32m[0511 07:15:24 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.1848507672548294, Train Loss: 0.1733154058456421
[32m[0511 07:15:24 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.1848517209291458, Train Loss: 0.17331445217132568
[32m[0511 07:15:24 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.18485265970230103, Train Loss: 0.17331352829933167
[32m[0511 07:15:24 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.18485359847545624, Train Loss: 0.17331258952617645
[32m[0511 07:15:24 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.18485452234745026, Train Loss: 0.17331163585186005
[32m[0511 07:15:25 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.18485549092292786, Train Loss: 0.17331069707870483
[32m[0511 07:15:25 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.18485641479492188, Train Loss: 0.17330977320671082
[32m[0511 07:15:25 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.1848573535680771, Train Loss: 0.1733088344335556
[32m[0511 07:15:25 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.1848582774400711, Train Loss: 0.17330791056156158
[32m[0511 07:15:25 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.1848592460155487, Train Loss: 0.17330697178840637
[32m[0511 07:15:25 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.18486015498638153, Train Loss: 0.17330604791641235
[32m[0511 07:15:25 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.18486109375953674, Train Loss: 0.17330512404441833
[32m[0511 07:15:25 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.18486203253269196, Train Loss: 0.17330420017242432
[32m[0511 07:15:25 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.18486297130584717, Train Loss: 0.1733032763004303
[32m[0511 07:15:25 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.1848638951778412, Train Loss: 0.17330235242843628
[32m[0511 07:15:25 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.1848648339509964, Train Loss: 0.17330142855644226
[32m[0511 07:15:25 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.1848657727241516, Train Loss: 0.17330051958560944
[32m[0511 07:15:25 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.18486669659614563, Train Loss: 0.17329959571361542
[32m[0511 07:15:25 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.18486762046813965, Train Loss: 0.1732986718416214
[32m[0511 07:15:25 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.18486854434013367, Train Loss: 0.17329776287078857
[32m[0511 07:15:25 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.18486948311328888, Train Loss: 0.17329685389995575
[32m[0511 07:15:25 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.18487043678760529, Train Loss: 0.17329593002796173
[32m[0511 07:15:25 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.18487133085727692, Train Loss: 0.1732950210571289
[32m[0511 07:15:25 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.18487225472927094, Train Loss: 0.1732940971851349
[32m[0511 07:15:25 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.18487317860126495, Train Loss: 0.17329318821430206
[32m[0511 07:15:25 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.18487411737442017, Train Loss: 0.17329227924346924
[32m[0511 07:15:25 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.184875026345253, Train Loss: 0.1732913851737976
[32m[0511 07:15:25 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.184875950217247, Train Loss: 0.1732904613018036
[32m[0511 07:15:25 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.18487687408924103, Train Loss: 0.17328956723213196
[32m[0511 07:15:26 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.18487778306007385, Train Loss: 0.17328865826129913
[32m[0511 07:15:26 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.18487869203090668, Train Loss: 0.1732877492904663
[32m[0511 07:15:26 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.1848796159029007, Train Loss: 0.17328685522079468
[32m[0511 07:15:26 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.18488053977489471, Train Loss: 0.17328597605228424
[32m[0511 07:15:26 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.18488144874572754, Train Loss: 0.17328506708145142
[32m[0511 07:15:26 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.18488237261772156, Train Loss: 0.17328417301177979
[32m[0511 07:15:26 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.18488328158855438, Train Loss: 0.17328327894210815
[32m[0511 07:15:26 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.1848841905593872, Train Loss: 0.17328235507011414
[32m[0511 07:15:26 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.18488508462905884, Train Loss: 0.1732814759016037
[32m[0511 07:15:26 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.18488599359989166, Train Loss: 0.17328059673309326
[32m[0511 07:15:26 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.1848868876695633, Train Loss: 0.17327970266342163
[32m[0511 07:15:26 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.1848878115415573, Train Loss: 0.1732788234949112
[32m[0511 07:15:26 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.18488867580890656, Train Loss: 0.17327791452407837
[32m[0511 07:15:26 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.18488959968090057, Train Loss: 0.17327703535556793
[32m[0511 07:15:26 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.184890478849411, Train Loss: 0.1732761561870575
[32m[0511 07:15:26 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.18489138782024384, Train Loss: 0.17327527701854706
[32m[0511 07:15:26 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.18489229679107666, Train Loss: 0.17327438294887543
[32m[0511 07:15:26 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.1848931610584259, Train Loss: 0.17327351868152618
[32m[0511 07:15:26 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.18489407002925873, Train Loss: 0.17327262461185455
[32m[0511 07:15:26 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.18489494919776917, Train Loss: 0.1732717603445053
[32m[0511 07:15:26 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.1848958283662796, Train Loss: 0.17327088117599487
[32m[0511 07:15:26 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.18489673733711243, Train Loss: 0.17327000200748444
[32m[0511 07:15:26 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.18489761650562286, Train Loss: 0.173269122838974
[32m[0511 07:15:26 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.1848984956741333, Train Loss: 0.17326822876930237
[32m[0511 07:15:27 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.18489935994148254, Train Loss: 0.17326736450195312
[32m[0511 07:15:27 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.18490023910999298, Train Loss: 0.17326650023460388
[32m[0511 07:15:27 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.1849011331796646, Train Loss: 0.17326562106609344
[32m[0511 07:15:27 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.18490201234817505, Train Loss: 0.1732647567987442
[32m[0511 07:15:27 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.1849028617143631, Train Loss: 0.17326389253139496
[32m[0511 07:15:27 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.18490374088287354, Train Loss: 0.17326302826404572
[32m[0511 07:15:27 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.18490460515022278, Train Loss: 0.17326216399669647
[32m[0511 07:15:27 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.18490546941757202, Train Loss: 0.17326128482818604
[32m[0511 07:15:27 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.18490631878376007, Train Loss: 0.1732604205608368
[32m[0511 07:15:27 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.1849071979522705, Train Loss: 0.17325955629348755
[32m[0511 07:15:27 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.18490806221961975, Train Loss: 0.1732587069272995
[32m[0511 07:15:27 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.1849089115858078, Train Loss: 0.17325787246227264
[32m[0511 07:15:27 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.18490976095199585, Train Loss: 0.1732569932937622
[32m[0511 07:15:27 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.1849106252193451, Train Loss: 0.17325614392757416
[32m[0511 07:15:27 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.18491145968437195, Train Loss: 0.17325527966022491
[32m[0511 07:15:27 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.1849123239517212, Train Loss: 0.17325443029403687
[32m[0511 07:15:27 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.18491314351558685, Train Loss: 0.17325358092784882
[32m[0511 07:15:27 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.1849140077829361, Train Loss: 0.17325271666049957
[32m[0511 07:15:27 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.18491484224796295, Train Loss: 0.17325185239315033
[32m[0511 07:15:27 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.1849156767129898, Train Loss: 0.17325103282928467
[32m[0511 07:15:27 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.18491652607917786, Train Loss: 0.17325016856193542
[32m[0511 07:15:27 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.1849173605442047, Train Loss: 0.17324930429458618
[32m[0511 07:15:27 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.18491816520690918, Train Loss: 0.17324846982955933
[32m[0511 07:15:28 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.18491901457309723, Train Loss: 0.17324763536453247
[32m[0511 07:15:28 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.1849198341369629, Train Loss: 0.17324678599834442
[32m[0511 07:15:28 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.18492063879966736, Train Loss: 0.17324595153331757
[32m[0511 07:15:28 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.18492145836353302, Train Loss: 0.17324510216712952
[32m[0511 07:15:28 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.18492230772972107, Train Loss: 0.17324426770210266
[32m[0511 07:15:28 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.18492309749126434, Train Loss: 0.1732434183359146
[32m[0511 07:15:28 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.1849239319562912, Train Loss: 0.17324258387088776
[32m[0511 07:15:28 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.18492473661899567, Train Loss: 0.1732417494058609
[32m[0511 07:15:28 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.18492554128170013, Train Loss: 0.17324091494083405
[32m[0511 07:15:28 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.1849263310432434, Train Loss: 0.17324009537696838
[32m[0511 07:15:28 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.18492715060710907, Train Loss: 0.17323927581310272
[32m[0511 07:15:28 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.18492795526981354, Train Loss: 0.17323842644691467
[32m[0511 07:15:28 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.18492873013019562, Train Loss: 0.173237606883049
[32m[0511 07:15:28 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.18492953479290009, Train Loss: 0.17323675751686096
[32m[0511 07:15:28 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.18493033945560455, Train Loss: 0.1732359379529953
[32m[0511 07:15:28 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.18493111431598663, Train Loss: 0.17323511838912964
[32m[0511 07:15:28 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.1849318891763687, Train Loss: 0.17323429882526398
[32m[0511 07:15:28 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.184932678937912, Train Loss: 0.17323346436023712
[32m[0511 07:15:28 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.18493346869945526, Train Loss: 0.17323264479637146
[32m[0511 07:15:28 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.18493424355983734, Train Loss: 0.1732318103313446
[32m[0511 07:15:28 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.18493501842021942, Train Loss: 0.17323099076747894
[32m[0511 07:15:29 @mbmf_sampler.py:98][0m Finished 9th episode
[32m[0511 07:15:29 @mbmf_sampler.py:102][0m 1809 timesteps from 9 episodes collected
[32m[0511 07:34:26 @mbmf_trainer.py:160][0m Mean reward: -1271.3028279798586
[32m[0511 07:34:26 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.16808368265628815, Train Loss: 0.17273567616939545
[32m[0511 07:34:26 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.16809897124767303, Train Loss: 0.17272759974002838
[32m[0511 07:34:26 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.16812294721603394, Train Loss: 0.1727156788110733
[32m[0511 07:34:26 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.16814880073070526, Train Loss: 0.17271006107330322
[32m[0511 07:34:26 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.16817551851272583, Train Loss: 0.17270411550998688
[32m[0511 07:34:26 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.16819973289966583, Train Loss: 0.17269891500473022
[32m[0511 07:34:27 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.16822166740894318, Train Loss: 0.17269429564476013
[32m[0511 07:34:27 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.16824200749397278, Train Loss: 0.17269004881381989
[32m[0511 07:34:27 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.16826093196868896, Train Loss: 0.17268617451190948
[32m[0511 07:34:27 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.16827861964702606, Train Loss: 0.17268258333206177
[32m[0511 07:34:27 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.16829517483711243, Train Loss: 0.17267921566963196
[32m[0511 07:34:27 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.1683107316493988, Train Loss: 0.17267608642578125
[32m[0511 07:34:27 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.16832537949085236, Train Loss: 0.17267316579818726
[32m[0511 07:34:27 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.16833922266960144, Train Loss: 0.172670379281044
[32m[0511 07:34:27 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.16835236549377441, Train Loss: 0.1726677566766739
[32m[0511 07:34:27 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.16836482286453247, Train Loss: 0.17266526818275452
[32m[0511 07:34:27 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.16837665438652039, Train Loss: 0.1726628839969635
[32m[0511 07:34:27 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.16838791966438293, Train Loss: 0.17266061902046204
[32m[0511 07:34:27 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.16839870810508728, Train Loss: 0.17265842854976654
[32m[0511 07:34:27 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.16840897500514984, Train Loss: 0.1726563423871994
[32m[0511 07:34:27 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.16841882467269897, Train Loss: 0.17265434563159943
[32m[0511 07:34:27 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.16842827200889587, Train Loss: 0.17265242338180542
[32m[0511 07:34:27 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.16843733191490173, Train Loss: 0.17265057563781738
[32m[0511 07:34:27 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.16844600439071655, Train Loss: 0.17264878749847412
[32m[0511 07:34:27 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.1684543490409851, Train Loss: 0.17264704406261444
[32m[0511 07:34:27 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.16846239566802979, Train Loss: 0.17264536023139954
[32m[0511 07:34:28 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.1684701293706894, Train Loss: 0.1726437211036682
[32m[0511 07:34:28 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.16847757995128632, Train Loss: 0.17264212667942047
[32m[0511 07:34:28 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.16848476231098175, Train Loss: 0.1726405769586563
[32m[0511 07:34:28 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.1684916764497757, Train Loss: 0.17263907194137573
[32m[0511 07:34:28 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.16849836707115173, Train Loss: 0.17263759672641754
[32m[0511 07:34:28 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.16850483417510986, Train Loss: 0.17263616621494293
[32m[0511 07:34:28 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.1685110628604889, Train Loss: 0.17263475060462952
[32m[0511 07:34:28 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.1685170829296112, Train Loss: 0.17263339459896088
[32m[0511 07:34:28 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.1685229241847992, Train Loss: 0.17263202369213104
[32m[0511 07:34:28 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.16852857172489166, Train Loss: 0.17263071238994598
[32m[0511 07:34:28 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.1685340404510498, Train Loss: 0.17262940108776093
[32m[0511 07:34:28 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.16853934526443481, Train Loss: 0.17262811958789825
[32m[0511 07:34:28 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.1685444861650467, Train Loss: 0.17262685298919678
[32m[0511 07:34:28 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.16854944825172424, Train Loss: 0.1726256161928177
[32m[0511 07:34:28 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.16855429112911224, Train Loss: 0.1726243942975998
[32m[0511 07:34:28 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.1685589998960495, Train Loss: 0.1726231724023819
[32m[0511 07:34:28 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.16856354475021362, Train Loss: 0.17262201011180878
[32m[0511 07:34:28 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.1685679852962494, Train Loss: 0.17262081801891327
[32m[0511 07:34:28 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.1685722917318344, Train Loss: 0.17261968553066254
[32m[0511 07:34:28 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.16857647895812988, Train Loss: 0.1726185381412506
[32m[0511 07:34:29 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.1685805469751358, Train Loss: 0.17261740565299988
[32m[0511 07:34:29 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.16858452558517456, Train Loss: 0.17261628806591034
[32m[0511 07:34:29 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.16858837008476257, Train Loss: 0.172615185379982
[32m[0511 07:34:29 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.16859212517738342, Train Loss: 0.17261408269405365
[32m[0511 07:34:29 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.1685957908630371, Train Loss: 0.1726130098104477
[32m[0511 07:34:29 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.16859939694404602, Train Loss: 0.17261195182800293
[32m[0511 07:34:29 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.168602854013443, Train Loss: 0.17261089384555817
[32m[0511 07:34:29 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.16860628128051758, Train Loss: 0.1726098209619522
[32m[0511 07:34:29 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.1686096042394638, Train Loss: 0.17260877788066864
[32m[0511 07:34:29 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.16861283779144287, Train Loss: 0.17260774970054626
[32m[0511 07:34:29 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.16861602663993835, Train Loss: 0.1726067215204239
[32m[0511 07:34:29 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.16861911118030548, Train Loss: 0.1726057231426239
[32m[0511 07:34:29 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.16862213611602783, Train Loss: 0.17260469496250153
[32m[0511 07:34:29 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.1686251014471054, Train Loss: 0.17260371148586273
[32m[0511 07:34:29 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.1686280071735382, Train Loss: 0.17260268330574036
[32m[0511 07:34:29 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.16863082349300385, Train Loss: 0.17260171473026276
[32m[0511 07:34:29 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.1686336249113083, Train Loss: 0.17260076105594635
[32m[0511 07:34:29 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.16863632202148438, Train Loss: 0.17259977757930756
[32m[0511 07:34:29 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.16863900423049927, Train Loss: 0.17259882390499115
[32m[0511 07:34:29 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.1686416119337082, Train Loss: 0.17259785532951355
[32m[0511 07:34:30 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.16864417493343353, Train Loss: 0.17259688675403595
[32m[0511 07:34:30 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.1686466932296753, Train Loss: 0.17259594798088074
[32m[0511 07:34:30 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.16864916682243347, Train Loss: 0.17259500920772552
[32m[0511 07:34:30 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.16865158081054688, Train Loss: 0.1725940704345703
[32m[0511 07:34:30 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.16865397989749908, Train Loss: 0.1725931316614151
[32m[0511 07:34:30 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.16865628957748413, Train Loss: 0.17259222269058228
[32m[0511 07:34:30 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.16865859925746918, Train Loss: 0.17259129881858826
[32m[0511 07:34:30 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.16866084933280945, Train Loss: 0.17259037494659424
[32m[0511 07:34:30 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.16866305470466614, Train Loss: 0.1725894659757614
[32m[0511 07:34:30 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.16866526007652283, Train Loss: 0.1725885421037674
[32m[0511 07:34:30 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.16866739094257355, Train Loss: 0.17258766293525696
[32m[0511 07:34:30 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.16866950690746307, Train Loss: 0.17258676886558533
[32m[0511 07:34:30 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.16867157816886902, Train Loss: 0.1725858896970749
[32m[0511 07:34:30 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.16867361962795258, Train Loss: 0.17258499562740326
[32m[0511 07:34:30 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.16867563128471375, Train Loss: 0.17258411645889282
[32m[0511 07:34:30 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.16867761313915253, Train Loss: 0.17258323729038239
[32m[0511 07:34:30 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.16867956519126892, Train Loss: 0.17258235812187195
[32m[0511 07:34:30 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.16868148744106293, Train Loss: 0.1725814938545227
[32m[0511 07:34:30 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.16868339478969574, Train Loss: 0.17258061468601227
[32m[0511 07:34:30 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.16868525743484497, Train Loss: 0.17257975041866302
[32m[0511 07:34:31 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.1686871200799942, Train Loss: 0.17257891595363617
[32m[0511 07:34:31 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.16868893802165985, Train Loss: 0.17257803678512573
[32m[0511 07:34:31 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.1686907261610031, Train Loss: 0.17257720232009888
[32m[0511 07:34:31 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.168692484498024, Train Loss: 0.17257635295391083
[32m[0511 07:34:31 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.16869425773620605, Train Loss: 0.17257551848888397
[32m[0511 07:34:31 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.16869597136974335, Train Loss: 0.17257465422153473
[32m[0511 07:34:31 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.16869768500328064, Train Loss: 0.17257384955883026
[32m[0511 07:34:31 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.16869935393333435, Train Loss: 0.17257298529148102
[32m[0511 07:34:31 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.16870103776454926, Train Loss: 0.17257219552993774
[32m[0511 07:34:31 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.16870267689228058, Train Loss: 0.1725713610649109
[32m[0511 07:34:31 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.1687043011188507, Train Loss: 0.17257052659988403
[32m[0511 07:34:31 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.16870591044425964, Train Loss: 0.17256970703601837
[32m[0511 07:34:31 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.16870750486850739, Train Loss: 0.1725688874721527
[32m[0511 07:34:31 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.16870906949043274, Train Loss: 0.17256806790828705
[32m[0511 07:34:31 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.1687106192111969, Train Loss: 0.17256727814674377
[32m[0511 07:34:31 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.16871215403079987, Train Loss: 0.17256644368171692
[32m[0511 07:34:31 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.16871367394924164, Train Loss: 0.17256566882133484
[32m[0511 07:34:31 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.16871517896652222, Train Loss: 0.17256486415863037
[32m[0511 07:34:31 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.1687166690826416, Train Loss: 0.1725640445947647
[32m[0511 07:34:31 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.1687181442975998, Train Loss: 0.17256326973438263
[32m[0511 07:34:31 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.1687196046113968, Train Loss: 0.17256246507167816
[32m[0511 07:34:32 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.1687210500240326, Train Loss: 0.1725616753101349
[32m[0511 07:34:32 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.168722465634346, Train Loss: 0.1725608855485916
[32m[0511 07:34:32 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.16872388124465942, Train Loss: 0.17256011068820953
[32m[0511 07:34:32 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.16872528195381165, Train Loss: 0.17255932092666626
[32m[0511 07:34:32 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.16872668266296387, Train Loss: 0.17255854606628418
[32m[0511 07:34:32 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.1687280684709549, Train Loss: 0.1725577712059021
[32m[0511 07:34:32 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.16872940957546234, Train Loss: 0.17255699634552002
[32m[0511 07:34:32 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.16873076558113098, Train Loss: 0.17255622148513794
[32m[0511 07:34:32 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.16873210668563843, Train Loss: 0.17255546152591705
[32m[0511 07:34:32 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.16873344779014587, Train Loss: 0.17255470156669617
[32m[0511 07:34:32 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.16873474419116974, Train Loss: 0.1725539118051529
[32m[0511 07:34:32 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.168736070394516, Train Loss: 0.1725531667470932
[32m[0511 07:34:32 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.16873736679553986, Train Loss: 0.17255240678787231
[32m[0511 07:34:32 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.16873863339424133, Train Loss: 0.17255164682865143
[32m[0511 07:34:32 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.168739914894104, Train Loss: 0.17255090177059174
[32m[0511 07:34:32 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.16874119639396667, Train Loss: 0.17255014181137085
[32m[0511 07:34:32 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.16874244809150696, Train Loss: 0.17254939675331116
[32m[0511 07:34:32 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.16874366998672485, Train Loss: 0.17254863679409027
[32m[0511 07:34:32 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.16874490678310394, Train Loss: 0.17254790663719177
[32m[0511 07:34:32 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.16874611377716064, Train Loss: 0.1725471317768097
[32m[0511 07:34:33 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.16874733567237854, Train Loss: 0.1725464016199112
[32m[0511 07:34:33 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.16874855756759644, Train Loss: 0.1725456565618515
[32m[0511 07:34:33 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.16874973475933075, Train Loss: 0.172544926404953
[32m[0511 07:34:33 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.16875092685222626, Train Loss: 0.1725441962480545
[32m[0511 07:34:33 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.16875210404396057, Train Loss: 0.172543466091156
[32m[0511 07:34:33 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.16875328123569489, Train Loss: 0.1725427210330963
[32m[0511 07:34:33 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.1687544286251068, Train Loss: 0.172542005777359
[32m[0511 07:34:33 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.16875557601451874, Train Loss: 0.17254126071929932
[32m[0511 07:34:33 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.16875672340393066, Train Loss: 0.1725405603647232
[32m[0511 07:34:33 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.1687578558921814, Train Loss: 0.1725398153066635
[32m[0511 07:34:33 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.16875898838043213, Train Loss: 0.1725391000509262
[32m[0511 07:34:33 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.16876010596752167, Train Loss: 0.1725383698940277
[32m[0511 07:34:33 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.16876120865345, Train Loss: 0.1725376546382904
[32m[0511 07:34:33 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.16876232624053955, Train Loss: 0.1725369393825531
[32m[0511 07:34:33 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.1687634140253067, Train Loss: 0.1725362241268158
[32m[0511 07:34:33 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.16876451671123505, Train Loss: 0.1725355088710785
[32m[0511 07:34:33 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.168765589594841, Train Loss: 0.17253480851650238
[32m[0511 07:34:33 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.16876667737960815, Train Loss: 0.17253409326076508
[32m[0511 07:34:33 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.16876773536205292, Train Loss: 0.17253339290618896
[32m[0511 07:34:33 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.16876879334449768, Train Loss: 0.17253267765045166
[32m[0511 07:34:34 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.16876986622810364, Train Loss: 0.17253197729587555
[32m[0511 07:34:34 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.168770894408226, Train Loss: 0.17253126204013824
[32m[0511 07:34:34 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.16877193748950958, Train Loss: 0.17253059148788452
[32m[0511 07:34:34 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.16877298057079315, Train Loss: 0.17252987623214722
[32m[0511 07:34:34 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.16877402365207672, Train Loss: 0.1725291758775711
[32m[0511 07:34:34 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.1687750518321991, Train Loss: 0.1725284904241562
[32m[0511 07:34:34 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.16877605020999908, Train Loss: 0.17252777516841888
[32m[0511 07:34:34 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.16877707839012146, Train Loss: 0.17252708971500397
[32m[0511 07:34:34 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.16877807676792145, Train Loss: 0.17252641916275024
[32m[0511 07:34:34 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.16877907514572144, Train Loss: 0.17252570390701294
[32m[0511 07:34:34 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.16878007352352142, Train Loss: 0.17252503335475922
[32m[0511 07:34:34 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.1687810719013214, Train Loss: 0.1725243330001831
[32m[0511 07:34:34 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.168782040476799, Train Loss: 0.172523632645607
[32m[0511 07:34:34 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.1687830090522766, Train Loss: 0.17252296209335327
[32m[0511 07:34:34 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.1687839776277542, Train Loss: 0.17252227663993835
[32m[0511 07:34:34 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.1687849462032318, Train Loss: 0.17252157628536224
[32m[0511 07:34:34 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.1687859147787094, Train Loss: 0.17252090573310852
[32m[0511 07:34:34 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.16878686845302582, Train Loss: 0.1725202202796936
[32m[0511 07:34:34 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.16878780722618103, Train Loss: 0.17251954972743988
[32m[0511 07:34:34 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.16878876090049744, Train Loss: 0.17251887917518616
[32m[0511 07:34:35 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.16878971457481384, Train Loss: 0.17251819372177124
[32m[0511 07:34:35 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.16879063844680786, Train Loss: 0.1725175380706787
[32m[0511 07:34:35 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.16879159212112427, Train Loss: 0.1725168526172638
[32m[0511 07:34:35 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.1687925159931183, Train Loss: 0.17251619696617126
[32m[0511 07:34:35 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.1687934398651123, Train Loss: 0.17251552641391754
[32m[0511 07:34:35 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.16879433393478394, Train Loss: 0.17251484096050262
[32m[0511 07:34:35 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.16879524290561676, Train Loss: 0.1725141853094101
[32m[0511 07:34:35 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.16879616677761078, Train Loss: 0.17251349985599518
[32m[0511 07:34:35 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.1687970757484436, Train Loss: 0.17251284420490265
[32m[0511 07:34:35 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.16879796981811523, Train Loss: 0.1725122034549713
[32m[0511 07:34:35 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.16879884898662567, Train Loss: 0.1725115329027176
[32m[0511 07:34:35 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.1687997579574585, Train Loss: 0.17251086235046387
[32m[0511 07:34:35 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.16880063712596893, Train Loss: 0.17251019179821014
[32m[0511 07:34:35 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.16880153119564056, Train Loss: 0.1725095510482788
[32m[0511 07:34:35 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.1688023805618286, Train Loss: 0.17250889539718628
[32m[0511 07:34:35 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.16880327463150024, Train Loss: 0.17250823974609375
[32m[0511 07:34:35 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.1688041388988495, Train Loss: 0.17250759899616241
[32m[0511 07:34:35 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.16880500316619873, Train Loss: 0.17250694334506989
[32m[0511 07:34:35 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.16880586743354797, Train Loss: 0.17250627279281616
[32m[0511 07:34:35 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.16880671679973602, Train Loss: 0.17250563204288483
[32m[0511 07:34:35 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.16880755126476288, Train Loss: 0.1725049763917923
[32m[0511 07:34:36 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.16880843043327332, Train Loss: 0.17250432074069977
[32m[0511 07:34:36 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.16880926489830017, Train Loss: 0.17250366508960724
[32m[0511 07:34:36 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.16881011426448822, Train Loss: 0.1725030094385147
[32m[0511 07:34:36 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.16881094872951508, Train Loss: 0.17250236868858337
[32m[0511 07:34:36 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.16881179809570312, Train Loss: 0.17250174283981323
[32m[0511 07:34:36 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.1688126176595688, Train Loss: 0.1725011020898819
[32m[0511 07:34:36 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.16881345212459564, Train Loss: 0.17250046133995056
[32m[0511 07:34:36 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.1688142716884613, Train Loss: 0.17249982059001923
[32m[0511 07:34:36 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.16881509125232697, Train Loss: 0.1724991649389267
[32m[0511 07:34:36 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.16881592571735382, Train Loss: 0.17249852418899536
[32m[0511 07:34:36 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.1688167303800583, Train Loss: 0.17249788343906403
[32m[0511 07:34:36 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.16881753504276276, Train Loss: 0.17249725759029388
[32m[0511 07:34:36 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.16881832480430603, Train Loss: 0.17249661684036255
[32m[0511 07:34:36 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.16881915926933289, Train Loss: 0.1724959760904312
[32m[0511 07:34:36 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.16881996393203735, Train Loss: 0.17249535024166107
[32m[0511 07:34:36 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.16882075369358063, Train Loss: 0.17249470949172974
[32m[0511 07:34:36 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.1688215434551239, Train Loss: 0.1724940985441208
[32m[0511 07:34:36 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.16882233321666718, Train Loss: 0.17249344289302826
[32m[0511 07:34:36 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.16882312297821045, Train Loss: 0.17249281704425812
[32m[0511 07:34:37 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.16882391273975372, Train Loss: 0.17249220609664917
[32m[0511 07:34:37 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.1688247174024582, Train Loss: 0.17249156534671783
[32m[0511 07:34:37 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.16882549226284027, Train Loss: 0.17249096930027008
[32m[0511 07:34:37 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.16882626712322235, Train Loss: 0.17249031364917755
[32m[0511 07:34:37 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.16882704198360443, Train Loss: 0.1724896878004074
[32m[0511 07:34:37 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.1688278168439865, Train Loss: 0.17248907685279846
[32m[0511 07:34:37 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.1688285768032074, Train Loss: 0.17248843610286713
[32m[0511 07:34:37 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.16882933676242828, Train Loss: 0.17248782515525818
[32m[0511 07:34:37 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.16883011162281036, Train Loss: 0.17248719930648804
[32m[0511 07:34:37 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.16883088648319244, Train Loss: 0.1724865585565567
[32m[0511 07:34:37 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.16883164644241333, Train Loss: 0.17248596251010895
[32m[0511 07:34:37 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.16883240640163422, Train Loss: 0.1724853366613388
[32m[0511 07:34:37 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.1688331663608551, Train Loss: 0.17248469591140747
[32m[0511 07:34:37 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.1688339114189148, Train Loss: 0.17248409986495972
[32m[0511 07:34:37 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.16883467137813568, Train Loss: 0.17248347401618958
[32m[0511 07:34:37 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.16883541643619537, Train Loss: 0.17248286306858063
[32m[0511 07:34:37 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.16883614659309387, Train Loss: 0.17248223721981049
[32m[0511 07:34:37 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.16883689165115356, Train Loss: 0.17248162627220154
[32m[0511 07:34:37 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.16883763670921326, Train Loss: 0.1724810153245926
[32m[0511 07:34:37 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.16883839666843414, Train Loss: 0.17248040437698364
[32m[0511 07:34:38 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.16883912682533264, Train Loss: 0.1724798083305359
[32m[0511 07:34:38 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.16883985698223114, Train Loss: 0.17247916758060455
[32m[0511 07:34:38 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.16884058713912964, Train Loss: 0.172478586435318
[32m[0511 07:34:38 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.16884131729602814, Train Loss: 0.17247794568538666
[32m[0511 07:34:38 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.16884204745292664, Train Loss: 0.1724773496389389
[32m[0511 07:34:38 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.16884277760982513, Train Loss: 0.17247672379016876
[32m[0511 07:34:38 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.16884350776672363, Train Loss: 0.1724761426448822
[32m[0511 07:34:38 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.16884422302246094, Train Loss: 0.17247551679611206
[32m[0511 07:34:38 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.16884495317935944, Train Loss: 0.1724749207496643
[32m[0511 07:34:38 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.16884565353393555, Train Loss: 0.17247432470321655
[32m[0511 07:34:38 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.16884636878967285, Train Loss: 0.1724736988544464
[32m[0511 07:34:38 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.16884708404541016, Train Loss: 0.17247310280799866
[32m[0511 07:34:38 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.16884781420230865, Train Loss: 0.1724724918603897
[32m[0511 07:34:38 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.16884851455688477, Train Loss: 0.17247189581394196
[32m[0511 07:34:38 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.16884924471378326, Train Loss: 0.1724712997674942
[32m[0511 07:34:38 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.16884994506835938, Train Loss: 0.17247067391872406
[32m[0511 07:34:38 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.16885064542293549, Train Loss: 0.1724700778722763
[32m[0511 07:34:38 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.1688513606786728, Train Loss: 0.17246948182582855
[32m[0511 07:34:38 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.1688520610332489, Train Loss: 0.1724688857793808
[32m[0511 07:34:38 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.168852761387825, Train Loss: 0.17246827483177185
[32m[0511 07:34:39 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.16885346174240112, Train Loss: 0.1724676787853241
[32m[0511 07:34:39 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.16885416209697723, Train Loss: 0.17246709764003754
[32m[0511 07:34:39 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.16885487735271454, Train Loss: 0.1724664866924286
[32m[0511 07:34:39 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.16885557770729065, Train Loss: 0.17246590554714203
[32m[0511 07:34:39 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.16885624825954437, Train Loss: 0.17246529459953308
[32m[0511 07:34:39 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.16885694861412048, Train Loss: 0.17246468365192413
[32m[0511 07:34:39 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.1688576489686966, Train Loss: 0.17246408760547638
[32m[0511 07:34:39 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.1688583344221115, Train Loss: 0.17246349155902863
[32m[0511 07:34:39 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.16885901987552643, Train Loss: 0.17246289551258087
[32m[0511 07:34:39 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.16885972023010254, Train Loss: 0.1724623143672943
[32m[0511 07:34:39 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.16886039078235626, Train Loss: 0.17246168851852417
[32m[0511 07:34:39 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.16886107623577118, Train Loss: 0.1724611222743988
[32m[0511 07:34:39 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.1688617616891861, Train Loss: 0.17246051132678986
[32m[0511 07:34:39 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.168862447142601, Train Loss: 0.1724599301815033
[32m[0511 07:34:39 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.16886313259601593, Train Loss: 0.17245934903621674
[32m[0511 07:34:39 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.16886380314826965, Train Loss: 0.17245875298976898
[32m[0511 07:34:39 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.16886450350284576, Train Loss: 0.17245815694332123
[32m[0511 07:34:39 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.1688651740550995, Train Loss: 0.17245756089687347
[32m[0511 07:34:39 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.1688658744096756, Train Loss: 0.17245697975158691
[32m[0511 07:34:39 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.16886651515960693, Train Loss: 0.17245639860630035
[32m[0511 07:34:40 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.16886720061302185, Train Loss: 0.1724558025598526
[32m[0511 07:34:40 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.16886787116527557, Train Loss: 0.17245520651340485
[32m[0511 07:34:40 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.1688685566186905, Train Loss: 0.1724546104669571
[32m[0511 07:34:40 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.1688692420721054, Train Loss: 0.17245402932167053
[32m[0511 07:34:40 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.16886989772319794, Train Loss: 0.17245344817638397
[32m[0511 07:34:40 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.16887058317661285, Train Loss: 0.17245283722877502
[32m[0511 07:34:40 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.16887125372886658, Train Loss: 0.17245227098464966
[32m[0511 07:34:40 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.1688719093799591, Train Loss: 0.1724516898393631
[32m[0511 07:34:40 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.16887259483337402, Train Loss: 0.17245109379291534
[32m[0511 07:34:40 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.16887325048446655, Train Loss: 0.1724504977464676
[32m[0511 07:34:40 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.16887392103672028, Train Loss: 0.17244993150234222
[32m[0511 07:34:40 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.1688745766878128, Train Loss: 0.17244933545589447
[32m[0511 07:34:40 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.16887523233890533, Train Loss: 0.1724487543106079
[32m[0511 07:34:40 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.16887593269348145, Train Loss: 0.17244817316532135
[32m[0511 07:34:40 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.16887660324573517, Train Loss: 0.1724475920200348
[32m[0511 07:34:40 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.1688772439956665, Train Loss: 0.17244699597358704
[32m[0511 07:34:40 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.16887791454792023, Train Loss: 0.17244642972946167
[32m[0511 07:34:40 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.16887858510017395, Train Loss: 0.1724458485841751
[32m[0511 07:34:40 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.16887922585010529, Train Loss: 0.17244526743888855
[32m[0511 07:34:40 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.1688799113035202, Train Loss: 0.172444686293602
[32m[0511 07:34:41 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.16888056695461273, Train Loss: 0.17244410514831543
[32m[0511 07:34:41 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.16888122260570526, Train Loss: 0.17244350910186768
[32m[0511 07:34:41 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.1688818782567978, Train Loss: 0.17244291305541992
[32m[0511 07:34:41 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.1688825488090515, Train Loss: 0.17244234681129456
[32m[0511 07:34:41 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.16888321936130524, Train Loss: 0.172441765666008
[32m[0511 07:34:41 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.16888387501239777, Train Loss: 0.17244116961956024
[32m[0511 07:34:41 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.1688845157623291, Train Loss: 0.17244061827659607
[32m[0511 07:34:41 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.16888518631458282, Train Loss: 0.17244002223014832
[32m[0511 07:34:41 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.16888584196567535, Train Loss: 0.17243947088718414
[32m[0511 07:34:41 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.16888651251792908, Train Loss: 0.1724388748407364
[32m[0511 07:34:41 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.1688871532678604, Train Loss: 0.17243829369544983
[32m[0511 07:34:41 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.16888782382011414, Train Loss: 0.17243772745132446
[32m[0511 07:34:41 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.16888847947120667, Train Loss: 0.1724371463060379
[32m[0511 07:34:41 @mbmf_main.py:224][0m batch size for trpo is 1000
[32m[0511 07:34:41 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 07:34:41 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 07:34:41 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 07:34:41 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 07:34:41 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 07:34:41 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 07:34:41 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 07:34:41 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 07:34:41 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 07:34:41 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 07:34:41 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 07:34:41 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 07:34:41 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 07:34:41 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 07:34:41 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 07:34:41 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 07:34:41 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 07:34:41 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 07:34:41 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 07:34:41 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 07:34:41 @mbmf_main.py:132][0m Training starts at /root/mbbl
[32m[0511 07:34:41 @base_worker.py:45][0m Worker 0 online
[32m[0511 07:34:41 @base_worker.py:45][0m Worker 1 online
[32m[0511 07:34:41 @base_worker.py:45][0m Worker 2 online
[32m[0511 07:34:41 @base_worker.py:45][0m Worker 3 online
[32m[0511 07:34:41 @base_worker.py:45][0m Worker 4 online
[32m[0511 07:34:41 @base_worker.py:45][0m Worker 5 online
[32m[0511 07:34:41 @base_worker.py:45][0m Worker 6 online
[32m[0511 07:34:41 @base_worker.py:45][0m Worker 7 online
[32m[0511 07:34:41 @base_worker.py:45][0m Worker 8 online
[32m[0511 07:34:41 @base_worker.py:45][0m Worker 9 online
[32m[0511 07:34:41 @base_worker.py:45][0m Worker 10 online
[32m[0511 07:34:41 @base_worker.py:45][0m Worker 11 online
[32m[0511 07:34:41 @base_worker.py:45][0m Worker 12 online
[32m[0511 07:34:41 @base_worker.py:45][0m Worker 13 online
[32m[0511 07:34:41 @base_worker.py:45][0m Worker 14 online
[32m[0511 07:34:41 @base_worker.py:45][0m Worker 15 online
[32m[0511 07:34:41 @base_worker.py:45][0m Worker 16 online
[32m[0511 07:34:41 @base_worker.py:45][0m Worker 17 online
[32m[0511 07:34:41 @base_worker.py:45][0m Worker 18 online
[32m[0511 07:34:41 @base_worker.py:45][0m Worker 19 online
[32m[0511 07:34:42 @base_trainer.py:152][0m Trainer maintains [1] policy network
[32m[0511 07:34:42 @base_trainer.py:152][0m Trainer maintains [1] dynamics network
[32m[0511 07:34:42 @base_trainer.py:152][0m Trainer maintains [1] reward network
[32m[0511 07:34:42 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:34:42 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:34:42 @base_trainer.py:216][0m Mean reward: -964.9523628806198
[32m[0511 07:34:43 @base_main.py:38][0m --------------- Iteration 1 ---------------
[32m[0511 07:34:43 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0000 mins
[32m[0511 07:34:43 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0511 07:34:43 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0148 mins
[32m[0511 07:34:43 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:34:43 @base_main.py:47][0m 1005 total steps have happened
[32m[0511 07:34:43 @base_main.py:52][0m [avg_reward]: -964.9523628806198
[32m[0511 07:34:43 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:34:43 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:34:43 @base_trainer.py:216][0m Mean reward: -1185.7319104086196
[32m[0511 07:34:44 @base_main.py:38][0m --------------- Iteration 2 ---------------
[32m[0511 07:34:44 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0177 mins
[32m[0511 07:34:44 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0511 07:34:44 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 07:34:44 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:34:44 @base_main.py:47][0m 2010 total steps have happened
[32m[0511 07:34:44 @base_main.py:52][0m [avg_reward]: -1185.7319104086196
[32m[0511 07:34:44 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:34:44 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:34:44 @base_trainer.py:216][0m Mean reward: -1237.9240424214563
[32m[0511 07:34:45 @base_main.py:38][0m --------------- Iteration 3 ---------------
[32m[0511 07:34:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0305 mins
[32m[0511 07:34:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0511 07:34:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 07:34:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:34:45 @base_main.py:47][0m 3015 total steps have happened
[32m[0511 07:34:45 @base_main.py:52][0m [avg_reward]: -1237.9240424214563
[32m[0511 07:34:45 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:34:45 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:34:45 @base_trainer.py:216][0m Mean reward: -1300.1249616237315
[32m[0511 07:34:45 @base_main.py:38][0m --------------- Iteration 4 ---------------
[32m[0511 07:34:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0437 mins
[32m[0511 07:34:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 07:34:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 07:34:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:34:45 @base_main.py:47][0m 4020 total steps have happened
[32m[0511 07:34:45 @base_main.py:52][0m [avg_reward]: -1300.1249616237315
[32m[0511 07:34:45 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:34:45 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:34:45 @base_trainer.py:216][0m Mean reward: -1124.8064377290882
[32m[0511 07:34:46 @base_main.py:38][0m --------------- Iteration 5 ---------------
[32m[0511 07:34:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0561 mins
[32m[0511 07:34:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 07:34:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 07:34:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:34:46 @base_main.py:47][0m 5025 total steps have happened
[32m[0511 07:34:46 @base_main.py:52][0m [avg_reward]: -1124.8064377290882
[32m[0511 07:34:46 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:34:46 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:34:46 @base_trainer.py:216][0m Mean reward: -1174.389185028694
[32m[0511 07:34:47 @base_main.py:38][0m --------------- Iteration 6 ---------------
[32m[0511 07:34:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0686 mins
[32m[0511 07:34:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0511 07:34:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 07:34:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:34:47 @base_main.py:47][0m 6030 total steps have happened
[32m[0511 07:34:47 @base_main.py:52][0m [avg_reward]: -1174.389185028694
[32m[0511 07:34:47 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:34:47 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:34:47 @base_trainer.py:216][0m Mean reward: -1138.0016007576185
[32m[0511 07:34:48 @base_main.py:38][0m --------------- Iteration 7 ---------------
[32m[0511 07:34:48 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0818 mins
[32m[0511 07:34:48 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 07:34:48 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 07:34:48 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:34:48 @base_main.py:47][0m 7035 total steps have happened
[32m[0511 07:34:48 @base_main.py:52][0m [avg_reward]: -1138.0016007576185
[32m[0511 07:34:48 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:34:48 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:34:48 @base_trainer.py:216][0m Mean reward: -1213.353855168292
[32m[0511 07:34:48 @base_main.py:38][0m --------------- Iteration 8 ---------------
[32m[0511 07:34:48 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0943 mins
[32m[0511 07:34:48 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 07:34:48 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 07:34:48 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:34:48 @base_main.py:47][0m 8040 total steps have happened
[32m[0511 07:34:48 @base_main.py:52][0m [avg_reward]: -1213.353855168292
[32m[0511 07:34:49 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:34:49 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:34:49 @base_trainer.py:216][0m Mean reward: -1387.4520587542459
[32m[0511 07:34:49 @base_main.py:38][0m --------------- Iteration 9 ---------------
[32m[0511 07:34:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1071 mins
[32m[0511 07:34:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 07:34:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 07:34:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:34:49 @base_main.py:47][0m 9045 total steps have happened
[32m[0511 07:34:49 @base_main.py:52][0m [avg_reward]: -1387.4520587542459
[32m[0511 07:34:49 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:34:49 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:34:49 @base_trainer.py:216][0m Mean reward: -1204.3824747656795
[32m[0511 07:34:50 @base_main.py:38][0m --------------- Iteration 10 ---------------
[32m[0511 07:34:50 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1199 mins
[32m[0511 07:34:50 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 07:34:50 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 07:34:50 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:34:50 @base_main.py:47][0m 10050 total steps have happened
[32m[0511 07:34:50 @base_main.py:52][0m [avg_reward]: -1204.3824747656795
[32m[0511 07:34:50 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:34:50 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:34:50 @base_trainer.py:216][0m Mean reward: -1137.7510241354337
[32m[0511 07:34:51 @base_main.py:38][0m --------------- Iteration 11 ---------------
[32m[0511 07:34:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1325 mins
[32m[0511 07:34:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 07:34:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 07:34:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:34:51 @base_main.py:47][0m 11055 total steps have happened
[32m[0511 07:34:51 @base_main.py:52][0m [avg_reward]: -1137.7510241354337
[32m[0511 07:34:51 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:34:51 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:34:51 @base_trainer.py:216][0m Mean reward: -1219.0908128558538
[32m[0511 07:34:51 @base_main.py:38][0m --------------- Iteration 12 ---------------
[32m[0511 07:34:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1449 mins
[32m[0511 07:34:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0511 07:34:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 07:34:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:34:51 @base_main.py:47][0m 12060 total steps have happened
[32m[0511 07:34:51 @base_main.py:52][0m [avg_reward]: -1219.0908128558538
[32m[0511 07:34:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:34:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:34:52 @base_trainer.py:216][0m Mean reward: -1076.6303027093709
[32m[0511 07:34:52 @base_main.py:38][0m --------------- Iteration 13 ---------------
[32m[0511 07:34:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1582 mins
[32m[0511 07:34:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 07:34:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 07:34:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:34:52 @base_main.py:47][0m 13065 total steps have happened
[32m[0511 07:34:52 @base_main.py:52][0m [avg_reward]: -1076.6303027093709
[32m[0511 07:34:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:34:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:34:52 @base_trainer.py:216][0m Mean reward: -1171.5575647522494
[32m[0511 07:34:53 @base_main.py:38][0m --------------- Iteration 14 ---------------
[32m[0511 07:34:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1708 mins
[32m[0511 07:34:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 07:34:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 07:34:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:34:53 @base_main.py:47][0m 14070 total steps have happened
[32m[0511 07:34:53 @base_main.py:52][0m [avg_reward]: -1171.5575647522494
[32m[0511 07:34:53 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:34:53 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:34:53 @base_trainer.py:216][0m Mean reward: -1009.092211656203
[32m[0511 07:34:54 @base_main.py:38][0m --------------- Iteration 15 ---------------
[32m[0511 07:34:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1835 mins
[32m[0511 07:34:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 07:34:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0108 mins
[32m[0511 07:34:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:34:54 @base_main.py:47][0m 15075 total steps have happened
[32m[0511 07:34:54 @base_main.py:52][0m [avg_reward]: -1009.092211656203
[32m[0511 07:34:54 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:34:54 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:34:54 @base_trainer.py:216][0m Mean reward: -1102.0732781767829
[32m[0511 07:34:55 @base_main.py:38][0m --------------- Iteration 16 ---------------
[32m[0511 07:34:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1967 mins
[32m[0511 07:34:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 07:34:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0107 mins
[32m[0511 07:34:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:34:55 @base_main.py:47][0m 16080 total steps have happened
[32m[0511 07:34:55 @base_main.py:52][0m [avg_reward]: -1102.0732781767829
[32m[0511 07:34:55 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:34:55 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:34:55 @base_trainer.py:216][0m Mean reward: -1229.3329774275521
[32m[0511 07:34:55 @base_main.py:38][0m --------------- Iteration 17 ---------------
[32m[0511 07:34:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2100 mins
[32m[0511 07:34:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 07:34:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 07:34:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:34:55 @base_main.py:47][0m 17085 total steps have happened
[32m[0511 07:34:55 @base_main.py:52][0m [avg_reward]: -1229.3329774275521
[32m[0511 07:34:55 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:34:55 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:34:55 @base_trainer.py:216][0m Mean reward: -1213.7780661800016
[32m[0511 07:34:56 @base_main.py:38][0m --------------- Iteration 18 ---------------
[32m[0511 07:34:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2226 mins
[32m[0511 07:34:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 07:34:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 07:34:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:34:56 @base_main.py:47][0m 18090 total steps have happened
[32m[0511 07:34:56 @base_main.py:52][0m [avg_reward]: -1213.7780661800016
[32m[0511 07:34:56 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:34:56 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:34:56 @base_trainer.py:216][0m Mean reward: -1202.2674683023686
[32m[0511 07:34:57 @base_main.py:38][0m --------------- Iteration 19 ---------------
[32m[0511 07:34:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2356 mins
[32m[0511 07:34:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 07:34:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 07:34:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:34:57 @base_main.py:47][0m 19095 total steps have happened
[32m[0511 07:34:57 @base_main.py:52][0m [avg_reward]: -1202.2674683023686
[32m[0511 07:34:57 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:34:57 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:34:57 @base_trainer.py:216][0m Mean reward: -1099.5711262291566
[32m[0511 07:34:58 @base_main.py:38][0m --------------- Iteration 20 ---------------
[32m[0511 07:34:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2481 mins
[32m[0511 07:34:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 07:34:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0511 07:34:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:34:58 @base_main.py:47][0m 20100 total steps have happened
[32m[0511 07:34:58 @base_main.py:52][0m [avg_reward]: -1099.5711262291566
[32m[0511 07:34:58 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:34:58 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:34:58 @base_trainer.py:216][0m Mean reward: -1159.7155633260475
[32m[0511 07:34:58 @base_main.py:38][0m --------------- Iteration 21 ---------------
[32m[0511 07:34:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2597 mins
[32m[0511 07:34:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0511 07:34:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 07:34:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:34:58 @base_main.py:47][0m 21105 total steps have happened
[32m[0511 07:34:58 @base_main.py:52][0m [avg_reward]: -1159.7155633260475
[32m[0511 07:34:58 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:34:58 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:34:58 @base_trainer.py:216][0m Mean reward: -1065.874597266194
[32m[0511 07:34:59 @base_main.py:38][0m --------------- Iteration 22 ---------------
[32m[0511 07:34:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2728 mins
[32m[0511 07:34:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 07:34:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 07:34:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:34:59 @base_main.py:47][0m 22110 total steps have happened
[32m[0511 07:34:59 @base_main.py:52][0m [avg_reward]: -1065.874597266194
[32m[0511 07:34:59 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:34:59 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:34:59 @base_trainer.py:216][0m Mean reward: -1115.1140661340278
[32m[0511 07:35:00 @base_main.py:38][0m --------------- Iteration 23 ---------------
[32m[0511 07:35:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2849 mins
[32m[0511 07:35:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 07:35:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 07:35:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:00 @base_main.py:47][0m 23115 total steps have happened
[32m[0511 07:35:00 @base_main.py:52][0m [avg_reward]: -1115.1140661340278
[32m[0511 07:35:00 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:00 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:00 @base_trainer.py:216][0m Mean reward: -1136.1291064463708
[32m[0511 07:35:01 @base_main.py:38][0m --------------- Iteration 24 ---------------
[32m[0511 07:35:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2971 mins
[32m[0511 07:35:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 07:35:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 07:35:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:01 @base_main.py:47][0m 24120 total steps have happened
[32m[0511 07:35:01 @base_main.py:52][0m [avg_reward]: -1136.1291064463708
[32m[0511 07:35:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:01 @base_trainer.py:216][0m Mean reward: -1167.9307671938163
[32m[0511 07:35:01 @base_main.py:38][0m --------------- Iteration 25 ---------------
[32m[0511 07:35:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3096 mins
[32m[0511 07:35:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 07:35:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 07:35:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:01 @base_main.py:47][0m 25125 total steps have happened
[32m[0511 07:35:01 @base_main.py:52][0m [avg_reward]: -1167.9307671938163
[32m[0511 07:35:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:01 @base_trainer.py:216][0m Mean reward: -1070.6730920398263
[32m[0511 07:35:02 @base_main.py:38][0m --------------- Iteration 26 ---------------
[32m[0511 07:35:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3223 mins
[32m[0511 07:35:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 07:35:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 07:35:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0511 07:35:02 @base_main.py:47][0m 26130 total steps have happened
[32m[0511 07:35:02 @base_main.py:52][0m [avg_reward]: -1070.6730920398263
[32m[0511 07:35:02 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:02 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:02 @base_trainer.py:216][0m Mean reward: -1255.1966212916916
[32m[0511 07:35:03 @base_main.py:38][0m --------------- Iteration 27 ---------------
[32m[0511 07:35:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3346 mins
[32m[0511 07:35:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 07:35:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 07:35:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:03 @base_main.py:47][0m 27135 total steps have happened
[32m[0511 07:35:03 @base_main.py:52][0m [avg_reward]: -1255.1966212916916
[32m[0511 07:35:03 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:03 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:03 @base_trainer.py:216][0m Mean reward: -1099.5956571489814
[32m[0511 07:35:04 @base_main.py:38][0m --------------- Iteration 28 ---------------
[32m[0511 07:35:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3476 mins
[32m[0511 07:35:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 07:35:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 07:35:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:04 @base_main.py:47][0m 28140 total steps have happened
[32m[0511 07:35:04 @base_main.py:52][0m [avg_reward]: -1099.5956571489814
[32m[0511 07:35:04 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:04 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:04 @base_trainer.py:216][0m Mean reward: -1425.4295816809067
[32m[0511 07:35:04 @base_main.py:38][0m --------------- Iteration 29 ---------------
[32m[0511 07:35:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3606 mins
[32m[0511 07:35:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 07:35:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 07:35:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:04 @base_main.py:47][0m 29145 total steps have happened
[32m[0511 07:35:04 @base_main.py:52][0m [avg_reward]: -1425.4295816809067
[32m[0511 07:35:05 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:05 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:05 @base_trainer.py:216][0m Mean reward: -1144.722939540028
[32m[0511 07:35:05 @base_main.py:38][0m --------------- Iteration 30 ---------------
[32m[0511 07:35:05 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3732 mins
[32m[0511 07:35:05 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 07:35:05 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 07:35:05 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:05 @base_main.py:47][0m 30150 total steps have happened
[32m[0511 07:35:05 @base_main.py:52][0m [avg_reward]: -1144.722939540028
[32m[0511 07:35:05 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:05 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:05 @base_trainer.py:216][0m Mean reward: -1126.1373813989055
[32m[0511 07:35:06 @base_main.py:38][0m --------------- Iteration 31 ---------------
[32m[0511 07:35:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3858 mins
[32m[0511 07:35:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 07:35:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 07:35:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:06 @base_main.py:47][0m 31155 total steps have happened
[32m[0511 07:35:06 @base_main.py:52][0m [avg_reward]: -1126.1373813989055
[32m[0511 07:35:06 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:06 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:06 @base_trainer.py:216][0m Mean reward: -997.3386251294171
[32m[0511 07:35:07 @base_main.py:38][0m --------------- Iteration 32 ---------------
[32m[0511 07:35:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3979 mins
[32m[0511 07:35:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 07:35:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 07:35:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:07 @base_main.py:47][0m 32160 total steps have happened
[32m[0511 07:35:07 @base_main.py:52][0m [avg_reward]: -997.3386251294171
[32m[0511 07:35:07 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:07 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:07 @base_trainer.py:216][0m Mean reward: -1166.7144111699533
[32m[0511 07:35:07 @base_main.py:38][0m --------------- Iteration 33 ---------------
[32m[0511 07:35:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4100 mins
[32m[0511 07:35:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 07:35:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 07:35:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:07 @base_main.py:47][0m 33165 total steps have happened
[32m[0511 07:35:07 @base_main.py:52][0m [avg_reward]: -1166.7144111699533
[32m[0511 07:35:07 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:07 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:07 @base_trainer.py:216][0m Mean reward: -1020.2020311483118
[32m[0511 07:35:08 @base_main.py:38][0m --------------- Iteration 34 ---------------
[32m[0511 07:35:08 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4223 mins
[32m[0511 07:35:08 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 07:35:08 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 07:35:08 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:08 @base_main.py:47][0m 34170 total steps have happened
[32m[0511 07:35:08 @base_main.py:52][0m [avg_reward]: -1020.2020311483118
[32m[0511 07:35:08 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:08 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:08 @base_trainer.py:216][0m Mean reward: -1047.7588903958926
[32m[0511 07:35:09 @base_main.py:38][0m --------------- Iteration 35 ---------------
[32m[0511 07:35:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4352 mins
[32m[0511 07:35:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 07:35:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 07:35:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0511 07:35:09 @base_main.py:47][0m 35175 total steps have happened
[32m[0511 07:35:09 @base_main.py:52][0m [avg_reward]: -1047.7588903958926
[32m[0511 07:35:09 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:09 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:09 @base_trainer.py:216][0m Mean reward: -1071.0963721197716
[32m[0511 07:35:10 @base_main.py:38][0m --------------- Iteration 36 ---------------
[32m[0511 07:35:10 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4482 mins
[32m[0511 07:35:10 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 07:35:10 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0511 07:35:10 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:10 @base_main.py:47][0m 36180 total steps have happened
[32m[0511 07:35:10 @base_main.py:52][0m [avg_reward]: -1071.0963721197716
[32m[0511 07:35:10 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:10 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:10 @base_trainer.py:216][0m Mean reward: -1128.0349750427781
[32m[0511 07:35:10 @base_main.py:38][0m --------------- Iteration 37 ---------------
[32m[0511 07:35:10 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4598 mins
[32m[0511 07:35:10 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 07:35:10 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 07:35:10 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:10 @base_main.py:47][0m 37185 total steps have happened
[32m[0511 07:35:10 @base_main.py:52][0m [avg_reward]: -1128.0349750427781
[32m[0511 07:35:10 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:10 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:10 @base_trainer.py:216][0m Mean reward: -1074.4257431857386
[32m[0511 07:35:11 @base_main.py:38][0m --------------- Iteration 38 ---------------
[32m[0511 07:35:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4724 mins
[32m[0511 07:35:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0511 07:35:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 07:35:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:11 @base_main.py:47][0m 38190 total steps have happened
[32m[0511 07:35:11 @base_main.py:52][0m [avg_reward]: -1074.4257431857386
[32m[0511 07:35:11 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:11 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:11 @base_trainer.py:216][0m Mean reward: -1135.605094680075
[32m[0511 07:35:12 @base_main.py:38][0m --------------- Iteration 39 ---------------
[32m[0511 07:35:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4853 mins
[32m[0511 07:35:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0511 07:35:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 07:35:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:12 @base_main.py:47][0m 39195 total steps have happened
[32m[0511 07:35:12 @base_main.py:52][0m [avg_reward]: -1135.605094680075
[32m[0511 07:35:12 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:12 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:12 @base_trainer.py:216][0m Mean reward: -1150.2396413981473
[32m[0511 07:35:13 @base_main.py:38][0m --------------- Iteration 40 ---------------
[32m[0511 07:35:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4980 mins
[32m[0511 07:35:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 07:35:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 07:35:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:13 @base_main.py:47][0m 40200 total steps have happened
[32m[0511 07:35:13 @base_main.py:52][0m [avg_reward]: -1150.2396413981473
[32m[0511 07:35:13 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:13 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:13 @base_trainer.py:216][0m Mean reward: -1199.209734142951
[32m[0511 07:35:13 @base_main.py:38][0m --------------- Iteration 41 ---------------
[32m[0511 07:35:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5105 mins
[32m[0511 07:35:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 07:35:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 07:35:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:13 @base_main.py:47][0m 41205 total steps have happened
[32m[0511 07:35:13 @base_main.py:52][0m [avg_reward]: -1199.209734142951
[32m[0511 07:35:13 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:13 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:13 @base_trainer.py:216][0m Mean reward: -1133.9109732606935
[32m[0511 07:35:14 @base_main.py:38][0m --------------- Iteration 42 ---------------
[32m[0511 07:35:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5226 mins
[32m[0511 07:35:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 07:35:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 07:35:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:14 @base_main.py:47][0m 42210 total steps have happened
[32m[0511 07:35:14 @base_main.py:52][0m [avg_reward]: -1133.9109732606935
[32m[0511 07:35:14 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:14 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:14 @base_trainer.py:216][0m Mean reward: -1223.4432534499836
[32m[0511 07:35:15 @base_main.py:38][0m --------------- Iteration 43 ---------------
[32m[0511 07:35:15 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5346 mins
[32m[0511 07:35:15 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 07:35:15 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 07:35:15 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:15 @base_main.py:47][0m 43215 total steps have happened
[32m[0511 07:35:15 @base_main.py:52][0m [avg_reward]: -1223.4432534499836
[32m[0511 07:35:15 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:15 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:15 @base_trainer.py:216][0m Mean reward: -1125.0033974875992
[32m[0511 07:35:16 @base_main.py:38][0m --------------- Iteration 44 ---------------
[32m[0511 07:35:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5475 mins
[32m[0511 07:35:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 07:35:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 07:35:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:16 @base_main.py:47][0m 44220 total steps have happened
[32m[0511 07:35:16 @base_main.py:52][0m [avg_reward]: -1125.0033974875992
[32m[0511 07:35:16 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:16 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:16 @base_trainer.py:216][0m Mean reward: -1140.9004368068786
[32m[0511 07:35:16 @base_main.py:38][0m --------------- Iteration 45 ---------------
[32m[0511 07:35:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5598 mins
[32m[0511 07:35:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 07:35:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 07:35:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:16 @base_main.py:47][0m 45225 total steps have happened
[32m[0511 07:35:16 @base_main.py:52][0m [avg_reward]: -1140.9004368068786
[32m[0511 07:35:16 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:16 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:16 @base_trainer.py:216][0m Mean reward: -1084.6216237083456
[32m[0511 07:35:17 @base_main.py:38][0m --------------- Iteration 46 ---------------
[32m[0511 07:35:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5722 mins
[32m[0511 07:35:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 07:35:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 07:35:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0511 07:35:17 @base_main.py:47][0m 46230 total steps have happened
[32m[0511 07:35:17 @base_main.py:52][0m [avg_reward]: -1084.6216237083456
[32m[0511 07:35:17 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:17 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:17 @base_trainer.py:216][0m Mean reward: -1091.002924914636
[32m[0511 07:35:18 @base_main.py:38][0m --------------- Iteration 47 ---------------
[32m[0511 07:35:18 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5853 mins
[32m[0511 07:35:18 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0511 07:35:18 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 07:35:18 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:18 @base_main.py:47][0m 47235 total steps have happened
[32m[0511 07:35:18 @base_main.py:52][0m [avg_reward]: -1091.002924914636
[32m[0511 07:35:18 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:18 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:18 @base_trainer.py:216][0m Mean reward: -1324.623278884726
[32m[0511 07:35:19 @base_main.py:38][0m --------------- Iteration 48 ---------------
[32m[0511 07:35:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5987 mins
[32m[0511 07:35:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 07:35:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 07:35:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:19 @base_main.py:47][0m 48240 total steps have happened
[32m[0511 07:35:19 @base_main.py:52][0m [avg_reward]: -1324.623278884726
[32m[0511 07:35:19 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:19 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:19 @base_trainer.py:216][0m Mean reward: -1107.9432878451819
[32m[0511 07:35:19 @base_main.py:38][0m --------------- Iteration 49 ---------------
[32m[0511 07:35:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6112 mins
[32m[0511 07:35:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 07:35:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 07:35:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:19 @base_main.py:47][0m 49245 total steps have happened
[32m[0511 07:35:19 @base_main.py:52][0m [avg_reward]: -1107.9432878451819
[32m[0511 07:35:20 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:20 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:20 @base_trainer.py:216][0m Mean reward: -1101.2827493950883
[32m[0511 07:35:20 @base_main.py:38][0m --------------- Iteration 50 ---------------
[32m[0511 07:35:20 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6242 mins
[32m[0511 07:35:20 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 07:35:20 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 07:35:20 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:20 @base_main.py:47][0m 50250 total steps have happened
[32m[0511 07:35:20 @base_main.py:52][0m [avg_reward]: -1101.2827493950883
[32m[0511 07:35:20 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:20 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:20 @base_trainer.py:216][0m Mean reward: -1049.4820928992813
[32m[0511 07:35:21 @base_main.py:38][0m --------------- Iteration 51 ---------------
[32m[0511 07:35:21 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6361 mins
[32m[0511 07:35:21 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 07:35:21 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 07:35:21 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:21 @base_main.py:47][0m 51255 total steps have happened
[32m[0511 07:35:21 @base_main.py:52][0m [avg_reward]: -1049.4820928992813
[32m[0511 07:35:21 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:21 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:21 @base_trainer.py:216][0m Mean reward: -1099.7548393266902
[32m[0511 07:35:22 @base_main.py:38][0m --------------- Iteration 52 ---------------
[32m[0511 07:35:22 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6491 mins
[32m[0511 07:35:22 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 07:35:22 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0108 mins
[32m[0511 07:35:22 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:22 @base_main.py:47][0m 52260 total steps have happened
[32m[0511 07:35:22 @base_main.py:52][0m [avg_reward]: -1099.7548393266902
[32m[0511 07:35:22 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:22 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:22 @base_trainer.py:216][0m Mean reward: -1152.1979513732663
[32m[0511 07:35:22 @base_main.py:38][0m --------------- Iteration 53 ---------------
[32m[0511 07:35:22 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6620 mins
[32m[0511 07:35:22 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0017 mins
[32m[0511 07:35:22 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 07:35:22 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:22 @base_main.py:47][0m 53265 total steps have happened
[32m[0511 07:35:22 @base_main.py:52][0m [avg_reward]: -1152.1979513732663
[32m[0511 07:35:23 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:23 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:23 @base_trainer.py:216][0m Mean reward: -1075.5112227745735
[32m[0511 07:35:23 @base_main.py:38][0m --------------- Iteration 54 ---------------
[32m[0511 07:35:23 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6743 mins
[32m[0511 07:35:23 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0511 07:35:23 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 07:35:23 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:23 @base_main.py:47][0m 54270 total steps have happened
[32m[0511 07:35:23 @base_main.py:52][0m [avg_reward]: -1075.5112227745735
[32m[0511 07:35:23 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:23 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:23 @base_trainer.py:216][0m Mean reward: -1251.7330411156843
[32m[0511 07:35:24 @base_main.py:38][0m --------------- Iteration 55 ---------------
[32m[0511 07:35:24 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6875 mins
[32m[0511 07:35:24 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 07:35:24 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 07:35:24 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:24 @base_main.py:47][0m 55275 total steps have happened
[32m[0511 07:35:24 @base_main.py:52][0m [avg_reward]: -1251.7330411156843
[32m[0511 07:35:24 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:24 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:24 @base_trainer.py:216][0m Mean reward: -1207.8700471500845
[32m[0511 07:35:25 @base_main.py:38][0m --------------- Iteration 56 ---------------
[32m[0511 07:35:25 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6996 mins
[32m[0511 07:35:25 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 07:35:25 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0107 mins
[32m[0511 07:35:25 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:25 @base_main.py:47][0m 56280 total steps have happened
[32m[0511 07:35:25 @base_main.py:52][0m [avg_reward]: -1207.8700471500845
[32m[0511 07:35:25 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:25 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:25 @base_trainer.py:216][0m Mean reward: -1152.9338819455857
[32m[0511 07:35:26 @base_main.py:38][0m --------------- Iteration 57 ---------------
[32m[0511 07:35:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7128 mins
[32m[0511 07:35:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 07:35:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 07:35:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:26 @base_main.py:47][0m 57285 total steps have happened
[32m[0511 07:35:26 @base_main.py:52][0m [avg_reward]: -1152.9338819455857
[32m[0511 07:35:26 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:26 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:26 @base_trainer.py:216][0m Mean reward: -1146.6210080024707
[32m[0511 07:35:26 @base_main.py:38][0m --------------- Iteration 58 ---------------
[32m[0511 07:35:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7257 mins
[32m[0511 07:35:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 07:35:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 07:35:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:26 @base_main.py:47][0m 58290 total steps have happened
[32m[0511 07:35:26 @base_main.py:52][0m [avg_reward]: -1146.6210080024707
[32m[0511 07:35:26 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:26 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:26 @base_trainer.py:216][0m Mean reward: -1061.078177301318
[32m[0511 07:35:27 @base_main.py:38][0m --------------- Iteration 59 ---------------
[32m[0511 07:35:27 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7388 mins
[32m[0511 07:35:27 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 07:35:27 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 07:35:27 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:27 @base_main.py:47][0m 59295 total steps have happened
[32m[0511 07:35:27 @base_main.py:52][0m [avg_reward]: -1061.078177301318
[32m[0511 07:35:27 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:27 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:27 @base_trainer.py:216][0m Mean reward: -1168.699712895153
[32m[0511 07:35:28 @base_main.py:38][0m --------------- Iteration 60 ---------------
[32m[0511 07:35:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7513 mins
[32m[0511 07:35:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 07:35:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 07:35:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:28 @base_main.py:47][0m 60300 total steps have happened
[32m[0511 07:35:28 @base_main.py:52][0m [avg_reward]: -1168.699712895153
[32m[0511 07:35:28 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:28 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:28 @base_trainer.py:216][0m Mean reward: -933.0974210614992
[32m[0511 07:35:29 @base_main.py:38][0m --------------- Iteration 61 ---------------
[32m[0511 07:35:29 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7637 mins
[32m[0511 07:35:29 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 07:35:29 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 07:35:29 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:29 @base_main.py:47][0m 61305 total steps have happened
[32m[0511 07:35:29 @base_main.py:52][0m [avg_reward]: -933.0974210614992
[32m[0511 07:35:29 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:29 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:29 @base_trainer.py:216][0m Mean reward: -964.634424668951
[32m[0511 07:35:29 @base_main.py:38][0m --------------- Iteration 62 ---------------
[32m[0511 07:35:29 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7762 mins
[32m[0511 07:35:29 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 07:35:29 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 07:35:29 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:29 @base_main.py:47][0m 62310 total steps have happened
[32m[0511 07:35:29 @base_main.py:52][0m [avg_reward]: -964.634424668951
[32m[0511 07:35:29 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:29 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:29 @base_trainer.py:216][0m Mean reward: -1160.2506916856037
[32m[0511 07:35:30 @base_main.py:38][0m --------------- Iteration 63 ---------------
[32m[0511 07:35:30 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7887 mins
[32m[0511 07:35:30 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0511 07:35:30 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 07:35:30 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:30 @base_main.py:47][0m 63315 total steps have happened
[32m[0511 07:35:30 @base_main.py:52][0m [avg_reward]: -1160.2506916856037
[32m[0511 07:35:30 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:30 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:30 @base_trainer.py:216][0m Mean reward: -1164.6632097565248
[32m[0511 07:35:31 @base_main.py:38][0m --------------- Iteration 64 ---------------
[32m[0511 07:35:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8019 mins
[32m[0511 07:35:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 07:35:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 07:35:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:31 @base_main.py:47][0m 64320 total steps have happened
[32m[0511 07:35:31 @base_main.py:52][0m [avg_reward]: -1164.6632097565248
[32m[0511 07:35:31 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:31 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:31 @base_trainer.py:216][0m Mean reward: -1172.5019996822587
[32m[0511 07:35:32 @base_main.py:38][0m --------------- Iteration 65 ---------------
[32m[0511 07:35:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8141 mins
[32m[0511 07:35:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 07:35:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 07:35:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:32 @base_main.py:47][0m 65325 total steps have happened
[32m[0511 07:35:32 @base_main.py:52][0m [avg_reward]: -1172.5019996822587
[32m[0511 07:35:32 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:32 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:32 @base_trainer.py:216][0m Mean reward: -1078.4421016785564
[32m[0511 07:35:32 @base_main.py:38][0m --------------- Iteration 66 ---------------
[32m[0511 07:35:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8262 mins
[32m[0511 07:35:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 07:35:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 07:35:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:32 @base_main.py:47][0m 66330 total steps have happened
[32m[0511 07:35:32 @base_main.py:52][0m [avg_reward]: -1078.4421016785564
[32m[0511 07:35:32 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:32 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:32 @base_trainer.py:216][0m Mean reward: -1145.807125497617
[32m[0511 07:35:33 @base_main.py:38][0m --------------- Iteration 67 ---------------
[32m[0511 07:35:33 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8391 mins
[32m[0511 07:35:33 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 07:35:33 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 07:35:33 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:33 @base_main.py:47][0m 67335 total steps have happened
[32m[0511 07:35:33 @base_main.py:52][0m [avg_reward]: -1145.807125497617
[32m[0511 07:35:33 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:33 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:33 @base_trainer.py:216][0m Mean reward: -1275.626823010008
[32m[0511 07:35:34 @base_main.py:38][0m --------------- Iteration 68 ---------------
[32m[0511 07:35:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8518 mins
[32m[0511 07:35:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 07:35:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 07:35:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:34 @base_main.py:47][0m 68340 total steps have happened
[32m[0511 07:35:34 @base_main.py:52][0m [avg_reward]: -1275.626823010008
[32m[0511 07:35:34 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:34 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:34 @base_trainer.py:216][0m Mean reward: -1107.5676123441485
[32m[0511 07:35:35 @base_main.py:38][0m --------------- Iteration 69 ---------------
[32m[0511 07:35:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8644 mins
[32m[0511 07:35:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 07:35:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 07:35:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:35 @base_main.py:47][0m 69345 total steps have happened
[32m[0511 07:35:35 @base_main.py:52][0m [avg_reward]: -1107.5676123441485
[32m[0511 07:35:35 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:35 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:35 @base_trainer.py:216][0m Mean reward: -1086.3012500650075
[32m[0511 07:35:35 @base_main.py:38][0m --------------- Iteration 70 ---------------
[32m[0511 07:35:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8770 mins
[32m[0511 07:35:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 07:35:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 07:35:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:35 @base_main.py:47][0m 70350 total steps have happened
[32m[0511 07:35:35 @base_main.py:52][0m [avg_reward]: -1086.3012500650075
[32m[0511 07:35:36 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:36 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:36 @base_trainer.py:216][0m Mean reward: -1131.0634909569792
[32m[0511 07:35:36 @base_main.py:38][0m --------------- Iteration 71 ---------------
[32m[0511 07:35:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8898 mins
[32m[0511 07:35:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 07:35:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 07:35:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:36 @base_main.py:47][0m 71355 total steps have happened
[32m[0511 07:35:36 @base_main.py:52][0m [avg_reward]: -1131.0634909569792
[32m[0511 07:35:36 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:36 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:36 @base_trainer.py:216][0m Mean reward: -1115.6632193337564
[32m[0511 07:35:37 @base_main.py:38][0m --------------- Iteration 72 ---------------
[32m[0511 07:35:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9024 mins
[32m[0511 07:35:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 07:35:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 07:35:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:37 @base_main.py:47][0m 72360 total steps have happened
[32m[0511 07:35:37 @base_main.py:52][0m [avg_reward]: -1115.6632193337564
[32m[0511 07:35:37 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:37 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:37 @base_trainer.py:216][0m Mean reward: -992.5990451782149
[32m[0511 07:35:38 @base_main.py:38][0m --------------- Iteration 73 ---------------
[32m[0511 07:35:38 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9150 mins
[32m[0511 07:35:38 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 07:35:38 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 07:35:38 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:38 @base_main.py:47][0m 73365 total steps have happened
[32m[0511 07:35:38 @base_main.py:52][0m [avg_reward]: -992.5990451782149
[32m[0511 07:35:38 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:38 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:38 @base_trainer.py:216][0m Mean reward: -1091.8738258590815
[32m[0511 07:35:38 @base_main.py:38][0m --------------- Iteration 74 ---------------
[32m[0511 07:35:38 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9275 mins
[32m[0511 07:35:38 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 07:35:38 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 07:35:38 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:38 @base_main.py:47][0m 74370 total steps have happened
[32m[0511 07:35:38 @base_main.py:52][0m [avg_reward]: -1091.8738258590815
[32m[0511 07:35:38 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:38 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:38 @base_trainer.py:216][0m Mean reward: -1149.193584787972
[32m[0511 07:35:39 @base_main.py:38][0m --------------- Iteration 75 ---------------
[32m[0511 07:35:39 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9392 mins
[32m[0511 07:35:39 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 07:35:39 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 07:35:39 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:39 @base_main.py:47][0m 75375 total steps have happened
[32m[0511 07:35:39 @base_main.py:52][0m [avg_reward]: -1149.193584787972
[32m[0511 07:35:39 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:39 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:39 @base_trainer.py:216][0m Mean reward: -1127.9350508508262
[32m[0511 07:35:40 @base_main.py:38][0m --------------- Iteration 76 ---------------
[32m[0511 07:35:40 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9514 mins
[32m[0511 07:35:40 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 07:35:40 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 07:35:40 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:40 @base_main.py:47][0m 76380 total steps have happened
[32m[0511 07:35:40 @base_main.py:52][0m [avg_reward]: -1127.9350508508262
[32m[0511 07:35:40 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:40 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:40 @base_trainer.py:216][0m Mean reward: -1100.1516004208377
[32m[0511 07:35:41 @base_main.py:38][0m --------------- Iteration 77 ---------------
[32m[0511 07:35:41 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9636 mins
[32m[0511 07:35:41 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 07:35:41 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 07:35:41 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:41 @base_main.py:47][0m 77385 total steps have happened
[32m[0511 07:35:41 @base_main.py:52][0m [avg_reward]: -1100.1516004208377
[32m[0511 07:35:41 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:41 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:41 @base_trainer.py:216][0m Mean reward: -1134.403842226795
[32m[0511 07:35:41 @base_main.py:38][0m --------------- Iteration 78 ---------------
[32m[0511 07:35:41 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9764 mins
[32m[0511 07:35:41 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 07:35:41 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 07:35:41 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:41 @base_main.py:47][0m 78390 total steps have happened
[32m[0511 07:35:41 @base_main.py:52][0m [avg_reward]: -1134.403842226795
[32m[0511 07:35:41 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:41 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:41 @base_trainer.py:216][0m Mean reward: -1111.211948769725
[32m[0511 07:35:42 @base_main.py:38][0m --------------- Iteration 79 ---------------
[32m[0511 07:35:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9887 mins
[32m[0511 07:35:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 07:35:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0511 07:35:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:42 @base_main.py:47][0m 79395 total steps have happened
[32m[0511 07:35:42 @base_main.py:52][0m [avg_reward]: -1111.211948769725
[32m[0511 07:35:42 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:42 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:42 @base_trainer.py:216][0m Mean reward: -1131.0378092316892
[32m[0511 07:35:43 @base_main.py:38][0m --------------- Iteration 80 ---------------
[32m[0511 07:35:43 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0005 mins
[32m[0511 07:35:43 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 07:35:43 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 07:35:43 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:43 @base_main.py:47][0m 80400 total steps have happened
[32m[0511 07:35:43 @base_main.py:52][0m [avg_reward]: -1131.0378092316892
[32m[0511 07:35:43 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:43 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:43 @base_trainer.py:216][0m Mean reward: -1140.5327300470312
[32m[0511 07:35:44 @base_main.py:38][0m --------------- Iteration 81 ---------------
[32m[0511 07:35:44 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0129 mins
[32m[0511 07:35:44 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 07:35:44 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 07:35:44 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:44 @base_main.py:47][0m 81405 total steps have happened
[32m[0511 07:35:44 @base_main.py:52][0m [avg_reward]: -1140.5327300470312
[32m[0511 07:35:44 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:44 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:44 @base_trainer.py:216][0m Mean reward: -1008.1857030500387
[32m[0511 07:35:44 @base_main.py:38][0m --------------- Iteration 82 ---------------
[32m[0511 07:35:44 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0258 mins
[32m[0511 07:35:44 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 07:35:44 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 07:35:44 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:44 @base_main.py:47][0m 82410 total steps have happened
[32m[0511 07:35:44 @base_main.py:52][0m [avg_reward]: -1008.1857030500387
[32m[0511 07:35:44 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:44 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:44 @base_trainer.py:216][0m Mean reward: -1220.6193351790375
[32m[0511 07:35:45 @base_main.py:38][0m --------------- Iteration 83 ---------------
[32m[0511 07:35:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0383 mins
[32m[0511 07:35:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 07:35:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 07:35:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:45 @base_main.py:47][0m 83415 total steps have happened
[32m[0511 07:35:45 @base_main.py:52][0m [avg_reward]: -1220.6193351790375
[32m[0511 07:35:45 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:45 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:45 @base_trainer.py:216][0m Mean reward: -1180.4103418427508
[32m[0511 07:35:46 @base_main.py:38][0m --------------- Iteration 84 ---------------
[32m[0511 07:35:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0507 mins
[32m[0511 07:35:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 07:35:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 07:35:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:46 @base_main.py:47][0m 84420 total steps have happened
[32m[0511 07:35:46 @base_main.py:52][0m [avg_reward]: -1180.4103418427508
[32m[0511 07:35:46 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:46 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:46 @base_trainer.py:216][0m Mean reward: -1131.9783283702247
[32m[0511 07:35:46 @base_main.py:38][0m --------------- Iteration 85 ---------------
[32m[0511 07:35:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0629 mins
[32m[0511 07:35:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 07:35:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 07:35:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:46 @base_main.py:47][0m 85425 total steps have happened
[32m[0511 07:35:46 @base_main.py:52][0m [avg_reward]: -1131.9783283702247
[32m[0511 07:35:47 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:47 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:47 @base_trainer.py:216][0m Mean reward: -1166.0179058006386
[32m[0511 07:35:47 @base_main.py:38][0m --------------- Iteration 86 ---------------
[32m[0511 07:35:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0753 mins
[32m[0511 07:35:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 07:35:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 07:35:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:47 @base_main.py:47][0m 86430 total steps have happened
[32m[0511 07:35:47 @base_main.py:52][0m [avg_reward]: -1166.0179058006386
[32m[0511 07:35:47 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:47 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:47 @base_trainer.py:216][0m Mean reward: -1174.452861392259
[32m[0511 07:35:48 @base_main.py:38][0m --------------- Iteration 87 ---------------
[32m[0511 07:35:48 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0883 mins
[32m[0511 07:35:48 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 07:35:48 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 07:35:48 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:48 @base_main.py:47][0m 87435 total steps have happened
[32m[0511 07:35:48 @base_main.py:52][0m [avg_reward]: -1174.452861392259
[32m[0511 07:35:48 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:48 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:48 @base_trainer.py:216][0m Mean reward: -1231.3725663549617
[32m[0511 07:35:49 @base_main.py:38][0m --------------- Iteration 88 ---------------
[32m[0511 07:35:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1012 mins
[32m[0511 07:35:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 07:35:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 07:35:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:49 @base_main.py:47][0m 88440 total steps have happened
[32m[0511 07:35:49 @base_main.py:52][0m [avg_reward]: -1231.3725663549617
[32m[0511 07:35:49 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:49 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:49 @base_trainer.py:216][0m Mean reward: -1141.5112574173563
[32m[0511 07:35:50 @base_main.py:38][0m --------------- Iteration 89 ---------------
[32m[0511 07:35:50 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1141 mins
[32m[0511 07:35:50 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 07:35:50 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 07:35:50 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:50 @base_main.py:47][0m 89445 total steps have happened
[32m[0511 07:35:50 @base_main.py:52][0m [avg_reward]: -1141.5112574173563
[32m[0511 07:35:50 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:50 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:50 @base_trainer.py:216][0m Mean reward: -1215.3515169229975
[32m[0511 07:35:50 @base_main.py:38][0m --------------- Iteration 90 ---------------
[32m[0511 07:35:50 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1266 mins
[32m[0511 07:35:50 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 07:35:50 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 07:35:50 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:50 @base_main.py:47][0m 90450 total steps have happened
[32m[0511 07:35:50 @base_main.py:52][0m [avg_reward]: -1215.3515169229975
[32m[0511 07:35:50 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:50 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:50 @base_trainer.py:216][0m Mean reward: -1278.1070606318247
[32m[0511 07:35:51 @base_main.py:38][0m --------------- Iteration 91 ---------------
[32m[0511 07:35:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1394 mins
[32m[0511 07:35:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 07:35:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 07:35:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:51 @base_main.py:47][0m 91455 total steps have happened
[32m[0511 07:35:51 @base_main.py:52][0m [avg_reward]: -1278.1070606318247
[32m[0511 07:35:51 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:51 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:51 @base_trainer.py:216][0m Mean reward: -1173.6844016388443
[32m[0511 07:35:52 @base_main.py:38][0m --------------- Iteration 92 ---------------
[32m[0511 07:35:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1519 mins
[32m[0511 07:35:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 07:35:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 07:35:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:52 @base_main.py:47][0m 92460 total steps have happened
[32m[0511 07:35:52 @base_main.py:52][0m [avg_reward]: -1173.6844016388443
[32m[0511 07:35:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:52 @base_trainer.py:216][0m Mean reward: -1121.1382143028939
[32m[0511 07:35:53 @base_main.py:38][0m --------------- Iteration 93 ---------------
[32m[0511 07:35:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1650 mins
[32m[0511 07:35:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 07:35:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 07:35:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:53 @base_main.py:47][0m 93465 total steps have happened
[32m[0511 07:35:53 @base_main.py:52][0m [avg_reward]: -1121.1382143028939
[32m[0511 07:35:53 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:53 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:53 @base_trainer.py:216][0m Mean reward: -1135.439082222857
[32m[0511 07:35:53 @base_main.py:38][0m --------------- Iteration 94 ---------------
[32m[0511 07:35:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1768 mins
[32m[0511 07:35:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 07:35:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 07:35:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:53 @base_main.py:47][0m 94470 total steps have happened
[32m[0511 07:35:53 @base_main.py:52][0m [avg_reward]: -1135.439082222857
[32m[0511 07:35:53 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:53 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:53 @base_trainer.py:216][0m Mean reward: -1264.3305400064862
[32m[0511 07:35:54 @base_main.py:38][0m --------------- Iteration 95 ---------------
[32m[0511 07:35:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1898 mins
[32m[0511 07:35:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 07:35:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 07:35:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:54 @base_main.py:47][0m 95475 total steps have happened
[32m[0511 07:35:54 @base_main.py:52][0m [avg_reward]: -1264.3305400064862
[32m[0511 07:35:54 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:54 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:54 @base_trainer.py:216][0m Mean reward: -1204.4514495869857
[32m[0511 07:35:55 @base_main.py:38][0m --------------- Iteration 96 ---------------
[32m[0511 07:35:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2024 mins
[32m[0511 07:35:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 07:35:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 07:35:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:55 @base_main.py:47][0m 96480 total steps have happened
[32m[0511 07:35:55 @base_main.py:52][0m [avg_reward]: -1204.4514495869857
[32m[0511 07:35:55 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:55 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:55 @base_trainer.py:216][0m Mean reward: -1143.0761171032125
[32m[0511 07:35:56 @base_main.py:38][0m --------------- Iteration 97 ---------------
[32m[0511 07:35:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2152 mins
[32m[0511 07:35:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 07:35:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 07:35:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:56 @base_main.py:47][0m 97485 total steps have happened
[32m[0511 07:35:56 @base_main.py:52][0m [avg_reward]: -1143.0761171032125
[32m[0511 07:35:56 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:56 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:56 @base_trainer.py:216][0m Mean reward: -1227.193829047656
[32m[0511 07:35:56 @base_main.py:38][0m --------------- Iteration 98 ---------------
[32m[0511 07:35:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2280 mins
[32m[0511 07:35:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 07:35:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 07:35:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:56 @base_main.py:47][0m 98490 total steps have happened
[32m[0511 07:35:56 @base_main.py:52][0m [avg_reward]: -1227.193829047656
[32m[0511 07:35:57 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:57 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:57 @base_trainer.py:216][0m Mean reward: -1171.6919977206576
[32m[0511 07:35:57 @base_main.py:38][0m --------------- Iteration 99 ---------------
[32m[0511 07:35:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2408 mins
[32m[0511 07:35:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 07:35:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 07:35:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:57 @base_main.py:47][0m 99495 total steps have happened
[32m[0511 07:35:57 @base_main.py:52][0m [avg_reward]: -1171.6919977206576
[32m[0511 07:35:57 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:57 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:57 @base_trainer.py:216][0m Mean reward: -1246.0919330145264
[32m[0511 07:35:58 @base_main.py:38][0m --------------- Iteration 100 ---------------
[32m[0511 07:35:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2530 mins
[32m[0511 07:35:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0511 07:35:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 07:35:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:58 @base_main.py:47][0m 100500 total steps have happened
[32m[0511 07:35:58 @base_main.py:52][0m [avg_reward]: -1246.0919330145264
[32m[0511 07:35:58 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:58 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:58 @base_trainer.py:216][0m Mean reward: -1189.9821815432358
[32m[0511 07:35:59 @base_main.py:38][0m --------------- Iteration 101 ---------------
[32m[0511 07:35:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2663 mins
[32m[0511 07:35:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 07:35:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 07:35:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:59 @base_main.py:47][0m 101505 total steps have happened
[32m[0511 07:35:59 @base_main.py:52][0m [avg_reward]: -1189.9821815432358
[32m[0511 07:35:59 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:35:59 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:35:59 @base_trainer.py:216][0m Mean reward: -1180.6492682128521
[32m[0511 07:35:59 @base_main.py:38][0m --------------- Iteration 102 ---------------
[32m[0511 07:35:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2788 mins
[32m[0511 07:35:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 07:35:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 07:35:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:35:59 @base_main.py:47][0m 102510 total steps have happened
[32m[0511 07:35:59 @base_main.py:52][0m [avg_reward]: -1180.6492682128521
[32m[0511 07:36:00 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:00 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:00 @base_trainer.py:216][0m Mean reward: -1237.3343779117874
[32m[0511 07:36:00 @base_main.py:38][0m --------------- Iteration 103 ---------------
[32m[0511 07:36:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2906 mins
[32m[0511 07:36:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0511 07:36:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 07:36:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:00 @base_main.py:47][0m 103515 total steps have happened
[32m[0511 07:36:00 @base_main.py:52][0m [avg_reward]: -1237.3343779117874
[32m[0511 07:36:00 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:00 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:00 @base_trainer.py:216][0m Mean reward: -1199.5558992185083
[32m[0511 07:36:01 @base_main.py:38][0m --------------- Iteration 104 ---------------
[32m[0511 07:36:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3036 mins
[32m[0511 07:36:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 07:36:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 07:36:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:01 @base_main.py:47][0m 104520 total steps have happened
[32m[0511 07:36:01 @base_main.py:52][0m [avg_reward]: -1199.5558992185083
[32m[0511 07:36:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:01 @base_trainer.py:216][0m Mean reward: -1113.8436222823575
[32m[0511 07:36:02 @base_main.py:38][0m --------------- Iteration 105 ---------------
[32m[0511 07:36:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3161 mins
[32m[0511 07:36:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 07:36:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 07:36:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:02 @base_main.py:47][0m 105525 total steps have happened
[32m[0511 07:36:02 @base_main.py:52][0m [avg_reward]: -1113.8436222823575
[32m[0511 07:36:02 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:02 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:02 @base_trainer.py:216][0m Mean reward: -1188.2363802569748
[32m[0511 07:36:02 @base_main.py:38][0m --------------- Iteration 106 ---------------
[32m[0511 07:36:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3287 mins
[32m[0511 07:36:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 07:36:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 07:36:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:02 @base_main.py:47][0m 106530 total steps have happened
[32m[0511 07:36:02 @base_main.py:52][0m [avg_reward]: -1188.2363802569748
[32m[0511 07:36:03 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:03 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:03 @base_trainer.py:216][0m Mean reward: -1147.178895634734
[32m[0511 07:36:03 @base_main.py:38][0m --------------- Iteration 107 ---------------
[32m[0511 07:36:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3408 mins
[32m[0511 07:36:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 07:36:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 07:36:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:03 @base_main.py:47][0m 107535 total steps have happened
[32m[0511 07:36:03 @base_main.py:52][0m [avg_reward]: -1147.178895634734
[32m[0511 07:36:03 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:03 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:03 @base_trainer.py:216][0m Mean reward: -1358.7229599776133
[32m[0511 07:36:04 @base_main.py:38][0m --------------- Iteration 108 ---------------
[32m[0511 07:36:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3533 mins
[32m[0511 07:36:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 07:36:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 07:36:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:04 @base_main.py:47][0m 108540 total steps have happened
[32m[0511 07:36:04 @base_main.py:52][0m [avg_reward]: -1358.7229599776133
[32m[0511 07:36:04 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:04 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:04 @base_trainer.py:216][0m Mean reward: -1205.6633815399614
[32m[0511 07:36:05 @base_main.py:38][0m --------------- Iteration 109 ---------------
[32m[0511 07:36:05 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3655 mins
[32m[0511 07:36:05 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 07:36:05 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 07:36:05 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:05 @base_main.py:47][0m 109545 total steps have happened
[32m[0511 07:36:05 @base_main.py:52][0m [avg_reward]: -1205.6633815399614
[32m[0511 07:36:05 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:05 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:05 @base_trainer.py:216][0m Mean reward: -1221.065591705741
[32m[0511 07:36:05 @base_main.py:38][0m --------------- Iteration 110 ---------------
[32m[0511 07:36:05 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3775 mins
[32m[0511 07:36:05 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 07:36:05 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 07:36:05 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:05 @base_main.py:47][0m 110550 total steps have happened
[32m[0511 07:36:05 @base_main.py:52][0m [avg_reward]: -1221.065591705741
[32m[0511 07:36:06 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:06 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:06 @base_trainer.py:216][0m Mean reward: -1224.2361729409022
[32m[0511 07:36:06 @base_main.py:38][0m --------------- Iteration 111 ---------------
[32m[0511 07:36:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3903 mins
[32m[0511 07:36:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 07:36:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 07:36:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:06 @base_main.py:47][0m 111555 total steps have happened
[32m[0511 07:36:06 @base_main.py:52][0m [avg_reward]: -1224.2361729409022
[32m[0511 07:36:06 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:06 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:06 @base_trainer.py:216][0m Mean reward: -1297.3533205055105
[32m[0511 07:36:07 @base_main.py:38][0m --------------- Iteration 112 ---------------
[32m[0511 07:36:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4027 mins
[32m[0511 07:36:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 07:36:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 07:36:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:07 @base_main.py:47][0m 112560 total steps have happened
[32m[0511 07:36:07 @base_main.py:52][0m [avg_reward]: -1297.3533205055105
[32m[0511 07:36:07 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:07 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:07 @base_trainer.py:216][0m Mean reward: -1162.9505724402852
[32m[0511 07:36:08 @base_main.py:38][0m --------------- Iteration 113 ---------------
[32m[0511 07:36:08 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4156 mins
[32m[0511 07:36:08 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 07:36:08 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 07:36:08 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:08 @base_main.py:47][0m 113565 total steps have happened
[32m[0511 07:36:08 @base_main.py:52][0m [avg_reward]: -1162.9505724402852
[32m[0511 07:36:08 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:08 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:08 @base_trainer.py:216][0m Mean reward: -1178.2922419549782
[32m[0511 07:36:08 @base_main.py:38][0m --------------- Iteration 114 ---------------
[32m[0511 07:36:08 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4280 mins
[32m[0511 07:36:08 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 07:36:08 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 07:36:08 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:08 @base_main.py:47][0m 114570 total steps have happened
[32m[0511 07:36:08 @base_main.py:52][0m [avg_reward]: -1178.2922419549782
[32m[0511 07:36:09 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:09 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:09 @base_trainer.py:216][0m Mean reward: -1208.7090879322022
[32m[0511 07:36:09 @base_main.py:38][0m --------------- Iteration 115 ---------------
[32m[0511 07:36:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4410 mins
[32m[0511 07:36:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 07:36:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 07:36:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:09 @base_main.py:47][0m 115575 total steps have happened
[32m[0511 07:36:09 @base_main.py:52][0m [avg_reward]: -1208.7090879322022
[32m[0511 07:36:09 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:09 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:09 @base_trainer.py:216][0m Mean reward: -1238.4432227543891
[32m[0511 07:36:10 @base_main.py:38][0m --------------- Iteration 116 ---------------
[32m[0511 07:36:10 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4535 mins
[32m[0511 07:36:10 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 07:36:10 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0511 07:36:10 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:10 @base_main.py:47][0m 116580 total steps have happened
[32m[0511 07:36:10 @base_main.py:52][0m [avg_reward]: -1238.4432227543891
[32m[0511 07:36:10 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:10 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:10 @base_trainer.py:216][0m Mean reward: -1159.9679006440704
[32m[0511 07:36:11 @base_main.py:38][0m --------------- Iteration 117 ---------------
[32m[0511 07:36:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4652 mins
[32m[0511 07:36:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 07:36:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 07:36:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:11 @base_main.py:47][0m 117585 total steps have happened
[32m[0511 07:36:11 @base_main.py:52][0m [avg_reward]: -1159.9679006440704
[32m[0511 07:36:11 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:11 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:11 @base_trainer.py:216][0m Mean reward: -1158.648781364027
[32m[0511 07:36:11 @base_main.py:38][0m --------------- Iteration 118 ---------------
[32m[0511 07:36:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4772 mins
[32m[0511 07:36:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 07:36:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 07:36:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:11 @base_main.py:47][0m 118590 total steps have happened
[32m[0511 07:36:11 @base_main.py:52][0m [avg_reward]: -1158.648781364027
[32m[0511 07:36:12 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:12 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:12 @base_trainer.py:216][0m Mean reward: -1162.556178049889
[32m[0511 07:36:12 @base_main.py:38][0m --------------- Iteration 119 ---------------
[32m[0511 07:36:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4898 mins
[32m[0511 07:36:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 07:36:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 07:36:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:12 @base_main.py:47][0m 119595 total steps have happened
[32m[0511 07:36:12 @base_main.py:52][0m [avg_reward]: -1162.556178049889
[32m[0511 07:36:12 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:12 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:12 @base_trainer.py:216][0m Mean reward: -1167.0551153235288
[32m[0511 07:36:13 @base_main.py:38][0m --------------- Iteration 120 ---------------
[32m[0511 07:36:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5019 mins
[32m[0511 07:36:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 07:36:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 07:36:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:13 @base_main.py:47][0m 120600 total steps have happened
[32m[0511 07:36:13 @base_main.py:52][0m [avg_reward]: -1167.0551153235288
[32m[0511 07:36:13 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:13 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:13 @base_trainer.py:216][0m Mean reward: -1296.5699824152566
[32m[0511 07:36:14 @base_main.py:38][0m --------------- Iteration 121 ---------------
[32m[0511 07:36:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5144 mins
[32m[0511 07:36:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 07:36:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 07:36:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:14 @base_main.py:47][0m 121605 total steps have happened
[32m[0511 07:36:14 @base_main.py:52][0m [avg_reward]: -1296.5699824152566
[32m[0511 07:36:14 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:14 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:14 @base_trainer.py:216][0m Mean reward: -1292.3594887017632
[32m[0511 07:36:14 @base_main.py:38][0m --------------- Iteration 122 ---------------
[32m[0511 07:36:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5272 mins
[32m[0511 07:36:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 07:36:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 07:36:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:14 @base_main.py:47][0m 122610 total steps have happened
[32m[0511 07:36:14 @base_main.py:52][0m [avg_reward]: -1292.3594887017632
[32m[0511 07:36:14 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:14 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:14 @base_trainer.py:216][0m Mean reward: -1061.958124677847
[32m[0511 07:36:15 @base_main.py:38][0m --------------- Iteration 123 ---------------
[32m[0511 07:36:15 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5396 mins
[32m[0511 07:36:15 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 07:36:15 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 07:36:15 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:15 @base_main.py:47][0m 123615 total steps have happened
[32m[0511 07:36:15 @base_main.py:52][0m [avg_reward]: -1061.958124677847
[32m[0511 07:36:15 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:15 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:15 @base_trainer.py:216][0m Mean reward: -1154.32915451252
[32m[0511 07:36:16 @base_main.py:38][0m --------------- Iteration 124 ---------------
[32m[0511 07:36:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5520 mins
[32m[0511 07:36:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 07:36:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 07:36:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:16 @base_main.py:47][0m 124620 total steps have happened
[32m[0511 07:36:16 @base_main.py:52][0m [avg_reward]: -1154.32915451252
[32m[0511 07:36:16 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:16 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:16 @base_trainer.py:216][0m Mean reward: -972.6384080973094
[32m[0511 07:36:17 @base_main.py:38][0m --------------- Iteration 125 ---------------
[32m[0511 07:36:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5647 mins
[32m[0511 07:36:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 07:36:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 07:36:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:17 @base_main.py:47][0m 125625 total steps have happened
[32m[0511 07:36:17 @base_main.py:52][0m [avg_reward]: -972.6384080973094
[32m[0511 07:36:17 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:17 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:17 @base_trainer.py:216][0m Mean reward: -1126.0217640705446
[32m[0511 07:36:17 @base_main.py:38][0m --------------- Iteration 126 ---------------
[32m[0511 07:36:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5776 mins
[32m[0511 07:36:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 07:36:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 07:36:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:17 @base_main.py:47][0m 126630 total steps have happened
[32m[0511 07:36:17 @base_main.py:52][0m [avg_reward]: -1126.0217640705446
[32m[0511 07:36:18 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:18 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:18 @base_trainer.py:216][0m Mean reward: -1083.35457653995
[32m[0511 07:36:18 @base_main.py:38][0m --------------- Iteration 127 ---------------
[32m[0511 07:36:18 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5901 mins
[32m[0511 07:36:18 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 07:36:18 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0511 07:36:18 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:18 @base_main.py:47][0m 127635 total steps have happened
[32m[0511 07:36:18 @base_main.py:52][0m [avg_reward]: -1083.35457653995
[32m[0511 07:36:18 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:18 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:18 @base_trainer.py:216][0m Mean reward: -1103.8945504578041
[32m[0511 07:36:19 @base_main.py:38][0m --------------- Iteration 128 ---------------
[32m[0511 07:36:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6019 mins
[32m[0511 07:36:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 07:36:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 07:36:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:19 @base_main.py:47][0m 128640 total steps have happened
[32m[0511 07:36:19 @base_main.py:52][0m [avg_reward]: -1103.8945504578041
[32m[0511 07:36:19 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:19 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:19 @base_trainer.py:216][0m Mean reward: -987.3376615734833
[32m[0511 07:36:20 @base_main.py:38][0m --------------- Iteration 129 ---------------
[32m[0511 07:36:20 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6146 mins
[32m[0511 07:36:20 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0018 mins
[32m[0511 07:36:20 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 07:36:20 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:20 @base_main.py:47][0m 129645 total steps have happened
[32m[0511 07:36:20 @base_main.py:52][0m [avg_reward]: -987.3376615734833
[32m[0511 07:36:20 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:20 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:20 @base_trainer.py:216][0m Mean reward: -1049.637921455026
[32m[0511 07:36:20 @base_main.py:38][0m --------------- Iteration 130 ---------------
[32m[0511 07:36:20 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6268 mins
[32m[0511 07:36:20 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 07:36:20 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 07:36:20 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:20 @base_main.py:47][0m 130650 total steps have happened
[32m[0511 07:36:20 @base_main.py:52][0m [avg_reward]: -1049.637921455026
[32m[0511 07:36:20 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:20 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:20 @base_trainer.py:216][0m Mean reward: -1096.308217850222
[32m[0511 07:36:21 @base_main.py:38][0m --------------- Iteration 131 ---------------
[32m[0511 07:36:21 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6394 mins
[32m[0511 07:36:21 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 07:36:21 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 07:36:21 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:21 @base_main.py:47][0m 131655 total steps have happened
[32m[0511 07:36:21 @base_main.py:52][0m [avg_reward]: -1096.308217850222
[32m[0511 07:36:21 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:21 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:21 @base_trainer.py:216][0m Mean reward: -1007.6896712384245
[32m[0511 07:36:22 @base_main.py:38][0m --------------- Iteration 132 ---------------
[32m[0511 07:36:22 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6521 mins
[32m[0511 07:36:22 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0511 07:36:22 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0511 07:36:22 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0511 07:36:22 @base_main.py:47][0m 132660 total steps have happened
[32m[0511 07:36:22 @base_main.py:52][0m [avg_reward]: -1007.6896712384245
[32m[0511 07:36:22 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:22 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:22 @base_trainer.py:216][0m Mean reward: -967.7911840247525
[32m[0511 07:36:23 @base_main.py:38][0m --------------- Iteration 133 ---------------
[32m[0511 07:36:23 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6644 mins
[32m[0511 07:36:23 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 07:36:23 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0511 07:36:23 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:23 @base_main.py:47][0m 133665 total steps have happened
[32m[0511 07:36:23 @base_main.py:52][0m [avg_reward]: -967.7911840247525
[32m[0511 07:36:23 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:23 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:23 @base_trainer.py:216][0m Mean reward: -1036.9452327857784
[32m[0511 07:36:23 @base_main.py:38][0m --------------- Iteration 134 ---------------
[32m[0511 07:36:23 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6760 mins
[32m[0511 07:36:23 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 07:36:23 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 07:36:23 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:23 @base_main.py:47][0m 134670 total steps have happened
[32m[0511 07:36:23 @base_main.py:52][0m [avg_reward]: -1036.9452327857784
[32m[0511 07:36:23 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:23 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:23 @base_trainer.py:216][0m Mean reward: -1034.886076389693
[32m[0511 07:36:24 @base_main.py:38][0m --------------- Iteration 135 ---------------
[32m[0511 07:36:24 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6886 mins
[32m[0511 07:36:24 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 07:36:24 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 07:36:24 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:24 @base_main.py:47][0m 135675 total steps have happened
[32m[0511 07:36:24 @base_main.py:52][0m [avg_reward]: -1034.886076389693
[32m[0511 07:36:24 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:24 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:24 @base_trainer.py:216][0m Mean reward: -1031.161084107423
[32m[0511 07:36:25 @base_main.py:38][0m --------------- Iteration 136 ---------------
[32m[0511 07:36:25 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7009 mins
[32m[0511 07:36:25 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 07:36:25 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 07:36:25 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:25 @base_main.py:47][0m 136680 total steps have happened
[32m[0511 07:36:25 @base_main.py:52][0m [avg_reward]: -1031.161084107423
[32m[0511 07:36:25 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:25 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:25 @base_trainer.py:216][0m Mean reward: -990.9896296074306
[32m[0511 07:36:25 @base_main.py:38][0m --------------- Iteration 137 ---------------
[32m[0511 07:36:25 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7127 mins
[32m[0511 07:36:25 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 07:36:25 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 07:36:25 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:25 @base_main.py:47][0m 137685 total steps have happened
[32m[0511 07:36:25 @base_main.py:52][0m [avg_reward]: -990.9896296074306
[32m[0511 07:36:26 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:26 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:26 @base_trainer.py:216][0m Mean reward: -990.4535629550548
[32m[0511 07:36:26 @base_main.py:38][0m --------------- Iteration 138 ---------------
[32m[0511 07:36:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7251 mins
[32m[0511 07:36:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 07:36:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 07:36:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:26 @base_main.py:47][0m 138690 total steps have happened
[32m[0511 07:36:26 @base_main.py:52][0m [avg_reward]: -990.4535629550548
[32m[0511 07:36:26 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:26 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:26 @base_trainer.py:216][0m Mean reward: -1013.7985009240394
[32m[0511 07:36:27 @base_main.py:38][0m --------------- Iteration 139 ---------------
[32m[0511 07:36:27 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7374 mins
[32m[0511 07:36:27 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 07:36:27 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 07:36:27 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:27 @base_main.py:47][0m 139695 total steps have happened
[32m[0511 07:36:27 @base_main.py:52][0m [avg_reward]: -1013.7985009240394
[32m[0511 07:36:27 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:27 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:27 @base_trainer.py:216][0m Mean reward: -974.725854566396
[32m[0511 07:36:28 @base_main.py:38][0m --------------- Iteration 140 ---------------
[32m[0511 07:36:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7498 mins
[32m[0511 07:36:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 07:36:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 07:36:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:28 @base_main.py:47][0m 140700 total steps have happened
[32m[0511 07:36:28 @base_main.py:52][0m [avg_reward]: -974.725854566396
[32m[0511 07:36:28 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:28 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:28 @base_trainer.py:216][0m Mean reward: -934.7152331372112
[32m[0511 07:36:28 @base_main.py:38][0m --------------- Iteration 141 ---------------
[32m[0511 07:36:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7617 mins
[32m[0511 07:36:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 07:36:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0511 07:36:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:28 @base_main.py:47][0m 141705 total steps have happened
[32m[0511 07:36:28 @base_main.py:52][0m [avg_reward]: -934.7152331372112
[32m[0511 07:36:29 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:29 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:29 @base_trainer.py:216][0m Mean reward: -996.9796112980694
[32m[0511 07:36:29 @base_main.py:38][0m --------------- Iteration 142 ---------------
[32m[0511 07:36:29 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7737 mins
[32m[0511 07:36:29 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 07:36:29 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0511 07:36:29 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:29 @base_main.py:47][0m 142710 total steps have happened
[32m[0511 07:36:29 @base_main.py:52][0m [avg_reward]: -996.9796112980694
[32m[0511 07:36:29 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:29 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:29 @base_trainer.py:216][0m Mean reward: -986.6603124576483
[32m[0511 07:36:30 @base_main.py:38][0m --------------- Iteration 143 ---------------
[32m[0511 07:36:30 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7855 mins
[32m[0511 07:36:30 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 07:36:30 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 07:36:30 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:30 @base_main.py:47][0m 143715 total steps have happened
[32m[0511 07:36:30 @base_main.py:52][0m [avg_reward]: -986.6603124576483
[32m[0511 07:36:30 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:30 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:30 @base_trainer.py:216][0m Mean reward: -863.9189515375463
[32m[0511 07:36:31 @base_main.py:38][0m --------------- Iteration 144 ---------------
[32m[0511 07:36:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7981 mins
[32m[0511 07:36:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 07:36:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 07:36:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:31 @base_main.py:47][0m 144720 total steps have happened
[32m[0511 07:36:31 @base_main.py:52][0m [avg_reward]: -863.9189515375463
[32m[0511 07:36:31 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:31 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:31 @base_trainer.py:216][0m Mean reward: -967.435728136554
[32m[0511 07:36:31 @base_main.py:38][0m --------------- Iteration 145 ---------------
[32m[0511 07:36:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8101 mins
[32m[0511 07:36:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 07:36:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 07:36:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:31 @base_main.py:47][0m 145725 total steps have happened
[32m[0511 07:36:31 @base_main.py:52][0m [avg_reward]: -967.435728136554
[32m[0511 07:36:31 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:31 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:31 @base_trainer.py:216][0m Mean reward: -955.7364999279796
[32m[0511 07:36:32 @base_main.py:38][0m --------------- Iteration 146 ---------------
[32m[0511 07:36:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8224 mins
[32m[0511 07:36:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 07:36:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 07:36:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:32 @base_main.py:47][0m 146730 total steps have happened
[32m[0511 07:36:32 @base_main.py:52][0m [avg_reward]: -955.7364999279796
[32m[0511 07:36:32 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:32 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:32 @base_trainer.py:216][0m Mean reward: -984.971322584936
[32m[0511 07:36:33 @base_main.py:38][0m --------------- Iteration 147 ---------------
[32m[0511 07:36:33 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8350 mins
[32m[0511 07:36:33 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 07:36:33 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 07:36:33 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:33 @base_main.py:47][0m 147735 total steps have happened
[32m[0511 07:36:33 @base_main.py:52][0m [avg_reward]: -984.971322584936
[32m[0511 07:36:33 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:33 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:33 @base_trainer.py:216][0m Mean reward: -972.7879202436201
[32m[0511 07:36:34 @base_main.py:38][0m --------------- Iteration 148 ---------------
[32m[0511 07:36:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8478 mins
[32m[0511 07:36:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 07:36:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 07:36:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:34 @base_main.py:47][0m 148740 total steps have happened
[32m[0511 07:36:34 @base_main.py:52][0m [avg_reward]: -972.7879202436201
[32m[0511 07:36:34 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:34 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:34 @base_trainer.py:216][0m Mean reward: -897.2965989273486
[32m[0511 07:36:34 @base_main.py:38][0m --------------- Iteration 149 ---------------
[32m[0511 07:36:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8599 mins
[32m[0511 07:36:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 07:36:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 07:36:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:34 @base_main.py:47][0m 149745 total steps have happened
[32m[0511 07:36:34 @base_main.py:52][0m [avg_reward]: -897.2965989273486
[32m[0511 07:36:34 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:34 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:34 @base_trainer.py:216][0m Mean reward: -1014.1450487304128
[32m[0511 07:36:35 @base_main.py:38][0m --------------- Iteration 150 ---------------
[32m[0511 07:36:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8716 mins
[32m[0511 07:36:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 07:36:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 07:36:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:35 @base_main.py:47][0m 150750 total steps have happened
[32m[0511 07:36:35 @base_main.py:52][0m [avg_reward]: -1014.1450487304128
[32m[0511 07:36:35 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:35 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:35 @base_trainer.py:216][0m Mean reward: -1119.0047658178084
[32m[0511 07:36:36 @base_main.py:38][0m --------------- Iteration 151 ---------------
[32m[0511 07:36:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8845 mins
[32m[0511 07:36:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 07:36:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 07:36:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:36 @base_main.py:47][0m 151755 total steps have happened
[32m[0511 07:36:36 @base_main.py:52][0m [avg_reward]: -1119.0047658178084
[32m[0511 07:36:36 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:36 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:36 @base_trainer.py:216][0m Mean reward: -999.9636524438004
[32m[0511 07:36:37 @base_main.py:38][0m --------------- Iteration 152 ---------------
[32m[0511 07:36:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8969 mins
[32m[0511 07:36:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0511 07:36:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 07:36:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:37 @base_main.py:47][0m 152760 total steps have happened
[32m[0511 07:36:37 @base_main.py:52][0m [avg_reward]: -999.9636524438004
[32m[0511 07:36:37 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:37 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:37 @base_trainer.py:216][0m Mean reward: -1106.9703209146933
[32m[0511 07:36:37 @base_main.py:38][0m --------------- Iteration 153 ---------------
[32m[0511 07:36:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9100 mins
[32m[0511 07:36:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 07:36:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 07:36:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:37 @base_main.py:47][0m 153765 total steps have happened
[32m[0511 07:36:37 @base_main.py:52][0m [avg_reward]: -1106.9703209146933
[32m[0511 07:36:37 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:37 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:37 @base_trainer.py:216][0m Mean reward: -945.4543737494052
[32m[0511 07:36:38 @base_main.py:38][0m --------------- Iteration 154 ---------------
[32m[0511 07:36:38 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9228 mins
[32m[0511 07:36:38 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 07:36:38 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 07:36:38 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:38 @base_main.py:47][0m 154770 total steps have happened
[32m[0511 07:36:38 @base_main.py:52][0m [avg_reward]: -945.4543737494052
[32m[0511 07:36:38 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:38 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:38 @base_trainer.py:216][0m Mean reward: -953.246730771155
[32m[0511 07:36:39 @base_main.py:38][0m --------------- Iteration 155 ---------------
[32m[0511 07:36:39 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9352 mins
[32m[0511 07:36:39 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 07:36:39 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0511 07:36:39 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:39 @base_main.py:47][0m 155775 total steps have happened
[32m[0511 07:36:39 @base_main.py:52][0m [avg_reward]: -953.246730771155
[32m[0511 07:36:39 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:39 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:39 @base_trainer.py:216][0m Mean reward: -999.5544958058969
[32m[0511 07:36:40 @base_main.py:38][0m --------------- Iteration 156 ---------------
[32m[0511 07:36:40 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9469 mins
[32m[0511 07:36:40 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 07:36:40 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 07:36:40 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:40 @base_main.py:47][0m 156780 total steps have happened
[32m[0511 07:36:40 @base_main.py:52][0m [avg_reward]: -999.5544958058969
[32m[0511 07:36:40 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:40 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:40 @base_trainer.py:216][0m Mean reward: -1125.4686706388952
[32m[0511 07:36:40 @base_main.py:38][0m --------------- Iteration 157 ---------------
[32m[0511 07:36:40 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9598 mins
[32m[0511 07:36:40 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 07:36:40 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0511 07:36:40 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:40 @base_main.py:47][0m 157785 total steps have happened
[32m[0511 07:36:40 @base_main.py:52][0m [avg_reward]: -1125.4686706388952
[32m[0511 07:36:40 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:40 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:40 @base_trainer.py:216][0m Mean reward: -937.0944353227135
[32m[0511 07:36:41 @base_main.py:38][0m --------------- Iteration 158 ---------------
[32m[0511 07:36:41 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9718 mins
[32m[0511 07:36:41 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 07:36:41 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 07:36:41 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:41 @base_main.py:47][0m 158790 total steps have happened
[32m[0511 07:36:41 @base_main.py:52][0m [avg_reward]: -937.0944353227135
[32m[0511 07:36:41 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:41 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:41 @base_trainer.py:216][0m Mean reward: -900.6865140409338
[32m[0511 07:36:42 @base_main.py:38][0m --------------- Iteration 159 ---------------
[32m[0511 07:36:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9842 mins
[32m[0511 07:36:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 07:36:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 07:36:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:42 @base_main.py:47][0m 159795 total steps have happened
[32m[0511 07:36:42 @base_main.py:52][0m [avg_reward]: -900.6865140409338
[32m[0511 07:36:42 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:42 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:42 @base_trainer.py:216][0m Mean reward: -917.103205847378
[32m[0511 07:36:43 @base_main.py:38][0m --------------- Iteration 160 ---------------
[32m[0511 07:36:43 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9970 mins
[32m[0511 07:36:43 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0511 07:36:43 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 07:36:43 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:43 @base_main.py:47][0m 160800 total steps have happened
[32m[0511 07:36:43 @base_main.py:52][0m [avg_reward]: -917.103205847378
[32m[0511 07:36:43 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:43 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:43 @base_trainer.py:216][0m Mean reward: -999.8258422981016
[32m[0511 07:36:43 @base_main.py:38][0m --------------- Iteration 161 ---------------
[32m[0511 07:36:43 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0101 mins
[32m[0511 07:36:43 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0018 mins
[32m[0511 07:36:43 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 07:36:43 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:43 @base_main.py:47][0m 161805 total steps have happened
[32m[0511 07:36:43 @base_main.py:52][0m [avg_reward]: -999.8258422981016
[32m[0511 07:36:43 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:43 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:43 @base_trainer.py:216][0m Mean reward: -849.0863706556014
[32m[0511 07:36:44 @base_main.py:38][0m --------------- Iteration 162 ---------------
[32m[0511 07:36:44 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0224 mins
[32m[0511 07:36:44 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 07:36:44 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 07:36:44 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:44 @base_main.py:47][0m 162810 total steps have happened
[32m[0511 07:36:44 @base_main.py:52][0m [avg_reward]: -849.0863706556014
[32m[0511 07:36:44 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:44 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:44 @base_trainer.py:216][0m Mean reward: -1131.0528477060902
[32m[0511 07:36:45 @base_main.py:38][0m --------------- Iteration 163 ---------------
[32m[0511 07:36:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0351 mins
[32m[0511 07:36:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 07:36:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 07:36:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:45 @base_main.py:47][0m 163815 total steps have happened
[32m[0511 07:36:45 @base_main.py:52][0m [avg_reward]: -1131.0528477060902
[32m[0511 07:36:45 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:45 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:45 @base_trainer.py:216][0m Mean reward: -867.0253983913362
[32m[0511 07:36:46 @base_main.py:38][0m --------------- Iteration 164 ---------------
[32m[0511 07:36:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0476 mins
[32m[0511 07:36:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 07:36:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 07:36:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:46 @base_main.py:47][0m 164820 total steps have happened
[32m[0511 07:36:46 @base_main.py:52][0m [avg_reward]: -867.0253983913362
[32m[0511 07:36:46 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:46 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:46 @base_trainer.py:216][0m Mean reward: -942.1057145415116
[32m[0511 07:36:46 @base_main.py:38][0m --------------- Iteration 165 ---------------
[32m[0511 07:36:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0606 mins
[32m[0511 07:36:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 07:36:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 07:36:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:46 @base_main.py:47][0m 165825 total steps have happened
[32m[0511 07:36:46 @base_main.py:52][0m [avg_reward]: -942.1057145415116
[32m[0511 07:36:47 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:47 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:47 @base_trainer.py:216][0m Mean reward: -912.9029211736258
[32m[0511 07:36:47 @base_main.py:38][0m --------------- Iteration 166 ---------------
[32m[0511 07:36:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0735 mins
[32m[0511 07:36:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 07:36:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 07:36:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:47 @base_main.py:47][0m 166830 total steps have happened
[32m[0511 07:36:47 @base_main.py:52][0m [avg_reward]: -912.9029211736258
[32m[0511 07:36:47 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:47 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:47 @base_trainer.py:216][0m Mean reward: -817.1406787262079
[32m[0511 07:36:48 @base_main.py:38][0m --------------- Iteration 167 ---------------
[32m[0511 07:36:48 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0864 mins
[32m[0511 07:36:48 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 07:36:48 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 07:36:48 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:48 @base_main.py:47][0m 167835 total steps have happened
[32m[0511 07:36:48 @base_main.py:52][0m [avg_reward]: -817.1406787262079
[32m[0511 07:36:48 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:48 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:48 @base_trainer.py:216][0m Mean reward: -967.3293857293456
[32m[0511 07:36:49 @base_main.py:38][0m --------------- Iteration 168 ---------------
[32m[0511 07:36:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0993 mins
[32m[0511 07:36:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 07:36:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 07:36:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:49 @base_main.py:47][0m 168840 total steps have happened
[32m[0511 07:36:49 @base_main.py:52][0m [avg_reward]: -967.3293857293456
[32m[0511 07:36:49 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:49 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:49 @base_trainer.py:216][0m Mean reward: -1161.712982654156
[32m[0511 07:36:49 @base_main.py:38][0m --------------- Iteration 169 ---------------
[32m[0511 07:36:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1122 mins
[32m[0511 07:36:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 07:36:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 07:36:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:49 @base_main.py:47][0m 169845 total steps have happened
[32m[0511 07:36:49 @base_main.py:52][0m [avg_reward]: -1161.712982654156
[32m[0511 07:36:50 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:50 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:50 @base_trainer.py:216][0m Mean reward: -884.722831381272
[32m[0511 07:36:50 @base_main.py:38][0m --------------- Iteration 170 ---------------
[32m[0511 07:36:50 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1243 mins
[32m[0511 07:36:50 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 07:36:50 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 07:36:50 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:50 @base_main.py:47][0m 170850 total steps have happened
[32m[0511 07:36:50 @base_main.py:52][0m [avg_reward]: -884.722831381272
[32m[0511 07:36:50 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:50 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:50 @base_trainer.py:216][0m Mean reward: -930.366192025527
[32m[0511 07:36:51 @base_main.py:38][0m --------------- Iteration 171 ---------------
[32m[0511 07:36:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1366 mins
[32m[0511 07:36:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 07:36:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 07:36:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:51 @base_main.py:47][0m 171855 total steps have happened
[32m[0511 07:36:51 @base_main.py:52][0m [avg_reward]: -930.366192025527
[32m[0511 07:36:51 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:51 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:51 @base_trainer.py:216][0m Mean reward: -967.5557526892977
[32m[0511 07:36:52 @base_main.py:38][0m --------------- Iteration 172 ---------------
[32m[0511 07:36:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1491 mins
[32m[0511 07:36:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0018 mins
[32m[0511 07:36:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 07:36:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:52 @base_main.py:47][0m 172860 total steps have happened
[32m[0511 07:36:52 @base_main.py:52][0m [avg_reward]: -967.5557526892977
[32m[0511 07:36:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:52 @base_trainer.py:216][0m Mean reward: -882.3739176288869
[32m[0511 07:36:52 @base_main.py:38][0m --------------- Iteration 173 ---------------
[32m[0511 07:36:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1613 mins
[32m[0511 07:36:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 07:36:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 07:36:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:52 @base_main.py:47][0m 173865 total steps have happened
[32m[0511 07:36:52 @base_main.py:52][0m [avg_reward]: -882.3739176288869
[32m[0511 07:36:53 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:53 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:53 @base_trainer.py:216][0m Mean reward: -879.6725399585072
[32m[0511 07:36:53 @base_main.py:38][0m --------------- Iteration 174 ---------------
[32m[0511 07:36:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1739 mins
[32m[0511 07:36:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 07:36:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 07:36:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0511 07:36:53 @base_main.py:47][0m 174870 total steps have happened
[32m[0511 07:36:53 @base_main.py:52][0m [avg_reward]: -879.6725399585072
[32m[0511 07:36:53 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:53 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:53 @base_trainer.py:216][0m Mean reward: -994.2255870466
[32m[0511 07:36:54 @base_main.py:38][0m --------------- Iteration 175 ---------------
[32m[0511 07:36:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1859 mins
[32m[0511 07:36:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 07:36:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 07:36:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:54 @base_main.py:47][0m 175875 total steps have happened
[32m[0511 07:36:54 @base_main.py:52][0m [avg_reward]: -994.2255870466
[32m[0511 07:36:54 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:54 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:54 @base_trainer.py:216][0m Mean reward: -920.5618746929467
[32m[0511 07:36:55 @base_main.py:38][0m --------------- Iteration 176 ---------------
[32m[0511 07:36:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1984 mins
[32m[0511 07:36:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 07:36:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 07:36:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:55 @base_main.py:47][0m 176880 total steps have happened
[32m[0511 07:36:55 @base_main.py:52][0m [avg_reward]: -920.5618746929467
[32m[0511 07:36:55 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:55 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:55 @base_trainer.py:216][0m Mean reward: -940.7724160113472
[32m[0511 07:36:55 @base_main.py:38][0m --------------- Iteration 177 ---------------
[32m[0511 07:36:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2109 mins
[32m[0511 07:36:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 07:36:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 07:36:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:55 @base_main.py:47][0m 177885 total steps have happened
[32m[0511 07:36:55 @base_main.py:52][0m [avg_reward]: -940.7724160113472
[32m[0511 07:36:56 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:56 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:56 @base_trainer.py:216][0m Mean reward: -979.5295998870413
[32m[0511 07:36:56 @base_main.py:38][0m --------------- Iteration 178 ---------------
[32m[0511 07:36:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2233 mins
[32m[0511 07:36:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 07:36:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 07:36:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:56 @base_main.py:47][0m 178890 total steps have happened
[32m[0511 07:36:56 @base_main.py:52][0m [avg_reward]: -979.5295998870413
[32m[0511 07:36:56 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:56 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:56 @base_trainer.py:216][0m Mean reward: -1008.6682098045181
[32m[0511 07:36:57 @base_main.py:38][0m --------------- Iteration 179 ---------------
[32m[0511 07:36:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2360 mins
[32m[0511 07:36:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 07:36:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 07:36:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:57 @base_main.py:47][0m 179895 total steps have happened
[32m[0511 07:36:57 @base_main.py:52][0m [avg_reward]: -1008.6682098045181
[32m[0511 07:36:57 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:57 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:57 @base_trainer.py:216][0m Mean reward: -1034.8144329856227
[32m[0511 07:36:58 @base_main.py:38][0m --------------- Iteration 180 ---------------
[32m[0511 07:36:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2482 mins
[32m[0511 07:36:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 07:36:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 07:36:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:58 @base_main.py:47][0m 180900 total steps have happened
[32m[0511 07:36:58 @base_main.py:52][0m [avg_reward]: -1034.8144329856227
[32m[0511 07:36:58 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:58 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:58 @base_trainer.py:216][0m Mean reward: -1000.9145995284374
[32m[0511 07:36:58 @base_main.py:38][0m --------------- Iteration 181 ---------------
[32m[0511 07:36:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2607 mins
[32m[0511 07:36:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 07:36:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 07:36:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:58 @base_main.py:47][0m 181905 total steps have happened
[32m[0511 07:36:58 @base_main.py:52][0m [avg_reward]: -1000.9145995284374
[32m[0511 07:36:59 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:59 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:59 @base_trainer.py:216][0m Mean reward: -933.7277676627333
[32m[0511 07:36:59 @base_main.py:38][0m --------------- Iteration 182 ---------------
[32m[0511 07:36:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2734 mins
[32m[0511 07:36:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 07:36:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 07:36:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:36:59 @base_main.py:47][0m 182910 total steps have happened
[32m[0511 07:36:59 @base_main.py:52][0m [avg_reward]: -933.7277676627333
[32m[0511 07:36:59 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:36:59 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:36:59 @base_trainer.py:216][0m Mean reward: -969.6556819187299
[32m[0511 07:37:00 @base_main.py:38][0m --------------- Iteration 183 ---------------
[32m[0511 07:37:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2858 mins
[32m[0511 07:37:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 07:37:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 07:37:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:37:00 @base_main.py:47][0m 183915 total steps have happened
[32m[0511 07:37:00 @base_main.py:52][0m [avg_reward]: -969.6556819187299
[32m[0511 07:37:00 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:37:00 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:37:00 @base_trainer.py:216][0m Mean reward: -1013.9752574040546
[32m[0511 07:37:01 @base_main.py:38][0m --------------- Iteration 184 ---------------
[32m[0511 07:37:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2983 mins
[32m[0511 07:37:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 07:37:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 07:37:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:37:01 @base_main.py:47][0m 184920 total steps have happened
[32m[0511 07:37:01 @base_main.py:52][0m [avg_reward]: -1013.9752574040546
[32m[0511 07:37:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:37:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:37:01 @base_trainer.py:216][0m Mean reward: -1058.3392716004746
[32m[0511 07:37:01 @base_main.py:38][0m --------------- Iteration 185 ---------------
[32m[0511 07:37:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3106 mins
[32m[0511 07:37:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 07:37:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 07:37:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:37:01 @base_main.py:47][0m 185925 total steps have happened
[32m[0511 07:37:01 @base_main.py:52][0m [avg_reward]: -1058.3392716004746
[32m[0511 07:37:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:37:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:37:01 @base_trainer.py:216][0m Mean reward: -1094.9661430328001
[32m[0511 07:37:02 @base_main.py:38][0m --------------- Iteration 186 ---------------
[32m[0511 07:37:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3226 mins
[32m[0511 07:37:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 07:37:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 07:37:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0511 07:37:02 @base_main.py:47][0m 186930 total steps have happened
[32m[0511 07:37:02 @base_main.py:52][0m [avg_reward]: -1094.9661430328001
[32m[0511 07:37:02 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:37:02 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:37:02 @base_trainer.py:216][0m Mean reward: -1029.7854799345
[32m[0511 07:37:03 @base_main.py:38][0m --------------- Iteration 187 ---------------
[32m[0511 07:37:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3348 mins
[32m[0511 07:37:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 07:37:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 07:37:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:37:03 @base_main.py:47][0m 187935 total steps have happened
[32m[0511 07:37:03 @base_main.py:52][0m [avg_reward]: -1029.7854799345
[32m[0511 07:37:03 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:37:03 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:37:03 @base_trainer.py:216][0m Mean reward: -969.5372108431654
[32m[0511 07:37:04 @base_main.py:38][0m --------------- Iteration 188 ---------------
[32m[0511 07:37:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3479 mins
[32m[0511 07:37:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 07:37:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 07:37:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:37:04 @base_main.py:47][0m 188940 total steps have happened
[32m[0511 07:37:04 @base_main.py:52][0m [avg_reward]: -969.5372108431654
[32m[0511 07:37:04 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:37:04 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:37:04 @base_trainer.py:216][0m Mean reward: -1014.3445113817139
[32m[0511 07:37:04 @base_main.py:38][0m --------------- Iteration 189 ---------------
[32m[0511 07:37:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3608 mins
[32m[0511 07:37:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 07:37:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 07:37:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:37:04 @base_main.py:47][0m 189945 total steps have happened
[32m[0511 07:37:04 @base_main.py:52][0m [avg_reward]: -1014.3445113817139
[32m[0511 07:37:05 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:37:05 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:37:05 @base_trainer.py:216][0m Mean reward: -1076.66389673654
[32m[0511 07:37:05 @base_main.py:38][0m --------------- Iteration 190 ---------------
[32m[0511 07:37:05 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3736 mins
[32m[0511 07:37:05 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 07:37:05 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 07:37:05 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:37:05 @base_main.py:47][0m 190950 total steps have happened
[32m[0511 07:37:05 @base_main.py:52][0m [avg_reward]: -1076.66389673654
[32m[0511 07:37:05 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:37:05 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:37:05 @base_trainer.py:216][0m Mean reward: -992.678187890461
[32m[0511 07:37:06 @base_main.py:38][0m --------------- Iteration 191 ---------------
[32m[0511 07:37:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3860 mins
[32m[0511 07:37:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 07:37:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 07:37:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:37:06 @base_main.py:47][0m 191955 total steps have happened
[32m[0511 07:37:06 @base_main.py:52][0m [avg_reward]: -992.678187890461
[32m[0511 07:37:06 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:37:06 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:37:06 @base_trainer.py:216][0m Mean reward: -1123.5389753375716
[32m[0511 07:37:07 @base_main.py:38][0m --------------- Iteration 192 ---------------
[32m[0511 07:37:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3983 mins
[32m[0511 07:37:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 07:37:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 07:37:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:37:07 @base_main.py:47][0m 192960 total steps have happened
[32m[0511 07:37:07 @base_main.py:52][0m [avg_reward]: -1123.5389753375716
[32m[0511 07:37:07 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:37:07 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:37:07 @base_trainer.py:216][0m Mean reward: -1138.1682332646237
[32m[0511 07:37:07 @base_main.py:38][0m --------------- Iteration 193 ---------------
[32m[0511 07:37:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4106 mins
[32m[0511 07:37:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 07:37:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 07:37:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:37:07 @base_main.py:47][0m 193965 total steps have happened
[32m[0511 07:37:07 @base_main.py:52][0m [avg_reward]: -1138.1682332646237
[32m[0511 07:37:07 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:37:07 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:37:07 @base_trainer.py:216][0m Mean reward: -1126.8792812953548
[32m[0511 07:37:08 @base_main.py:38][0m --------------- Iteration 194 ---------------
[32m[0511 07:37:08 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4228 mins
[32m[0511 07:37:08 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 07:37:08 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 07:37:08 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:37:08 @base_main.py:47][0m 194970 total steps have happened
[32m[0511 07:37:08 @base_main.py:52][0m [avg_reward]: -1126.8792812953548
[32m[0511 07:37:08 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:37:08 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:37:08 @base_trainer.py:216][0m Mean reward: -1075.9254088488092
[32m[0511 07:37:09 @base_main.py:38][0m --------------- Iteration 195 ---------------
[32m[0511 07:37:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4356 mins
[32m[0511 07:37:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 07:37:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 07:37:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:37:09 @base_main.py:47][0m 195975 total steps have happened
[32m[0511 07:37:09 @base_main.py:52][0m [avg_reward]: -1075.9254088488092
[32m[0511 07:37:09 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:37:09 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:37:09 @base_trainer.py:216][0m Mean reward: -1173.242443242239
[32m[0511 07:37:10 @base_main.py:38][0m --------------- Iteration 196 ---------------
[32m[0511 07:37:10 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4484 mins
[32m[0511 07:37:10 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 07:37:10 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 07:37:10 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:37:10 @base_main.py:47][0m 196980 total steps have happened
[32m[0511 07:37:10 @base_main.py:52][0m [avg_reward]: -1173.242443242239
[32m[0511 07:37:10 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:37:10 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:37:10 @base_trainer.py:216][0m Mean reward: -1086.7506708224696
[32m[0511 07:37:10 @base_main.py:38][0m --------------- Iteration 197 ---------------
[32m[0511 07:37:10 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4608 mins
[32m[0511 07:37:10 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 07:37:10 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 07:37:10 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:37:10 @base_main.py:47][0m 197985 total steps have happened
[32m[0511 07:37:10 @base_main.py:52][0m [avg_reward]: -1086.7506708224696
[32m[0511 07:37:11 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:37:11 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:37:11 @base_trainer.py:216][0m Mean reward: -1199.5830137999442
[32m[0511 07:37:11 @base_main.py:38][0m --------------- Iteration 198 ---------------
[32m[0511 07:37:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4732 mins
[32m[0511 07:37:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 07:37:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 07:37:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:37:11 @base_main.py:47][0m 198990 total steps have happened
[32m[0511 07:37:11 @base_main.py:52][0m [avg_reward]: -1199.5830137999442
[32m[0511 07:37:11 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:37:11 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:37:11 @base_trainer.py:216][0m Mean reward: -1179.1587657320038
[32m[0511 07:37:12 @base_main.py:38][0m --------------- Iteration 199 ---------------
[32m[0511 07:37:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4857 mins
[32m[0511 07:37:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 07:37:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 07:37:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:37:12 @base_main.py:47][0m 199995 total steps have happened
[32m[0511 07:37:12 @base_main.py:52][0m [avg_reward]: -1179.1587657320038
[32m[0511 07:37:12 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 07:37:12 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:37:12 @base_trainer.py:216][0m Mean reward: -1177.672357436765
[32m[0511 07:37:13 @base_main.py:38][0m --------------- Iteration 200 ---------------
[32m[0511 07:37:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4986 mins
[32m[0511 07:37:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 07:37:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 07:37:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 07:37:13 @base_main.py:47][0m 201000 total steps have happened
[32m[0511 07:37:13 @base_main.py:52][0m [avg_reward]: -1177.672357436765
[32m[0511 07:37:13 @base_worker.py:111][0m kill message for worker 17
[32m[0511 07:37:13 @base_worker.py:111][0m kill message for worker 4
[32m[0511 07:37:13 @base_worker.py:111][0m kill message for worker 11
[32m[0511 07:37:13 @base_worker.py:111][0m kill message for worker 15
[32m[0511 07:37:13 @base_worker.py:111][0m kill message for worker 0
[32m[0511 07:37:13 @base_worker.py:111][0m kill message for worker 16
[32m[0511 07:37:13 @base_worker.py:111][0m kill message for worker 6
[32m[0511 07:37:13 @base_worker.py:111][0m kill message for worker 2
[32m[0511 07:37:13 @base_worker.py:111][0m kill message for worker 7
[32m[0511 07:37:13 @base_worker.py:111][0m kill message for worker 1
[32m[0511 07:37:13 @base_worker.py:111][0m kill message for worker 18
[32m[0511 07:37:13 @base_worker.py:111][0m kill message for worker 13
[32m[0511 07:37:13 @base_worker.py:111][0m kill message for worker 5
[32m[0511 07:37:13 @base_worker.py:111][0m kill message for worker 19
[32m[0511 07:37:13 @base_worker.py:111][0m kill message for worker 14
[32m[0511 07:37:13 @base_worker.py:111][0m kill message for worker 3
[32m[0511 07:37:13 @base_worker.py:111][0m kill message for worker 10
[32m[0511 07:37:13 @base_worker.py:111][0m kill message for worker 8
[32m[0511 07:37:13 @base_worker.py:111][0m kill message for worker 9
[32m[0511 07:37:13 @base_worker.py:111][0m kill message for worker 12
