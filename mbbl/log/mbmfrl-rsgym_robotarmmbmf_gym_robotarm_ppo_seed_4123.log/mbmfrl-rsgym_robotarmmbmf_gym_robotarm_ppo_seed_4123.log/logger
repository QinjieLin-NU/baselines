[32m[0512 05:09:09 @logger.py:103][0m Log file set to /root/mbbl/log/mbmfrl-rsgym_robotarmmbmf_gym_robotarm_ppo_seed_4123.log/mbmfrl-rsgym_robotarmmbmf_gym_robotarm_ppo_seed_4123.log
[32m[0512 05:09:09 @mbmf_main.py:23][0m Training starts at /root/mbbl
[32m[0512 05:09:09 @base_worker.py:45][0m Worker 0 online
[32m[0512 05:09:10 @base_worker.py:45][0m Worker 1 online
[32m[0512 05:09:10 @base_worker.py:45][0m Worker 2 online
[32m[0512 05:09:10 @base_worker.py:45][0m Worker 3 online
[32m[0512 05:09:10 @base_worker.py:45][0m Worker 4 online
[32m[0512 05:09:10 @base_worker.py:45][0m Worker 5 online
[32m[0512 05:09:10 @base_worker.py:45][0m Worker 6 online
[32m[0512 05:09:10 @base_worker.py:45][0m Worker 7 online
[32m[0512 05:09:10 @base_worker.py:45][0m Worker 8 online
[32m[0512 05:09:10 @base_worker.py:45][0m Worker 9 online
[32m[0512 05:09:10 @base_worker.py:45][0m Worker 10 online
[32m[0512 05:09:10 @base_worker.py:45][0m Worker 11 online
[32m[0512 05:09:10 @base_worker.py:45][0m Worker 12 online
[32m[0512 05:09:10 @base_worker.py:45][0m Worker 13 online
[32m[0512 05:09:10 @base_worker.py:45][0m Worker 14 online
[32m[0512 05:09:10 @base_worker.py:45][0m Worker 15 online
[32m[0512 05:09:10 @base_worker.py:45][0m Worker 16 online
[32m[0512 05:09:10 @base_worker.py:45][0m Worker 17 online
[32m[0512 05:09:10 @base_worker.py:45][0m Worker 18 online
[32m[0512 05:09:10 @base_worker.py:45][0m Worker 19 online
[32m[0512 05:09:11 @base_trainer.py:152][0m Trainer maintains [1] policy network
[32m[0512 05:09:11 @base_trainer.py:152][0m Trainer maintains [1] dynamics network
[32m[0512 05:09:11 @base_trainer.py:152][0m Trainer maintains [1] reward network
[32m[0512 05:09:12 @mbmf_main.py:46][0m Generating 1000 random timesteps
[32m[0512 05:09:12 @mbmf_sampler.py:39][0m done with episode
[32m[0512 05:09:12 @mbmf_sampler.py:39][0m done with episode
[32m[0512 05:09:12 @mbmf_sampler.py:39][0m done with episode
[32m[0512 05:09:12 @mbmf_sampler.py:39][0m done with episode
[32m[0512 05:09:12 @mbmf_sampler.py:39][0m done with episode
[32m[0512 05:09:12 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:09:12 @base_trainer.py:216][0m Mean reward: -320.80618527751375
[32m[0512 05:09:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2307368516921997, Train Loss: 0.9109295606613159
[32m[0512 05:09:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2307325601577759, Train Loss: 0.9109227061271667
[32m[0512 05:09:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2307281494140625, Train Loss: 0.9109163284301758
[32m[0512 05:09:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2307238578796387, Train Loss: 0.9109098315238953
[32m[0512 05:09:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.230720043182373, Train Loss: 0.9109037518501282
[32m[0512 05:09:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.230716347694397, Train Loss: 0.9108977913856506
[32m[0512 05:09:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.230712652206421, Train Loss: 0.9108919501304626
[32m[0512 05:09:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2307090759277344, Train Loss: 0.9108863472938538
[32m[0512 05:09:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2307058572769165, Train Loss: 0.9108810424804688
[32m[0512 05:09:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2307027578353882, Train Loss: 0.910875678062439
[32m[0512 05:09:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2306996583938599, Train Loss: 0.9108708500862122
[32m[0512 05:09:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2306967973709106, Train Loss: 0.9108659625053406
[32m[0512 05:09:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2306939363479614, Train Loss: 0.9108613133430481
[32m[0512 05:09:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2306911945343018, Train Loss: 0.9108569622039795
[32m[0512 05:09:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2306886911392212, Train Loss: 0.9108526706695557
[32m[0512 05:09:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2306861877441406, Train Loss: 0.9108486771583557
[32m[0512 05:09:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.23068368434906, Train Loss: 0.9108447432518005
[32m[0512 05:09:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2306811809539795, Train Loss: 0.9108408689498901
[32m[0512 05:09:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.230678915977478, Train Loss: 0.9108374714851379
[32m[0512 05:09:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2306764125823975, Train Loss: 0.9108341336250305
[32m[0512 05:09:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2306740283966064, Train Loss: 0.9108307957649231
[32m[0512 05:09:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.230671763420105, Train Loss: 0.9108276963233948
[32m[0512 05:09:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2306692600250244, Train Loss: 0.910824716091156
[32m[0512 05:09:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2306667566299438, Train Loss: 0.9108219742774963
[32m[0512 05:09:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2306644916534424, Train Loss: 0.9108191132545471
[32m[0512 05:09:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2306618690490723, Train Loss: 0.9108164310455322
[32m[0512 05:09:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2306593656539917, Train Loss: 0.910814106464386
[32m[0512 05:09:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2306569814682007, Train Loss: 0.9108116030693054
[32m[0512 05:09:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2306544780731201, Train Loss: 0.910809338092804
[32m[0512 05:09:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2306519746780396, Train Loss: 0.9108071327209473
[32m[0512 05:09:13 @base_main.py:38][0m --------------- Iteration 1 ---------------
[32m[0512 05:09:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0000 mins
[32m[0512 05:09:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0059 mins
[32m[0512 05:09:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0122 mins
[32m[0512 05:09:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0030 mins
[32m[0512 05:09:13 @base_main.py:47][0m 1005 total steps have happened
[32m[0512 05:09:13 @base_main.py:52][0m [avg_reward]: -320.80618527751375
[32m[0512 05:09:13 @base_main.py:52][0m [update_op]: None
[32m[0512 05:09:13 @base_main.py:52][0m [train_loss]: 0.9108071327209473
[32m[0512 05:09:13 @base_main.py:52][0m [val_loss]: 1.2306519746780396
[32m[0512 05:09:13 @base_main.py:52][0m [avg_train_loss]: 0.9108071327209473
[32m[0512 05:11:36 @mbmf_sampler.py:39][0m done with episode
[32m[0512 05:13:56 @mbmf_sampler.py:39][0m done with episode
[32m[0512 05:16:15 @mbmf_sampler.py:39][0m done with episode
[32m[0512 05:18:35 @mbmf_sampler.py:39][0m done with episode
[32m[0512 05:20:54 @mbmf_sampler.py:39][0m done with episode
[32m[0512 05:20:54 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:20:54 @base_trainer.py:216][0m Mean reward: -256.72815162657736
[32m[0512 05:20:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8630949854850769, Train Loss: 1.0116835832595825
[32m[0512 05:20:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8631125092506409, Train Loss: 1.0116795301437378
[32m[0512 05:20:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8631391525268555, Train Loss: 1.0116686820983887
[32m[0512 05:20:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8631712794303894, Train Loss: 1.0116544961929321
[32m[0512 05:20:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8632065057754517, Train Loss: 1.0116394758224487
[32m[0512 05:20:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8632435202598572, Train Loss: 1.0116240978240967
[32m[0512 05:20:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8632811307907104, Train Loss: 1.0116095542907715
[32m[0512 05:20:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8633188605308533, Train Loss: 1.0115958452224731
[32m[0512 05:20:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8633561134338379, Train Loss: 1.0115832090377808
[32m[0512 05:20:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8633923530578613, Train Loss: 1.0115717649459839
[32m[0512 05:20:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8634272217750549, Train Loss: 1.0115612745285034
[32m[0512 05:20:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8634608387947083, Train Loss: 1.0115517377853394
[32m[0512 05:20:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8634929656982422, Train Loss: 1.0115431547164917
[32m[0512 05:20:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8635233640670776, Train Loss: 1.0115355253219604
[32m[0512 05:20:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8635525107383728, Train Loss: 1.011528491973877
[32m[0512 05:20:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8635799884796143, Train Loss: 1.0115221738815308
[32m[0512 05:20:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8636062741279602, Train Loss: 1.0115164518356323
[32m[0512 05:20:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8636310696601868, Train Loss: 1.011511206626892
[32m[0512 05:20:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8636546730995178, Train Loss: 1.0115065574645996
[32m[0512 05:20:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8636768460273743, Train Loss: 1.0115023851394653
[32m[0512 05:20:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8636981844902039, Train Loss: 1.0114985704421997
[32m[0512 05:20:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8637183904647827, Train Loss: 1.0114951133728027
[32m[0512 05:20:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8637377023696899, Train Loss: 1.011492133140564
[32m[0512 05:20:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.863756000995636, Train Loss: 1.0114892721176147
[32m[0512 05:20:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8637735247612, Train Loss: 1.0114866495132446
[32m[0512 05:20:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.863789975643158, Train Loss: 1.0114845037460327
[32m[0512 05:20:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8638058304786682, Train Loss: 1.0114823579788208
[32m[0512 05:20:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8638209700584412, Train Loss: 1.011480450630188
[32m[0512 05:20:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.863835334777832, Train Loss: 1.0114787817001343
[32m[0512 05:20:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8638491034507751, Train Loss: 1.0114773511886597
[32m[0512 05:20:55 @base_main.py:38][0m --------------- Iteration 2 ---------------
[32m[0512 05:20:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0212 mins
[32m[0512 05:20:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 11.6763 mins
[32m[0512 05:20:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0202 mins
[32m[0512 05:20:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0043 mins
[32m[0512 05:20:55 @base_main.py:47][0m 2010 total steps have happened
[32m[0512 05:20:55 @base_main.py:52][0m [avg_reward]: -256.72815162657736
[32m[0512 05:20:55 @base_main.py:52][0m [update_op]: None
[32m[0512 05:20:55 @base_main.py:52][0m [train_loss]: 1.3510704040527344
[32m[0512 05:20:55 @base_main.py:52][0m [val_loss]: 0.8638491034507751
[32m[0512 05:20:55 @base_main.py:52][0m [avg_train_loss]: 1.0114773511886597
[32m[0512 05:23:16 @mbmf_sampler.py:39][0m done with episode
[32m[0512 05:25:35 @mbmf_sampler.py:39][0m done with episode
[32m[0512 05:27:54 @mbmf_sampler.py:39][0m done with episode
[32m[0512 05:30:14 @mbmf_sampler.py:39][0m done with episode
[32m[0512 05:32:33 @mbmf_sampler.py:39][0m done with episode
[32m[0512 05:32:33 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:32:33 @base_trainer.py:216][0m Mean reward: -307.3452287218471
[32m[0512 05:32:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2269235849380493, Train Loss: 0.9836023449897766
[32m[0512 05:32:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2269877195358276, Train Loss: 0.9835965037345886
[32m[0512 05:32:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2270697355270386, Train Loss: 0.983585000038147
[32m[0512 05:32:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2271571159362793, Train Loss: 0.9835717082023621
[32m[0512 05:32:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2272435426712036, Train Loss: 0.9835590124130249
[32m[0512 05:32:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2273259162902832, Train Loss: 0.983547568321228
[32m[0512 05:32:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2274024486541748, Train Loss: 0.983537495136261
[32m[0512 05:32:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2274726629257202, Train Loss: 0.9835289716720581
[32m[0512 05:32:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.227536678314209, Train Loss: 0.9835216403007507
[32m[0512 05:32:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2275947332382202, Train Loss: 0.9835156202316284
[32m[0512 05:32:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.227647304534912, Train Loss: 0.9835103750228882
[32m[0512 05:32:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2276947498321533, Train Loss: 0.9835062026977539
[32m[0512 05:32:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2277379035949707, Train Loss: 0.9835025668144226
[32m[0512 05:32:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2277772426605225, Train Loss: 0.9834995269775391
[32m[0512 05:32:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2278125286102295, Train Loss: 0.9834968447685242
[32m[0512 05:32:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2278449535369873, Train Loss: 0.983494758605957
[32m[0512 05:32:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2278742790222168, Train Loss: 0.9834928512573242
[32m[0512 05:32:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2279011011123657, Train Loss: 0.9834913015365601
[32m[0512 05:32:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2279256582260132, Train Loss: 0.983489990234375
[32m[0512 05:32:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2279481887817383, Train Loss: 0.9834888577461243
[32m[0512 05:32:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2279689311981201, Train Loss: 0.9834879040718079
[32m[0512 05:32:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2279876470565796, Train Loss: 0.9834870100021362
[32m[0512 05:32:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.228004813194275, Train Loss: 0.9834863543510437
[32m[0512 05:32:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2280207872390747, Train Loss: 0.9834858179092407
[32m[0512 05:32:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2280353307724, Train Loss: 0.983485221862793
[32m[0512 05:32:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2280486822128296, Train Loss: 0.9834848642349243
[32m[0512 05:32:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2280610799789429, Train Loss: 0.9834844470024109
[32m[0512 05:32:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2280725240707397, Train Loss: 0.9834840893745422
[32m[0512 05:32:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2280828952789307, Train Loss: 0.9834837913513184
[32m[0512 05:32:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2280925512313843, Train Loss: 0.983483612537384
[32m[0512 05:32:35 @base_main.py:38][0m --------------- Iteration 3 ---------------
[32m[0512 05:32:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 11.7221 mins
[32m[0512 05:32:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 11.6295 mins
[32m[0512 05:32:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0306 mins
[32m[0512 05:32:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0045 mins
[32m[0512 05:32:35 @base_main.py:47][0m 3015 total steps have happened
[32m[0512 05:32:35 @base_main.py:52][0m [avg_reward]: -307.3452287218471
[32m[0512 05:32:35 @base_main.py:52][0m [update_op]: None
[32m[0512 05:32:35 @base_main.py:52][0m [train_loss]: 1.0762394666671753
[32m[0512 05:32:35 @base_main.py:52][0m [val_loss]: 1.2280925512313843
[32m[0512 05:32:35 @base_main.py:52][0m [avg_train_loss]: 0.983483612537384
[32m[0512 05:34:55 @mbmf_sampler.py:39][0m done with episode
[32m[0512 05:37:15 @mbmf_sampler.py:39][0m done with episode
[32m[0512 05:39:34 @mbmf_sampler.py:39][0m done with episode
[32m[0512 05:41:53 @mbmf_sampler.py:39][0m done with episode
[32m[0512 05:44:13 @mbmf_sampler.py:39][0m done with episode
[32m[0512 05:44:13 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:44:13 @base_trainer.py:216][0m Mean reward: -281.1995954367445
[32m[0512 05:44:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.911831796169281, Train Loss: 1.025591254234314
[32m[0512 05:44:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9119115471839905, Train Loss: 1.0255780220031738
[32m[0512 05:44:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9120028018951416, Train Loss: 1.0255603790283203
[32m[0512 05:44:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.912095844745636, Train Loss: 1.0255427360534668
[32m[0512 05:44:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9121857285499573, Train Loss: 1.0255271196365356
[32m[0512 05:44:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9122700095176697, Train Loss: 1.0255138874053955
[32m[0512 05:44:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9123473167419434, Train Loss: 1.0255032777786255
[32m[0512 05:44:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9124180674552917, Train Loss: 1.0254944562911987
[32m[0512 05:44:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9124820232391357, Train Loss: 1.0254875421524048
[32m[0512 05:44:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9125396609306335, Train Loss: 1.0254820585250854
[32m[0512 05:44:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9125916361808777, Train Loss: 1.0254775285720825
[32m[0512 05:44:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9126381278038025, Train Loss: 1.025473952293396
[32m[0512 05:44:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9126799702644348, Train Loss: 1.0254710912704468
[32m[0512 05:44:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.912717342376709, Train Loss: 1.0254688262939453
[32m[0512 05:44:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.912750780582428, Train Loss: 1.025467038154602
[32m[0512 05:44:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9127805829048157, Train Loss: 1.0254656076431274
[32m[0512 05:44:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9128074049949646, Train Loss: 1.0254642963409424
[32m[0512 05:44:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.91283118724823, Train Loss: 1.0254634618759155
[32m[0512 05:44:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.91285240650177, Train Loss: 1.0254627466201782
[32m[0512 05:44:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9128715991973877, Train Loss: 1.025462031364441
[32m[0512 05:44:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9128885269165039, Train Loss: 1.0254615545272827
[32m[0512 05:44:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9129034876823425, Train Loss: 1.025461196899414
[32m[0512 05:44:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9129170179367065, Train Loss: 1.0254607200622559
[32m[0512 05:44:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.912929117679596, Train Loss: 1.0254604816436768
[32m[0512 05:44:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9129397869110107, Train Loss: 1.0254603624343872
[32m[0512 05:44:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9129492044448853, Train Loss: 1.0254600048065186
[32m[0512 05:44:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9129578471183777, Train Loss: 1.0254600048065186
[32m[0512 05:44:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9129654169082642, Train Loss: 1.025459885597229
[32m[0512 05:44:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9129721522331238, Train Loss: 1.0254595279693604
[32m[0512 05:44:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9129781723022461, Train Loss: 1.02545964717865
[32m[0512 05:44:16 @base_main.py:38][0m --------------- Iteration 4 ---------------
[32m[0512 05:44:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 23.3868 mins
[32m[0512 05:44:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 11.6340 mins
[32m[0512 05:44:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0436 mins
[32m[0512 05:44:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0046 mins
[32m[0512 05:44:16 @base_main.py:47][0m 4020 total steps have happened
[32m[0512 05:44:16 @base_main.py:52][0m [avg_reward]: -281.1995954367445
[32m[0512 05:44:16 @base_main.py:52][0m [update_op]: None
[32m[0512 05:44:16 @base_main.py:52][0m [train_loss]: 1.2324458360671997
[32m[0512 05:44:16 @base_main.py:52][0m [val_loss]: 0.9129781723022461
[32m[0512 05:44:16 @base_main.py:52][0m [avg_train_loss]: 1.02545964717865
[32m[0512 05:46:36 @mbmf_sampler.py:39][0m done with episode
[32m[0512 05:48:55 @mbmf_sampler.py:39][0m done with episode
[32m[0512 05:51:14 @mbmf_sampler.py:39][0m done with episode
[32m[0512 05:53:33 @mbmf_sampler.py:39][0m done with episode
[32m[0512 05:55:53 @mbmf_sampler.py:39][0m done with episode
[32m[0512 05:55:53 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:55:53 @base_trainer.py:216][0m Mean reward: -230.7956810378656
[32m[0512 05:55:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7385175824165344, Train Loss: 1.0321635007858276
[32m[0512 05:55:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7384946346282959, Train Loss: 1.0321587324142456
[32m[0512 05:55:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7384684085845947, Train Loss: 1.0321543216705322
[32m[0512 05:55:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7384428977966309, Train Loss: 1.0321502685546875
[32m[0512 05:55:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7384198904037476, Train Loss: 1.0321474075317383
[32m[0512 05:55:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7383995652198792, Train Loss: 1.0321451425552368
[32m[0512 05:55:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7383818626403809, Train Loss: 1.0321437120437622
[32m[0512 05:55:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.738366425037384, Train Loss: 1.0321425199508667
[32m[0512 05:55:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7383531332015991, Train Loss: 1.0321416854858398
[32m[0512 05:55:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7383415699005127, Train Loss: 1.0321412086486816
[32m[0512 05:55:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.73833167552948, Train Loss: 1.032140851020813
[32m[0512 05:55:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7383230924606323, Train Loss: 1.0321406126022339
[32m[0512 05:55:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7383157014846802, Train Loss: 1.0321403741836548
[32m[0512 05:55:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7383092045783997, Train Loss: 1.0321402549743652
[32m[0512 05:55:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7383037209510803, Train Loss: 1.0321402549743652
[32m[0512 05:55:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7382990717887878, Train Loss: 1.0321402549743652
[32m[0512 05:55:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7382948994636536, Train Loss: 1.0321401357650757
[32m[0512 05:55:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7382913827896118, Train Loss: 1.0321402549743652
[32m[0512 05:55:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7382883429527283, Train Loss: 1.0321401357650757
[32m[0512 05:55:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7382857799530029, Train Loss: 1.0321402549743652
[32m[0512 05:55:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7382835149765015, Train Loss: 1.0321402549743652
[32m[0512 05:55:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7382816076278687, Train Loss: 1.0321402549743652
[32m[0512 05:55:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7382798790931702, Train Loss: 1.0321402549743652
[32m[0512 05:55:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7382785081863403, Train Loss: 1.0321402549743652
[32m[0512 05:55:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7382772564888, Train Loss: 1.0321402549743652
[32m[0512 05:55:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7382762432098389, Train Loss: 1.0321402549743652
[32m[0512 05:55:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7382753491401672, Train Loss: 1.0321402549743652
[32m[0512 05:55:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7382746338844299, Train Loss: 1.0321402549743652
[32m[0512 05:55:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7382739186286926, Train Loss: 1.0321402549743652
[32m[0512 05:55:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7382734417915344, Train Loss: 1.0321402549743652
[32m[0512 05:55:56 @base_main.py:38][0m --------------- Iteration 5 ---------------
[32m[0512 05:55:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 35.0691 mins
[32m[0512 05:55:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 11.6098 mins
[32m[0512 05:55:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0554 mins
[32m[0512 05:55:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0042 mins
[32m[0512 05:55:56 @base_main.py:47][0m 5025 total steps have happened
[32m[0512 05:55:56 @base_main.py:52][0m [avg_reward]: -230.7956810378656
[32m[0512 05:55:56 @base_main.py:52][0m [update_op]: None
[32m[0512 05:55:56 @base_main.py:52][0m [train_loss]: 0.9916539788246155
[32m[0512 05:55:56 @base_main.py:52][0m [val_loss]: 0.7382734417915344
[32m[0512 05:55:56 @base_main.py:52][0m [avg_train_loss]: 1.0321402549743652
[32m[0512 05:58:15 @mbmf_sampler.py:39][0m done with episode
[32m[0512 06:00:34 @mbmf_sampler.py:39][0m done with episode
[32m[0512 06:02:54 @mbmf_sampler.py:39][0m done with episode
[32m[0512 06:05:10 @mbmf_sampler.py:39][0m done with episode
[32m[0512 06:07:18 @mbmf_sampler.py:39][0m done with episode
[32m[0512 06:07:18 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0512 06:07:18 @base_trainer.py:216][0m Mean reward: -299.1469549911825
[32m[0512 06:07:18 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8527697324752808, Train Loss: 1.022171139717102
[32m[0512 06:07:19 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8527800440788269, Train Loss: 1.0221701860427856
[32m[0512 06:07:19 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8527921438217163, Train Loss: 1.0221691131591797
[32m[0512 06:07:19 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8528032898902893, Train Loss: 1.0221682786941528
[32m[0512 06:07:19 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8528128266334534, Train Loss: 1.0221675634384155
[32m[0512 06:07:19 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8528204560279846, Train Loss: 1.0221672058105469
[32m[0512 06:07:19 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8528266549110413, Train Loss: 1.0221667289733887
[32m[0512 06:07:19 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8528316020965576, Train Loss: 1.0221664905548096
[32m[0512 06:07:19 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8528355956077576, Train Loss: 1.02216637134552
[32m[0512 06:07:19 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8528386354446411, Train Loss: 1.02216637134552
[32m[0512 06:07:20 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8528410792350769, Train Loss: 1.0221662521362305
[32m[0512 06:07:20 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8528430461883545, Train Loss: 1.0221662521362305
[32m[0512 06:07:20 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8528447151184082, Train Loss: 1.022166132926941
[32m[0512 06:07:20 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8528459072113037, Train Loss: 1.0221662521362305
[32m[0512 06:07:20 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8528468012809753, Train Loss: 1.022166132926941
[32m[0512 06:07:20 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8528476357460022, Train Loss: 1.022166132926941
[32m[0512 06:07:20 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8528482913970947, Train Loss: 1.022166132926941
[32m[0512 06:07:20 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8528488278388977, Train Loss: 1.022166132926941
[32m[0512 06:07:20 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8528491258621216, Train Loss: 1.022166132926941
[32m[0512 06:07:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8528494834899902, Train Loss: 1.022166132926941
[32m[0512 06:07:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8528497815132141, Train Loss: 1.0221660137176514
[32m[0512 06:07:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8528499603271484, Train Loss: 1.0221660137176514
[32m[0512 06:07:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8528501391410828, Train Loss: 1.022166132926941
[32m[0512 06:07:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8528501391410828, Train Loss: 1.022166132926941
[32m[0512 06:07:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8528502583503723, Train Loss: 1.022166132926941
[32m[0512 06:07:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8528503179550171, Train Loss: 1.022166132926941
[32m[0512 06:07:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8528503179550171, Train Loss: 1.022166132926941
[32m[0512 06:07:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8528504371643066, Train Loss: 1.022166132926941
[32m[0512 06:07:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8528504371643066, Train Loss: 1.022166132926941
[32m[0512 06:07:22 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8528504371643066, Train Loss: 1.022166132926941
[32m[0512 06:07:22 @base_main.py:38][0m --------------- Iteration 6 ---------------
[32m[0512 06:07:22 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 46.7385 mins
[32m[0512 06:07:22 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 11.3680 mins
[32m[0512 06:07:22 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0545 mins
[32m[0512 06:07:22 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0048 mins
[32m[0512 06:07:22 @base_main.py:47][0m 6030 total steps have happened
[32m[0512 06:07:22 @base_main.py:52][0m [avg_reward]: -299.1469549911825
[32m[0512 06:07:22 @base_main.py:52][0m [update_op]: None
[32m[0512 06:07:22 @base_main.py:52][0m [train_loss]: 0.48622050881385803
[32m[0512 06:07:22 @base_main.py:52][0m [val_loss]: 0.8528504371643066
[32m[0512 06:07:22 @base_main.py:52][0m [avg_train_loss]: 1.022166132926941
[32m[0512 06:09:31 @mbmf_sampler.py:39][0m done with episode
[32m[0512 06:11:38 @mbmf_sampler.py:39][0m done with episode
[32m[0512 06:13:46 @mbmf_sampler.py:39][0m done with episode
[32m[0512 06:15:55 @mbmf_sampler.py:39][0m done with episode
[32m[0512 06:18:02 @mbmf_sampler.py:39][0m done with episode
[32m[0512 06:18:02 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0512 06:18:02 @base_trainer.py:216][0m Mean reward: -282.0340328114429
[32m[0512 06:18:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1664988994598389, Train Loss: 1.0080006122589111
[32m[0512 06:18:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1665295362472534, Train Loss: 1.0079967975616455
[32m[0512 06:18:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1665478944778442, Train Loss: 1.0079947710037231
[32m[0512 06:18:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1665582656860352, Train Loss: 1.0079938173294067
[32m[0512 06:18:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1665635108947754, Train Loss: 1.0079933404922485
[32m[0512 06:18:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1665657758712769, Train Loss: 1.007993221282959
[32m[0512 06:18:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.166566014289856, Train Loss: 1.007993221282959
[32m[0512 06:18:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1665658950805664, Train Loss: 1.0079931020736694
[32m[0512 06:18:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1665654182434082, Train Loss: 1.0079931020736694
[32m[0512 06:18:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.166564702987671, Train Loss: 1.007993221282959
[32m[0512 06:18:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1665641069412231, Train Loss: 1.007993221282959
[32m[0512 06:18:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1665633916854858, Train Loss: 1.007993221282959
[32m[0512 06:18:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1665629148483276, Train Loss: 1.007993221282959
[32m[0512 06:18:04 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1665626764297485, Train Loss: 1.0079931020736694
[32m[0512 06:18:04 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1665624380111694, Train Loss: 1.007993221282959
[32m[0512 06:18:04 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1665623188018799, Train Loss: 1.0079931020736694
[32m[0512 06:18:04 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1665620803833008, Train Loss: 1.0079931020736694
[32m[0512 06:18:04 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1665618419647217, Train Loss: 1.007993221282959
[32m[0512 06:18:04 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1665618419647217, Train Loss: 1.007993221282959
[32m[0512 06:18:04 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1665617227554321, Train Loss: 1.007993221282959
[32m[0512 06:18:04 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1665617227554321, Train Loss: 1.007993221282959
[32m[0512 06:18:05 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1665616035461426, Train Loss: 1.007993221282959
[32m[0512 06:18:05 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1665616035461426, Train Loss: 1.007993221282959
[32m[0512 06:18:05 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1665616035461426, Train Loss: 1.007993221282959
[32m[0512 06:18:05 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.166561484336853, Train Loss: 1.007993221282959
[32m[0512 06:18:05 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.166561484336853, Train Loss: 1.007993221282959
[32m[0512 06:18:05 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.166561484336853, Train Loss: 1.007993221282959
[32m[0512 06:18:05 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.166561484336853, Train Loss: 1.007993221282959
[32m[0512 06:18:05 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.166561484336853, Train Loss: 1.007993221282959
[32m[0512 06:18:06 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.166561484336853, Train Loss: 1.007993221282959
[32m[0512 06:18:06 @base_main.py:38][0m --------------- Iteration 7 ---------------
[32m[0512 06:18:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 58.1660 mins
[32m[0512 06:18:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 10.6659 mins
[32m[0512 06:18:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0625 mins
[32m[0512 06:18:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0053 mins
[32m[0512 06:18:06 @base_main.py:47][0m 7035 total steps have happened
[32m[0512 06:18:06 @base_main.py:52][0m [avg_reward]: -282.0340328114429
[32m[0512 06:18:06 @base_main.py:52][0m [update_op]: None
[32m[0512 06:18:06 @base_main.py:52][0m [train_loss]: 0.9533405900001526
[32m[0512 06:18:06 @base_main.py:52][0m [val_loss]: 1.166561484336853
[32m[0512 06:18:06 @base_main.py:52][0m [avg_train_loss]: 1.007993221282959
[32m[0512 06:18:06 @mbmf_trainer.py:160][0m Mean reward: -282.57940427188197
[32m[0512 06:18:06 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.23017050325870514, Train Loss: 0.22560226917266846
[32m[0512 06:18:06 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.23019903898239136, Train Loss: 0.22546280920505524
[32m[0512 06:18:06 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.230230450630188, Train Loss: 0.2254151850938797
[32m[0512 06:18:06 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.23024703562259674, Train Loss: 0.2253868728876114
[32m[0512 06:18:06 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.23025289177894592, Train Loss: 0.22536303102970123
[32m[0512 06:18:06 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.23025326430797577, Train Loss: 0.22534118592739105
[32m[0512 06:18:06 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.23025083541870117, Train Loss: 0.2253206968307495
[32m[0512 06:18:06 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.2302471399307251, Train Loss: 0.2253013402223587
[32m[0512 06:18:06 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.23024308681488037, Train Loss: 0.22528298199176788
[32m[0512 06:18:06 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.23023928701877594, Train Loss: 0.22526544332504272
[32m[0512 06:18:06 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.23023593425750732, Train Loss: 0.22524864971637726
[32m[0512 06:18:06 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.23023317754268646, Train Loss: 0.22523260116577148
[32m[0512 06:18:06 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.23023094236850739, Train Loss: 0.22521714866161346
[32m[0512 06:18:06 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.23022907972335815, Train Loss: 0.22520238161087036
[32m[0512 06:18:06 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.23022758960723877, Train Loss: 0.22518813610076904
[32m[0512 06:18:07 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.23022638261318207, Train Loss: 0.22517436742782593
[32m[0512 06:18:07 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.23022545874118805, Train Loss: 0.2251611351966858
[32m[0512 06:18:07 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.23022471368312836, Train Loss: 0.22514832019805908
[32m[0512 06:18:07 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.23022417724132538, Train Loss: 0.2251359224319458
[32m[0512 06:18:07 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.2302238643169403, Train Loss: 0.22512386739253998
[32m[0512 06:18:07 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.2302236706018448, Train Loss: 0.225112184882164
[32m[0512 06:18:07 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.2302236706018448, Train Loss: 0.22510085999965668
[32m[0512 06:18:07 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.23022378981113434, Train Loss: 0.22508977353572845
[32m[0512 06:18:07 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.23022408783435822, Train Loss: 0.22507895529270172
[32m[0512 06:18:07 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.23022446036338806, Train Loss: 0.22506843507289886
[32m[0512 06:18:07 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.23022493720054626, Train Loss: 0.2250581532716751
[32m[0512 06:18:07 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.2302255481481552, Train Loss: 0.22504810988903046
[32m[0512 06:18:07 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.23022626340389252, Train Loss: 0.22503824532032013
[32m[0512 06:18:07 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.23022708296775818, Train Loss: 0.2250286489725113
[32m[0512 06:18:07 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.2302280217409134, Train Loss: 0.22501926124095917
[32m[0512 06:18:07 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.23022902011871338, Train Loss: 0.22501003742218018
[32m[0512 06:18:07 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.2302301675081253, Train Loss: 0.2250009924173355
[32m[0512 06:18:07 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.2302314043045044, Train Loss: 0.22499215602874756
[32m[0512 06:18:07 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.23023270070552826, Train Loss: 0.22498351335525513
[32m[0512 06:18:07 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.23023416101932526, Train Loss: 0.22497498989105225
[32m[0512 06:18:07 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.23023569583892822, Train Loss: 0.2249666452407837
[32m[0512 06:18:07 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.23023730516433716, Train Loss: 0.22495847940444946
[32m[0512 06:18:07 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.23023901879787445, Train Loss: 0.22495044767856598
[32m[0512 06:18:07 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.2302408516407013, Train Loss: 0.22494257986545563
[32m[0512 06:18:07 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.2302427589893341, Train Loss: 0.22493486106395721
[32m[0512 06:18:07 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.23024475574493408, Train Loss: 0.22492726147174835
[32m[0512 06:18:07 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.23024684190750122, Train Loss: 0.22491984069347382
[32m[0512 06:18:07 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.23024900257587433, Train Loss: 0.22491253912448883
[32m[0512 06:18:07 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.2302512675523758, Train Loss: 0.22490531206130981
[32m[0512 06:18:07 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.23025359213352203, Train Loss: 0.22489826381206512
[32m[0512 06:18:07 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.23025602102279663, Train Loss: 0.2248913198709488
[32m[0512 06:18:07 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.230258509516716, Train Loss: 0.224884495139122
[32m[0512 06:18:07 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.23026105761528015, Train Loss: 0.22487778961658478
[32m[0512 06:18:07 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.23026368021965027, Train Loss: 0.2248711735010147
[32m[0512 06:18:07 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.23026634752750397, Train Loss: 0.224864661693573
[32m[0512 06:18:08 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.23026910424232483, Train Loss: 0.22485828399658203
[32m[0512 06:18:08 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.23027190566062927, Train Loss: 0.22485196590423584
[32m[0512 06:18:08 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.2302747666835785, Train Loss: 0.2248457670211792
[32m[0512 06:18:08 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.23027770221233368, Train Loss: 0.22483964264392853
[32m[0512 06:18:08 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.23028060793876648, Train Loss: 0.22483360767364502
[32m[0512 06:18:08 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.23028360307216644, Train Loss: 0.22482764720916748
[32m[0512 06:18:08 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.23028664290905, Train Loss: 0.2248217612504959
[32m[0512 06:18:08 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.23028972744941711, Train Loss: 0.2248159646987915
[32m[0512 06:18:08 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.23029281198978424, Train Loss: 0.22481019794940948
[32m[0512 06:18:08 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.23029592633247375, Train Loss: 0.2248045653104782
[32m[0512 06:18:08 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.23029910027980804, Train Loss: 0.22479896247386932
[32m[0512 06:18:08 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.23030227422714233, Train Loss: 0.2247934341430664
[32m[0512 06:18:08 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.2303055077791214, Train Loss: 0.22478793561458588
[32m[0512 06:18:08 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.23030871152877808, Train Loss: 0.22478251159191132
[32m[0512 06:18:08 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.23031194508075714, Train Loss: 0.22477711737155914
[32m[0512 06:18:08 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.2303152084350586, Train Loss: 0.22477178275585175
[32m[0512 06:18:08 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.23031848669052124, Train Loss: 0.22476649284362793
[32m[0512 06:18:08 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.2303217649459839, Train Loss: 0.2247612476348877
[32m[0512 06:18:08 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.23032501339912415, Train Loss: 0.22475606203079224
[32m[0512 06:18:08 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.23032832145690918, Train Loss: 0.22475089132785797
[32m[0512 06:18:08 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.2303316444158554, Train Loss: 0.22474579513072968
[32m[0512 06:18:08 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.23033492267131805, Train Loss: 0.22474068403244019
[32m[0512 06:18:08 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.2303382307291031, Train Loss: 0.22473566234111786
[32m[0512 06:18:08 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.23034153878688812, Train Loss: 0.22473061084747314
[32m[0512 06:18:08 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.23034486174583435, Train Loss: 0.22472558915615082
[32m[0512 06:18:08 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.230348140001297, Train Loss: 0.22472061216831207
[32m[0512 06:18:08 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.23035143315792084, Train Loss: 0.22471565008163452
[32m[0512 06:18:08 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.23035472631454468, Train Loss: 0.22471071779727936
[32m[0512 06:18:08 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.23035800457000732, Train Loss: 0.22470581531524658
[32m[0512 06:18:08 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.23036131262779236, Train Loss: 0.224700927734375
[32m[0512 06:18:08 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.23036454617977142, Train Loss: 0.2246960550546646
[32m[0512 06:18:08 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.23036783933639526, Train Loss: 0.22469119727611542
[32m[0512 06:18:08 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.23037110269069672, Train Loss: 0.22468633949756622
[32m[0512 06:18:08 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.23037435114383698, Train Loss: 0.224681556224823
[32m[0512 06:18:09 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.23037761449813843, Train Loss: 0.2246767282485962
[32m[0512 06:18:09 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.2303808480501175, Train Loss: 0.22467191517353058
[32m[0512 06:18:09 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.23038408160209656, Train Loss: 0.22466714680194855
[32m[0512 06:18:09 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.23038731515407562, Train Loss: 0.22466236352920532
[32m[0512 06:18:09 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.2303905040025711, Train Loss: 0.2246575802564621
[32m[0512 06:18:09 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.23039370775222778, Train Loss: 0.22465278208255768
[32m[0512 06:18:09 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.23039688169956207, Train Loss: 0.22464807331562042
[32m[0512 06:18:09 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.23040010035037994, Train Loss: 0.2246433049440384
[32m[0512 06:18:09 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.23040324449539185, Train Loss: 0.22463858127593994
[32m[0512 06:18:09 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.23040641844272614, Train Loss: 0.2246338278055191
[32m[0512 06:18:09 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.23040956258773804, Train Loss: 0.22462910413742065
[32m[0512 06:18:09 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.23041270673274994, Train Loss: 0.22462435066699982
[32m[0512 06:18:09 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.23041585087776184, Train Loss: 0.22461962699890137
[32m[0512 06:18:09 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.23041896522045135, Train Loss: 0.2246149182319641
[32m[0512 06:18:09 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.23042207956314087, Train Loss: 0.22461019456386566
[32m[0512 06:18:09 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.23042520880699158, Train Loss: 0.22460545599460602
[32m[0512 06:18:09 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.2304282933473587, Train Loss: 0.22460073232650757
[32m[0512 06:18:09 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.23043137788772583, Train Loss: 0.22459600865840912
[32m[0512 06:18:09 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.23043446242809296, Train Loss: 0.22459131479263306
[32m[0512 06:18:09 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.2304375320672989, Train Loss: 0.22458656132221222
[32m[0512 06:18:09 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.23044060170650482, Train Loss: 0.22458185255527496
[32m[0512 06:18:09 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.23044365644454956, Train Loss: 0.2245771288871765
[32m[0512 06:18:09 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.2304466962814331, Train Loss: 0.22457242012023926
[32m[0512 06:18:09 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.23044973611831665, Train Loss: 0.22456765174865723
[32m[0512 06:18:09 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.2304527759552002, Train Loss: 0.22456298768520355
[32m[0512 06:18:09 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.23045581579208374, Train Loss: 0.2245582491159439
[32m[0512 06:18:09 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.2304588109254837, Train Loss: 0.22455351054668427
[32m[0512 06:18:09 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.23046185076236725, Train Loss: 0.224548801779747
[32m[0512 06:18:09 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.2304648458957672, Train Loss: 0.22454404830932617
[32m[0512 06:18:09 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.2304678112268448, Train Loss: 0.22453932464122772
[32m[0512 06:18:09 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.23047083616256714, Train Loss: 0.22453457117080688
[32m[0512 06:18:09 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.2304738312959671, Train Loss: 0.22452986240386963
[32m[0512 06:18:09 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.23047682642936707, Train Loss: 0.2245250940322876
[32m[0512 06:18:09 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.23047977685928345, Train Loss: 0.22452037036418915
[32m[0512 06:18:10 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.2304827868938446, Train Loss: 0.2245156168937683
[32m[0512 06:18:10 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.2304857224225998, Train Loss: 0.22451086342334747
[32m[0512 06:18:10 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.23048871755599976, Train Loss: 0.22450608015060425
[32m[0512 06:18:10 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.23049166798591614, Train Loss: 0.2245013266801834
[32m[0512 06:18:10 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.2304946482181549, Train Loss: 0.22449658811092377
[32m[0512 06:18:10 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.2304975986480713, Train Loss: 0.22449183464050293
[32m[0512 06:18:10 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.23050056397914886, Train Loss: 0.2244870662689209
[32m[0512 06:18:10 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.23050349950790405, Train Loss: 0.22448228299617767
[32m[0512 06:18:10 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.23050647974014282, Train Loss: 0.22447751462459564
[32m[0512 06:18:10 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.23050940036773682, Train Loss: 0.22447270154953003
[32m[0512 06:18:10 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.230512335896492, Train Loss: 0.224467933177948
[32m[0512 06:18:10 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.23051530122756958, Train Loss: 0.22446314990520477
[32m[0512 06:18:10 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.23051823675632477, Train Loss: 0.22445835173130035
[32m[0512 06:18:10 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.23052117228507996, Train Loss: 0.22445355355739594
[32m[0512 06:18:10 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.23052412271499634, Train Loss: 0.22444875538349152
[32m[0512 06:18:10 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.23052702844142914, Train Loss: 0.2244439721107483
[32m[0512 06:18:10 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.23052997887134552, Train Loss: 0.22443915903568268
[32m[0512 06:18:10 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.2305329144001007, Train Loss: 0.22443436086177826
[32m[0512 06:18:10 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.2305358350276947, Train Loss: 0.22442953288555145
[32m[0512 06:18:10 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.23053878545761108, Train Loss: 0.22442470490932465
[32m[0512 06:18:10 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.23054172098636627, Train Loss: 0.22441989183425903
[32m[0512 06:18:10 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.23054462671279907, Train Loss: 0.22441507875919342
[32m[0512 06:18:10 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.23054756224155426, Train Loss: 0.224410280585289
[32m[0512 06:18:10 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.23055051267147064, Train Loss: 0.2244054079055786
[32m[0512 06:18:10 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.23055344820022583, Train Loss: 0.2244005799293518
[32m[0512 06:18:10 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.23055636882781982, Train Loss: 0.2243957370519638
[32m[0512 06:18:10 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.230559304356575, Train Loss: 0.224390909075737
[32m[0512 06:18:10 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.2305622547864914, Train Loss: 0.2243860810995102
[32m[0512 06:18:10 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.23056519031524658, Train Loss: 0.2243812531232834
[32m[0512 06:18:10 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.23056811094284058, Train Loss: 0.224376380443573
[32m[0512 06:18:10 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.23057103157043457, Train Loss: 0.2243715077638626
[32m[0512 06:18:10 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.23057399690151215, Train Loss: 0.2243666648864746
[32m[0512 06:18:10 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.23057690262794495, Train Loss: 0.22436177730560303
[32m[0512 06:18:10 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.23057980835437775, Train Loss: 0.22435694932937622
[32m[0512 06:18:10 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.23058278858661652, Train Loss: 0.22435207664966583
[32m[0512 06:18:11 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.2305857390165329, Train Loss: 0.22434723377227783
[32m[0512 06:18:11 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.23058867454528809, Train Loss: 0.22434236109256744
[32m[0512 06:18:11 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.23059162497520447, Train Loss: 0.22433750331401825
[32m[0512 06:18:11 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.23059456050395966, Train Loss: 0.22433261573314667
[32m[0512 06:18:11 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.23059751093387604, Train Loss: 0.22432772815227509
[32m[0512 06:18:11 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.23060043156147003, Train Loss: 0.2243228405714035
[32m[0512 06:18:11 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.2306034117937088, Train Loss: 0.2243179827928543
[32m[0512 06:18:11 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.2306063324213028, Train Loss: 0.22431309521198273
[32m[0512 06:18:11 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.23060929775238037, Train Loss: 0.22430820763111115
[32m[0512 06:18:11 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.23061221837997437, Train Loss: 0.22430334985256195
[32m[0512 06:18:11 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.23061524331569672, Train Loss: 0.22429846227169037
[32m[0512 06:18:11 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.2306181937456131, Train Loss: 0.2242935448884964
[32m[0512 06:18:11 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.23062114417552948, Train Loss: 0.22428864240646362
[32m[0512 06:18:11 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.23062409460544586, Train Loss: 0.22428375482559204
[32m[0512 06:18:11 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.23062703013420105, Train Loss: 0.22427886724472046
[32m[0512 06:18:11 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.230630025267601, Train Loss: 0.22427399456501007
[32m[0512 06:18:11 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.2306329905986786, Train Loss: 0.2242690473794937
[32m[0512 06:18:11 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.23063594102859497, Train Loss: 0.22426418960094452
[32m[0512 06:18:11 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.23063893616199493, Train Loss: 0.22425930202007294
[32m[0512 06:18:11 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.23064188659191132, Train Loss: 0.22425436973571777
[32m[0512 06:18:11 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.23064486682415009, Train Loss: 0.224249467253685
[32m[0512 06:18:11 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.23064786195755005, Train Loss: 0.22424457967281342
[32m[0512 06:18:11 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.23065084218978882, Train Loss: 0.22423966228961945
[32m[0512 06:18:11 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.23065385222434998, Train Loss: 0.22423475980758667
[32m[0512 06:18:11 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.23065683245658875, Train Loss: 0.2242298573255539
[32m[0512 06:18:11 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.23065979778766632, Train Loss: 0.22422493994235992
[32m[0512 06:18:11 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.2306627780199051, Train Loss: 0.22422003746032715
[32m[0512 06:18:11 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.23066577315330505, Train Loss: 0.22421513497829437
[32m[0512 06:18:11 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.2306687831878662, Train Loss: 0.2242102473974228
[32m[0512 06:18:11 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.23067176342010498, Train Loss: 0.22420533001422882
[32m[0512 06:18:11 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.23067477345466614, Train Loss: 0.22420041263103485
[32m[0512 06:18:11 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.2306777983903885, Train Loss: 0.22419549524784088
[32m[0512 06:18:11 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.23068079352378845, Train Loss: 0.2241905778646469
[32m[0512 06:18:11 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.2306838035583496, Train Loss: 0.22418570518493652
[32m[0512 06:18:12 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.23068682849407196, Train Loss: 0.22418075799942017
[32m[0512 06:18:12 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.23068982362747192, Train Loss: 0.22417587041854858
[32m[0512 06:18:12 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.23069283366203308, Train Loss: 0.22417093813419342
[32m[0512 06:18:12 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.23069585859775543, Train Loss: 0.22416603565216064
[32m[0512 06:18:12 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.2306988537311554, Train Loss: 0.22416113317012787
[32m[0512 06:18:12 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.23070187866687775, Train Loss: 0.2241562157869339
[32m[0512 06:18:12 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.23070494830608368, Train Loss: 0.22415129840373993
[32m[0512 06:18:12 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.23070794343948364, Train Loss: 0.22414642572402954
[32m[0512 06:18:12 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.2307109534740448, Train Loss: 0.22414149343967438
[32m[0512 06:18:12 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.23071402311325073, Train Loss: 0.2241365909576416
[32m[0512 06:18:12 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.2307170331478119, Train Loss: 0.22413168847560883
[32m[0512 06:18:12 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.23072007298469543, Train Loss: 0.22412680089473724
[32m[0512 06:18:12 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.23072309792041779, Train Loss: 0.22412188351154327
[32m[0512 06:18:12 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.23072613775730133, Train Loss: 0.2241169810295105
[32m[0512 06:18:12 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.23072919249534607, Train Loss: 0.22411207854747772
[32m[0512 06:18:12 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.23073223233222961, Train Loss: 0.22410716116428375
[32m[0512 06:18:12 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.23073527216911316, Train Loss: 0.22410227358341217
[32m[0512 06:18:12 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.2307383269071579, Train Loss: 0.22409741580486298
[32m[0512 06:18:12 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.23074141144752502, Train Loss: 0.2240924835205078
[32m[0512 06:18:12 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.23074442148208618, Train Loss: 0.22408759593963623
[32m[0512 06:18:12 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.23074749112129211, Train Loss: 0.22408270835876465
[32m[0512 06:18:12 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.23075053095817566, Train Loss: 0.22407782077789307
[32m[0512 06:18:12 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.23075363039970398, Train Loss: 0.2240729182958603
[32m[0512 06:18:12 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.23075668513774872, Train Loss: 0.2240680307149887
[32m[0512 06:18:12 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.23075975477695465, Train Loss: 0.22406314313411713
[32m[0512 06:18:12 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.2307628095149994, Train Loss: 0.22405827045440674
[32m[0512 06:18:12 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.23076587915420532, Train Loss: 0.22405336797237396
[32m[0512 06:18:12 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.23076893389225006, Train Loss: 0.22404851019382477
[32m[0512 06:18:12 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.2307720184326172, Train Loss: 0.22404362261295319
[32m[0512 06:18:12 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.23077510297298431, Train Loss: 0.2240387350320816
[32m[0512 06:18:12 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.23077817261219025, Train Loss: 0.2240338772535324
[32m[0512 06:18:12 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.23078124225139618, Train Loss: 0.22402900457382202
[32m[0512 06:18:12 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.2307843416929245, Train Loss: 0.22402411699295044
[32m[0512 06:18:12 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.23078741133213043, Train Loss: 0.22401922941207886
[32m[0512 06:18:12 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.23079051077365875, Train Loss: 0.22401435673236847
[32m[0512 06:18:12 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.23079359531402588, Train Loss: 0.22400952875614166
[32m[0512 06:18:13 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.23079665005207062, Train Loss: 0.22400468587875366
[32m[0512 06:18:13 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.23079973459243774, Train Loss: 0.22399984300136566
[32m[0512 06:18:13 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.23080281913280487, Train Loss: 0.22399498522281647
[32m[0512 06:18:13 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.23080594837665558, Train Loss: 0.22399009764194489
[32m[0512 06:18:13 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.2308090478181839, Train Loss: 0.22398526966571808
[32m[0512 06:18:13 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.23081210255622864, Train Loss: 0.22398041188716888
[32m[0512 06:18:13 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.23081520199775696, Train Loss: 0.2239755541086197
[32m[0512 06:18:13 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.23081828653812408, Train Loss: 0.22397072613239288
[32m[0512 06:18:13 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.2308214157819748, Train Loss: 0.22396588325500488
[32m[0512 06:18:13 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.2308245152235031, Train Loss: 0.22396105527877808
[32m[0512 06:18:13 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.23082759976387024, Train Loss: 0.22395622730255127
[32m[0512 06:18:13 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.23083068430423737, Train Loss: 0.22395141422748566
[32m[0512 06:18:13 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.23083381354808807, Train Loss: 0.22394658625125885
[32m[0512 06:18:13 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.23083694279193878, Train Loss: 0.22394174337387085
[32m[0512 06:18:13 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.2308400422334671, Train Loss: 0.22393696010112762
[32m[0512 06:18:13 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.23084312677383423, Train Loss: 0.22393210232257843
[32m[0512 06:18:13 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.23084622621536255, Train Loss: 0.2239273339509964
[32m[0512 06:18:13 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.23084932565689087, Train Loss: 0.22392255067825317
[32m[0512 06:18:13 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.23085243999958038, Train Loss: 0.22391772270202637
[32m[0512 06:18:13 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.2308555394411087, Train Loss: 0.22391293942928314
[32m[0512 06:18:13 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.2308586686849594, Train Loss: 0.22390812635421753
[32m[0512 06:18:13 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.23086176812648773, Train Loss: 0.2239033430814743
[32m[0512 06:18:13 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.23086485266685486, Train Loss: 0.22389857470989227
[32m[0512 06:18:13 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.23086798191070557, Train Loss: 0.22389377653598785
[32m[0512 06:18:13 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.2308710813522339, Train Loss: 0.22388899326324463
[32m[0512 06:18:13 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.2308741807937622, Train Loss: 0.2238842099905014
[32m[0512 06:18:13 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.23087731003761292, Train Loss: 0.22387945652008057
[32m[0512 06:18:13 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.23088043928146362, Train Loss: 0.22387468814849854
[32m[0512 06:18:13 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.23088353872299194, Train Loss: 0.2238699346780777
[32m[0512 06:18:13 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.23088666796684265, Train Loss: 0.22386516630649567
[32m[0512 06:18:13 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.23088973760604858, Train Loss: 0.22386042773723602
[32m[0512 06:18:13 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.2308928668498993, Train Loss: 0.223855659365654
[32m[0512 06:18:13 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.23089595139026642, Train Loss: 0.22385092079639435
[32m[0512 06:18:13 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.23089908063411713, Train Loss: 0.2238461822271347
[32m[0512 06:18:14 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.23090220987796783, Train Loss: 0.22384144365787506
[32m[0512 06:18:14 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.23090527951717377, Train Loss: 0.22383670508861542
[32m[0512 06:18:14 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.23090840876102448, Train Loss: 0.22383199632167816
[32m[0512 06:18:14 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.2309115082025528, Train Loss: 0.2238272875547409
[32m[0512 06:18:14 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.2309146374464035, Train Loss: 0.22382254898548126
[32m[0512 06:18:14 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.23091775178909302, Train Loss: 0.223817840218544
[32m[0512 06:18:14 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.23092085123062134, Train Loss: 0.22381313145160675
[32m[0512 06:18:14 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.23092395067214966, Train Loss: 0.22380846738815308
[32m[0512 06:18:14 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.23092705011367798, Train Loss: 0.22380374372005463
[32m[0512 06:18:14 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.2309301644563675, Train Loss: 0.22379906475543976
[32m[0512 06:18:14 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.2309332638978958, Train Loss: 0.2237943857908249
[32m[0512 06:18:14 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.23093636333942413, Train Loss: 0.22378967702388763
[32m[0512 06:18:14 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.23093947768211365, Train Loss: 0.22378502786159515
[32m[0512 06:18:14 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.23094254732131958, Train Loss: 0.2237803339958191
[32m[0512 06:18:14 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.2309456318616867, Train Loss: 0.2237756997346878
[32m[0512 06:18:14 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.23094876110553741, Train Loss: 0.22377103567123413
[32m[0512 06:18:14 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.23095186054706573, Train Loss: 0.22376637160778046
[32m[0512 06:18:14 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.23095497488975525, Train Loss: 0.22376172244548798
[32m[0512 06:18:14 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.23095804452896118, Train Loss: 0.2237570881843567
[32m[0512 06:18:14 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.2309611737728119, Train Loss: 0.2237524390220642
[32m[0512 06:18:14 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.23096424341201782, Train Loss: 0.2237478345632553
[32m[0512 06:18:14 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.23096731305122375, Train Loss: 0.22374320030212402
[32m[0512 06:18:14 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.23097039759159088, Train Loss: 0.22373855113983154
[32m[0512 06:18:14 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.2309735119342804, Train Loss: 0.22373396158218384
[32m[0512 06:18:14 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.23097656667232513, Train Loss: 0.22372932732105255
[32m[0512 06:18:14 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.23097966611385345, Train Loss: 0.22372473776340485
[32m[0512 06:18:14 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.23098278045654297, Train Loss: 0.22372013330459595
[32m[0512 06:18:14 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.2309858500957489, Train Loss: 0.22371554374694824
[32m[0512 06:18:14 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.23098893463611603, Train Loss: 0.22371095418930054
[32m[0512 06:18:14 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.23099200427532196, Train Loss: 0.22370637953281403
[32m[0512 06:18:14 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.2309950590133667, Train Loss: 0.2237018197774887
[32m[0512 06:18:14 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.23099811375141144, Train Loss: 0.223697230219841
[32m[0512 06:18:14 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.23100119829177856, Train Loss: 0.2236926555633545
[32m[0512 06:18:14 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.2310042828321457, Train Loss: 0.22368812561035156
[32m[0512 06:18:14 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.23100732266902924, Train Loss: 0.22368355095386505
[32m[0512 06:18:15 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.23101040720939636, Train Loss: 0.2236790508031845
[32m[0512 06:18:15 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.2310134619474411, Train Loss: 0.2236744910478592
[32m[0512 06:18:15 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.23101653158664703, Train Loss: 0.22366994619369507
[32m[0512 06:18:15 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.23101958632469177, Train Loss: 0.22366541624069214
[32m[0512 06:18:15 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.2310226410627365, Train Loss: 0.2236609011888504
[32m[0512 06:18:15 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.23102571070194244, Train Loss: 0.22365641593933105
[32m[0512 06:18:15 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.231028750538826, Train Loss: 0.22365190088748932
[32m[0512 06:18:15 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.23103179037570953, Train Loss: 0.22364741563796997
[32m[0512 06:18:15 @mbmf_sampler.py:98][0m Finished 9th episode
[32m[0512 06:18:15 @mbmf_sampler.py:102][0m 1809 timesteps from 9 episodes collected
[32m[0512 06:37:26 @mbmf_trainer.py:160][0m Mean reward: -277.9847641243181
[32m[0512 06:37:26 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.22432154417037964, Train Loss: 0.2214364856481552
[32m[0512 06:37:26 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.22437870502471924, Train Loss: 0.22139398753643036
[32m[0512 06:37:26 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.22438912093639374, Train Loss: 0.2213641107082367
[32m[0512 06:37:26 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.2244056910276413, Train Loss: 0.22134001553058624
[32m[0512 06:37:26 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.22442768514156342, Train Loss: 0.22131966054439545
[32m[0512 06:37:26 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.22444882988929749, Train Loss: 0.22130151093006134
[32m[0512 06:37:26 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.22446848452091217, Train Loss: 0.221284881234169
[32m[0512 06:37:27 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.22448737919330597, Train Loss: 0.2212696224451065
[32m[0512 06:37:27 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.2245056927204132, Train Loss: 0.22125551104545593
[32m[0512 06:37:27 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.22452345490455627, Train Loss: 0.22124244272708893
[32m[0512 06:37:27 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.22454063594341278, Train Loss: 0.22123029828071594
[32m[0512 06:37:27 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.22455725073814392, Train Loss: 0.22121891379356384
[32m[0512 06:37:27 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.2245733141899109, Train Loss: 0.22120818495750427
[32m[0512 06:37:27 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.22458888590335846, Train Loss: 0.22119808197021484
[32m[0512 06:37:27 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.22460393607616425, Train Loss: 0.2211885154247284
[32m[0512 06:37:27 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.22461852431297302, Train Loss: 0.22117938101291656
[32m[0512 06:37:27 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.2246326208114624, Train Loss: 0.22117067873477936
[32m[0512 06:37:27 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.22464631497859955, Train Loss: 0.2211623638868332
[32m[0512 06:37:27 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.2246595174074173, Train Loss: 0.22115439176559448
[32m[0512 06:37:27 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.22467230260372162, Train Loss: 0.22114673256874084
[32m[0512 06:37:27 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.2246847003698349, Train Loss: 0.22113938629627228
[32m[0512 06:37:27 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.22469668090343475, Train Loss: 0.2211322784423828
[32m[0512 06:37:27 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.22470827400684357, Train Loss: 0.22112539410591125
[32m[0512 06:37:27 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.22471947968006134, Train Loss: 0.2211187332868576
[32m[0512 06:37:27 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.22473034262657166, Train Loss: 0.22111225128173828
[32m[0512 06:37:27 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.22474083304405212, Train Loss: 0.22110596299171448
[32m[0512 06:37:27 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.22475092113018036, Train Loss: 0.221099853515625
[32m[0512 06:37:27 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.2247607409954071, Train Loss: 0.22109387814998627
[32m[0512 06:37:27 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.2247702181339264, Train Loss: 0.22108803689479828
[32m[0512 06:37:27 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.22477933764457703, Train Loss: 0.22108235955238342
[32m[0512 06:37:27 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.22478820383548737, Train Loss: 0.22107678651809692
[32m[0512 06:37:27 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.22479680180549622, Train Loss: 0.2210712879896164
[32m[0512 06:37:27 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.22480508685112, Train Loss: 0.221065953373909
[32m[0512 06:37:27 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.2248130738735199, Train Loss: 0.22106070816516876
[32m[0512 06:37:27 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.2248208224773407, Train Loss: 0.2210555076599121
[32m[0512 06:37:27 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.2248283177614212, Train Loss: 0.221050426363945
[32m[0512 06:37:28 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.224835604429245, Train Loss: 0.2210453897714615
[32m[0512 06:37:28 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.2248426228761673, Train Loss: 0.22104044258594513
[32m[0512 06:37:28 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.22484944760799408, Train Loss: 0.22103558480739594
[32m[0512 06:37:28 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.22485603392124176, Train Loss: 0.22103074193000793
[32m[0512 06:37:28 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.22486241161823273, Train Loss: 0.2210259884595871
[32m[0512 06:37:28 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.22486859560012817, Train Loss: 0.22102126479148865
[32m[0512 06:37:28 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.2248746156692505, Train Loss: 0.22101663053035736
[32m[0512 06:37:28 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.2248804122209549, Train Loss: 0.22101204097270966
[32m[0512 06:37:28 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.22488607466220856, Train Loss: 0.22100748121738434
[32m[0512 06:37:28 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.2248915135860443, Train Loss: 0.2210029512643814
[32m[0512 06:37:28 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.2248968780040741, Train Loss: 0.22099846601486206
[32m[0512 06:37:28 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.22490200400352478, Train Loss: 0.2209940403699875
[32m[0512 06:37:28 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.22490699589252472, Train Loss: 0.2209896445274353
[32m[0512 06:37:28 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.2249118536710739, Train Loss: 0.22098524868488312
[32m[0512 06:37:28 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.22491662204265594, Train Loss: 0.2209809124469757
[32m[0512 06:37:28 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.22492121160030365, Train Loss: 0.22097662091255188
[32m[0512 06:37:28 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.2249256819486618, Train Loss: 0.22097231447696686
[32m[0512 06:37:28 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.2249300330877304, Train Loss: 0.2209680825471878
[32m[0512 06:37:28 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.22493425011634827, Train Loss: 0.22096382081508636
[32m[0512 06:37:28 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.22493837773799896, Train Loss: 0.2209596335887909
[32m[0512 06:37:28 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.2249424159526825, Train Loss: 0.22095546126365662
[32m[0512 06:37:28 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.22494634985923767, Train Loss: 0.22095130383968353
[32m[0512 06:37:28 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.2249501645565033, Train Loss: 0.22094716131687164
[32m[0512 06:37:28 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.22495387494564056, Train Loss: 0.22094304859638214
[32m[0512 06:37:28 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.22495752573013306, Train Loss: 0.22093895077705383
[32m[0512 06:37:28 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.2249610871076584, Train Loss: 0.22093485295772552
[32m[0512 06:37:28 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.22496454417705536, Train Loss: 0.220930814743042
[32m[0512 06:37:28 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.22496794164180756, Train Loss: 0.22092676162719727
[32m[0512 06:37:29 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.22497126460075378, Train Loss: 0.22092270851135254
[32m[0512 06:37:29 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.22497451305389404, Train Loss: 0.2209187000989914
[32m[0512 06:37:29 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.22497768700122833, Train Loss: 0.22091467678546906
[32m[0512 06:37:29 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.22498080134391785, Train Loss: 0.2209107130765915
[32m[0512 06:37:29 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.22498385608196259, Train Loss: 0.22090671956539154
[32m[0512 06:37:29 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.22498683631420135, Train Loss: 0.22090277075767517
[32m[0512 06:37:29 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.22498977184295654, Train Loss: 0.2208988070487976
[32m[0512 06:37:29 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.22499263286590576, Train Loss: 0.22089487314224243
[32m[0512 06:37:29 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.2249954640865326, Train Loss: 0.22089093923568726
[32m[0512 06:37:29 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.22499823570251465, Train Loss: 0.22088700532913208
[32m[0512 06:37:29 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.22500094771385193, Train Loss: 0.22088311612606049
[32m[0512 06:37:29 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.2250036597251892, Train Loss: 0.2208792120218277
[32m[0512 06:37:29 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.22500628232955933, Train Loss: 0.2208753079175949
[32m[0512 06:37:29 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.22500887513160706, Train Loss: 0.22087141871452332
[32m[0512 06:37:29 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.2250114232301712, Train Loss: 0.2208675742149353
[32m[0512 06:37:29 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.22501394152641296, Train Loss: 0.2208637148141861
[32m[0512 06:37:29 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.22501643002033234, Train Loss: 0.2208598405122757
[32m[0512 06:37:29 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.22501887381076813, Train Loss: 0.22085601091384888
[32m[0512 06:37:29 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.22502128779888153, Train Loss: 0.22085218131542206
[32m[0512 06:37:29 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.22502365708351135, Train Loss: 0.22084832191467285
[32m[0512 06:37:29 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.2250259816646576, Train Loss: 0.22084452211856842
[32m[0512 06:37:29 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.22502832114696503, Train Loss: 0.2208406925201416
[32m[0512 06:37:29 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.22503061592578888, Train Loss: 0.22083687782287598
[32m[0512 06:37:29 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.22503285109996796, Train Loss: 0.22083307802677155
[32m[0512 06:37:29 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.22503510117530823, Train Loss: 0.2208293080329895
[32m[0512 06:37:29 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.2250373512506485, Train Loss: 0.22082549333572388
[32m[0512 06:37:29 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.2250395268201828, Train Loss: 0.22082169353961945
[32m[0512 06:37:29 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.2250417023897171, Train Loss: 0.2208179384469986
[32m[0512 06:37:30 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.22504383325576782, Train Loss: 0.22081416845321655
[32m[0512 06:37:30 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.22504600882530212, Train Loss: 0.2208104133605957
[32m[0512 06:37:30 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.22504813969135284, Train Loss: 0.22080662846565247
[32m[0512 06:37:30 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.22505024075508118, Train Loss: 0.22080285847187042
[32m[0512 06:37:30 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.22505229711532593, Train Loss: 0.22079911828041077
[32m[0512 06:37:30 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.22505438327789307, Train Loss: 0.2207953780889511
[32m[0512 06:37:30 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.22505643963813782, Train Loss: 0.22079163789749146
[32m[0512 06:37:30 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.22505849599838257, Train Loss: 0.2207879275083542
[32m[0512 06:37:30 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.22506050765514374, Train Loss: 0.22078417241573334
[32m[0512 06:37:30 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.2250625491142273, Train Loss: 0.22078043222427368
[32m[0512 06:37:30 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.22506454586982727, Train Loss: 0.22077669203281403
[32m[0512 06:37:30 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.22506655752658844, Train Loss: 0.22077298164367676
[32m[0512 06:37:30 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.22506853938102722, Train Loss: 0.2207692712545395
[32m[0512 06:37:30 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.2250705361366272, Train Loss: 0.22076557576656342
[32m[0512 06:37:30 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.2250724881887436, Train Loss: 0.22076185047626495
[32m[0512 06:37:30 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.22507445514202118, Train Loss: 0.22075815498828888
[32m[0512 06:37:30 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.22507640719413757, Train Loss: 0.22075442969799042
[32m[0512 06:37:30 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.22507835924625397, Train Loss: 0.22075077891349792
[32m[0512 06:37:30 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.22508032619953156, Train Loss: 0.22074705362319946
[32m[0512 06:37:30 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.22508227825164795, Train Loss: 0.22074337303638458
[32m[0512 06:37:30 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.22508418560028076, Train Loss: 0.2207396775484085
[32m[0512 06:37:30 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.22508613765239716, Train Loss: 0.22073601186275482
[32m[0512 06:37:30 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.22508805990219116, Train Loss: 0.22073234617710114
[32m[0512 06:37:30 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.22508999705314636, Train Loss: 0.22072865068912506
[32m[0512 06:37:30 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.22509191930294037, Train Loss: 0.22072499990463257
[32m[0512 06:37:30 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.22509382665157318, Train Loss: 0.2207213193178177
[32m[0512 06:37:30 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.22509576380252838, Train Loss: 0.220717653632164
[32m[0512 06:37:31 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.2250976711511612, Train Loss: 0.2207140028476715
[32m[0512 06:37:31 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.2250996232032776, Train Loss: 0.22071033716201782
[32m[0512 06:37:31 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.225101500749588, Train Loss: 0.22070668637752533
[32m[0512 06:37:31 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.2251034379005432, Train Loss: 0.22070302069187164
[32m[0512 06:37:31 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.22510536015033722, Train Loss: 0.22069936990737915
[32m[0512 06:37:31 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.22510728240013123, Train Loss: 0.22069570422172546
[32m[0512 06:37:31 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.22510918974876404, Train Loss: 0.22069209814071655
[32m[0512 06:37:31 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.22511112689971924, Train Loss: 0.22068843245506287
[32m[0512 06:37:31 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.22511301934719086, Train Loss: 0.22068479657173157
[32m[0512 06:37:31 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.22511495649814606, Train Loss: 0.22068116068840027
[32m[0512 06:37:31 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.22511687874794006, Train Loss: 0.22067755460739136
[32m[0512 06:37:31 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.22511878609657288, Train Loss: 0.22067388892173767
[32m[0512 06:37:31 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.22512072324752808, Train Loss: 0.22067028284072876
[32m[0512 06:37:31 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.22512269020080566, Train Loss: 0.22066664695739746
[32m[0512 06:37:31 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.22512458264827728, Train Loss: 0.22066302597522736
[32m[0512 06:37:31 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.22512654960155487, Train Loss: 0.22065940499305725
[32m[0512 06:37:31 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.22512848675251007, Train Loss: 0.22065576910972595
[32m[0512 06:37:31 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.22513042390346527, Train Loss: 0.22065216302871704
[32m[0512 06:37:31 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.22513239085674286, Train Loss: 0.22064857184886932
[32m[0512 06:37:31 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.22513431310653687, Train Loss: 0.22064495086669922
[32m[0512 06:37:31 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.22513626515865326, Train Loss: 0.2206413447856903
[32m[0512 06:37:31 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.22513823211193085, Train Loss: 0.2206377387046814
[32m[0512 06:37:31 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.22514018416404724, Train Loss: 0.22063414752483368
[32m[0512 06:37:31 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.22514216601848602, Train Loss: 0.22063055634498596
[32m[0512 06:37:31 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.22514411807060242, Train Loss: 0.22062692046165466
[32m[0512 06:37:31 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.2251461148262024, Train Loss: 0.22062332928180695
[32m[0512 06:37:31 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.22514811158180237, Train Loss: 0.22061972320079803
[32m[0512 06:37:31 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.22515009343624115, Train Loss: 0.2206161469221115
[32m[0512 06:37:32 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.22515206038951874, Train Loss: 0.2206125557422638
[32m[0512 06:37:32 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.2251540720462799, Train Loss: 0.22060896456241608
[32m[0512 06:37:32 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.22515606880187988, Train Loss: 0.22060537338256836
[32m[0512 06:37:32 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.22515806555747986, Train Loss: 0.22060178220272064
[32m[0512 06:37:32 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.22516009211540222, Train Loss: 0.2205982208251953
[32m[0512 06:37:32 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.2251621037721634, Train Loss: 0.2205946296453476
[32m[0512 06:37:32 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.22516413033008575, Train Loss: 0.22059106826782227
[32m[0512 06:37:32 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.22516614198684692, Train Loss: 0.22058747708797455
[32m[0512 06:37:32 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.22516821324825287, Train Loss: 0.22058390080928802
[32m[0512 06:37:32 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.22517025470733643, Train Loss: 0.2205803394317627
[32m[0512 06:37:32 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.22517229616641998, Train Loss: 0.22057674825191498
[32m[0512 06:37:32 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.22517436742782593, Train Loss: 0.22057320177555084
[32m[0512 06:37:32 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.22517643868923187, Train Loss: 0.22056961059570312
[32m[0512 06:37:32 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.22517846524715424, Train Loss: 0.22056607902050018
[32m[0512 06:37:32 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.22518053650856018, Train Loss: 0.22056250274181366
[32m[0512 06:37:32 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.22518262267112732, Train Loss: 0.22055891156196594
[32m[0512 06:37:32 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.22518472373485565, Train Loss: 0.2205553650856018
[32m[0512 06:37:32 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.22518682479858398, Train Loss: 0.22055180370807648
[32m[0512 06:37:32 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.22518891096115112, Train Loss: 0.22054825723171234
[32m[0512 06:37:32 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.22519102692604065, Train Loss: 0.2205447256565094
[32m[0512 06:37:32 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.22519312798976898, Train Loss: 0.22054116427898407
[32m[0512 06:37:32 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.2251952439546585, Train Loss: 0.22053761780261993
[32m[0512 06:37:32 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.22519735991954803, Train Loss: 0.220534086227417
[32m[0512 06:37:32 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.22519952058792114, Train Loss: 0.22053052484989166
[32m[0512 06:37:32 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.22520163655281067, Train Loss: 0.22052697837352753
[32m[0512 06:37:32 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.22520379722118378, Train Loss: 0.2205234318971634
[32m[0512 06:37:32 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.22520595788955688, Train Loss: 0.22051991522312164
[32m[0512 06:37:33 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.2252080738544464, Train Loss: 0.2205163687467575
[32m[0512 06:37:33 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.2252102643251419, Train Loss: 0.22051282227039337
[32m[0512 06:37:33 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.2252124398946762, Train Loss: 0.22050930559635162
[32m[0512 06:37:33 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.2252146154642105, Train Loss: 0.2205057591199875
[32m[0512 06:37:33 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.2252167910337448, Train Loss: 0.22050221264362335
[32m[0512 06:37:33 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.2252189815044403, Train Loss: 0.2204987108707428
[32m[0512 06:37:33 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.225221186876297, Train Loss: 0.22049519419670105
[32m[0512 06:37:33 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.2252233922481537, Train Loss: 0.22049164772033691
[32m[0512 06:37:33 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.22522559762001038, Train Loss: 0.22048811614513397
[32m[0512 06:37:33 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.22522781789302826, Train Loss: 0.22048459947109222
[32m[0512 06:37:33 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.22523005306720734, Train Loss: 0.22048108279705048
[32m[0512 06:37:33 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.22523227334022522, Train Loss: 0.22047758102416992
[32m[0512 06:37:33 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.2252345085144043, Train Loss: 0.22047406435012817
[32m[0512 06:37:33 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.22523675858974457, Train Loss: 0.22047056257724762
[32m[0512 06:37:33 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.22523902356624603, Train Loss: 0.22046704590320587
[32m[0512 06:37:33 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.2252413034439087, Train Loss: 0.2204635590314865
[32m[0512 06:37:33 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.22524352371692657, Train Loss: 0.22046002745628357
[32m[0512 06:37:33 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.22524580359458923, Train Loss: 0.2204565405845642
[32m[0512 06:37:33 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.2252480834722519, Train Loss: 0.22045300900936127
[32m[0512 06:37:33 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.22525037825107574, Train Loss: 0.2204495072364807
[32m[0512 06:37:33 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.2252526581287384, Train Loss: 0.22044602036476135
[32m[0512 06:37:33 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.22525496780872345, Train Loss: 0.2204425185918808
[32m[0512 06:37:33 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.2252572625875473, Train Loss: 0.22043900191783905
[32m[0512 06:37:33 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.22525960206985474, Train Loss: 0.22043554484844208
[32m[0512 06:37:33 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.2252618819475174, Train Loss: 0.22043202817440033
[32m[0512 06:37:33 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.22526422142982483, Train Loss: 0.22042852640151978
[32m[0512 06:37:33 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.22526654601097107, Train Loss: 0.2204250693321228
[32m[0512 06:37:33 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.2252688854932785, Train Loss: 0.22042155265808105
[32m[0512 06:37:34 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.22527123987674713, Train Loss: 0.2204180508852005
[32m[0512 06:37:34 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.22527357935905457, Train Loss: 0.22041457891464233
[32m[0512 06:37:34 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.2252759337425232, Train Loss: 0.22041112184524536
[32m[0512 06:37:34 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.22527828812599182, Train Loss: 0.2204076498746872
[32m[0512 06:37:34 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.22528064250946045, Train Loss: 0.22040413320064545
[32m[0512 06:37:34 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.22528304159641266, Train Loss: 0.2204006463289261
[32m[0512 06:37:34 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.2252853810787201, Train Loss: 0.2203972041606903
[32m[0512 06:37:34 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.2252878099679947, Train Loss: 0.22039371728897095
[32m[0512 06:37:34 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.2252901792526245, Train Loss: 0.22039026021957397
[32m[0512 06:37:34 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.2252926081418991, Train Loss: 0.22038677334785461
[32m[0512 06:37:34 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.22529497742652893, Train Loss: 0.22038333117961884
[32m[0512 06:37:34 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.22529740631580353, Train Loss: 0.22037985920906067
[32m[0512 06:37:34 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.22529982030391693, Train Loss: 0.2203764170408249
[32m[0512 06:37:34 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.22530223429203033, Train Loss: 0.22037294507026672
[32m[0512 06:37:34 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.22530464828014374, Train Loss: 0.22036948800086975
[32m[0512 06:37:34 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.22530710697174072, Train Loss: 0.220365971326828
[32m[0512 06:37:34 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.22530952095985413, Train Loss: 0.2203625738620758
[32m[0512 06:37:34 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.22531196475028992, Train Loss: 0.22035910189151764
[32m[0512 06:37:34 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.2253144234418869, Train Loss: 0.22035565972328186
[32m[0512 06:37:34 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.2253168821334839, Train Loss: 0.2203521877527237
[32m[0512 06:37:34 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.22531935572624207, Train Loss: 0.2203487753868103
[32m[0512 06:37:34 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.22532182931900024, Train Loss: 0.22034533321857452
[32m[0512 06:37:34 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.22532428801059723, Train Loss: 0.22034186124801636
[32m[0512 06:37:34 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.2253267467021942, Train Loss: 0.22033843398094177
[32m[0512 06:37:34 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.22532925009727478, Train Loss: 0.220334991812706
[32m[0512 06:37:34 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.22533172369003296, Train Loss: 0.2203315645456314
[32m[0512 06:37:34 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.22533421218395233, Train Loss: 0.22032810747623444
[32m[0512 06:37:34 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.2253367155790329, Train Loss: 0.22032469511032104
[32m[0512 06:37:34 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.22533921897411346, Train Loss: 0.22032120823860168
[32m[0512 06:37:34 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.22534175217151642, Train Loss: 0.2203178107738495
[32m[0512 06:37:35 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.2253442406654358, Train Loss: 0.2203143686056137
[32m[0512 06:37:35 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.22534677386283875, Train Loss: 0.22031094133853912
[32m[0512 06:37:35 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.2253492921590805, Train Loss: 0.22030752897262573
[32m[0512 06:37:35 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.22535182535648346, Train Loss: 0.22030410170555115
[32m[0512 06:37:35 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.22535432875156403, Train Loss: 0.22030068933963776
[32m[0512 06:37:35 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.22535687685012817, Train Loss: 0.22029729187488556
[32m[0512 06:37:35 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.22535943984985352, Train Loss: 0.2202938348054886
[32m[0512 06:37:35 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.22536197304725647, Train Loss: 0.22029045224189758
[32m[0512 06:37:35 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.2253645360469818, Train Loss: 0.220287024974823
[32m[0512 06:37:35 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.22536709904670715, Train Loss: 0.2202836126089096
[32m[0512 06:37:35 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.2253696620464325, Train Loss: 0.22028018534183502
[32m[0512 06:37:35 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.22537222504615784, Train Loss: 0.2202768176794052
[32m[0512 06:37:35 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.22537480294704437, Train Loss: 0.22027340531349182
[32m[0512 06:37:35 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.2253773957490921, Train Loss: 0.22026996314525604
[32m[0512 06:37:35 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.22537995874881744, Train Loss: 0.22026658058166504
[32m[0512 06:37:35 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.22538253664970398, Train Loss: 0.22026319801807404
[32m[0512 06:37:35 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.2253851294517517, Train Loss: 0.22025980055332184
[32m[0512 06:37:35 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.22538770735263824, Train Loss: 0.22025640308856964
[32m[0512 06:37:35 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.22539032995700836, Train Loss: 0.22025299072265625
[32m[0512 06:37:35 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.2253929227590561, Train Loss: 0.22024962306022644
[32m[0512 06:37:35 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.22539553046226501, Train Loss: 0.22024622559547424
[32m[0512 06:37:35 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.22539813816547394, Train Loss: 0.22024284303188324
[32m[0512 06:37:35 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.22540076076984406, Train Loss: 0.22023944556713104
[32m[0512 06:37:35 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.22540338337421417, Train Loss: 0.22023607790470123
[32m[0512 06:37:35 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.2254060059785843, Train Loss: 0.22023271024227142
[32m[0512 06:37:35 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.2254086434841156, Train Loss: 0.22022931277751923
[32m[0512 06:37:35 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.22541125118732452, Train Loss: 0.2202259600162506
[32m[0512 06:37:35 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.22541387379169464, Train Loss: 0.2202225625514984
[32m[0512 06:37:36 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.22541654109954834, Train Loss: 0.2202191799879074
[32m[0512 06:37:36 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.22541917860507965, Train Loss: 0.2202158123254776
[32m[0512 06:37:36 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.22542181611061096, Train Loss: 0.22021245956420898
[32m[0512 06:37:36 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.22542449831962585, Train Loss: 0.2202090620994568
[32m[0512 06:37:36 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.22542713582515717, Train Loss: 0.22020570933818817
[32m[0512 06:37:36 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.22542978823184967, Train Loss: 0.22020235657691956
[32m[0512 06:37:36 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.22543248534202576, Train Loss: 0.22019900381565094
[32m[0512 06:37:36 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.22543510794639587, Train Loss: 0.22019563615322113
[32m[0512 06:37:36 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.22543780505657196, Train Loss: 0.22019228339195251
[32m[0512 06:37:36 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.22544047236442566, Train Loss: 0.2201889306306839
[32m[0512 06:37:36 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.22544315457344055, Train Loss: 0.22018557786941528
[32m[0512 06:37:36 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.22544580698013306, Train Loss: 0.22018222510814667
[32m[0512 06:37:36 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.22544851899147034, Train Loss: 0.22017887234687805
[32m[0512 06:37:36 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.22545120120048523, Train Loss: 0.22017551958560944
[32m[0512 06:37:36 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.22545388340950012, Train Loss: 0.22017218172550201
[32m[0512 06:37:36 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.2254566103219986, Train Loss: 0.2201688438653946
[32m[0512 06:37:36 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.22545930743217468, Train Loss: 0.22016550600528717
[32m[0512 06:37:36 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.22546200454235077, Train Loss: 0.22016218304634094
[32m[0512 06:37:36 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.22546470165252686, Train Loss: 0.22015881538391113
[32m[0512 06:37:36 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.22546739876270294, Train Loss: 0.2201555073261261
[32m[0512 06:37:36 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.22547011077404022, Train Loss: 0.22015216946601868
[32m[0512 06:37:36 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.2254728376865387, Train Loss: 0.22014884650707245
[32m[0512 06:37:36 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.22547556459903717, Train Loss: 0.22014550864696503
[32m[0512 06:37:36 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.22547827661037445, Train Loss: 0.2201421856880188
[32m[0512 06:37:36 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.22548098862171173, Train Loss: 0.22013884782791138
[32m[0512 06:37:36 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.2254837155342102, Train Loss: 0.22013555467128754
[32m[0512 06:37:36 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.22548645734786987, Train Loss: 0.2201322466135025
[32m[0512 06:37:36 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.22548919916152954, Train Loss: 0.22012893855571747
[32m[0512 06:37:37 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.2254919409751892, Train Loss: 0.22012560069561005
[32m[0512 06:37:37 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.22549468278884888, Train Loss: 0.2201223075389862
[32m[0512 06:37:37 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.22549740970134735, Train Loss: 0.22011898458003998
[32m[0512 06:37:37 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.22550015151500702, Train Loss: 0.22011567652225494
[32m[0512 06:37:37 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.22550290822982788, Train Loss: 0.2201123684644699
[32m[0512 06:37:37 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.22550565004348755, Train Loss: 0.22010907530784607
[32m[0512 06:37:37 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.2255084216594696, Train Loss: 0.22010578215122223
[32m[0512 06:37:37 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.22551117837429047, Train Loss: 0.2201024740934372
[32m[0512 06:37:37 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.22551392018795013, Train Loss: 0.22009919583797455
[32m[0512 06:37:37 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.2255166918039322, Train Loss: 0.22009588778018951
[32m[0512 06:37:37 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.22551944851875305, Train Loss: 0.22009259462356567
[32m[0512 06:37:37 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.2255222052335739, Train Loss: 0.22008930146694183
[32m[0512 06:37:37 @mbmf_sampler.py:98][0m Finished 9th episode
[32m[0512 06:37:37 @mbmf_sampler.py:102][0m 1809 timesteps from 9 episodes collected
[32m[0512 06:56:46 @mbmf_trainer.py:160][0m Mean reward: -283.95022065683236
[32m[0512 06:56:46 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.2236495167016983, Train Loss: 0.21677570044994354
[32m[0512 06:56:46 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.22370043396949768, Train Loss: 0.21669314801692963
[32m[0512 06:56:46 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.2237234264612198, Train Loss: 0.21665719151496887
[32m[0512 06:56:46 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.22375966608524323, Train Loss: 0.21661849319934845
[32m[0512 06:56:46 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.22380022704601288, Train Loss: 0.21659059822559357
[32m[0512 06:56:46 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.22383861243724823, Train Loss: 0.21656706929206848
[32m[0512 06:56:46 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.22387383878231049, Train Loss: 0.21654608845710754
[32m[0512 06:56:46 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.2239067703485489, Train Loss: 0.2165278196334839
[32m[0512 06:56:47 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.2239377349615097, Train Loss: 0.2165115475654602
[32m[0512 06:56:47 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.22396661341190338, Train Loss: 0.21649684011936188
[32m[0512 06:56:47 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.2239936739206314, Train Loss: 0.21648339927196503
[32m[0512 06:56:47 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.22401900589466095, Train Loss: 0.21647101640701294
[32m[0512 06:56:47 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.22404277324676514, Train Loss: 0.21645952761173248
[32m[0512 06:56:47 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.2240651249885559, Train Loss: 0.2164488136768341
[32m[0512 06:56:47 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.2240862250328064, Train Loss: 0.21643877029418945
[32m[0512 06:56:47 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.22410613298416138, Train Loss: 0.21642926335334778
[32m[0512 06:56:47 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.2241249829530716, Train Loss: 0.2164202481508255
[32m[0512 06:56:47 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.2241428643465042, Train Loss: 0.21641169488430023
[32m[0512 06:56:47 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.2241598516702652, Train Loss: 0.216403529047966
[32m[0512 06:56:47 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.22417601943016052, Train Loss: 0.21639567613601685
[32m[0512 06:56:47 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.22419147193431854, Train Loss: 0.21638819575309753
[32m[0512 06:56:47 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.22420622408390045, Train Loss: 0.2163809984922409
[32m[0512 06:56:47 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.2242203652858734, Train Loss: 0.21637402474880219
[32m[0512 06:56:47 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.224233940243721, Train Loss: 0.21636728942394257
[32m[0512 06:56:47 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.22424697875976562, Train Loss: 0.21636074781417847
[32m[0512 06:56:47 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.22425954043865204, Train Loss: 0.21635444462299347
[32m[0512 06:56:47 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.22427162528038025, Train Loss: 0.2163482904434204
[32m[0512 06:56:47 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.22428332269191742, Train Loss: 0.21634232997894287
[32m[0512 06:56:47 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.22429458796977997, Train Loss: 0.21633650362491608
[32m[0512 06:56:47 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.22430555522441864, Train Loss: 0.21633082628250122
[32m[0512 06:56:48 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.22431614995002747, Train Loss: 0.2163253128528595
[32m[0512 06:56:48 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.22432641685009003, Train Loss: 0.21631988883018494
[32m[0512 06:56:48 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.2243364155292511, Train Loss: 0.21631456911563873
[32m[0512 06:56:48 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.22434614598751068, Train Loss: 0.21630939841270447
[32m[0512 06:56:48 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.22435563802719116, Train Loss: 0.21630433201789856
[32m[0512 06:56:48 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.22436487674713135, Train Loss: 0.21629934012889862
[32m[0512 06:56:48 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.22437387704849243, Train Loss: 0.21629443764686584
[32m[0512 06:56:48 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.22438263893127441, Train Loss: 0.2162896692752838
[32m[0512 06:56:48 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.22439128160476685, Train Loss: 0.21628494560718536
[32m[0512 06:56:48 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.22439968585968018, Train Loss: 0.21628031134605408
[32m[0512 06:56:48 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.22440789639949799, Train Loss: 0.21627572178840637
[32m[0512 06:56:48 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.22441595792770386, Train Loss: 0.21627125144004822
[32m[0512 06:56:48 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.22442390024662018, Train Loss: 0.21626685559749603
[32m[0512 06:56:48 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.22443166375160217, Train Loss: 0.21626248955726624
[32m[0512 06:56:48 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.22443926334381104, Train Loss: 0.2162581980228424
[32m[0512 06:56:48 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.22444675862789154, Train Loss: 0.21625395119190216
[32m[0512 06:56:48 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.2244541049003601, Train Loss: 0.21624979376792908
[32m[0512 06:56:48 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.22446134686470032, Train Loss: 0.21624568104743958
[32m[0512 06:56:48 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.22446845471858978, Train Loss: 0.21624161303043365
[32m[0512 06:56:48 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.22447548806667328, Train Loss: 0.21623758971691132
[32m[0512 06:56:48 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.22448238730430603, Train Loss: 0.21623361110687256
[32m[0512 06:56:49 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.22448918223381042, Train Loss: 0.21622969210147858
[32m[0512 06:56:49 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.22449587285518646, Train Loss: 0.21622581779956818
[32m[0512 06:56:49 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.22450248897075653, Train Loss: 0.21622198820114136
[32m[0512 06:56:49 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.22450903058052063, Train Loss: 0.21621818840503693
[32m[0512 06:56:49 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.22451545298099518, Train Loss: 0.21621443331241608
[32m[0512 06:56:49 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.22452177107334137, Train Loss: 0.2162107229232788
[32m[0512 06:56:49 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.22452807426452637, Train Loss: 0.21620702743530273
[32m[0512 06:56:49 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.2245343029499054, Train Loss: 0.21620340645313263
[32m[0512 06:56:49 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.22454042732715607, Train Loss: 0.21619977056980133
[32m[0512 06:56:49 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.22454652190208435, Train Loss: 0.216196209192276
[32m[0512 06:56:49 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.2245524674654007, Train Loss: 0.21619264781475067
[32m[0512 06:56:49 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.22455844283103943, Train Loss: 0.2161891609430313
[32m[0512 06:56:49 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.2245643138885498, Train Loss: 0.21618567407131195
[32m[0512 06:56:49 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.2245701104402542, Train Loss: 0.21618220210075378
[32m[0512 06:56:49 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.22457584738731384, Train Loss: 0.2161787897348404
[32m[0512 06:56:49 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.22458156943321228, Train Loss: 0.216175377368927
[32m[0512 06:56:49 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.22458721697330475, Train Loss: 0.2161720246076584
[32m[0512 06:56:49 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.22459279000759125, Train Loss: 0.21616865694522858
[32m[0512 06:56:49 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.22459833323955536, Train Loss: 0.21616534888744354
[32m[0512 06:56:49 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.2246038317680359, Train Loss: 0.21616202592849731
[32m[0512 06:56:49 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.22460925579071045, Train Loss: 0.21615876257419586
[32m[0512 06:56:49 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.224614679813385, Train Loss: 0.2161554992198944
[32m[0512 06:56:49 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.2246200144290924, Train Loss: 0.21615226566791534
[32m[0512 06:56:50 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.22462530434131622, Train Loss: 0.21614904701709747
[32m[0512 06:56:50 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.22463060915470123, Train Loss: 0.21614588797092438
[32m[0512 06:56:50 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.22463585436344147, Train Loss: 0.2161426991224289
[32m[0512 06:56:50 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.22464103996753693, Train Loss: 0.2161395400762558
[32m[0512 06:56:50 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.2246461808681488, Train Loss: 0.2161364108324051
[32m[0512 06:56:50 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.2246512919664383, Train Loss: 0.21613331139087677
[32m[0512 06:56:50 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.22465632855892181, Train Loss: 0.21613018214702606
[32m[0512 06:56:50 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.22466139495372772, Train Loss: 0.21612711250782013
[32m[0512 06:56:50 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.22466640174388885, Train Loss: 0.2161240577697754
[32m[0512 06:56:50 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.2246713489294052, Train Loss: 0.21612101793289185
[32m[0512 06:56:50 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.224676251411438, Train Loss: 0.2161179780960083
[32m[0512 06:56:50 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.22468116879463196, Train Loss: 0.21611496806144714
[32m[0512 06:56:50 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.22468605637550354, Train Loss: 0.21611198782920837
[32m[0512 06:56:50 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.22469089925289154, Train Loss: 0.2161089926958084
[32m[0512 06:56:50 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.22469569742679596, Train Loss: 0.21610604226589203
[32m[0512 06:56:50 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.22470048069953918, Train Loss: 0.21610307693481445
[32m[0512 06:56:50 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.22470521926879883, Train Loss: 0.21610014140605927
[32m[0512 06:56:50 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.22470994293689728, Train Loss: 0.21609720587730408
[32m[0512 06:56:50 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.22471465170383453, Train Loss: 0.21609430015087128
[32m[0512 06:56:50 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.2247193157672882, Train Loss: 0.21609137952327728
[32m[0512 06:56:50 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.2247239351272583, Train Loss: 0.21608848869800568
[32m[0512 06:56:50 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.2247285544872284, Train Loss: 0.21608562767505646
[32m[0512 06:56:50 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.2247331142425537, Train Loss: 0.21608275175094604
[32m[0512 06:56:51 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.22473768889904022, Train Loss: 0.21607990562915802
[32m[0512 06:56:51 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.22474224865436554, Train Loss: 0.2160770744085312
[32m[0512 06:56:51 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.2247467190027237, Train Loss: 0.21607421338558197
[32m[0512 06:56:51 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.22475123405456543, Train Loss: 0.21607141196727753
[32m[0512 06:56:51 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.2247556746006012, Train Loss: 0.2160685956478119
[32m[0512 06:56:51 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.22476013004779816, Train Loss: 0.21606580913066864
[32m[0512 06:56:51 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.22476452589035034, Train Loss: 0.2160630226135254
[32m[0512 06:56:51 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.22476895153522491, Train Loss: 0.21606023609638214
[32m[0512 06:56:51 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.22477330267429352, Train Loss: 0.21605747938156128
[32m[0512 06:56:51 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.22477765381336212, Train Loss: 0.21605469286441803
[32m[0512 06:56:51 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.22478199005126953, Train Loss: 0.21605195105075836
[32m[0512 06:56:51 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.22478631138801575, Train Loss: 0.2160492241382599
[32m[0512 06:56:51 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.2247905731201172, Train Loss: 0.21604648232460022
[32m[0512 06:56:51 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.22479483485221863, Train Loss: 0.21604375541210175
[32m[0512 06:56:51 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.22479909658432007, Train Loss: 0.21604105830192566
[32m[0512 06:56:51 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.22480329871177673, Train Loss: 0.21603833138942719
[32m[0512 06:56:51 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.2248075008392334, Train Loss: 0.2160356193780899
[32m[0512 06:56:51 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.22481168806552887, Train Loss: 0.2160329520702362
[32m[0512 06:56:51 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.22481584548950195, Train Loss: 0.2160302996635437
[32m[0512 06:56:51 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.22482001781463623, Train Loss: 0.2160276174545288
[32m[0512 06:56:51 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.22482416033744812, Train Loss: 0.21602492034435272
[32m[0512 06:56:51 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.22482825815677643, Train Loss: 0.2160222977399826
[32m[0512 06:56:52 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.22483234107494354, Train Loss: 0.2160196304321289
[32m[0512 06:56:52 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.22483639419078827, Train Loss: 0.2160169631242752
[32m[0512 06:56:52 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.22484047710895538, Train Loss: 0.2160143405199051
[32m[0512 06:56:52 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.22484451532363892, Train Loss: 0.21601171791553497
[32m[0512 06:56:52 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.22484852373600006, Train Loss: 0.21600909531116486
[32m[0512 06:56:52 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.2248525321483612, Train Loss: 0.21600645780563354
[32m[0512 06:56:52 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.22485654056072235, Train Loss: 0.21600385010242462
[32m[0512 06:56:52 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.22486050426959991, Train Loss: 0.2160012274980545
[32m[0512 06:56:52 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.2248644381761551, Train Loss: 0.21599864959716797
[32m[0512 06:56:52 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.22486840188503265, Train Loss: 0.21599608659744263
[32m[0512 06:56:52 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.22487230598926544, Train Loss: 0.2159934788942337
[32m[0512 06:56:52 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.22487621009349823, Train Loss: 0.21599090099334717
[32m[0512 06:56:52 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.22488011419773102, Train Loss: 0.21598833799362183
[32m[0512 06:56:52 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.22488398849964142, Train Loss: 0.21598577499389648
[32m[0512 06:56:52 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.22488784790039062, Train Loss: 0.21598319709300995
[32m[0512 06:56:52 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.22489167749881744, Train Loss: 0.2159806489944458
[32m[0512 06:56:52 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.22489550709724426, Train Loss: 0.21597810089588165
[32m[0512 06:56:52 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.2248993217945099, Train Loss: 0.2159755676984787
[32m[0512 06:56:52 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.22490312159061432, Train Loss: 0.21597301959991455
[32m[0512 06:56:52 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.22490690648555756, Train Loss: 0.2159704864025116
[32m[0512 06:56:52 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.2249106913805008, Train Loss: 0.21596795320510864
[32m[0512 06:56:52 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.22491444647312164, Train Loss: 0.21596544981002808
[32m[0512 06:56:53 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.2249181717634201, Train Loss: 0.21596291661262512
[32m[0512 06:56:53 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.22492189705371857, Train Loss: 0.21596039831638336
[32m[0512 06:56:53 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.22492560744285583, Train Loss: 0.2159578949213028
[32m[0512 06:56:53 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.22492928802967072, Train Loss: 0.21595537662506104
[32m[0512 06:56:53 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.2249329686164856, Train Loss: 0.21595290303230286
[32m[0512 06:56:53 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.22493666410446167, Train Loss: 0.21595041453838348
[32m[0512 06:56:53 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.22494031488895416, Train Loss: 0.2159479260444641
[32m[0512 06:56:53 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.22494398057460785, Train Loss: 0.21594543755054474
[32m[0512 06:56:53 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.22494760155677795, Train Loss: 0.21594296395778656
[32m[0512 06:56:53 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.22495120763778687, Train Loss: 0.21594050526618958
[32m[0512 06:56:53 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.22495481371879578, Train Loss: 0.2159380167722702
[32m[0512 06:56:53 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.2249584048986435, Train Loss: 0.21593555808067322
[32m[0512 06:56:53 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.22496196627616882, Train Loss: 0.21593309938907623
[32m[0512 06:56:53 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.22496551275253296, Train Loss: 0.21593064069747925
[32m[0512 06:56:53 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.22496910393238068, Train Loss: 0.21592818200588226
[32m[0512 06:56:53 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.22497263550758362, Train Loss: 0.21592573821544647
[32m[0512 06:56:53 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.22497616708278656, Train Loss: 0.2159232795238495
[32m[0512 06:56:53 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.2249796986579895, Train Loss: 0.2159208506345749
[32m[0512 06:56:53 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.22498318552970886, Train Loss: 0.2159184366464615
[32m[0512 06:56:53 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.22498667240142822, Train Loss: 0.2159160077571869
[32m[0512 06:56:53 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.2249901443719864, Train Loss: 0.2159135490655899
[32m[0512 06:56:53 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.22499361634254456, Train Loss: 0.2159111648797989
[32m[0512 06:56:54 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.22499707341194153, Train Loss: 0.2159087210893631
[32m[0512 06:56:54 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.2250005453824997, Train Loss: 0.2159062922000885
[32m[0512 06:56:54 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.22500397264957428, Train Loss: 0.21590390801429749
[32m[0512 06:56:54 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.22500739991664886, Train Loss: 0.2159014791250229
[32m[0512 06:56:54 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.22501078248023987, Train Loss: 0.21589906513690948
[32m[0512 06:56:54 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.22501416504383087, Train Loss: 0.21589668095111847
[32m[0512 06:56:54 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.22501756250858307, Train Loss: 0.21589426696300507
[32m[0512 06:56:54 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.22502094507217407, Train Loss: 0.21589188277721405
[32m[0512 06:56:54 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.2250242978334427, Train Loss: 0.21588948369026184
[32m[0512 06:56:54 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.2250276505947113, Train Loss: 0.21588711440563202
[32m[0512 06:56:54 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.22503100335597992, Train Loss: 0.215884730219841
[32m[0512 06:56:54 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.22503432631492615, Train Loss: 0.21588234603405
[32m[0512 06:56:54 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.22503761947155, Train Loss: 0.21587996184825897
[32m[0512 06:56:54 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.2250409722328186, Train Loss: 0.21587760746479034
[32m[0512 06:56:54 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.22504425048828125, Train Loss: 0.21587522327899933
[32m[0512 06:56:54 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.22504757344722748, Train Loss: 0.2158728688955307
[32m[0512 06:56:54 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.22505083680152893, Train Loss: 0.21587048470973969
[32m[0512 06:56:54 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.22505411505699158, Train Loss: 0.21586814522743225
[32m[0512 06:56:54 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.22505736351013184, Train Loss: 0.21586576104164124
[32m[0512 06:56:54 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.2250605970621109, Train Loss: 0.2158634215593338
[32m[0512 06:56:54 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.22506386041641235, Train Loss: 0.21586106717586517
[32m[0512 06:56:54 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.22506704926490784, Train Loss: 0.21585874259471893
[32m[0512 06:56:55 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.2250702828168869, Train Loss: 0.2158564031124115
[32m[0512 06:56:55 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.22507350146770477, Train Loss: 0.21585404872894287
[32m[0512 06:56:55 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.22507670521736145, Train Loss: 0.21585170924663544
[32m[0512 06:56:55 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.22507986426353455, Train Loss: 0.215849369764328
[32m[0512 06:56:55 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.22508306801319122, Train Loss: 0.21584706008434296
[32m[0512 06:56:55 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.2250862568616867, Train Loss: 0.21584470570087433
[32m[0512 06:56:55 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.22508935630321503, Train Loss: 0.2158423662185669
[32m[0512 06:56:55 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.2250925451517105, Train Loss: 0.21584005653858185
[32m[0512 06:56:55 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.22509564459323883, Train Loss: 0.2158377319574356
[32m[0512 06:56:55 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.22509881854057312, Train Loss: 0.21583545207977295
[32m[0512 06:56:55 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.22510191798210144, Train Loss: 0.21583311259746552
[32m[0512 06:56:55 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.22510504722595215, Train Loss: 0.21583077311515808
[32m[0512 06:56:55 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.22510814666748047, Train Loss: 0.21582849323749542
[32m[0512 06:56:55 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.2251112461090088, Train Loss: 0.21582618355751038
[32m[0512 06:56:55 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.22511433064937592, Train Loss: 0.21582387387752533
[32m[0512 06:56:55 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.22511738538742065, Train Loss: 0.21582159399986267
[32m[0512 06:56:55 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.22512046992778778, Train Loss: 0.21581928431987762
[32m[0512 06:56:55 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.22512350976467133, Train Loss: 0.21581697463989258
[32m[0512 06:56:55 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.22512654960155487, Train Loss: 0.21581469476222992
[32m[0512 06:56:55 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.225129634141922, Train Loss: 0.21581239998340607
[32m[0512 06:56:55 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.22513264417648315, Train Loss: 0.2158101201057434
[32m[0512 06:56:55 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.2251356542110443, Train Loss: 0.21580784022808075
[32m[0512 06:56:56 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.22513869404792786, Train Loss: 0.2158055603504181
[32m[0512 06:56:56 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.22514168918132782, Train Loss: 0.21580326557159424
[32m[0512 06:56:56 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.22514468431472778, Train Loss: 0.21580098569393158
[32m[0512 06:56:56 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.22514766454696655, Train Loss: 0.21579870581626892
[32m[0512 06:56:56 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.22515065968036652, Train Loss: 0.21579644083976746
[32m[0512 06:56:56 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.2251536250114441, Train Loss: 0.21579419076442719
[32m[0512 06:56:56 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.22515660524368286, Train Loss: 0.21579192578792572
[32m[0512 06:56:56 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.22515954077243805, Train Loss: 0.21578967571258545
[32m[0512 06:56:56 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.22516252100467682, Train Loss: 0.2157873809337616
[32m[0512 06:56:56 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.22516542673110962, Train Loss: 0.21578513085842133
[32m[0512 06:56:56 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.2251683622598648, Train Loss: 0.21578289568424225
[32m[0512 06:56:56 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.22517129778862, Train Loss: 0.21578063070774078
[32m[0512 06:56:56 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.2251742035150528, Train Loss: 0.2157783806324005
[32m[0512 06:56:56 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.2251771092414856, Train Loss: 0.21577614545822144
[32m[0512 06:56:56 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.2251800298690796, Train Loss: 0.21577388048171997
[32m[0512 06:56:56 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.22518290579319, Train Loss: 0.2157716453075409
[32m[0512 06:56:56 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.22518578171730042, Train Loss: 0.21576939523220062
[32m[0512 06:56:56 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.22518865764141083, Train Loss: 0.21576716005802155
[32m[0512 06:56:56 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.22519154846668243, Train Loss: 0.21576492488384247
[32m[0512 06:56:56 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.22519439458847046, Train Loss: 0.2157626897096634
[32m[0512 06:56:56 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.22519724071025848, Train Loss: 0.21576045453548431
[32m[0512 06:56:56 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.22520007193088531, Train Loss: 0.21575821936130524
[32m[0512 06:56:56 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.22520291805267334, Train Loss: 0.21575601398944855
[32m[0512 06:56:57 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.22520577907562256, Train Loss: 0.21575377881526947
[32m[0512 06:56:57 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.2252085953950882, Train Loss: 0.2157515436410904
[32m[0512 06:56:57 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.22521141171455383, Train Loss: 0.2157493382692337
[32m[0512 06:56:57 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.22521419823169708, Train Loss: 0.21574710309505463
[32m[0512 06:56:57 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.22521701455116272, Train Loss: 0.21574489772319794
[32m[0512 06:56:57 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.22521980106830597, Train Loss: 0.21574269235134125
[32m[0512 06:56:57 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.2252226173877716, Train Loss: 0.21574045717716217
[32m[0512 06:56:57 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.22522537410259247, Train Loss: 0.21573826670646667
[32m[0512 06:56:57 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.22522814571857452, Train Loss: 0.21573606133460999
[32m[0512 06:56:57 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.22523093223571777, Train Loss: 0.2157338559627533
[32m[0512 06:56:57 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.22523367404937744, Train Loss: 0.2157316505908966
[32m[0512 06:56:57 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.2252364307641983, Train Loss: 0.21572943031787872
[32m[0512 06:56:57 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.22523917257785797, Train Loss: 0.21572722494602203
[32m[0512 06:56:57 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.22524188458919525, Train Loss: 0.21572506427764893
[32m[0512 06:56:57 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.2252446562051773, Train Loss: 0.21572284400463104
[32m[0512 06:56:57 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.2252473682165146, Train Loss: 0.21572065353393555
[32m[0512 06:56:57 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.22525009512901306, Train Loss: 0.21571844816207886
[32m[0512 06:56:57 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.22525277733802795, Train Loss: 0.21571628749370575
[32m[0512 06:56:57 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.22525547444820404, Train Loss: 0.21571408212184906
[32m[0512 06:56:57 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.2252582162618637, Train Loss: 0.21571189165115356
[32m[0512 06:56:57 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.2252608686685562, Train Loss: 0.21570971608161926
[32m[0512 06:56:57 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.2252635508775711, Train Loss: 0.21570755541324615
[32m[0512 06:56:58 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.2252662628889084, Train Loss: 0.21570536494255066
[32m[0512 06:56:58 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.2252689003944397, Train Loss: 0.21570318937301636
[32m[0512 06:56:58 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.2252715826034546, Train Loss: 0.21570099890232086
[32m[0512 06:56:58 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.2252742499113083, Train Loss: 0.21569883823394775
[32m[0512 06:56:58 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.2252768576145172, Train Loss: 0.21569666266441345
[32m[0512 06:56:58 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.2252795398235321, Train Loss: 0.21569450199604034
[32m[0512 06:56:58 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.2252821922302246, Train Loss: 0.21569232642650604
[32m[0512 06:56:58 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.22528478503227234, Train Loss: 0.21569016575813293
[32m[0512 06:56:58 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.22528742253780365, Train Loss: 0.21568800508975983
[32m[0512 06:56:58 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.22529006004333496, Train Loss: 0.21568584442138672
[32m[0512 06:56:58 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.2252926528453827, Train Loss: 0.2156836837530136
[32m[0512 06:56:58 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.2252952754497528, Train Loss: 0.2156815230846405
[32m[0512 06:56:58 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.22529789805412292, Train Loss: 0.2156793624162674
[32m[0512 06:56:58 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.22530046105384827, Train Loss: 0.21567721664905548
[32m[0512 06:56:58 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.225303053855896, Train Loss: 0.21567505598068237
[32m[0512 06:56:58 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.22530564665794373, Train Loss: 0.21567292511463165
[32m[0512 06:56:58 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.22530820965766907, Train Loss: 0.21567076444625854
[32m[0512 06:56:58 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.2253107726573944, Train Loss: 0.21566863358020782
[32m[0512 06:56:58 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.22531335055828094, Train Loss: 0.21566644310951233
[32m[0512 06:56:58 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.2253159135580063, Train Loss: 0.215664342045784
[32m[0512 06:56:58 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.22531846165657043, Train Loss: 0.2156621813774109
[32m[0512 06:56:58 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.22532100975513458, Train Loss: 0.21566006541252136
[32m[0512 06:56:58 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.22532354295253754, Train Loss: 0.21565790474414825
[32m[0512 06:56:58 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.22532612085342407, Train Loss: 0.21565577387809753
[32m[0512 06:56:59 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.22532857954502106, Train Loss: 0.21565364301204681
[32m[0512 06:56:59 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.2253311425447464, Train Loss: 0.2156515121459961
[32m[0512 06:56:59 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.22533367574214935, Train Loss: 0.21564941108226776
[32m[0512 06:56:59 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.22533617913722992, Train Loss: 0.21564726531505585
[32m[0512 06:56:59 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.22533869743347168, Train Loss: 0.21564511954784393
[32m[0512 06:56:59 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.22534117102622986, Train Loss: 0.2156430035829544
[32m[0512 06:56:59 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.22534364461898804, Train Loss: 0.2156408727169037
[32m[0512 06:56:59 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.2253461480140686, Train Loss: 0.21563875675201416
[32m[0512 06:56:59 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.22534865140914917, Train Loss: 0.21563662588596344
[32m[0512 06:56:59 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.22535113990306854, Train Loss: 0.2156345248222351
[32m[0512 06:56:59 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.22535359859466553, Train Loss: 0.2156323939561844
[32m[0512 06:56:59 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.2253560721874237, Train Loss: 0.21563030779361725
[32m[0512 06:56:59 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.2253585308790207, Train Loss: 0.21562817692756653
[32m[0512 06:56:59 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.22536097466945648, Train Loss: 0.2156260907649994
[32m[0512 06:56:59 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.22536343336105347, Train Loss: 0.21562395989894867
[32m[0512 06:56:59 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.22536589205265045, Train Loss: 0.21562182903289795
[32m[0512 06:56:59 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.22536835074424744, Train Loss: 0.2156197428703308
[32m[0512 06:56:59 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.22537076473236084, Train Loss: 0.21561762690544128
[32m[0512 06:56:59 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.22537320852279663, Train Loss: 0.21561552584171295
[32m[0512 06:56:59 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.22537563741207123, Train Loss: 0.2156134396791458
[32m[0512 06:56:59 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.22537802159786224, Train Loss: 0.21561133861541748
[32m[0512 06:56:59 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.22538043558597565, Train Loss: 0.21560922265052795
[32m[0512 06:56:59 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.22538286447525024, Train Loss: 0.21560712158679962
[32m[0512 06:57:00 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.22538524866104126, Train Loss: 0.21560503542423248
[32m[0512 06:57:00 @mbmf_sampler.py:98][0m Finished 9th episode
[32m[0512 06:57:00 @mbmf_sampler.py:102][0m 1809 timesteps from 9 episodes collected
[32m[0512 07:16:08 @mbmf_trainer.py:160][0m Mean reward: -318.6950396655994
[32m[0512 07:16:08 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.21330223977565765, Train Loss: 0.21636758744716644
[32m[0512 07:16:08 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.21332228183746338, Train Loss: 0.2163061946630478
[32m[0512 07:16:08 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.2133510857820511, Train Loss: 0.21630257368087769
[32m[0512 07:16:08 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.2133805900812149, Train Loss: 0.21627332270145416
[32m[0512 07:16:08 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.21340398490428925, Train Loss: 0.2162545621395111
[32m[0512 07:16:08 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.21342521905899048, Train Loss: 0.21623721718788147
[32m[0512 07:16:08 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.21344435214996338, Train Loss: 0.21622124314308167
[32m[0512 07:16:08 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.2134622484445572, Train Loss: 0.21620644629001617
[32m[0512 07:16:08 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.21347928047180176, Train Loss: 0.2161925733089447
[32m[0512 07:16:08 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.21349558234214783, Train Loss: 0.21617946028709412
[32m[0512 07:16:08 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.21351131796836853, Train Loss: 0.21616706252098083
[32m[0512 07:16:09 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.21352657675743103, Train Loss: 0.2161552757024765
[32m[0512 07:16:09 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.21354138851165771, Train Loss: 0.21614398062229156
[32m[0512 07:16:09 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.21355585753917694, Train Loss: 0.21613313257694244
[32m[0512 07:16:09 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.21356995403766632, Train Loss: 0.21612276136875153
[32m[0512 07:16:09 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.21358369290828705, Train Loss: 0.21611274778842926
[32m[0512 07:16:09 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.2135971039533615, Train Loss: 0.21610306203365326
[32m[0512 07:16:09 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.2136102318763733, Train Loss: 0.21609368920326233
[32m[0512 07:16:09 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.21362309157848358, Train Loss: 0.21608467400074005
[32m[0512 07:16:09 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.21363565325737, Train Loss: 0.21607589721679688
[32m[0512 07:16:09 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.2136479765176773, Train Loss: 0.21606741845607758
[32m[0512 07:16:09 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.21366003155708313, Train Loss: 0.2160591185092926
[32m[0512 07:16:09 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.21367186307907104, Train Loss: 0.21605105698108673
[32m[0512 07:16:09 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.21368344128131866, Train Loss: 0.21604323387145996
[32m[0512 07:16:09 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.21369484066963196, Train Loss: 0.2160356193780899
[32m[0512 07:16:09 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.21370600163936615, Train Loss: 0.21602816879749298
[32m[0512 07:16:09 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.21371696889400482, Train Loss: 0.21602091193199158
[32m[0512 07:16:09 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.21372780203819275, Train Loss: 0.2160138040781021
[32m[0512 07:16:09 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.21373838186264038, Train Loss: 0.21600686013698578
[32m[0512 07:16:09 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.21374884247779846, Train Loss: 0.21600006520748138
[32m[0512 07:16:10 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.21375912427902222, Train Loss: 0.21599344909191132
[32m[0512 07:16:10 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.21376921236515045, Train Loss: 0.2159869521856308
[32m[0512 07:16:10 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.21377918124198914, Train Loss: 0.21598052978515625
[32m[0512 07:16:10 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.21378903090953827, Train Loss: 0.21597428619861603
[32m[0512 07:16:10 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.21379873156547546, Train Loss: 0.21596814692020416
[32m[0512 07:16:10 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.21380828320980072, Train Loss: 0.21596212685108185
[32m[0512 07:16:10 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.21381768584251404, Train Loss: 0.2159562110900879
[32m[0512 07:16:10 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.2138269990682602, Train Loss: 0.2159503847360611
[32m[0512 07:16:10 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.213836207985878, Train Loss: 0.21594470739364624
[32m[0512 07:16:10 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.21384522318840027, Train Loss: 0.21593908965587616
[32m[0512 07:16:10 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.21385420858860016, Train Loss: 0.21593357622623444
[32m[0512 07:16:10 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.2138630449771881, Train Loss: 0.21592816710472107
[32m[0512 07:16:10 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.2138717919588089, Train Loss: 0.21592281758785248
[32m[0512 07:16:10 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.21388046443462372, Train Loss: 0.21591754257678986
[32m[0512 07:16:10 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.213889017701149, Train Loss: 0.21591238677501678
[32m[0512 07:16:10 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.21389751136302948, Train Loss: 0.2159072756767273
[32m[0512 07:16:10 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.21390585601329803, Train Loss: 0.21590226888656616
[32m[0512 07:16:10 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.21391411125659943, Train Loss: 0.21589727699756622
[32m[0512 07:16:10 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.21392232179641724, Train Loss: 0.21589240431785583
[32m[0512 07:16:10 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.21393045783042908, Train Loss: 0.21588759124279022
[32m[0512 07:16:10 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.21393845975399017, Train Loss: 0.21588283777236938
[32m[0512 07:16:11 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.2139464169740677, Train Loss: 0.21587814390659332
[32m[0512 07:16:11 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.21395432949066162, Train Loss: 0.21587347984313965
[32m[0512 07:16:11 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.213962122797966, Train Loss: 0.21586890518665314
[32m[0512 07:16:11 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.21396984159946442, Train Loss: 0.2158643752336502
[32m[0512 07:16:11 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.21397754549980164, Train Loss: 0.21585994958877563
[32m[0512 07:16:11 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.2139851450920105, Train Loss: 0.21585550904273987
[32m[0512 07:16:11 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.21399268507957458, Train Loss: 0.21585115790367126
[32m[0512 07:16:11 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.2140001505613327, Train Loss: 0.21584686636924744
[32m[0512 07:16:11 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.21400752663612366, Train Loss: 0.2158425897359848
[32m[0512 07:16:11 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.21401487290859222, Train Loss: 0.21583838760852814
[32m[0512 07:16:11 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.21402214467525482, Train Loss: 0.21583420038223267
[32m[0512 07:16:11 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.21402937173843384, Train Loss: 0.21583008766174316
[32m[0512 07:16:11 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.21403655409812927, Train Loss: 0.21582601964473724
[32m[0512 07:16:11 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.21404366195201874, Train Loss: 0.2158219814300537
[32m[0512 07:16:11 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.21405071020126343, Train Loss: 0.21581794321537018
[32m[0512 07:16:11 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.21405774354934692, Train Loss: 0.21581397950649261
[32m[0512 07:16:11 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.21406467258930206, Train Loss: 0.21581007540225983
[32m[0512 07:16:11 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.21407155692577362, Train Loss: 0.21580618619918823
[32m[0512 07:16:11 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.2140783667564392, Train Loss: 0.21580234169960022
[32m[0512 07:16:11 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.21408511698246002, Train Loss: 0.2157985121011734
[32m[0512 07:16:11 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.21409188210964203, Train Loss: 0.21579475700855255
[32m[0512 07:16:12 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.21409854292869568, Train Loss: 0.2157910019159317
[32m[0512 07:16:12 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.21410517394542694, Train Loss: 0.21578727662563324
[32m[0512 07:16:12 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.21411177515983582, Train Loss: 0.21578361093997955
[32m[0512 07:16:12 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.21411830186843872, Train Loss: 0.21578000485897064
[32m[0512 07:16:12 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.21412476897239685, Train Loss: 0.21577633917331696
[32m[0512 07:16:12 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.2141312211751938, Train Loss: 0.21577276289463043
[32m[0512 07:16:12 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.21413762867450714, Train Loss: 0.2157692015171051
[32m[0512 07:16:12 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.21414397656917572, Train Loss: 0.21576566994190216
[32m[0512 07:16:12 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.2141502946615219, Train Loss: 0.2157621830701828
[32m[0512 07:16:12 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.21415656805038452, Train Loss: 0.21575869619846344
[32m[0512 07:16:12 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.21416276693344116, Train Loss: 0.21575522422790527
[32m[0512 07:16:12 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.214168980717659, Train Loss: 0.2157517820596695
[32m[0512 07:16:12 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.21417510509490967, Train Loss: 0.2157483994960785
[32m[0512 07:16:12 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.21418119966983795, Train Loss: 0.2157449722290039
[32m[0512 07:16:12 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.21418723464012146, Train Loss: 0.21574163436889648
[32m[0512 07:16:12 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.21419328451156616, Train Loss: 0.21573831140995026
[32m[0512 07:16:12 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.2141992300748825, Train Loss: 0.21573500335216522
[32m[0512 07:16:12 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.21420516073703766, Train Loss: 0.21573171019554138
[32m[0512 07:16:12 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.214211106300354, Train Loss: 0.21572843194007874
[32m[0512 07:16:13 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.2142169177532196, Train Loss: 0.21572519838809967
[32m[0512 07:16:13 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.2142227739095688, Train Loss: 0.2157219797372818
[32m[0512 07:16:13 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.214228555560112, Train Loss: 0.21571876108646393
[32m[0512 07:16:13 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.21423427760601044, Train Loss: 0.21571555733680725
[32m[0512 07:16:13 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.21424001455307007, Train Loss: 0.21571236848831177
[32m[0512 07:16:13 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.21424566209316254, Train Loss: 0.21570925414562225
[32m[0512 07:16:13 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.214251309633255, Train Loss: 0.21570611000061035
[32m[0512 07:16:13 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.2142569124698639, Train Loss: 0.21570299565792084
[32m[0512 07:16:13 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.21426250040531158, Train Loss: 0.21569989621639252
[32m[0512 07:16:13 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.21426799893379211, Train Loss: 0.21569682657718658
[32m[0512 07:16:13 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.21427349746227264, Train Loss: 0.21569375693798065
[32m[0512 07:16:13 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.21427898108959198, Train Loss: 0.2156907021999359
[32m[0512 07:16:13 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.21428442001342773, Train Loss: 0.21568766236305237
[32m[0512 07:16:13 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.2142897993326187, Train Loss: 0.2156846523284912
[32m[0512 07:16:13 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.21429522335529327, Train Loss: 0.21568165719509125
[32m[0512 07:16:13 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.21430052816867828, Train Loss: 0.21567867696285248
[32m[0512 07:16:13 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.2143058031797409, Train Loss: 0.2156756967306137
[32m[0512 07:16:13 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.21431109309196472, Train Loss: 0.21567273139953613
[32m[0512 07:16:13 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.21431632339954376, Train Loss: 0.21566981077194214
[32m[0512 07:16:13 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.2143215537071228, Train Loss: 0.21566683053970337
[32m[0512 07:16:14 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.21432673931121826, Train Loss: 0.21566392481327057
[32m[0512 07:16:14 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.21433188021183014, Train Loss: 0.21566104888916016
[32m[0512 07:16:14 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.21433702111244202, Train Loss: 0.21565817296504974
[32m[0512 07:16:14 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.21434207260608673, Train Loss: 0.21565526723861694
[32m[0512 07:16:14 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.21434713900089264, Train Loss: 0.21565242111682892
[32m[0512 07:16:14 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.21435216069221497, Train Loss: 0.2156495600938797
[32m[0512 07:16:14 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.2143571823835373, Train Loss: 0.21564672887325287
[32m[0512 07:16:14 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.21436217427253723, Train Loss: 0.21564388275146484
[32m[0512 07:16:14 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.2143671214580536, Train Loss: 0.21564103662967682
[32m[0512 07:16:14 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.21437205374240875, Train Loss: 0.21563826501369476
[32m[0512 07:16:14 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.21437692642211914, Train Loss: 0.2156354933977127
[32m[0512 07:16:14 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.21438176929950714, Train Loss: 0.21563267707824707
[32m[0512 07:16:14 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.21438659727573395, Train Loss: 0.2156299203634262
[32m[0512 07:16:14 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.21439146995544434, Train Loss: 0.21562717854976654
[32m[0512 07:16:14 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.21439625322818756, Train Loss: 0.21562442183494568
[32m[0512 07:16:14 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.2144010066986084, Train Loss: 0.21562165021896362
[32m[0512 07:16:14 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.21440573036670685, Train Loss: 0.21561893820762634
[32m[0512 07:16:14 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.2144104242324829, Train Loss: 0.21561618149280548
[32m[0512 07:16:14 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.21441513299942017, Train Loss: 0.2156134694814682
[32m[0512 07:16:14 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.21441978216171265, Train Loss: 0.2156108021736145
[32m[0512 07:16:15 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.21442444622516632, Train Loss: 0.21560807526111603
[32m[0512 07:16:15 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.21442902088165283, Train Loss: 0.21560540795326233
[32m[0512 07:16:15 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.21443359553813934, Train Loss: 0.21560269594192505
[32m[0512 07:16:15 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.21443818509578705, Train Loss: 0.21560005843639374
[32m[0512 07:16:15 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.21444271504878998, Train Loss: 0.21559740602970123
[32m[0512 07:16:15 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.2144472450017929, Train Loss: 0.21559476852416992
[32m[0512 07:16:15 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.21445174515247345, Train Loss: 0.21559210121631622
[32m[0512 07:16:15 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.2144562304019928, Train Loss: 0.2155894786119461
[32m[0512 07:16:15 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.21446064114570618, Train Loss: 0.21558688580989838
[32m[0512 07:16:15 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.21446509659290314, Train Loss: 0.21558421850204468
[32m[0512 07:16:15 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.21446950733661652, Train Loss: 0.21558161079883575
[32m[0512 07:16:15 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.21447385847568512, Train Loss: 0.21557903289794922
[32m[0512 07:16:15 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.21447819471359253, Train Loss: 0.2155764102935791
[32m[0512 07:16:15 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.21448256075382233, Train Loss: 0.21557383239269257
[32m[0512 07:16:15 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.21448686718940735, Train Loss: 0.21557126939296722
[32m[0512 07:16:15 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.21449115872383118, Train Loss: 0.2155686914920807
[32m[0512 07:16:15 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.2144954651594162, Train Loss: 0.21556614339351654
[32m[0512 07:16:15 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.21449971199035645, Train Loss: 0.2155635803937912
[32m[0512 07:16:15 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.2145039439201355, Train Loss: 0.21556104719638824
[32m[0512 07:16:16 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.21450817584991455, Train Loss: 0.2155584841966629
[32m[0512 07:16:16 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.21451236307621002, Train Loss: 0.21555595099925995
[32m[0512 07:16:16 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.2145165354013443, Train Loss: 0.215553417801857
[32m[0512 07:16:16 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.21452069282531738, Train Loss: 0.21555088460445404
[32m[0512 07:16:16 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.21452483534812927, Train Loss: 0.21554838120937347
[32m[0512 07:16:16 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.21452894806861877, Train Loss: 0.2155458778142929
[32m[0512 07:16:16 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.21453304588794708, Train Loss: 0.21554332971572876
[32m[0512 07:16:16 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.2145370990037918, Train Loss: 0.21554087102413177
[32m[0512 07:16:16 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.21454115211963654, Train Loss: 0.2155383676290512
[32m[0512 07:16:16 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.21454520523548126, Train Loss: 0.21553586423397064
[32m[0512 07:16:16 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.2145492285490036, Train Loss: 0.21553340554237366
[32m[0512 07:16:16 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.21455325186252594, Train Loss: 0.21553091704845428
[32m[0512 07:16:16 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.21455726027488708, Train Loss: 0.2155284434556961
[32m[0512 07:16:16 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.21456120908260345, Train Loss: 0.21552596986293793
[32m[0512 07:16:16 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.21456517279148102, Train Loss: 0.21552354097366333
[32m[0512 07:16:16 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.214569091796875, Train Loss: 0.21552108228206635
[32m[0512 07:16:16 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.21457301080226898, Train Loss: 0.21551862359046936
[32m[0512 07:16:16 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.21457692980766296, Train Loss: 0.21551617980003357
[32m[0512 07:16:16 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.21458077430725098, Train Loss: 0.21551375091075897
[32m[0512 07:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.21458464860916138, Train Loss: 0.21551132202148438
[32m[0512 07:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.21458850800991058, Train Loss: 0.21550889313220978
[32m[0512 07:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.2145923525094986, Train Loss: 0.21550649404525757
[32m[0512 07:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.21459613740444183, Train Loss: 0.2155040204524994
[32m[0512 07:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.21459995210170746, Train Loss: 0.215501606464386
[32m[0512 07:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.2146037518978119, Train Loss: 0.21549922227859497
[32m[0512 07:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.21460752189159393, Train Loss: 0.21549683809280396
[32m[0512 07:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.21461129188537598, Train Loss: 0.21549443900585175
[32m[0512 07:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.21461504697799683, Train Loss: 0.21549206972122192
[32m[0512 07:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.2146187573671341, Train Loss: 0.21548967063426971
[32m[0512 07:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.21462248265743256, Train Loss: 0.2154872864484787
[32m[0512 07:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.21462616324424744, Train Loss: 0.2154848724603653
[32m[0512 07:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.21462982892990112, Train Loss: 0.21548251807689667
[32m[0512 07:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.214633509516716, Train Loss: 0.21548014879226685
[32m[0512 07:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.2146371603012085, Train Loss: 0.21547779440879822
[32m[0512 07:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.2146407812833786, Train Loss: 0.2154754102230072
[32m[0512 07:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.21464446187019348, Train Loss: 0.21547307074069977
[32m[0512 07:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.2146480530500412, Train Loss: 0.21547070145606995
[32m[0512 07:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.21465159952640533, Train Loss: 0.2154683917760849
[32m[0512 07:16:17 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.21465523540973663, Train Loss: 0.21546602249145508
[32m[0512 07:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.21465878188610077, Train Loss: 0.21546368300914764
[32m[0512 07:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.2146623581647873, Train Loss: 0.2154613584280014
[32m[0512 07:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.21466585993766785, Train Loss: 0.21545901894569397
[32m[0512 07:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.2146693915128708, Train Loss: 0.21545670926570892
[32m[0512 07:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.2146729677915573, Train Loss: 0.21545439958572388
[32m[0512 07:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.21467642486095428, Train Loss: 0.21545206010341644
[32m[0512 07:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.21467992663383484, Train Loss: 0.2154497504234314
[32m[0512 07:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.2146834284067154, Train Loss: 0.21544742584228516
[32m[0512 07:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.21468687057495117, Train Loss: 0.21544510126113892
[32m[0512 07:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.21469029784202576, Train Loss: 0.21544283628463745
[32m[0512 07:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.21469378471374512, Train Loss: 0.2154405117034912
[32m[0512 07:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.2146972119808197, Train Loss: 0.21543823182582855
[32m[0512 07:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.2147006094455719, Train Loss: 0.2154359221458435
[32m[0512 07:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.21470405161380768, Train Loss: 0.21543361246585846
[32m[0512 07:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.21470744907855988, Train Loss: 0.2154313176870346
[32m[0512 07:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.2147108018398285, Train Loss: 0.21542906761169434
[32m[0512 07:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.2147141546010971, Train Loss: 0.21542678773403168
[32m[0512 07:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.2147175371646881, Train Loss: 0.21542449295520782
[32m[0512 07:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.21472088992595673, Train Loss: 0.21542224287986755
[32m[0512 07:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.21472422778606415, Train Loss: 0.21541999280452728
[32m[0512 07:16:18 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.21472755074501038, Train Loss: 0.21541768312454224
[32m[0512 07:16:19 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.2147308588027954, Train Loss: 0.21541543304920197
[32m[0512 07:16:19 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.21473419666290283, Train Loss: 0.2154131829738617
[32m[0512 07:16:19 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.21473747491836548, Train Loss: 0.21541093289852142
[32m[0512 07:16:19 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.21474073827266693, Train Loss: 0.21540866792201996
[32m[0512 07:16:19 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.21474401652812958, Train Loss: 0.2154064178466797
[32m[0512 07:16:19 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.21474727988243103, Train Loss: 0.21540416777133942
[32m[0512 07:16:19 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.2147505283355713, Train Loss: 0.21540193259716034
[32m[0512 07:16:19 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.21475379168987274, Train Loss: 0.21539968252182007
[32m[0512 07:16:19 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.21475699543952942, Train Loss: 0.2153974175453186
[32m[0512 07:16:19 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.21476022899150848, Train Loss: 0.21539521217346191
[32m[0512 07:16:19 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.21476346254348755, Train Loss: 0.21539297699928284
[32m[0512 07:16:19 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.21476665139198303, Train Loss: 0.21539074182510376
[32m[0512 07:16:19 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.21476981043815613, Train Loss: 0.21538853645324707
[32m[0512 07:16:19 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.2147730588912964, Train Loss: 0.215386301279068
[32m[0512 07:16:19 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.2147762030363083, Train Loss: 0.21538406610488892
[32m[0512 07:16:19 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.214779332280159, Train Loss: 0.21538186073303223
[32m[0512 07:16:19 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.21478252112865448, Train Loss: 0.21537965536117554
[32m[0512 07:16:19 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.214785635471344, Train Loss: 0.21537743508815765
[32m[0512 07:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.21478880941867828, Train Loss: 0.21537519991397858
[32m[0512 07:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.21479195356369019, Train Loss: 0.21537302434444427
[32m[0512 07:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.2147950530052185, Train Loss: 0.2153708040714264
[32m[0512 07:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.21479815244674683, Train Loss: 0.2153686136007309
[32m[0512 07:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.21480125188827515, Train Loss: 0.21536637842655182
[32m[0512 07:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.21480433642864227, Train Loss: 0.21536420285701752
[32m[0512 07:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.2148074209690094, Train Loss: 0.21536202728748322
[32m[0512 07:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.21481049060821533, Train Loss: 0.21535983681678772
[32m[0512 07:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.21481354534626007, Train Loss: 0.21535763144493103
[32m[0512 07:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.2148166298866272, Train Loss: 0.21535545587539673
[32m[0512 07:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.21481965482234955, Train Loss: 0.21535325050354004
[32m[0512 07:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.2148227095603943, Train Loss: 0.21535108983516693
[32m[0512 07:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.21482577919960022, Train Loss: 0.21534891426563263
[32m[0512 07:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.214828759431839, Train Loss: 0.21534672379493713
[32m[0512 07:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.21483179926872253, Train Loss: 0.21534456312656403
[32m[0512 07:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.2148347645998001, Train Loss: 0.2153424173593521
[32m[0512 07:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.21483780443668365, Train Loss: 0.21534019708633423
[32m[0512 07:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.21484078466892242, Train Loss: 0.21533805131912231
[32m[0512 07:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.2148437798023224, Train Loss: 0.2153358906507492
[32m[0512 07:16:20 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.21484674513339996, Train Loss: 0.2153337150812149
[32m[0512 07:16:21 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.21484975516796112, Train Loss: 0.2153315544128418
[32m[0512 07:16:21 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.21485266089439392, Train Loss: 0.21532940864562988
[32m[0512 07:16:21 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.2148556262254715, Train Loss: 0.21532726287841797
[32m[0512 07:16:21 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.21485859155654907, Train Loss: 0.21532511711120605
[32m[0512 07:16:21 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.21486151218414307, Train Loss: 0.21532295644283295
[32m[0512 07:16:21 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.21486447751522064, Train Loss: 0.21532078087329865
[32m[0512 07:16:21 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.21486738324165344, Train Loss: 0.21531866490840912
[32m[0512 07:16:21 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.21487031877040863, Train Loss: 0.2153165340423584
[32m[0512 07:16:21 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.21487320959568024, Train Loss: 0.2153143435716629
[32m[0512 07:16:21 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.21487610042095184, Train Loss: 0.21531222760677338
[32m[0512 07:16:21 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.21487902104854584, Train Loss: 0.21531008183956146
[32m[0512 07:16:21 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.21488188207149506, Train Loss: 0.21530795097351074
[32m[0512 07:16:21 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.21488477289676666, Train Loss: 0.2153058499097824
[32m[0512 07:16:21 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.21488766372203827, Train Loss: 0.2153036743402481
[32m[0512 07:16:21 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.2148905247449875, Train Loss: 0.21530155837535858
[32m[0512 07:16:21 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.2148934155702591, Train Loss: 0.21529941260814667
[32m[0512 07:16:21 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.21489626169204712, Train Loss: 0.21529728174209595
[32m[0512 07:16:21 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.21489907801151276, Train Loss: 0.21529518067836761
[32m[0512 07:16:21 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.21490193903446198, Train Loss: 0.2152930647134781
[32m[0512 07:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.21490478515625, Train Loss: 0.21529096364974976
[32m[0512 07:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.21490760147571564, Train Loss: 0.21528881788253784
[32m[0512 07:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.21491044759750366, Train Loss: 0.2152867168188095
[32m[0512 07:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.2149132341146469, Train Loss: 0.21528460085391998
[32m[0512 07:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.21491608023643494, Train Loss: 0.21528245508670807
[32m[0512 07:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.21491889655590057, Train Loss: 0.21528038382530212
[32m[0512 07:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.21492168307304382, Train Loss: 0.2152782380580902
[32m[0512 07:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.21492448449134827, Train Loss: 0.21527613699436188
[32m[0512 07:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.21492727100849152, Train Loss: 0.21527403593063354
[32m[0512 07:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.21493005752563477, Train Loss: 0.2152719348669052
[32m[0512 07:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.21493282914161682, Train Loss: 0.21526981890201569
[32m[0512 07:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.21493560075759888, Train Loss: 0.21526771783828735
[32m[0512 07:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.21493834257125854, Train Loss: 0.2152656465768814
[32m[0512 07:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.2149411290884018, Train Loss: 0.21526356041431427
[32m[0512 07:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.21494387090206146, Train Loss: 0.21526145935058594
[32m[0512 07:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.21494661271572113, Train Loss: 0.2152593582868576
[32m[0512 07:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.2149493545293808, Train Loss: 0.21525727212429047
[32m[0512 07:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.21495211124420166, Train Loss: 0.21525515615940094
[32m[0512 07:16:22 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.21495485305786133, Train Loss: 0.2152530699968338
[32m[0512 07:16:23 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.21495753526687622, Train Loss: 0.21525098383426666
[32m[0512 07:16:23 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.2149602621793747, Train Loss: 0.21524891257286072
[32m[0512 07:16:23 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.21496300399303436, Train Loss: 0.21524681150913239
[32m[0512 07:16:23 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.21496570110321045, Train Loss: 0.21524472534656525
[32m[0512 07:16:23 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.21496841311454773, Train Loss: 0.2152426689863205
[32m[0512 07:16:23 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.21497108042240143, Train Loss: 0.21524058282375336
[32m[0512 07:16:23 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.21497377753257751, Train Loss: 0.2152385115623474
[32m[0512 07:16:23 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.214976504445076, Train Loss: 0.21523644030094147
[32m[0512 07:16:23 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.21497918665409088, Train Loss: 0.21523436903953552
[32m[0512 07:16:23 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.21498186886310577, Train Loss: 0.21523231267929077
[32m[0512 07:16:23 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.21498458087444305, Train Loss: 0.21523021161556244
[32m[0512 07:16:23 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.21498720347881317, Train Loss: 0.21522817015647888
[32m[0512 07:16:23 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.21498987078666687, Train Loss: 0.21522608399391174
[32m[0512 07:16:23 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.21499253809452057, Train Loss: 0.215224027633667
[32m[0512 07:16:23 @mbmf_main.py:224][0m batch size for trpo is 1000
[32m[0512 07:16:23 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 07:16:23 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 07:16:23 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 07:16:23 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 07:16:23 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 07:16:23 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 07:16:23 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 07:16:23 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 07:16:23 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 07:16:23 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 07:16:23 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 07:16:23 @mbmf_main.py:132][0m Training starts at /root/mbbl
[32m[0512 07:16:23 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 07:16:23 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 07:16:23 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 07:16:23 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 07:16:23 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 07:16:23 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 07:16:23 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 07:16:23 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 07:16:23 @base_worker.py:45][0m Worker 0 online
[32m[0512 07:16:23 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 07:16:23 @base_worker.py:45][0m Worker 1 online
[32m[0512 07:16:23 @base_worker.py:45][0m Worker 2 online
[32m[0512 07:16:23 @base_worker.py:45][0m Worker 3 online
[32m[0512 07:16:23 @base_worker.py:45][0m Worker 4 online
[32m[0512 07:16:23 @base_worker.py:45][0m Worker 5 online
[32m[0512 07:16:23 @base_worker.py:45][0m Worker 6 online
[32m[0512 07:16:23 @base_worker.py:45][0m Worker 7 online
[32m[0512 07:16:23 @base_worker.py:45][0m Worker 8 online
[32m[0512 07:16:23 @base_worker.py:45][0m Worker 9 online
[32m[0512 07:16:23 @base_worker.py:45][0m Worker 10 online
[32m[0512 07:16:23 @base_worker.py:45][0m Worker 11 online
[32m[0512 07:16:23 @base_worker.py:45][0m Worker 12 online
[32m[0512 07:16:23 @base_worker.py:45][0m Worker 13 online
[32m[0512 07:16:23 @base_worker.py:45][0m Worker 14 online
[32m[0512 07:16:23 @base_worker.py:45][0m Worker 15 online
[32m[0512 07:16:23 @base_worker.py:45][0m Worker 16 online
[32m[0512 07:16:23 @base_worker.py:45][0m Worker 17 online
[32m[0512 07:16:23 @base_worker.py:45][0m Worker 18 online
[32m[0512 07:16:23 @base_worker.py:45][0m Worker 19 online
[32m[0512 07:16:24 @base_trainer.py:152][0m Trainer maintains [1] policy network
[32m[0512 07:16:24 @base_trainer.py:152][0m Trainer maintains [1] dynamics network
[32m[0512 07:16:24 @base_trainer.py:152][0m Trainer maintains [1] reward network
[32m[0512 07:16:25 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:25 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:25 @base_trainer.py:216][0m Mean reward: -421.63967072096165
[32m[0512 07:16:26 @base_main.py:38][0m --------------- Iteration 1 ---------------
[32m[0512 07:16:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0000 mins
[32m[0512 07:16:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0049 mins
[32m[0512 07:16:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0148 mins
[32m[0512 07:16:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:16:26 @base_main.py:47][0m 1005 total steps have happened
[32m[0512 07:16:26 @base_main.py:52][0m [avg_reward]: -421.63967072096165
[32m[0512 07:16:26 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:26 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:26 @base_trainer.py:216][0m Mean reward: -436.777645510563
[32m[0512 07:16:26 @base_main.py:38][0m --------------- Iteration 2 ---------------
[32m[0512 07:16:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0199 mins
[32m[0512 07:16:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0048 mins
[32m[0512 07:16:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 07:16:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:16:26 @base_main.py:47][0m 2010 total steps have happened
[32m[0512 07:16:26 @base_main.py:52][0m [avg_reward]: -436.777645510563
[32m[0512 07:16:27 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:27 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:27 @base_trainer.py:216][0m Mean reward: -286.0102190454655
[32m[0512 07:16:27 @base_main.py:38][0m --------------- Iteration 3 ---------------
[32m[0512 07:16:27 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0334 mins
[32m[0512 07:16:27 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0046 mins
[32m[0512 07:16:27 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0512 07:16:27 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:16:27 @base_main.py:47][0m 3015 total steps have happened
[32m[0512 07:16:27 @base_main.py:52][0m [avg_reward]: -286.0102190454655
[32m[0512 07:16:27 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:27 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:27 @base_trainer.py:216][0m Mean reward: -234.35252746681908
[32m[0512 07:16:28 @base_main.py:38][0m --------------- Iteration 4 ---------------
[32m[0512 07:16:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0476 mins
[32m[0512 07:16:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0036 mins
[32m[0512 07:16:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 07:16:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:16:28 @base_main.py:47][0m 4020 total steps have happened
[32m[0512 07:16:28 @base_main.py:52][0m [avg_reward]: -234.35252746681908
[32m[0512 07:16:28 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:28 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:28 @base_trainer.py:216][0m Mean reward: -235.74405469339018
[32m[0512 07:16:29 @base_main.py:38][0m --------------- Iteration 5 ---------------
[32m[0512 07:16:29 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0601 mins
[32m[0512 07:16:29 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0046 mins
[32m[0512 07:16:29 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 07:16:29 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:16:29 @base_main.py:47][0m 5025 total steps have happened
[32m[0512 07:16:29 @base_main.py:52][0m [avg_reward]: -235.74405469339018
[32m[0512 07:16:29 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:29 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:29 @base_trainer.py:216][0m Mean reward: -163.4628608324475
[32m[0512 07:16:29 @base_main.py:38][0m --------------- Iteration 6 ---------------
[32m[0512 07:16:29 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0740 mins
[32m[0512 07:16:29 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 07:16:29 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0512 07:16:29 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:16:29 @base_main.py:47][0m 6030 total steps have happened
[32m[0512 07:16:29 @base_main.py:52][0m [avg_reward]: -163.4628608324475
[32m[0512 07:16:30 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:30 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:30 @base_trainer.py:216][0m Mean reward: -203.5862840870278
[32m[0512 07:16:30 @base_main.py:38][0m --------------- Iteration 7 ---------------
[32m[0512 07:16:30 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0863 mins
[32m[0512 07:16:30 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 07:16:30 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 07:16:30 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:16:30 @base_main.py:47][0m 7035 total steps have happened
[32m[0512 07:16:30 @base_main.py:52][0m [avg_reward]: -203.5862840870278
[32m[0512 07:16:30 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:30 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:30 @base_trainer.py:216][0m Mean reward: -179.02682376855628
[32m[0512 07:16:31 @base_main.py:38][0m --------------- Iteration 8 ---------------
[32m[0512 07:16:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0977 mins
[32m[0512 07:16:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 07:16:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0512 07:16:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:16:31 @base_main.py:47][0m 8040 total steps have happened
[32m[0512 07:16:31 @base_main.py:52][0m [avg_reward]: -179.02682376855628
[32m[0512 07:16:31 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:31 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:31 @base_trainer.py:216][0m Mean reward: -155.89679195787252
[32m[0512 07:16:32 @base_main.py:38][0m --------------- Iteration 9 ---------------
[32m[0512 07:16:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1091 mins
[32m[0512 07:16:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 07:16:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0512 07:16:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:16:32 @base_main.py:47][0m 9045 total steps have happened
[32m[0512 07:16:32 @base_main.py:52][0m [avg_reward]: -155.89679195787252
[32m[0512 07:16:32 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:32 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:32 @base_trainer.py:216][0m Mean reward: -117.01711815490872
[32m[0512 07:16:32 @base_main.py:38][0m --------------- Iteration 10 ---------------
[32m[0512 07:16:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1213 mins
[32m[0512 07:16:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 07:16:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0512 07:16:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:16:32 @base_main.py:47][0m 10050 total steps have happened
[32m[0512 07:16:32 @base_main.py:52][0m [avg_reward]: -117.01711815490872
[32m[0512 07:16:32 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:32 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:32 @base_trainer.py:216][0m Mean reward: -123.43012254093792
[32m[0512 07:16:33 @base_main.py:38][0m --------------- Iteration 11 ---------------
[32m[0512 07:16:33 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1329 mins
[32m[0512 07:16:33 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 07:16:33 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0512 07:16:33 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:16:33 @base_main.py:47][0m 11055 total steps have happened
[32m[0512 07:16:33 @base_main.py:52][0m [avg_reward]: -123.43012254093792
[32m[0512 07:16:33 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:33 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:33 @base_trainer.py:216][0m Mean reward: -111.61500415150549
[32m[0512 07:16:34 @base_main.py:38][0m --------------- Iteration 12 ---------------
[32m[0512 07:16:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1447 mins
[32m[0512 07:16:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:16:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0512 07:16:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 07:16:34 @base_main.py:47][0m 12060 total steps have happened
[32m[0512 07:16:34 @base_main.py:52][0m [avg_reward]: -111.61500415150549
[32m[0512 07:16:34 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:34 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:34 @base_trainer.py:216][0m Mean reward: -101.54078996626507
[32m[0512 07:16:35 @base_main.py:38][0m --------------- Iteration 13 ---------------
[32m[0512 07:16:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1569 mins
[32m[0512 07:16:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 07:16:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0512 07:16:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0512 07:16:35 @base_main.py:47][0m 13065 total steps have happened
[32m[0512 07:16:35 @base_main.py:52][0m [avg_reward]: -101.54078996626507
[32m[0512 07:16:35 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:35 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:35 @base_trainer.py:216][0m Mean reward: -114.02867589852251
[32m[0512 07:16:35 @base_main.py:38][0m --------------- Iteration 14 ---------------
[32m[0512 07:16:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1699 mins
[32m[0512 07:16:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 07:16:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 07:16:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 07:16:35 @base_main.py:47][0m 14070 total steps have happened
[32m[0512 07:16:35 @base_main.py:52][0m [avg_reward]: -114.02867589852251
[32m[0512 07:16:35 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:35 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:35 @base_trainer.py:216][0m Mean reward: -191.04422326902278
[32m[0512 07:16:36 @base_main.py:38][0m --------------- Iteration 15 ---------------
[32m[0512 07:16:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1820 mins
[32m[0512 07:16:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:16:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0512 07:16:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 07:16:36 @base_main.py:47][0m 15075 total steps have happened
[32m[0512 07:16:36 @base_main.py:52][0m [avg_reward]: -191.04422326902278
[32m[0512 07:16:36 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:36 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:36 @base_trainer.py:216][0m Mean reward: -213.04795376109823
[32m[0512 07:16:37 @base_main.py:38][0m --------------- Iteration 16 ---------------
[32m[0512 07:16:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1942 mins
[32m[0512 07:16:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 07:16:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0512 07:16:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 07:16:37 @base_main.py:47][0m 16080 total steps have happened
[32m[0512 07:16:37 @base_main.py:52][0m [avg_reward]: -213.04795376109823
[32m[0512 07:16:37 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:37 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:37 @base_trainer.py:216][0m Mean reward: -154.2013571862554
[32m[0512 07:16:37 @base_main.py:38][0m --------------- Iteration 17 ---------------
[32m[0512 07:16:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2061 mins
[32m[0512 07:16:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 07:16:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0084 mins
[32m[0512 07:16:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 07:16:37 @base_main.py:47][0m 17085 total steps have happened
[32m[0512 07:16:37 @base_main.py:52][0m [avg_reward]: -154.2013571862554
[32m[0512 07:16:38 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:38 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:38 @base_trainer.py:216][0m Mean reward: -193.62776231324185
[32m[0512 07:16:38 @base_main.py:38][0m --------------- Iteration 18 ---------------
[32m[0512 07:16:38 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2175 mins
[32m[0512 07:16:38 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0512 07:16:38 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0512 07:16:38 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 07:16:38 @base_main.py:47][0m 18090 total steps have happened
[32m[0512 07:16:38 @base_main.py:52][0m [avg_reward]: -193.62776231324185
[32m[0512 07:16:38 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:38 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:38 @base_trainer.py:216][0m Mean reward: -177.86967807052392
[32m[0512 07:16:39 @base_main.py:38][0m --------------- Iteration 19 ---------------
[32m[0512 07:16:39 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2297 mins
[32m[0512 07:16:39 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 07:16:39 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0512 07:16:39 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:16:39 @base_main.py:47][0m 19095 total steps have happened
[32m[0512 07:16:39 @base_main.py:52][0m [avg_reward]: -177.86967807052392
[32m[0512 07:16:39 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:39 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:39 @base_trainer.py:216][0m Mean reward: -108.74074019925688
[32m[0512 07:16:39 @base_main.py:38][0m --------------- Iteration 20 ---------------
[32m[0512 07:16:39 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2414 mins
[32m[0512 07:16:39 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:16:39 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0084 mins
[32m[0512 07:16:39 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:16:39 @base_main.py:47][0m 20100 total steps have happened
[32m[0512 07:16:39 @base_main.py:52][0m [avg_reward]: -108.74074019925688
[32m[0512 07:16:40 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:40 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:40 @base_trainer.py:216][0m Mean reward: -90.1462436676754
[32m[0512 07:16:40 @base_main.py:38][0m --------------- Iteration 21 ---------------
[32m[0512 07:16:40 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2526 mins
[32m[0512 07:16:40 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 07:16:40 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 07:16:40 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:16:40 @base_main.py:47][0m 21105 total steps have happened
[32m[0512 07:16:40 @base_main.py:52][0m [avg_reward]: -90.1462436676754
[32m[0512 07:16:40 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:40 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:40 @base_trainer.py:216][0m Mean reward: -88.37380072232857
[32m[0512 07:16:41 @base_main.py:38][0m --------------- Iteration 22 ---------------
[32m[0512 07:16:41 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2644 mins
[32m[0512 07:16:41 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:16:41 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0512 07:16:41 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:16:41 @base_main.py:47][0m 22110 total steps have happened
[32m[0512 07:16:41 @base_main.py:52][0m [avg_reward]: -88.37380072232857
[32m[0512 07:16:41 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:41 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:41 @base_trainer.py:216][0m Mean reward: -69.01031601768561
[32m[0512 07:16:42 @base_main.py:38][0m --------------- Iteration 23 ---------------
[32m[0512 07:16:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2767 mins
[32m[0512 07:16:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0512 07:16:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0512 07:16:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 07:16:42 @base_main.py:47][0m 23115 total steps have happened
[32m[0512 07:16:42 @base_main.py:52][0m [avg_reward]: -69.01031601768561
[32m[0512 07:16:42 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:42 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:42 @base_trainer.py:216][0m Mean reward: -139.80818438740587
[32m[0512 07:16:42 @base_main.py:38][0m --------------- Iteration 24 ---------------
[32m[0512 07:16:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2894 mins
[32m[0512 07:16:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:16:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0512 07:16:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 07:16:42 @base_main.py:47][0m 24120 total steps have happened
[32m[0512 07:16:42 @base_main.py:52][0m [avg_reward]: -139.80818438740587
[32m[0512 07:16:43 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:43 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:43 @base_trainer.py:216][0m Mean reward: -90.81071358148446
[32m[0512 07:16:43 @base_main.py:38][0m --------------- Iteration 25 ---------------
[32m[0512 07:16:43 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3023 mins
[32m[0512 07:16:43 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:16:43 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0512 07:16:43 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:16:43 @base_main.py:47][0m 25125 total steps have happened
[32m[0512 07:16:43 @base_main.py:52][0m [avg_reward]: -90.81071358148446
[32m[0512 07:16:43 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:43 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:43 @base_trainer.py:216][0m Mean reward: -64.84910217570345
[32m[0512 07:16:44 @base_main.py:38][0m --------------- Iteration 26 ---------------
[32m[0512 07:16:44 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3153 mins
[32m[0512 07:16:44 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:16:44 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0512 07:16:44 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:16:44 @base_main.py:47][0m 26130 total steps have happened
[32m[0512 07:16:44 @base_main.py:52][0m [avg_reward]: -64.84910217570345
[32m[0512 07:16:44 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:44 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:44 @base_trainer.py:216][0m Mean reward: -65.38745540085556
[32m[0512 07:16:45 @base_main.py:38][0m --------------- Iteration 27 ---------------
[32m[0512 07:16:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3276 mins
[32m[0512 07:16:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 07:16:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0512 07:16:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:16:45 @base_main.py:47][0m 27135 total steps have happened
[32m[0512 07:16:45 @base_main.py:52][0m [avg_reward]: -65.38745540085556
[32m[0512 07:16:45 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:45 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:45 @base_trainer.py:216][0m Mean reward: -94.78050198379391
[32m[0512 07:16:45 @base_main.py:38][0m --------------- Iteration 28 ---------------
[32m[0512 07:16:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3403 mins
[32m[0512 07:16:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 07:16:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0512 07:16:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:16:45 @base_main.py:47][0m 28140 total steps have happened
[32m[0512 07:16:45 @base_main.py:52][0m [avg_reward]: -94.78050198379391
[32m[0512 07:16:46 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:46 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:46 @base_trainer.py:216][0m Mean reward: -66.75963686705961
[32m[0512 07:16:46 @base_main.py:38][0m --------------- Iteration 29 ---------------
[32m[0512 07:16:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3527 mins
[32m[0512 07:16:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 07:16:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0512 07:16:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:16:46 @base_main.py:47][0m 29145 total steps have happened
[32m[0512 07:16:46 @base_main.py:52][0m [avg_reward]: -66.75963686705961
[32m[0512 07:16:46 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:46 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:46 @base_trainer.py:216][0m Mean reward: -54.33799547295979
[32m[0512 07:16:47 @base_main.py:38][0m --------------- Iteration 30 ---------------
[32m[0512 07:16:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3645 mins
[32m[0512 07:16:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 07:16:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0512 07:16:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:16:47 @base_main.py:47][0m 30150 total steps have happened
[32m[0512 07:16:47 @base_main.py:52][0m [avg_reward]: -54.33799547295979
[32m[0512 07:16:47 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:47 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:47 @base_trainer.py:216][0m Mean reward: -55.95768609008346
[32m[0512 07:16:48 @base_main.py:38][0m --------------- Iteration 31 ---------------
[32m[0512 07:16:48 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3770 mins
[32m[0512 07:16:48 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 07:16:48 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 07:16:48 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:16:48 @base_main.py:47][0m 31155 total steps have happened
[32m[0512 07:16:48 @base_main.py:52][0m [avg_reward]: -55.95768609008346
[32m[0512 07:16:48 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:48 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:48 @base_trainer.py:216][0m Mean reward: -72.98886133607682
[32m[0512 07:16:48 @base_main.py:38][0m --------------- Iteration 32 ---------------
[32m[0512 07:16:48 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3889 mins
[32m[0512 07:16:48 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 07:16:48 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0512 07:16:48 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:16:48 @base_main.py:47][0m 32160 total steps have happened
[32m[0512 07:16:48 @base_main.py:52][0m [avg_reward]: -72.98886133607682
[32m[0512 07:16:49 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:49 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:49 @base_trainer.py:216][0m Mean reward: -102.15823870187774
[32m[0512 07:16:49 @base_main.py:38][0m --------------- Iteration 33 ---------------
[32m[0512 07:16:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4015 mins
[32m[0512 07:16:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:16:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0512 07:16:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:16:49 @base_main.py:47][0m 33165 total steps have happened
[32m[0512 07:16:49 @base_main.py:52][0m [avg_reward]: -102.15823870187774
[32m[0512 07:16:49 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:49 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:49 @base_trainer.py:216][0m Mean reward: -66.06186599197471
[32m[0512 07:16:50 @base_main.py:38][0m --------------- Iteration 34 ---------------
[32m[0512 07:16:50 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4139 mins
[32m[0512 07:16:50 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 07:16:50 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 07:16:50 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:16:50 @base_main.py:47][0m 34170 total steps have happened
[32m[0512 07:16:50 @base_main.py:52][0m [avg_reward]: -66.06186599197471
[32m[0512 07:16:50 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:50 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:50 @base_trainer.py:216][0m Mean reward: -54.98659293609346
[32m[0512 07:16:51 @base_main.py:38][0m --------------- Iteration 35 ---------------
[32m[0512 07:16:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4259 mins
[32m[0512 07:16:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:16:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 07:16:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:16:51 @base_main.py:47][0m 35175 total steps have happened
[32m[0512 07:16:51 @base_main.py:52][0m [avg_reward]: -54.98659293609346
[32m[0512 07:16:51 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:51 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:51 @base_trainer.py:216][0m Mean reward: -87.88510304978482
[32m[0512 07:16:51 @base_main.py:38][0m --------------- Iteration 36 ---------------
[32m[0512 07:16:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4379 mins
[32m[0512 07:16:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 07:16:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0512 07:16:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:16:51 @base_main.py:47][0m 36180 total steps have happened
[32m[0512 07:16:51 @base_main.py:52][0m [avg_reward]: -87.88510304978482
[32m[0512 07:16:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:52 @base_trainer.py:216][0m Mean reward: -65.49778974658896
[32m[0512 07:16:52 @base_main.py:38][0m --------------- Iteration 37 ---------------
[32m[0512 07:16:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4510 mins
[32m[0512 07:16:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:16:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0512 07:16:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:16:52 @base_main.py:47][0m 37185 total steps have happened
[32m[0512 07:16:52 @base_main.py:52][0m [avg_reward]: -65.49778974658896
[32m[0512 07:16:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:52 @base_trainer.py:216][0m Mean reward: -56.145832101328836
[32m[0512 07:16:53 @base_main.py:38][0m --------------- Iteration 38 ---------------
[32m[0512 07:16:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4639 mins
[32m[0512 07:16:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 07:16:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0512 07:16:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0512 07:16:53 @base_main.py:47][0m 38190 total steps have happened
[32m[0512 07:16:53 @base_main.py:52][0m [avg_reward]: -56.145832101328836
[32m[0512 07:16:53 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:53 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:53 @base_trainer.py:216][0m Mean reward: -54.70602115025779
[32m[0512 07:16:54 @base_main.py:38][0m --------------- Iteration 39 ---------------
[32m[0512 07:16:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4767 mins
[32m[0512 07:16:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:16:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0512 07:16:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:16:54 @base_main.py:47][0m 39195 total steps have happened
[32m[0512 07:16:54 @base_main.py:52][0m [avg_reward]: -54.70602115025779
[32m[0512 07:16:54 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:54 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:54 @base_trainer.py:216][0m Mean reward: -45.93890756966783
[32m[0512 07:16:54 @base_main.py:38][0m --------------- Iteration 40 ---------------
[32m[0512 07:16:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4896 mins
[32m[0512 07:16:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:16:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0512 07:16:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:16:54 @base_main.py:47][0m 40200 total steps have happened
[32m[0512 07:16:54 @base_main.py:52][0m [avg_reward]: -45.93890756966783
[32m[0512 07:16:55 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:55 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:55 @base_trainer.py:216][0m Mean reward: -49.41388982386902
[32m[0512 07:16:55 @base_main.py:38][0m --------------- Iteration 41 ---------------
[32m[0512 07:16:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5019 mins
[32m[0512 07:16:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0512 07:16:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0512 07:16:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 07:16:55 @base_main.py:47][0m 41205 total steps have happened
[32m[0512 07:16:55 @base_main.py:52][0m [avg_reward]: -49.41388982386902
[32m[0512 07:16:55 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:55 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:55 @base_trainer.py:216][0m Mean reward: -45.88703834166509
[32m[0512 07:16:56 @base_main.py:38][0m --------------- Iteration 42 ---------------
[32m[0512 07:16:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5142 mins
[32m[0512 07:16:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 07:16:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0512 07:16:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:16:56 @base_main.py:47][0m 42210 total steps have happened
[32m[0512 07:16:56 @base_main.py:52][0m [avg_reward]: -45.88703834166509
[32m[0512 07:16:56 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:56 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:56 @base_trainer.py:216][0m Mean reward: -58.1300291703615
[32m[0512 07:16:57 @base_main.py:38][0m --------------- Iteration 43 ---------------
[32m[0512 07:16:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5267 mins
[32m[0512 07:16:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:16:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0512 07:16:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:16:57 @base_main.py:47][0m 43215 total steps have happened
[32m[0512 07:16:57 @base_main.py:52][0m [avg_reward]: -58.1300291703615
[32m[0512 07:16:57 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:57 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:57 @base_trainer.py:216][0m Mean reward: -92.86520328106785
[32m[0512 07:16:57 @base_main.py:38][0m --------------- Iteration 44 ---------------
[32m[0512 07:16:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5391 mins
[32m[0512 07:16:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 07:16:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0512 07:16:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 07:16:57 @base_main.py:47][0m 44220 total steps have happened
[32m[0512 07:16:57 @base_main.py:52][0m [avg_reward]: -92.86520328106785
[32m[0512 07:16:57 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:57 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:58 @base_trainer.py:216][0m Mean reward: -118.11523193247415
[32m[0512 07:16:58 @base_main.py:38][0m --------------- Iteration 45 ---------------
[32m[0512 07:16:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5504 mins
[32m[0512 07:16:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 07:16:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0512 07:16:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:16:58 @base_main.py:47][0m 45225 total steps have happened
[32m[0512 07:16:58 @base_main.py:52][0m [avg_reward]: -118.11523193247415
[32m[0512 07:16:58 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:58 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:58 @base_trainer.py:216][0m Mean reward: -99.21164694789461
[32m[0512 07:16:59 @base_main.py:38][0m --------------- Iteration 46 ---------------
[32m[0512 07:16:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5632 mins
[32m[0512 07:16:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 07:16:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0512 07:16:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 07:16:59 @base_main.py:47][0m 46230 total steps have happened
[32m[0512 07:16:59 @base_main.py:52][0m [avg_reward]: -99.21164694789461
[32m[0512 07:16:59 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:16:59 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:16:59 @base_trainer.py:216][0m Mean reward: -83.9357673284743
[32m[0512 07:17:00 @base_main.py:38][0m --------------- Iteration 47 ---------------
[32m[0512 07:17:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5754 mins
[32m[0512 07:17:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 07:17:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0512 07:17:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:00 @base_main.py:47][0m 47235 total steps have happened
[32m[0512 07:17:00 @base_main.py:52][0m [avg_reward]: -83.9357673284743
[32m[0512 07:17:00 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:00 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:00 @base_trainer.py:216][0m Mean reward: -92.36441762407449
[32m[0512 07:17:00 @base_main.py:38][0m --------------- Iteration 48 ---------------
[32m[0512 07:17:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5883 mins
[32m[0512 07:17:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 07:17:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0512 07:17:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:00 @base_main.py:47][0m 48240 total steps have happened
[32m[0512 07:17:00 @base_main.py:52][0m [avg_reward]: -92.36441762407449
[32m[0512 07:17:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:01 @base_trainer.py:216][0m Mean reward: -78.61368414597256
[32m[0512 07:17:01 @base_main.py:38][0m --------------- Iteration 49 ---------------
[32m[0512 07:17:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6009 mins
[32m[0512 07:17:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:17:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0512 07:17:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:01 @base_main.py:47][0m 49245 total steps have happened
[32m[0512 07:17:01 @base_main.py:52][0m [avg_reward]: -78.61368414597256
[32m[0512 07:17:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:01 @base_trainer.py:216][0m Mean reward: -98.85630046105496
[32m[0512 07:17:02 @base_main.py:38][0m --------------- Iteration 50 ---------------
[32m[0512 07:17:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6130 mins
[32m[0512 07:17:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 07:17:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0512 07:17:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 07:17:02 @base_main.py:47][0m 50250 total steps have happened
[32m[0512 07:17:02 @base_main.py:52][0m [avg_reward]: -98.85630046105496
[32m[0512 07:17:02 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:02 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:02 @base_trainer.py:216][0m Mean reward: -83.46593217758627
[32m[0512 07:17:03 @base_main.py:38][0m --------------- Iteration 51 ---------------
[32m[0512 07:17:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6259 mins
[32m[0512 07:17:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:17:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0512 07:17:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:03 @base_main.py:47][0m 51255 total steps have happened
[32m[0512 07:17:03 @base_main.py:52][0m [avg_reward]: -83.46593217758627
[32m[0512 07:17:03 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:03 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:03 @base_trainer.py:216][0m Mean reward: -105.78257878501594
[32m[0512 07:17:03 @base_main.py:38][0m --------------- Iteration 52 ---------------
[32m[0512 07:17:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6388 mins
[32m[0512 07:17:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 07:17:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0512 07:17:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:03 @base_main.py:47][0m 52260 total steps have happened
[32m[0512 07:17:03 @base_main.py:52][0m [avg_reward]: -105.78257878501594
[32m[0512 07:17:04 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:04 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:04 @base_trainer.py:216][0m Mean reward: -74.12597333506679
[32m[0512 07:17:04 @base_main.py:38][0m --------------- Iteration 53 ---------------
[32m[0512 07:17:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6512 mins
[32m[0512 07:17:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 07:17:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 07:17:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 07:17:04 @base_main.py:47][0m 53265 total steps have happened
[32m[0512 07:17:04 @base_main.py:52][0m [avg_reward]: -74.12597333506679
[32m[0512 07:17:04 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:04 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:04 @base_trainer.py:216][0m Mean reward: -74.5105294162133
[32m[0512 07:17:05 @base_main.py:38][0m --------------- Iteration 54 ---------------
[32m[0512 07:17:05 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6635 mins
[32m[0512 07:17:05 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 07:17:05 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0512 07:17:05 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:05 @base_main.py:47][0m 54270 total steps have happened
[32m[0512 07:17:05 @base_main.py:52][0m [avg_reward]: -74.5105294162133
[32m[0512 07:17:05 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:05 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:05 @base_trainer.py:216][0m Mean reward: -55.03495473904449
[32m[0512 07:17:06 @base_main.py:38][0m --------------- Iteration 55 ---------------
[32m[0512 07:17:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6761 mins
[32m[0512 07:17:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 07:17:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 07:17:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:06 @base_main.py:47][0m 55275 total steps have happened
[32m[0512 07:17:06 @base_main.py:52][0m [avg_reward]: -55.03495473904449
[32m[0512 07:17:06 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:06 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:06 @base_trainer.py:216][0m Mean reward: -46.724483882802836
[32m[0512 07:17:06 @base_main.py:38][0m --------------- Iteration 56 ---------------
[32m[0512 07:17:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6880 mins
[32m[0512 07:17:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:17:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 07:17:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 07:17:06 @base_main.py:47][0m 56280 total steps have happened
[32m[0512 07:17:06 @base_main.py:52][0m [avg_reward]: -46.724483882802836
[32m[0512 07:17:06 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:06 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:06 @base_trainer.py:216][0m Mean reward: -43.81400078455654
[32m[0512 07:17:07 @base_main.py:38][0m --------------- Iteration 57 ---------------
[32m[0512 07:17:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6996 mins
[32m[0512 07:17:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:17:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 07:17:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:07 @base_main.py:47][0m 57285 total steps have happened
[32m[0512 07:17:07 @base_main.py:52][0m [avg_reward]: -43.81400078455654
[32m[0512 07:17:07 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:07 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:07 @base_trainer.py:216][0m Mean reward: -50.97052220092848
[32m[0512 07:17:08 @base_main.py:38][0m --------------- Iteration 58 ---------------
[32m[0512 07:17:08 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7112 mins
[32m[0512 07:17:08 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0512 07:17:08 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0512 07:17:08 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:08 @base_main.py:47][0m 58290 total steps have happened
[32m[0512 07:17:08 @base_main.py:52][0m [avg_reward]: -50.97052220092848
[32m[0512 07:17:08 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:08 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:08 @base_trainer.py:216][0m Mean reward: -47.04149079976754
[32m[0512 07:17:08 @base_main.py:38][0m --------------- Iteration 59 ---------------
[32m[0512 07:17:08 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7231 mins
[32m[0512 07:17:08 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 07:17:08 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0512 07:17:08 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:08 @base_main.py:47][0m 59295 total steps have happened
[32m[0512 07:17:08 @base_main.py:52][0m [avg_reward]: -47.04149079976754
[32m[0512 07:17:09 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:09 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:09 @base_trainer.py:216][0m Mean reward: -45.06813029932691
[32m[0512 07:17:09 @base_main.py:38][0m --------------- Iteration 60 ---------------
[32m[0512 07:17:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7356 mins
[32m[0512 07:17:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 07:17:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0512 07:17:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:09 @base_main.py:47][0m 60300 total steps have happened
[32m[0512 07:17:09 @base_main.py:52][0m [avg_reward]: -45.06813029932691
[32m[0512 07:17:09 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:09 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:09 @base_trainer.py:216][0m Mean reward: -46.9225758956937
[32m[0512 07:17:10 @base_main.py:38][0m --------------- Iteration 61 ---------------
[32m[0512 07:17:10 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7481 mins
[32m[0512 07:17:10 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 07:17:10 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0512 07:17:10 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:10 @base_main.py:47][0m 61305 total steps have happened
[32m[0512 07:17:10 @base_main.py:52][0m [avg_reward]: -46.9225758956937
[32m[0512 07:17:10 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:10 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:10 @base_trainer.py:216][0m Mean reward: -42.60476482574134
[32m[0512 07:17:11 @base_main.py:38][0m --------------- Iteration 62 ---------------
[32m[0512 07:17:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7603 mins
[32m[0512 07:17:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 07:17:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0512 07:17:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:11 @base_main.py:47][0m 62310 total steps have happened
[32m[0512 07:17:11 @base_main.py:52][0m [avg_reward]: -42.60476482574134
[32m[0512 07:17:11 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:11 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:11 @base_trainer.py:216][0m Mean reward: -44.30085863904679
[32m[0512 07:17:11 @base_main.py:38][0m --------------- Iteration 63 ---------------
[32m[0512 07:17:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7726 mins
[32m[0512 07:17:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 07:17:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0512 07:17:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:11 @base_main.py:47][0m 63315 total steps have happened
[32m[0512 07:17:11 @base_main.py:52][0m [avg_reward]: -44.30085863904679
[32m[0512 07:17:12 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:12 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:12 @base_trainer.py:216][0m Mean reward: -47.30202364385636
[32m[0512 07:17:12 @base_main.py:38][0m --------------- Iteration 64 ---------------
[32m[0512 07:17:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7851 mins
[32m[0512 07:17:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 07:17:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0512 07:17:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:12 @base_main.py:47][0m 64320 total steps have happened
[32m[0512 07:17:12 @base_main.py:52][0m [avg_reward]: -47.30202364385636
[32m[0512 07:17:12 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:12 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:12 @base_trainer.py:216][0m Mean reward: -42.42906080362269
[32m[0512 07:17:13 @base_main.py:38][0m --------------- Iteration 65 ---------------
[32m[0512 07:17:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7974 mins
[32m[0512 07:17:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:17:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0512 07:17:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 07:17:13 @base_main.py:47][0m 65325 total steps have happened
[32m[0512 07:17:13 @base_main.py:52][0m [avg_reward]: -42.42906080362269
[32m[0512 07:17:13 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:13 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:13 @base_trainer.py:216][0m Mean reward: -42.73592599828831
[32m[0512 07:17:14 @base_main.py:38][0m --------------- Iteration 66 ---------------
[32m[0512 07:17:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8087 mins
[32m[0512 07:17:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:17:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 07:17:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:14 @base_main.py:47][0m 66330 total steps have happened
[32m[0512 07:17:14 @base_main.py:52][0m [avg_reward]: -42.73592599828831
[32m[0512 07:17:14 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:14 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:14 @base_trainer.py:216][0m Mean reward: -44.29590390880871
[32m[0512 07:17:14 @base_main.py:38][0m --------------- Iteration 67 ---------------
[32m[0512 07:17:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8205 mins
[32m[0512 07:17:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 07:17:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0512 07:17:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:14 @base_main.py:47][0m 67335 total steps have happened
[32m[0512 07:17:14 @base_main.py:52][0m [avg_reward]: -44.29590390880871
[32m[0512 07:17:14 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:14 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:14 @base_trainer.py:216][0m Mean reward: -41.739490468518554
[32m[0512 07:17:15 @base_main.py:38][0m --------------- Iteration 68 ---------------
[32m[0512 07:17:15 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8331 mins
[32m[0512 07:17:15 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 07:17:15 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 07:17:15 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:15 @base_main.py:47][0m 68340 total steps have happened
[32m[0512 07:17:15 @base_main.py:52][0m [avg_reward]: -41.739490468518554
[32m[0512 07:17:15 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:15 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:15 @base_trainer.py:216][0m Mean reward: -43.064083724030795
[32m[0512 07:17:16 @base_main.py:38][0m --------------- Iteration 69 ---------------
[32m[0512 07:17:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8452 mins
[32m[0512 07:17:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 07:17:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0512 07:17:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 07:17:16 @base_main.py:47][0m 69345 total steps have happened
[32m[0512 07:17:16 @base_main.py:52][0m [avg_reward]: -43.064083724030795
[32m[0512 07:17:16 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:16 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:16 @base_trainer.py:216][0m Mean reward: -43.80195949683425
[32m[0512 07:17:17 @base_main.py:38][0m --------------- Iteration 70 ---------------
[32m[0512 07:17:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8577 mins
[32m[0512 07:17:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0512 07:17:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0512 07:17:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:17 @base_main.py:47][0m 70350 total steps have happened
[32m[0512 07:17:17 @base_main.py:52][0m [avg_reward]: -43.80195949683425
[32m[0512 07:17:17 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:17 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:17 @base_trainer.py:216][0m Mean reward: -42.85205578622938
[32m[0512 07:17:17 @base_main.py:38][0m --------------- Iteration 71 ---------------
[32m[0512 07:17:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8706 mins
[32m[0512 07:17:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:17:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0512 07:17:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:17 @base_main.py:47][0m 71355 total steps have happened
[32m[0512 07:17:17 @base_main.py:52][0m [avg_reward]: -42.85205578622938
[32m[0512 07:17:17 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:17 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:17 @base_trainer.py:216][0m Mean reward: -41.14998857395322
[32m[0512 07:17:18 @base_main.py:38][0m --------------- Iteration 72 ---------------
[32m[0512 07:17:18 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8827 mins
[32m[0512 07:17:18 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 07:17:18 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0512 07:17:18 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:18 @base_main.py:47][0m 72360 total steps have happened
[32m[0512 07:17:18 @base_main.py:52][0m [avg_reward]: -41.14998857395322
[32m[0512 07:17:18 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:18 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:18 @base_trainer.py:216][0m Mean reward: -42.00444081254915
[32m[0512 07:17:19 @base_main.py:38][0m --------------- Iteration 73 ---------------
[32m[0512 07:17:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8947 mins
[32m[0512 07:17:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:17:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0512 07:17:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 07:17:19 @base_main.py:47][0m 73365 total steps have happened
[32m[0512 07:17:19 @base_main.py:52][0m [avg_reward]: -42.00444081254915
[32m[0512 07:17:19 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:19 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:19 @base_trainer.py:216][0m Mean reward: -43.47518449082818
[32m[0512 07:17:19 @base_main.py:38][0m --------------- Iteration 74 ---------------
[32m[0512 07:17:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9068 mins
[32m[0512 07:17:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 07:17:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0512 07:17:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:19 @base_main.py:47][0m 74370 total steps have happened
[32m[0512 07:17:19 @base_main.py:52][0m [avg_reward]: -43.47518449082818
[32m[0512 07:17:20 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:20 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:20 @base_trainer.py:216][0m Mean reward: -40.8273468456165
[32m[0512 07:17:20 @base_main.py:38][0m --------------- Iteration 75 ---------------
[32m[0512 07:17:20 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9191 mins
[32m[0512 07:17:20 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 07:17:20 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 07:17:20 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:20 @base_main.py:47][0m 75375 total steps have happened
[32m[0512 07:17:20 @base_main.py:52][0m [avg_reward]: -40.8273468456165
[32m[0512 07:17:20 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:20 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:20 @base_trainer.py:216][0m Mean reward: -41.324509990896814
[32m[0512 07:17:21 @base_main.py:38][0m --------------- Iteration 76 ---------------
[32m[0512 07:17:21 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9311 mins
[32m[0512 07:17:21 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 07:17:21 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0512 07:17:21 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:21 @base_main.py:47][0m 76380 total steps have happened
[32m[0512 07:17:21 @base_main.py:52][0m [avg_reward]: -41.324509990896814
[32m[0512 07:17:21 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:21 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:21 @base_trainer.py:216][0m Mean reward: -43.90428211032319
[32m[0512 07:17:22 @base_main.py:38][0m --------------- Iteration 77 ---------------
[32m[0512 07:17:22 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9441 mins
[32m[0512 07:17:22 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 07:17:22 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0512 07:17:22 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:22 @base_main.py:47][0m 77385 total steps have happened
[32m[0512 07:17:22 @base_main.py:52][0m [avg_reward]: -43.90428211032319
[32m[0512 07:17:22 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:22 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:22 @base_trainer.py:216][0m Mean reward: -67.63537392968809
[32m[0512 07:17:22 @base_main.py:38][0m --------------- Iteration 78 ---------------
[32m[0512 07:17:22 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9563 mins
[32m[0512 07:17:22 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:17:22 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0512 07:17:22 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:22 @base_main.py:47][0m 78390 total steps have happened
[32m[0512 07:17:22 @base_main.py:52][0m [avg_reward]: -67.63537392968809
[32m[0512 07:17:23 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:23 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:23 @base_trainer.py:216][0m Mean reward: -60.480917881434564
[32m[0512 07:17:23 @base_main.py:38][0m --------------- Iteration 79 ---------------
[32m[0512 07:17:23 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9689 mins
[32m[0512 07:17:23 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:17:23 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0512 07:17:23 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:23 @base_main.py:47][0m 79395 total steps have happened
[32m[0512 07:17:23 @base_main.py:52][0m [avg_reward]: -60.480917881434564
[32m[0512 07:17:23 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:23 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:23 @base_trainer.py:216][0m Mean reward: -46.949379988817874
[32m[0512 07:17:24 @base_main.py:38][0m --------------- Iteration 80 ---------------
[32m[0512 07:17:24 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9816 mins
[32m[0512 07:17:24 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:17:24 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0512 07:17:24 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:24 @base_main.py:47][0m 80400 total steps have happened
[32m[0512 07:17:24 @base_main.py:52][0m [avg_reward]: -46.949379988817874
[32m[0512 07:17:24 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:24 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:24 @base_trainer.py:216][0m Mean reward: -41.60093009463024
[32m[0512 07:17:25 @base_main.py:38][0m --------------- Iteration 81 ---------------
[32m[0512 07:17:25 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9933 mins
[32m[0512 07:17:25 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:17:25 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0512 07:17:25 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 07:17:25 @base_main.py:47][0m 81405 total steps have happened
[32m[0512 07:17:25 @base_main.py:52][0m [avg_reward]: -41.60093009463024
[32m[0512 07:17:25 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:25 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:25 @base_trainer.py:216][0m Mean reward: -42.06404004895391
[32m[0512 07:17:25 @base_main.py:38][0m --------------- Iteration 82 ---------------
[32m[0512 07:17:25 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0062 mins
[32m[0512 07:17:25 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:17:25 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0512 07:17:25 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:25 @base_main.py:47][0m 82410 total steps have happened
[32m[0512 07:17:25 @base_main.py:52][0m [avg_reward]: -42.06404004895391
[32m[0512 07:17:26 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:26 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:26 @base_trainer.py:216][0m Mean reward: -47.29734080361112
[32m[0512 07:17:26 @base_main.py:38][0m --------------- Iteration 83 ---------------
[32m[0512 07:17:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0185 mins
[32m[0512 07:17:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:17:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0512 07:17:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 07:17:26 @base_main.py:47][0m 83415 total steps have happened
[32m[0512 07:17:26 @base_main.py:52][0m [avg_reward]: -47.29734080361112
[32m[0512 07:17:26 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:26 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:26 @base_trainer.py:216][0m Mean reward: -44.90791377371723
[32m[0512 07:17:27 @base_main.py:38][0m --------------- Iteration 84 ---------------
[32m[0512 07:17:27 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0310 mins
[32m[0512 07:17:27 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 07:17:27 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0512 07:17:27 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:27 @base_main.py:47][0m 84420 total steps have happened
[32m[0512 07:17:27 @base_main.py:52][0m [avg_reward]: -44.90791377371723
[32m[0512 07:17:27 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:27 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:27 @base_trainer.py:216][0m Mean reward: -41.28204219456266
[32m[0512 07:17:28 @base_main.py:38][0m --------------- Iteration 85 ---------------
[32m[0512 07:17:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0434 mins
[32m[0512 07:17:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 07:17:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0512 07:17:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:28 @base_main.py:47][0m 85425 total steps have happened
[32m[0512 07:17:28 @base_main.py:52][0m [avg_reward]: -41.28204219456266
[32m[0512 07:17:28 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:28 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:28 @base_trainer.py:216][0m Mean reward: -47.615856658074954
[32m[0512 07:17:28 @base_main.py:38][0m --------------- Iteration 86 ---------------
[32m[0512 07:17:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0554 mins
[32m[0512 07:17:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 07:17:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0512 07:17:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 07:17:28 @base_main.py:47][0m 86430 total steps have happened
[32m[0512 07:17:28 @base_main.py:52][0m [avg_reward]: -47.615856658074954
[32m[0512 07:17:29 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:29 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:29 @base_trainer.py:216][0m Mean reward: -43.3340033319226
[32m[0512 07:17:29 @base_main.py:38][0m --------------- Iteration 87 ---------------
[32m[0512 07:17:29 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0678 mins
[32m[0512 07:17:29 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 07:17:29 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0512 07:17:29 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:29 @base_main.py:47][0m 87435 total steps have happened
[32m[0512 07:17:29 @base_main.py:52][0m [avg_reward]: -43.3340033319226
[32m[0512 07:17:29 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:29 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:29 @base_trainer.py:216][0m Mean reward: -54.44658503541139
[32m[0512 07:17:30 @base_main.py:38][0m --------------- Iteration 88 ---------------
[32m[0512 07:17:30 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0799 mins
[32m[0512 07:17:30 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 07:17:30 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0512 07:17:30 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:30 @base_main.py:47][0m 88440 total steps have happened
[32m[0512 07:17:30 @base_main.py:52][0m [avg_reward]: -54.44658503541139
[32m[0512 07:17:30 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:30 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:30 @base_trainer.py:216][0m Mean reward: -42.71258768163359
[32m[0512 07:17:31 @base_main.py:38][0m --------------- Iteration 89 ---------------
[32m[0512 07:17:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0920 mins
[32m[0512 07:17:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:17:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0512 07:17:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:31 @base_main.py:47][0m 89445 total steps have happened
[32m[0512 07:17:31 @base_main.py:52][0m [avg_reward]: -42.71258768163359
[32m[0512 07:17:31 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:31 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:31 @base_trainer.py:216][0m Mean reward: -60.142744974013155
[32m[0512 07:17:31 @base_main.py:38][0m --------------- Iteration 90 ---------------
[32m[0512 07:17:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1047 mins
[32m[0512 07:17:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 07:17:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0512 07:17:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:31 @base_main.py:47][0m 90450 total steps have happened
[32m[0512 07:17:31 @base_main.py:52][0m [avg_reward]: -60.142744974013155
[32m[0512 07:17:31 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:31 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:31 @base_trainer.py:216][0m Mean reward: -44.42810345480288
[32m[0512 07:17:32 @base_main.py:38][0m --------------- Iteration 91 ---------------
[32m[0512 07:17:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1161 mins
[32m[0512 07:17:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 07:17:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0512 07:17:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:32 @base_main.py:47][0m 91455 total steps have happened
[32m[0512 07:17:32 @base_main.py:52][0m [avg_reward]: -44.42810345480288
[32m[0512 07:17:32 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:32 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:32 @base_trainer.py:216][0m Mean reward: -47.24545235814467
[32m[0512 07:17:33 @base_main.py:38][0m --------------- Iteration 92 ---------------
[32m[0512 07:17:33 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1291 mins
[32m[0512 07:17:33 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 07:17:33 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 07:17:33 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:33 @base_main.py:47][0m 92460 total steps have happened
[32m[0512 07:17:33 @base_main.py:52][0m [avg_reward]: -47.24545235814467
[32m[0512 07:17:33 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:33 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:33 @base_trainer.py:216][0m Mean reward: -45.072123550687294
[32m[0512 07:17:34 @base_main.py:38][0m --------------- Iteration 93 ---------------
[32m[0512 07:17:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1412 mins
[32m[0512 07:17:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 07:17:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0512 07:17:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:34 @base_main.py:47][0m 93465 total steps have happened
[32m[0512 07:17:34 @base_main.py:52][0m [avg_reward]: -45.072123550687294
[32m[0512 07:17:34 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:34 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:34 @base_trainer.py:216][0m Mean reward: -45.85298249185564
[32m[0512 07:17:34 @base_main.py:38][0m --------------- Iteration 94 ---------------
[32m[0512 07:17:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1535 mins
[32m[0512 07:17:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:17:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0512 07:17:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:34 @base_main.py:47][0m 94470 total steps have happened
[32m[0512 07:17:34 @base_main.py:52][0m [avg_reward]: -45.85298249185564
[32m[0512 07:17:34 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:34 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:34 @base_trainer.py:216][0m Mean reward: -44.796315172593836
[32m[0512 07:17:35 @base_main.py:38][0m --------------- Iteration 95 ---------------
[32m[0512 07:17:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1665 mins
[32m[0512 07:17:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 07:17:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0512 07:17:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:35 @base_main.py:47][0m 95475 total steps have happened
[32m[0512 07:17:35 @base_main.py:52][0m [avg_reward]: -44.796315172593836
[32m[0512 07:17:35 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:35 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:35 @base_trainer.py:216][0m Mean reward: -47.295023673255244
[32m[0512 07:17:36 @base_main.py:38][0m --------------- Iteration 96 ---------------
[32m[0512 07:17:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1792 mins
[32m[0512 07:17:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 07:17:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0512 07:17:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:36 @base_main.py:47][0m 96480 total steps have happened
[32m[0512 07:17:36 @base_main.py:52][0m [avg_reward]: -47.295023673255244
[32m[0512 07:17:36 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:36 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:36 @base_trainer.py:216][0m Mean reward: -45.85387476765574
[32m[0512 07:17:37 @base_main.py:38][0m --------------- Iteration 97 ---------------
[32m[0512 07:17:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1918 mins
[32m[0512 07:17:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:17:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0512 07:17:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 07:17:37 @base_main.py:47][0m 97485 total steps have happened
[32m[0512 07:17:37 @base_main.py:52][0m [avg_reward]: -45.85387476765574
[32m[0512 07:17:37 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:37 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:37 @base_trainer.py:216][0m Mean reward: -47.12896051778479
[32m[0512 07:17:37 @base_main.py:38][0m --------------- Iteration 98 ---------------
[32m[0512 07:17:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2048 mins
[32m[0512 07:17:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 07:17:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0512 07:17:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:37 @base_main.py:47][0m 98490 total steps have happened
[32m[0512 07:17:37 @base_main.py:52][0m [avg_reward]: -47.12896051778479
[32m[0512 07:17:38 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:38 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:38 @base_trainer.py:216][0m Mean reward: -45.89055848384404
[32m[0512 07:17:38 @base_main.py:38][0m --------------- Iteration 99 ---------------
[32m[0512 07:17:38 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2172 mins
[32m[0512 07:17:38 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:17:38 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0512 07:17:38 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:38 @base_main.py:47][0m 99495 total steps have happened
[32m[0512 07:17:38 @base_main.py:52][0m [avg_reward]: -45.89055848384404
[32m[0512 07:17:38 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:38 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:38 @base_trainer.py:216][0m Mean reward: -48.39351156209206
[32m[0512 07:17:39 @base_main.py:38][0m --------------- Iteration 100 ---------------
[32m[0512 07:17:39 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2300 mins
[32m[0512 07:17:39 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 07:17:39 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0512 07:17:39 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:39 @base_main.py:47][0m 100500 total steps have happened
[32m[0512 07:17:39 @base_main.py:52][0m [avg_reward]: -48.39351156209206
[32m[0512 07:17:39 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:39 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:39 @base_trainer.py:216][0m Mean reward: -50.62007166587325
[32m[0512 07:17:40 @base_main.py:38][0m --------------- Iteration 101 ---------------
[32m[0512 07:17:40 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2424 mins
[32m[0512 07:17:40 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 07:17:40 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0512 07:17:40 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:40 @base_main.py:47][0m 101505 total steps have happened
[32m[0512 07:17:40 @base_main.py:52][0m [avg_reward]: -50.62007166587325
[32m[0512 07:17:40 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:40 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:40 @base_trainer.py:216][0m Mean reward: -49.56872435241307
[32m[0512 07:17:40 @base_main.py:38][0m --------------- Iteration 102 ---------------
[32m[0512 07:17:40 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2552 mins
[32m[0512 07:17:40 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:17:40 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0512 07:17:40 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 07:17:40 @base_main.py:47][0m 102510 total steps have happened
[32m[0512 07:17:40 @base_main.py:52][0m [avg_reward]: -49.56872435241307
[32m[0512 07:17:40 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:40 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:40 @base_trainer.py:216][0m Mean reward: -65.9787139271586
[32m[0512 07:17:41 @base_main.py:38][0m --------------- Iteration 103 ---------------
[32m[0512 07:17:41 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2666 mins
[32m[0512 07:17:41 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 07:17:41 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0512 07:17:41 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:41 @base_main.py:47][0m 103515 total steps have happened
[32m[0512 07:17:41 @base_main.py:52][0m [avg_reward]: -65.9787139271586
[32m[0512 07:17:41 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:41 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:41 @base_trainer.py:216][0m Mean reward: -51.69745182132611
[32m[0512 07:17:42 @base_main.py:38][0m --------------- Iteration 104 ---------------
[32m[0512 07:17:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2794 mins
[32m[0512 07:17:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 07:17:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0512 07:17:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:42 @base_main.py:47][0m 104520 total steps have happened
[32m[0512 07:17:42 @base_main.py:52][0m [avg_reward]: -51.69745182132611
[32m[0512 07:17:42 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:42 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:42 @base_trainer.py:216][0m Mean reward: -58.9119747967967
[32m[0512 07:17:43 @base_main.py:38][0m --------------- Iteration 105 ---------------
[32m[0512 07:17:43 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2923 mins
[32m[0512 07:17:43 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:17:43 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0512 07:17:43 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:43 @base_main.py:47][0m 105525 total steps have happened
[32m[0512 07:17:43 @base_main.py:52][0m [avg_reward]: -58.9119747967967
[32m[0512 07:17:43 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:43 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:43 @base_trainer.py:216][0m Mean reward: -72.71134740889408
[32m[0512 07:17:43 @base_main.py:38][0m --------------- Iteration 106 ---------------
[32m[0512 07:17:43 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3046 mins
[32m[0512 07:17:43 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0512 07:17:43 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0512 07:17:43 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:43 @base_main.py:47][0m 106530 total steps have happened
[32m[0512 07:17:43 @base_main.py:52][0m [avg_reward]: -72.71134740889408
[32m[0512 07:17:44 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:44 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:44 @base_trainer.py:216][0m Mean reward: -50.81082973382492
[32m[0512 07:17:44 @base_main.py:38][0m --------------- Iteration 107 ---------------
[32m[0512 07:17:44 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3171 mins
[32m[0512 07:17:44 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 07:17:44 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0512 07:17:44 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:44 @base_main.py:47][0m 107535 total steps have happened
[32m[0512 07:17:44 @base_main.py:52][0m [avg_reward]: -50.81082973382492
[32m[0512 07:17:44 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:44 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:44 @base_trainer.py:216][0m Mean reward: -62.74489915469578
[32m[0512 07:17:45 @base_main.py:38][0m --------------- Iteration 108 ---------------
[32m[0512 07:17:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3303 mins
[32m[0512 07:17:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 07:17:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0512 07:17:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:45 @base_main.py:47][0m 108540 total steps have happened
[32m[0512 07:17:45 @base_main.py:52][0m [avg_reward]: -62.74489915469578
[32m[0512 07:17:45 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:45 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:45 @base_trainer.py:216][0m Mean reward: -66.49493369013031
[32m[0512 07:17:46 @base_main.py:38][0m --------------- Iteration 109 ---------------
[32m[0512 07:17:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3429 mins
[32m[0512 07:17:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 07:17:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 07:17:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:46 @base_main.py:47][0m 109545 total steps have happened
[32m[0512 07:17:46 @base_main.py:52][0m [avg_reward]: -66.49493369013031
[32m[0512 07:17:46 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:46 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:46 @base_trainer.py:216][0m Mean reward: -57.625221676138
[32m[0512 07:17:46 @base_main.py:38][0m --------------- Iteration 110 ---------------
[32m[0512 07:17:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3543 mins
[32m[0512 07:17:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 07:17:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0512 07:17:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:46 @base_main.py:47][0m 110550 total steps have happened
[32m[0512 07:17:46 @base_main.py:52][0m [avg_reward]: -57.625221676138
[32m[0512 07:17:46 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:46 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:46 @base_trainer.py:216][0m Mean reward: -51.10349481908453
[32m[0512 07:17:47 @base_main.py:38][0m --------------- Iteration 111 ---------------
[32m[0512 07:17:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3664 mins
[32m[0512 07:17:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 07:17:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0512 07:17:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:47 @base_main.py:47][0m 111555 total steps have happened
[32m[0512 07:17:47 @base_main.py:52][0m [avg_reward]: -51.10349481908453
[32m[0512 07:17:47 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:47 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:47 @base_trainer.py:216][0m Mean reward: -46.58445878999548
[32m[0512 07:17:48 @base_main.py:38][0m --------------- Iteration 112 ---------------
[32m[0512 07:17:48 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3793 mins
[32m[0512 07:17:48 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:17:48 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0512 07:17:48 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:48 @base_main.py:47][0m 112560 total steps have happened
[32m[0512 07:17:48 @base_main.py:52][0m [avg_reward]: -46.58445878999548
[32m[0512 07:17:48 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:48 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:48 @base_trainer.py:216][0m Mean reward: -52.13433198858968
[32m[0512 07:17:49 @base_main.py:38][0m --------------- Iteration 113 ---------------
[32m[0512 07:17:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3917 mins
[32m[0512 07:17:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0512 07:17:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0512 07:17:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:49 @base_main.py:47][0m 113565 total steps have happened
[32m[0512 07:17:49 @base_main.py:52][0m [avg_reward]: -52.13433198858968
[32m[0512 07:17:49 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:49 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:49 @base_trainer.py:216][0m Mean reward: -48.8992290260064
[32m[0512 07:17:49 @base_main.py:38][0m --------------- Iteration 114 ---------------
[32m[0512 07:17:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4034 mins
[32m[0512 07:17:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 07:17:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0512 07:17:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:49 @base_main.py:47][0m 114570 total steps have happened
[32m[0512 07:17:49 @base_main.py:52][0m [avg_reward]: -48.8992290260064
[32m[0512 07:17:49 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:49 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:49 @base_trainer.py:216][0m Mean reward: -56.700706950968446
[32m[0512 07:17:50 @base_main.py:38][0m --------------- Iteration 115 ---------------
[32m[0512 07:17:50 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4163 mins
[32m[0512 07:17:50 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:17:50 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0512 07:17:50 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 07:17:50 @base_main.py:47][0m 115575 total steps have happened
[32m[0512 07:17:50 @base_main.py:52][0m [avg_reward]: -56.700706950968446
[32m[0512 07:17:50 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:50 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:50 @base_trainer.py:216][0m Mean reward: -64.88313369439462
[32m[0512 07:17:51 @base_main.py:38][0m --------------- Iteration 116 ---------------
[32m[0512 07:17:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4292 mins
[32m[0512 07:17:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 07:17:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0512 07:17:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:51 @base_main.py:47][0m 116580 total steps have happened
[32m[0512 07:17:51 @base_main.py:52][0m [avg_reward]: -64.88313369439462
[32m[0512 07:17:51 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:51 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:51 @base_trainer.py:216][0m Mean reward: -67.91045285450396
[32m[0512 07:17:52 @base_main.py:38][0m --------------- Iteration 117 ---------------
[32m[0512 07:17:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4419 mins
[32m[0512 07:17:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:17:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0512 07:17:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:52 @base_main.py:47][0m 117585 total steps have happened
[32m[0512 07:17:52 @base_main.py:52][0m [avg_reward]: -67.91045285450396
[32m[0512 07:17:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:52 @base_trainer.py:216][0m Mean reward: -47.845639875542176
[32m[0512 07:17:52 @base_main.py:38][0m --------------- Iteration 118 ---------------
[32m[0512 07:17:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4540 mins
[32m[0512 07:17:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0034 mins
[32m[0512 07:17:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0512 07:17:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:52 @base_main.py:47][0m 118590 total steps have happened
[32m[0512 07:17:52 @base_main.py:52][0m [avg_reward]: -47.845639875542176
[32m[0512 07:17:53 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:53 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:53 @base_trainer.py:216][0m Mean reward: -49.83489158624909
[32m[0512 07:17:53 @base_main.py:38][0m --------------- Iteration 119 ---------------
[32m[0512 07:17:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4672 mins
[32m[0512 07:17:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 07:17:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0512 07:17:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:53 @base_main.py:47][0m 119595 total steps have happened
[32m[0512 07:17:53 @base_main.py:52][0m [avg_reward]: -49.83489158624909
[32m[0512 07:17:53 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:53 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:53 @base_trainer.py:216][0m Mean reward: -49.84086305075376
[32m[0512 07:17:54 @base_main.py:38][0m --------------- Iteration 120 ---------------
[32m[0512 07:17:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4798 mins
[32m[0512 07:17:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 07:17:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0512 07:17:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:54 @base_main.py:47][0m 120600 total steps have happened
[32m[0512 07:17:54 @base_main.py:52][0m [avg_reward]: -49.84086305075376
[32m[0512 07:17:54 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:54 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:54 @base_trainer.py:216][0m Mean reward: -51.004661369901086
[32m[0512 07:17:55 @base_main.py:38][0m --------------- Iteration 121 ---------------
[32m[0512 07:17:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4924 mins
[32m[0512 07:17:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 07:17:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0512 07:17:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:55 @base_main.py:47][0m 121605 total steps have happened
[32m[0512 07:17:55 @base_main.py:52][0m [avg_reward]: -51.004661369901086
[32m[0512 07:17:55 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:55 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:55 @base_trainer.py:216][0m Mean reward: -51.755374805549515
[32m[0512 07:17:55 @base_main.py:38][0m --------------- Iteration 122 ---------------
[32m[0512 07:17:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5056 mins
[32m[0512 07:17:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 07:17:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 07:17:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:55 @base_main.py:47][0m 122610 total steps have happened
[32m[0512 07:17:55 @base_main.py:52][0m [avg_reward]: -51.755374805549515
[32m[0512 07:17:56 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:56 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:56 @base_trainer.py:216][0m Mean reward: -77.86629759582861
[32m[0512 07:17:56 @base_main.py:38][0m --------------- Iteration 123 ---------------
[32m[0512 07:17:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5176 mins
[32m[0512 07:17:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:17:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0512 07:17:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:56 @base_main.py:47][0m 123615 total steps have happened
[32m[0512 07:17:56 @base_main.py:52][0m [avg_reward]: -77.86629759582861
[32m[0512 07:17:56 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:56 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:56 @base_trainer.py:216][0m Mean reward: -58.761015745106064
[32m[0512 07:17:57 @base_main.py:38][0m --------------- Iteration 124 ---------------
[32m[0512 07:17:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5302 mins
[32m[0512 07:17:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 07:17:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 07:17:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:57 @base_main.py:47][0m 124620 total steps have happened
[32m[0512 07:17:57 @base_main.py:52][0m [avg_reward]: -58.761015745106064
[32m[0512 07:17:57 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:57 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:57 @base_trainer.py:216][0m Mean reward: -51.32768838728357
[32m[0512 07:17:58 @base_main.py:38][0m --------------- Iteration 125 ---------------
[32m[0512 07:17:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5415 mins
[32m[0512 07:17:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:17:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0512 07:17:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 07:17:58 @base_main.py:47][0m 125625 total steps have happened
[32m[0512 07:17:58 @base_main.py:52][0m [avg_reward]: -51.32768838728357
[32m[0512 07:17:58 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:58 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:58 @base_trainer.py:216][0m Mean reward: -49.29413490874301
[32m[0512 07:17:58 @base_main.py:38][0m --------------- Iteration 126 ---------------
[32m[0512 07:17:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5538 mins
[32m[0512 07:17:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 07:17:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0512 07:17:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:58 @base_main.py:47][0m 126630 total steps have happened
[32m[0512 07:17:58 @base_main.py:52][0m [avg_reward]: -49.29413490874301
[32m[0512 07:17:58 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:58 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:58 @base_trainer.py:216][0m Mean reward: -49.584381894962206
[32m[0512 07:17:59 @base_main.py:38][0m --------------- Iteration 127 ---------------
[32m[0512 07:17:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5653 mins
[32m[0512 07:17:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0512 07:17:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0512 07:17:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:17:59 @base_main.py:47][0m 127635 total steps have happened
[32m[0512 07:17:59 @base_main.py:52][0m [avg_reward]: -49.584381894962206
[32m[0512 07:17:59 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:17:59 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:17:59 @base_trainer.py:216][0m Mean reward: -49.36736104010269
[32m[0512 07:18:00 @base_main.py:38][0m --------------- Iteration 128 ---------------
[32m[0512 07:18:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5778 mins
[32m[0512 07:18:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 07:18:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0512 07:18:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:00 @base_main.py:47][0m 128640 total steps have happened
[32m[0512 07:18:00 @base_main.py:52][0m [avg_reward]: -49.36736104010269
[32m[0512 07:18:00 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:00 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:00 @base_trainer.py:216][0m Mean reward: -49.31701867839997
[32m[0512 07:18:00 @base_main.py:38][0m --------------- Iteration 129 ---------------
[32m[0512 07:18:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5900 mins
[32m[0512 07:18:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 07:18:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0512 07:18:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:00 @base_main.py:47][0m 129645 total steps have happened
[32m[0512 07:18:00 @base_main.py:52][0m [avg_reward]: -49.31701867839997
[32m[0512 07:18:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:01 @base_trainer.py:216][0m Mean reward: -50.491833338790826
[32m[0512 07:18:01 @base_main.py:38][0m --------------- Iteration 130 ---------------
[32m[0512 07:18:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6028 mins
[32m[0512 07:18:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0512 07:18:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0512 07:18:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:01 @base_main.py:47][0m 130650 total steps have happened
[32m[0512 07:18:01 @base_main.py:52][0m [avg_reward]: -50.491833338790826
[32m[0512 07:18:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:01 @base_trainer.py:216][0m Mean reward: -54.86456605719047
[32m[0512 07:18:02 @base_main.py:38][0m --------------- Iteration 131 ---------------
[32m[0512 07:18:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6147 mins
[32m[0512 07:18:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 07:18:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0512 07:18:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:02 @base_main.py:47][0m 131655 total steps have happened
[32m[0512 07:18:02 @base_main.py:52][0m [avg_reward]: -54.86456605719047
[32m[0512 07:18:02 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:02 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:02 @base_trainer.py:216][0m Mean reward: -59.0968560117009
[32m[0512 07:18:03 @base_main.py:38][0m --------------- Iteration 132 ---------------
[32m[0512 07:18:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6275 mins
[32m[0512 07:18:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 07:18:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0512 07:18:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:03 @base_main.py:47][0m 132660 total steps have happened
[32m[0512 07:18:03 @base_main.py:52][0m [avg_reward]: -59.0968560117009
[32m[0512 07:18:03 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:03 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:03 @base_trainer.py:216][0m Mean reward: -74.12972183904027
[32m[0512 07:18:03 @base_main.py:38][0m --------------- Iteration 133 ---------------
[32m[0512 07:18:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6395 mins
[32m[0512 07:18:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:18:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0512 07:18:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:03 @base_main.py:47][0m 133665 total steps have happened
[32m[0512 07:18:03 @base_main.py:52][0m [avg_reward]: -74.12972183904027
[32m[0512 07:18:04 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:04 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:04 @base_trainer.py:216][0m Mean reward: -72.37311511315308
[32m[0512 07:18:04 @base_main.py:38][0m --------------- Iteration 134 ---------------
[32m[0512 07:18:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6520 mins
[32m[0512 07:18:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:18:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0512 07:18:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:04 @base_main.py:47][0m 134670 total steps have happened
[32m[0512 07:18:04 @base_main.py:52][0m [avg_reward]: -72.37311511315308
[32m[0512 07:18:04 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:04 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:04 @base_trainer.py:216][0m Mean reward: -53.21027184633897
[32m[0512 07:18:05 @base_main.py:38][0m --------------- Iteration 135 ---------------
[32m[0512 07:18:05 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6651 mins
[32m[0512 07:18:05 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 07:18:05 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0512 07:18:05 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:05 @base_main.py:47][0m 135675 total steps have happened
[32m[0512 07:18:05 @base_main.py:52][0m [avg_reward]: -53.21027184633897
[32m[0512 07:18:05 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:05 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:05 @base_trainer.py:216][0m Mean reward: -52.90841132289362
[32m[0512 07:18:06 @base_main.py:38][0m --------------- Iteration 136 ---------------
[32m[0512 07:18:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6772 mins
[32m[0512 07:18:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 07:18:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0512 07:18:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 07:18:06 @base_main.py:47][0m 136680 total steps have happened
[32m[0512 07:18:06 @base_main.py:52][0m [avg_reward]: -52.90841132289362
[32m[0512 07:18:06 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:06 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:06 @base_trainer.py:216][0m Mean reward: -53.608648566026055
[32m[0512 07:18:06 @base_main.py:38][0m --------------- Iteration 137 ---------------
[32m[0512 07:18:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6899 mins
[32m[0512 07:18:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 07:18:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 07:18:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:06 @base_main.py:47][0m 137685 total steps have happened
[32m[0512 07:18:06 @base_main.py:52][0m [avg_reward]: -53.608648566026055
[32m[0512 07:18:07 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:07 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:07 @base_trainer.py:216][0m Mean reward: -51.36998925228353
[32m[0512 07:18:07 @base_main.py:38][0m --------------- Iteration 138 ---------------
[32m[0512 07:18:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7017 mins
[32m[0512 07:18:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:18:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0512 07:18:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:07 @base_main.py:47][0m 138690 total steps have happened
[32m[0512 07:18:07 @base_main.py:52][0m [avg_reward]: -51.36998925228353
[32m[0512 07:18:07 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:07 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:07 @base_trainer.py:216][0m Mean reward: -50.11267418387555
[32m[0512 07:18:08 @base_main.py:38][0m --------------- Iteration 139 ---------------
[32m[0512 07:18:08 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7133 mins
[32m[0512 07:18:08 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 07:18:08 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0512 07:18:08 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:08 @base_main.py:47][0m 139695 total steps have happened
[32m[0512 07:18:08 @base_main.py:52][0m [avg_reward]: -50.11267418387555
[32m[0512 07:18:08 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:08 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:08 @base_trainer.py:216][0m Mean reward: -51.47093422857142
[32m[0512 07:18:09 @base_main.py:38][0m --------------- Iteration 140 ---------------
[32m[0512 07:18:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7248 mins
[32m[0512 07:18:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 07:18:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0512 07:18:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:09 @base_main.py:47][0m 140700 total steps have happened
[32m[0512 07:18:09 @base_main.py:52][0m [avg_reward]: -51.47093422857142
[32m[0512 07:18:09 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:09 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:09 @base_trainer.py:216][0m Mean reward: -52.51447126064302
[32m[0512 07:18:09 @base_main.py:38][0m --------------- Iteration 141 ---------------
[32m[0512 07:18:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7375 mins
[32m[0512 07:18:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 07:18:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0512 07:18:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:09 @base_main.py:47][0m 141705 total steps have happened
[32m[0512 07:18:09 @base_main.py:52][0m [avg_reward]: -52.51447126064302
[32m[0512 07:18:09 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:09 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:09 @base_trainer.py:216][0m Mean reward: -53.64302332613117
[32m[0512 07:18:10 @base_main.py:38][0m --------------- Iteration 142 ---------------
[32m[0512 07:18:10 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7495 mins
[32m[0512 07:18:10 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 07:18:10 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0512 07:18:10 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:10 @base_main.py:47][0m 142710 total steps have happened
[32m[0512 07:18:10 @base_main.py:52][0m [avg_reward]: -53.64302332613117
[32m[0512 07:18:10 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:10 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:10 @base_trainer.py:216][0m Mean reward: -54.397294214047406
[32m[0512 07:18:11 @base_main.py:38][0m --------------- Iteration 143 ---------------
[32m[0512 07:18:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7620 mins
[32m[0512 07:18:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 07:18:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0512 07:18:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:11 @base_main.py:47][0m 143715 total steps have happened
[32m[0512 07:18:11 @base_main.py:52][0m [avg_reward]: -54.397294214047406
[32m[0512 07:18:11 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:11 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:11 @base_trainer.py:216][0m Mean reward: -82.89275879057956
[32m[0512 07:18:12 @base_main.py:38][0m --------------- Iteration 144 ---------------
[32m[0512 07:18:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7739 mins
[32m[0512 07:18:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:18:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0512 07:18:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 07:18:12 @base_main.py:47][0m 144720 total steps have happened
[32m[0512 07:18:12 @base_main.py:52][0m [avg_reward]: -82.89275879057956
[32m[0512 07:18:12 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:12 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:12 @base_trainer.py:216][0m Mean reward: -56.902793237087664
[32m[0512 07:18:12 @base_main.py:38][0m --------------- Iteration 145 ---------------
[32m[0512 07:18:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7866 mins
[32m[0512 07:18:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 07:18:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0512 07:18:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 07:18:12 @base_main.py:47][0m 145725 total steps have happened
[32m[0512 07:18:12 @base_main.py:52][0m [avg_reward]: -56.902793237087664
[32m[0512 07:18:12 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:12 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:12 @base_trainer.py:216][0m Mean reward: -65.16192095190087
[32m[0512 07:18:13 @base_main.py:38][0m --------------- Iteration 146 ---------------
[32m[0512 07:18:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7994 mins
[32m[0512 07:18:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0512 07:18:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0512 07:18:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 07:18:13 @base_main.py:47][0m 146730 total steps have happened
[32m[0512 07:18:13 @base_main.py:52][0m [avg_reward]: -65.16192095190087
[32m[0512 07:18:13 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:13 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:13 @base_trainer.py:216][0m Mean reward: -67.15817530469319
[32m[0512 07:18:14 @base_main.py:38][0m --------------- Iteration 147 ---------------
[32m[0512 07:18:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8116 mins
[32m[0512 07:18:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:18:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0512 07:18:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 07:18:14 @base_main.py:47][0m 147735 total steps have happened
[32m[0512 07:18:14 @base_main.py:52][0m [avg_reward]: -67.15817530469319
[32m[0512 07:18:14 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:14 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:14 @base_trainer.py:216][0m Mean reward: -58.482822792806964
[32m[0512 07:18:15 @base_main.py:38][0m --------------- Iteration 148 ---------------
[32m[0512 07:18:15 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8239 mins
[32m[0512 07:18:15 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 07:18:15 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0512 07:18:15 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:15 @base_main.py:47][0m 148740 total steps have happened
[32m[0512 07:18:15 @base_main.py:52][0m [avg_reward]: -58.482822792806964
[32m[0512 07:18:15 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:15 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:15 @base_trainer.py:216][0m Mean reward: -58.24898664935097
[32m[0512 07:18:15 @base_main.py:38][0m --------------- Iteration 149 ---------------
[32m[0512 07:18:15 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8371 mins
[32m[0512 07:18:15 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 07:18:15 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0512 07:18:15 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:15 @base_main.py:47][0m 149745 total steps have happened
[32m[0512 07:18:15 @base_main.py:52][0m [avg_reward]: -58.24898664935097
[32m[0512 07:18:15 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:15 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:15 @base_trainer.py:216][0m Mean reward: -57.907701606297664
[32m[0512 07:18:16 @base_main.py:38][0m --------------- Iteration 150 ---------------
[32m[0512 07:18:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8487 mins
[32m[0512 07:18:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:18:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0512 07:18:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0512 07:18:16 @base_main.py:47][0m 150750 total steps have happened
[32m[0512 07:18:16 @base_main.py:52][0m [avg_reward]: -57.907701606297664
[32m[0512 07:18:16 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:16 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:16 @base_trainer.py:216][0m Mean reward: -58.20339861346224
[32m[0512 07:18:17 @base_main.py:38][0m --------------- Iteration 151 ---------------
[32m[0512 07:18:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8611 mins
[32m[0512 07:18:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 07:18:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 07:18:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0512 07:18:17 @base_main.py:47][0m 151755 total steps have happened
[32m[0512 07:18:17 @base_main.py:52][0m [avg_reward]: -58.20339861346224
[32m[0512 07:18:17 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:17 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:17 @base_trainer.py:216][0m Mean reward: -58.32646637484822
[32m[0512 07:18:17 @base_main.py:38][0m --------------- Iteration 152 ---------------
[32m[0512 07:18:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8729 mins
[32m[0512 07:18:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 07:18:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0512 07:18:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:17 @base_main.py:47][0m 152760 total steps have happened
[32m[0512 07:18:17 @base_main.py:52][0m [avg_reward]: -58.32646637484822
[32m[0512 07:18:18 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:18 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:18 @base_trainer.py:216][0m Mean reward: -57.023010792151396
[32m[0512 07:18:18 @base_main.py:38][0m --------------- Iteration 153 ---------------
[32m[0512 07:18:18 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8854 mins
[32m[0512 07:18:18 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 07:18:18 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 07:18:18 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:18 @base_main.py:47][0m 153765 total steps have happened
[32m[0512 07:18:18 @base_main.py:52][0m [avg_reward]: -57.023010792151396
[32m[0512 07:18:18 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:18 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:18 @base_trainer.py:216][0m Mean reward: -62.26008874388274
[32m[0512 07:18:19 @base_main.py:38][0m --------------- Iteration 154 ---------------
[32m[0512 07:18:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8975 mins
[32m[0512 07:18:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 07:18:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0512 07:18:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:19 @base_main.py:47][0m 154770 total steps have happened
[32m[0512 07:18:19 @base_main.py:52][0m [avg_reward]: -62.26008874388274
[32m[0512 07:18:19 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:19 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:19 @base_trainer.py:216][0m Mean reward: -66.29338420919008
[32m[0512 07:18:20 @base_main.py:38][0m --------------- Iteration 155 ---------------
[32m[0512 07:18:20 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9097 mins
[32m[0512 07:18:20 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:18:20 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0512 07:18:20 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:20 @base_main.py:47][0m 155775 total steps have happened
[32m[0512 07:18:20 @base_main.py:52][0m [avg_reward]: -66.29338420919008
[32m[0512 07:18:20 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:20 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:20 @base_trainer.py:216][0m Mean reward: -71.42394329920953
[32m[0512 07:18:20 @base_main.py:38][0m --------------- Iteration 156 ---------------
[32m[0512 07:18:20 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9224 mins
[32m[0512 07:18:20 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:18:20 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0512 07:18:20 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:20 @base_main.py:47][0m 156780 total steps have happened
[32m[0512 07:18:20 @base_main.py:52][0m [avg_reward]: -71.42394329920953
[32m[0512 07:18:21 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:21 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:21 @base_trainer.py:216][0m Mean reward: -55.71563963201326
[32m[0512 07:18:21 @base_main.py:38][0m --------------- Iteration 157 ---------------
[32m[0512 07:18:21 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9347 mins
[32m[0512 07:18:21 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:18:21 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0512 07:18:21 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:21 @base_main.py:47][0m 157785 total steps have happened
[32m[0512 07:18:21 @base_main.py:52][0m [avg_reward]: -55.71563963201326
[32m[0512 07:18:21 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:21 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:21 @base_trainer.py:216][0m Mean reward: -57.83333292771347
[32m[0512 07:18:22 @base_main.py:38][0m --------------- Iteration 158 ---------------
[32m[0512 07:18:22 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9472 mins
[32m[0512 07:18:22 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 07:18:22 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0512 07:18:22 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:22 @base_main.py:47][0m 158790 total steps have happened
[32m[0512 07:18:22 @base_main.py:52][0m [avg_reward]: -57.83333292771347
[32m[0512 07:18:22 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:22 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:22 @base_trainer.py:216][0m Mean reward: -69.55396438769408
[32m[0512 07:18:23 @base_main.py:38][0m --------------- Iteration 159 ---------------
[32m[0512 07:18:23 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9584 mins
[32m[0512 07:18:23 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 07:18:23 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 07:18:23 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:23 @base_main.py:47][0m 159795 total steps have happened
[32m[0512 07:18:23 @base_main.py:52][0m [avg_reward]: -69.55396438769408
[32m[0512 07:18:23 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:23 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:23 @base_trainer.py:216][0m Mean reward: -59.690606193948405
[32m[0512 07:18:23 @base_main.py:38][0m --------------- Iteration 160 ---------------
[32m[0512 07:18:23 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9700 mins
[32m[0512 07:18:23 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 07:18:23 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0512 07:18:23 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:23 @base_main.py:47][0m 160800 total steps have happened
[32m[0512 07:18:23 @base_main.py:52][0m [avg_reward]: -59.690606193948405
[32m[0512 07:18:23 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:23 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:23 @base_trainer.py:216][0m Mean reward: -69.70775200409398
[32m[0512 07:18:24 @base_main.py:38][0m --------------- Iteration 161 ---------------
[32m[0512 07:18:24 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9827 mins
[32m[0512 07:18:24 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 07:18:24 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0512 07:18:24 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:24 @base_main.py:47][0m 161805 total steps have happened
[32m[0512 07:18:24 @base_main.py:52][0m [avg_reward]: -69.70775200409398
[32m[0512 07:18:24 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:24 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:24 @base_trainer.py:216][0m Mean reward: -60.641717048852726
[32m[0512 07:18:25 @base_main.py:38][0m --------------- Iteration 162 ---------------
[32m[0512 07:18:25 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9952 mins
[32m[0512 07:18:25 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 07:18:25 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0512 07:18:25 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:25 @base_main.py:47][0m 162810 total steps have happened
[32m[0512 07:18:25 @base_main.py:52][0m [avg_reward]: -60.641717048852726
[32m[0512 07:18:25 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:25 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:25 @base_trainer.py:216][0m Mean reward: -70.38153363936438
[32m[0512 07:18:26 @base_main.py:38][0m --------------- Iteration 163 ---------------
[32m[0512 07:18:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0080 mins
[32m[0512 07:18:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:18:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0512 07:18:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:26 @base_main.py:47][0m 163815 total steps have happened
[32m[0512 07:18:26 @base_main.py:52][0m [avg_reward]: -70.38153363936438
[32m[0512 07:18:26 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:26 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:26 @base_trainer.py:216][0m Mean reward: -66.85419387805734
[32m[0512 07:18:26 @base_main.py:38][0m --------------- Iteration 164 ---------------
[32m[0512 07:18:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0206 mins
[32m[0512 07:18:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 07:18:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0512 07:18:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:26 @base_main.py:47][0m 164820 total steps have happened
[32m[0512 07:18:26 @base_main.py:52][0m [avg_reward]: -66.85419387805734
[32m[0512 07:18:26 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:26 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:26 @base_trainer.py:216][0m Mean reward: -69.84471213658284
[32m[0512 07:18:27 @base_main.py:38][0m --------------- Iteration 165 ---------------
[32m[0512 07:18:27 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0334 mins
[32m[0512 07:18:27 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 07:18:27 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0512 07:18:27 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:27 @base_main.py:47][0m 165825 total steps have happened
[32m[0512 07:18:27 @base_main.py:52][0m [avg_reward]: -69.84471213658284
[32m[0512 07:18:27 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:27 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:27 @base_trainer.py:216][0m Mean reward: -67.99598804430192
[32m[0512 07:18:28 @base_main.py:38][0m --------------- Iteration 166 ---------------
[32m[0512 07:18:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0460 mins
[32m[0512 07:18:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 07:18:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 07:18:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:28 @base_main.py:47][0m 166830 total steps have happened
[32m[0512 07:18:28 @base_main.py:52][0m [avg_reward]: -67.99598804430192
[32m[0512 07:18:28 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:28 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:28 @base_trainer.py:216][0m Mean reward: -62.47527810211092
[32m[0512 07:18:29 @base_main.py:38][0m --------------- Iteration 167 ---------------
[32m[0512 07:18:29 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0580 mins
[32m[0512 07:18:29 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 07:18:29 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0512 07:18:29 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:29 @base_main.py:47][0m 167835 total steps have happened
[32m[0512 07:18:29 @base_main.py:52][0m [avg_reward]: -62.47527810211092
[32m[0512 07:18:29 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:29 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:29 @base_trainer.py:216][0m Mean reward: -68.88161728701722
[32m[0512 07:18:29 @base_main.py:38][0m --------------- Iteration 168 ---------------
[32m[0512 07:18:29 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0707 mins
[32m[0512 07:18:29 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 07:18:29 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0512 07:18:29 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:29 @base_main.py:47][0m 168840 total steps have happened
[32m[0512 07:18:29 @base_main.py:52][0m [avg_reward]: -68.88161728701722
[32m[0512 07:18:29 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:29 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:29 @base_trainer.py:216][0m Mean reward: -70.41014064683452
[32m[0512 07:18:30 @base_main.py:38][0m --------------- Iteration 169 ---------------
[32m[0512 07:18:30 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0832 mins
[32m[0512 07:18:30 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 07:18:30 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0512 07:18:30 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:30 @base_main.py:47][0m 169845 total steps have happened
[32m[0512 07:18:30 @base_main.py:52][0m [avg_reward]: -70.41014064683452
[32m[0512 07:18:30 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:30 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:30 @base_trainer.py:216][0m Mean reward: -64.26343576940863
[32m[0512 07:18:31 @base_main.py:38][0m --------------- Iteration 170 ---------------
[32m[0512 07:18:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0954 mins
[32m[0512 07:18:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:18:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0512 07:18:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:31 @base_main.py:47][0m 170850 total steps have happened
[32m[0512 07:18:31 @base_main.py:52][0m [avg_reward]: -64.26343576940863
[32m[0512 07:18:31 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:31 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:31 @base_trainer.py:216][0m Mean reward: -75.50052677395422
[32m[0512 07:18:32 @base_main.py:38][0m --------------- Iteration 171 ---------------
[32m[0512 07:18:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1079 mins
[32m[0512 07:18:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:18:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0512 07:18:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:32 @base_main.py:47][0m 171855 total steps have happened
[32m[0512 07:18:32 @base_main.py:52][0m [avg_reward]: -75.50052677395422
[32m[0512 07:18:32 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:32 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:32 @base_trainer.py:216][0m Mean reward: -66.02479320302784
[32m[0512 07:18:32 @base_main.py:38][0m --------------- Iteration 172 ---------------
[32m[0512 07:18:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1206 mins
[32m[0512 07:18:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:18:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0512 07:18:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:32 @base_main.py:47][0m 172860 total steps have happened
[32m[0512 07:18:32 @base_main.py:52][0m [avg_reward]: -66.02479320302784
[32m[0512 07:18:32 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:32 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:32 @base_trainer.py:216][0m Mean reward: -61.9672494595673
[32m[0512 07:18:33 @base_main.py:38][0m --------------- Iteration 173 ---------------
[32m[0512 07:18:33 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1331 mins
[32m[0512 07:18:33 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 07:18:33 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0512 07:18:33 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:33 @base_main.py:47][0m 173865 total steps have happened
[32m[0512 07:18:33 @base_main.py:52][0m [avg_reward]: -61.9672494595673
[32m[0512 07:18:33 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:33 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:33 @base_trainer.py:216][0m Mean reward: -66.2961263553764
[32m[0512 07:18:34 @base_main.py:38][0m --------------- Iteration 174 ---------------
[32m[0512 07:18:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1453 mins
[32m[0512 07:18:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:18:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0512 07:18:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 07:18:34 @base_main.py:47][0m 174870 total steps have happened
[32m[0512 07:18:34 @base_main.py:52][0m [avg_reward]: -66.2961263553764
[32m[0512 07:18:34 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:34 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:34 @base_trainer.py:216][0m Mean reward: -60.83956728540413
[32m[0512 07:18:35 @base_main.py:38][0m --------------- Iteration 175 ---------------
[32m[0512 07:18:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1571 mins
[32m[0512 07:18:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 07:18:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0512 07:18:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:35 @base_main.py:47][0m 175875 total steps have happened
[32m[0512 07:18:35 @base_main.py:52][0m [avg_reward]: -60.83956728540413
[32m[0512 07:18:35 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:35 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:35 @base_trainer.py:216][0m Mean reward: -59.30618769142992
[32m[0512 07:18:35 @base_main.py:38][0m --------------- Iteration 176 ---------------
[32m[0512 07:18:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1704 mins
[32m[0512 07:18:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:18:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0512 07:18:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:35 @base_main.py:47][0m 176880 total steps have happened
[32m[0512 07:18:35 @base_main.py:52][0m [avg_reward]: -59.30618769142992
[32m[0512 07:18:35 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:35 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:35 @base_trainer.py:216][0m Mean reward: -58.4371212951851
[32m[0512 07:18:36 @base_main.py:38][0m --------------- Iteration 177 ---------------
[32m[0512 07:18:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1825 mins
[32m[0512 07:18:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:18:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0512 07:18:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:36 @base_main.py:47][0m 177885 total steps have happened
[32m[0512 07:18:36 @base_main.py:52][0m [avg_reward]: -58.4371212951851
[32m[0512 07:18:36 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:36 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:36 @base_trainer.py:216][0m Mean reward: -57.34694886835128
[32m[0512 07:18:37 @base_main.py:38][0m --------------- Iteration 178 ---------------
[32m[0512 07:18:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1950 mins
[32m[0512 07:18:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 07:18:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0512 07:18:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:37 @base_main.py:47][0m 178890 total steps have happened
[32m[0512 07:18:37 @base_main.py:52][0m [avg_reward]: -57.34694886835128
[32m[0512 07:18:37 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:37 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:37 @base_trainer.py:216][0m Mean reward: -85.6468639581886
[32m[0512 07:18:37 @base_main.py:38][0m --------------- Iteration 179 ---------------
[32m[0512 07:18:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2071 mins
[32m[0512 07:18:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:18:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0512 07:18:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:37 @base_main.py:47][0m 179895 total steps have happened
[32m[0512 07:18:37 @base_main.py:52][0m [avg_reward]: -85.6468639581886
[32m[0512 07:18:38 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:38 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:38 @base_trainer.py:216][0m Mean reward: -86.32654599216315
[32m[0512 07:18:38 @base_main.py:38][0m --------------- Iteration 180 ---------------
[32m[0512 07:18:38 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2193 mins
[32m[0512 07:18:38 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:18:38 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0512 07:18:38 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:38 @base_main.py:47][0m 180900 total steps have happened
[32m[0512 07:18:38 @base_main.py:52][0m [avg_reward]: -86.32654599216315
[32m[0512 07:18:38 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:38 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:38 @base_trainer.py:216][0m Mean reward: -68.90066460309993
[32m[0512 07:18:39 @base_main.py:38][0m --------------- Iteration 181 ---------------
[32m[0512 07:18:39 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2321 mins
[32m[0512 07:18:39 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 07:18:39 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0512 07:18:39 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:39 @base_main.py:47][0m 181905 total steps have happened
[32m[0512 07:18:39 @base_main.py:52][0m [avg_reward]: -68.90066460309993
[32m[0512 07:18:39 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:39 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:39 @base_trainer.py:216][0m Mean reward: -56.70734563187081
[32m[0512 07:18:40 @base_main.py:38][0m --------------- Iteration 182 ---------------
[32m[0512 07:18:40 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2447 mins
[32m[0512 07:18:40 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:18:40 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0512 07:18:40 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:40 @base_main.py:47][0m 182910 total steps have happened
[32m[0512 07:18:40 @base_main.py:52][0m [avg_reward]: -56.70734563187081
[32m[0512 07:18:40 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:40 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:40 @base_trainer.py:216][0m Mean reward: -56.57521309144217
[32m[0512 07:18:40 @base_main.py:38][0m --------------- Iteration 183 ---------------
[32m[0512 07:18:40 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2564 mins
[32m[0512 07:18:40 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 07:18:40 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0512 07:18:40 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:40 @base_main.py:47][0m 183915 total steps have happened
[32m[0512 07:18:40 @base_main.py:52][0m [avg_reward]: -56.57521309144217
[32m[0512 07:18:41 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:41 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:41 @base_trainer.py:216][0m Mean reward: -57.50546746752849
[32m[0512 07:18:41 @base_main.py:38][0m --------------- Iteration 184 ---------------
[32m[0512 07:18:41 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2691 mins
[32m[0512 07:18:41 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 07:18:41 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0512 07:18:41 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:41 @base_main.py:47][0m 184920 total steps have happened
[32m[0512 07:18:41 @base_main.py:52][0m [avg_reward]: -57.50546746752849
[32m[0512 07:18:41 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:41 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:41 @base_trainer.py:216][0m Mean reward: -58.117958557232974
[32m[0512 07:18:42 @base_main.py:38][0m --------------- Iteration 185 ---------------
[32m[0512 07:18:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2812 mins
[32m[0512 07:18:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 07:18:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0512 07:18:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:42 @base_main.py:47][0m 185925 total steps have happened
[32m[0512 07:18:42 @base_main.py:52][0m [avg_reward]: -58.117958557232974
[32m[0512 07:18:42 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:42 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:42 @base_trainer.py:216][0m Mean reward: -100.94054085513676
[32m[0512 07:18:43 @base_main.py:38][0m --------------- Iteration 186 ---------------
[32m[0512 07:18:43 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2940 mins
[32m[0512 07:18:43 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:18:43 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0512 07:18:43 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:43 @base_main.py:47][0m 186930 total steps have happened
[32m[0512 07:18:43 @base_main.py:52][0m [avg_reward]: -100.94054085513676
[32m[0512 07:18:43 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:43 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:43 @base_trainer.py:216][0m Mean reward: -75.94376755342674
[32m[0512 07:18:43 @base_main.py:38][0m --------------- Iteration 187 ---------------
[32m[0512 07:18:43 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3062 mins
[32m[0512 07:18:43 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:18:43 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0512 07:18:43 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:43 @base_main.py:47][0m 187935 total steps have happened
[32m[0512 07:18:43 @base_main.py:52][0m [avg_reward]: -75.94376755342674
[32m[0512 07:18:44 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:44 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:44 @base_trainer.py:216][0m Mean reward: -69.17543172397251
[32m[0512 07:18:44 @base_main.py:38][0m --------------- Iteration 188 ---------------
[32m[0512 07:18:44 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3187 mins
[32m[0512 07:18:44 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 07:18:44 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0512 07:18:44 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:44 @base_main.py:47][0m 188940 total steps have happened
[32m[0512 07:18:44 @base_main.py:52][0m [avg_reward]: -69.17543172397251
[32m[0512 07:18:44 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:44 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:44 @base_trainer.py:216][0m Mean reward: -59.05308766193804
[32m[0512 07:18:45 @base_main.py:38][0m --------------- Iteration 189 ---------------
[32m[0512 07:18:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3313 mins
[32m[0512 07:18:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 07:18:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0512 07:18:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:45 @base_main.py:47][0m 189945 total steps have happened
[32m[0512 07:18:45 @base_main.py:52][0m [avg_reward]: -59.05308766193804
[32m[0512 07:18:45 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:45 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:45 @base_trainer.py:216][0m Mean reward: -76.09413855479804
[32m[0512 07:18:46 @base_main.py:38][0m --------------- Iteration 190 ---------------
[32m[0512 07:18:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3441 mins
[32m[0512 07:18:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 07:18:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0512 07:18:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:46 @base_main.py:47][0m 190950 total steps have happened
[32m[0512 07:18:46 @base_main.py:52][0m [avg_reward]: -76.09413855479804
[32m[0512 07:18:46 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:46 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:46 @base_trainer.py:216][0m Mean reward: -55.93011345474182
[32m[0512 07:18:46 @base_main.py:38][0m --------------- Iteration 191 ---------------
[32m[0512 07:18:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3562 mins
[32m[0512 07:18:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:18:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 07:18:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:46 @base_main.py:47][0m 191955 total steps have happened
[32m[0512 07:18:46 @base_main.py:52][0m [avg_reward]: -55.93011345474182
[32m[0512 07:18:47 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:47 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:47 @base_trainer.py:216][0m Mean reward: -77.58937170985077
[32m[0512 07:18:47 @base_main.py:38][0m --------------- Iteration 192 ---------------
[32m[0512 07:18:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3681 mins
[32m[0512 07:18:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 07:18:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0512 07:18:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:47 @base_main.py:47][0m 192960 total steps have happened
[32m[0512 07:18:47 @base_main.py:52][0m [avg_reward]: -77.58937170985077
[32m[0512 07:18:47 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:47 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:47 @base_trainer.py:216][0m Mean reward: -67.62442772111885
[32m[0512 07:18:48 @base_main.py:38][0m --------------- Iteration 193 ---------------
[32m[0512 07:18:48 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3804 mins
[32m[0512 07:18:48 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:18:48 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 07:18:48 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0512 07:18:48 @base_main.py:47][0m 193965 total steps have happened
[32m[0512 07:18:48 @base_main.py:52][0m [avg_reward]: -67.62442772111885
[32m[0512 07:18:48 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:48 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:48 @base_trainer.py:216][0m Mean reward: -62.90385726670453
[32m[0512 07:18:49 @base_main.py:38][0m --------------- Iteration 194 ---------------
[32m[0512 07:18:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3924 mins
[32m[0512 07:18:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 07:18:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0512 07:18:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 07:18:49 @base_main.py:47][0m 194970 total steps have happened
[32m[0512 07:18:49 @base_main.py:52][0m [avg_reward]: -62.90385726670453
[32m[0512 07:18:49 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:49 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:49 @base_trainer.py:216][0m Mean reward: -74.39651429932252
[32m[0512 07:18:49 @base_main.py:38][0m --------------- Iteration 195 ---------------
[32m[0512 07:18:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4055 mins
[32m[0512 07:18:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 07:18:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0512 07:18:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:49 @base_main.py:47][0m 195975 total steps have happened
[32m[0512 07:18:49 @base_main.py:52][0m [avg_reward]: -74.39651429932252
[32m[0512 07:18:50 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:50 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:50 @base_trainer.py:216][0m Mean reward: -66.7918774351759
[32m[0512 07:18:50 @base_main.py:38][0m --------------- Iteration 196 ---------------
[32m[0512 07:18:50 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4181 mins
[32m[0512 07:18:50 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 07:18:50 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 07:18:50 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:50 @base_main.py:47][0m 196980 total steps have happened
[32m[0512 07:18:50 @base_main.py:52][0m [avg_reward]: -66.7918774351759
[32m[0512 07:18:50 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:50 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:50 @base_trainer.py:216][0m Mean reward: -88.02409048234368
[32m[0512 07:18:51 @base_main.py:38][0m --------------- Iteration 197 ---------------
[32m[0512 07:18:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4299 mins
[32m[0512 07:18:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:18:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0512 07:18:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 07:18:51 @base_main.py:47][0m 197985 total steps have happened
[32m[0512 07:18:51 @base_main.py:52][0m [avg_reward]: -88.02409048234368
[32m[0512 07:18:51 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:51 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:51 @base_trainer.py:216][0m Mean reward: -73.51348617512843
[32m[0512 07:18:52 @base_main.py:38][0m --------------- Iteration 198 ---------------
[32m[0512 07:18:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4423 mins
[32m[0512 07:18:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 07:18:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0512 07:18:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:52 @base_main.py:47][0m 198990 total steps have happened
[32m[0512 07:18:52 @base_main.py:52][0m [avg_reward]: -73.51348617512843
[32m[0512 07:18:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:52 @base_trainer.py:216][0m Mean reward: -70.0040782550323
[32m[0512 07:18:52 @base_main.py:38][0m --------------- Iteration 199 ---------------
[32m[0512 07:18:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4544 mins
[32m[0512 07:18:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 07:18:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0512 07:18:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:52 @base_main.py:47][0m 199995 total steps have happened
[32m[0512 07:18:52 @base_main.py:52][0m [avg_reward]: -70.0040782550323
[32m[0512 07:18:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 07:18:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 07:18:52 @base_trainer.py:216][0m Mean reward: -70.64128658247174
[32m[0512 07:18:53 @base_main.py:38][0m --------------- Iteration 200 ---------------
[32m[0512 07:18:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4665 mins
[32m[0512 07:18:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 07:18:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0512 07:18:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 07:18:53 @base_main.py:47][0m 201000 total steps have happened
[32m[0512 07:18:53 @base_main.py:52][0m [avg_reward]: -70.64128658247174
[32m[0512 07:18:53 @base_worker.py:111][0m kill message for worker 7
[32m[0512 07:18:53 @base_worker.py:111][0m kill message for worker 18
[32m[0512 07:18:53 @base_worker.py:111][0m kill message for worker 19
[32m[0512 07:18:53 @base_worker.py:111][0m kill message for worker 6
[32m[0512 07:18:53 @base_worker.py:111][0m kill message for worker 8
[32m[0512 07:18:53 @base_worker.py:111][0m kill message for worker 10
[32m[0512 07:18:53 @base_worker.py:111][0m kill message for worker 1
[32m[0512 07:18:53 @base_worker.py:111][0m kill message for worker 0
[32m[0512 07:18:53 @base_worker.py:111][0m kill message for worker 4
[32m[0512 07:18:53 @base_worker.py:111][0m kill message for worker 16
[32m[0512 07:18:53 @base_worker.py:111][0m kill message for worker 2
[32m[0512 07:18:53 @base_worker.py:111][0m kill message for worker 13
[32m[0512 07:18:53 @base_worker.py:111][0m kill message for worker 9
[32m[0512 07:18:53 @base_worker.py:111][0m kill message for worker 3
[32m[0512 07:18:53 @base_worker.py:111][0m kill message for worker 12
[32m[0512 07:18:53 @base_worker.py:111][0m kill message for worker 15
[32m[0512 07:18:53 @base_worker.py:111][0m kill message for worker 11
[32m[0512 07:18:53 @base_worker.py:111][0m kill message for worker 5
[32m[0512 07:18:53 @base_worker.py:111][0m kill message for worker 17
[32m[0512 07:18:53 @base_worker.py:111][0m kill message for worker 14
