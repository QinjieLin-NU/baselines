[32m[0511 16:43:28 @logger.py:103][0m Log file set to /root/mbbl/log/mbmfrl-rsgym_swingupmbmf_gym_swingup_ppo_seed_1234.log/mbmfrl-rsgym_swingupmbmf_gym_swingup_ppo_seed_1234.log
[32m[0511 16:43:28 @mbmf_main.py:23][0m Training starts at /root/mbbl
[32m[0511 16:43:28 @base_worker.py:45][0m Worker 0 online
[32m[0511 16:43:29 @base_worker.py:45][0m Worker 1 online
[32m[0511 16:43:29 @base_worker.py:45][0m Worker 2 online
[32m[0511 16:43:29 @base_worker.py:45][0m Worker 3 online
[32m[0511 16:43:29 @base_worker.py:45][0m Worker 4 online
[32m[0511 16:43:29 @base_worker.py:45][0m Worker 5 online
[32m[0511 16:43:29 @base_worker.py:45][0m Worker 6 online
[32m[0511 16:43:29 @base_worker.py:45][0m Worker 7 online
[32m[0511 16:43:29 @base_worker.py:45][0m Worker 8 online
[32m[0511 16:43:29 @base_worker.py:45][0m Worker 9 online
[32m[0511 16:43:29 @base_worker.py:45][0m Worker 10 online
[32m[0511 16:43:29 @base_worker.py:45][0m Worker 11 online
[32m[0511 16:43:29 @base_worker.py:45][0m Worker 12 online
[32m[0511 16:43:29 @base_worker.py:45][0m Worker 13 online
[32m[0511 16:43:29 @base_worker.py:45][0m Worker 14 online
[32m[0511 16:43:29 @base_worker.py:45][0m Worker 15 online
[32m[0511 16:43:29 @base_worker.py:45][0m Worker 16 online
[32m[0511 16:43:29 @base_worker.py:45][0m Worker 17 online
[32m[0511 16:43:29 @base_worker.py:45][0m Worker 18 online
[32m[0511 16:43:29 @base_worker.py:45][0m Worker 19 online
[32m[0511 16:43:30 @base_trainer.py:152][0m Trainer maintains [1] policy network
[32m[0511 16:43:30 @base_trainer.py:152][0m Trainer maintains [1] dynamics network
[32m[0511 16:43:30 @base_trainer.py:152][0m Trainer maintains [1] reward network
[32m[0511 16:43:31 @mbmf_main.py:46][0m Generating 1000 random timesteps
[32m[0511 16:43:31 @mbmf_sampler.py:39][0m done with episode
[32m[0511 16:43:31 @mbmf_sampler.py:39][0m done with episode
[32m[0511 16:43:31 @mbmf_sampler.py:50][0m 1002 timesteps from 2 episodes collected
[32m[0511 16:43:31 @base_trainer.py:216][0m Mean reward: -276.6986604028037
[32m[0511 16:43:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5456231236457825, Train Loss: 0.52812659740448
[32m[0511 16:43:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5456376671791077, Train Loss: 0.5281248092651367
[32m[0511 16:43:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5456523299217224, Train Loss: 0.528123140335083
[32m[0511 16:43:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5456675291061401, Train Loss: 0.528121829032898
[32m[0511 16:43:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5456832051277161, Train Loss: 0.5281205177307129
[32m[0511 16:43:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5456992387771606, Train Loss: 0.5281195044517517
[32m[0511 16:43:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5457156300544739, Train Loss: 0.5281185507774353
[32m[0511 16:43:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5457322001457214, Train Loss: 0.5281176567077637
[32m[0511 16:43:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5457486510276794, Train Loss: 0.5281170010566711
[32m[0511 16:43:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.545764684677124, Train Loss: 0.5281164646148682
[32m[0511 16:43:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5457803010940552, Train Loss: 0.52811598777771
[32m[0511 16:43:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5457950234413147, Train Loss: 0.5281156301498413
[32m[0511 16:43:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5458088517189026, Train Loss: 0.5281153321266174
[32m[0511 16:43:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5458216071128845, Train Loss: 0.5281151533126831
[32m[0511 16:43:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5458330512046814, Train Loss: 0.5281150937080383
[32m[0511 16:43:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5458430647850037, Train Loss: 0.5281150341033936
[32m[0511 16:43:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5458515882492065, Train Loss: 0.5281150937080383
[32m[0511 16:43:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.54585862159729, Train Loss: 0.5281151533126831
[32m[0511 16:43:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5458643436431885, Train Loss: 0.5281151533126831
[32m[0511 16:43:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5458685755729675, Train Loss: 0.5281152725219727
[32m[0511 16:43:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5458716154098511, Train Loss: 0.5281153321266174
[32m[0511 16:43:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5458734035491943, Train Loss: 0.5281153321266174
[32m[0511 16:43:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5458742380142212, Train Loss: 0.5281153917312622
[32m[0511 16:43:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5458741188049316, Train Loss: 0.5281153917312622
[32m[0511 16:43:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5458731651306152, Train Loss: 0.528115451335907
[32m[0511 16:43:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5458716154098511, Train Loss: 0.5281153321266174
[32m[0511 16:43:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5458694100379944, Train Loss: 0.5281153321266174
[32m[0511 16:43:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5458667278289795, Train Loss: 0.5281153321266174
[32m[0511 16:43:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.545863687992096, Train Loss: 0.5281153321266174
[32m[0511 16:43:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.545860230922699, Train Loss: 0.5281153321266174
[32m[0511 16:43:32 @base_main.py:38][0m --------------- Iteration 1 ---------------
[32m[0511 16:43:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0000 mins
[32m[0511 16:43:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0016 mins
[32m[0511 16:43:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0117 mins
[32m[0511 16:43:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0042 mins
[32m[0511 16:43:32 @base_main.py:47][0m 1002 total steps have happened
[32m[0511 16:43:32 @base_main.py:52][0m [avg_reward]: -276.6986604028037
[32m[0511 16:43:32 @base_main.py:52][0m [update_op]: None
[32m[0511 16:43:32 @base_main.py:52][0m [train_loss]: 0.5281153321266174
[32m[0511 16:43:32 @base_main.py:52][0m [val_loss]: 0.545860230922699
[32m[0511 16:43:32 @base_main.py:52][0m [avg_train_loss]: 0.5281153321266174
[32m[0511 16:50:07 @mbmf_sampler.py:39][0m done with episode
[32m[0511 16:56:45 @mbmf_sampler.py:39][0m done with episode
[32m[0511 16:56:45 @mbmf_sampler.py:50][0m 1002 timesteps from 2 episodes collected
[32m[0511 16:56:45 @base_trainer.py:216][0m Mean reward: -454.28193164048776
[32m[0511 16:56:45 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.475983589887619, Train Loss: 0.5396869778633118
[32m[0511 16:56:45 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.47600337862968445, Train Loss: 0.5396757125854492
[32m[0511 16:56:45 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.47602465748786926, Train Loss: 0.5396634936332703
[32m[0511 16:56:45 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.47604674100875854, Train Loss: 0.5396512150764465
[32m[0511 16:56:45 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4760691821575165, Train Loss: 0.5396396517753601
[32m[0511 16:56:45 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4760914742946625, Train Loss: 0.5396290421485901
[32m[0511 16:56:45 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4761134386062622, Train Loss: 0.5396193861961365
[32m[0511 16:56:45 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4761347770690918, Train Loss: 0.5396108627319336
[32m[0511 16:56:45 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.47615545988082886, Train Loss: 0.5396032929420471
[32m[0511 16:56:45 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.47617530822753906, Train Loss: 0.5395967364311218
[32m[0511 16:56:45 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.47619426250457764, Train Loss: 0.5395910143852234
[32m[0511 16:56:45 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4762123227119446, Train Loss: 0.5395858883857727
[32m[0511 16:56:46 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.47622963786125183, Train Loss: 0.5395815968513489
[32m[0511 16:56:46 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.47624582052230835, Train Loss: 0.5395777821540833
[32m[0511 16:56:46 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.47626128792762756, Train Loss: 0.539574384689331
[32m[0511 16:56:46 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4762759208679199, Train Loss: 0.5395714640617371
[32m[0511 16:56:46 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4762896001338959, Train Loss: 0.5395689606666565
[32m[0511 16:56:46 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.47630250453948975, Train Loss: 0.539566695690155
[32m[0511 16:56:46 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4763147532939911, Train Loss: 0.5395647287368774
[32m[0511 16:56:46 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.47632625699043274, Train Loss: 0.539563000202179
[32m[0511 16:56:46 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.47633716464042664, Train Loss: 0.5395614504814148
[32m[0511 16:56:46 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4763474464416504, Train Loss: 0.539560079574585
[32m[0511 16:56:46 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.476357102394104, Train Loss: 0.5395588874816895
[32m[0511 16:56:46 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.476366251707077, Train Loss: 0.5395577549934387
[32m[0511 16:56:46 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.47637486457824707, Train Loss: 0.5395568609237671
[32m[0511 16:56:46 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4763830006122589, Train Loss: 0.5395560264587402
[32m[0511 16:56:46 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4763907194137573, Train Loss: 0.5395552515983582
[32m[0511 16:56:46 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4763979911804199, Train Loss: 0.5395545363426208
[32m[0511 16:56:46 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.47640490531921387, Train Loss: 0.5395538806915283
[32m[0511 16:56:46 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4764114320278168, Train Loss: 0.5395533442497253
[32m[0511 16:56:46 @base_main.py:38][0m --------------- Iteration 2 ---------------
[32m[0511 16:56:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0176 mins
[32m[0511 16:56:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 13.2206 mins
[32m[0511 16:56:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0181 mins
[32m[0511 16:56:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0056 mins
[32m[0511 16:56:46 @base_main.py:47][0m 2004 total steps have happened
[32m[0511 16:56:46 @base_main.py:52][0m [avg_reward]: -454.28193164048776
[32m[0511 16:56:46 @base_main.py:52][0m [update_op]: None
[32m[0511 16:56:46 @base_main.py:52][0m [train_loss]: 0.5922752618789673
[32m[0511 16:56:46 @base_main.py:52][0m [val_loss]: 0.4764114320278168
[32m[0511 16:56:46 @base_main.py:52][0m [avg_train_loss]: 0.5395533442497253
[32m[0511 17:03:21 @mbmf_sampler.py:39][0m done with episode
[32m[0511 17:09:51 @mbmf_sampler.py:39][0m done with episode
[32m[0511 17:09:51 @mbmf_sampler.py:50][0m 1002 timesteps from 2 episodes collected
[32m[0511 17:09:51 @base_trainer.py:216][0m Mean reward: -455.6964045087418
[32m[0511 17:09:51 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.46112993359565735, Train Loss: 0.5332731008529663
[32m[0511 17:09:51 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.46105343103408813, Train Loss: 0.5332540273666382
[32m[0511 17:09:51 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.46099627017974854, Train Loss: 0.5332409143447876
[32m[0511 17:09:51 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.460950642824173, Train Loss: 0.5332297086715698
[32m[0511 17:09:51 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4609124958515167, Train Loss: 0.5332198143005371
[32m[0511 17:09:51 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4608798921108246, Train Loss: 0.5332112312316895
[32m[0511 17:09:51 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4608513116836548, Train Loss: 0.5332038402557373
[32m[0511 17:09:51 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4608258008956909, Train Loss: 0.5331974625587463
[32m[0511 17:09:51 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4608025848865509, Train Loss: 0.5331920385360718
[32m[0511 17:09:51 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.460781067609787, Train Loss: 0.5331874489784241
[32m[0511 17:09:51 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4607609212398529, Train Loss: 0.5331833362579346
[32m[0511 17:09:51 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.46074187755584717, Train Loss: 0.5331798791885376
[32m[0511 17:09:52 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4607236385345459, Train Loss: 0.5331767201423645
[32m[0511 17:09:52 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4607061743736267, Train Loss: 0.5331740975379944
[32m[0511 17:09:52 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.46068906784057617, Train Loss: 0.5331717133522034
[32m[0511 17:09:52 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.46067240834236145, Train Loss: 0.5331695079803467
[32m[0511 17:09:52 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.460656076669693, Train Loss: 0.5331675410270691
[32m[0511 17:09:52 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4606401026248932, Train Loss: 0.5331658720970154
[32m[0511 17:09:52 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4606243669986725, Train Loss: 0.5331642031669617
[32m[0511 17:09:52 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.46060875058174133, Train Loss: 0.5331628322601318
[32m[0511 17:09:52 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4605933129787445, Train Loss: 0.5331615209579468
[32m[0511 17:09:52 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.46057814359664917, Train Loss: 0.5331602096557617
[32m[0511 17:09:52 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4605630934238434, Train Loss: 0.533159077167511
[32m[0511 17:09:52 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.46054813265800476, Train Loss: 0.5331579446792603
[32m[0511 17:09:52 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.46053338050842285, Train Loss: 0.5331569910049438
[32m[0511 17:09:52 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.46051880717277527, Train Loss: 0.5331560373306274
[32m[0511 17:09:52 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.46050429344177246, Train Loss: 0.533155083656311
[32m[0511 17:09:52 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.46048998832702637, Train Loss: 0.5331541895866394
[32m[0511 17:09:52 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4604758620262146, Train Loss: 0.5331534147262573
[32m[0511 17:09:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.46046164631843567, Train Loss: 0.5331526398658752
[32m[0511 17:09:53 @base_main.py:38][0m --------------- Iteration 3 ---------------
[32m[0511 17:09:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 13.2620 mins
[32m[0511 17:09:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 13.0719 mins
[32m[0511 17:09:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0297 mins
[32m[0511 17:09:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0052 mins
[32m[0511 17:09:53 @base_main.py:47][0m 3006 total steps have happened
[32m[0511 17:09:53 @base_main.py:52][0m [avg_reward]: -455.6964045087418
[32m[0511 17:09:53 @base_main.py:52][0m [update_op]: None
[32m[0511 17:09:53 @base_main.py:52][0m [train_loss]: 0.5160510540008545
[32m[0511 17:09:53 @base_main.py:52][0m [val_loss]: 0.46046164631843567
[32m[0511 17:09:53 @base_main.py:52][0m [avg_train_loss]: 0.5331526398658752
[32m[0511 17:16:23 @mbmf_sampler.py:39][0m done with episode
[32m[0511 17:22:53 @mbmf_sampler.py:39][0m done with episode
[32m[0511 17:22:53 @mbmf_sampler.py:50][0m 1002 timesteps from 2 episodes collected
[32m[0511 17:22:53 @base_trainer.py:216][0m Mean reward: -452.23525114900605
[32m[0511 17:22:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4060165286064148, Train Loss: 0.5369123816490173
[32m[0511 17:22:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4060119092464447, Train Loss: 0.5369082093238831
[32m[0511 17:22:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4060109853744507, Train Loss: 0.5369043946266174
[32m[0511 17:22:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.40601199865341187, Train Loss: 0.5369008779525757
[32m[0511 17:22:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.40601372718811035, Train Loss: 0.5368977189064026
[32m[0511 17:22:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4060157537460327, Train Loss: 0.5368949770927429
[32m[0511 17:22:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4060177505016327, Train Loss: 0.5368924736976624
[32m[0511 17:22:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4060196876525879, Train Loss: 0.5368902087211609
[32m[0511 17:22:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.40602144598960876, Train Loss: 0.5368882417678833
[32m[0511 17:22:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.40602296590805054, Train Loss: 0.5368863940238953
[32m[0511 17:22:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.40602439641952515, Train Loss: 0.5368846654891968
[32m[0511 17:22:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.40602558851242065, Train Loss: 0.5368830561637878
[32m[0511 17:22:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4060267508029938, Train Loss: 0.5368815660476685
[32m[0511 17:22:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.40602758526802063, Train Loss: 0.5368801951408386
[32m[0511 17:22:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.40602847933769226, Train Loss: 0.5368789434432983
[32m[0511 17:22:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4060291647911072, Train Loss: 0.5368776917457581
[32m[0511 17:22:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.40602967143058777, Train Loss: 0.5368765592575073
[32m[0511 17:22:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.40603017807006836, Train Loss: 0.5368754863739014
[32m[0511 17:22:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4060305953025818, Train Loss: 0.5368744730949402
[32m[0511 17:22:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.40603092312812805, Train Loss: 0.536873459815979
[32m[0511 17:22:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.40603116154670715, Train Loss: 0.5368725657463074
[32m[0511 17:22:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4060313403606415, Train Loss: 0.5368717312812805
[32m[0511 17:22:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.40603142976760864, Train Loss: 0.5368708372116089
[32m[0511 17:22:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.40603142976760864, Train Loss: 0.5368701219558716
[32m[0511 17:22:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.40603137016296387, Train Loss: 0.5368694067001343
[32m[0511 17:22:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4060313403606415, Train Loss: 0.5368686318397522
[32m[0511 17:22:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.40603119134902954, Train Loss: 0.5368680357933044
[32m[0511 17:22:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.40603107213974, Train Loss: 0.5368673205375671
[32m[0511 17:22:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4060307741165161, Train Loss: 0.5368667840957642
[32m[0511 17:22:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4060305655002594, Train Loss: 0.5368662476539612
[32m[0511 17:22:55 @base_main.py:38][0m --------------- Iteration 4 ---------------
[32m[0511 17:22:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 26.3689 mins
[32m[0511 17:22:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 12.9986 mins
[32m[0511 17:22:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0382 mins
[32m[0511 17:22:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0053 mins
[32m[0511 17:22:55 @base_main.py:47][0m 4008 total steps have happened
[32m[0511 17:22:55 @base_main.py:52][0m [avg_reward]: -452.23525114900605
[32m[0511 17:22:55 @base_main.py:52][0m [update_op]: None
[32m[0511 17:22:55 @base_main.py:52][0m [train_loss]: 0.4645293653011322
[32m[0511 17:22:55 @base_main.py:52][0m [val_loss]: 0.4060305655002594
[32m[0511 17:22:55 @base_main.py:52][0m [avg_train_loss]: 0.5368662476539612
[32m[0511 17:29:26 @mbmf_sampler.py:39][0m done with episode
[32m[0511 17:35:56 @mbmf_sampler.py:39][0m done with episode
[32m[0511 17:35:56 @mbmf_sampler.py:50][0m 1002 timesteps from 2 episodes collected
[32m[0511 17:35:56 @base_trainer.py:216][0m Mean reward: -454.32172125597674
[32m[0511 17:35:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5154003500938416, Train Loss: 0.5269647836685181
[32m[0511 17:35:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5154157876968384, Train Loss: 0.52695631980896
[32m[0511 17:35:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5154325366020203, Train Loss: 0.5269472599029541
[32m[0511 17:35:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5154496431350708, Train Loss: 0.526938259601593
[32m[0511 17:35:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5154673457145691, Train Loss: 0.5269296169281006
[32m[0511 17:35:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5154852271080017, Train Loss: 0.5269213914871216
[32m[0511 17:35:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5155032873153687, Train Loss: 0.5269134044647217
[32m[0511 17:35:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5155214667320251, Train Loss: 0.5269057750701904
[32m[0511 17:35:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5155395269393921, Train Loss: 0.5268986225128174
[32m[0511 17:35:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5155576467514038, Train Loss: 0.5268917083740234
[32m[0511 17:35:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5155757665634155, Train Loss: 0.5268850326538086
[32m[0511 17:35:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5155936479568481, Train Loss: 0.5268786549568176
[32m[0511 17:35:58 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5156112909317017, Train Loss: 0.5268725752830505
[32m[0511 17:35:58 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5156288146972656, Train Loss: 0.5268667340278625
[32m[0511 17:35:58 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5156462788581848, Train Loss: 0.5268610715866089
[32m[0511 17:35:58 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5156633853912354, Train Loss: 0.5268557071685791
[32m[0511 17:35:58 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5156803131103516, Train Loss: 0.5268504619598389
[32m[0511 17:35:58 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5156970024108887, Train Loss: 0.526845395565033
[32m[0511 17:35:58 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5157135128974915, Train Loss: 0.5268406271934509
[32m[0511 17:35:58 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5157297253608704, Train Loss: 0.5268359780311584
[32m[0511 17:35:58 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5157457590103149, Train Loss: 0.5268315672874451
[32m[0511 17:35:58 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5157614946365356, Train Loss: 0.5268272757530212
[32m[0511 17:35:58 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.515777051448822, Train Loss: 0.5268232226371765
[32m[0511 17:35:59 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5157922506332397, Train Loss: 0.5268192887306213
[32m[0511 17:35:59 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5158073902130127, Train Loss: 0.5268154144287109
[32m[0511 17:35:59 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5158221125602722, Train Loss: 0.5268117189407349
[32m[0511 17:35:59 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5158367156982422, Train Loss: 0.5268081426620483
[32m[0511 17:35:59 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5158511400222778, Train Loss: 0.5268047451972961
[32m[0511 17:35:59 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5158652067184448, Train Loss: 0.5268014073371887
[32m[0511 17:35:59 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5158791542053223, Train Loss: 0.5267983675003052
[32m[0511 17:35:59 @base_main.py:38][0m --------------- Iteration 5 ---------------
[32m[0511 17:35:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 39.4110 mins
[32m[0511 17:35:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 13.0134 mins
[32m[0511 17:35:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0483 mins
[32m[0511 17:35:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0053 mins
[32m[0511 17:35:59 @base_main.py:47][0m 5010 total steps have happened
[32m[0511 17:35:59 @base_main.py:52][0m [avg_reward]: -454.32172125597674
[32m[0511 17:35:59 @base_main.py:52][0m [update_op]: None
[32m[0511 17:35:59 @base_main.py:52][0m [train_loss]: 0.49048125743865967
[32m[0511 17:35:59 @base_main.py:52][0m [val_loss]: 0.5158791542053223
[32m[0511 17:35:59 @base_main.py:52][0m [avg_train_loss]: 0.5267983675003052
[32m[0511 17:42:30 @mbmf_sampler.py:39][0m done with episode
[32m[0511 17:49:01 @mbmf_sampler.py:39][0m done with episode
[32m[0511 17:49:01 @mbmf_sampler.py:50][0m 1002 timesteps from 2 episodes collected
[32m[0511 17:49:01 @base_trainer.py:216][0m Mean reward: -450.29048291868526
[32m[0511 17:49:01 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5007964372634888, Train Loss: 0.5246908664703369
[32m[0511 17:49:01 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5008542537689209, Train Loss: 0.524681031703949
[32m[0511 17:49:01 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5009388327598572, Train Loss: 0.5246726870536804
[32m[0511 17:49:01 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5010263323783875, Train Loss: 0.5246657729148865
[32m[0511 17:49:01 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5011100172996521, Train Loss: 0.524660050868988
[32m[0511 17:49:01 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5011877417564392, Train Loss: 0.5246554017066956
[32m[0511 17:49:01 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5012595653533936, Train Loss: 0.5246514678001404
[32m[0511 17:49:01 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5013259649276733, Train Loss: 0.524648129940033
[32m[0511 17:49:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.501387357711792, Train Loss: 0.524645209312439
[32m[0511 17:49:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5014443397521973, Train Loss: 0.5246427059173584
[32m[0511 17:49:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5014972686767578, Train Loss: 0.5246405601501465
[32m[0511 17:49:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5015466809272766, Train Loss: 0.5246385931968689
[32m[0511 17:49:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5015929937362671, Train Loss: 0.52463698387146
[32m[0511 17:49:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5016363263130188, Train Loss: 0.524635374546051
[32m[0511 17:49:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5016771554946899, Train Loss: 0.524634063243866
[32m[0511 17:49:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5017155408859253, Train Loss: 0.5246328711509705
[32m[0511 17:49:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5017518401145935, Train Loss: 0.524631679058075
[32m[0511 17:49:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5017862319946289, Train Loss: 0.5246306657791138
[32m[0511 17:49:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.501818835735321, Train Loss: 0.5246297717094421
[32m[0511 17:49:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5018497109413147, Train Loss: 0.5246290564537048
[32m[0511 17:49:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5018792152404785, Train Loss: 0.524628221988678
[32m[0511 17:49:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.501907229423523, Train Loss: 0.5246275067329407
[32m[0511 17:49:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5019339323043823, Train Loss: 0.5246269106864929
[32m[0511 17:49:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5019594430923462, Train Loss: 0.5246263146400452
[32m[0511 17:49:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5019838809967041, Train Loss: 0.5246257781982422
[32m[0511 17:49:04 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5020071268081665, Train Loss: 0.5246253609657288
[32m[0511 17:49:04 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5020294189453125, Train Loss: 0.5246250033378601
[32m[0511 17:49:04 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5020508766174316, Train Loss: 0.5246245861053467
[32m[0511 17:49:04 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5020713210105896, Train Loss: 0.524624228477478
[32m[0511 17:49:04 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5020909905433655, Train Loss: 0.5246238112449646
[32m[0511 17:49:04 @base_main.py:38][0m --------------- Iteration 6 ---------------
[32m[0511 17:49:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 52.4781 mins
[32m[0511 17:49:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 13.0188 mins
[32m[0511 17:49:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0584 mins
[32m[0511 17:49:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0054 mins
[32m[0511 17:49:04 @base_main.py:47][0m 6012 total steps have happened
[32m[0511 17:49:04 @base_main.py:52][0m [avg_reward]: -450.29048291868526
[32m[0511 17:49:04 @base_main.py:52][0m [update_op]: None
[32m[0511 17:49:04 @base_main.py:52][0m [train_loss]: 0.5730066895484924
[32m[0511 17:49:04 @base_main.py:52][0m [val_loss]: 0.5020909905433655
[32m[0511 17:49:04 @base_main.py:52][0m [avg_train_loss]: 0.5246238112449646
[32m[0511 17:55:36 @mbmf_sampler.py:39][0m done with episode
[32m[0511 18:02:06 @mbmf_sampler.py:39][0m done with episode
[32m[0511 18:02:06 @mbmf_sampler.py:50][0m 1002 timesteps from 2 episodes collected
[32m[0511 18:02:06 @base_trainer.py:216][0m Mean reward: -450.22942785243595
[32m[0511 18:02:06 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5073846578598022, Train Loss: 0.5225372910499573
[32m[0511 18:02:06 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5074333548545837, Train Loss: 0.5225281119346619
[32m[0511 18:02:06 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5074804425239563, Train Loss: 0.5225175619125366
[32m[0511 18:02:06 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5075268149375916, Train Loss: 0.5225077867507935
[32m[0511 18:02:06 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5075727701187134, Train Loss: 0.5224990248680115
[32m[0511 18:02:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5076181292533875, Train Loss: 0.5224913358688354
[32m[0511 18:02:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5076628923416138, Train Loss: 0.5224842429161072
[32m[0511 18:02:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5077069997787476, Train Loss: 0.5224778056144714
[32m[0511 18:02:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.507750391960144, Train Loss: 0.5224718451499939
[32m[0511 18:02:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5077930092811584, Train Loss: 0.5224663019180298
[32m[0511 18:02:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5078348517417908, Train Loss: 0.5224609971046448
[32m[0511 18:02:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5078760981559753, Train Loss: 0.5224561095237732
[32m[0511 18:02:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5079165697097778, Train Loss: 0.5224514603614807
[32m[0511 18:02:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5079562664031982, Train Loss: 0.5224471092224121
[32m[0511 18:02:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5079952478408813, Train Loss: 0.5224429368972778
[32m[0511 18:02:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5080335140228271, Train Loss: 0.5224389433860779
[32m[0511 18:02:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5080710053443909, Train Loss: 0.5224352478981018
[32m[0511 18:02:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5081079006195068, Train Loss: 0.5224316120147705
[32m[0511 18:02:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5081440806388855, Train Loss: 0.5224282741546631
[32m[0511 18:02:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5081794857978821, Train Loss: 0.5224249958992004
[32m[0511 18:02:09 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5082143545150757, Train Loss: 0.5224219560623169
[32m[0511 18:02:09 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.508248507976532, Train Loss: 0.5224190354347229
[32m[0511 18:02:09 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5082820653915405, Train Loss: 0.5224161744117737
[32m[0511 18:02:09 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5083149075508118, Train Loss: 0.5224135518074036
[32m[0511 18:02:09 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5083470940589905, Train Loss: 0.522411048412323
[32m[0511 18:02:09 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5083786845207214, Train Loss: 0.5224086046218872
[32m[0511 18:02:09 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5084097385406494, Train Loss: 0.522406280040741
[32m[0511 18:02:10 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5084400773048401, Train Loss: 0.522404134273529
[32m[0511 18:02:10 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5084697604179382, Train Loss: 0.5224019289016724
[32m[0511 18:02:10 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.508499026298523, Train Loss: 0.5224000215530396
[32m[0511 18:02:10 @base_main.py:38][0m --------------- Iteration 7 ---------------
[32m[0511 18:02:10 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 65.5608 mins
[32m[0511 18:02:10 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 13.0240 mins
[32m[0511 18:02:10 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0664 mins
[32m[0511 18:02:10 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0051 mins
[32m[0511 18:02:10 @base_main.py:47][0m 7014 total steps have happened
[32m[0511 18:02:10 @base_main.py:52][0m [avg_reward]: -450.22942785243595
[32m[0511 18:02:10 @base_main.py:52][0m [update_op]: None
[32m[0511 18:02:10 @base_main.py:52][0m [train_loss]: 0.5054200291633606
[32m[0511 18:02:10 @base_main.py:52][0m [val_loss]: 0.508499026298523
[32m[0511 18:02:10 @base_main.py:52][0m [avg_train_loss]: 0.5224000215530396
[32m[0511 18:02:10 @mbmf_trainer.py:160][0m Mean reward: -427.6791256754481
[32m[0511 18:02:10 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.288624107837677, Train Loss: 0.2962363064289093
[32m[0511 18:02:10 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.2852674722671509, Train Loss: 0.29293134808540344
[32m[0511 18:02:10 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.2825511395931244, Train Loss: 0.290431946516037
[32m[0511 18:02:10 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.2801746129989624, Train Loss: 0.2883036136627197
[32m[0511 18:02:10 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.27806124091148376, Train Loss: 0.28637784719467163
[32m[0511 18:02:10 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.2761979401111603, Train Loss: 0.2846710979938507
[32m[0511 18:02:10 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.2745767831802368, Train Loss: 0.28321051597595215
[32m[0511 18:02:10 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.27318960428237915, Train Loss: 0.28199303150177
[32m[0511 18:02:10 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.2720094323158264, Train Loss: 0.28098684549331665
[32m[0511 18:02:11 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.27099284529685974, Train Loss: 0.28014326095581055
[32m[0511 18:02:11 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.27009665966033936, Train Loss: 0.2794152796268463
[32m[0511 18:02:11 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.2692883014678955, Train Loss: 0.27876728773117065
[32m[0511 18:02:11 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.26854610443115234, Train Loss: 0.2781756520271301
[32m[0511 18:02:11 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.2678562104701996, Train Loss: 0.2776261866092682
[32m[0511 18:02:11 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.26720988750457764, Train Loss: 0.27711132168769836
[32m[0511 18:02:11 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.2666019797325134, Train Loss: 0.2766275703907013
[32m[0511 18:02:11 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.2660295069217682, Train Loss: 0.27617356181144714
[32m[0511 18:02:11 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.26549074053764343, Train Loss: 0.27574852108955383
[32m[0511 18:02:11 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.2649843394756317, Train Loss: 0.27535203099250793
[32m[0511 18:02:11 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.26450902223587036, Train Loss: 0.2749832570552826
[32m[0511 18:02:11 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.2640635669231415, Train Loss: 0.27464136481285095
[32m[0511 18:02:11 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.26364657282829285, Train Loss: 0.27432510256767273
[32m[0511 18:02:11 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.26325640082359314, Train Loss: 0.2740330398082733
[32m[0511 18:02:11 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.2628914415836334, Train Loss: 0.2737635672092438
[32m[0511 18:02:11 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.2625497579574585, Train Loss: 0.27351486682891846
[32m[0511 18:02:11 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.2622295320034027, Train Loss: 0.2732851207256317
[32m[0511 18:02:11 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.26192888617515564, Train Loss: 0.2730725109577179
[32m[0511 18:02:11 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.26164597272872925, Train Loss: 0.2728751599788666
[32m[0511 18:02:11 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.26137885451316833, Train Loss: 0.27269139885902405
[32m[0511 18:02:11 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.26112595200538635, Train Loss: 0.27251961827278137
[32m[0511 18:02:11 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.2608857750892639, Train Loss: 0.27235832810401917
[32m[0511 18:02:11 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.26065680384635925, Train Loss: 0.27220621705055237
[32m[0511 18:02:11 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.2604377865791321, Train Loss: 0.2720620930194855
[32m[0511 18:02:11 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.2602275609970093, Train Loss: 0.2719248831272125
[32m[0511 18:02:11 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.2600250840187073, Train Loss: 0.27179384231567383
[32m[0511 18:02:11 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.2598295509815216, Train Loss: 0.2716679871082306
[32m[0511 18:02:11 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.259640097618103, Train Loss: 0.27154675126075745
[32m[0511 18:02:11 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.2594560980796814, Train Loss: 0.27142956852912903
[32m[0511 18:02:11 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.2592768967151642, Train Loss: 0.2713159918785095
[32m[0511 18:02:11 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.2591019570827484, Train Loss: 0.27120551466941833
[32m[0511 18:02:11 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.25893089175224304, Train Loss: 0.2710978090763092
[32m[0511 18:02:11 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.25876322388648987, Train Loss: 0.27099257707595825
[32m[0511 18:02:11 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.258598655462265, Train Loss: 0.270889550447464
[32m[0511 18:02:11 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.25843682885169983, Train Loss: 0.2707885205745697
[32m[0511 18:02:12 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.25827744603157043, Train Loss: 0.2706892788410187
[32m[0511 18:02:12 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.2581203281879425, Train Loss: 0.2705915570259094
[32m[0511 18:02:12 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.25796520709991455, Train Loss: 0.27049535512924194
[32m[0511 18:02:12 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.25781190395355225, Train Loss: 0.27040043473243713
[32m[0511 18:02:12 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.2576601803302765, Train Loss: 0.27030667662620544
[32m[0511 18:02:12 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.2575100362300873, Train Loss: 0.2702140212059021
[32m[0511 18:02:12 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.25736111402511597, Train Loss: 0.27012231945991516
[32m[0511 18:02:12 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.25721344351768494, Train Loss: 0.27003148198127747
[32m[0511 18:02:12 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.257066935300827, Train Loss: 0.2699415385723114
[32m[0511 18:02:12 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.2569213807582855, Train Loss: 0.26985228061676025
[32m[0511 18:02:12 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.2567767798900604, Train Loss: 0.2697637379169464
[32m[0511 18:02:12 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.25663310289382935, Train Loss: 0.2696758508682251
[32m[0511 18:02:12 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.2564902603626251, Train Loss: 0.26958855986595154
[32m[0511 18:02:12 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.25634822249412537, Train Loss: 0.2695018947124481
[32m[0511 18:02:12 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.25620704889297485, Train Loss: 0.2694157660007477
[32m[0511 18:02:12 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.25606662034988403, Train Loss: 0.2693302631378174
[32m[0511 18:02:12 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.25592705607414246, Train Loss: 0.26924535632133484
[32m[0511 18:02:12 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.2557883858680725, Train Loss: 0.26916101574897766
[32m[0511 18:02:12 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.25565066933631897, Train Loss: 0.26907727122306824
[32m[0511 18:02:12 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.25551390647888184, Train Loss: 0.26899412274360657
[32m[0511 18:02:12 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.25537824630737305, Train Loss: 0.268911749124527
[32m[0511 18:02:12 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.255243718624115, Train Loss: 0.2688300609588623
[32m[0511 18:02:12 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.2551104724407196, Train Loss: 0.2687491178512573
[32m[0511 18:02:12 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.2549785375595093, Train Loss: 0.2686690092086792
[32m[0511 18:02:12 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.2548481225967407, Train Loss: 0.2685897648334503
[32m[0511 18:02:12 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.25471925735473633, Train Loss: 0.26851144433021545
[32m[0511 18:02:12 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.25459209084510803, Train Loss: 0.26843416690826416
[32m[0511 18:02:12 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.2544666528701782, Train Loss: 0.2683578431606293
[32m[0511 18:02:12 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.2543431222438812, Train Loss: 0.2682827115058899
[32m[0511 18:02:12 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.25422152876853943, Train Loss: 0.26820868253707886
[32m[0511 18:02:12 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.25410196185112, Train Loss: 0.26813581585884094
[32m[0511 18:02:12 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.2539845108985901, Train Loss: 0.2680642306804657
[32m[0511 18:02:12 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.2538691461086273, Train Loss: 0.26799383759498596
[32m[0511 18:02:12 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.2537560760974884, Train Loss: 0.26792481541633606
[32m[0511 18:02:12 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.2536451816558838, Train Loss: 0.26785704493522644
[32m[0511 18:02:12 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.25353655219078064, Train Loss: 0.26779064536094666
[32m[0511 18:02:13 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.25343018770217896, Train Loss: 0.26772555708885193
[32m[0511 18:02:13 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.25332605838775635, Train Loss: 0.26766183972358704
[32m[0511 18:02:13 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.2532242238521576, Train Loss: 0.267599493265152
[32m[0511 18:02:13 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.2531246244907379, Train Loss: 0.26753848791122437
[32m[0511 18:02:13 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.2530273199081421, Train Loss: 0.2674787640571594
[32m[0511 18:02:13 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.2529321610927582, Train Loss: 0.2674204409122467
[32m[0511 18:02:13 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.25283923745155334, Train Loss: 0.26736342906951904
[32m[0511 18:02:13 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.2527484595775604, Train Loss: 0.26730769872665405
[32m[0511 18:02:13 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.25265973806381226, Train Loss: 0.26725324988365173
[32m[0511 18:02:13 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.2525731325149536, Train Loss: 0.2672000825405121
[32m[0511 18:02:13 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.2524885833263397, Train Loss: 0.2671481668949127
[32m[0511 18:02:13 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.2524060308933258, Train Loss: 0.2670973837375641
[32m[0511 18:02:13 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.2523254156112671, Train Loss: 0.2670479118824005
[32m[0511 18:02:13 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.2522467076778412, Train Loss: 0.2669995427131653
[32m[0511 18:02:13 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.2521698772907257, Train Loss: 0.2669523060321808
[32m[0511 18:02:13 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.2520948648452759, Train Loss: 0.2669062316417694
[32m[0511 18:02:13 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.2520216405391693, Train Loss: 0.266861230134964
[32m[0511 18:02:13 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.25195011496543884, Train Loss: 0.26681727170944214
[32m[0511 18:02:13 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.2518802881240845, Train Loss: 0.26677432656288147
[32m[0511 18:02:13 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.2518121004104614, Train Loss: 0.26673242449760437
[32m[0511 18:02:13 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.2517455220222473, Train Loss: 0.26669150590896606
[32m[0511 18:02:13 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.25168049335479736, Train Loss: 0.26665154099464417
[32m[0511 18:02:13 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.2516169548034668, Train Loss: 0.2666124701499939
[32m[0511 18:02:13 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.251554936170578, Train Loss: 0.26657429337501526
[32m[0511 18:02:13 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.25149428844451904, Train Loss: 0.26653701066970825
[32m[0511 18:02:13 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.2514351010322571, Train Loss: 0.2665005326271057
[32m[0511 18:02:13 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.2513771951198578, Train Loss: 0.2664649188518524
[32m[0511 18:02:13 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.25132066011428833, Train Loss: 0.2664300799369812
[32m[0511 18:02:13 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.25126537680625916, Train Loss: 0.26639601588249207
[32m[0511 18:02:13 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.25121137499809265, Train Loss: 0.2663626968860626
[32m[0511 18:02:13 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.25115853548049927, Train Loss: 0.2663300931453705
[32m[0511 18:02:13 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.2511069178581238, Train Loss: 0.26629823446273804
[32m[0511 18:02:13 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.25105637311935425, Train Loss: 0.26626697182655334
[32m[0511 18:02:13 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.25100696086883545, Train Loss: 0.26623639464378357
[32m[0511 18:02:13 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.2509586215019226, Train Loss: 0.2662064731121063
[32m[0511 18:02:14 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.25091132521629333, Train Loss: 0.26617708802223206
[32m[0511 18:02:14 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.25086504220962524, Train Loss: 0.2661483585834503
[32m[0511 18:02:14 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.25081974267959595, Train Loss: 0.26612016558647156
[32m[0511 18:02:14 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.25077539682388306, Train Loss: 0.26609256863594055
[32m[0511 18:02:14 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.2507319748401642, Train Loss: 0.26606544852256775
[32m[0511 18:02:14 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.25068941712379456, Train Loss: 0.2660389244556427
[32m[0511 18:02:14 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.25064781308174133, Train Loss: 0.2660128176212311
[32m[0511 18:02:14 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.2506070137023926, Train Loss: 0.26598721742630005
[32m[0511 18:02:14 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.2505670487880707, Train Loss: 0.26596206426620483
[32m[0511 18:02:14 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.25052788853645325, Train Loss: 0.2659373879432678
[32m[0511 18:02:14 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.2504894435405731, Train Loss: 0.2659131586551666
[32m[0511 18:02:14 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.2504517734050751, Train Loss: 0.2658892869949341
[32m[0511 18:02:14 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.2504148781299591, Train Loss: 0.26586583256721497
[32m[0511 18:02:14 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.25037869811058044, Train Loss: 0.2658427655696869
[32m[0511 18:02:14 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.2503431737422943, Train Loss: 0.26582011580467224
[32m[0511 18:02:14 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.2503083050251007, Train Loss: 0.26579779386520386
[32m[0511 18:02:14 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.25027409195899963, Train Loss: 0.2657758295536041
[32m[0511 18:02:14 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.2502405345439911, Train Loss: 0.26575419306755066
[32m[0511 18:02:14 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.2502075135707855, Train Loss: 0.26573288440704346
[32m[0511 18:02:14 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.2501751482486725, Train Loss: 0.2657119035720825
[32m[0511 18:02:14 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.2501433491706848, Train Loss: 0.26569119095802307
[32m[0511 18:02:14 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.2501121163368225, Train Loss: 0.2656707763671875
[32m[0511 18:02:14 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.2500814199447632, Train Loss: 0.2656506597995758
[32m[0511 18:02:14 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.25005123019218445, Train Loss: 0.265630841255188
[32m[0511 18:02:14 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.2500215768814087, Train Loss: 0.2656112313270569
[32m[0511 18:02:14 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.24999243021011353, Train Loss: 0.26559188961982727
[32m[0511 18:02:14 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.24996371567249298, Train Loss: 0.26557281613349915
[32m[0511 18:02:14 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.24993550777435303, Train Loss: 0.26555395126342773
[32m[0511 18:02:14 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.2499077469110489, Train Loss: 0.2655353248119354
[32m[0511 18:02:14 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.24988041818141937, Train Loss: 0.2655169367790222
[32m[0511 18:02:14 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.2498534917831421, Train Loss: 0.2654987573623657
[32m[0511 18:02:14 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.249827042222023, Train Loss: 0.26548075675964355
[32m[0511 18:02:14 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.2498009353876114, Train Loss: 0.2654629647731781
[32m[0511 18:02:14 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.249775230884552, Train Loss: 0.26544538140296936
[32m[0511 18:02:14 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.24974991381168365, Train Loss: 0.26542797684669495
[32m[0511 18:02:14 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.24972496926784515, Train Loss: 0.26541072130203247
[32m[0511 18:02:15 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.2497003674507141, Train Loss: 0.2653936445713043
[32m[0511 18:02:15 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.24967610836029053, Train Loss: 0.2653767764568329
[32m[0511 18:02:15 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.2496522068977356, Train Loss: 0.2653600573539734
[32m[0511 18:02:15 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.24962863326072693, Train Loss: 0.26534342765808105
[32m[0511 18:02:15 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.24960534274578094, Train Loss: 0.2653270363807678
[32m[0511 18:02:15 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.24958239495754242, Train Loss: 0.26531076431274414
[32m[0511 18:02:15 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.24955971539020538, Train Loss: 0.2652946412563324
[32m[0511 18:02:15 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.2495373636484146, Train Loss: 0.2652786076068878
[32m[0511 18:02:15 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.24951526522636414, Train Loss: 0.26526275277137756
[32m[0511 18:02:15 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.24949344992637634, Train Loss: 0.2652469873428345
[32m[0511 18:02:15 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.24947190284729004, Train Loss: 0.2652313709259033
[32m[0511 18:02:15 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.24945059418678284, Train Loss: 0.2652158737182617
[32m[0511 18:02:15 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.24942956864833832, Train Loss: 0.26520049571990967
[32m[0511 18:02:15 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.24940873682498932, Train Loss: 0.26518523693084717
[32m[0511 18:02:15 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.2493882179260254, Train Loss: 0.2651700973510742
[32m[0511 18:02:15 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.2493678778409958, Train Loss: 0.26515498757362366
[32m[0511 18:02:15 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.2493477463722229, Train Loss: 0.2651400864124298
[32m[0511 18:02:15 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.24932782351970673, Train Loss: 0.26512524485588074
[32m[0511 18:02:15 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.24930812418460846, Train Loss: 0.26511046290397644
[32m[0511 18:02:15 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.2492886632680893, Train Loss: 0.2650958001613617
[32m[0511 18:02:15 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.24926938116550446, Train Loss: 0.2650812566280365
[32m[0511 18:02:15 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.24925027787685394, Train Loss: 0.26506680250167847
[32m[0511 18:02:15 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.24923138320446014, Train Loss: 0.2650523781776428
[32m[0511 18:02:15 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.24921263754367828, Train Loss: 0.26503807306289673
[32m[0511 18:02:15 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.24919411540031433, Train Loss: 0.2650238573551178
[32m[0511 18:02:15 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.24917574226856232, Train Loss: 0.26500973105430603
[32m[0511 18:02:15 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.24915751814842224, Train Loss: 0.26499566435813904
[32m[0511 18:02:15 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.24913950264453888, Train Loss: 0.26498162746429443
[32m[0511 18:02:15 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.24912159144878387, Train Loss: 0.2649677097797394
[32m[0511 18:02:15 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.249103844165802, Train Loss: 0.2649538815021515
[32m[0511 18:02:15 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.24908626079559326, Train Loss: 0.2649400532245636
[32m[0511 18:02:15 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.24906882643699646, Train Loss: 0.26492640376091003
[32m[0511 18:02:15 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.2490515410900116, Train Loss: 0.2649127244949341
[32m[0511 18:02:15 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.2490343600511551, Train Loss: 0.2648991644382477
[32m[0511 18:02:15 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.24901734292507172, Train Loss: 0.26488566398620605
[32m[0511 18:02:15 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.2490004450082779, Train Loss: 0.26487216353416443
[32m[0511 18:02:16 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.24898366630077362, Train Loss: 0.26485875248908997
[32m[0511 18:02:16 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.2489670366048813, Train Loss: 0.2648454010486603
[32m[0511 18:02:16 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.24895049631595612, Train Loss: 0.26483216881752014
[32m[0511 18:02:16 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.2489340901374817, Train Loss: 0.26481893658638
[32m[0511 18:02:16 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.24891780316829681, Train Loss: 0.26480576395988464
[32m[0511 18:02:16 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.2489016056060791, Train Loss: 0.26479265093803406
[32m[0511 18:02:16 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.24888552725315094, Train Loss: 0.26477953791618347
[32m[0511 18:02:16 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.24886953830718994, Train Loss: 0.2647665739059448
[32m[0511 18:02:16 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.2488536685705185, Train Loss: 0.2647535800933838
[32m[0511 18:02:16 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.2488379180431366, Train Loss: 0.2647406756877899
[32m[0511 18:02:16 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.24882227182388306, Train Loss: 0.26472780108451843
[32m[0511 18:02:16 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.2488066852092743, Train Loss: 0.26471495628356934
[32m[0511 18:02:16 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.24879120290279388, Train Loss: 0.264702171087265
[32m[0511 18:02:16 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.24877581000328064, Train Loss: 0.26468947529792786
[32m[0511 18:02:16 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.24876050651073456, Train Loss: 0.2646767497062683
[32m[0511 18:02:16 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.24874527752399445, Train Loss: 0.2646641433238983
[32m[0511 18:02:16 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.24873019754886627, Train Loss: 0.2646515369415283
[32m[0511 18:02:16 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.24871514737606049, Train Loss: 0.2646389305591583
[32m[0511 18:02:16 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.24870020151138306, Train Loss: 0.26462647318840027
[32m[0511 18:02:16 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.2486853003501892, Train Loss: 0.26461395621299744
[32m[0511 18:02:16 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.24867048859596252, Train Loss: 0.26460155844688416
[32m[0511 18:02:16 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.2486557513475418, Train Loss: 0.2645891606807709
[32m[0511 18:02:16 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.24864111840724945, Train Loss: 0.26457679271698
[32m[0511 18:02:16 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.24862651526927948, Train Loss: 0.26456448435783386
[32m[0511 18:02:16 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.24861200153827667, Train Loss: 0.26455214619636536
[32m[0511 18:02:16 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.24859757721424103, Train Loss: 0.264539897441864
[32m[0511 18:02:16 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.24858316779136658, Train Loss: 0.26452770829200745
[32m[0511 18:02:16 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.24856887757778168, Train Loss: 0.26451554894447327
[32m[0511 18:02:16 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.24855466187000275, Train Loss: 0.2645033895969391
[32m[0511 18:02:16 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.248540461063385, Train Loss: 0.2644912600517273
[32m[0511 18:02:16 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.24852633476257324, Train Loss: 0.2644791901111603
[32m[0511 18:02:16 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.24851229786872864, Train Loss: 0.26446714997291565
[32m[0511 18:02:16 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.2484983205795288, Train Loss: 0.2644551694393158
[32m[0511 18:02:16 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.24848435819149017, Train Loss: 0.26444318890571594
[32m[0511 18:02:16 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.24847052991390228, Train Loss: 0.2644312083721161
[32m[0511 18:02:17 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.2484566867351532, Train Loss: 0.2644193470478058
[32m[0511 18:02:17 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.2484429031610489, Train Loss: 0.2644074559211731
[32m[0511 18:02:17 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.24842920899391174, Train Loss: 0.2643955945968628
[32m[0511 18:02:17 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.24841557443141937, Train Loss: 0.2643837630748749
[32m[0511 18:02:17 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.2484019696712494, Train Loss: 0.26437199115753174
[32m[0511 18:02:17 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.2483883947134018, Train Loss: 0.264360249042511
[32m[0511 18:02:17 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.24837492406368256, Train Loss: 0.2643485367298126
[32m[0511 18:02:17 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.2483614832162857, Train Loss: 0.26433679461479187
[32m[0511 18:02:17 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.24834807217121124, Train Loss: 0.2643251419067383
[32m[0511 18:02:17 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.24833475053310394, Train Loss: 0.2643134891986847
[32m[0511 18:02:17 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.24832144379615784, Train Loss: 0.2643018960952759
[32m[0511 18:02:17 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.2483082115650177, Train Loss: 0.26429030299186707
[32m[0511 18:02:17 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.24829499423503876, Train Loss: 0.26427873969078064
[32m[0511 18:02:17 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.24828185141086578, Train Loss: 0.264267235994339
[32m[0511 18:02:17 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.248268723487854, Train Loss: 0.26425573229789734
[32m[0511 18:02:17 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.2482556700706482, Train Loss: 0.26424428820610046
[32m[0511 18:02:17 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.24824264645576477, Train Loss: 0.2642328143119812
[32m[0511 18:02:17 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.24822965264320374, Train Loss: 0.2642214000225067
[32m[0511 18:02:17 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.24821671843528748, Train Loss: 0.2642100155353546
[32m[0511 18:02:17 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.248203843832016, Train Loss: 0.2641986608505249
[32m[0511 18:02:17 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.2481909990310669, Train Loss: 0.2641873061656952
[32m[0511 18:02:17 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.248178169131279, Train Loss: 0.26417598128318787
[32m[0511 18:02:17 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.24816539883613586, Train Loss: 0.2641647160053253
[32m[0511 18:02:17 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.24815265834331512, Train Loss: 0.2641534209251404
[32m[0511 18:02:17 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.24813999235630035, Train Loss: 0.2641422152519226
[32m[0511 18:02:17 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.24812732636928558, Train Loss: 0.26413097977638245
[32m[0511 18:02:17 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.24811474978923798, Train Loss: 0.26411980390548706
[32m[0511 18:02:17 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.24810215830802917, Train Loss: 0.2641086280345917
[32m[0511 18:02:17 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.24808962643146515, Train Loss: 0.26409751176834106
[32m[0511 18:02:17 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.2480771541595459, Train Loss: 0.26408639550209045
[32m[0511 18:02:17 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.24806468188762665, Train Loss: 0.26407530903816223
[32m[0511 18:02:17 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.24805226922035217, Train Loss: 0.264064222574234
[32m[0511 18:02:17 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.24803988635540009, Train Loss: 0.26405319571495056
[32m[0511 18:02:17 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.24802754819393158, Train Loss: 0.2640421688556671
[32m[0511 18:02:17 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.24801525473594666, Train Loss: 0.26403114199638367
[32m[0511 18:02:17 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.24800294637680054, Train Loss: 0.264020174741745
[32m[0511 18:02:17 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.2479907125234604, Train Loss: 0.2640092670917511
[32m[0511 18:02:18 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.24797850847244263, Train Loss: 0.2639982998371124
[32m[0511 18:02:18 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.24796633422374725, Train Loss: 0.2639874219894409
[32m[0511 18:02:18 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.24795418977737427, Train Loss: 0.2639765441417694
[32m[0511 18:02:18 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.24794209003448486, Train Loss: 0.2639656662940979
[32m[0511 18:02:18 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.24793000519275665, Train Loss: 0.2639547884464264
[32m[0511 18:02:18 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.2479180097579956, Train Loss: 0.26394400000572205
[32m[0511 18:02:18 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.24790596961975098, Train Loss: 0.2639332115650177
[32m[0511 18:02:18 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.2478940188884735, Train Loss: 0.26392245292663574
[32m[0511 18:02:18 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.24788209795951843, Train Loss: 0.2639116942882538
[32m[0511 18:02:18 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.24787020683288574, Train Loss: 0.2639009654521942
[32m[0511 18:02:18 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.24785833060741425, Train Loss: 0.26389023661613464
[32m[0511 18:02:18 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.24784648418426514, Train Loss: 0.2638796269893646
[32m[0511 18:02:18 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.2478346824645996, Train Loss: 0.26386892795562744
[32m[0511 18:02:18 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.24782291054725647, Train Loss: 0.26385825872421265
[32m[0511 18:02:18 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.24781113862991333, Train Loss: 0.263847678899765
[32m[0511 18:02:18 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.24779944121837616, Train Loss: 0.263837069272995
[32m[0511 18:02:18 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.24778775870800018, Train Loss: 0.263826459646225
[32m[0511 18:02:18 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.2477760910987854, Train Loss: 0.2638159394264221
[32m[0511 18:02:18 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.2477644830942154, Train Loss: 0.26380541920661926
[32m[0511 18:02:18 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.24775293469429016, Train Loss: 0.263794869184494
[32m[0511 18:02:18 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.24774132668972015, Train Loss: 0.26378437876701355
[32m[0511 18:02:18 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.2477298080921173, Train Loss: 0.2637738883495331
[32m[0511 18:02:18 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.24771834909915924, Train Loss: 0.2637634575366974
[32m[0511 18:02:18 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.2477068454027176, Train Loss: 0.2637530267238617
[32m[0511 18:02:18 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.24769540131092072, Train Loss: 0.263742595911026
[32m[0511 18:02:18 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.24768398702144623, Train Loss: 0.2637321949005127
[32m[0511 18:02:18 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.24767261743545532, Train Loss: 0.26372185349464417
[32m[0511 18:02:18 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.2476612627506256, Train Loss: 0.26371148228645325
[32m[0511 18:02:18 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.24764995276927948, Train Loss: 0.2637011706829071
[32m[0511 18:02:18 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.24763862788677216, Train Loss: 0.26369085907936096
[32m[0511 18:02:18 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.2476273775100708, Train Loss: 0.2636805474758148
[32m[0511 18:02:18 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.24761614203453064, Train Loss: 0.26367029547691345
[32m[0511 18:02:18 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.24760493636131287, Train Loss: 0.2636600434780121
[32m[0511 18:02:18 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.2475937455892563, Train Loss: 0.2636497914791107
[32m[0511 18:02:18 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.2475825846195221, Train Loss: 0.2636395990848541
[32m[0511 18:02:18 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.2475714385509491, Train Loss: 0.2636294364929199
[32m[0511 18:02:18 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.24756035208702087, Train Loss: 0.26361921429634094
[32m[0511 18:02:18 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.24754932522773743, Train Loss: 0.2636091113090515
[32m[0511 18:02:19 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.247538223862648, Train Loss: 0.2635989487171173
[32m[0511 18:02:19 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.24752722680568695, Train Loss: 0.2635888159275055
[32m[0511 18:02:19 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.2475162297487259, Train Loss: 0.26357874274253845
[32m[0511 18:02:19 @mbmf_sampler.py:98][0m Finished 4th episode
[32m[0511 18:02:19 @mbmf_sampler.py:102][0m 2004 timesteps from 4 episodes collected
[32m[0511 18:28:26 @mbmf_trainer.py:160][0m Mean reward: -426.8233731677041
[32m[0511 18:28:26 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.2948569655418396, Train Loss: 0.29175567626953125
[32m[0511 18:28:26 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.29651743173599243, Train Loss: 0.28632786870002747
[32m[0511 18:28:26 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.2965829074382782, Train Loss: 0.2849559187889099
[32m[0511 18:28:26 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.2960832417011261, Train Loss: 0.2839992642402649
[32m[0511 18:28:26 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.2960387170314789, Train Loss: 0.2832390069961548
[32m[0511 18:28:26 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.29624420404434204, Train Loss: 0.2826682925224304
[32m[0511 18:28:26 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.2964467704296112, Train Loss: 0.282205194234848
[32m[0511 18:28:26 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.2966015636920929, Train Loss: 0.28181034326553345
[32m[0511 18:28:27 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.2967391014099121, Train Loss: 0.2814580798149109
[32m[0511 18:28:27 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.29687798023223877, Train Loss: 0.2811383306980133
[32m[0511 18:28:27 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.2970183193683624, Train Loss: 0.28084614872932434
[32m[0511 18:28:27 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.29715660214424133, Train Loss: 0.28057706356048584
[32m[0511 18:28:27 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.29729214310646057, Train Loss: 0.280327707529068
[32m[0511 18:28:27 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.29742521047592163, Train Loss: 0.2800953984260559
[32m[0511 18:28:27 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.2975557744503021, Train Loss: 0.2798781394958496
[32m[0511 18:28:27 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.29768386483192444, Train Loss: 0.2796741724014282
[32m[0511 18:28:27 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.2978092133998871, Train Loss: 0.2794821560382843
[32m[0511 18:28:27 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.2979317307472229, Train Loss: 0.27930083870887756
[32m[0511 18:28:27 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.2980513274669647, Train Loss: 0.27912914752960205
[32m[0511 18:28:27 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.29816797375679016, Train Loss: 0.2789662182331085
[32m[0511 18:28:27 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.29828163981437683, Train Loss: 0.2788112163543701
[32m[0511 18:28:27 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.2983924150466919, Train Loss: 0.2786634564399719
[32m[0511 18:28:27 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.298500120639801, Train Loss: 0.2785223126411438
[32m[0511 18:28:27 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.2986048758029938, Train Loss: 0.27838727831840515
[32m[0511 18:28:27 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.2987067997455597, Train Loss: 0.2782578468322754
[32m[0511 18:28:27 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.2988058924674988, Train Loss: 0.2781336307525635
[32m[0511 18:28:27 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.29890215396881104, Train Loss: 0.2780141830444336
[32m[0511 18:28:27 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.298995703458786, Train Loss: 0.27789926528930664
[32m[0511 18:28:27 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.2990865707397461, Train Loss: 0.27778851985931396
[32m[0511 18:28:27 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.29917487502098083, Train Loss: 0.2776816487312317
[32m[0511 18:28:27 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.2992604970932007, Train Loss: 0.2775784134864807
[32m[0511 18:28:27 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.29934370517730713, Train Loss: 0.2774786353111267
[32m[0511 18:28:27 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.299424409866333, Train Loss: 0.2773820757865906
[32m[0511 18:28:27 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.29950281977653503, Train Loss: 0.2772885262966156
[32m[0511 18:28:27 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.2995789051055908, Train Loss: 0.27719786763191223
[32m[0511 18:28:27 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.29965266585350037, Train Loss: 0.27710989117622375
[32m[0511 18:28:28 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.299724280834198, Train Loss: 0.2770244777202606
[32m[0511 18:28:28 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.2997937500476837, Train Loss: 0.2769414782524109
[32m[0511 18:28:28 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.2998611629009247, Train Loss: 0.2768608033657074
[32m[0511 18:28:28 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.2999264895915985, Train Loss: 0.2767822742462158
[32m[0511 18:28:28 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.29998984932899475, Train Loss: 0.27670586109161377
[32m[0511 18:28:28 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.3000512719154358, Train Loss: 0.2766314148902893
[32m[0511 18:28:28 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.300110787153244, Train Loss: 0.2765588164329529
[32m[0511 18:28:28 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.3001684546470642, Train Loss: 0.2764880359172821
[32m[0511 18:28:28 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.30022433400154114, Train Loss: 0.2764189541339874
[32m[0511 18:28:28 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.3002784848213196, Train Loss: 0.2763515114784241
[32m[0511 18:28:28 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.30033087730407715, Train Loss: 0.2762855887413025
[32m[0511 18:28:28 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.300381600856781, Train Loss: 0.2762211859226227
[32m[0511 18:28:28 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.3004307448863983, Train Loss: 0.2761581838130951
[32m[0511 18:28:28 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.3004782795906067, Train Loss: 0.27609655261039734
[32m[0511 18:28:28 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.3005242347717285, Train Loss: 0.27603620290756226
[32m[0511 18:28:28 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.30056867003440857, Train Loss: 0.27597710490226746
[32m[0511 18:28:28 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.3006117045879364, Train Loss: 0.27591919898986816
[32m[0511 18:28:28 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.30065327882766724, Train Loss: 0.2758623957633972
[32m[0511 18:28:28 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.30069342255592346, Train Loss: 0.2758067548274994
[32m[0511 18:28:28 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.300732284784317, Train Loss: 0.27575209736824036
[32m[0511 18:28:28 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.3007696866989136, Train Loss: 0.2756984829902649
[32m[0511 18:28:28 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.30080586671829224, Train Loss: 0.2756458520889282
[32m[0511 18:28:28 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.3008407652378082, Train Loss: 0.27559414505958557
[32m[0511 18:28:28 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.3008745014667511, Train Loss: 0.27554330229759216
[32m[0511 18:28:28 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.3009069859981537, Train Loss: 0.275493323802948
[32m[0511 18:28:28 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.30093830823898315, Train Loss: 0.2754442095756531
[32m[0511 18:28:28 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.3009685277938843, Train Loss: 0.27539581060409546
[32m[0511 18:28:29 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.30099764466285706, Train Loss: 0.2753482460975647
[32m[0511 18:28:29 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.3010256588459015, Train Loss: 0.27530139684677124
[32m[0511 18:28:29 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.30105265974998474, Train Loss: 0.2752552628517151
[32m[0511 18:28:29 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.3010787069797516, Train Loss: 0.27520984411239624
[32m[0511 18:28:29 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.3011036515235901, Train Loss: 0.27516502141952515
[32m[0511 18:28:29 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.30112770199775696, Train Loss: 0.2751208543777466
[32m[0511 18:28:29 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.301150918006897, Train Loss: 0.27507728338241577
[32m[0511 18:28:29 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.3011731207370758, Train Loss: 0.2750343680381775
[32m[0511 18:28:29 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.30119451880455017, Train Loss: 0.2749919891357422
[32m[0511 18:28:29 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.3012150228023529, Train Loss: 0.27495014667510986
[32m[0511 18:28:29 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.30123475193977356, Train Loss: 0.2749088406562805
[32m[0511 18:28:29 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.30125367641448975, Train Loss: 0.27486807107925415
[32m[0511 18:28:29 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.30127182602882385, Train Loss: 0.27482783794403076
[32m[0511 18:28:29 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.3012892007827759, Train Loss: 0.2747880220413208
[32m[0511 18:28:29 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.3013059198856354, Train Loss: 0.27474871277809143
[32m[0511 18:28:29 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.3013218641281128, Train Loss: 0.2747098505496979
[32m[0511 18:28:29 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.30133721232414246, Train Loss: 0.27467140555381775
[32m[0511 18:28:29 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.3013518452644348, Train Loss: 0.2746334373950958
[32m[0511 18:28:29 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.3013658821582794, Train Loss: 0.27459585666656494
[32m[0511 18:28:29 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.3013792932033539, Train Loss: 0.2745586633682251
[32m[0511 18:28:29 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.301392138004303, Train Loss: 0.2745218873023987
[32m[0511 18:28:29 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.3014044165611267, Train Loss: 0.2744854688644409
[32m[0511 18:28:29 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.3014160692691803, Train Loss: 0.2744494378566742
[32m[0511 18:28:29 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.30142727494239807, Train Loss: 0.2744137644767761
[32m[0511 18:28:29 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.30143794417381287, Train Loss: 0.2743784189224243
[32m[0511 18:28:29 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.3014480769634247, Train Loss: 0.27434343099594116
[32m[0511 18:28:29 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.3014577627182007, Train Loss: 0.27430880069732666
[32m[0511 18:28:29 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.3014669716358185, Train Loss: 0.27427446842193604
[32m[0511 18:28:30 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.30147573351860046, Train Loss: 0.2742404341697693
[32m[0511 18:28:30 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.301484078168869, Train Loss: 0.2742067277431488
[32m[0511 18:28:30 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.30149200558662415, Train Loss: 0.2741733491420746
[32m[0511 18:28:30 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.30149948596954346, Train Loss: 0.27414020895957947
[32m[0511 18:28:30 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.30150654911994934, Train Loss: 0.2741073966026306
[32m[0511 18:28:30 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.3015133738517761, Train Loss: 0.27407485246658325
[32m[0511 18:28:30 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.3015197813510895, Train Loss: 0.274042546749115
[32m[0511 18:28:30 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.3015258014202118, Train Loss: 0.2740105390548706
[32m[0511 18:28:30 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.30153152346611023, Train Loss: 0.2739788293838501
[32m[0511 18:28:30 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.3015369176864624, Train Loss: 0.2739472985267639
[32m[0511 18:28:30 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.3015419840812683, Train Loss: 0.2739160656929016
[32m[0511 18:28:30 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.30154675245285034, Train Loss: 0.2738850712776184
[32m[0511 18:28:30 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.30155131220817566, Train Loss: 0.2738543152809143
[32m[0511 18:28:30 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.3015555441379547, Train Loss: 0.2738238275051117
[32m[0511 18:28:30 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.3015595078468323, Train Loss: 0.2737935185432434
[32m[0511 18:28:30 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.30156323313713074, Train Loss: 0.2737634778022766
[32m[0511 18:28:30 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.3015666902065277, Train Loss: 0.27373364567756653
[32m[0511 18:28:30 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.3015699088573456, Train Loss: 0.27370405197143555
[32m[0511 18:28:30 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.30157291889190674, Train Loss: 0.2736746370792389
[32m[0511 18:28:30 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.30157575011253357, Train Loss: 0.27364543080329895
[32m[0511 18:28:30 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.3015783429145813, Train Loss: 0.2736164927482605
[32m[0511 18:28:30 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.3015806972980499, Train Loss: 0.273587703704834
[32m[0511 18:28:30 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.301582932472229, Train Loss: 0.2735591232776642
[32m[0511 18:28:30 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.301584929227829, Train Loss: 0.2735307812690735
[32m[0511 18:28:30 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.3015868067741394, Train Loss: 0.2735026478767395
[32m[0511 18:28:30 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.3015885055065155, Train Loss: 0.27347463369369507
[32m[0511 18:28:30 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.30159005522727966, Train Loss: 0.27344685792922974
[32m[0511 18:28:31 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.3015913963317871, Train Loss: 0.27341926097869873
[32m[0511 18:28:31 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.3015926480293274, Train Loss: 0.27339184284210205
[32m[0511 18:28:31 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.30159375071525574, Train Loss: 0.2733646631240845
[32m[0511 18:28:31 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.30159464478492737, Train Loss: 0.27333760261535645
[32m[0511 18:28:31 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.301595538854599, Train Loss: 0.27331072092056274
[32m[0511 18:28:31 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.3015962541103363, Train Loss: 0.27328404784202576
[32m[0511 18:28:31 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.30159682035446167, Train Loss: 0.2732575535774231
[32m[0511 18:28:31 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.3015972971916199, Train Loss: 0.2732312083244324
[32m[0511 18:28:31 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.3015977442264557, Train Loss: 0.273205041885376
[32m[0511 18:28:31 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.3015979528427124, Train Loss: 0.2731790542602539
[32m[0511 18:28:31 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.30159813165664673, Train Loss: 0.27315324544906616
[32m[0511 18:28:31 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.3015982508659363, Train Loss: 0.27312755584716797
[32m[0511 18:28:31 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.3015982508659363, Train Loss: 0.2731020748615265
[32m[0511 18:28:31 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.3015982210636139, Train Loss: 0.27307671308517456
[32m[0511 18:28:31 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.30159804224967957, Train Loss: 0.27305155992507935
[32m[0511 18:28:31 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.30159780383110046, Train Loss: 0.27302655577659607
[32m[0511 18:28:31 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.301597535610199, Train Loss: 0.27300167083740234
[32m[0511 18:28:31 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.3015972077846527, Train Loss: 0.27297699451446533
[32m[0511 18:28:31 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.3015967607498169, Train Loss: 0.27295243740081787
[32m[0511 18:28:31 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.3015962839126587, Train Loss: 0.27292805910110474
[32m[0511 18:28:31 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.3015957474708557, Train Loss: 0.27290380001068115
[32m[0511 18:28:31 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.3015950918197632, Train Loss: 0.2728797197341919
[32m[0511 18:28:31 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.30159449577331543, Train Loss: 0.2728557586669922
[32m[0511 18:28:31 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.3015937805175781, Train Loss: 0.2728319764137268
[32m[0511 18:28:31 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.30159303545951843, Train Loss: 0.272808313369751
[32m[0511 18:28:31 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.30159226059913635, Train Loss: 0.2727847993373871
[32m[0511 18:28:31 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.3015914261341095, Train Loss: 0.2727614641189575
[32m[0511 18:28:32 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.30159062147140503, Train Loss: 0.2727382183074951
[32m[0511 18:28:32 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.3015896677970886, Train Loss: 0.27271515130996704
[32m[0511 18:28:32 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.301588773727417, Train Loss: 0.2726922035217285
[32m[0511 18:28:32 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.3015878200531006, Train Loss: 0.27266940474510193
[32m[0511 18:28:32 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.3015868365764618, Train Loss: 0.2726467251777649
[32m[0511 18:28:32 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.3015857934951782, Train Loss: 0.2726241946220398
[32m[0511 18:28:32 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.30158472061157227, Train Loss: 0.27260181307792664
[32m[0511 18:28:32 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.3015837073326111, Train Loss: 0.2725795805454254
[32m[0511 18:28:32 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.30158260464668274, Train Loss: 0.27255743741989136
[32m[0511 18:28:32 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.301581472158432, Train Loss: 0.2725354731082916
[32m[0511 18:28:32 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.30158036947250366, Train Loss: 0.27251359820365906
[32m[0511 18:28:32 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.30157917737960815, Train Loss: 0.2724918723106384
[32m[0511 18:28:32 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.3015780746936798, Train Loss: 0.27247029542922974
[32m[0511 18:28:32 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.3015768826007843, Train Loss: 0.2724488377571106
[32m[0511 18:28:32 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.301575630903244, Train Loss: 0.2724274694919586
[32m[0511 18:28:32 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.3015744388103485, Train Loss: 0.2724062502384186
[32m[0511 18:28:32 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.301573246717453, Train Loss: 0.2723851799964905
[32m[0511 18:28:32 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.3015719950199127, Train Loss: 0.27236419916152954
[32m[0511 18:28:32 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.30157074332237244, Train Loss: 0.27234333753585815
[32m[0511 18:28:32 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.30156949162483215, Train Loss: 0.2723226249217987
[32m[0511 18:28:32 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.30156829953193665, Train Loss: 0.2723020315170288
[32m[0511 18:28:32 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.3015669882297516, Train Loss: 0.27228155732154846
[32m[0511 18:28:32 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.3015657365322113, Train Loss: 0.27226120233535767
[32m[0511 18:28:32 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.30156445503234863, Train Loss: 0.2722409665584564
[32m[0511 18:28:32 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.30156323313713074, Train Loss: 0.27222082018852234
[32m[0511 18:28:32 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.3015618920326233, Train Loss: 0.2722008228302002
[32m[0511 18:28:32 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.3015606105327606, Train Loss: 0.2721809446811676
[32m[0511 18:28:33 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.30155932903289795, Train Loss: 0.27216118574142456
[32m[0511 18:28:33 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.3015580475330353, Train Loss: 0.2721415162086487
[32m[0511 18:28:33 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.3015567660331726, Train Loss: 0.27212196588516235
[32m[0511 18:28:33 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.30155545473098755, Train Loss: 0.2721025347709656
[32m[0511 18:28:33 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.30155420303344727, Train Loss: 0.27208322286605835
[32m[0511 18:28:33 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.3015528917312622, Train Loss: 0.2720640003681183
[32m[0511 18:28:33 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.3015516400337219, Train Loss: 0.2720448970794678
[32m[0511 18:28:33 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.30155032873153687, Train Loss: 0.2720259428024292
[32m[0511 18:28:33 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.3015490472316742, Train Loss: 0.2720070481300354
[32m[0511 18:28:33 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.3015477657318115, Train Loss: 0.27198827266693115
[32m[0511 18:28:33 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.30154648423194885, Train Loss: 0.27196961641311646
[32m[0511 18:28:33 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.3015452027320862, Train Loss: 0.2719510495662689
[32m[0511 18:28:33 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.3015439510345459, Train Loss: 0.27193260192871094
[32m[0511 18:28:33 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.301542729139328, Train Loss: 0.2719142436981201
[32m[0511 18:28:33 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.30154141783714294, Train Loss: 0.27189600467681885
[32m[0511 18:28:33 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.30154016613960266, Train Loss: 0.27187785506248474
[32m[0511 18:28:33 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.3015389144420624, Train Loss: 0.2718598544597626
[32m[0511 18:28:33 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.3015376627445221, Train Loss: 0.2718418836593628
[32m[0511 18:28:33 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.3015364408493042, Train Loss: 0.27182406187057495
[32m[0511 18:28:33 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.3015352189540863, Train Loss: 0.2718062996864319
[32m[0511 18:28:33 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.301533967256546, Train Loss: 0.27178865671157837
[32m[0511 18:28:33 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.3015327453613281, Train Loss: 0.2717711329460144
[32m[0511 18:28:33 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.30153149366378784, Train Loss: 0.2717536985874176
[32m[0511 18:28:33 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.30153030157089233, Train Loss: 0.2717363238334656
[32m[0511 18:28:33 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.3015291094779968, Train Loss: 0.2717190980911255
[32m[0511 18:28:33 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.30152785778045654, Train Loss: 0.2717019319534302
[32m[0511 18:28:33 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.30152666568756104, Train Loss: 0.2716849148273468
[32m[0511 18:28:34 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.3015255033969879, Train Loss: 0.2716679275035858
[32m[0511 18:28:34 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.3015243113040924, Train Loss: 0.27165108919143677
[32m[0511 18:28:34 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.3015230894088745, Train Loss: 0.2716342806816101
[32m[0511 18:28:34 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.3015219569206238, Train Loss: 0.271617591381073
[32m[0511 18:28:34 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.30152079463005066, Train Loss: 0.27160102128982544
[32m[0511 18:28:34 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.30151960253715515, Train Loss: 0.27158451080322266
[32m[0511 18:28:34 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.30151844024658203, Train Loss: 0.2715681195259094
[32m[0511 18:28:34 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.3015173375606537, Train Loss: 0.2715517580509186
[32m[0511 18:28:34 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.30151617527008057, Train Loss: 0.2715355157852173
[32m[0511 18:28:34 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.30151501297950745, Train Loss: 0.27151936292648315
[32m[0511 18:28:34 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.3015139102935791, Train Loss: 0.2715033292770386
[32m[0511 18:28:34 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.301512748003006, Train Loss: 0.27148735523223877
[32m[0511 18:28:34 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.30151161551475525, Train Loss: 0.27147144079208374
[32m[0511 18:28:34 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.3015105128288269, Train Loss: 0.27145564556121826
[32m[0511 18:28:34 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.30150941014289856, Train Loss: 0.27143990993499756
[32m[0511 18:28:34 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.3015083074569702, Train Loss: 0.2714242935180664
[32m[0511 18:28:34 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.30150720477104187, Train Loss: 0.27140873670578003
[32m[0511 18:28:34 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.3015061616897583, Train Loss: 0.2713932394981384
[32m[0511 18:28:34 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.30150505900382996, Train Loss: 0.2713778614997864
[32m[0511 18:28:34 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.301503986120224, Train Loss: 0.2713625431060791
[32m[0511 18:28:34 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.30150291323661804, Train Loss: 0.2713472843170166
[32m[0511 18:28:34 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.3015018403530121, Train Loss: 0.27133214473724365
[32m[0511 18:28:34 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.30150076746940613, Train Loss: 0.2713170647621155
[32m[0511 18:28:34 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.30149972438812256, Train Loss: 0.27130210399627686
[32m[0511 18:28:34 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.301498681306839, Train Loss: 0.271287202835083
[32m[0511 18:28:34 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.30149760842323303, Train Loss: 0.27127233147621155
[32m[0511 18:28:34 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.30149656534194946, Train Loss: 0.27125757932662964
[32m[0511 18:28:34 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.3014955520629883, Train Loss: 0.2712428867816925
[32m[0511 18:28:35 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.3014945387840271, Train Loss: 0.27122825384140015
[32m[0511 18:28:35 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.30149349570274353, Train Loss: 0.27121371030807495
[32m[0511 18:28:35 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.30149248242378235, Train Loss: 0.27119922637939453
[32m[0511 18:28:35 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.3014914393424988, Train Loss: 0.27118486166000366
[32m[0511 18:28:35 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.3014904260635376, Train Loss: 0.2711705267429352
[32m[0511 18:28:35 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.3014894127845764, Train Loss: 0.27115628123283386
[32m[0511 18:28:35 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.3014884293079376, Train Loss: 0.2711420953273773
[32m[0511 18:28:35 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.30148744583129883, Train Loss: 0.27112799882888794
[32m[0511 18:28:35 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.30148640275001526, Train Loss: 0.27111393213272095
[32m[0511 18:28:35 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.30148541927337646, Train Loss: 0.2710999846458435
[32m[0511 18:28:35 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.30148443579673767, Train Loss: 0.27108609676361084
[32m[0511 18:28:35 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.3014834523200989, Train Loss: 0.27107223868370056
[32m[0511 18:28:35 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.3014824688434601, Train Loss: 0.27105849981307983
[32m[0511 18:28:35 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.3014814853668213, Train Loss: 0.2710447907447815
[32m[0511 18:28:35 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.3014805018901825, Train Loss: 0.27103114128112793
[32m[0511 18:28:35 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.3014795780181885, Train Loss: 0.27101758122444153
[32m[0511 18:28:35 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.30147862434387207, Train Loss: 0.2710040807723999
[32m[0511 18:28:35 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.3014776408672333, Train Loss: 0.27099061012268066
[32m[0511 18:28:35 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.30147668719291687, Train Loss: 0.270977258682251
[32m[0511 18:28:35 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.30147576332092285, Train Loss: 0.27096396684646606
[32m[0511 18:28:35 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.30147477984428406, Train Loss: 0.27095070481300354
[32m[0511 18:28:35 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.30147382616996765, Train Loss: 0.2709375023841858
[32m[0511 18:28:35 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.30147290229797363, Train Loss: 0.2709243893623352
[32m[0511 18:28:35 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.30147191882133484, Train Loss: 0.2709113359451294
[32m[0511 18:28:35 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.3014709949493408, Train Loss: 0.27089831233024597
[32m[0511 18:28:35 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.301470011472702, Train Loss: 0.2708853483200073
[32m[0511 18:28:35 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.301469087600708, Train Loss: 0.27087247371673584
[32m[0511 18:28:36 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.3014681041240692, Train Loss: 0.27085965871810913
[32m[0511 18:28:36 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.3014672100543976, Train Loss: 0.2708469033241272
[32m[0511 18:28:36 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.30146631598472595, Train Loss: 0.27083417773246765
[32m[0511 18:28:36 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.30146539211273193, Train Loss: 0.2708215117454529
[32m[0511 18:28:36 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.3014644682407379, Train Loss: 0.2708089351654053
[32m[0511 18:28:36 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.3014635443687439, Train Loss: 0.27079638838768005
[32m[0511 18:28:36 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.3014626204967499, Train Loss: 0.2707838714122772
[32m[0511 18:28:36 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.30146166682243347, Train Loss: 0.27077147364616394
[32m[0511 18:28:36 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.30146077275276184, Train Loss: 0.27075910568237305
[32m[0511 18:28:36 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.30145981907844543, Train Loss: 0.27074676752090454
[32m[0511 18:28:36 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.3014589250087738, Train Loss: 0.2707344889640808
[32m[0511 18:28:36 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.3014580309391022, Train Loss: 0.27072227001190186
[32m[0511 18:28:36 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.30145707726478577, Train Loss: 0.2707101106643677
[32m[0511 18:28:36 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.30145618319511414, Train Loss: 0.27069801092147827
[32m[0511 18:28:36 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.3014552593231201, Train Loss: 0.27068594098091125
[32m[0511 18:28:36 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.3014543354511261, Train Loss: 0.270673930644989
[32m[0511 18:28:36 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.30145344138145447, Train Loss: 0.27066195011138916
[32m[0511 18:28:36 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.30145248770713806, Train Loss: 0.27065008878707886
[32m[0511 18:28:36 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.3014516532421112, Train Loss: 0.27063822746276855
[32m[0511 18:28:36 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.3014506995677948, Train Loss: 0.27062639594078064
[32m[0511 18:28:36 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.30144980549812317, Train Loss: 0.2706146240234375
[32m[0511 18:28:36 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.30144888162612915, Train Loss: 0.27060291171073914
[32m[0511 18:28:36 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.3014480173587799, Train Loss: 0.27059125900268555
[32m[0511 18:28:36 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.3014470934867859, Train Loss: 0.27057963609695435
[32m[0511 18:28:36 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.30144619941711426, Train Loss: 0.2705680727958679
[32m[0511 18:28:36 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.301445335149765, Train Loss: 0.2705565392971039
[32m[0511 18:28:36 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.301444411277771, Train Loss: 0.2705450654029846
[32m[0511 18:28:37 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.301443487405777, Train Loss: 0.27053362131118774
[32m[0511 18:28:37 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.30144256353378296, Train Loss: 0.27052223682403564
[32m[0511 18:28:37 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.30144166946411133, Train Loss: 0.2705109119415283
[32m[0511 18:28:37 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.3014407455921173, Train Loss: 0.270499587059021
[32m[0511 18:28:37 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.3014398217201233, Train Loss: 0.27048832178115845
[32m[0511 18:28:37 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.30143895745277405, Train Loss: 0.2704771161079407
[32m[0511 18:28:37 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.30143803358078003, Train Loss: 0.2704659402370453
[32m[0511 18:28:37 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.301437109708786, Train Loss: 0.2704548239707947
[32m[0511 18:28:37 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.30143624544143677, Train Loss: 0.27044373750686646
[32m[0511 18:28:37 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.30143532156944275, Train Loss: 0.2704326808452606
[32m[0511 18:28:37 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.3014344573020935, Train Loss: 0.27042168378829956
[32m[0511 18:28:37 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.3014335036277771, Train Loss: 0.2704107165336609
[32m[0511 18:28:37 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.30143263936042786, Train Loss: 0.2703997492790222
[32m[0511 18:28:37 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.30143171548843384, Train Loss: 0.2703889012336731
[32m[0511 18:28:37 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.3014307916164398, Train Loss: 0.270378053188324
[32m[0511 18:28:37 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.3014298677444458, Train Loss: 0.27036720514297485
[32m[0511 18:28:37 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.30142897367477417, Train Loss: 0.2703564763069153
[32m[0511 18:28:37 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.30142802000045776, Train Loss: 0.2703457474708557
[32m[0511 18:28:37 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.30142709612846375, Train Loss: 0.27033501863479614
[32m[0511 18:28:37 @mbmf_sampler.py:98][0m Finished 4th episode
[32m[0511 18:28:37 @mbmf_sampler.py:102][0m 2004 timesteps from 4 episodes collected
[32m[0511 18:54:44 @mbmf_trainer.py:160][0m Mean reward: -421.3677903507454
[32m[0511 18:54:45 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.2957535982131958, Train Loss: 0.29000911116600037
[32m[0511 18:54:45 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.2951209545135498, Train Loss: 0.289077490568161
[32m[0511 18:54:45 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.2945617437362671, Train Loss: 0.2882062792778015
[32m[0511 18:54:45 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.29414522647857666, Train Loss: 0.287530779838562
[32m[0511 18:54:45 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.2938160300254822, Train Loss: 0.2869718670845032
[32m[0511 18:54:45 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.29355353116989136, Train Loss: 0.2865047752857208
[32m[0511 18:54:45 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.29334723949432373, Train Loss: 0.28610706329345703
[32m[0511 18:54:45 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.29318374395370483, Train Loss: 0.28576359152793884
[32m[0511 18:54:45 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.29305312037467957, Train Loss: 0.28546324372291565
[32m[0511 18:54:45 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.29294833540916443, Train Loss: 0.2851976752281189
[32m[0511 18:54:45 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.29286372661590576, Train Loss: 0.28496065735816956
[32m[0511 18:54:45 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.29279497265815735, Train Loss: 0.28474730253219604
[32m[0511 18:54:45 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.29273876547813416, Train Loss: 0.2845538258552551
[32m[0511 18:54:45 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.2926924526691437, Train Loss: 0.28437724709510803
[32m[0511 18:54:45 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.2926540970802307, Train Loss: 0.2842150628566742
[32m[0511 18:54:45 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.29262202978134155, Train Loss: 0.28406521677970886
[32m[0511 18:54:45 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.29259493947029114, Train Loss: 0.28392621874809265
[32m[0511 18:54:45 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.2925717830657959, Train Loss: 0.2837965786457062
[32m[0511 18:54:45 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.29255178570747375, Train Loss: 0.28367525339126587
[32m[0511 18:54:45 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.2925342619419098, Train Loss: 0.2835611402988434
[32m[0511 18:54:45 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.29251864552497864, Train Loss: 0.2834535241127014
[32m[0511 18:54:45 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.29250451922416687, Train Loss: 0.2833516597747803
[32m[0511 18:54:46 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.29249152541160583, Train Loss: 0.2832548916339874
[32m[0511 18:54:46 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.2924794554710388, Train Loss: 0.28316283226013184
[32m[0511 18:54:46 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.29246798157691956, Train Loss: 0.2830749452114105
[32m[0511 18:54:46 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.2924569547176361, Train Loss: 0.28299084305763245
[32m[0511 18:54:46 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.2924463152885437, Train Loss: 0.2829102575778961
[32m[0511 18:54:46 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.2924358546733856, Train Loss: 0.28283271193504333
[32m[0511 18:54:46 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.29242557287216187, Train Loss: 0.28275805711746216
[32m[0511 18:54:46 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.2924153208732605, Train Loss: 0.2826860547065735
[32m[0511 18:54:46 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.29240506887435913, Train Loss: 0.282616525888443
[32m[0511 18:54:46 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.29239484667778015, Train Loss: 0.2825492322444916
[32m[0511 18:54:46 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.292384535074234, Train Loss: 0.2824840247631073
[32m[0511 18:54:46 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.2923740744590759, Train Loss: 0.28242072463035583
[32m[0511 18:54:46 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.29236355423927307, Train Loss: 0.28235924243927
[32m[0511 18:54:46 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.29235297441482544, Train Loss: 0.2822994291782379
[32m[0511 18:54:46 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.2923422157764435, Train Loss: 0.28224125504493713
[32m[0511 18:54:46 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.29233139753341675, Train Loss: 0.2821844816207886
[32m[0511 18:54:46 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.2923204302787781, Train Loss: 0.28212910890579224
[32m[0511 18:54:46 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.29230934381484985, Train Loss: 0.28207501769065857
[32m[0511 18:54:46 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.29229822754859924, Train Loss: 0.2820221781730652
[32m[0511 18:54:46 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.2922869324684143, Train Loss: 0.28197047114372253
[32m[0511 18:54:46 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.292275607585907, Train Loss: 0.2819198966026306
[32m[0511 18:54:46 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.2922641336917877, Train Loss: 0.28187036514282227
[32m[0511 18:54:46 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.29225262999534607, Train Loss: 0.28182175755500793
[32m[0511 18:54:46 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.29224103689193726, Train Loss: 0.2817741334438324
[32m[0511 18:54:47 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.29222944378852844, Train Loss: 0.2817274332046509
[32m[0511 18:54:47 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.2922177314758301, Train Loss: 0.2816815674304962
[32m[0511 18:54:47 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.2922060191631317, Train Loss: 0.281636506319046
[32m[0511 18:54:47 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.2921942174434662, Train Loss: 0.2815922498703003
[32m[0511 18:54:47 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.29218238592147827, Train Loss: 0.28154873847961426
[32m[0511 18:54:47 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.29217058420181274, Train Loss: 0.28150588274002075
[32m[0511 18:54:47 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.29215872287750244, Train Loss: 0.2814638018608093
[32m[0511 18:54:47 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.2921469211578369, Train Loss: 0.28142231702804565
[32m[0511 18:54:47 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.2921350598335266, Train Loss: 0.2813815474510193
[32m[0511 18:54:47 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.2921232283115387, Train Loss: 0.2813413441181183
[32m[0511 18:54:47 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.2921113967895508, Train Loss: 0.2813017666339874
[32m[0511 18:54:47 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.29209962487220764, Train Loss: 0.28126275539398193
[32m[0511 18:54:47 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.2920878529548645, Train Loss: 0.2812243103981018
[32m[0511 18:54:47 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.29207608103752136, Train Loss: 0.2811863422393799
[32m[0511 18:54:47 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.2920643389225006, Train Loss: 0.2811489403247833
[32m[0511 18:54:47 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.29205265641212463, Train Loss: 0.28111207485198975
[32m[0511 18:54:47 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.29204100370407104, Train Loss: 0.2810756266117096
[32m[0511 18:54:47 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.29202941060066223, Train Loss: 0.2810397446155548
[32m[0511 18:54:47 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.2920178771018982, Train Loss: 0.28100425004959106
[32m[0511 18:54:47 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.29200640320777893, Train Loss: 0.2809692919254303
[32m[0511 18:54:47 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.29199492931365967, Train Loss: 0.2809346914291382
[32m[0511 18:54:47 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.29198360443115234, Train Loss: 0.2809005677700043
[32m[0511 18:54:47 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.291972279548645, Train Loss: 0.2808668613433838
[32m[0511 18:54:48 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.29196107387542725, Train Loss: 0.28083351254463196
[32m[0511 18:54:48 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.2919498682022095, Train Loss: 0.28080061078071594
[32m[0511 18:54:48 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.29193878173828125, Train Loss: 0.28076812624931335
[32m[0511 18:54:48 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.2919277250766754, Train Loss: 0.28073593974113464
[32m[0511 18:54:48 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.29191678762435913, Train Loss: 0.280704140663147
[32m[0511 18:54:48 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.2919059097766876, Train Loss: 0.28067275881767273
[32m[0511 18:54:48 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.2918950617313385, Train Loss: 0.28064170479774475
[32m[0511 18:54:48 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.2918843924999237, Train Loss: 0.2806110084056854
[32m[0511 18:54:48 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.2918737232685089, Train Loss: 0.28058066964149475
[32m[0511 18:54:48 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.29186320304870605, Train Loss: 0.28055059909820557
[32m[0511 18:54:48 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.2918526828289032, Train Loss: 0.28052088618278503
[32m[0511 18:54:48 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.2918423116207123, Train Loss: 0.28049150109291077
[32m[0511 18:54:48 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.29183197021484375, Train Loss: 0.28046247363090515
[32m[0511 18:54:48 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.29182174801826477, Train Loss: 0.28043368458747864
[32m[0511 18:54:48 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.29181161522865295, Train Loss: 0.2804052531719208
[32m[0511 18:54:48 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.2918015122413635, Train Loss: 0.2803770899772644
[32m[0511 18:54:48 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.29179155826568604, Train Loss: 0.2803491950035095
[32m[0511 18:54:48 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.2917816936969757, Train Loss: 0.28032156825065613
[32m[0511 18:54:48 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.29177191853523254, Train Loss: 0.2802943289279938
[32m[0511 18:54:48 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.29176217317581177, Train Loss: 0.28026723861694336
[32m[0511 18:54:48 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.29175257682800293, Train Loss: 0.2802405059337616
[32m[0511 18:54:48 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.29174304008483887, Train Loss: 0.2802140414714813
[32m[0511 18:54:48 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.2917335629463196, Train Loss: 0.28018784523010254
[32m[0511 18:54:49 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.29172423481941223, Train Loss: 0.28016185760498047
[32m[0511 18:54:49 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.29171496629714966, Train Loss: 0.2801361382007599
[32m[0511 18:54:49 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.2917056977748871, Train Loss: 0.2801106572151184
[32m[0511 18:54:49 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.29169660806655884, Train Loss: 0.2800854444503784
[32m[0511 18:54:49 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.29168760776519775, Train Loss: 0.28006044030189514
[32m[0511 18:54:49 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.29167860746383667, Train Loss: 0.28003567457199097
[32m[0511 18:54:49 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.2916697561740875, Train Loss: 0.2800111472606659
[32m[0511 18:54:49 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.29166093468666077, Train Loss: 0.2799869179725647
[32m[0511 18:54:49 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.29165223240852356, Train Loss: 0.2799628674983978
[32m[0511 18:54:49 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.29164358973503113, Train Loss: 0.27993902564048767
[32m[0511 18:54:49 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.29163503646850586, Train Loss: 0.27991539239883423
[32m[0511 18:54:49 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.29162657260894775, Train Loss: 0.2798919975757599
[32m[0511 18:54:49 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.2916181683540344, Train Loss: 0.27986881136894226
[32m[0511 18:54:49 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.29160985350608826, Train Loss: 0.27984580397605896
[32m[0511 18:54:49 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.2916015386581421, Train Loss: 0.27982303500175476
[32m[0511 18:54:49 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.29159340262413025, Train Loss: 0.2798004448413849
[32m[0511 18:54:49 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.2915852665901184, Train Loss: 0.27977806329727173
[32m[0511 18:54:49 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.2915772795677185, Train Loss: 0.2797558605670929
[32m[0511 18:54:49 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.29156923294067383, Train Loss: 0.27973389625549316
[32m[0511 18:54:49 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.2915613353252411, Train Loss: 0.27971208095550537
[32m[0511 18:54:49 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.2915535271167755, Train Loss: 0.2796904742717743
[32m[0511 18:54:49 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.29154571890830994, Train Loss: 0.27966904640197754
[32m[0511 18:54:49 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.2915380597114563, Train Loss: 0.27964773774147034
[32m[0511 18:54:49 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.2915303707122803, Train Loss: 0.2796266973018646
[32m[0511 18:54:50 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.2915228307247162, Train Loss: 0.27960577607154846
[32m[0511 18:54:50 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.2915152907371521, Train Loss: 0.2795850336551666
[32m[0511 18:54:50 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.2915078103542328, Train Loss: 0.2795644998550415
[32m[0511 18:54:50 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.29150038957595825, Train Loss: 0.27954408526420593
[32m[0511 18:54:50 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.2914930284023285, Train Loss: 0.2795238792896271
[32m[0511 18:54:50 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.2914857268333435, Train Loss: 0.27950379252433777
[32m[0511 18:54:50 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.2914784848690033, Train Loss: 0.2794838845729828
[32m[0511 18:54:50 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.2914712727069855, Train Loss: 0.27946415543556213
[32m[0511 18:54:50 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.2914641499519348, Train Loss: 0.2794445753097534
[32m[0511 18:54:50 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.29145708680152893, Train Loss: 0.27942511439323425
[32m[0511 18:54:50 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.29145005345344543, Train Loss: 0.2794058322906494
[32m[0511 18:54:50 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.29144299030303955, Train Loss: 0.2793866991996765
[32m[0511 18:54:50 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.2914360463619232, Train Loss: 0.27936768531799316
[32m[0511 18:54:50 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.29142916202545166, Train Loss: 0.27934882044792175
[32m[0511 18:54:50 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.2914223372936249, Train Loss: 0.2793301045894623
[32m[0511 18:54:50 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.2914155125617981, Train Loss: 0.27931156754493713
[32m[0511 18:54:50 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.2914087176322937, Train Loss: 0.27929309010505676
[32m[0511 18:54:50 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.2914019823074341, Train Loss: 0.2792748212814331
[32m[0511 18:54:50 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.29139527678489685, Train Loss: 0.2792566418647766
[32m[0511 18:54:50 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.2913886606693268, Train Loss: 0.27923861145973206
[32m[0511 18:54:50 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.2913820147514343, Train Loss: 0.27922067046165466
[32m[0511 18:54:50 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.29137539863586426, Train Loss: 0.279202938079834
[32m[0511 18:54:50 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.29136887192726135, Train Loss: 0.2791852653026581
[32m[0511 18:54:50 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.29136234521865845, Train Loss: 0.2791677415370941
[32m[0511 18:54:51 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.29135584831237793, Train Loss: 0.2791502773761749
[32m[0511 18:54:51 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.2913494110107422, Train Loss: 0.27913305163383484
[32m[0511 18:54:51 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.29134297370910645, Train Loss: 0.2791158854961395
[32m[0511 18:54:51 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.2913365960121155, Train Loss: 0.2790988087654114
[32m[0511 18:54:51 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.2913302481174469, Train Loss: 0.27908191084861755
[32m[0511 18:54:51 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.2913239002227783, Train Loss: 0.2790650427341461
[32m[0511 18:54:51 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.29131758213043213, Train Loss: 0.279048353433609
[32m[0511 18:54:51 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.2913113236427307, Train Loss: 0.27903175354003906
[32m[0511 18:54:51 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.2913050651550293, Train Loss: 0.2790152430534363
[32m[0511 18:54:51 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.29129883646965027, Train Loss: 0.27899882197380066
[32m[0511 18:54:51 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.29129260778427124, Train Loss: 0.278982549905777
[32m[0511 18:54:51 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.291286438703537, Train Loss: 0.27896636724472046
[32m[0511 18:54:51 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.2912802994251251, Train Loss: 0.2789503037929535
[32m[0511 18:54:51 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.2912741005420685, Train Loss: 0.2789342999458313
[32m[0511 18:54:51 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.2912679612636566, Train Loss: 0.27891841530799866
[32m[0511 18:54:51 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.2912619113922119, Train Loss: 0.2789026200771332
[32m[0511 18:54:51 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.29125580191612244, Train Loss: 0.27888694405555725
[32m[0511 18:54:51 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.29124972224235535, Train Loss: 0.2788713872432709
[32m[0511 18:54:51 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.29124370217323303, Train Loss: 0.2788558602333069
[32m[0511 18:54:51 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.29123765230178833, Train Loss: 0.27884042263031006
[32m[0511 18:54:51 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.2912316620349884, Train Loss: 0.2788251042366028
[32m[0511 18:54:51 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.2912255823612213, Train Loss: 0.27880987524986267
[32m[0511 18:54:51 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.2912196218967438, Train Loss: 0.27879470586776733
[32m[0511 18:54:51 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.29121363162994385, Train Loss: 0.27877968549728394
[32m[0511 18:54:52 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.2912076711654663, Train Loss: 0.2787646949291229
[32m[0511 18:54:52 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.29120171070098877, Train Loss: 0.27874982357025146
[32m[0511 18:54:52 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.291195809841156, Train Loss: 0.27873504161834717
[32m[0511 18:54:52 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.29118984937667847, Train Loss: 0.27872028946876526
[32m[0511 18:54:52 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.2911839187145233, Train Loss: 0.2787056565284729
[32m[0511 18:54:52 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.29117801785469055, Train Loss: 0.27869105339050293
[32m[0511 18:54:52 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.2911720871925354, Train Loss: 0.2786765992641449
[32m[0511 18:54:52 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.291166216135025, Train Loss: 0.27866223454475403
[32m[0511 18:54:52 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.29116034507751465, Train Loss: 0.27864784002304077
[32m[0511 18:54:52 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.2911544442176819, Train Loss: 0.27863359451293945
[32m[0511 18:54:52 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.2911485731601715, Train Loss: 0.2786194086074829
[32m[0511 18:54:52 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.2911427319049835, Train Loss: 0.27860528230667114
[32m[0511 18:54:52 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.29113686084747314, Train Loss: 0.27859124541282654
[32m[0511 18:54:52 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.29113101959228516, Train Loss: 0.2785772681236267
[32m[0511 18:54:52 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.29112517833709717, Train Loss: 0.27856338024139404
[32m[0511 18:54:52 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.29111936688423157, Train Loss: 0.27854955196380615
[32m[0511 18:54:52 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.2911134958267212, Train Loss: 0.27853578329086304
[32m[0511 18:54:52 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.2911076843738556, Train Loss: 0.2785220742225647
[32m[0511 18:54:52 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.2911019027233124, Train Loss: 0.27850842475891113
[32m[0511 18:54:52 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.291096031665802, Train Loss: 0.2784948945045471
[32m[0511 18:54:52 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.2910902202129364, Train Loss: 0.2784813940525055
[32m[0511 18:54:52 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.2910844385623932, Train Loss: 0.27846798300743103
[32m[0511 18:54:52 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.2910786271095276, Train Loss: 0.2784545421600342
[32m[0511 18:54:53 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.291072815656662, Train Loss: 0.27844125032424927
[32m[0511 18:54:53 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.2910670042037964, Train Loss: 0.27842798829078674
[32m[0511 18:54:53 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.2910611927509308, Train Loss: 0.2784148156642914
[32m[0511 18:54:53 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.2910554111003876, Train Loss: 0.2784016728401184
[32m[0511 18:54:53 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.291049599647522, Train Loss: 0.2783885896205902
[32m[0511 18:54:53 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.29104387760162354, Train Loss: 0.2783755958080292
[32m[0511 18:54:53 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.29103803634643555, Train Loss: 0.27836260199546814
[32m[0511 18:54:53 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.29103225469589233, Train Loss: 0.27834969758987427
[32m[0511 18:54:53 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.2910264730453491, Train Loss: 0.27833685278892517
[32m[0511 18:54:53 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.2910206615924835, Train Loss: 0.27832403779029846
[32m[0511 18:54:53 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.2910148799419403, Train Loss: 0.2783113121986389
[32m[0511 18:54:53 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.2910090982913971, Train Loss: 0.27829858660697937
[32m[0511 18:54:53 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.2910032868385315, Train Loss: 0.278285950422287
[32m[0511 18:54:53 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.29099753499031067, Train Loss: 0.2782733738422394
[32m[0511 18:54:53 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.29099175333976746, Train Loss: 0.27826082706451416
[32m[0511 18:54:53 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.29098594188690186, Train Loss: 0.2782483994960785
[32m[0511 18:54:53 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.29098016023635864, Train Loss: 0.27823591232299805
[32m[0511 18:54:53 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.29097434878349304, Train Loss: 0.27822351455688477
[32m[0511 18:54:53 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.29096856713294983, Train Loss: 0.27821117639541626
[32m[0511 18:54:53 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.2909627854824066, Train Loss: 0.27819889783859253
[32m[0511 18:54:53 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.2909570336341858, Train Loss: 0.2781866192817688
[32m[0511 18:54:53 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.2909512221813202, Train Loss: 0.27817443013191223
[32m[0511 18:54:53 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.290945440530777, Train Loss: 0.27816224098205566
[32m[0511 18:54:53 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.2909396290779114, Train Loss: 0.27815020084381104
[32m[0511 18:54:54 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.2909338176250458, Train Loss: 0.27813810110092163
[32m[0511 18:54:54 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.29092803597450256, Train Loss: 0.2781261205673218
[32m[0511 18:54:54 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.29092225432395935, Train Loss: 0.2781141400337219
[32m[0511 18:54:54 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.29091644287109375, Train Loss: 0.27810215950012207
[32m[0511 18:54:54 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.29091063141822815, Train Loss: 0.2780902683734894
[32m[0511 18:54:54 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.29090484976768494, Train Loss: 0.27807846665382385
[32m[0511 18:54:54 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.2908990681171417, Train Loss: 0.27806663513183594
[32m[0511 18:54:54 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.2908932566642761, Train Loss: 0.2780548930168152
[32m[0511 18:54:54 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.2908874452114105, Train Loss: 0.27804315090179443
[32m[0511 18:54:54 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.2908816337585449, Train Loss: 0.27803146839141846
[32m[0511 18:54:54 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.2908758521080017, Train Loss: 0.27801981568336487
[32m[0511 18:54:54 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.2908700108528137, Train Loss: 0.27800822257995605
[32m[0511 18:54:54 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.2908642292022705, Train Loss: 0.27799662947654724
[32m[0511 18:54:54 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.2908583879470825, Train Loss: 0.2779851257801056
[32m[0511 18:54:54 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.2908525764942169, Train Loss: 0.27797359228134155
[32m[0511 18:54:54 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.2908467650413513, Train Loss: 0.2779621481895447
[32m[0511 18:54:54 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.2908409535884857, Train Loss: 0.2779507339000702
[32m[0511 18:54:54 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.29083508253097534, Train Loss: 0.2779393792152405
[32m[0511 18:54:54 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.29082930088043213, Train Loss: 0.2779279947280884
[32m[0511 18:54:54 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.29082345962524414, Train Loss: 0.27791666984558105
[32m[0511 18:54:54 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.29081764817237854, Train Loss: 0.2779054045677185
[32m[0511 18:54:54 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.29081183671951294, Train Loss: 0.27789413928985596
[32m[0511 18:54:54 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.29080602526664734, Train Loss: 0.27788296341896057
[32m[0511 18:54:54 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.29080015420913696, Train Loss: 0.2778717875480652
[32m[0511 18:54:55 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.29079437255859375, Train Loss: 0.2778606414794922
[32m[0511 18:54:55 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.2907885015010834, Train Loss: 0.2778495252132416
[32m[0511 18:54:55 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.2907826900482178, Train Loss: 0.27783846855163574
[32m[0511 18:54:55 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.2907768785953522, Train Loss: 0.2778274118900299
[32m[0511 18:54:55 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.2907710075378418, Train Loss: 0.27781641483306885
[32m[0511 18:54:55 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.2907651960849762, Train Loss: 0.2778054177761078
[32m[0511 18:54:55 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.2907593548297882, Train Loss: 0.2777944505214691
[32m[0511 18:54:55 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.2907535433769226, Train Loss: 0.2777835726737976
[32m[0511 18:54:55 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.29074767231941223, Train Loss: 0.2777726650238037
[32m[0511 18:54:55 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.290741890668869, Train Loss: 0.277761846780777
[32m[0511 18:54:55 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.29073598980903625, Train Loss: 0.27775099873542786
[32m[0511 18:54:55 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.29073020815849304, Train Loss: 0.2777402102947235
[32m[0511 18:54:55 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.29072433710098267, Train Loss: 0.27772942185401917
[32m[0511 18:54:55 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.2907184660434723, Train Loss: 0.2777186930179596
[32m[0511 18:54:55 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.2907126247882843, Train Loss: 0.2777079641819
[32m[0511 18:54:55 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.2907067835330963, Train Loss: 0.2776973247528076
[32m[0511 18:54:55 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.2907009720802307, Train Loss: 0.2776866853237152
[32m[0511 18:54:55 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.2906951606273651, Train Loss: 0.2776760756969452
[32m[0511 18:54:55 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.29068928956985474, Train Loss: 0.2776654362678528
[32m[0511 18:54:55 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.29068344831466675, Train Loss: 0.27765488624572754
[32m[0511 18:54:55 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.29067763686180115, Train Loss: 0.2776443064212799
[32m[0511 18:54:55 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.29067176580429077, Train Loss: 0.27763381600379944
[32m[0511 18:54:55 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.29066595435142517, Train Loss: 0.27762335538864136
[32m[0511 18:54:55 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.29066014289855957, Train Loss: 0.2776128947734833
[32m[0511 18:54:55 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.2906542718410492, Train Loss: 0.2776023745536804
[32m[0511 18:54:56 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.2906484305858612, Train Loss: 0.2775920331478119
[32m[0511 18:54:56 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.29064255952835083, Train Loss: 0.2775816321372986
[32m[0511 18:54:56 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.2906367778778076, Train Loss: 0.27757129073143005
[32m[0511 18:54:56 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.29063093662261963, Train Loss: 0.2775609493255615
[32m[0511 18:54:56 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.29062509536743164, Train Loss: 0.277550607919693
[32m[0511 18:54:56 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.29061928391456604, Train Loss: 0.27754029631614685
[32m[0511 18:54:56 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.29061347246170044, Train Loss: 0.27753007411956787
[32m[0511 18:54:56 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.29060763120651245, Train Loss: 0.2775198221206665
[32m[0511 18:54:56 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.29060184955596924, Train Loss: 0.2775095999240875
[32m[0511 18:54:56 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.29059600830078125, Train Loss: 0.27749940752983093
[32m[0511 18:54:56 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.29059016704559326, Train Loss: 0.2774892747402191
[32m[0511 18:54:56 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.29058435559272766, Train Loss: 0.2774790823459625
[32m[0511 18:54:56 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.29057854413986206, Train Loss: 0.2774689793586731
[32m[0511 18:54:56 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.29057273268699646, Train Loss: 0.27745890617370605
[32m[0511 18:54:56 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.29056695103645325, Train Loss: 0.27744877338409424
[32m[0511 18:54:56 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.29056113958358765, Train Loss: 0.2774387300014496
[32m[0511 18:54:56 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.29055532813072205, Train Loss: 0.27742868661880493
[32m[0511 18:54:56 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.29054948687553406, Train Loss: 0.27741870284080505
[32m[0511 18:54:56 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.29054373502731323, Train Loss: 0.2774086892604828
[32m[0511 18:54:56 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.29053795337677, Train Loss: 0.2773987054824829
[32m[0511 18:54:56 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.2905322015285492, Train Loss: 0.2773888111114502
[32m[0511 18:54:56 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.2905263602733612, Train Loss: 0.2773788273334503
[32m[0511 18:54:56 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.2905206084251404, Train Loss: 0.2773689329624176
[32m[0511 18:54:57 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.29051482677459717, Train Loss: 0.2773590683937073
[32m[0511 18:54:57 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.29050904512405396, Train Loss: 0.27734917402267456
[32m[0511 18:54:57 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.29050329327583313, Train Loss: 0.2773393392562866
[32m[0511 18:54:57 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.2904975116252899, Train Loss: 0.27732953429222107
[32m[0511 18:54:57 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.2904917895793915, Train Loss: 0.27731969952583313
[32m[0511 18:54:57 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.29048600792884827, Train Loss: 0.27730992436408997
[32m[0511 18:54:57 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.29048028588294983, Train Loss: 0.2773001790046692
[32m[0511 18:54:57 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.290474534034729, Train Loss: 0.2772904336452484
[32m[0511 18:54:57 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.2904687821865082, Train Loss: 0.27728068828582764
[32m[0511 18:54:57 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.29046303033828735, Train Loss: 0.27727097272872925
[32m[0511 18:54:57 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.2904573082923889, Train Loss: 0.27726128697395325
[32m[0511 18:54:57 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.2904515862464905, Train Loss: 0.27725163102149963
[32m[0511 18:54:57 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.29044586420059204, Train Loss: 0.27724194526672363
[32m[0511 18:54:57 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.290440171957016, Train Loss: 0.2772323191165924
[32m[0511 18:54:57 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.29043442010879517, Train Loss: 0.27722272276878357
[32m[0511 18:54:57 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.2904287576675415, Train Loss: 0.27721306681632996
[32m[0511 18:54:57 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.29042306542396545, Train Loss: 0.2772034704685211
[32m[0511 18:54:58 @mbmf_sampler.py:98][0m Finished 4th episode
[32m[0511 18:54:58 @mbmf_sampler.py:102][0m 2004 timesteps from 4 episodes collected
[32m[0511 19:21:07 @mbmf_trainer.py:160][0m Mean reward: -402.28825052533733
[32m[0511 19:21:07 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.2918306589126587, Train Loss: 0.2885558605194092
[32m[0511 19:21:07 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.2904522120952606, Train Loss: 0.2869674563407898
[32m[0511 19:21:07 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.2906413674354553, Train Loss: 0.28616863489151
[32m[0511 19:21:07 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.2904195189476013, Train Loss: 0.2856394648551941
[32m[0511 19:21:07 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.2903449833393097, Train Loss: 0.2852804660797119
[32m[0511 19:21:07 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.2902413308620453, Train Loss: 0.2849906384944916
[32m[0511 19:21:07 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.29014623165130615, Train Loss: 0.2847418785095215
[32m[0511 19:21:07 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.2900449335575104, Train Loss: 0.2845199704170227
[32m[0511 19:21:07 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.28994256258010864, Train Loss: 0.2843179702758789
[32m[0511 19:21:07 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.2898389399051666, Train Loss: 0.2841309607028961
[32m[0511 19:21:07 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.2897353172302246, Train Loss: 0.2839561402797699
[32m[0511 19:21:07 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.28963232040405273, Train Loss: 0.2837914526462555
[32m[0511 19:21:07 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.2895304262638092, Train Loss: 0.2836354374885559
[32m[0511 19:21:07 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.28942999243736267, Train Loss: 0.2834870517253876
[32m[0511 19:21:07 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.28933119773864746, Train Loss: 0.2833453118801117
[32m[0511 19:21:07 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.2892342507839203, Train Loss: 0.2832096815109253
[32m[0511 19:21:07 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.2891392111778259, Train Loss: 0.28307950496673584
[32m[0511 19:21:07 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.2890462577342987, Train Loss: 0.28295427560806274
[32m[0511 19:21:08 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.2889552712440491, Train Loss: 0.28283366560935974
[32m[0511 19:21:08 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.2888663411140442, Train Loss: 0.2827173173427582
[32m[0511 19:21:08 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.28877946734428406, Train Loss: 0.2826048731803894
[32m[0511 19:21:08 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.2886946499347687, Train Loss: 0.28249603509902954
[32m[0511 19:21:08 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.28861182928085327, Train Loss: 0.28239068388938904
[32m[0511 19:21:08 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.28853103518486023, Train Loss: 0.2822885513305664
[32m[0511 19:21:08 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.2884521186351776, Train Loss: 0.28218939900398254
[32m[0511 19:21:08 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.2883751094341278, Train Loss: 0.2820930480957031
[32m[0511 19:21:08 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.28829994797706604, Train Loss: 0.2819993793964386
[32m[0511 19:21:08 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.2882266342639923, Train Loss: 0.2819082736968994
[32m[0511 19:21:08 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.28815507888793945, Train Loss: 0.28181955218315125
[32m[0511 19:21:08 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.28808513283729553, Train Loss: 0.28173306584358215
[32m[0511 19:21:08 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.2880168855190277, Train Loss: 0.281648725271225
[32m[0511 19:21:08 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.28795021772384644, Train Loss: 0.2815665304660797
[32m[0511 19:21:08 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.2878850996494293, Train Loss: 0.28148624300956726
[32m[0511 19:21:08 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.2878214418888092, Train Loss: 0.28140777349472046
[32m[0511 19:21:08 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.28775930404663086, Train Loss: 0.2813311517238617
[32m[0511 19:21:08 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.2876984775066376, Train Loss: 0.28125616908073425
[32m[0511 19:21:08 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.28763899207115173, Train Loss: 0.2811828851699829
[32m[0511 19:21:09 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.28758084774017334, Train Loss: 0.28111112117767334
[32m[0511 19:21:09 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.28752389550209045, Train Loss: 0.28104087710380554
[32m[0511 19:21:09 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.28746816515922546, Train Loss: 0.28097206354141235
[32m[0511 19:21:09 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.2874135971069336, Train Loss: 0.2809045910835266
[32m[0511 19:21:09 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.28736016154289246, Train Loss: 0.2808384597301483
[32m[0511 19:21:09 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.2873077988624573, Train Loss: 0.28077366948127747
[32m[0511 19:21:09 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.28725650906562805, Train Loss: 0.28071004152297974
[32m[0511 19:21:09 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.2872062027454376, Train Loss: 0.2806475758552551
[32m[0511 19:21:09 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.2871568500995636, Train Loss: 0.28058627247810364
[32m[0511 19:21:09 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.287108451128006, Train Loss: 0.28052613139152527
[32m[0511 19:21:09 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.28706094622612, Train Loss: 0.2804669737815857
[32m[0511 19:21:09 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.287014365196228, Train Loss: 0.28040891885757446
[32m[0511 19:21:09 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.2869685888290405, Train Loss: 0.28035181760787964
[32m[0511 19:21:09 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.28692367672920227, Train Loss: 0.28029564023017883
[32m[0511 19:21:09 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.2868795096874237, Train Loss: 0.28024041652679443
[32m[0511 19:21:09 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.2868361473083496, Train Loss: 0.28018611669540405
[32m[0511 19:21:09 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.2867935299873352, Train Loss: 0.2801326513290405
[32m[0511 19:21:09 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.2867516577243805, Train Loss: 0.28008005023002625
[32m[0511 19:21:09 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.2867104411125183, Train Loss: 0.2800282835960388
[32m[0511 19:21:10 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.28666990995407104, Train Loss: 0.27997729182243347
[32m[0511 19:21:10 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.2866300642490387, Train Loss: 0.2799270749092102
[32m[0511 19:21:10 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.2865908443927765, Train Loss: 0.27987757325172424
[32m[0511 19:21:10 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.28655222058296204, Train Loss: 0.27982887625694275
[32m[0511 19:21:10 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.2865142226219177, Train Loss: 0.2797808051109314
[32m[0511 19:21:10 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.28647685050964355, Train Loss: 0.27973347902297974
[32m[0511 19:21:10 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.28643998503685, Train Loss: 0.2796867787837982
[32m[0511 19:21:10 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.28640368580818176, Train Loss: 0.2796407639980316
[32m[0511 19:21:10 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.2863679528236389, Train Loss: 0.279595285654068
[32m[0511 19:21:10 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.28633272647857666, Train Loss: 0.2795504927635193
[32m[0511 19:21:10 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.286298006772995, Train Loss: 0.27950629591941833
[32m[0511 19:21:10 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.28626376390457153, Train Loss: 0.2794627249240875
[32m[0511 19:21:10 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.28623002767562866, Train Loss: 0.2794196605682373
[32m[0511 19:21:10 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.286196768283844, Train Loss: 0.27937719225883484
[32m[0511 19:21:10 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.28616395592689514, Train Loss: 0.2793352007865906
[32m[0511 19:21:10 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.2861316502094269, Train Loss: 0.2792937755584717
[32m[0511 19:21:10 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.28609973192214966, Train Loss: 0.2792528569698334
[32m[0511 19:21:10 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.28606826066970825, Train Loss: 0.27921247482299805
[32m[0511 19:21:10 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.2860371470451355, Train Loss: 0.27917250990867615
[32m[0511 19:21:10 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.28600651025772095, Train Loss: 0.27913302183151245
[32m[0511 19:21:11 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.28597623109817505, Train Loss: 0.27909404039382935
[32m[0511 19:21:11 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.2859463691711426, Train Loss: 0.27905556559562683
[32m[0511 19:21:11 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.28591689467430115, Train Loss: 0.2790174186229706
[32m[0511 19:21:11 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.28588780760765076, Train Loss: 0.2789797782897949
[32m[0511 19:21:11 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.28585904836654663, Train Loss: 0.2789425551891327
[32m[0511 19:21:11 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.28583064675331116, Train Loss: 0.2789056897163391
[32m[0511 19:21:11 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.28580260276794434, Train Loss: 0.2788693308830261
[32m[0511 19:21:11 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.2857748866081238, Train Loss: 0.278833270072937
[32m[0511 19:21:11 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.28574755787849426, Train Loss: 0.2787976562976837
[32m[0511 19:21:11 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.285720556974411, Train Loss: 0.2787623703479767
[32m[0511 19:21:11 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.28569385409355164, Train Loss: 0.27872753143310547
[32m[0511 19:21:11 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.28566744923591614, Train Loss: 0.27869299054145813
[32m[0511 19:21:11 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.2856414020061493, Train Loss: 0.27865883708000183
[32m[0511 19:21:11 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.28561559319496155, Train Loss: 0.2786249816417694
[32m[0511 19:21:11 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.28559014201164246, Train Loss: 0.27859148383140564
[32m[0511 19:21:11 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.28556498885154724, Train Loss: 0.2785583734512329
[32m[0511 19:21:11 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.2855401337146759, Train Loss: 0.27852559089660645
[32m[0511 19:21:11 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.28551554679870605, Train Loss: 0.2784930169582367
[32m[0511 19:21:11 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.2854912281036377, Train Loss: 0.27846086025238037
[32m[0511 19:21:12 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.28546714782714844, Train Loss: 0.27842897176742554
[32m[0511 19:21:12 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.28544336557388306, Train Loss: 0.27839741110801697
[32m[0511 19:21:12 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.28541988134384155, Train Loss: 0.2783661186695099
[32m[0511 19:21:12 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.28539663553237915, Train Loss: 0.2783351242542267
[32m[0511 19:21:12 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.2853736877441406, Train Loss: 0.27830439805984497
[32m[0511 19:21:12 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.2853509187698364, Train Loss: 0.2782739996910095
[32m[0511 19:21:12 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.2853284478187561, Train Loss: 0.2782438397407532
[32m[0511 19:21:12 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.2853062152862549, Train Loss: 0.2782139182090759
[32m[0511 19:21:12 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.2852841913700104, Train Loss: 0.27818432450294495
[32m[0511 19:21:12 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.28526246547698975, Train Loss: 0.2781548798084259
[32m[0511 19:21:12 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.28524094820022583, Train Loss: 0.2781258821487427
[32m[0511 19:21:12 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.28521963953971863, Train Loss: 0.2780969738960266
[32m[0511 19:21:12 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.2851985991001129, Train Loss: 0.2780683636665344
[32m[0511 19:21:12 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.28517773747444153, Train Loss: 0.27803999185562134
[32m[0511 19:21:12 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.28515711426734924, Train Loss: 0.27801188826560974
[32m[0511 19:21:12 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.28513672947883606, Train Loss: 0.2779839336872101
[32m[0511 19:21:12 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.2851165533065796, Train Loss: 0.2779562473297119
[32m[0511 19:21:12 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.28509655594825745, Train Loss: 0.27792882919311523
[32m[0511 19:21:12 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.2850768268108368, Train Loss: 0.27790161967277527
[32m[0511 19:21:13 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.2850572466850281, Train Loss: 0.27787458896636963
[32m[0511 19:21:13 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.2850378751754761, Train Loss: 0.2778477966785431
[32m[0511 19:21:13 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.2850187420845032, Train Loss: 0.27782124280929565
[32m[0511 19:21:13 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.2849997580051422, Train Loss: 0.27779486775398254
[32m[0511 19:21:13 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.28498101234436035, Train Loss: 0.27776867151260376
[32m[0511 19:21:13 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.2849624454975128, Train Loss: 0.27774274349212646
[32m[0511 19:21:13 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.2849440276622772, Train Loss: 0.2777169346809387
[32m[0511 19:21:13 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.28492581844329834, Train Loss: 0.2776913344860077
[32m[0511 19:21:13 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.28490781784057617, Train Loss: 0.27766600251197815
[32m[0511 19:21:13 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.28488996624946594, Train Loss: 0.27764075994491577
[32m[0511 19:21:13 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.2848723530769348, Train Loss: 0.2776157557964325
[32m[0511 19:21:13 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.28485485911369324, Train Loss: 0.27759093046188354
[32m[0511 19:21:13 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.2848375737667084, Train Loss: 0.27756625413894653
[32m[0511 19:21:13 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.28482046723365784, Train Loss: 0.2775418162345886
[32m[0511 19:21:13 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.28480347990989685, Train Loss: 0.27751752734184265
[32m[0511 19:21:13 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.2847867012023926, Train Loss: 0.2774933874607086
[32m[0511 19:21:13 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.28477007150650024, Train Loss: 0.2774694263935089
[32m[0511 19:21:13 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.2847536504268646, Train Loss: 0.27744561433792114
[32m[0511 19:21:13 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.28473731875419617, Train Loss: 0.2774220108985901
[32m[0511 19:21:13 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.2847211956977844, Train Loss: 0.27739858627319336
[32m[0511 19:21:14 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.2847052216529846, Train Loss: 0.2773752510547638
[32m[0511 19:21:14 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.28468942642211914, Train Loss: 0.27735209465026855
[32m[0511 19:21:14 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.2846737504005432, Train Loss: 0.27732911705970764
[32m[0511 19:21:14 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.2846582531929016, Train Loss: 0.27730628848075867
[32m[0511 19:21:14 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.28464287519454956, Train Loss: 0.27728360891342163
[32m[0511 19:21:14 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.28462761640548706, Train Loss: 0.27726104855537415
[32m[0511 19:21:14 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.28461259603500366, Train Loss: 0.277238667011261
[32m[0511 19:21:14 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.2845976650714874, Train Loss: 0.27721646428108215
[32m[0511 19:21:14 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.28458288311958313, Train Loss: 0.2771943211555481
[32m[0511 19:21:14 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.2845682203769684, Train Loss: 0.27717238664627075
[32m[0511 19:21:14 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.28455373644828796, Train Loss: 0.27715057134628296
[32m[0511 19:21:14 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.2845394015312195, Train Loss: 0.2771288752555847
[32m[0511 19:21:14 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.28452515602111816, Train Loss: 0.2771073281764984
[32m[0511 19:21:14 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.28451108932495117, Train Loss: 0.27708595991134644
[32m[0511 19:21:14 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.28449711203575134, Train Loss: 0.277064710855484
[32m[0511 19:21:14 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.28448331356048584, Train Loss: 0.27704352140426636
[32m[0511 19:21:14 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.2844695746898651, Train Loss: 0.27702251076698303
[32m[0511 19:21:14 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.2844560444355011, Train Loss: 0.27700158953666687
[32m[0511 19:21:14 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.28444257378578186, Train Loss: 0.27698081731796265
[32m[0511 19:21:14 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.28442925214767456, Train Loss: 0.27696019411087036
[32m[0511 19:21:15 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.2844160795211792, Train Loss: 0.27693966031074524
[32m[0511 19:21:15 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.2844030261039734, Train Loss: 0.27691927552223206
[32m[0511 19:21:15 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.28439009189605713, Train Loss: 0.27689895033836365
[32m[0511 19:21:15 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.28437721729278564, Train Loss: 0.27687883377075195
[32m[0511 19:21:15 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.2843645513057709, Train Loss: 0.27685877680778503
[32m[0511 19:21:15 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.2843519151210785, Train Loss: 0.2768388092517853
[32m[0511 19:21:15 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.28433945775032043, Train Loss: 0.27681905031204224
[32m[0511 19:21:15 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.28432711958885193, Train Loss: 0.2767992913722992
[32m[0511 19:21:15 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.2843148410320282, Train Loss: 0.2767796814441681
[32m[0511 19:21:15 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.284302681684494, Train Loss: 0.2767602503299713
[32m[0511 19:21:15 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.284290611743927, Train Loss: 0.2767408490180969
[32m[0511 19:21:15 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.2842787206172943, Train Loss: 0.2767215669155121
[32m[0511 19:21:15 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.2842668890953064, Train Loss: 0.2767024040222168
[32m[0511 19:21:15 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.28425514698028564, Train Loss: 0.27668333053588867
[32m[0511 19:21:15 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.28424355387687683, Train Loss: 0.2766643464565277
[32m[0511 19:21:15 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.2842320203781128, Train Loss: 0.2766454815864563
[32m[0511 19:21:15 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.2842206358909607, Train Loss: 0.2766267657279968
[32m[0511 19:21:15 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.28420934081077576, Train Loss: 0.27660807967185974
[32m[0511 19:21:15 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.2841981053352356, Train Loss: 0.2765895128250122
[32m[0511 19:21:15 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.284186989068985, Train Loss: 0.27657103538513184
[32m[0511 19:21:16 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.28417593240737915, Train Loss: 0.27655264735221863
[32m[0511 19:21:16 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.28416502475738525, Train Loss: 0.27653437852859497
[32m[0511 19:21:16 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.2841542065143585, Train Loss: 0.2765161991119385
[32m[0511 19:21:16 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.2841434180736542, Train Loss: 0.27649813890457153
[32m[0511 19:21:16 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.28413280844688416, Train Loss: 0.276480108499527
[32m[0511 19:21:16 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.2841222286224365, Train Loss: 0.2764621675014496
[32m[0511 19:21:16 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.28411179780960083, Train Loss: 0.27644434571266174
[32m[0511 19:21:16 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.2841013967990875, Train Loss: 0.27642664313316345
[32m[0511 19:21:16 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.2840910851955414, Train Loss: 0.27640897035598755
[32m[0511 19:21:16 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.2840809226036072, Train Loss: 0.2763914167881012
[32m[0511 19:21:16 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.284070760011673, Train Loss: 0.276373952627182
[32m[0511 19:21:16 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.2840607464313507, Train Loss: 0.2763565480709076
[32m[0511 19:21:16 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.28405073285102844, Train Loss: 0.27633923292160034
[32m[0511 19:21:16 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.2840408682823181, Train Loss: 0.2763219475746155
[32m[0511 19:21:16 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.2840310335159302, Train Loss: 0.27630481123924255
[32m[0511 19:21:16 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.2840213179588318, Train Loss: 0.2762877643108368
[32m[0511 19:21:16 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.28401169180870056, Train Loss: 0.2762707769870758
[32m[0511 19:21:16 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.2840021252632141, Train Loss: 0.2762538492679596
[32m[0511 19:21:16 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.28399258852005005, Train Loss: 0.27623704075813293
[32m[0511 19:21:16 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.2839832007884979, Train Loss: 0.2762202322483063
[32m[0511 19:21:17 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.2839738428592682, Train Loss: 0.27620357275009155
[32m[0511 19:21:17 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.2839645743370056, Train Loss: 0.2761869430541992
[32m[0511 19:21:17 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.2839553654193878, Train Loss: 0.27617040276527405
[32m[0511 19:21:17 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.2839462459087372, Train Loss: 0.27615395188331604
[32m[0511 19:21:17 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.28393715620040894, Train Loss: 0.2761375308036804
[32m[0511 19:21:17 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.28392818570137024, Train Loss: 0.27612122893333435
[32m[0511 19:21:17 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.28391924500465393, Train Loss: 0.27610495686531067
[32m[0511 19:21:17 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.2839103639125824, Train Loss: 0.27608874440193176
[32m[0511 19:21:17 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.2839016020298004, Train Loss: 0.2760726511478424
[32m[0511 19:21:17 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.2838928997516632, Train Loss: 0.2760566174983978
[32m[0511 19:21:17 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.283884197473526, Train Loss: 0.2760406732559204
[32m[0511 19:21:17 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.28387564420700073, Train Loss: 0.276024729013443
[32m[0511 19:21:17 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.2838670611381531, Train Loss: 0.27600887417793274
[32m[0511 19:21:17 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.2838585674762726, Train Loss: 0.27599310874938965
[32m[0511 19:21:17 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.28385019302368164, Train Loss: 0.27597737312316895
[32m[0511 19:21:17 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.2838417887687683, Train Loss: 0.275961697101593
[32m[0511 19:21:17 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.28383350372314453, Train Loss: 0.27594617009162903
[32m[0511 19:21:17 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.28382524847984314, Train Loss: 0.27593058347702026
[32m[0511 19:21:17 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.2838170826435089, Train Loss: 0.27591511607170105
[32m[0511 19:21:17 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.28380894660949707, Train Loss: 0.2758997082710266
[32m[0511 19:21:18 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.28380087018013, Train Loss: 0.27588433027267456
[32m[0511 19:21:18 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.2837928831577301, Train Loss: 0.27586910128593445
[32m[0511 19:21:18 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.2837849259376526, Train Loss: 0.27585384249687195
[32m[0511 19:21:18 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.2837769687175751, Train Loss: 0.2758386433124542
[32m[0511 19:21:18 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.2837691009044647, Train Loss: 0.27582356333732605
[32m[0511 19:21:18 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.28376129269599915, Train Loss: 0.27580851316452026
[32m[0511 19:21:18 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.28375354409217834, Train Loss: 0.27579352259635925
[32m[0511 19:21:18 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.2837459146976471, Train Loss: 0.27577853202819824
[32m[0511 19:21:18 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.2837381958961487, Train Loss: 0.2757636308670044
[32m[0511 19:21:18 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.2837305963039398, Train Loss: 0.2757488191127777
[32m[0511 19:21:18 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.28372302651405334, Train Loss: 0.2757340669631958
[32m[0511 19:21:18 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.28371551632881165, Train Loss: 0.2757193148136139
[32m[0511 19:21:18 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.28370803594589233, Train Loss: 0.27570468187332153
[32m[0511 19:21:18 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.2837006151676178, Train Loss: 0.2756900191307068
[32m[0511 19:21:18 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.28369325399398804, Train Loss: 0.2756754457950592
[32m[0511 19:21:18 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.2836858928203583, Train Loss: 0.2756609618663788
[32m[0511 19:21:18 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.2836786210536957, Train Loss: 0.275646448135376
[32m[0511 19:21:18 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.28367137908935547, Train Loss: 0.27563199400901794
[32m[0511 19:21:18 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.28366416692733765, Train Loss: 0.27561768889427185
[32m[0511 19:21:19 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.2836569845676422, Train Loss: 0.27560335397720337
[32m[0511 19:21:19 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.28364986181259155, Train Loss: 0.27558907866477966
[32m[0511 19:21:19 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.28364279866218567, Train Loss: 0.2755748927593231
[32m[0511 19:21:19 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.2836357653141022, Train Loss: 0.2755606770515442
[32m[0511 19:21:19 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.2836287319660187, Train Loss: 0.2755465507507324
[32m[0511 19:21:19 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.28362181782722473, Train Loss: 0.27553248405456543
[32m[0511 19:21:19 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.2836148738861084, Train Loss: 0.2755184471607208
[32m[0511 19:21:19 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.28360798954963684, Train Loss: 0.2755044400691986
[32m[0511 19:21:19 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.28360113501548767, Train Loss: 0.27549052238464355
[32m[0511 19:21:19 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.28359436988830566, Train Loss: 0.2754766345024109
[32m[0511 19:21:19 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.2835875451564789, Train Loss: 0.27546271681785583
[32m[0511 19:21:19 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.28358083963394165, Train Loss: 0.2754489481449127
[32m[0511 19:21:19 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.28357410430908203, Train Loss: 0.2754351794719696
[32m[0511 19:21:19 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.2835674583911896, Train Loss: 0.27542147040367126
[32m[0511 19:21:19 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.2835608124732971, Train Loss: 0.2754077911376953
[32m[0511 19:21:19 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.28355419635772705, Train Loss: 0.27539414167404175
[32m[0511 19:21:19 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.28354763984680176, Train Loss: 0.27538052201271057
[32m[0511 19:21:19 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.28354108333587646, Train Loss: 0.27536696195602417
[32m[0511 19:21:19 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.28353458642959595, Train Loss: 0.27535349130630493
[32m[0511 19:21:20 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.28352805972099304, Train Loss: 0.2753399610519409
[32m[0511 19:21:20 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.2835216522216797, Train Loss: 0.27532655000686646
[32m[0511 19:21:20 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.28351524472236633, Train Loss: 0.275313138961792
[32m[0511 19:21:20 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.28350886702537537, Train Loss: 0.2752997875213623
[32m[0511 19:21:20 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.283502459526062, Train Loss: 0.275286465883255
[32m[0511 19:21:20 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.2834961712360382, Train Loss: 0.2752732038497925
[32m[0511 19:21:20 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.2834898829460144, Train Loss: 0.27525994181632996
[32m[0511 19:21:20 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.283483624458313, Train Loss: 0.2752467691898346
[32m[0511 19:21:20 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.2834773659706116, Train Loss: 0.27523356676101685
[32m[0511 19:21:20 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.28347110748291016, Train Loss: 0.27522045373916626
[32m[0511 19:21:20 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.2834649384021759, Train Loss: 0.2752073407173157
[32m[0511 19:21:20 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.28345873951911926, Train Loss: 0.27519428730010986
[32m[0511 19:21:20 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.2834526002407074, Train Loss: 0.27518129348754883
[32m[0511 19:21:20 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.2834464907646179, Train Loss: 0.2751683294773102
[32m[0511 19:21:20 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.2834404408931732, Train Loss: 0.27515533566474915
[32m[0511 19:21:20 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.28343436121940613, Train Loss: 0.27514246106147766
[32m[0511 19:21:20 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.2834283113479614, Train Loss: 0.2751295566558838
[32m[0511 19:21:20 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.2834222912788391, Train Loss: 0.2751167416572571
[32m[0511 19:21:20 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.2834162712097168, Train Loss: 0.275103896856308
[32m[0511 19:21:20 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.28341034054756165, Train Loss: 0.27509114146232605
[32m[0511 19:21:21 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.2834043800830841, Train Loss: 0.2750784456729889
[32m[0511 19:21:21 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.28339844942092896, Train Loss: 0.27506572008132935
[32m[0511 19:21:21 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.2833925485610962, Train Loss: 0.2750529944896698
[32m[0511 19:21:21 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.2833866477012634, Train Loss: 0.2750403881072998
[32m[0511 19:21:21 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.28338080644607544, Train Loss: 0.2750277817249298
[32m[0511 19:21:21 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.28337493538856506, Train Loss: 0.2750151753425598
[32m[0511 19:21:21 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.28336912393569946, Train Loss: 0.2750026285648346
[32m[0511 19:21:21 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.28336331248283386, Train Loss: 0.27499011158943176
[32m[0511 19:21:21 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.28335753083229065, Train Loss: 0.2749776542186737
[32m[0511 19:21:21 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.2833517789840698, Train Loss: 0.27496522665023804
[32m[0511 19:21:21 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.2833460569381714, Train Loss: 0.27495276927948
[32m[0511 19:21:21 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.28334033489227295, Train Loss: 0.2749404311180115
[32m[0511 19:21:21 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.2833346128463745, Train Loss: 0.2749280631542206
[32m[0511 19:21:21 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.28332892060279846, Train Loss: 0.2749157249927521
[32m[0511 19:21:21 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.2833232283592224, Train Loss: 0.27490344643592834
[32m[0511 19:21:21 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.28331759572029114, Train Loss: 0.274891197681427
[32m[0511 19:21:21 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.28331199288368225, Train Loss: 0.2748788893222809
[32m[0511 19:21:21 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.283306360244751, Train Loss: 0.27486667037010193
[32m[0511 19:21:21 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.2833007574081421, Train Loss: 0.27485454082489014
[32m[0511 19:21:21 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.2832951843738556, Train Loss: 0.27484235167503357
[32m[0511 19:21:22 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.2832896113395691, Train Loss: 0.2748302221298218
[32m[0511 19:21:22 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.283284068107605, Train Loss: 0.27481815218925476
[32m[0511 19:21:22 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.28327852487564087, Train Loss: 0.27480605244636536
[32m[0511 19:21:22 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.28327301144599915, Train Loss: 0.2747940421104431
[32m[0511 19:21:22 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.2832674980163574, Train Loss: 0.2747820019721985
[32m[0511 19:21:22 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.2832620143890381, Train Loss: 0.27477002143859863
[32m[0511 19:21:22 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.28325656056404114, Train Loss: 0.27475807070732117
[32m[0511 19:21:22 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.2832510769367218, Train Loss: 0.2747461497783661
[32m[0511 19:21:22 @mbmf_main.py:224][0m batch size for trpo is 1000
[32m[0511 19:21:22 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 19:21:22 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 19:21:22 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 19:21:22 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 19:21:22 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 19:21:22 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 19:21:22 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 19:21:22 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 19:21:22 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 19:21:22 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 19:21:22 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 19:21:22 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 19:21:22 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 19:21:22 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 19:21:22 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 19:21:22 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 19:21:22 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 19:21:22 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 19:21:22 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 19:21:22 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 19:21:22 @mbmf_main.py:132][0m Training starts at /root/mbbl
[32m[0511 19:21:22 @base_worker.py:45][0m Worker 0 online
[32m[0511 19:21:22 @base_worker.py:45][0m Worker 1 online
[32m[0511 19:21:22 @base_worker.py:45][0m Worker 2 online
[32m[0511 19:21:22 @base_worker.py:45][0m Worker 3 online
[32m[0511 19:21:22 @base_worker.py:45][0m Worker 4 online
[32m[0511 19:21:22 @base_worker.py:45][0m Worker 5 online
[32m[0511 19:21:22 @base_worker.py:45][0m Worker 6 online
[32m[0511 19:21:22 @base_worker.py:45][0m Worker 7 online
[32m[0511 19:21:22 @base_worker.py:45][0m Worker 8 online
[32m[0511 19:21:22 @base_worker.py:45][0m Worker 9 online
[32m[0511 19:21:22 @base_worker.py:45][0m Worker 10 online
[32m[0511 19:21:22 @base_worker.py:45][0m Worker 11 online
[32m[0511 19:21:22 @base_worker.py:45][0m Worker 12 online
[32m[0511 19:21:22 @base_worker.py:45][0m Worker 13 online
[32m[0511 19:21:22 @base_worker.py:45][0m Worker 14 online
[32m[0511 19:21:22 @base_worker.py:45][0m Worker 15 online
[32m[0511 19:21:22 @base_worker.py:45][0m Worker 16 online
[32m[0511 19:21:22 @base_worker.py:45][0m Worker 17 online
[32m[0511 19:21:22 @base_worker.py:45][0m Worker 18 online
[32m[0511 19:21:22 @base_worker.py:45][0m Worker 19 online
[32m[0511 19:21:23 @base_trainer.py:152][0m Trainer maintains [1] policy network
[32m[0511 19:21:23 @base_trainer.py:152][0m Trainer maintains [1] dynamics network
[32m[0511 19:21:23 @base_trainer.py:152][0m Trainer maintains [1] reward network
[32m[0511 19:21:23 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:21:23 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:21:23 @base_trainer.py:216][0m Mean reward: -452.2784420091503
[32m[0511 19:21:24 @base_main.py:38][0m --------------- Iteration 1 ---------------
[32m[0511 19:21:24 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0000 mins
[32m[0511 19:21:24 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0043 mins
[32m[0511 19:21:24 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0148 mins
[32m[0511 19:21:24 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:21:24 @base_main.py:47][0m 1002 total steps have happened
[32m[0511 19:21:24 @base_main.py:52][0m [avg_reward]: -452.2784420091503
[32m[0511 19:21:24 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:21:24 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:21:24 @base_trainer.py:216][0m Mean reward: -448.81225867118553
[32m[0511 19:21:25 @base_main.py:38][0m --------------- Iteration 2 ---------------
[32m[0511 19:21:25 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0192 mins
[32m[0511 19:21:25 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0052 mins
[32m[0511 19:21:25 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0511 19:21:25 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:21:25 @base_main.py:47][0m 2004 total steps have happened
[32m[0511 19:21:25 @base_main.py:52][0m [avg_reward]: -448.81225867118553
[32m[0511 19:21:25 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:21:25 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:21:25 @base_trainer.py:216][0m Mean reward: -439.91762928208226
[32m[0511 19:21:26 @base_main.py:38][0m --------------- Iteration 3 ---------------
[32m[0511 19:21:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0339 mins
[32m[0511 19:21:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0051 mins
[32m[0511 19:21:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 19:21:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:21:26 @base_main.py:47][0m 3006 total steps have happened
[32m[0511 19:21:26 @base_main.py:52][0m [avg_reward]: -439.91762928208226
[32m[0511 19:21:26 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:21:26 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:21:26 @base_trainer.py:216][0m Mean reward: -423.7680295426242
[32m[0511 19:21:27 @base_main.py:38][0m --------------- Iteration 4 ---------------
[32m[0511 19:21:27 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0489 mins
[32m[0511 19:21:27 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0054 mins
[32m[0511 19:21:27 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 19:21:27 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:21:27 @base_main.py:47][0m 4008 total steps have happened
[32m[0511 19:21:27 @base_main.py:52][0m [avg_reward]: -423.7680295426242
[32m[0511 19:21:27 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:21:27 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:21:27 @base_trainer.py:216][0m Mean reward: -436.96470934070567
[32m[0511 19:21:28 @base_main.py:38][0m --------------- Iteration 5 ---------------
[32m[0511 19:21:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0645 mins
[32m[0511 19:21:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0511 19:21:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 19:21:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:21:28 @base_main.py:47][0m 5010 total steps have happened
[32m[0511 19:21:28 @base_main.py:52][0m [avg_reward]: -436.96470934070567
[32m[0511 19:21:28 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:21:28 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:21:28 @base_trainer.py:216][0m Mean reward: -423.28316133869987
[32m[0511 19:21:28 @base_main.py:38][0m --------------- Iteration 6 ---------------
[32m[0511 19:21:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0792 mins
[32m[0511 19:21:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0036 mins
[32m[0511 19:21:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 19:21:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:21:28 @base_main.py:47][0m 6012 total steps have happened
[32m[0511 19:21:28 @base_main.py:52][0m [avg_reward]: -423.28316133869987
[32m[0511 19:21:29 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:21:29 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:21:29 @base_trainer.py:216][0m Mean reward: -281.6407190481748
[32m[0511 19:21:29 @base_main.py:38][0m --------------- Iteration 7 ---------------
[32m[0511 19:21:29 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0934 mins
[32m[0511 19:21:29 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0046 mins
[32m[0511 19:21:29 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 19:21:29 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:21:29 @base_main.py:47][0m 7014 total steps have happened
[32m[0511 19:21:29 @base_main.py:52][0m [avg_reward]: -281.6407190481748
[32m[0511 19:21:30 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:21:30 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:21:30 @base_trainer.py:216][0m Mean reward: -405.25731005237384
[32m[0511 19:21:30 @base_main.py:38][0m --------------- Iteration 8 ---------------
[32m[0511 19:21:30 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1086 mins
[32m[0511 19:21:30 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0044 mins
[32m[0511 19:21:30 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 19:21:30 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:21:30 @base_main.py:47][0m 8016 total steps have happened
[32m[0511 19:21:30 @base_main.py:52][0m [avg_reward]: -405.25731005237384
[32m[0511 19:21:31 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:21:31 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:21:31 @base_trainer.py:216][0m Mean reward: -399.6621576943455
[32m[0511 19:21:31 @base_main.py:38][0m --------------- Iteration 9 ---------------
[32m[0511 19:21:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1234 mins
[32m[0511 19:21:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0049 mins
[32m[0511 19:21:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 19:21:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:21:31 @base_main.py:47][0m 9018 total steps have happened
[32m[0511 19:21:31 @base_main.py:52][0m [avg_reward]: -399.6621576943455
[32m[0511 19:21:31 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:21:31 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:21:31 @base_trainer.py:216][0m Mean reward: -418.1005379588825
[32m[0511 19:21:32 @base_main.py:38][0m --------------- Iteration 10 ---------------
[32m[0511 19:21:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1385 mins
[32m[0511 19:21:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0046 mins
[32m[0511 19:21:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 19:21:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:21:32 @base_main.py:47][0m 10020 total steps have happened
[32m[0511 19:21:32 @base_main.py:52][0m [avg_reward]: -418.1005379588825
[32m[0511 19:21:32 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:21:32 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:21:32 @base_trainer.py:216][0m Mean reward: -434.97000338471315
[32m[0511 19:21:33 @base_main.py:38][0m --------------- Iteration 11 ---------------
[32m[0511 19:21:33 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1539 mins
[32m[0511 19:21:33 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0050 mins
[32m[0511 19:21:33 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 19:21:33 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:21:33 @base_main.py:47][0m 11022 total steps have happened
[32m[0511 19:21:33 @base_main.py:52][0m [avg_reward]: -434.97000338471315
[32m[0511 19:21:33 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:21:33 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:21:33 @base_trainer.py:216][0m Mean reward: -424.152412990863
[32m[0511 19:21:34 @base_main.py:38][0m --------------- Iteration 12 ---------------
[32m[0511 19:21:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1696 mins
[32m[0511 19:21:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0044 mins
[32m[0511 19:21:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 19:21:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:21:34 @base_main.py:47][0m 12024 total steps have happened
[32m[0511 19:21:34 @base_main.py:52][0m [avg_reward]: -424.152412990863
[32m[0511 19:21:34 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:21:34 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:21:34 @base_trainer.py:216][0m Mean reward: -455.4810032052567
[32m[0511 19:21:35 @base_main.py:38][0m --------------- Iteration 13 ---------------
[32m[0511 19:21:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1847 mins
[32m[0511 19:21:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0044 mins
[32m[0511 19:21:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 19:21:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:21:35 @base_main.py:47][0m 13026 total steps have happened
[32m[0511 19:21:35 @base_main.py:52][0m [avg_reward]: -455.4810032052567
[32m[0511 19:21:35 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:21:35 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:21:35 @base_trainer.py:216][0m Mean reward: -460.4879057157081
[32m[0511 19:21:36 @base_main.py:38][0m --------------- Iteration 14 ---------------
[32m[0511 19:21:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1990 mins
[32m[0511 19:21:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0047 mins
[32m[0511 19:21:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 19:21:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:21:36 @base_main.py:47][0m 14028 total steps have happened
[32m[0511 19:21:36 @base_main.py:52][0m [avg_reward]: -460.4879057157081
[32m[0511 19:21:36 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:21:36 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:21:36 @base_trainer.py:216][0m Mean reward: -459.8082685329469
[32m[0511 19:21:37 @base_main.py:38][0m --------------- Iteration 15 ---------------
[32m[0511 19:21:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2142 mins
[32m[0511 19:21:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0048 mins
[32m[0511 19:21:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 19:21:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:21:37 @base_main.py:47][0m 15030 total steps have happened
[32m[0511 19:21:37 @base_main.py:52][0m [avg_reward]: -459.8082685329469
[32m[0511 19:21:37 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:21:37 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:21:37 @base_trainer.py:216][0m Mean reward: -455.1086788303045
[32m[0511 19:21:38 @base_main.py:38][0m --------------- Iteration 16 ---------------
[32m[0511 19:21:38 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2290 mins
[32m[0511 19:21:38 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 19:21:38 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0109 mins
[32m[0511 19:21:38 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:21:38 @base_main.py:47][0m 16032 total steps have happened
[32m[0511 19:21:38 @base_main.py:52][0m [avg_reward]: -455.1086788303045
[32m[0511 19:21:38 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:21:38 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:21:38 @base_trainer.py:216][0m Mean reward: -455.8365031870902
[32m[0511 19:21:38 @base_main.py:38][0m --------------- Iteration 17 ---------------
[32m[0511 19:21:38 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2440 mins
[32m[0511 19:21:38 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0043 mins
[32m[0511 19:21:38 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 19:21:38 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0511 19:21:38 @base_main.py:47][0m 17034 total steps have happened
[32m[0511 19:21:38 @base_main.py:52][0m [avg_reward]: -455.8365031870902
[32m[0511 19:21:39 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:21:39 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:21:39 @base_trainer.py:216][0m Mean reward: -455.3153349296491
[32m[0511 19:21:39 @base_main.py:38][0m --------------- Iteration 18 ---------------
[32m[0511 19:21:39 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2587 mins
[32m[0511 19:21:39 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0054 mins
[32m[0511 19:21:39 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 19:21:39 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0511 19:21:39 @base_main.py:47][0m 18036 total steps have happened
[32m[0511 19:21:39 @base_main.py:52][0m [avg_reward]: -455.3153349296491
[32m[0511 19:21:40 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:21:40 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:21:40 @base_trainer.py:216][0m Mean reward: -451.7691322974972
[32m[0511 19:21:40 @base_main.py:38][0m --------------- Iteration 19 ---------------
[32m[0511 19:21:40 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2748 mins
[32m[0511 19:21:40 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0046 mins
[32m[0511 19:21:40 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 19:21:40 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0511 19:21:40 @base_main.py:47][0m 19038 total steps have happened
[32m[0511 19:21:40 @base_main.py:52][0m [avg_reward]: -451.7691322974972
[32m[0511 19:21:41 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:21:41 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:21:41 @base_trainer.py:216][0m Mean reward: -453.39442015767224
[32m[0511 19:21:41 @base_main.py:38][0m --------------- Iteration 20 ---------------
[32m[0511 19:21:41 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2896 mins
[32m[0511 19:21:41 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0043 mins
[32m[0511 19:21:41 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 19:21:41 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:21:41 @base_main.py:47][0m 20040 total steps have happened
[32m[0511 19:21:41 @base_main.py:52][0m [avg_reward]: -453.39442015767224
[32m[0511 19:21:41 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:21:41 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:21:41 @base_trainer.py:216][0m Mean reward: -454.5236253255468
[32m[0511 19:21:42 @base_main.py:38][0m --------------- Iteration 21 ---------------
[32m[0511 19:21:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3046 mins
[32m[0511 19:21:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0047 mins
[32m[0511 19:21:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 19:21:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:21:42 @base_main.py:47][0m 21042 total steps have happened
[32m[0511 19:21:42 @base_main.py:52][0m [avg_reward]: -454.5236253255468
[32m[0511 19:21:42 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:21:42 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:21:42 @base_trainer.py:216][0m Mean reward: -451.9566094180346
[32m[0511 19:21:43 @base_main.py:38][0m --------------- Iteration 22 ---------------
[32m[0511 19:21:43 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3195 mins
[32m[0511 19:21:43 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0511 19:21:43 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 19:21:43 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:21:43 @base_main.py:47][0m 22044 total steps have happened
[32m[0511 19:21:43 @base_main.py:52][0m [avg_reward]: -451.9566094180346
[32m[0511 19:21:43 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:21:43 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:21:43 @base_trainer.py:216][0m Mean reward: -452.03689775755896
[32m[0511 19:21:44 @base_main.py:38][0m --------------- Iteration 23 ---------------
[32m[0511 19:21:44 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3343 mins
[32m[0511 19:21:44 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0038 mins
[32m[0511 19:21:44 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 19:21:44 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:21:44 @base_main.py:47][0m 23046 total steps have happened
[32m[0511 19:21:44 @base_main.py:52][0m [avg_reward]: -452.03689775755896
[32m[0511 19:21:44 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:21:44 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:21:44 @base_trainer.py:216][0m Mean reward: -458.09604406986637
[32m[0511 19:21:45 @base_main.py:38][0m --------------- Iteration 24 ---------------
[32m[0511 19:21:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3485 mins
[32m[0511 19:21:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0037 mins
[32m[0511 19:21:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 19:21:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:21:45 @base_main.py:47][0m 24048 total steps have happened
[32m[0511 19:21:45 @base_main.py:52][0m [avg_reward]: -458.09604406986637
[32m[0511 19:21:45 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:21:45 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:21:45 @base_trainer.py:216][0m Mean reward: -450.9270651242623
[32m[0511 19:21:46 @base_main.py:38][0m --------------- Iteration 25 ---------------
[32m[0511 19:21:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3628 mins
[32m[0511 19:21:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0511 19:21:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0108 mins
[32m[0511 19:21:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:21:46 @base_main.py:47][0m 25050 total steps have happened
[32m[0511 19:21:46 @base_main.py:52][0m [avg_reward]: -450.9270651242623
[32m[0511 19:21:46 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:21:46 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:21:46 @base_trainer.py:216][0m Mean reward: -454.9838601624471
[32m[0511 19:21:46 @base_main.py:38][0m --------------- Iteration 26 ---------------
[32m[0511 19:21:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3779 mins
[32m[0511 19:21:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0046 mins
[32m[0511 19:21:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 19:21:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:21:46 @base_main.py:47][0m 26052 total steps have happened
[32m[0511 19:21:46 @base_main.py:52][0m [avg_reward]: -454.9838601624471
[32m[0511 19:21:47 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:21:47 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:21:47 @base_trainer.py:216][0m Mean reward: -450.89706018098957
[32m[0511 19:21:47 @base_main.py:38][0m --------------- Iteration 27 ---------------
[32m[0511 19:21:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3930 mins
[32m[0511 19:21:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0047 mins
[32m[0511 19:21:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 19:21:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:21:47 @base_main.py:47][0m 27054 total steps have happened
[32m[0511 19:21:47 @base_main.py:52][0m [avg_reward]: -450.89706018098957
[32m[0511 19:21:48 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:21:48 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:21:48 @base_trainer.py:216][0m Mean reward: -452.2446596192918
[32m[0511 19:21:48 @base_main.py:38][0m --------------- Iteration 28 ---------------
[32m[0511 19:21:48 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4083 mins
[32m[0511 19:21:48 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 19:21:48 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 19:21:48 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:21:48 @base_main.py:47][0m 28056 total steps have happened
[32m[0511 19:21:48 @base_main.py:52][0m [avg_reward]: -452.2446596192918
[32m[0511 19:21:48 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:21:48 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:21:48 @base_trainer.py:216][0m Mean reward: -455.72482457551735
[32m[0511 19:21:49 @base_main.py:38][0m --------------- Iteration 29 ---------------
[32m[0511 19:21:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4225 mins
[32m[0511 19:21:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0038 mins
[32m[0511 19:21:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 19:21:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:21:49 @base_main.py:47][0m 29058 total steps have happened
[32m[0511 19:21:49 @base_main.py:52][0m [avg_reward]: -455.72482457551735
[32m[0511 19:21:49 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:21:49 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:21:49 @base_trainer.py:216][0m Mean reward: -450.26905795645064
[32m[0511 19:21:50 @base_main.py:38][0m --------------- Iteration 30 ---------------
[32m[0511 19:21:50 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4369 mins
[32m[0511 19:21:50 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0053 mins
[32m[0511 19:21:50 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0107 mins
[32m[0511 19:21:50 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:21:50 @base_main.py:47][0m 30060 total steps have happened
[32m[0511 19:21:50 @base_main.py:52][0m [avg_reward]: -450.26905795645064
[32m[0511 19:21:50 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:21:50 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:21:50 @base_trainer.py:216][0m Mean reward: -433.7124497227764
[32m[0511 19:21:51 @base_main.py:38][0m --------------- Iteration 31 ---------------
[32m[0511 19:21:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4530 mins
[32m[0511 19:21:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0511 19:21:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0108 mins
[32m[0511 19:21:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:21:51 @base_main.py:47][0m 31062 total steps have happened
[32m[0511 19:21:51 @base_main.py:52][0m [avg_reward]: -433.7124497227764
[32m[0511 19:21:51 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:21:51 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:21:51 @base_trainer.py:216][0m Mean reward: -440.451184686833
[32m[0511 19:21:52 @base_main.py:38][0m --------------- Iteration 32 ---------------
[32m[0511 19:21:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4681 mins
[32m[0511 19:21:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0043 mins
[32m[0511 19:21:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0108 mins
[32m[0511 19:21:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:21:52 @base_main.py:47][0m 32064 total steps have happened
[32m[0511 19:21:52 @base_main.py:52][0m [avg_reward]: -440.451184686833
[32m[0511 19:21:52 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:21:52 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:21:52 @base_trainer.py:216][0m Mean reward: -425.7136423664598
[32m[0511 19:21:53 @base_main.py:38][0m --------------- Iteration 33 ---------------
[32m[0511 19:21:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4833 mins
[32m[0511 19:21:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 19:21:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0107 mins
[32m[0511 19:21:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:21:53 @base_main.py:47][0m 33066 total steps have happened
[32m[0511 19:21:53 @base_main.py:52][0m [avg_reward]: -425.7136423664598
[32m[0511 19:21:53 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:21:53 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:21:53 @base_trainer.py:216][0m Mean reward: -422.6763378244859
[32m[0511 19:21:54 @base_main.py:38][0m --------------- Iteration 34 ---------------
[32m[0511 19:21:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4980 mins
[32m[0511 19:21:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0045 mins
[32m[0511 19:21:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 19:21:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0511 19:21:54 @base_main.py:47][0m 34068 total steps have happened
[32m[0511 19:21:54 @base_main.py:52][0m [avg_reward]: -422.6763378244859
[32m[0511 19:21:54 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:21:54 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:21:54 @base_trainer.py:216][0m Mean reward: -383.79116364926233
[32m[0511 19:21:55 @base_main.py:38][0m --------------- Iteration 35 ---------------
[32m[0511 19:21:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5131 mins
[32m[0511 19:21:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0511 19:21:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 19:21:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:21:55 @base_main.py:47][0m 35070 total steps have happened
[32m[0511 19:21:55 @base_main.py:52][0m [avg_reward]: -383.79116364926233
[32m[0511 19:21:55 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:21:55 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:21:55 @base_trainer.py:216][0m Mean reward: -445.3815322985096
[32m[0511 19:21:55 @base_main.py:38][0m --------------- Iteration 36 ---------------
[32m[0511 19:21:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5277 mins
[32m[0511 19:21:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 19:21:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 19:21:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:21:55 @base_main.py:47][0m 36072 total steps have happened
[32m[0511 19:21:55 @base_main.py:52][0m [avg_reward]: -445.3815322985096
[32m[0511 19:21:56 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:21:56 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:21:56 @base_trainer.py:216][0m Mean reward: -430.6148467140364
[32m[0511 19:21:56 @base_main.py:38][0m --------------- Iteration 37 ---------------
[32m[0511 19:21:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5423 mins
[32m[0511 19:21:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0051 mins
[32m[0511 19:21:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 19:21:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0511 19:21:56 @base_main.py:47][0m 37074 total steps have happened
[32m[0511 19:21:56 @base_main.py:52][0m [avg_reward]: -430.6148467140364
[32m[0511 19:21:57 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:21:57 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:21:57 @base_trainer.py:216][0m Mean reward: -449.9003587307774
[32m[0511 19:21:57 @base_main.py:38][0m --------------- Iteration 38 ---------------
[32m[0511 19:21:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5579 mins
[32m[0511 19:21:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0047 mins
[32m[0511 19:21:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0108 mins
[32m[0511 19:21:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:21:57 @base_main.py:47][0m 38076 total steps have happened
[32m[0511 19:21:57 @base_main.py:52][0m [avg_reward]: -449.9003587307774
[32m[0511 19:21:58 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:21:58 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:21:58 @base_trainer.py:216][0m Mean reward: -437.11273527248864
[32m[0511 19:21:58 @base_main.py:38][0m --------------- Iteration 39 ---------------
[32m[0511 19:21:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5736 mins
[32m[0511 19:21:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0038 mins
[32m[0511 19:21:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0107 mins
[32m[0511 19:21:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0511 19:21:58 @base_main.py:47][0m 39078 total steps have happened
[32m[0511 19:21:58 @base_main.py:52][0m [avg_reward]: -437.11273527248864
[32m[0511 19:21:58 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:21:58 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:21:58 @base_trainer.py:216][0m Mean reward: -426.6293816346635
[32m[0511 19:21:59 @base_main.py:38][0m --------------- Iteration 40 ---------------
[32m[0511 19:21:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5884 mins
[32m[0511 19:21:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0511 19:21:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 19:21:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:21:59 @base_main.py:47][0m 40080 total steps have happened
[32m[0511 19:21:59 @base_main.py:52][0m [avg_reward]: -426.6293816346635
[32m[0511 19:21:59 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:21:59 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:21:59 @base_trainer.py:216][0m Mean reward: -451.86848595335937
[32m[0511 19:22:00 @base_main.py:38][0m --------------- Iteration 41 ---------------
[32m[0511 19:22:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6021 mins
[32m[0511 19:22:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0038 mins
[32m[0511 19:22:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 19:22:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:00 @base_main.py:47][0m 41082 total steps have happened
[32m[0511 19:22:00 @base_main.py:52][0m [avg_reward]: -451.86848595335937
[32m[0511 19:22:00 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:00 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:00 @base_trainer.py:216][0m Mean reward: -434.5632718228085
[32m[0511 19:22:01 @base_main.py:38][0m --------------- Iteration 42 ---------------
[32m[0511 19:22:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6165 mins
[32m[0511 19:22:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0511 19:22:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 19:22:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:01 @base_main.py:47][0m 42084 total steps have happened
[32m[0511 19:22:01 @base_main.py:52][0m [avg_reward]: -434.5632718228085
[32m[0511 19:22:01 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:01 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:01 @base_trainer.py:216][0m Mean reward: -400.0259405043482
[32m[0511 19:22:02 @base_main.py:38][0m --------------- Iteration 43 ---------------
[32m[0511 19:22:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6309 mins
[32m[0511 19:22:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0511 19:22:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 19:22:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:02 @base_main.py:47][0m 43086 total steps have happened
[32m[0511 19:22:02 @base_main.py:52][0m [avg_reward]: -400.0259405043482
[32m[0511 19:22:02 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:02 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:02 @base_trainer.py:216][0m Mean reward: -450.66364451622894
[32m[0511 19:22:02 @base_main.py:38][0m --------------- Iteration 44 ---------------
[32m[0511 19:22:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6454 mins
[32m[0511 19:22:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0038 mins
[32m[0511 19:22:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 19:22:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:02 @base_main.py:47][0m 44088 total steps have happened
[32m[0511 19:22:02 @base_main.py:52][0m [avg_reward]: -450.66364451622894
[32m[0511 19:22:03 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:03 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:03 @base_trainer.py:216][0m Mean reward: -449.61137039491194
[32m[0511 19:22:03 @base_main.py:38][0m --------------- Iteration 45 ---------------
[32m[0511 19:22:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6594 mins
[32m[0511 19:22:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0511 19:22:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 19:22:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:03 @base_main.py:47][0m 45090 total steps have happened
[32m[0511 19:22:03 @base_main.py:52][0m [avg_reward]: -449.61137039491194
[32m[0511 19:22:04 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:04 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:04 @base_trainer.py:216][0m Mean reward: -424.50132051301466
[32m[0511 19:22:04 @base_main.py:38][0m --------------- Iteration 46 ---------------
[32m[0511 19:22:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6737 mins
[32m[0511 19:22:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 19:22:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 19:22:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:04 @base_main.py:47][0m 46092 total steps have happened
[32m[0511 19:22:04 @base_main.py:52][0m [avg_reward]: -424.50132051301466
[32m[0511 19:22:04 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:04 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:04 @base_trainer.py:216][0m Mean reward: -411.879385016284
[32m[0511 19:22:05 @base_main.py:38][0m --------------- Iteration 47 ---------------
[32m[0511 19:22:05 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6884 mins
[32m[0511 19:22:05 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0048 mins
[32m[0511 19:22:05 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 19:22:05 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:05 @base_main.py:47][0m 47094 total steps have happened
[32m[0511 19:22:05 @base_main.py:52][0m [avg_reward]: -411.879385016284
[32m[0511 19:22:05 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:05 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:05 @base_trainer.py:216][0m Mean reward: -431.9571956573372
[32m[0511 19:22:06 @base_main.py:38][0m --------------- Iteration 48 ---------------
[32m[0511 19:22:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7036 mins
[32m[0511 19:22:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0044 mins
[32m[0511 19:22:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 19:22:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:06 @base_main.py:47][0m 48096 total steps have happened
[32m[0511 19:22:06 @base_main.py:52][0m [avg_reward]: -431.9571956573372
[32m[0511 19:22:06 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:06 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:06 @base_trainer.py:216][0m Mean reward: -440.49426679179004
[32m[0511 19:22:07 @base_main.py:38][0m --------------- Iteration 49 ---------------
[32m[0511 19:22:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7182 mins
[32m[0511 19:22:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0036 mins
[32m[0511 19:22:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 19:22:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:07 @base_main.py:47][0m 49098 total steps have happened
[32m[0511 19:22:07 @base_main.py:52][0m [avg_reward]: -440.49426679179004
[32m[0511 19:22:07 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:07 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:07 @base_trainer.py:216][0m Mean reward: -368.41449493158
[32m[0511 19:22:08 @base_main.py:38][0m --------------- Iteration 50 ---------------
[32m[0511 19:22:08 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7319 mins
[32m[0511 19:22:08 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 19:22:08 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0107 mins
[32m[0511 19:22:08 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:08 @base_main.py:47][0m 50100 total steps have happened
[32m[0511 19:22:08 @base_main.py:52][0m [avg_reward]: -368.41449493158
[32m[0511 19:22:08 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:08 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:08 @base_trainer.py:216][0m Mean reward: -378.1046513783974
[32m[0511 19:22:09 @base_main.py:38][0m --------------- Iteration 51 ---------------
[32m[0511 19:22:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7468 mins
[32m[0511 19:22:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 19:22:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0107 mins
[32m[0511 19:22:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:09 @base_main.py:47][0m 51102 total steps have happened
[32m[0511 19:22:09 @base_main.py:52][0m [avg_reward]: -378.1046513783974
[32m[0511 19:22:09 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:09 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:09 @base_trainer.py:216][0m Mean reward: -367.74060117531326
[32m[0511 19:22:09 @base_main.py:38][0m --------------- Iteration 52 ---------------
[32m[0511 19:22:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7616 mins
[32m[0511 19:22:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0046 mins
[32m[0511 19:22:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0511 19:22:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:09 @base_main.py:47][0m 52104 total steps have happened
[32m[0511 19:22:09 @base_main.py:52][0m [avg_reward]: -367.74060117531326
[32m[0511 19:22:10 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:10 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:10 @base_trainer.py:216][0m Mean reward: -389.57930448786476
[32m[0511 19:22:10 @base_main.py:38][0m --------------- Iteration 53 ---------------
[32m[0511 19:22:10 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7756 mins
[32m[0511 19:22:10 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0038 mins
[32m[0511 19:22:10 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 19:22:10 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:10 @base_main.py:47][0m 53106 total steps have happened
[32m[0511 19:22:10 @base_main.py:52][0m [avg_reward]: -389.57930448786476
[32m[0511 19:22:10 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:10 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:10 @base_trainer.py:216][0m Mean reward: -260.1839010003347
[32m[0511 19:22:11 @base_main.py:38][0m --------------- Iteration 54 ---------------
[32m[0511 19:22:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7894 mins
[32m[0511 19:22:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0043 mins
[32m[0511 19:22:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 19:22:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:11 @base_main.py:47][0m 54108 total steps have happened
[32m[0511 19:22:11 @base_main.py:52][0m [avg_reward]: -260.1839010003347
[32m[0511 19:22:11 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:11 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:11 @base_trainer.py:216][0m Mean reward: -304.8054264410986
[32m[0511 19:22:12 @base_main.py:38][0m --------------- Iteration 55 ---------------
[32m[0511 19:22:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8040 mins
[32m[0511 19:22:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0036 mins
[32m[0511 19:22:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 19:22:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:12 @base_main.py:47][0m 55110 total steps have happened
[32m[0511 19:22:12 @base_main.py:52][0m [avg_reward]: -304.8054264410986
[32m[0511 19:22:12 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:12 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:12 @base_trainer.py:216][0m Mean reward: -297.9830534301779
[32m[0511 19:22:13 @base_main.py:38][0m --------------- Iteration 56 ---------------
[32m[0511 19:22:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8179 mins
[32m[0511 19:22:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 19:22:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 19:22:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:13 @base_main.py:47][0m 56112 total steps have happened
[32m[0511 19:22:13 @base_main.py:52][0m [avg_reward]: -297.9830534301779
[32m[0511 19:22:13 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:13 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:13 @base_trainer.py:216][0m Mean reward: -447.42520766380983
[32m[0511 19:22:14 @base_main.py:38][0m --------------- Iteration 57 ---------------
[32m[0511 19:22:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8324 mins
[32m[0511 19:22:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0037 mins
[32m[0511 19:22:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 19:22:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:14 @base_main.py:47][0m 57114 total steps have happened
[32m[0511 19:22:14 @base_main.py:52][0m [avg_reward]: -447.42520766380983
[32m[0511 19:22:14 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:14 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:14 @base_trainer.py:216][0m Mean reward: -368.5646935675894
[32m[0511 19:22:15 @base_main.py:38][0m --------------- Iteration 58 ---------------
[32m[0511 19:22:15 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8463 mins
[32m[0511 19:22:15 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0038 mins
[32m[0511 19:22:15 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 19:22:15 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:15 @base_main.py:47][0m 58116 total steps have happened
[32m[0511 19:22:15 @base_main.py:52][0m [avg_reward]: -368.5646935675894
[32m[0511 19:22:15 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:15 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:15 @base_trainer.py:216][0m Mean reward: -412.3603718236494
[32m[0511 19:22:15 @base_main.py:38][0m --------------- Iteration 59 ---------------
[32m[0511 19:22:15 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8606 mins
[32m[0511 19:22:15 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0038 mins
[32m[0511 19:22:15 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 19:22:15 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:15 @base_main.py:47][0m 59118 total steps have happened
[32m[0511 19:22:15 @base_main.py:52][0m [avg_reward]: -412.3603718236494
[32m[0511 19:22:16 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:16 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:16 @base_trainer.py:216][0m Mean reward: -349.94346056303885
[32m[0511 19:22:16 @base_main.py:38][0m --------------- Iteration 60 ---------------
[32m[0511 19:22:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8749 mins
[32m[0511 19:22:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0044 mins
[32m[0511 19:22:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 19:22:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:16 @base_main.py:47][0m 60120 total steps have happened
[32m[0511 19:22:16 @base_main.py:52][0m [avg_reward]: -349.94346056303885
[32m[0511 19:22:16 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:16 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:17 @base_trainer.py:216][0m Mean reward: -385.1306838547163
[32m[0511 19:22:17 @base_main.py:38][0m --------------- Iteration 61 ---------------
[32m[0511 19:22:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8893 mins
[32m[0511 19:22:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0046 mins
[32m[0511 19:22:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0511 19:22:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:17 @base_main.py:47][0m 61122 total steps have happened
[32m[0511 19:22:17 @base_main.py:52][0m [avg_reward]: -385.1306838547163
[32m[0511 19:22:17 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:17 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:17 @base_trainer.py:216][0m Mean reward: -412.4922582332929
[32m[0511 19:22:18 @base_main.py:38][0m --------------- Iteration 62 ---------------
[32m[0511 19:22:18 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9033 mins
[32m[0511 19:22:18 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0511 19:22:18 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0107 mins
[32m[0511 19:22:18 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:18 @base_main.py:47][0m 62124 total steps have happened
[32m[0511 19:22:18 @base_main.py:52][0m [avg_reward]: -412.4922582332929
[32m[0511 19:22:18 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:18 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:18 @base_trainer.py:216][0m Mean reward: -280.86832327005754
[32m[0511 19:22:19 @base_main.py:38][0m --------------- Iteration 63 ---------------
[32m[0511 19:22:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9183 mins
[32m[0511 19:22:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0049 mins
[32m[0511 19:22:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 19:22:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:19 @base_main.py:47][0m 63126 total steps have happened
[32m[0511 19:22:19 @base_main.py:52][0m [avg_reward]: -280.86832327005754
[32m[0511 19:22:19 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:19 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:19 @base_trainer.py:216][0m Mean reward: -400.6004901078058
[32m[0511 19:22:20 @base_main.py:38][0m --------------- Iteration 64 ---------------
[32m[0511 19:22:20 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9339 mins
[32m[0511 19:22:20 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0051 mins
[32m[0511 19:22:20 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 19:22:20 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:20 @base_main.py:47][0m 64128 total steps have happened
[32m[0511 19:22:20 @base_main.py:52][0m [avg_reward]: -400.6004901078058
[32m[0511 19:22:20 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:20 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:20 @base_trainer.py:216][0m Mean reward: -388.4110577049307
[32m[0511 19:22:21 @base_main.py:38][0m --------------- Iteration 65 ---------------
[32m[0511 19:22:21 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9494 mins
[32m[0511 19:22:21 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 19:22:21 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 19:22:21 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:21 @base_main.py:47][0m 65130 total steps have happened
[32m[0511 19:22:21 @base_main.py:52][0m [avg_reward]: -388.4110577049307
[32m[0511 19:22:21 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:21 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:21 @base_trainer.py:216][0m Mean reward: -394.1110978376568
[32m[0511 19:22:22 @base_main.py:38][0m --------------- Iteration 66 ---------------
[32m[0511 19:22:22 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9641 mins
[32m[0511 19:22:22 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0036 mins
[32m[0511 19:22:22 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 19:22:22 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:22 @base_main.py:47][0m 66132 total steps have happened
[32m[0511 19:22:22 @base_main.py:52][0m [avg_reward]: -394.1110978376568
[32m[0511 19:22:22 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:22 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:22 @base_trainer.py:216][0m Mean reward: -454.23507723040956
[32m[0511 19:22:22 @base_main.py:38][0m --------------- Iteration 67 ---------------
[32m[0511 19:22:22 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9775 mins
[32m[0511 19:22:22 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 19:22:22 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 19:22:22 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:22 @base_main.py:47][0m 67134 total steps have happened
[32m[0511 19:22:22 @base_main.py:52][0m [avg_reward]: -454.23507723040956
[32m[0511 19:22:23 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:23 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:23 @base_trainer.py:216][0m Mean reward: -414.3959304080562
[32m[0511 19:22:23 @base_main.py:38][0m --------------- Iteration 68 ---------------
[32m[0511 19:22:23 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9923 mins
[32m[0511 19:22:23 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0045 mins
[32m[0511 19:22:23 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0107 mins
[32m[0511 19:22:23 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:23 @base_main.py:47][0m 68136 total steps have happened
[32m[0511 19:22:23 @base_main.py:52][0m [avg_reward]: -414.3959304080562
[32m[0511 19:22:24 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:24 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:24 @base_trainer.py:216][0m Mean reward: -357.4244027006617
[32m[0511 19:22:24 @base_main.py:38][0m --------------- Iteration 69 ---------------
[32m[0511 19:22:24 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0076 mins
[32m[0511 19:22:24 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 19:22:24 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 19:22:24 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:24 @base_main.py:47][0m 69138 total steps have happened
[32m[0511 19:22:24 @base_main.py:52][0m [avg_reward]: -357.4244027006617
[32m[0511 19:22:24 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:24 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:24 @base_trainer.py:216][0m Mean reward: -357.4244027006617
[32m[0511 19:22:25 @base_main.py:38][0m --------------- Iteration 70 ---------------
[32m[0511 19:22:25 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0219 mins
[32m[0511 19:22:25 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0045 mins
[32m[0511 19:22:25 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 19:22:25 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:25 @base_main.py:47][0m 70140 total steps have happened
[32m[0511 19:22:25 @base_main.py:52][0m [avg_reward]: -357.4244027006617
[32m[0511 19:22:25 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:25 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:25 @base_trainer.py:216][0m Mean reward: -395.54698338822936
[32m[0511 19:22:26 @base_main.py:38][0m --------------- Iteration 71 ---------------
[32m[0511 19:22:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0371 mins
[32m[0511 19:22:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0511 19:22:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0107 mins
[32m[0511 19:22:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:26 @base_main.py:47][0m 71142 total steps have happened
[32m[0511 19:22:26 @base_main.py:52][0m [avg_reward]: -395.54698338822936
[32m[0511 19:22:26 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:26 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:26 @base_trainer.py:216][0m Mean reward: -439.90130353138346
[32m[0511 19:22:27 @base_main.py:38][0m --------------- Iteration 72 ---------------
[32m[0511 19:22:27 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0519 mins
[32m[0511 19:22:27 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0511 19:22:27 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 19:22:27 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:27 @base_main.py:47][0m 72144 total steps have happened
[32m[0511 19:22:27 @base_main.py:52][0m [avg_reward]: -439.90130353138346
[32m[0511 19:22:27 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:27 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:27 @base_trainer.py:216][0m Mean reward: -349.6654483134432
[32m[0511 19:22:28 @base_main.py:38][0m --------------- Iteration 73 ---------------
[32m[0511 19:22:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0669 mins
[32m[0511 19:22:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 19:22:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0107 mins
[32m[0511 19:22:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:28 @base_main.py:47][0m 73146 total steps have happened
[32m[0511 19:22:28 @base_main.py:52][0m [avg_reward]: -349.6654483134432
[32m[0511 19:22:28 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:28 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:28 @base_trainer.py:216][0m Mean reward: -379.4288652525241
[32m[0511 19:22:29 @base_main.py:38][0m --------------- Iteration 74 ---------------
[32m[0511 19:22:29 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0817 mins
[32m[0511 19:22:29 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0038 mins
[32m[0511 19:22:29 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0108 mins
[32m[0511 19:22:29 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:29 @base_main.py:47][0m 74148 total steps have happened
[32m[0511 19:22:29 @base_main.py:52][0m [avg_reward]: -379.4288652525241
[32m[0511 19:22:29 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:29 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:29 @base_trainer.py:216][0m Mean reward: -331.4580379736616
[32m[0511 19:22:30 @base_main.py:38][0m --------------- Iteration 75 ---------------
[32m[0511 19:22:30 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0964 mins
[32m[0511 19:22:30 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0511 19:22:30 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 19:22:30 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:30 @base_main.py:47][0m 75150 total steps have happened
[32m[0511 19:22:30 @base_main.py:52][0m [avg_reward]: -331.4580379736616
[32m[0511 19:22:30 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:30 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:30 @base_trainer.py:216][0m Mean reward: -376.2000615207853
[32m[0511 19:22:30 @base_main.py:38][0m --------------- Iteration 76 ---------------
[32m[0511 19:22:30 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1110 mins
[32m[0511 19:22:30 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0044 mins
[32m[0511 19:22:30 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 19:22:30 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:30 @base_main.py:47][0m 76152 total steps have happened
[32m[0511 19:22:30 @base_main.py:52][0m [avg_reward]: -376.2000615207853
[32m[0511 19:22:31 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:31 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:31 @base_trainer.py:216][0m Mean reward: -362.7298039007751
[32m[0511 19:22:31 @base_main.py:38][0m --------------- Iteration 77 ---------------
[32m[0511 19:22:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1260 mins
[32m[0511 19:22:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0034 mins
[32m[0511 19:22:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 19:22:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:31 @base_main.py:47][0m 77154 total steps have happened
[32m[0511 19:22:31 @base_main.py:52][0m [avg_reward]: -362.7298039007751
[32m[0511 19:22:31 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:31 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:31 @base_trainer.py:216][0m Mean reward: -338.9051710915943
[32m[0511 19:22:32 @base_main.py:38][0m --------------- Iteration 78 ---------------
[32m[0511 19:22:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1395 mins
[32m[0511 19:22:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0511 19:22:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 19:22:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:32 @base_main.py:47][0m 78156 total steps have happened
[32m[0511 19:22:32 @base_main.py:52][0m [avg_reward]: -338.9051710915943
[32m[0511 19:22:32 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:32 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:32 @base_trainer.py:216][0m Mean reward: -355.0776434897529
[32m[0511 19:22:33 @base_main.py:38][0m --------------- Iteration 79 ---------------
[32m[0511 19:22:33 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1543 mins
[32m[0511 19:22:33 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 19:22:33 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 19:22:33 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:33 @base_main.py:47][0m 79158 total steps have happened
[32m[0511 19:22:33 @base_main.py:52][0m [avg_reward]: -355.0776434897529
[32m[0511 19:22:33 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:33 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:33 @base_trainer.py:216][0m Mean reward: -358.112947627358
[32m[0511 19:22:34 @base_main.py:38][0m --------------- Iteration 80 ---------------
[32m[0511 19:22:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1682 mins
[32m[0511 19:22:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0511 19:22:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 19:22:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:34 @base_main.py:47][0m 80160 total steps have happened
[32m[0511 19:22:34 @base_main.py:52][0m [avg_reward]: -358.112947627358
[32m[0511 19:22:34 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:34 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:34 @base_trainer.py:216][0m Mean reward: -336.8989237575365
[32m[0511 19:22:35 @base_main.py:38][0m --------------- Iteration 81 ---------------
[32m[0511 19:22:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1826 mins
[32m[0511 19:22:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0511 19:22:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 19:22:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:35 @base_main.py:47][0m 81162 total steps have happened
[32m[0511 19:22:35 @base_main.py:52][0m [avg_reward]: -336.8989237575365
[32m[0511 19:22:35 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:35 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:35 @base_trainer.py:216][0m Mean reward: -327.28377371453905
[32m[0511 19:22:36 @base_main.py:38][0m --------------- Iteration 82 ---------------
[32m[0511 19:22:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1973 mins
[32m[0511 19:22:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0511 19:22:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 19:22:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:36 @base_main.py:47][0m 82164 total steps have happened
[32m[0511 19:22:36 @base_main.py:52][0m [avg_reward]: -327.28377371453905
[32m[0511 19:22:36 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:36 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:36 @base_trainer.py:216][0m Mean reward: -339.8434208751616
[32m[0511 19:22:36 @base_main.py:38][0m --------------- Iteration 83 ---------------
[32m[0511 19:22:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2113 mins
[32m[0511 19:22:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0044 mins
[32m[0511 19:22:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 19:22:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:36 @base_main.py:47][0m 83166 total steps have happened
[32m[0511 19:22:36 @base_main.py:52][0m [avg_reward]: -339.8434208751616
[32m[0511 19:22:37 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:37 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:37 @base_trainer.py:216][0m Mean reward: -358.1489445366279
[32m[0511 19:22:37 @base_main.py:38][0m --------------- Iteration 84 ---------------
[32m[0511 19:22:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2265 mins
[32m[0511 19:22:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0045 mins
[32m[0511 19:22:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0511 19:22:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:37 @base_main.py:47][0m 84168 total steps have happened
[32m[0511 19:22:37 @base_main.py:52][0m [avg_reward]: -358.1489445366279
[32m[0511 19:22:38 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:38 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:38 @base_trainer.py:216][0m Mean reward: -331.2781996682121
[32m[0511 19:22:38 @base_main.py:38][0m --------------- Iteration 85 ---------------
[32m[0511 19:22:38 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2400 mins
[32m[0511 19:22:38 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0045 mins
[32m[0511 19:22:38 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 19:22:38 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:38 @base_main.py:47][0m 85170 total steps have happened
[32m[0511 19:22:38 @base_main.py:52][0m [avg_reward]: -331.2781996682121
[32m[0511 19:22:38 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:38 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:38 @base_trainer.py:216][0m Mean reward: -342.87678998912884
[32m[0511 19:22:39 @base_main.py:38][0m --------------- Iteration 86 ---------------
[32m[0511 19:22:39 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2548 mins
[32m[0511 19:22:39 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 19:22:39 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 19:22:39 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:39 @base_main.py:47][0m 86172 total steps have happened
[32m[0511 19:22:39 @base_main.py:52][0m [avg_reward]: -342.87678998912884
[32m[0511 19:22:39 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:39 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:39 @base_trainer.py:216][0m Mean reward: -315.1963874347792
[32m[0511 19:22:40 @base_main.py:38][0m --------------- Iteration 87 ---------------
[32m[0511 19:22:40 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2695 mins
[32m[0511 19:22:40 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0044 mins
[32m[0511 19:22:40 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 19:22:40 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:40 @base_main.py:47][0m 87174 total steps have happened
[32m[0511 19:22:40 @base_main.py:52][0m [avg_reward]: -315.1963874347792
[32m[0511 19:22:40 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:40 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:40 @base_trainer.py:216][0m Mean reward: -333.3549275136118
[32m[0511 19:22:41 @base_main.py:38][0m --------------- Iteration 88 ---------------
[32m[0511 19:22:41 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2847 mins
[32m[0511 19:22:41 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0511 19:22:41 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0108 mins
[32m[0511 19:22:41 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:41 @base_main.py:47][0m 88176 total steps have happened
[32m[0511 19:22:41 @base_main.py:52][0m [avg_reward]: -333.3549275136118
[32m[0511 19:22:41 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:41 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:41 @base_trainer.py:216][0m Mean reward: -316.597458328603
[32m[0511 19:22:42 @base_main.py:38][0m --------------- Iteration 89 ---------------
[32m[0511 19:22:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2998 mins
[32m[0511 19:22:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0048 mins
[32m[0511 19:22:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 19:22:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:42 @base_main.py:47][0m 89178 total steps have happened
[32m[0511 19:22:42 @base_main.py:52][0m [avg_reward]: -316.597458328603
[32m[0511 19:22:42 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:42 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:42 @base_trainer.py:216][0m Mean reward: -347.2405212344784
[32m[0511 19:22:43 @base_main.py:38][0m --------------- Iteration 90 ---------------
[32m[0511 19:22:43 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3147 mins
[32m[0511 19:22:43 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 19:22:43 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 19:22:43 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:43 @base_main.py:47][0m 90180 total steps have happened
[32m[0511 19:22:43 @base_main.py:52][0m [avg_reward]: -347.2405212344784
[32m[0511 19:22:43 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:43 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:43 @base_trainer.py:216][0m Mean reward: -302.69912827420296
[32m[0511 19:22:43 @base_main.py:38][0m --------------- Iteration 91 ---------------
[32m[0511 19:22:43 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3288 mins
[32m[0511 19:22:43 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0043 mins
[32m[0511 19:22:43 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 19:22:43 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:43 @base_main.py:47][0m 91182 total steps have happened
[32m[0511 19:22:43 @base_main.py:52][0m [avg_reward]: -302.69912827420296
[32m[0511 19:22:44 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:44 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:44 @base_trainer.py:216][0m Mean reward: -319.055682586815
[32m[0511 19:22:44 @base_main.py:38][0m --------------- Iteration 92 ---------------
[32m[0511 19:22:44 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3430 mins
[32m[0511 19:22:44 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0037 mins
[32m[0511 19:22:44 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0107 mins
[32m[0511 19:22:44 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:44 @base_main.py:47][0m 92184 total steps have happened
[32m[0511 19:22:44 @base_main.py:52][0m [avg_reward]: -319.055682586815
[32m[0511 19:22:45 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:45 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:45 @base_trainer.py:216][0m Mean reward: -357.84070164843433
[32m[0511 19:22:45 @base_main.py:38][0m --------------- Iteration 93 ---------------
[32m[0511 19:22:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3576 mins
[32m[0511 19:22:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0038 mins
[32m[0511 19:22:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 19:22:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:45 @base_main.py:47][0m 93186 total steps have happened
[32m[0511 19:22:45 @base_main.py:52][0m [avg_reward]: -357.84070164843433
[32m[0511 19:22:45 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:45 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:45 @base_trainer.py:216][0m Mean reward: -385.1872815293204
[32m[0511 19:22:46 @base_main.py:38][0m --------------- Iteration 94 ---------------
[32m[0511 19:22:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3721 mins
[32m[0511 19:22:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0511 19:22:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 19:22:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:46 @base_main.py:47][0m 94188 total steps have happened
[32m[0511 19:22:46 @base_main.py:52][0m [avg_reward]: -385.1872815293204
[32m[0511 19:22:46 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:46 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:46 @base_trainer.py:216][0m Mean reward: -388.75933112975815
[32m[0511 19:22:47 @base_main.py:38][0m --------------- Iteration 95 ---------------
[32m[0511 19:22:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3868 mins
[32m[0511 19:22:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0043 mins
[32m[0511 19:22:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 19:22:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:47 @base_main.py:47][0m 95190 total steps have happened
[32m[0511 19:22:47 @base_main.py:52][0m [avg_reward]: -388.75933112975815
[32m[0511 19:22:47 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:47 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:47 @base_trainer.py:216][0m Mean reward: -382.24300728269327
[32m[0511 19:22:48 @base_main.py:38][0m --------------- Iteration 96 ---------------
[32m[0511 19:22:48 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4016 mins
[32m[0511 19:22:48 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0037 mins
[32m[0511 19:22:48 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 19:22:48 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:48 @base_main.py:47][0m 96192 total steps have happened
[32m[0511 19:22:48 @base_main.py:52][0m [avg_reward]: -382.24300728269327
[32m[0511 19:22:48 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:48 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:48 @base_trainer.py:216][0m Mean reward: -384.24360618952926
[32m[0511 19:22:49 @base_main.py:38][0m --------------- Iteration 97 ---------------
[32m[0511 19:22:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4151 mins
[32m[0511 19:22:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0049 mins
[32m[0511 19:22:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 19:22:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:49 @base_main.py:47][0m 97194 total steps have happened
[32m[0511 19:22:49 @base_main.py:52][0m [avg_reward]: -384.24360618952926
[32m[0511 19:22:49 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:49 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:49 @base_trainer.py:216][0m Mean reward: -394.8214540553002
[32m[0511 19:22:50 @base_main.py:38][0m --------------- Iteration 98 ---------------
[32m[0511 19:22:50 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4308 mins
[32m[0511 19:22:50 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0045 mins
[32m[0511 19:22:50 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 19:22:50 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:50 @base_main.py:47][0m 98196 total steps have happened
[32m[0511 19:22:50 @base_main.py:52][0m [avg_reward]: -394.8214540553002
[32m[0511 19:22:50 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:50 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:50 @base_trainer.py:216][0m Mean reward: -394.98373127972684
[32m[0511 19:22:51 @base_main.py:38][0m --------------- Iteration 99 ---------------
[32m[0511 19:22:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4456 mins
[32m[0511 19:22:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0046 mins
[32m[0511 19:22:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 19:22:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:51 @base_main.py:47][0m 99198 total steps have happened
[32m[0511 19:22:51 @base_main.py:52][0m [avg_reward]: -394.98373127972684
[32m[0511 19:22:51 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:51 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:51 @base_trainer.py:216][0m Mean reward: -414.4590578331232
[32m[0511 19:22:51 @base_main.py:38][0m --------------- Iteration 100 ---------------
[32m[0511 19:22:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4606 mins
[32m[0511 19:22:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0046 mins
[32m[0511 19:22:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 19:22:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:51 @base_main.py:47][0m 100200 total steps have happened
[32m[0511 19:22:51 @base_main.py:52][0m [avg_reward]: -414.4590578331232
[32m[0511 19:22:52 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:52 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:52 @base_trainer.py:216][0m Mean reward: -409.3609916852847
[32m[0511 19:22:52 @base_main.py:38][0m --------------- Iteration 101 ---------------
[32m[0511 19:22:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4754 mins
[32m[0511 19:22:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0511 19:22:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 19:22:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:52 @base_main.py:47][0m 101202 total steps have happened
[32m[0511 19:22:52 @base_main.py:52][0m [avg_reward]: -409.3609916852847
[32m[0511 19:22:53 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:53 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:53 @base_trainer.py:216][0m Mean reward: -406.54904789149
[32m[0511 19:22:53 @base_main.py:38][0m --------------- Iteration 102 ---------------
[32m[0511 19:22:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4901 mins
[32m[0511 19:22:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 19:22:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 19:22:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:53 @base_main.py:47][0m 102204 total steps have happened
[32m[0511 19:22:53 @base_main.py:52][0m [avg_reward]: -406.54904789149
[32m[0511 19:22:53 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:53 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:53 @base_trainer.py:216][0m Mean reward: -410.1957101150882
[32m[0511 19:22:54 @base_main.py:38][0m --------------- Iteration 103 ---------------
[32m[0511 19:22:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5048 mins
[32m[0511 19:22:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0511 19:22:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 19:22:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:54 @base_main.py:47][0m 103206 total steps have happened
[32m[0511 19:22:54 @base_main.py:52][0m [avg_reward]: -410.1957101150882
[32m[0511 19:22:54 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:54 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:54 @base_trainer.py:216][0m Mean reward: -416.5222593293206
[32m[0511 19:22:55 @base_main.py:38][0m --------------- Iteration 104 ---------------
[32m[0511 19:22:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5194 mins
[32m[0511 19:22:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0511 19:22:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 19:22:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:55 @base_main.py:47][0m 104208 total steps have happened
[32m[0511 19:22:55 @base_main.py:52][0m [avg_reward]: -416.5222593293206
[32m[0511 19:22:55 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:55 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:55 @base_trainer.py:216][0m Mean reward: -416.91798157297507
[32m[0511 19:22:56 @base_main.py:38][0m --------------- Iteration 105 ---------------
[32m[0511 19:22:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5340 mins
[32m[0511 19:22:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0038 mins
[32m[0511 19:22:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 19:22:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:56 @base_main.py:47][0m 105210 total steps have happened
[32m[0511 19:22:56 @base_main.py:52][0m [avg_reward]: -416.91798157297507
[32m[0511 19:22:56 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:56 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:56 @base_trainer.py:216][0m Mean reward: -423.3505589775286
[32m[0511 19:22:57 @base_main.py:38][0m --------------- Iteration 106 ---------------
[32m[0511 19:22:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5485 mins
[32m[0511 19:22:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0511 19:22:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 19:22:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:57 @base_main.py:47][0m 106212 total steps have happened
[32m[0511 19:22:57 @base_main.py:52][0m [avg_reward]: -423.3505589775286
[32m[0511 19:22:57 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:57 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:57 @base_trainer.py:216][0m Mean reward: -410.42025661284697
[32m[0511 19:22:58 @base_main.py:38][0m --------------- Iteration 107 ---------------
[32m[0511 19:22:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5633 mins
[32m[0511 19:22:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0037 mins
[32m[0511 19:22:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 19:22:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:58 @base_main.py:47][0m 107214 total steps have happened
[32m[0511 19:22:58 @base_main.py:52][0m [avg_reward]: -410.42025661284697
[32m[0511 19:22:58 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:58 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:58 @base_trainer.py:216][0m Mean reward: -415.4001074230515
[32m[0511 19:22:58 @base_main.py:38][0m --------------- Iteration 108 ---------------
[32m[0511 19:22:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5773 mins
[32m[0511 19:22:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 19:22:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 19:22:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0511 19:22:58 @base_main.py:47][0m 108216 total steps have happened
[32m[0511 19:22:58 @base_main.py:52][0m [avg_reward]: -415.4001074230515
[32m[0511 19:22:59 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:59 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:59 @base_trainer.py:216][0m Mean reward: -411.5777179613454
[32m[0511 19:22:59 @base_main.py:38][0m --------------- Iteration 109 ---------------
[32m[0511 19:22:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5911 mins
[32m[0511 19:22:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 19:22:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0511 19:22:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:22:59 @base_main.py:47][0m 109218 total steps have happened
[32m[0511 19:22:59 @base_main.py:52][0m [avg_reward]: -411.5777179613454
[32m[0511 19:22:59 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:22:59 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:22:59 @base_trainer.py:216][0m Mean reward: -412.4430243450411
[32m[0511 19:23:00 @base_main.py:38][0m --------------- Iteration 110 ---------------
[32m[0511 19:23:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6040 mins
[32m[0511 19:23:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0037 mins
[32m[0511 19:23:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 19:23:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:00 @base_main.py:47][0m 110220 total steps have happened
[32m[0511 19:23:00 @base_main.py:52][0m [avg_reward]: -412.4430243450411
[32m[0511 19:23:00 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:00 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:00 @base_trainer.py:216][0m Mean reward: -412.28572214101325
[32m[0511 19:23:01 @base_main.py:38][0m --------------- Iteration 111 ---------------
[32m[0511 19:23:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6183 mins
[32m[0511 19:23:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0038 mins
[32m[0511 19:23:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 19:23:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:01 @base_main.py:47][0m 111222 total steps have happened
[32m[0511 19:23:01 @base_main.py:52][0m [avg_reward]: -412.28572214101325
[32m[0511 19:23:01 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:01 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:01 @base_trainer.py:216][0m Mean reward: -419.0862665767558
[32m[0511 19:23:02 @base_main.py:38][0m --------------- Iteration 112 ---------------
[32m[0511 19:23:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6329 mins
[32m[0511 19:23:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 19:23:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0107 mins
[32m[0511 19:23:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:02 @base_main.py:47][0m 112224 total steps have happened
[32m[0511 19:23:02 @base_main.py:52][0m [avg_reward]: -419.0862665767558
[32m[0511 19:23:02 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:02 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:02 @base_trainer.py:216][0m Mean reward: -426.8946494903351
[32m[0511 19:23:03 @base_main.py:38][0m --------------- Iteration 113 ---------------
[32m[0511 19:23:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6478 mins
[32m[0511 19:23:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0044 mins
[32m[0511 19:23:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 19:23:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:03 @base_main.py:47][0m 113226 total steps have happened
[32m[0511 19:23:03 @base_main.py:52][0m [avg_reward]: -426.8946494903351
[32m[0511 19:23:03 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:03 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:03 @base_trainer.py:216][0m Mean reward: -428.24470393113586
[32m[0511 19:23:04 @base_main.py:38][0m --------------- Iteration 114 ---------------
[32m[0511 19:23:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6629 mins
[32m[0511 19:23:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0511 19:23:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 19:23:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:04 @base_main.py:47][0m 114228 total steps have happened
[32m[0511 19:23:04 @base_main.py:52][0m [avg_reward]: -428.24470393113586
[32m[0511 19:23:04 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:04 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:04 @base_trainer.py:216][0m Mean reward: -421.06810311965495
[32m[0511 19:23:04 @base_main.py:38][0m --------------- Iteration 115 ---------------
[32m[0511 19:23:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6777 mins
[32m[0511 19:23:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0511 19:23:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 19:23:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:04 @base_main.py:47][0m 115230 total steps have happened
[32m[0511 19:23:04 @base_main.py:52][0m [avg_reward]: -421.06810311965495
[32m[0511 19:23:05 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:05 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:05 @base_trainer.py:216][0m Mean reward: -415.23618993854484
[32m[0511 19:23:05 @base_main.py:38][0m --------------- Iteration 116 ---------------
[32m[0511 19:23:05 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6922 mins
[32m[0511 19:23:05 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0044 mins
[32m[0511 19:23:05 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 19:23:05 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:05 @base_main.py:47][0m 116232 total steps have happened
[32m[0511 19:23:05 @base_main.py:52][0m [avg_reward]: -415.23618993854484
[32m[0511 19:23:06 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:06 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:06 @base_trainer.py:216][0m Mean reward: -420.3831565526667
[32m[0511 19:23:06 @base_main.py:38][0m --------------- Iteration 117 ---------------
[32m[0511 19:23:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7067 mins
[32m[0511 19:23:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0511 19:23:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 19:23:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:06 @base_main.py:47][0m 117234 total steps have happened
[32m[0511 19:23:06 @base_main.py:52][0m [avg_reward]: -420.3831565526667
[32m[0511 19:23:06 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:06 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:06 @base_trainer.py:216][0m Mean reward: -452.14679107653484
[32m[0511 19:23:07 @base_main.py:38][0m --------------- Iteration 118 ---------------
[32m[0511 19:23:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7209 mins
[32m[0511 19:23:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0044 mins
[32m[0511 19:23:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 19:23:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:07 @base_main.py:47][0m 118236 total steps have happened
[32m[0511 19:23:07 @base_main.py:52][0m [avg_reward]: -452.14679107653484
[32m[0511 19:23:07 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:07 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:07 @base_trainer.py:216][0m Mean reward: -436.8655215982911
[32m[0511 19:23:08 @base_main.py:38][0m --------------- Iteration 119 ---------------
[32m[0511 19:23:08 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7357 mins
[32m[0511 19:23:08 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0048 mins
[32m[0511 19:23:08 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0511 19:23:08 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:08 @base_main.py:47][0m 119238 total steps have happened
[32m[0511 19:23:08 @base_main.py:52][0m [avg_reward]: -436.8655215982911
[32m[0511 19:23:08 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:08 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:08 @base_trainer.py:216][0m Mean reward: -421.3495569517942
[32m[0511 19:23:09 @base_main.py:38][0m --------------- Iteration 120 ---------------
[32m[0511 19:23:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7494 mins
[32m[0511 19:23:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0511 19:23:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 19:23:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:09 @base_main.py:47][0m 120240 total steps have happened
[32m[0511 19:23:09 @base_main.py:52][0m [avg_reward]: -421.3495569517942
[32m[0511 19:23:09 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:09 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:09 @base_trainer.py:216][0m Mean reward: -421.08240648511264
[32m[0511 19:23:10 @base_main.py:38][0m --------------- Iteration 121 ---------------
[32m[0511 19:23:10 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7640 mins
[32m[0511 19:23:10 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0037 mins
[32m[0511 19:23:10 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 19:23:10 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:10 @base_main.py:47][0m 121242 total steps have happened
[32m[0511 19:23:10 @base_main.py:52][0m [avg_reward]: -421.08240648511264
[32m[0511 19:23:10 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:10 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:10 @base_trainer.py:216][0m Mean reward: -411.42865691621785
[32m[0511 19:23:10 @base_main.py:38][0m --------------- Iteration 122 ---------------
[32m[0511 19:23:10 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7778 mins
[32m[0511 19:23:10 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0511 19:23:10 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 19:23:10 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:10 @base_main.py:47][0m 122244 total steps have happened
[32m[0511 19:23:10 @base_main.py:52][0m [avg_reward]: -411.42865691621785
[32m[0511 19:23:11 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:11 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:11 @base_trainer.py:216][0m Mean reward: -412.8208822311609
[32m[0511 19:23:11 @base_main.py:38][0m --------------- Iteration 123 ---------------
[32m[0511 19:23:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7919 mins
[32m[0511 19:23:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0045 mins
[32m[0511 19:23:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 19:23:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:11 @base_main.py:47][0m 123246 total steps have happened
[32m[0511 19:23:11 @base_main.py:52][0m [avg_reward]: -412.8208822311609
[32m[0511 19:23:12 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:12 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:12 @base_trainer.py:216][0m Mean reward: -402.8741017948048
[32m[0511 19:23:12 @base_main.py:38][0m --------------- Iteration 124 ---------------
[32m[0511 19:23:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8069 mins
[32m[0511 19:23:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0043 mins
[32m[0511 19:23:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 19:23:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:12 @base_main.py:47][0m 124248 total steps have happened
[32m[0511 19:23:12 @base_main.py:52][0m [avg_reward]: -402.8741017948048
[32m[0511 19:23:12 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:12 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:12 @base_trainer.py:216][0m Mean reward: -396.88653066962905
[32m[0511 19:23:13 @base_main.py:38][0m --------------- Iteration 125 ---------------
[32m[0511 19:23:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8217 mins
[32m[0511 19:23:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0038 mins
[32m[0511 19:23:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 19:23:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:13 @base_main.py:47][0m 125250 total steps have happened
[32m[0511 19:23:13 @base_main.py:52][0m [avg_reward]: -396.88653066962905
[32m[0511 19:23:13 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:13 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:13 @base_trainer.py:216][0m Mean reward: -393.85738094585736
[32m[0511 19:23:14 @base_main.py:38][0m --------------- Iteration 126 ---------------
[32m[0511 19:23:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8356 mins
[32m[0511 19:23:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0511 19:23:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 19:23:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:14 @base_main.py:47][0m 126252 total steps have happened
[32m[0511 19:23:14 @base_main.py:52][0m [avg_reward]: -393.85738094585736
[32m[0511 19:23:14 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:14 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:14 @base_trainer.py:216][0m Mean reward: -384.77899812040425
[32m[0511 19:23:15 @base_main.py:38][0m --------------- Iteration 127 ---------------
[32m[0511 19:23:15 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8495 mins
[32m[0511 19:23:15 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0036 mins
[32m[0511 19:23:15 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 19:23:15 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:15 @base_main.py:47][0m 127254 total steps have happened
[32m[0511 19:23:15 @base_main.py:52][0m [avg_reward]: -384.77899812040425
[32m[0511 19:23:15 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:15 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:15 @base_trainer.py:216][0m Mean reward: -388.39365024840083
[32m[0511 19:23:16 @base_main.py:38][0m --------------- Iteration 128 ---------------
[32m[0511 19:23:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8634 mins
[32m[0511 19:23:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0038 mins
[32m[0511 19:23:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 19:23:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:16 @base_main.py:47][0m 128256 total steps have happened
[32m[0511 19:23:16 @base_main.py:52][0m [avg_reward]: -388.39365024840083
[32m[0511 19:23:16 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:16 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:16 @base_trainer.py:216][0m Mean reward: -394.2503718033605
[32m[0511 19:23:16 @base_main.py:38][0m --------------- Iteration 129 ---------------
[32m[0511 19:23:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8779 mins
[32m[0511 19:23:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0044 mins
[32m[0511 19:23:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 19:23:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:16 @base_main.py:47][0m 129258 total steps have happened
[32m[0511 19:23:16 @base_main.py:52][0m [avg_reward]: -394.2503718033605
[32m[0511 19:23:17 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:17 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:17 @base_trainer.py:216][0m Mean reward: -375.94490130550116
[32m[0511 19:23:17 @base_main.py:38][0m --------------- Iteration 130 ---------------
[32m[0511 19:23:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8928 mins
[32m[0511 19:23:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0045 mins
[32m[0511 19:23:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 19:23:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:17 @base_main.py:47][0m 130260 total steps have happened
[32m[0511 19:23:17 @base_main.py:52][0m [avg_reward]: -375.94490130550116
[32m[0511 19:23:18 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:18 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:18 @base_trainer.py:216][0m Mean reward: -388.07668499928286
[32m[0511 19:23:18 @base_main.py:38][0m --------------- Iteration 131 ---------------
[32m[0511 19:23:18 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9071 mins
[32m[0511 19:23:18 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0044 mins
[32m[0511 19:23:18 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 19:23:18 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:18 @base_main.py:47][0m 131262 total steps have happened
[32m[0511 19:23:18 @base_main.py:52][0m [avg_reward]: -388.07668499928286
[32m[0511 19:23:18 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:18 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:18 @base_trainer.py:216][0m Mean reward: -391.4086008538018
[32m[0511 19:23:19 @base_main.py:38][0m --------------- Iteration 132 ---------------
[32m[0511 19:23:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9217 mins
[32m[0511 19:23:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0043 mins
[32m[0511 19:23:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 19:23:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:19 @base_main.py:47][0m 132264 total steps have happened
[32m[0511 19:23:19 @base_main.py:52][0m [avg_reward]: -391.4086008538018
[32m[0511 19:23:19 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:19 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:19 @base_trainer.py:216][0m Mean reward: -346.8238112306957
[32m[0511 19:23:20 @base_main.py:38][0m --------------- Iteration 133 ---------------
[32m[0511 19:23:20 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9365 mins
[32m[0511 19:23:20 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0511 19:23:20 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 19:23:20 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:20 @base_main.py:47][0m 133266 total steps have happened
[32m[0511 19:23:20 @base_main.py:52][0m [avg_reward]: -346.8238112306957
[32m[0511 19:23:20 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:20 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:20 @base_trainer.py:216][0m Mean reward: -379.9149278453176
[32m[0511 19:23:21 @base_main.py:38][0m --------------- Iteration 134 ---------------
[32m[0511 19:23:21 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9509 mins
[32m[0511 19:23:21 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0045 mins
[32m[0511 19:23:21 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 19:23:21 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:21 @base_main.py:47][0m 134268 total steps have happened
[32m[0511 19:23:21 @base_main.py:52][0m [avg_reward]: -379.9149278453176
[32m[0511 19:23:21 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:21 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:21 @base_trainer.py:216][0m Mean reward: -352.0027703309392
[32m[0511 19:23:22 @base_main.py:38][0m --------------- Iteration 135 ---------------
[32m[0511 19:23:22 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9655 mins
[32m[0511 19:23:22 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0511 19:23:22 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 19:23:22 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:22 @base_main.py:47][0m 135270 total steps have happened
[32m[0511 19:23:22 @base_main.py:52][0m [avg_reward]: -352.0027703309392
[32m[0511 19:23:22 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:22 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:22 @base_trainer.py:216][0m Mean reward: -356.68695619801554
[32m[0511 19:23:23 @base_main.py:38][0m --------------- Iteration 136 ---------------
[32m[0511 19:23:23 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9796 mins
[32m[0511 19:23:23 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 19:23:23 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 19:23:23 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:23 @base_main.py:47][0m 136272 total steps have happened
[32m[0511 19:23:23 @base_main.py:52][0m [avg_reward]: -356.68695619801554
[32m[0511 19:23:23 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:23 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:23 @base_trainer.py:216][0m Mean reward: -367.0314635852917
[32m[0511 19:23:23 @base_main.py:38][0m --------------- Iteration 137 ---------------
[32m[0511 19:23:23 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9942 mins
[32m[0511 19:23:23 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0511 19:23:23 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 19:23:23 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:23 @base_main.py:47][0m 137274 total steps have happened
[32m[0511 19:23:23 @base_main.py:52][0m [avg_reward]: -367.0314635852917
[32m[0511 19:23:24 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:24 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:24 @base_trainer.py:216][0m Mean reward: -358.44931949124316
[32m[0511 19:23:24 @base_main.py:38][0m --------------- Iteration 138 ---------------
[32m[0511 19:23:24 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0088 mins
[32m[0511 19:23:24 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 19:23:24 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 19:23:24 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:24 @base_main.py:47][0m 138276 total steps have happened
[32m[0511 19:23:24 @base_main.py:52][0m [avg_reward]: -358.44931949124316
[32m[0511 19:23:24 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:24 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:24 @base_trainer.py:216][0m Mean reward: -373.6176784673129
[32m[0511 19:23:25 @base_main.py:38][0m --------------- Iteration 139 ---------------
[32m[0511 19:23:25 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0233 mins
[32m[0511 19:23:25 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0037 mins
[32m[0511 19:23:25 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 19:23:25 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:25 @base_main.py:47][0m 139278 total steps have happened
[32m[0511 19:23:25 @base_main.py:52][0m [avg_reward]: -373.6176784673129
[32m[0511 19:23:25 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:25 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:25 @base_trainer.py:216][0m Mean reward: -364.61657121696487
[32m[0511 19:23:26 @base_main.py:38][0m --------------- Iteration 140 ---------------
[32m[0511 19:23:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0377 mins
[32m[0511 19:23:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0511 19:23:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 19:23:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:26 @base_main.py:47][0m 140280 total steps have happened
[32m[0511 19:23:26 @base_main.py:52][0m [avg_reward]: -364.61657121696487
[32m[0511 19:23:26 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:26 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:26 @base_trainer.py:216][0m Mean reward: -383.9094505332565
[32m[0511 19:23:27 @base_main.py:38][0m --------------- Iteration 141 ---------------
[32m[0511 19:23:27 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0525 mins
[32m[0511 19:23:27 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0052 mins
[32m[0511 19:23:27 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 19:23:27 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:27 @base_main.py:47][0m 141282 total steps have happened
[32m[0511 19:23:27 @base_main.py:52][0m [avg_reward]: -383.9094505332565
[32m[0511 19:23:27 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:27 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:27 @base_trainer.py:216][0m Mean reward: -379.39349584812294
[32m[0511 19:23:28 @base_main.py:38][0m --------------- Iteration 142 ---------------
[32m[0511 19:23:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0684 mins
[32m[0511 19:23:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0043 mins
[32m[0511 19:23:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 19:23:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:28 @base_main.py:47][0m 142284 total steps have happened
[32m[0511 19:23:28 @base_main.py:52][0m [avg_reward]: -379.39349584812294
[32m[0511 19:23:28 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:28 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:28 @base_trainer.py:216][0m Mean reward: -370.96483138282514
[32m[0511 19:23:29 @base_main.py:38][0m --------------- Iteration 143 ---------------
[32m[0511 19:23:29 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0832 mins
[32m[0511 19:23:29 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 19:23:29 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 19:23:29 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:29 @base_main.py:47][0m 143286 total steps have happened
[32m[0511 19:23:29 @base_main.py:52][0m [avg_reward]: -370.96483138282514
[32m[0511 19:23:29 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:29 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:29 @base_trainer.py:216][0m Mean reward: -349.71321407300235
[32m[0511 19:23:30 @base_main.py:38][0m --------------- Iteration 144 ---------------
[32m[0511 19:23:30 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0971 mins
[32m[0511 19:23:30 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0511 19:23:30 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 19:23:30 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:30 @base_main.py:47][0m 144288 total steps have happened
[32m[0511 19:23:30 @base_main.py:52][0m [avg_reward]: -349.71321407300235
[32m[0511 19:23:30 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:30 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:30 @base_trainer.py:216][0m Mean reward: -362.16216506688534
[32m[0511 19:23:30 @base_main.py:38][0m --------------- Iteration 145 ---------------
[32m[0511 19:23:30 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1116 mins
[32m[0511 19:23:30 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0511 19:23:30 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 19:23:30 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:30 @base_main.py:47][0m 145290 total steps have happened
[32m[0511 19:23:30 @base_main.py:52][0m [avg_reward]: -362.16216506688534
[32m[0511 19:23:31 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:31 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:31 @base_trainer.py:216][0m Mean reward: -371.8417940122402
[32m[0511 19:23:31 @base_main.py:38][0m --------------- Iteration 146 ---------------
[32m[0511 19:23:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1260 mins
[32m[0511 19:23:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0511 19:23:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 19:23:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:31 @base_main.py:47][0m 146292 total steps have happened
[32m[0511 19:23:31 @base_main.py:52][0m [avg_reward]: -371.8417940122402
[32m[0511 19:23:32 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:32 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:32 @base_trainer.py:216][0m Mean reward: -347.17123949605684
[32m[0511 19:23:32 @base_main.py:38][0m --------------- Iteration 147 ---------------
[32m[0511 19:23:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1404 mins
[32m[0511 19:23:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0511 19:23:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 19:23:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0511 19:23:32 @base_main.py:47][0m 147294 total steps have happened
[32m[0511 19:23:32 @base_main.py:52][0m [avg_reward]: -347.17123949605684
[32m[0511 19:23:32 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:32 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:32 @base_trainer.py:216][0m Mean reward: -377.4437653310713
[32m[0511 19:23:33 @base_main.py:38][0m --------------- Iteration 148 ---------------
[32m[0511 19:23:33 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1546 mins
[32m[0511 19:23:33 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 19:23:33 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 19:23:33 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:33 @base_main.py:47][0m 148296 total steps have happened
[32m[0511 19:23:33 @base_main.py:52][0m [avg_reward]: -377.4437653310713
[32m[0511 19:23:33 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:33 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:33 @base_trainer.py:216][0m Mean reward: -353.0686434914488
[32m[0511 19:23:34 @base_main.py:38][0m --------------- Iteration 149 ---------------
[32m[0511 19:23:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1686 mins
[32m[0511 19:23:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0511 19:23:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 19:23:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:34 @base_main.py:47][0m 149298 total steps have happened
[32m[0511 19:23:34 @base_main.py:52][0m [avg_reward]: -353.0686434914488
[32m[0511 19:23:34 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:34 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:34 @base_trainer.py:216][0m Mean reward: -371.28315416619205
[32m[0511 19:23:35 @base_main.py:38][0m --------------- Iteration 150 ---------------
[32m[0511 19:23:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1831 mins
[32m[0511 19:23:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0043 mins
[32m[0511 19:23:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 19:23:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0511 19:23:35 @base_main.py:47][0m 150300 total steps have happened
[32m[0511 19:23:35 @base_main.py:52][0m [avg_reward]: -371.28315416619205
[32m[0511 19:23:35 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:35 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:35 @base_trainer.py:216][0m Mean reward: -374.82093024220313
[32m[0511 19:23:36 @base_main.py:38][0m --------------- Iteration 151 ---------------
[32m[0511 19:23:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1978 mins
[32m[0511 19:23:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0511 19:23:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 19:23:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:36 @base_main.py:47][0m 151302 total steps have happened
[32m[0511 19:23:36 @base_main.py:52][0m [avg_reward]: -374.82093024220313
[32m[0511 19:23:36 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:36 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:36 @base_trainer.py:216][0m Mean reward: -368.56780492795747
[32m[0511 19:23:37 @base_main.py:38][0m --------------- Iteration 152 ---------------
[32m[0511 19:23:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2124 mins
[32m[0511 19:23:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0048 mins
[32m[0511 19:23:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 19:23:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:37 @base_main.py:47][0m 152304 total steps have happened
[32m[0511 19:23:37 @base_main.py:52][0m [avg_reward]: -368.56780492795747
[32m[0511 19:23:37 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:37 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:37 @base_trainer.py:216][0m Mean reward: -374.8438111654214
[32m[0511 19:23:37 @base_main.py:38][0m --------------- Iteration 153 ---------------
[32m[0511 19:23:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2279 mins
[32m[0511 19:23:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0044 mins
[32m[0511 19:23:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 19:23:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:37 @base_main.py:47][0m 153306 total steps have happened
[32m[0511 19:23:37 @base_main.py:52][0m [avg_reward]: -374.8438111654214
[32m[0511 19:23:38 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:38 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:38 @base_trainer.py:216][0m Mean reward: -353.2514041299487
[32m[0511 19:23:38 @base_main.py:38][0m --------------- Iteration 154 ---------------
[32m[0511 19:23:38 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2427 mins
[32m[0511 19:23:38 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0043 mins
[32m[0511 19:23:38 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 19:23:38 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0511 19:23:38 @base_main.py:47][0m 154308 total steps have happened
[32m[0511 19:23:38 @base_main.py:52][0m [avg_reward]: -353.2514041299487
[32m[0511 19:23:39 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:39 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:39 @base_trainer.py:216][0m Mean reward: -365.1527329229693
[32m[0511 19:23:39 @base_main.py:38][0m --------------- Iteration 155 ---------------
[32m[0511 19:23:39 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2576 mins
[32m[0511 19:23:39 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0044 mins
[32m[0511 19:23:39 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 19:23:39 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:39 @base_main.py:47][0m 155310 total steps have happened
[32m[0511 19:23:39 @base_main.py:52][0m [avg_reward]: -365.1527329229693
[32m[0511 19:23:39 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:39 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:39 @base_trainer.py:216][0m Mean reward: -353.0162062620184
[32m[0511 19:23:40 @base_main.py:38][0m --------------- Iteration 156 ---------------
[32m[0511 19:23:40 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2724 mins
[32m[0511 19:23:40 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 19:23:40 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 19:23:40 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:40 @base_main.py:47][0m 156312 total steps have happened
[32m[0511 19:23:40 @base_main.py:52][0m [avg_reward]: -353.0162062620184
[32m[0511 19:23:40 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:40 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:40 @base_trainer.py:216][0m Mean reward: -345.85596199458587
[32m[0511 19:23:41 @base_main.py:38][0m --------------- Iteration 157 ---------------
[32m[0511 19:23:41 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2869 mins
[32m[0511 19:23:41 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0045 mins
[32m[0511 19:23:41 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 19:23:41 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:41 @base_main.py:47][0m 157314 total steps have happened
[32m[0511 19:23:41 @base_main.py:52][0m [avg_reward]: -345.85596199458587
[32m[0511 19:23:41 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:41 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:41 @base_trainer.py:216][0m Mean reward: -328.9591751475416
[32m[0511 19:23:42 @base_main.py:38][0m --------------- Iteration 158 ---------------
[32m[0511 19:23:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3015 mins
[32m[0511 19:23:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0038 mins
[32m[0511 19:23:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 19:23:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:42 @base_main.py:47][0m 158316 total steps have happened
[32m[0511 19:23:42 @base_main.py:52][0m [avg_reward]: -328.9591751475416
[32m[0511 19:23:42 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:42 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:42 @base_trainer.py:216][0m Mean reward: -344.9857723077039
[32m[0511 19:23:43 @base_main.py:38][0m --------------- Iteration 159 ---------------
[32m[0511 19:23:43 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3156 mins
[32m[0511 19:23:43 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0511 19:23:43 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 19:23:43 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:43 @base_main.py:47][0m 159318 total steps have happened
[32m[0511 19:23:43 @base_main.py:52][0m [avg_reward]: -344.9857723077039
[32m[0511 19:23:43 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:43 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:43 @base_trainer.py:216][0m Mean reward: -356.22574766601804
[32m[0511 19:23:44 @base_main.py:38][0m --------------- Iteration 160 ---------------
[32m[0511 19:23:44 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3298 mins
[32m[0511 19:23:44 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0043 mins
[32m[0511 19:23:44 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 19:23:44 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:44 @base_main.py:47][0m 160320 total steps have happened
[32m[0511 19:23:44 @base_main.py:52][0m [avg_reward]: -356.22574766601804
[32m[0511 19:23:44 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:44 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:44 @base_trainer.py:216][0m Mean reward: -315.335038512963
[32m[0511 19:23:44 @base_main.py:38][0m --------------- Iteration 161 ---------------
[32m[0511 19:23:44 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3442 mins
[32m[0511 19:23:44 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0038 mins
[32m[0511 19:23:44 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 19:23:44 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:44 @base_main.py:47][0m 161322 total steps have happened
[32m[0511 19:23:44 @base_main.py:52][0m [avg_reward]: -315.335038512963
[32m[0511 19:23:45 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:45 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:45 @base_trainer.py:216][0m Mean reward: -328.6562231099097
[32m[0511 19:23:45 @base_main.py:38][0m --------------- Iteration 162 ---------------
[32m[0511 19:23:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3578 mins
[32m[0511 19:23:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0036 mins
[32m[0511 19:23:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 19:23:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:45 @base_main.py:47][0m 162324 total steps have happened
[32m[0511 19:23:45 @base_main.py:52][0m [avg_reward]: -328.6562231099097
[32m[0511 19:23:45 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:45 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:45 @base_trainer.py:216][0m Mean reward: -357.6197647394554
[32m[0511 19:23:46 @base_main.py:38][0m --------------- Iteration 163 ---------------
[32m[0511 19:23:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3721 mins
[32m[0511 19:23:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 19:23:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 19:23:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:46 @base_main.py:47][0m 163326 total steps have happened
[32m[0511 19:23:46 @base_main.py:52][0m [avg_reward]: -357.6197647394554
[32m[0511 19:23:46 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:46 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:46 @base_trainer.py:216][0m Mean reward: -342.29074886682497
[32m[0511 19:23:47 @base_main.py:38][0m --------------- Iteration 164 ---------------
[32m[0511 19:23:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3864 mins
[32m[0511 19:23:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 19:23:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0107 mins
[32m[0511 19:23:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:47 @base_main.py:47][0m 164328 total steps have happened
[32m[0511 19:23:47 @base_main.py:52][0m [avg_reward]: -342.29074886682497
[32m[0511 19:23:47 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:47 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:47 @base_trainer.py:216][0m Mean reward: -356.0050265218496
[32m[0511 19:23:48 @base_main.py:38][0m --------------- Iteration 165 ---------------
[32m[0511 19:23:48 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4012 mins
[32m[0511 19:23:48 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0511 19:23:48 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 19:23:48 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:48 @base_main.py:47][0m 165330 total steps have happened
[32m[0511 19:23:48 @base_main.py:52][0m [avg_reward]: -356.0050265218496
[32m[0511 19:23:48 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:48 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:48 @base_trainer.py:216][0m Mean reward: -371.1929916915474
[32m[0511 19:23:49 @base_main.py:38][0m --------------- Iteration 166 ---------------
[32m[0511 19:23:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4157 mins
[32m[0511 19:23:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0045 mins
[32m[0511 19:23:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 19:23:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:49 @base_main.py:47][0m 166332 total steps have happened
[32m[0511 19:23:49 @base_main.py:52][0m [avg_reward]: -371.1929916915474
[32m[0511 19:23:49 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:49 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:49 @base_trainer.py:216][0m Mean reward: -340.77636118664
[32m[0511 19:23:50 @base_main.py:38][0m --------------- Iteration 167 ---------------
[32m[0511 19:23:50 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4304 mins
[32m[0511 19:23:50 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 19:23:50 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 19:23:50 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:50 @base_main.py:47][0m 167334 total steps have happened
[32m[0511 19:23:50 @base_main.py:52][0m [avg_reward]: -340.77636118664
[32m[0511 19:23:50 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:50 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:50 @base_trainer.py:216][0m Mean reward: -356.6458378788378
[32m[0511 19:23:50 @base_main.py:38][0m --------------- Iteration 168 ---------------
[32m[0511 19:23:50 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4443 mins
[32m[0511 19:23:50 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0511 19:23:50 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 19:23:50 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:50 @base_main.py:47][0m 168336 total steps have happened
[32m[0511 19:23:50 @base_main.py:52][0m [avg_reward]: -356.6458378788378
[32m[0511 19:23:51 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:51 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:51 @base_trainer.py:216][0m Mean reward: -328.2132339001207
[32m[0511 19:23:51 @base_main.py:38][0m --------------- Iteration 169 ---------------
[32m[0511 19:23:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4586 mins
[32m[0511 19:23:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0046 mins
[32m[0511 19:23:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 19:23:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:51 @base_main.py:47][0m 169338 total steps have happened
[32m[0511 19:23:51 @base_main.py:52][0m [avg_reward]: -328.2132339001207
[32m[0511 19:23:52 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:52 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:52 @base_trainer.py:216][0m Mean reward: -347.35025042808434
[32m[0511 19:23:52 @base_main.py:38][0m --------------- Iteration 170 ---------------
[32m[0511 19:23:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4731 mins
[32m[0511 19:23:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0055 mins
[32m[0511 19:23:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 19:23:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:52 @base_main.py:47][0m 170340 total steps have happened
[32m[0511 19:23:52 @base_main.py:52][0m [avg_reward]: -347.35025042808434
[32m[0511 19:23:52 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:52 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:52 @base_trainer.py:216][0m Mean reward: -375.06404313076075
[32m[0511 19:23:53 @base_main.py:38][0m --------------- Iteration 171 ---------------
[32m[0511 19:23:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4883 mins
[32m[0511 19:23:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0046 mins
[32m[0511 19:23:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 19:23:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:53 @base_main.py:47][0m 171342 total steps have happened
[32m[0511 19:23:53 @base_main.py:52][0m [avg_reward]: -375.06404313076075
[32m[0511 19:23:53 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:53 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:53 @base_trainer.py:216][0m Mean reward: -361.11144301452384
[32m[0511 19:23:54 @base_main.py:38][0m --------------- Iteration 172 ---------------
[32m[0511 19:23:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.5029 mins
[32m[0511 19:23:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0045 mins
[32m[0511 19:23:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 19:23:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:54 @base_main.py:47][0m 172344 total steps have happened
[32m[0511 19:23:54 @base_main.py:52][0m [avg_reward]: -361.11144301452384
[32m[0511 19:23:54 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:54 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:54 @base_trainer.py:216][0m Mean reward: -299.4372566697634
[32m[0511 19:23:55 @base_main.py:38][0m --------------- Iteration 173 ---------------
[32m[0511 19:23:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.5171 mins
[32m[0511 19:23:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0049 mins
[32m[0511 19:23:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 19:23:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:55 @base_main.py:47][0m 173346 total steps have happened
[32m[0511 19:23:55 @base_main.py:52][0m [avg_reward]: -299.4372566697634
[32m[0511 19:23:55 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:55 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:55 @base_trainer.py:216][0m Mean reward: -366.14125630704973
[32m[0511 19:23:56 @base_main.py:38][0m --------------- Iteration 174 ---------------
[32m[0511 19:23:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.5324 mins
[32m[0511 19:23:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0511 19:23:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0107 mins
[32m[0511 19:23:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:56 @base_main.py:47][0m 174348 total steps have happened
[32m[0511 19:23:56 @base_main.py:52][0m [avg_reward]: -366.14125630704973
[32m[0511 19:23:56 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:56 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:56 @base_trainer.py:216][0m Mean reward: -315.50426992193127
[32m[0511 19:23:57 @base_main.py:38][0m --------------- Iteration 175 ---------------
[32m[0511 19:23:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.5474 mins
[32m[0511 19:23:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0511 19:23:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0109 mins
[32m[0511 19:23:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:57 @base_main.py:47][0m 175350 total steps have happened
[32m[0511 19:23:57 @base_main.py:52][0m [avg_reward]: -315.50426992193127
[32m[0511 19:23:57 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:57 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:57 @base_trainer.py:216][0m Mean reward: -335.048405711808
[32m[0511 19:23:58 @base_main.py:38][0m --------------- Iteration 176 ---------------
[32m[0511 19:23:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.5626 mins
[32m[0511 19:23:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0044 mins
[32m[0511 19:23:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 19:23:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:58 @base_main.py:47][0m 176352 total steps have happened
[32m[0511 19:23:58 @base_main.py:52][0m [avg_reward]: -335.048405711808
[32m[0511 19:23:58 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:58 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:58 @base_trainer.py:216][0m Mean reward: -375.40925708389364
[32m[0511 19:23:58 @base_main.py:38][0m --------------- Iteration 177 ---------------
[32m[0511 19:23:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.5773 mins
[32m[0511 19:23:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 19:23:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 19:23:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:58 @base_main.py:47][0m 177354 total steps have happened
[32m[0511 19:23:58 @base_main.py:52][0m [avg_reward]: -375.40925708389364
[32m[0511 19:23:59 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:59 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:59 @base_trainer.py:216][0m Mean reward: -343.70079615953
[32m[0511 19:23:59 @base_main.py:38][0m --------------- Iteration 178 ---------------
[32m[0511 19:23:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.5914 mins
[32m[0511 19:23:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0511 19:23:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 19:23:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:23:59 @base_main.py:47][0m 178356 total steps have happened
[32m[0511 19:23:59 @base_main.py:52][0m [avg_reward]: -343.70079615953
[32m[0511 19:23:59 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:23:59 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:23:59 @base_trainer.py:216][0m Mean reward: -288.43803500547983
[32m[0511 19:24:00 @base_main.py:38][0m --------------- Iteration 179 ---------------
[32m[0511 19:24:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.6055 mins
[32m[0511 19:24:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0511 19:24:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0511 19:24:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:24:00 @base_main.py:47][0m 179358 total steps have happened
[32m[0511 19:24:00 @base_main.py:52][0m [avg_reward]: -288.43803500547983
[32m[0511 19:24:00 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:24:00 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:24:00 @base_trainer.py:216][0m Mean reward: -350.351442533126
[32m[0511 19:24:01 @base_main.py:38][0m --------------- Iteration 180 ---------------
[32m[0511 19:24:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.6192 mins
[32m[0511 19:24:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 19:24:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 19:24:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:24:01 @base_main.py:47][0m 180360 total steps have happened
[32m[0511 19:24:01 @base_main.py:52][0m [avg_reward]: -350.351442533126
[32m[0511 19:24:01 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:24:01 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:24:01 @base_trainer.py:216][0m Mean reward: -313.69231412855567
[32m[0511 19:24:02 @base_main.py:38][0m --------------- Iteration 181 ---------------
[32m[0511 19:24:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.6332 mins
[32m[0511 19:24:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 19:24:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 19:24:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:24:02 @base_main.py:47][0m 181362 total steps have happened
[32m[0511 19:24:02 @base_main.py:52][0m [avg_reward]: -313.69231412855567
[32m[0511 19:24:02 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:24:02 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:24:02 @base_trainer.py:216][0m Mean reward: -368.01349895261507
[32m[0511 19:24:02 @base_main.py:38][0m --------------- Iteration 182 ---------------
[32m[0511 19:24:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.6471 mins
[32m[0511 19:24:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0511 19:24:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0511 19:24:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:24:02 @base_main.py:47][0m 182364 total steps have happened
[32m[0511 19:24:02 @base_main.py:52][0m [avg_reward]: -368.01349895261507
[32m[0511 19:24:03 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:24:03 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:24:03 @base_trainer.py:216][0m Mean reward: -302.29252076561886
[32m[0511 19:24:03 @base_main.py:38][0m --------------- Iteration 183 ---------------
[32m[0511 19:24:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.6603 mins
[32m[0511 19:24:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 19:24:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 19:24:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:24:03 @base_main.py:47][0m 183366 total steps have happened
[32m[0511 19:24:03 @base_main.py:52][0m [avg_reward]: -302.29252076561886
[32m[0511 19:24:04 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:24:04 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:24:04 @base_trainer.py:216][0m Mean reward: -308.48364696382237
[32m[0511 19:24:04 @base_main.py:38][0m --------------- Iteration 184 ---------------
[32m[0511 19:24:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.6747 mins
[32m[0511 19:24:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0037 mins
[32m[0511 19:24:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 19:24:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:24:04 @base_main.py:47][0m 184368 total steps have happened
[32m[0511 19:24:04 @base_main.py:52][0m [avg_reward]: -308.48364696382237
[32m[0511 19:24:04 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:24:04 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:24:04 @base_trainer.py:216][0m Mean reward: -328.8028713319844
[32m[0511 19:24:05 @base_main.py:38][0m --------------- Iteration 185 ---------------
[32m[0511 19:24:05 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.6888 mins
[32m[0511 19:24:05 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0511 19:24:05 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 19:24:05 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0511 19:24:05 @base_main.py:47][0m 185370 total steps have happened
[32m[0511 19:24:05 @base_main.py:52][0m [avg_reward]: -328.8028713319844
[32m[0511 19:24:05 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:24:05 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:24:05 @base_trainer.py:216][0m Mean reward: -396.75178692946236
[32m[0511 19:24:06 @base_main.py:38][0m --------------- Iteration 186 ---------------
[32m[0511 19:24:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.7035 mins
[32m[0511 19:24:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0511 19:24:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 19:24:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0511 19:24:06 @base_main.py:47][0m 186372 total steps have happened
[32m[0511 19:24:06 @base_main.py:52][0m [avg_reward]: -396.75178692946236
[32m[0511 19:24:06 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:24:06 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:24:06 @base_trainer.py:216][0m Mean reward: -348.79208239496586
[32m[0511 19:24:07 @base_main.py:38][0m --------------- Iteration 187 ---------------
[32m[0511 19:24:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.7179 mins
[32m[0511 19:24:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0046 mins
[32m[0511 19:24:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 19:24:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:24:07 @base_main.py:47][0m 187374 total steps have happened
[32m[0511 19:24:07 @base_main.py:52][0m [avg_reward]: -348.79208239496586
[32m[0511 19:24:07 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:24:07 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:24:07 @base_trainer.py:216][0m Mean reward: -361.7659719873126
[32m[0511 19:24:08 @base_main.py:38][0m --------------- Iteration 188 ---------------
[32m[0511 19:24:08 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.7326 mins
[32m[0511 19:24:08 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0044 mins
[32m[0511 19:24:08 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 19:24:08 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:24:08 @base_main.py:47][0m 188376 total steps have happened
[32m[0511 19:24:08 @base_main.py:52][0m [avg_reward]: -361.7659719873126
[32m[0511 19:24:08 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:24:08 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:24:08 @base_trainer.py:216][0m Mean reward: -295.15883584641125
[32m[0511 19:24:09 @base_main.py:38][0m --------------- Iteration 189 ---------------
[32m[0511 19:24:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.7473 mins
[32m[0511 19:24:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0511 19:24:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 19:24:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:24:09 @base_main.py:47][0m 189378 total steps have happened
[32m[0511 19:24:09 @base_main.py:52][0m [avg_reward]: -295.15883584641125
[32m[0511 19:24:09 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:24:09 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:24:09 @base_trainer.py:216][0m Mean reward: -320.902938978008
[32m[0511 19:24:09 @base_main.py:38][0m --------------- Iteration 190 ---------------
[32m[0511 19:24:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.7620 mins
[32m[0511 19:24:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0043 mins
[32m[0511 19:24:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 19:24:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:24:09 @base_main.py:47][0m 190380 total steps have happened
[32m[0511 19:24:09 @base_main.py:52][0m [avg_reward]: -320.902938978008
[32m[0511 19:24:10 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:24:10 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:24:10 @base_trainer.py:216][0m Mean reward: -343.0502371797925
[32m[0511 19:24:10 @base_main.py:38][0m --------------- Iteration 191 ---------------
[32m[0511 19:24:10 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.7762 mins
[32m[0511 19:24:10 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0511 19:24:10 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 19:24:10 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:24:10 @base_main.py:47][0m 191382 total steps have happened
[32m[0511 19:24:10 @base_main.py:52][0m [avg_reward]: -343.0502371797925
[32m[0511 19:24:11 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:24:11 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:24:11 @base_trainer.py:216][0m Mean reward: -336.0484786243004
[32m[0511 19:24:11 @base_main.py:38][0m --------------- Iteration 192 ---------------
[32m[0511 19:24:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.7907 mins
[32m[0511 19:24:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0044 mins
[32m[0511 19:24:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 19:24:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:24:11 @base_main.py:47][0m 192384 total steps have happened
[32m[0511 19:24:11 @base_main.py:52][0m [avg_reward]: -336.0484786243004
[32m[0511 19:24:11 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:24:11 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:24:11 @base_trainer.py:216][0m Mean reward: -426.90695718857836
[32m[0511 19:24:12 @base_main.py:38][0m --------------- Iteration 193 ---------------
[32m[0511 19:24:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.8056 mins
[32m[0511 19:24:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0511 19:24:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 19:24:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:24:12 @base_main.py:47][0m 193386 total steps have happened
[32m[0511 19:24:12 @base_main.py:52][0m [avg_reward]: -426.90695718857836
[32m[0511 19:24:12 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:24:12 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:24:12 @base_trainer.py:216][0m Mean reward: -396.2948173994672
[32m[0511 19:24:13 @base_main.py:38][0m --------------- Iteration 194 ---------------
[32m[0511 19:24:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.8196 mins
[32m[0511 19:24:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0053 mins
[32m[0511 19:24:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 19:24:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:24:13 @base_main.py:47][0m 194388 total steps have happened
[32m[0511 19:24:13 @base_main.py:52][0m [avg_reward]: -396.2948173994672
[32m[0511 19:24:13 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:24:13 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:24:13 @base_trainer.py:216][0m Mean reward: -317.79712874683645
[32m[0511 19:24:14 @base_main.py:38][0m --------------- Iteration 195 ---------------
[32m[0511 19:24:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.8351 mins
[32m[0511 19:24:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0511 19:24:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 19:24:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:24:14 @base_main.py:47][0m 195390 total steps have happened
[32m[0511 19:24:14 @base_main.py:52][0m [avg_reward]: -317.79712874683645
[32m[0511 19:24:14 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:24:14 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:24:14 @base_trainer.py:216][0m Mean reward: -309.03772977239123
[32m[0511 19:24:15 @base_main.py:38][0m --------------- Iteration 196 ---------------
[32m[0511 19:24:15 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.8492 mins
[32m[0511 19:24:15 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0511 19:24:15 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 19:24:15 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:24:15 @base_main.py:47][0m 196392 total steps have happened
[32m[0511 19:24:15 @base_main.py:52][0m [avg_reward]: -309.03772977239123
[32m[0511 19:24:15 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:24:15 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:24:15 @base_trainer.py:216][0m Mean reward: -346.47560600037406
[32m[0511 19:24:16 @base_main.py:38][0m --------------- Iteration 197 ---------------
[32m[0511 19:24:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.8637 mins
[32m[0511 19:24:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0044 mins
[32m[0511 19:24:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 19:24:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:24:16 @base_main.py:47][0m 197394 total steps have happened
[32m[0511 19:24:16 @base_main.py:52][0m [avg_reward]: -346.47560600037406
[32m[0511 19:24:16 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:24:16 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:24:16 @base_trainer.py:216][0m Mean reward: -320.4687315563415
[32m[0511 19:24:16 @base_main.py:38][0m --------------- Iteration 198 ---------------
[32m[0511 19:24:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.8783 mins
[32m[0511 19:24:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0043 mins
[32m[0511 19:24:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 19:24:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:24:16 @base_main.py:47][0m 198396 total steps have happened
[32m[0511 19:24:16 @base_main.py:52][0m [avg_reward]: -320.4687315563415
[32m[0511 19:24:17 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:24:17 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:24:17 @base_trainer.py:216][0m Mean reward: -346.5189593993167
[32m[0511 19:24:17 @base_main.py:38][0m --------------- Iteration 199 ---------------
[32m[0511 19:24:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.8930 mins
[32m[0511 19:24:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0047 mins
[32m[0511 19:24:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 19:24:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:24:17 @base_main.py:47][0m 199398 total steps have happened
[32m[0511 19:24:17 @base_main.py:52][0m [avg_reward]: -346.5189593993167
[32m[0511 19:24:18 @singletask_sampler.py:101][0m Finished 2th episode
[32m[0511 19:24:18 @singletask_sampler.py:105][0m 1002 timesteps from 2 episodes collected
[32m[0511 19:24:18 @base_trainer.py:216][0m Mean reward: -348.093469547273
[32m[0511 19:24:18 @base_main.py:38][0m --------------- Iteration 200 ---------------
[32m[0511 19:24:18 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.9079 mins
[32m[0511 19:24:18 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0044 mins
[32m[0511 19:24:18 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 19:24:18 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 19:24:18 @base_main.py:47][0m 200400 total steps have happened
[32m[0511 19:24:18 @base_main.py:52][0m [avg_reward]: -348.093469547273
[32m[0511 19:24:18 @base_worker.py:111][0m kill message for worker 18
[32m[0511 19:24:18 @base_worker.py:111][0m kill message for worker 15
[32m[0511 19:24:18 @base_worker.py:111][0m kill message for worker 14
[32m[0511 19:24:18 @base_worker.py:111][0m kill message for worker 12
[32m[0511 19:24:18 @base_worker.py:111][0m kill message for worker 10
[32m[0511 19:24:18 @base_worker.py:111][0m kill message for worker 1
[32m[0511 19:24:18 @base_worker.py:111][0m kill message for worker 16
[32m[0511 19:24:18 @base_worker.py:111][0m kill message for worker 4
[32m[0511 19:24:18 @base_worker.py:111][0m kill message for worker 6
[32m[0511 19:24:18 @base_worker.py:111][0m kill message for worker 8
[32m[0511 19:24:18 @base_worker.py:111][0m kill message for worker 13
[32m[0511 19:24:18 @base_worker.py:111][0m kill message for worker 5
[32m[0511 19:24:18 @base_worker.py:111][0m kill message for worker 2
[32m[0511 19:24:18 @base_worker.py:111][0m kill message for worker 11
[32m[0511 19:24:18 @base_worker.py:111][0m kill message for worker 17
[32m[0511 19:24:18 @base_worker.py:111][0m kill message for worker 3
[32m[0511 19:24:18 @base_worker.py:111][0m kill message for worker 0
[32m[0511 19:24:18 @base_worker.py:111][0m kill message for worker 9
[32m[0511 19:24:18 @base_worker.py:111][0m kill message for worker 7
[32m[0511 19:24:18 @base_worker.py:111][0m kill message for worker 19
