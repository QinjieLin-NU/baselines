[32m[0514 04:56:20 @logger.py:103][0m Log file set to /root/mbbl/log/mbmfrl-rsgym_robotarm_hr_50_mbmf_gym_robotarm_ppo_seed_1234.log/mbmfrl-rsgym_robotarm_hr_50_mbmf_gym_robotarm_ppo_seed_1234.log
[32m[0514 04:56:20 @mbmf_main.py:23][0m Training starts at /root/mbbl
[32m[0514 04:56:20 @base_worker.py:45][0m Worker 0 online
[32m[0514 04:56:21 @base_worker.py:45][0m Worker 1 online
[32m[0514 04:56:21 @base_worker.py:45][0m Worker 2 online
[32m[0514 04:56:21 @base_worker.py:45][0m Worker 3 online
[32m[0514 04:56:21 @base_worker.py:45][0m Worker 4 online
[32m[0514 04:56:21 @base_worker.py:45][0m Worker 5 online
[32m[0514 04:56:21 @base_worker.py:45][0m Worker 6 online
[32m[0514 04:56:21 @base_worker.py:45][0m Worker 7 online
[32m[0514 04:56:21 @base_worker.py:45][0m Worker 8 online
[32m[0514 04:56:21 @base_worker.py:45][0m Worker 9 online
[32m[0514 04:56:21 @base_worker.py:45][0m Worker 10 online
[32m[0514 04:56:21 @base_worker.py:45][0m Worker 11 online
[32m[0514 04:56:21 @base_worker.py:45][0m Worker 12 online
[32m[0514 04:56:21 @base_worker.py:45][0m Worker 13 online
[32m[0514 04:56:21 @base_worker.py:45][0m Worker 14 online
[32m[0514 04:56:21 @base_worker.py:45][0m Worker 15 online
[32m[0514 04:56:21 @base_worker.py:45][0m Worker 16 online
[32m[0514 04:56:21 @base_worker.py:45][0m Worker 17 online
[32m[0514 04:56:21 @base_worker.py:45][0m Worker 18 online
[32m[0514 04:56:21 @base_worker.py:45][0m Worker 19 online
[32m[0514 04:56:22 @base_trainer.py:152][0m Trainer maintains [1] policy network
[32m[0514 04:56:22 @base_trainer.py:152][0m Trainer maintains [1] dynamics network
[32m[0514 04:56:22 @base_trainer.py:152][0m Trainer maintains [1] reward network
[32m[0514 04:56:23 @mbmf_main.py:46][0m Generating 1000 random timesteps
[32m[0514 04:56:23 @mbmf_sampler.py:39][0m done with episode
[32m[0514 04:56:23 @mbmf_sampler.py:39][0m done with episode
[32m[0514 04:56:23 @mbmf_sampler.py:39][0m done with episode
[32m[0514 04:56:23 @mbmf_sampler.py:39][0m done with episode
[32m[0514 04:56:23 @mbmf_sampler.py:39][0m done with episode
[32m[0514 04:56:23 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0514 04:56:23 @base_trainer.py:216][0m Mean reward: -239.97154937877696
[32m[0514 04:56:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.050061583518982, Train Loss: 1.0149692296981812
[32m[0514 04:56:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0500801801681519, Train Loss: 1.014959692955017
[32m[0514 04:56:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0500991344451904, Train Loss: 1.0149503946304321
[32m[0514 04:56:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0501182079315186, Train Loss: 1.0149412155151367
[32m[0514 04:56:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0501375198364258, Train Loss: 1.0149322748184204
[32m[0514 04:56:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.050156831741333, Train Loss: 1.0149234533309937
[32m[0514 04:56:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0501763820648193, Train Loss: 1.0149149894714355
[32m[0514 04:56:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0501958131790161, Train Loss: 1.014906644821167
[32m[0514 04:56:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0502156019210815, Train Loss: 1.014898419380188
[32m[0514 04:56:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.050235390663147, Train Loss: 1.0148905515670776
[32m[0514 04:56:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0502554178237915, Train Loss: 1.0148826837539673
[32m[0514 04:56:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0502753257751465, Train Loss: 1.0148749351501465
[32m[0514 04:56:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0502955913543701, Train Loss: 1.0148677825927734
[32m[0514 04:56:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0503156185150146, Train Loss: 1.0148606300354004
[32m[0514 04:56:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0503358840942383, Train Loss: 1.0148537158966064
[32m[0514 04:56:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.050356149673462, Train Loss: 1.0148468017578125
[32m[0514 04:56:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.050376534461975, Train Loss: 1.0148403644561768
[32m[0514 04:56:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0503969192504883, Train Loss: 1.014833927154541
[32m[0514 04:56:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0504173040390015, Train Loss: 1.014827847480774
[32m[0514 04:56:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.050437569618225, Train Loss: 1.014822006225586
[32m[0514 04:56:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0504578351974487, Train Loss: 1.014816164970398
[32m[0514 04:56:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0504778623580933, Train Loss: 1.014810562133789
[32m[0514 04:56:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0504982471466064, Train Loss: 1.0148054361343384
[32m[0514 04:56:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.050518274307251, Train Loss: 1.0148000717163086
[32m[0514 04:56:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0505385398864746, Train Loss: 1.014795184135437
[32m[0514 04:56:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0505584478378296, Train Loss: 1.0147902965545654
[32m[0514 04:56:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0505783557891846, Train Loss: 1.0147857666015625
[32m[0514 04:56:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0505982637405396, Train Loss: 1.0147812366485596
[32m[0514 04:56:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0506179332733154, Train Loss: 1.0147769451141357
[32m[0514 04:56:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0506374835968018, Train Loss: 1.0147727727890015
[32m[0514 04:56:24 @base_main.py:38][0m --------------- Iteration 1 ---------------
[32m[0514 04:56:24 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0000 mins
[32m[0514 04:56:24 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0044 mins
[32m[0514 04:56:24 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0114 mins
[32m[0514 04:56:24 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0035 mins
[32m[0514 04:56:24 @base_main.py:47][0m 1005 total steps have happened
[32m[0514 04:56:24 @base_main.py:52][0m [avg_reward]: -239.97154937877696
[32m[0514 04:56:24 @base_main.py:52][0m [update_op]: None
[32m[0514 04:56:24 @base_main.py:52][0m [train_loss]: 1.0147727727890015
[32m[0514 04:56:24 @base_main.py:52][0m [val_loss]: 1.0506374835968018
[32m[0514 04:56:24 @base_main.py:52][0m [avg_train_loss]: 1.0147727727890015
[32m[0514 04:56:49 @mbmf_sampler.py:39][0m done with episode
[32m[0514 04:57:25 @mbmf_sampler.py:39][0m done with episode
[32m[0514 04:58:02 @mbmf_sampler.py:39][0m done with episode
[32m[0514 04:58:39 @mbmf_sampler.py:39][0m done with episode
[32m[0514 04:59:17 @mbmf_sampler.py:39][0m done with episode
[32m[0514 04:59:17 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0514 04:59:17 @base_trainer.py:216][0m Mean reward: -250.27327661155573
[32m[0514 04:59:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9052191376686096, Train Loss: 1.007893443107605
[32m[0514 04:59:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9052280783653259, Train Loss: 1.0078963041305542
[32m[0514 04:59:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9052309393882751, Train Loss: 1.0078967809677124
[32m[0514 04:59:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9052297472953796, Train Loss: 1.007895588874817
[32m[0514 04:59:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9052257537841797, Train Loss: 1.007893443107605
[32m[0514 04:59:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9052204489707947, Train Loss: 1.0078905820846558
[32m[0514 04:59:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9052140712738037, Train Loss: 1.0078874826431274
[32m[0514 04:59:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9052075147628784, Train Loss: 1.0078843832015991
[32m[0514 04:59:18 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.905201256275177, Train Loss: 1.00788152217865
[32m[0514 04:59:18 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9051951766014099, Train Loss: 1.0078788995742798
[32m[0514 04:59:18 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9051894545555115, Train Loss: 1.0078765153884888
[32m[0514 04:59:18 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9051845669746399, Train Loss: 1.0078744888305664
[32m[0514 04:59:18 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.905180037021637, Train Loss: 1.0078727006912231
[32m[0514 04:59:18 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9051766395568848, Train Loss: 1.007871150970459
[32m[0514 04:59:18 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9051734209060669, Train Loss: 1.007869839668274
[32m[0514 04:59:18 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9051710963249207, Train Loss: 1.0078688859939575
[32m[0514 04:59:18 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.905168890953064, Train Loss: 1.0078679323196411
[32m[0514 04:59:18 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9051674008369446, Train Loss: 1.0078672170639038
[32m[0514 04:59:18 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9051662087440491, Train Loss: 1.0078665018081665
[32m[0514 04:59:18 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9051653146743774, Train Loss: 1.0078659057617188
[32m[0514 04:59:18 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.905164897441864, Train Loss: 1.007865309715271
[32m[0514 04:59:18 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9051646590232849, Train Loss: 1.0078648328781128
[32m[0514 04:59:18 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9051645398139954, Train Loss: 1.0078644752502441
[32m[0514 04:59:18 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9051646590232849, Train Loss: 1.0078641176223755
[32m[0514 04:59:19 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9051647186279297, Train Loss: 1.0078638792037964
[32m[0514 04:59:19 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9051650762557983, Train Loss: 1.0078636407852173
[32m[0514 04:59:19 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9051653742790222, Train Loss: 1.0078634023666382
[32m[0514 04:59:19 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9051656723022461, Train Loss: 1.007863163948059
[32m[0514 04:59:19 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9051660895347595, Train Loss: 1.00786292552948
[32m[0514 04:59:19 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9051665663719177, Train Loss: 1.00786292552948
[32m[0514 04:59:19 @base_main.py:38][0m --------------- Iteration 2 ---------------
[32m[0514 04:59:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0193 mins
[32m[0514 04:59:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 2.8819 mins
[32m[0514 04:59:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0318 mins
[32m[0514 04:59:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0082 mins
[32m[0514 04:59:19 @base_main.py:47][0m 2010 total steps have happened
[32m[0514 04:59:19 @base_main.py:52][0m [avg_reward]: -250.27327661155573
[32m[0514 04:59:19 @base_main.py:52][0m [update_op]: None
[32m[0514 04:59:19 @base_main.py:52][0m [train_loss]: 0.9152178168296814
[32m[0514 04:59:19 @base_main.py:52][0m [val_loss]: 0.9051665663719177
[32m[0514 04:59:19 @base_main.py:52][0m [avg_train_loss]: 1.00786292552948
[32m[0514 04:59:56 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:00:32 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:01:09 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:01:46 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:02:22 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:02:22 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:02:22 @base_trainer.py:216][0m Mean reward: -281.7041306502557
[32m[0514 05:02:22 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.539146900177002, Train Loss: 0.9427194595336914
[32m[0514 05:02:22 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5392417907714844, Train Loss: 0.9427086114883423
[32m[0514 05:02:22 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5393469333648682, Train Loss: 0.9426944851875305
[32m[0514 05:02:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5394525527954102, Train Loss: 0.942679762840271
[32m[0514 05:02:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5395532846450806, Train Loss: 0.9426664113998413
[32m[0514 05:02:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5396474599838257, Train Loss: 0.9426547884941101
[32m[0514 05:02:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5397337675094604, Train Loss: 0.9426448941230774
[32m[0514 05:02:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5398123264312744, Train Loss: 0.9426366686820984
[32m[0514 05:02:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5398837327957153, Train Loss: 0.9426298141479492
[32m[0514 05:02:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5399479866027832, Train Loss: 0.9426242709159851
[32m[0514 05:02:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5400062799453735, Train Loss: 0.9426196813583374
[32m[0514 05:02:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5400588512420654, Train Loss: 0.9426159858703613
[32m[0514 05:02:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5401066541671753, Train Loss: 0.9426129460334778
[32m[0514 05:02:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5401496887207031, Train Loss: 0.9426103830337524
[32m[0514 05:02:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5401889085769653, Train Loss: 0.9426083564758301
[32m[0514 05:02:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5402247905731201, Train Loss: 0.9426067471504211
[32m[0514 05:02:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5402573347091675, Train Loss: 0.942605197429657
[32m[0514 05:02:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5402870178222656, Train Loss: 0.9426041841506958
[32m[0514 05:02:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.540313959121704, Train Loss: 0.9426032304763794
[32m[0514 05:02:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5403389930725098, Train Loss: 0.9426023364067078
[32m[0514 05:02:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.540361762046814, Train Loss: 0.9426017999649048
[32m[0514 05:02:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.540382742881775, Train Loss: 0.9426010847091675
[32m[0514 05:02:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.540401816368103, Train Loss: 0.9426006078720093
[32m[0514 05:02:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.540419578552246, Train Loss: 0.9426001310348511
[32m[0514 05:02:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5404359102249146, Train Loss: 0.942599892616272
[32m[0514 05:02:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5404508113861084, Train Loss: 0.9425995945930481
[32m[0514 05:02:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5404646396636963, Train Loss: 0.9425992965698242
[32m[0514 05:02:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5404775142669678, Train Loss: 0.9425991177558899
[32m[0514 05:02:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5404895544052124, Train Loss: 0.9425989389419556
[32m[0514 05:02:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5405004024505615, Train Loss: 0.942598819732666
[32m[0514 05:02:26 @base_main.py:38][0m --------------- Iteration 3 ---------------
[32m[0514 05:02:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.9414 mins
[32m[0514 05:02:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 3.0456 mins
[32m[0514 05:02:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0541 mins
[32m[0514 05:02:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0066 mins
[32m[0514 05:02:26 @base_main.py:47][0m 3015 total steps have happened
[32m[0514 05:02:26 @base_main.py:52][0m [avg_reward]: -281.7041306502557
[32m[0514 05:02:26 @base_main.py:52][0m [update_op]: None
[32m[0514 05:02:26 @base_main.py:52][0m [train_loss]: 1.36247718334198
[32m[0514 05:02:26 @base_main.py:52][0m [val_loss]: 1.5405004024505615
[32m[0514 05:02:26 @base_main.py:52][0m [avg_train_loss]: 0.942598819732666
[32m[0514 05:03:02 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:03:37 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:04:13 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:04:50 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:05:27 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:05:27 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:05:27 @base_trainer.py:216][0m Mean reward: -243.865821128605
[32m[0514 05:05:27 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9871916770935059, Train Loss: 1.0302478075027466
[32m[0514 05:05:27 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9871863126754761, Train Loss: 1.0302389860153198
[32m[0514 05:05:27 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9871789216995239, Train Loss: 1.030227780342102
[32m[0514 05:05:28 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9871717095375061, Train Loss: 1.0302163362503052
[32m[0514 05:05:28 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9871659278869629, Train Loss: 1.0302057266235352
[32m[0514 05:05:28 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9871613383293152, Train Loss: 1.0301964282989502
[32m[0514 05:05:28 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9871581792831421, Train Loss: 1.0301886796951294
[32m[0514 05:05:28 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9871564507484436, Train Loss: 1.0301820039749146
[32m[0514 05:05:28 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9871556162834167, Train Loss: 1.0301762819290161
[32m[0514 05:05:28 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9871558547019958, Train Loss: 1.0301716327667236
[32m[0514 05:05:29 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9871566295623779, Train Loss: 1.0301676988601685
[32m[0514 05:05:29 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9871578812599182, Train Loss: 1.0301644802093506
[32m[0514 05:05:29 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9871599078178406, Train Loss: 1.030161738395691
[32m[0514 05:05:29 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9871617555618286, Train Loss: 1.0301594734191895
[32m[0514 05:05:29 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9871640205383301, Train Loss: 1.0301575660705566
[32m[0514 05:05:29 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9871662259101868, Train Loss: 1.030155897140503
[32m[0514 05:05:29 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9871684908866882, Train Loss: 1.0301545858383179
[32m[0514 05:05:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9871708154678345, Train Loss: 1.0301533937454224
[32m[0514 05:05:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9871730208396912, Train Loss: 1.030152440071106
[32m[0514 05:05:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9871752262115479, Train Loss: 1.0301517248153687
[32m[0514 05:05:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9871773719787598, Train Loss: 1.030151128768921
[32m[0514 05:05:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9871793985366821, Train Loss: 1.0301505327224731
[32m[0514 05:05:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9871813058853149, Train Loss: 1.030150055885315
[32m[0514 05:05:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9871830940246582, Train Loss: 1.0301496982574463
[32m[0514 05:05:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9871848225593567, Train Loss: 1.0301493406295776
[32m[0514 05:05:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9871863722801208, Train Loss: 1.0301491022109985
[32m[0514 05:05:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9871878027915955, Train Loss: 1.0301488637924194
[32m[0514 05:05:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9871892333030701, Train Loss: 1.0301487445831299
[32m[0514 05:05:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9871905446052551, Train Loss: 1.0301485061645508
[32m[0514 05:05:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9871917366981506, Train Loss: 1.0301483869552612
[32m[0514 05:05:32 @base_main.py:38][0m --------------- Iteration 4 ---------------
[32m[0514 05:05:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 6.0479 mins
[32m[0514 05:05:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 3.0190 mins
[32m[0514 05:05:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0741 mins
[32m[0514 05:05:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0066 mins
[32m[0514 05:05:32 @base_main.py:47][0m 4020 total steps have happened
[32m[0514 05:05:32 @base_main.py:52][0m [avg_reward]: -243.865821128605
[32m[0514 05:05:32 @base_main.py:52][0m [update_op]: None
[32m[0514 05:05:32 @base_main.py:52][0m [train_loss]: 1.7928119897842407
[32m[0514 05:05:32 @base_main.py:52][0m [val_loss]: 0.9871917366981506
[32m[0514 05:05:32 @base_main.py:52][0m [avg_train_loss]: 1.0301483869552612
[32m[0514 05:06:08 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:06:43 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:07:19 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:07:56 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:08:33 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:08:33 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:08:33 @base_trainer.py:216][0m Mean reward: -301.587427157602
[32m[0514 05:08:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2222020626068115, Train Loss: 0.97724848985672
[32m[0514 05:08:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2222625017166138, Train Loss: 0.9772425889968872
[32m[0514 05:08:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2223166227340698, Train Loss: 0.9772374033927917
[32m[0514 05:08:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2223613262176514, Train Loss: 0.9772337675094604
[32m[0514 05:08:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2223968505859375, Train Loss: 0.9772313237190247
[32m[0514 05:08:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2224239110946655, Train Loss: 0.9772298336029053
[32m[0514 05:08:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2224444150924683, Train Loss: 0.9772288799285889
[32m[0514 05:08:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.222460150718689, Train Loss: 0.9772282838821411
[32m[0514 05:08:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.222471833229065, Train Loss: 0.9772279262542725
[32m[0514 05:08:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2224806547164917, Train Loss: 0.9772276282310486
[32m[0514 05:08:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.222487449645996, Train Loss: 0.977227509021759
[32m[0514 05:08:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2224924564361572, Train Loss: 0.9772273302078247
[32m[0514 05:08:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.222496509552002, Train Loss: 0.9772272109985352
[32m[0514 05:08:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2224998474121094, Train Loss: 0.9772270917892456
[32m[0514 05:08:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2225021123886108, Train Loss: 0.9772270917892456
[32m[0514 05:08:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2225042581558228, Train Loss: 0.9772270917892456
[32m[0514 05:08:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.222506046295166, Train Loss: 0.977226972579956
[32m[0514 05:08:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.222507357597351, Train Loss: 0.977226972579956
[32m[0514 05:08:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.222508430480957, Train Loss: 0.9772269129753113
[32m[0514 05:08:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2225092649459839, Train Loss: 0.9772269129753113
[32m[0514 05:08:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2225099802017212, Train Loss: 0.9772269129753113
[32m[0514 05:08:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.222510576248169, Train Loss: 0.9772269129753113
[32m[0514 05:08:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2225111722946167, Train Loss: 0.9772269129753113
[32m[0514 05:08:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.222511649131775, Train Loss: 0.9772269129753113
[32m[0514 05:08:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.222512125968933, Train Loss: 0.9772267937660217
[32m[0514 05:08:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2225126028060913, Train Loss: 0.9772267937660217
[32m[0514 05:08:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2225128412246704, Train Loss: 0.9772269129753113
[32m[0514 05:08:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.222513198852539, Train Loss: 0.9772269129753113
[32m[0514 05:08:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2225134372711182, Train Loss: 0.9772269129753113
[32m[0514 05:08:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2225135564804077, Train Loss: 0.9772267937660217
[32m[0514 05:08:38 @base_main.py:38][0m --------------- Iteration 5 ---------------
[32m[0514 05:08:38 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 9.1477 mins
[32m[0514 05:08:38 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 3.0202 mins
[32m[0514 05:08:38 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0730 mins
[32m[0514 05:08:38 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0067 mins
[32m[0514 05:08:38 @base_main.py:47][0m 5025 total steps have happened
[32m[0514 05:08:38 @base_main.py:52][0m [avg_reward]: -301.587427157602
[32m[0514 05:08:38 @base_main.py:52][0m [update_op]: None
[32m[0514 05:08:38 @base_main.py:52][0m [train_loss]: 1.0446186065673828
[32m[0514 05:08:38 @base_main.py:52][0m [val_loss]: 1.2225135564804077
[32m[0514 05:08:38 @base_main.py:52][0m [avg_train_loss]: 0.9772267937660217
[32m[0514 05:09:14 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:09:49 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:10:25 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:11:02 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:11:39 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:11:39 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:11:39 @base_trainer.py:216][0m Mean reward: -371.19472878289406
[32m[0514 05:11:39 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.7066583633422852, Train Loss: 0.9699560403823853
[32m[0514 05:11:39 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.7066795825958252, Train Loss: 0.9699525237083435
[32m[0514 05:11:39 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.7067002058029175, Train Loss: 0.9699496626853943
[32m[0514 05:11:40 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.7067196369171143, Train Loss: 0.9699475765228271
[32m[0514 05:11:40 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.7067376375198364, Train Loss: 0.9699459075927734
[32m[0514 05:11:40 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.7067539691925049, Train Loss: 0.9699447751045227
[32m[0514 05:11:40 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.7067686319351196, Train Loss: 0.9699438214302063
[32m[0514 05:11:40 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.7067819833755493, Train Loss: 0.9699432253837585
[32m[0514 05:11:41 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.706792950630188, Train Loss: 0.9699428081512451
[32m[0514 05:11:41 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.706803321838379, Train Loss: 0.9699424505233765
[32m[0514 05:11:41 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.7068120241165161, Train Loss: 0.9699420928955078
[32m[0514 05:11:41 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.7068198919296265, Train Loss: 0.9699419140815735
[32m[0514 05:11:42 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.7068265676498413, Train Loss: 0.9699418544769287
[32m[0514 05:11:42 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.7068326473236084, Train Loss: 0.9699417352676392
[32m[0514 05:11:42 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.7068374156951904, Train Loss: 0.9699415564537048
[32m[0514 05:11:42 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.706842064857483, Train Loss: 0.9699416756629944
[32m[0514 05:11:42 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.706845760345459, Train Loss: 0.9699414968490601
[32m[0514 05:11:43 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.7068488597869873, Train Loss: 0.9699414968490601
[32m[0514 05:11:43 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.7068521976470947, Train Loss: 0.9699415564537048
[32m[0514 05:11:43 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.706854224205017, Train Loss: 0.9699414968490601
[32m[0514 05:11:43 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.7068564891815186, Train Loss: 0.9699415564537048
[32m[0514 05:11:43 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.7068582773208618, Train Loss: 0.9699414968490601
[32m[0514 05:11:44 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.7068597078323364, Train Loss: 0.9699414968490601
[32m[0514 05:11:44 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.706860899925232, Train Loss: 0.9699413776397705
[32m[0514 05:11:44 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.706862211227417, Train Loss: 0.9699413776397705
[32m[0514 05:11:44 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.7068630456924438, Train Loss: 0.9699414968490601
[32m[0514 05:11:44 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.7068639993667603, Train Loss: 0.9699413776397705
[32m[0514 05:11:44 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.7068647146224976, Train Loss: 0.9699413776397705
[32m[0514 05:11:45 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.7068654298782349, Train Loss: 0.9699414968490601
[32m[0514 05:11:45 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.7068657875061035, Train Loss: 0.9699413776397705
[32m[0514 05:11:45 @base_main.py:38][0m --------------- Iteration 6 ---------------
[32m[0514 05:11:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 12.2477 mins
[32m[0514 05:11:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 3.0148 mins
[32m[0514 05:11:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.1010 mins
[32m[0514 05:11:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0063 mins
[32m[0514 05:11:45 @base_main.py:47][0m 6030 total steps have happened
[32m[0514 05:11:45 @base_main.py:52][0m [avg_reward]: -371.19472878289406
[32m[0514 05:11:45 @base_main.py:52][0m [update_op]: None
[32m[0514 05:11:45 @base_main.py:52][0m [train_loss]: 1.6477490663528442
[32m[0514 05:11:45 @base_main.py:52][0m [val_loss]: 1.7068657875061035
[32m[0514 05:11:45 @base_main.py:52][0m [avg_train_loss]: 0.9699413776397705
[32m[0514 05:12:22 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:12:58 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:13:32 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:14:08 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:14:45 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:14:45 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:14:45 @base_trainer.py:216][0m Mean reward: -341.44841256159486
[32m[0514 05:14:45 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1151827573776245, Train Loss: 0.9212535619735718
[32m[0514 05:14:46 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1151832342147827, Train Loss: 0.9212527871131897
[32m[0514 05:14:46 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1151816844940186, Train Loss: 0.9212522506713867
[32m[0514 05:14:46 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1151801347732544, Train Loss: 0.9212520122528076
[32m[0514 05:14:46 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1151789426803589, Train Loss: 0.9212518930435181
[32m[0514 05:14:47 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1151782274246216, Train Loss: 0.9212518930435181
[32m[0514 05:14:47 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1151776313781738, Train Loss: 0.9212518334388733
[32m[0514 05:14:47 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1151773929595947, Train Loss: 0.9212518930435181
[32m[0514 05:14:47 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1151772737503052, Train Loss: 0.9212518334388733
[32m[0514 05:14:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1151773929595947, Train Loss: 0.9212518930435181
[32m[0514 05:14:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1151775121688843, Train Loss: 0.9212518334388733
[32m[0514 05:14:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1151772737503052, Train Loss: 0.9212518930435181
[32m[0514 05:14:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1151775121688843, Train Loss: 0.9212518930435181
[32m[0514 05:14:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1151775121688843, Train Loss: 0.9212518930435181
[32m[0514 05:14:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1151776313781738, Train Loss: 0.9212518930435181
[32m[0514 05:14:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1151776313781738, Train Loss: 0.9212518930435181
[32m[0514 05:14:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.115177869796753, Train Loss: 0.9212518930435181
[32m[0514 05:14:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1151777505874634, Train Loss: 0.9212518930435181
[32m[0514 05:14:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.115177869796753, Train Loss: 0.9212518334388733
[32m[0514 05:14:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1151779890060425, Train Loss: 0.9212518930435181
[32m[0514 05:14:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1151779890060425, Train Loss: 0.9212518930435181
[32m[0514 05:14:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1151779890060425, Train Loss: 0.9212518930435181
[32m[0514 05:14:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1151779890060425, Train Loss: 0.9212518930435181
[32m[0514 05:14:51 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.115178108215332, Train Loss: 0.9212518930435181
[32m[0514 05:14:51 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1151779890060425, Train Loss: 0.9212518930435181
[32m[0514 05:14:51 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1151779890060425, Train Loss: 0.9212518334388733
[32m[0514 05:14:51 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1151779890060425, Train Loss: 0.9212518930435181
[32m[0514 05:14:51 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1151779890060425, Train Loss: 0.9212518930435181
[32m[0514 05:14:51 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1151779890060425, Train Loss: 0.9212518334388733
[32m[0514 05:14:52 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.115178108215332, Train Loss: 0.9212518334388733
[32m[0514 05:14:52 @base_main.py:38][0m --------------- Iteration 7 ---------------
[32m[0514 05:14:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 15.3700 mins
[32m[0514 05:14:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 3.0013 mins
[32m[0514 05:14:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.1082 mins
[32m[0514 05:14:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0085 mins
[32m[0514 05:14:52 @base_main.py:47][0m 7035 total steps have happened
[32m[0514 05:14:52 @base_main.py:52][0m [avg_reward]: -341.44841256159486
[32m[0514 05:14:52 @base_main.py:52][0m [update_op]: None
[32m[0514 05:14:52 @base_main.py:52][0m [train_loss]: 1.3321794271469116
[32m[0514 05:14:52 @base_main.py:52][0m [val_loss]: 1.115178108215332
[32m[0514 05:14:52 @base_main.py:52][0m [avg_train_loss]: 0.9212518334388733
[32m[0514 05:14:52 @mbmf_trainer.py:160][0m Mean reward: -290.00647803875495
[32m[0514 05:14:52 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.316599577665329, Train Loss: 0.31434378027915955
[32m[0514 05:14:53 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.3167248070240021, Train Loss: 0.3142346441745758
[32m[0514 05:14:53 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.31679990887641907, Train Loss: 0.3141971528530121
[32m[0514 05:14:53 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.31684017181396484, Train Loss: 0.3141744136810303
[32m[0514 05:14:53 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.3168604075908661, Train Loss: 0.31415584683418274
[32m[0514 05:14:53 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.31687161326408386, Train Loss: 0.3141385018825531
[32m[0514 05:14:53 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.3168799877166748, Train Loss: 0.314121812582016
[32m[0514 05:14:53 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.3168880343437195, Train Loss: 0.314105749130249
[32m[0514 05:14:53 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.3168964087963104, Train Loss: 0.31409022212028503
[32m[0514 05:14:53 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.31690511107444763, Train Loss: 0.3140751123428345
[32m[0514 05:14:53 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.31691375374794006, Train Loss: 0.31406038999557495
[32m[0514 05:14:53 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.31692221760749817, Train Loss: 0.3140459656715393
[32m[0514 05:14:53 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.3169304430484772, Train Loss: 0.314031720161438
[32m[0514 05:14:53 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.3169383108615875, Train Loss: 0.31401771306991577
[32m[0514 05:14:53 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.3169459402561188, Train Loss: 0.3140038251876831
[32m[0514 05:14:53 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.31695324182510376, Train Loss: 0.3139900863170624
[32m[0514 05:14:53 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.31696030497550964, Train Loss: 0.3139764666557312
[32m[0514 05:14:53 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.3169671297073364, Train Loss: 0.3139629662036896
[32m[0514 05:14:53 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.3169737160205841, Train Loss: 0.3139495551586151
[32m[0514 05:14:53 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.31698012351989746, Train Loss: 0.3139362037181854
[32m[0514 05:14:53 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.3169862926006317, Train Loss: 0.3139229714870453
[32m[0514 05:14:53 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.31699231266975403, Train Loss: 0.3139098584651947
[32m[0514 05:14:53 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.3169981837272644, Train Loss: 0.31389671564102173
[32m[0514 05:14:53 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.31700384616851807, Train Loss: 0.31388363242149353
[32m[0514 05:14:53 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.31700944900512695, Train Loss: 0.3138706684112549
[32m[0514 05:14:54 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.31701481342315674, Train Loss: 0.3138577342033386
[32m[0514 05:14:54 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.31702011823654175, Train Loss: 0.31384479999542236
[32m[0514 05:14:54 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.3170252740383148, Train Loss: 0.31383198499679565
[32m[0514 05:14:54 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.31703031063079834, Train Loss: 0.31381916999816895
[32m[0514 05:14:54 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.3170352876186371, Train Loss: 0.3138064444065094
[32m[0514 05:14:54 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.3170401155948639, Train Loss: 0.31379374861717224
[32m[0514 05:14:54 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.3170449137687683, Train Loss: 0.31378111243247986
[32m[0514 05:14:54 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.3170495629310608, Train Loss: 0.313768595457077
[32m[0514 05:14:54 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.31705421209335327, Train Loss: 0.3137560784816742
[32m[0514 05:14:54 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.3170587420463562, Train Loss: 0.3137436509132385
[32m[0514 05:14:54 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.31706324219703674, Train Loss: 0.31373131275177
[32m[0514 05:14:54 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.3170676827430725, Train Loss: 0.3137190043926239
[32m[0514 05:14:54 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.3170720934867859, Train Loss: 0.3137068450450897
[32m[0514 05:14:54 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.3170764148235321, Train Loss: 0.31369468569755554
[32m[0514 05:14:54 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.3170807659626007, Train Loss: 0.3136826157569885
[32m[0514 05:14:54 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.3170850872993469, Train Loss: 0.31367072463035583
[32m[0514 05:14:54 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.317089319229126, Train Loss: 0.31365883350372314
[32m[0514 05:14:54 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.31709355115890503, Train Loss: 0.3136471211910248
[32m[0514 05:14:54 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.3170977234840393, Train Loss: 0.3136354386806488
[32m[0514 05:14:54 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.3171018958091736, Train Loss: 0.3136238753795624
[32m[0514 05:14:54 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.31710609793663025, Train Loss: 0.3136124312877655
[32m[0514 05:14:54 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.31711018085479736, Train Loss: 0.3136011064052582
[32m[0514 05:14:54 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.31711432337760925, Train Loss: 0.3135899007320404
[32m[0514 05:14:54 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.31711840629577637, Train Loss: 0.3135787546634674
[32m[0514 05:14:55 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.31712254881858826, Train Loss: 0.31356775760650635
[32m[0514 05:14:55 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.3171265721321106, Train Loss: 0.31355684995651245
[32m[0514 05:14:55 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.3171306550502777, Train Loss: 0.3135461211204529
[32m[0514 05:14:55 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.31713470816612244, Train Loss: 0.3135354220867157
[32m[0514 05:14:55 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.3171387016773224, Train Loss: 0.31352490186691284
[32m[0514 05:14:55 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.3171427547931671, Train Loss: 0.31351450085639954
[32m[0514 05:14:55 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.3171467185020447, Train Loss: 0.31350424885749817
[32m[0514 05:14:55 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.31715068221092224, Train Loss: 0.3134940564632416
[32m[0514 05:14:55 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.3171546459197998, Train Loss: 0.31348398327827454
[32m[0514 05:14:55 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.31715860962867737, Train Loss: 0.3134740889072418
[32m[0514 05:14:55 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.31716251373291016, Train Loss: 0.3134642541408539
[32m[0514 05:14:55 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.31716641783714294, Train Loss: 0.3134545683860779
[32m[0514 05:14:55 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.31717026233673096, Train Loss: 0.31344494223594666
[32m[0514 05:14:55 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.3171740174293518, Train Loss: 0.31343546509742737
[32m[0514 05:14:55 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.3171778619289398, Train Loss: 0.31342613697052
[32m[0514 05:14:55 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.31718164682388306, Train Loss: 0.31341689825057983
[32m[0514 05:14:55 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.3171853721141815, Train Loss: 0.3134077787399292
[32m[0514 05:14:55 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.3171890377998352, Train Loss: 0.31339871883392334
[32m[0514 05:14:55 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.3171926736831665, Train Loss: 0.3133898079395294
[32m[0514 05:14:55 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.3171962797641754, Train Loss: 0.31338098645210266
[32m[0514 05:14:55 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.31719985604286194, Train Loss: 0.3133722245693207
[32m[0514 05:14:55 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.3172033429145813, Train Loss: 0.31336361169815063
[32m[0514 05:14:56 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.31720682978630066, Train Loss: 0.31335511803627014
[32m[0514 05:14:56 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.31721028685569763, Train Loss: 0.31334662437438965
[32m[0514 05:14:56 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.31721359491348267, Train Loss: 0.3133383095264435
[32m[0514 05:14:56 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.3172169625759125, Train Loss: 0.3133300244808197
[32m[0514 05:14:56 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.31722021102905273, Train Loss: 0.3133218586444855
[32m[0514 05:14:56 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.317223459482193, Train Loss: 0.313313752412796
[32m[0514 05:14:56 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.3172265887260437, Train Loss: 0.31330573558807373
[32m[0514 05:14:56 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.317229688167572, Train Loss: 0.3132978081703186
[32m[0514 05:14:56 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.31723272800445557, Train Loss: 0.31328991055488586
[32m[0514 05:14:56 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.31723570823669434, Train Loss: 0.3132821023464203
[32m[0514 05:14:56 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.31723862886428833, Train Loss: 0.31327441334724426
[32m[0514 05:14:56 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.31724151968955994, Train Loss: 0.31326672434806824
[32m[0514 05:14:56 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.3172443211078644, Train Loss: 0.31325915455818176
[32m[0514 05:14:56 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.31724706292152405, Train Loss: 0.31325164437294006
[32m[0514 05:14:56 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.31724974513053894, Train Loss: 0.31324413418769836
[32m[0514 05:14:56 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.31725239753723145, Train Loss: 0.31323668360710144
[32m[0514 05:14:56 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.3172549307346344, Train Loss: 0.31322938203811646
[32m[0514 05:14:56 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.31725743412971497, Train Loss: 0.3132220506668091
[32m[0514 05:14:56 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.31725984811782837, Train Loss: 0.3132147490978241
[32m[0514 05:14:56 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.3172622323036194, Train Loss: 0.31320759654045105
[32m[0514 05:14:56 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.31726452708244324, Train Loss: 0.3132003843784332
[32m[0514 05:14:56 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.3172667622566223, Train Loss: 0.31319329142570496
[32m[0514 05:14:57 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.3172689974308014, Train Loss: 0.3131861984729767
[32m[0514 05:14:57 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.3172711133956909, Train Loss: 0.3131791651248932
[32m[0514 05:14:57 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.31727316975593567, Train Loss: 0.3131721317768097
[32m[0514 05:14:57 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.31727519631385803, Train Loss: 0.31316518783569336
[32m[0514 05:14:57 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.3172771632671356, Train Loss: 0.313158243894577
[32m[0514 05:14:57 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.31727901101112366, Train Loss: 0.31315138936042786
[32m[0514 05:14:57 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.3172808885574341, Train Loss: 0.3131445050239563
[32m[0514 05:14:57 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.31728264689445496, Train Loss: 0.3131376802921295
[32m[0514 05:14:57 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.31728437542915344, Train Loss: 0.31313085556030273
[32m[0514 05:14:57 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.31728601455688477, Train Loss: 0.3131240904331207
[32m[0514 05:14:57 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.3172876238822937, Train Loss: 0.3131173551082611
[32m[0514 05:14:57 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.31728917360305786, Train Loss: 0.3131106197834015
[32m[0514 05:14:57 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.317290723323822, Train Loss: 0.31310391426086426
[32m[0514 05:14:57 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.317292183637619, Train Loss: 0.3130972683429718
[32m[0514 05:14:57 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.31729358434677124, Train Loss: 0.31309056282043457
[32m[0514 05:14:57 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.3172949254512787, Train Loss: 0.3130839765071869
[32m[0514 05:14:57 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.31729623675346375, Train Loss: 0.3130773603916168
[32m[0514 05:14:57 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.31729748845100403, Train Loss: 0.31307077407836914
[32m[0514 05:14:57 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.3172987103462219, Train Loss: 0.31306421756744385
[32m[0514 05:14:57 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.31729990243911743, Train Loss: 0.31305766105651855
[32m[0514 05:14:57 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.31730103492736816, Train Loss: 0.31305113434791565
[32m[0514 05:14:57 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.3173021078109741, Train Loss: 0.31304463744163513
[32m[0514 05:14:57 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.3173031508922577, Train Loss: 0.3130381107330322
[32m[0514 05:14:58 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.31730416417121887, Train Loss: 0.3130316436290741
[32m[0514 05:14:58 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.31730514764785767, Train Loss: 0.3130251467227936
[32m[0514 05:14:58 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.3173060715198517, Train Loss: 0.31301870942115784
[32m[0514 05:14:58 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.3173069655895233, Train Loss: 0.3130122125148773
[32m[0514 05:14:58 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.31730780005455017, Train Loss: 0.3130057752132416
[32m[0514 05:14:58 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.3173086643218994, Train Loss: 0.3129993975162506
[32m[0514 05:14:58 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.3173094689846039, Train Loss: 0.31299296021461487
[32m[0514 05:14:58 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.31731024384498596, Train Loss: 0.3129865229129791
[32m[0514 05:14:58 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.3173109292984009, Train Loss: 0.31298017501831055
[32m[0514 05:14:58 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.3173116445541382, Train Loss: 0.3129737675189972
[32m[0514 05:14:58 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.3173123002052307, Train Loss: 0.3129673898220062
[32m[0514 05:14:58 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.31731298565864563, Train Loss: 0.31296107172966003
[32m[0514 05:14:58 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.3173135817050934, Train Loss: 0.31295469403266907
[32m[0514 05:14:58 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.31731417775154114, Train Loss: 0.3129483461380005
[32m[0514 05:14:58 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.3173147737979889, Train Loss: 0.3129419982433319
[32m[0514 05:14:58 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.3173152804374695, Train Loss: 0.3129356801509857
[32m[0514 05:14:58 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.31731581687927246, Train Loss: 0.3129293620586395
[32m[0514 05:14:58 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.31731635332107544, Train Loss: 0.31292304396629333
[32m[0514 05:14:58 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.31731680035591125, Train Loss: 0.3129167854785919
[32m[0514 05:14:58 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.31731727719306946, Train Loss: 0.31291043758392334
[32m[0514 05:14:58 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.3173177242279053, Train Loss: 0.31290414929389954
[32m[0514 05:14:58 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.3173181414604187, Train Loss: 0.3128978908061981
[32m[0514 05:14:58 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.31731855869293213, Train Loss: 0.3128916025161743
[32m[0514 05:14:58 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.31731897592544556, Train Loss: 0.3128853142261505
[32m[0514 05:14:59 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.3173193633556366, Train Loss: 0.3128790557384491
[32m[0514 05:14:59 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.31731975078582764, Train Loss: 0.31287282705307007
[32m[0514 05:14:59 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.3173201084136963, Train Loss: 0.31286653876304626
[32m[0514 05:14:59 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.31732046604156494, Train Loss: 0.31286028027534485
[32m[0514 05:14:59 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.3173207938671112, Train Loss: 0.3128540813922882
[32m[0514 05:14:59 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.3173210918903351, Train Loss: 0.3128478229045868
[32m[0514 05:14:59 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.31732141971588135, Train Loss: 0.3128415644168854
[32m[0514 05:14:59 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.3173217475414276, Train Loss: 0.3128353953361511
[32m[0514 05:14:59 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.3173220455646515, Train Loss: 0.3128291368484497
[32m[0514 05:14:59 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.317322313785553, Train Loss: 0.3128229081630707
[32m[0514 05:14:59 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.31732261180877686, Train Loss: 0.31281670928001404
[32m[0514 05:14:59 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.31732285022735596, Train Loss: 0.312810480594635
[32m[0514 05:14:59 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.31732314825057983, Train Loss: 0.31280431151390076
[32m[0514 05:14:59 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.3173234164714813, Train Loss: 0.3127981126308441
[32m[0514 05:14:59 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.3173236846923828, Train Loss: 0.3127919137477875
[32m[0514 05:14:59 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.3173239529132843, Train Loss: 0.31278571486473083
[32m[0514 05:14:59 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.3173242211341858, Train Loss: 0.3127795457839966
[32m[0514 05:14:59 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.3173244595527649, Train Loss: 0.31277337670326233
[32m[0514 05:14:59 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.317324697971344, Train Loss: 0.3127672076225281
[32m[0514 05:14:59 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.3173249661922455, Train Loss: 0.31276100873947144
[32m[0514 05:14:59 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.3173252046108246, Train Loss: 0.31275486946105957
[32m[0514 05:14:59 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.3173254728317261, Train Loss: 0.3127487003803253
[32m[0514 05:15:00 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.3173256814479828, Train Loss: 0.31274256110191345
[32m[0514 05:15:00 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.31732597947120667, Train Loss: 0.3127364218235016
[32m[0514 05:15:00 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.31732621788978577, Train Loss: 0.31273025274276733
[32m[0514 05:15:00 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.31732645630836487, Train Loss: 0.31272411346435547
[32m[0514 05:15:00 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.31732669472694397, Train Loss: 0.312718003988266
[32m[0514 05:15:00 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.31732693314552307, Train Loss: 0.3127118647098541
[32m[0514 05:15:00 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.31732723116874695, Train Loss: 0.3127056956291199
[32m[0514 05:15:00 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.31732746958732605, Train Loss: 0.3126995861530304
[32m[0514 05:15:00 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.31732773780822754, Train Loss: 0.3126934766769409
[32m[0514 05:15:00 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.3173280358314514, Train Loss: 0.31268733739852905
[32m[0514 05:15:00 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.3173282742500305, Train Loss: 0.31268125772476196
[32m[0514 05:15:00 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.317328542470932, Train Loss: 0.3126751482486725
[32m[0514 05:15:00 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.3173287808895111, Train Loss: 0.312669038772583
[32m[0514 05:15:00 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.317329078912735, Train Loss: 0.3126629590988159
[32m[0514 05:15:00 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.31732937693595886, Train Loss: 0.31265684962272644
[32m[0514 05:15:00 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.31732964515686035, Train Loss: 0.31265074014663696
[32m[0514 05:15:00 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.317330002784729, Train Loss: 0.3126446604728699
[32m[0514 05:15:00 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.3173302710056305, Train Loss: 0.31263861060142517
[32m[0514 05:15:00 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.31733056902885437, Train Loss: 0.3126325309276581
[32m[0514 05:15:00 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.31733089685440063, Train Loss: 0.312626451253891
[32m[0514 05:15:00 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.3173312544822693, Train Loss: 0.3126203715801239
[32m[0514 05:15:00 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.31733155250549316, Train Loss: 0.3126143515110016
[32m[0514 05:15:01 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.31733188033103943, Train Loss: 0.3126082718372345
[32m[0514 05:15:01 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.3173322379589081, Train Loss: 0.3126022517681122
[32m[0514 05:15:01 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.31733259558677673, Train Loss: 0.3125961720943451
[32m[0514 05:15:01 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.317332923412323, Train Loss: 0.3125901222229004
[32m[0514 05:15:01 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.31733331084251404, Train Loss: 0.31258413195610046
[32m[0514 05:15:01 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.3173336684703827, Train Loss: 0.3125780522823334
[32m[0514 05:15:01 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.31733405590057373, Train Loss: 0.31257203221321106
[32m[0514 05:15:01 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.31733444333076477, Train Loss: 0.31256601214408875
[32m[0514 05:15:01 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.3173348307609558, Train Loss: 0.31255999207496643
[32m[0514 05:15:01 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.31733524799346924, Train Loss: 0.3125539720058441
[32m[0514 05:15:01 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.31733566522598267, Train Loss: 0.3125479519367218
[32m[0514 05:15:01 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.3173360526561737, Train Loss: 0.3125419318675995
[32m[0514 05:15:01 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.3173365294933319, Train Loss: 0.31253594160079956
[32m[0514 05:15:01 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.31733694672584534, Train Loss: 0.31252995133399963
[32m[0514 05:15:01 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.31733739376068115, Train Loss: 0.3125239610671997
[32m[0514 05:15:01 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.31733787059783936, Train Loss: 0.3125179708003998
[32m[0514 05:15:01 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.31733834743499756, Train Loss: 0.31251201033592224
[32m[0514 05:15:01 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.31733882427215576, Train Loss: 0.3125060200691223
[32m[0514 05:15:01 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.31733930110931396, Train Loss: 0.31250008940696716
[32m[0514 05:15:01 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.31733977794647217, Train Loss: 0.31249406933784485
[32m[0514 05:15:01 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.31734031438827515, Train Loss: 0.3124881386756897
[32m[0514 05:15:01 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.31734082102775574, Train Loss: 0.31248220801353455
[32m[0514 05:15:02 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.3173413574695587, Train Loss: 0.312476247549057
[32m[0514 05:15:02 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.3173419237136841, Train Loss: 0.31247028708457947
[32m[0514 05:15:02 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.31734246015548706, Train Loss: 0.31246432662010193
[32m[0514 05:15:02 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.3173430263996124, Train Loss: 0.3124583959579468
[32m[0514 05:15:02 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.3173435628414154, Train Loss: 0.3124524652957916
[32m[0514 05:15:02 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.31734418869018555, Train Loss: 0.3124465346336365
[32m[0514 05:15:02 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.3173447549343109, Train Loss: 0.3124406337738037
[32m[0514 05:15:02 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.31734538078308105, Train Loss: 0.31243476271629333
[32m[0514 05:15:02 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.3173459768295288, Train Loss: 0.3124288022518158
[32m[0514 05:15:02 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.31734660267829895, Train Loss: 0.31242290139198303
[32m[0514 05:15:02 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.3173472583293915, Train Loss: 0.31241700053215027
[32m[0514 05:15:02 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.3173479437828064, Train Loss: 0.3124111294746399
[32m[0514 05:15:02 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.31734856963157654, Train Loss: 0.31240522861480713
[32m[0514 05:15:02 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.31734922528266907, Train Loss: 0.31239935755729675
[32m[0514 05:15:02 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.31734994053840637, Train Loss: 0.3123934864997864
[32m[0514 05:15:02 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.3173506259918213, Train Loss: 0.312387615442276
[32m[0514 05:15:02 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.3173512816429138, Train Loss: 0.3123817443847656
[32m[0514 05:15:02 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.3173520267009735, Train Loss: 0.31237587332725525
[32m[0514 05:15:02 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.3173527717590332, Train Loss: 0.31237003207206726
[32m[0514 05:15:02 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.3173534870147705, Train Loss: 0.3123641908168793
[32m[0514 05:15:02 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.3173542618751526, Train Loss: 0.31235837936401367
[32m[0514 05:15:03 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.31735503673553467, Train Loss: 0.3123525381088257
[32m[0514 05:15:03 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.31735578179359436, Train Loss: 0.3123466968536377
[32m[0514 05:15:03 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.31735655665397644, Train Loss: 0.3123408854007721
[32m[0514 05:15:03 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.3173573613166809, Train Loss: 0.3123350441455841
[32m[0514 05:15:03 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.3173581659793854, Train Loss: 0.3123292326927185
[32m[0514 05:15:03 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.31735897064208984, Train Loss: 0.3123234510421753
[32m[0514 05:15:03 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.3173598051071167, Train Loss: 0.3123176395893097
[32m[0514 05:15:03 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.31736063957214355, Train Loss: 0.3123118579387665
[32m[0514 05:15:03 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.3173614740371704, Train Loss: 0.31230607628822327
[32m[0514 05:15:03 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.31736236810684204, Train Loss: 0.31230029463768005
[32m[0514 05:15:03 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.31736326217651367, Train Loss: 0.31229451298713684
[32m[0514 05:15:03 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.3173641264438629, Train Loss: 0.31228873133659363
[32m[0514 05:15:03 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.31736505031585693, Train Loss: 0.3122829496860504
[32m[0514 05:15:03 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.3173659145832062, Train Loss: 0.312277227640152
[32m[0514 05:15:03 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.3173668682575226, Train Loss: 0.31227144598960876
[32m[0514 05:15:03 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.3173677623271942, Train Loss: 0.3122657239437103
[32m[0514 05:15:03 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.3173687160015106, Train Loss: 0.3122600018978119
[32m[0514 05:15:03 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.317369669675827, Train Loss: 0.31225425004959106
[32m[0514 05:15:03 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.31737062335014343, Train Loss: 0.31224849820137024
[32m[0514 05:15:03 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.31737157702445984, Train Loss: 0.3122427761554718
[32m[0514 05:15:03 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.31737256050109863, Train Loss: 0.31223705410957336
[32m[0514 05:15:03 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.3173735737800598, Train Loss: 0.3122313320636749
[32m[0514 05:15:03 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.3173745572566986, Train Loss: 0.3122256398200989
[32m[0514 05:15:03 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.3173755705356598, Train Loss: 0.3122199475765228
[32m[0514 05:15:04 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.31737658381462097, Train Loss: 0.3122142255306244
[32m[0514 05:15:04 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.31737756729125977, Train Loss: 0.3122085630893707
[32m[0514 05:15:04 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.3173786699771881, Train Loss: 0.31220290064811707
[32m[0514 05:15:04 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.3173797130584717, Train Loss: 0.312197208404541
[32m[0514 05:15:04 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.31738075613975525, Train Loss: 0.31219157576560974
[32m[0514 05:15:04 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.3173818588256836, Train Loss: 0.3121859133243561
[32m[0514 05:15:04 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.31738293170928955, Train Loss: 0.3121802508831024
[32m[0514 05:15:04 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.3173839747905731, Train Loss: 0.31217458844184875
[32m[0514 05:15:04 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.31738507747650146, Train Loss: 0.3121689558029175
[32m[0514 05:15:04 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.3173862099647522, Train Loss: 0.3121633231639862
[32m[0514 05:15:04 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.31738731265068054, Train Loss: 0.31215769052505493
[32m[0514 05:15:04 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.3173884451389313, Train Loss: 0.31215205788612366
[32m[0514 05:15:04 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.317389577627182, Train Loss: 0.31214645504951477
[32m[0514 05:15:04 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.31739071011543274, Train Loss: 0.3121408224105835
[32m[0514 05:15:04 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.31739187240600586, Train Loss: 0.312135249376297
[32m[0514 05:15:04 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.317393034696579, Train Loss: 0.31212958693504333
[32m[0514 05:15:04 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.3173941969871521, Train Loss: 0.3121240437030792
[32m[0514 05:15:04 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.3173953592777252, Train Loss: 0.3121184706687927
[32m[0514 05:15:04 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.3173965513706207, Train Loss: 0.31211286783218384
[32m[0514 05:15:04 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.3173977732658386, Train Loss: 0.31210729479789734
[32m[0514 05:15:04 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.3173989951610565, Train Loss: 0.31210169196128845
[32m[0514 05:15:04 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.31740012764930725, Train Loss: 0.31209614872932434
[32m[0514 05:15:04 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.31740137934684753, Train Loss: 0.31209060549736023
[32m[0514 05:15:05 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.31740260124206543, Train Loss: 0.3120850622653961
[32m[0514 05:15:05 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.3174038231372833, Train Loss: 0.3120794892311096
[32m[0514 05:15:05 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.3174050748348236, Train Loss: 0.3120739459991455
[32m[0514 05:15:05 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.3174063265323639, Train Loss: 0.3120684325695038
[32m[0514 05:15:05 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.3174075484275818, Train Loss: 0.3120628893375397
[32m[0514 05:15:05 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.31740882992744446, Train Loss: 0.31205737590789795
[32m[0514 05:15:05 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.31741008162498474, Train Loss: 0.31205183267593384
[32m[0514 05:15:05 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.3174113631248474, Train Loss: 0.3120463490486145
[32m[0514 05:15:05 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.3174126446247101, Train Loss: 0.3120408356189728
[32m[0514 05:15:05 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.31741392612457275, Train Loss: 0.31203535199165344
[32m[0514 05:15:05 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.3174152076244354, Train Loss: 0.3120298385620117
[32m[0514 05:15:05 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.3174165189266205, Train Loss: 0.31202438473701477
[32m[0514 05:15:05 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.31741780042648315, Train Loss: 0.31201887130737305
[32m[0514 05:15:05 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.3174191117286682, Train Loss: 0.3120134174823761
[32m[0514 05:15:05 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.31742042303085327, Train Loss: 0.3120079040527344
[32m[0514 05:15:05 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.3174217641353607, Train Loss: 0.3120024502277374
[32m[0514 05:15:05 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.3174230754375458, Train Loss: 0.31199702620506287
[32m[0514 05:15:05 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.31742438673973083, Train Loss: 0.31199154257774353
[32m[0514 05:15:05 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.3174257278442383, Train Loss: 0.3119860589504242
[32m[0514 05:15:05 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.3174270689487457, Train Loss: 0.31198063492774963
[32m[0514 05:15:05 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.3174284100532532, Train Loss: 0.3119752109050751
[32m[0514 05:15:06 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.317429780960083, Train Loss: 0.3119697868824005
[32m[0514 05:15:06 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.31743112206459045, Train Loss: 0.31196436285972595
[32m[0514 05:15:06 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.3174324631690979, Train Loss: 0.311958909034729
[32m[0514 05:15:06 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.3174338638782501, Train Loss: 0.31195351481437683
[32m[0514 05:15:06 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.31743523478507996, Train Loss: 0.31194809079170227
[32m[0514 05:15:06 @mbmf_sampler.py:98][0m Finished 9th episode
[32m[0514 05:15:06 @mbmf_sampler.py:102][0m 1809 timesteps from 9 episodes collected
[32m[0514 05:20:25 @mbmf_trainer.py:160][0m Mean reward: -327.61499925301484
[32m[0514 05:20:25 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.3130773603916168, Train Loss: 0.31476232409477234
[32m[0514 05:20:25 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.313281774520874, Train Loss: 0.31467729806900024
[32m[0514 05:20:25 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.31335118412971497, Train Loss: 0.31462666392326355
[32m[0514 05:20:25 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.31336402893066406, Train Loss: 0.31458693742752075
[32m[0514 05:20:25 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.31337636709213257, Train Loss: 0.314551442861557
[32m[0514 05:20:25 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.313396692276001, Train Loss: 0.31452038884162903
[32m[0514 05:20:25 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.31342047452926636, Train Loss: 0.3144928514957428
[32m[0514 05:20:25 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.31344473361968994, Train Loss: 0.3144676983356476
[32m[0514 05:20:25 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.3134685158729553, Train Loss: 0.3144444227218628
[32m[0514 05:20:25 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.3134915828704834, Train Loss: 0.31442299485206604
[32m[0514 05:20:25 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.3135139048099518, Train Loss: 0.3144031763076782
[32m[0514 05:20:25 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.3135356307029724, Train Loss: 0.3143847584724426
[32m[0514 05:20:25 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.31355684995651245, Train Loss: 0.3143675923347473
[32m[0514 05:20:25 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.3135775327682495, Train Loss: 0.3143514096736908
[32m[0514 05:20:25 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.3135976791381836, Train Loss: 0.3143361508846283
[32m[0514 05:20:25 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.31361740827560425, Train Loss: 0.3143216669559479
[32m[0514 05:20:26 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.31363657116889954, Train Loss: 0.31430795788764954
[32m[0514 05:20:26 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.3136553466320038, Train Loss: 0.3142947852611542
[32m[0514 05:20:26 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.31367361545562744, Train Loss: 0.31428220868110657
[32m[0514 05:20:26 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.31369152665138245, Train Loss: 0.31427013874053955
[32m[0514 05:20:26 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.31370896100997925, Train Loss: 0.3142584562301636
[32m[0514 05:20:26 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.313726007938385, Train Loss: 0.314247190952301
[32m[0514 05:20:26 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.3137427568435669, Train Loss: 0.31423628330230713
[32m[0514 05:20:26 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.31375908851623535, Train Loss: 0.3142256736755371
[32m[0514 05:20:26 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.31377506256103516, Train Loss: 0.31421536207199097
[32m[0514 05:20:26 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.3137907087802887, Train Loss: 0.3142053484916687
[32m[0514 05:20:26 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.31380602717399597, Train Loss: 0.31419554352760315
[32m[0514 05:20:26 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.31382110714912415, Train Loss: 0.3141859471797943
[32m[0514 05:20:26 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.3138357996940613, Train Loss: 0.3141765594482422
[32m[0514 05:20:26 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.3138503134250641, Train Loss: 0.314167320728302
[32m[0514 05:20:26 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.31386443972587585, Train Loss: 0.31415823101997375
[32m[0514 05:20:26 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.3138783872127533, Train Loss: 0.31414932012557983
[32m[0514 05:20:26 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.31389206647872925, Train Loss: 0.31414052844047546
[32m[0514 05:20:26 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.3139054775238037, Train Loss: 0.31413185596466064
[32m[0514 05:20:27 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.31391870975494385, Train Loss: 0.31412333250045776
[32m[0514 05:20:27 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.3139317035675049, Train Loss: 0.31411492824554443
[32m[0514 05:20:27 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.3139444887638092, Train Loss: 0.31410664319992065
[32m[0514 05:20:27 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.31395700573921204, Train Loss: 0.31409841775894165
[32m[0514 05:20:27 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.3139694035053253, Train Loss: 0.3140902817249298
[32m[0514 05:20:27 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.3139816224575043, Train Loss: 0.31408220529556274
[32m[0514 05:20:27 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.3139936327934265, Train Loss: 0.31407421827316284
[32m[0514 05:20:27 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.31400543451309204, Train Loss: 0.3140662908554077
[32m[0514 05:20:27 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.314017117023468, Train Loss: 0.31405848264694214
[32m[0514 05:20:27 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.31402865052223206, Train Loss: 0.31405067443847656
[32m[0514 05:20:27 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.3140399754047394, Train Loss: 0.31404295563697815
[32m[0514 05:20:27 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.31405121088027954, Train Loss: 0.3140352964401245
[32m[0514 05:20:27 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.314062237739563, Train Loss: 0.31402769684791565
[32m[0514 05:20:27 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.31407320499420166, Train Loss: 0.3140201270580292
[32m[0514 05:20:27 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.3140840232372284, Train Loss: 0.3140126168727875
[32m[0514 05:20:27 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.3140946328639984, Train Loss: 0.31400516629219055
[32m[0514 05:20:27 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.31410521268844604, Train Loss: 0.31399771571159363
[32m[0514 05:20:27 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.31411564350128174, Train Loss: 0.3139903247356415
[32m[0514 05:20:27 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.31412598490715027, Train Loss: 0.3139829635620117
[32m[0514 05:20:28 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.3141361474990845, Train Loss: 0.3139756917953491
[32m[0514 05:20:28 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.3141462504863739, Train Loss: 0.31396836042404175
[32m[0514 05:20:28 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.3141562342643738, Train Loss: 0.3139611482620239
[32m[0514 05:20:28 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.31416618824005127, Train Loss: 0.3139539062976837
[32m[0514 05:20:28 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.31417593359947205, Train Loss: 0.3139467239379883
[32m[0514 05:20:28 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.31418564915657043, Train Loss: 0.31393957138061523
[32m[0514 05:20:28 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.31419527530670166, Train Loss: 0.3139324486255646
[32m[0514 05:20:28 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.3142048418521881, Train Loss: 0.3139253556728363
[32m[0514 05:20:28 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.314214289188385, Train Loss: 0.3139182925224304
[32m[0514 05:20:28 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.31422361731529236, Train Loss: 0.3139112889766693
[32m[0514 05:20:28 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.3142329156398773, Train Loss: 0.3139042556285858
[32m[0514 05:20:28 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.3142421543598175, Train Loss: 0.3138972222805023
[32m[0514 05:20:28 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.31425127387046814, Train Loss: 0.313890278339386
[32m[0514 05:20:28 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.3142603635787964, Train Loss: 0.31388330459594727
[32m[0514 05:20:28 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.3142693340778351, Train Loss: 0.31387633085250854
[32m[0514 05:20:28 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.314278244972229, Train Loss: 0.313869446516037
[32m[0514 05:20:28 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.31428706645965576, Train Loss: 0.31386253237724304
[32m[0514 05:20:28 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.3142959177494049, Train Loss: 0.31385570764541626
[32m[0514 05:20:29 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.3143046796321869, Train Loss: 0.3138487935066223
[32m[0514 05:20:29 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.3143133521080017, Train Loss: 0.31384193897247314
[32m[0514 05:20:29 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.31432193517684937, Train Loss: 0.31383511424064636
[32m[0514 05:20:29 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.31433048844337463, Train Loss: 0.3138282895088196
[32m[0514 05:20:29 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.3143390417098999, Train Loss: 0.3138214945793152
[32m[0514 05:20:29 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.3143475353717804, Train Loss: 0.3138146996498108
[32m[0514 05:20:29 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.31435590982437134, Train Loss: 0.31380796432495117
[32m[0514 05:20:29 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.3143642544746399, Train Loss: 0.31380119919776917
[32m[0514 05:20:29 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.31437259912490845, Train Loss: 0.31379446387290955
[32m[0514 05:20:29 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.31438082456588745, Train Loss: 0.3137877285480499
[32m[0514 05:20:29 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.31438902020454407, Train Loss: 0.3137809634208679
[32m[0514 05:20:29 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.3143971860408783, Train Loss: 0.3137742578983307
[32m[0514 05:20:29 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.3144053518772125, Train Loss: 0.31376758217811584
[32m[0514 05:20:29 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.3144134283065796, Train Loss: 0.3137609362602234
[32m[0514 05:20:29 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.31442147493362427, Train Loss: 0.31375420093536377
[32m[0514 05:20:29 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.3144294321537018, Train Loss: 0.3137475550174713
[32m[0514 05:20:29 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.3144373893737793, Train Loss: 0.31374093890190125
[32m[0514 05:20:29 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.3144453465938568, Train Loss: 0.3137343227863312
[32m[0514 05:20:30 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.3144531846046448, Train Loss: 0.3137277066707611
[32m[0514 05:20:30 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.3144610524177551, Train Loss: 0.31372109055519104
[32m[0514 05:20:30 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.3144688904285431, Train Loss: 0.31371447443962097
[32m[0514 05:20:30 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.3144766688346863, Train Loss: 0.3137078285217285
[32m[0514 05:20:30 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.3144843876361847, Train Loss: 0.31370124220848083
[32m[0514 05:20:30 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.3144921362400055, Train Loss: 0.31369465589523315
[32m[0514 05:20:30 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.31449979543685913, Train Loss: 0.31368809938430786
[32m[0514 05:20:30 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.31450745463371277, Train Loss: 0.3136815130710602
[32m[0514 05:20:30 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.31451505422592163, Train Loss: 0.3136749863624573
[32m[0514 05:20:30 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.3145226836204529, Train Loss: 0.3136684000492096
[32m[0514 05:20:30 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.31453025341033936, Train Loss: 0.3136618435382843
[32m[0514 05:20:30 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.31453776359558105, Train Loss: 0.3136553466320038
[32m[0514 05:20:30 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.31454527378082275, Train Loss: 0.3136487901210785
[32m[0514 05:20:30 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.31455278396606445, Train Loss: 0.313642293214798
[32m[0514 05:20:30 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.314560204744339, Train Loss: 0.31363579630851746
[32m[0514 05:20:30 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.3145676553249359, Train Loss: 0.31362923979759216
[32m[0514 05:20:30 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.31457504630088806, Train Loss: 0.31362277269363403
[32m[0514 05:20:30 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.3145824372768402, Train Loss: 0.31361624598503113
[32m[0514 05:20:31 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.31458982825279236, Train Loss: 0.3136097490787506
[32m[0514 05:20:31 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.3145971894264221, Train Loss: 0.3136032819747925
[32m[0514 05:20:31 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.3146044611930847, Train Loss: 0.31359681487083435
[32m[0514 05:20:31 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.3146117925643921, Train Loss: 0.31359031796455383
[32m[0514 05:20:31 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.3146190345287323, Train Loss: 0.3135838508605957
[32m[0514 05:20:31 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.3146263659000397, Train Loss: 0.3135773837566376
[32m[0514 05:20:31 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.3146336078643799, Train Loss: 0.31357094645500183
[32m[0514 05:20:31 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.3146408498287201, Train Loss: 0.3135644495487213
[32m[0514 05:20:31 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.3146480321884155, Train Loss: 0.31355801224708557
[32m[0514 05:20:31 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.31465521454811096, Train Loss: 0.31355154514312744
[32m[0514 05:20:31 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.314662367105484, Train Loss: 0.3135451376438141
[32m[0514 05:20:31 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.31466957926750183, Train Loss: 0.31353870034217834
[32m[0514 05:20:31 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.3146767020225525, Train Loss: 0.3135322630405426
[32m[0514 05:20:31 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.31468379497528076, Train Loss: 0.31352582573890686
[32m[0514 05:20:31 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.3146909177303314, Train Loss: 0.3135194778442383
[32m[0514 05:20:31 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.3146980106830597, Train Loss: 0.3135130703449249
[32m[0514 05:20:31 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.31470510363578796, Train Loss: 0.3135066032409668
[32m[0514 05:20:31 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.31471216678619385, Train Loss: 0.31350022554397583
[32m[0514 05:20:31 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.31471922993659973, Train Loss: 0.3134937882423401
[32m[0514 05:20:32 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.3147262632846832, Train Loss: 0.31348738074302673
[32m[0514 05:20:32 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.3147332966327667, Train Loss: 0.31348103284835815
[32m[0514 05:20:32 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.31474027037620544, Train Loss: 0.3134746253490448
[32m[0514 05:20:32 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.31474733352661133, Train Loss: 0.31346824765205383
[32m[0514 05:20:32 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.3147542476654053, Train Loss: 0.3134618401527405
[32m[0514 05:20:32 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.31476128101348877, Train Loss: 0.3134554624557495
[32m[0514 05:20:32 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.3147682547569275, Train Loss: 0.31344908475875854
[32m[0514 05:20:32 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.3147752285003662, Train Loss: 0.3134427070617676
[32m[0514 05:20:32 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.31478220224380493, Train Loss: 0.3134363293647766
[32m[0514 05:20:32 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.3147890865802765, Train Loss: 0.31342998147010803
[32m[0514 05:20:32 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.3147960603237152, Train Loss: 0.31342363357543945
[32m[0514 05:20:32 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.31480297446250916, Train Loss: 0.3134172558784485
[32m[0514 05:20:32 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.3148099184036255, Train Loss: 0.3134108781814575
[32m[0514 05:20:32 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.3148168623447418, Train Loss: 0.3134045898914337
[32m[0514 05:20:32 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.3148237466812134, Train Loss: 0.31339821219444275
[32m[0514 05:20:32 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.31483063101768494, Train Loss: 0.31339186429977417
[32m[0514 05:20:32 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.3148374855518341, Train Loss: 0.313385546207428
[32m[0514 05:20:33 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.31484436988830566, Train Loss: 0.3133791983127594
[32m[0514 05:20:33 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.31485122442245483, Train Loss: 0.3133729100227356
[32m[0514 05:20:33 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.314858078956604, Train Loss: 0.313366562128067
[32m[0514 05:20:33 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.31486496329307556, Train Loss: 0.31336021423339844
[32m[0514 05:20:33 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.31487181782722473, Train Loss: 0.31335392594337463
[32m[0514 05:20:33 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.3148786425590515, Train Loss: 0.31334754824638367
[32m[0514 05:20:33 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.3148854672908783, Train Loss: 0.31334125995635986
[32m[0514 05:20:33 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.31489232182502747, Train Loss: 0.31333497166633606
[32m[0514 05:20:33 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.31489914655685425, Train Loss: 0.3133286237716675
[32m[0514 05:20:33 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.31490591168403625, Train Loss: 0.3133222758769989
[32m[0514 05:20:33 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.3149127960205078, Train Loss: 0.3133159875869751
[32m[0514 05:20:33 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.3149195909500122, Train Loss: 0.3133096992969513
[32m[0514 05:20:33 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.314926415681839, Train Loss: 0.3133033812046051
[32m[0514 05:20:33 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.314933180809021, Train Loss: 0.3132971525192261
[32m[0514 05:20:33 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.3149400055408478, Train Loss: 0.3132907748222351
[32m[0514 05:20:33 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.3149468004703522, Train Loss: 0.3132845461368561
[32m[0514 05:20:33 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.3149535655975342, Train Loss: 0.3132781982421875
[32m[0514 05:20:33 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.3149603307247162, Train Loss: 0.3132719397544861
[32m[0514 05:20:34 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.3149671256542206, Train Loss: 0.3132656514644623
[32m[0514 05:20:34 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.3149738907814026, Train Loss: 0.31325939297676086
[32m[0514 05:20:34 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.3149806559085846, Train Loss: 0.3132530450820923
[32m[0514 05:20:34 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.314987450838089, Train Loss: 0.31324681639671326
[32m[0514 05:20:34 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.3149941563606262, Train Loss: 0.31324049830436707
[32m[0514 05:20:34 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.3150009512901306, Train Loss: 0.31323426961898804
[32m[0514 05:20:34 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.31500768661499023, Train Loss: 0.3132280111312866
[32m[0514 05:20:34 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.31501445174217224, Train Loss: 0.3132217526435852
[32m[0514 05:20:34 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.3150211572647095, Train Loss: 0.3132154643535614
[32m[0514 05:20:34 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.3150279223918915, Train Loss: 0.3132091760635376
[32m[0514 05:20:34 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.3150346577167511, Train Loss: 0.31320294737815857
[32m[0514 05:20:34 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.3150413930416107, Train Loss: 0.31319668889045715
[32m[0514 05:20:34 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.31504812836647034, Train Loss: 0.31319043040275574
[32m[0514 05:20:34 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.31505483388900757, Train Loss: 0.3131841719150543
[32m[0514 05:20:34 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.3150615692138672, Train Loss: 0.3131779432296753
[32m[0514 05:20:34 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.3150682747364044, Train Loss: 0.3131716847419739
[32m[0514 05:20:34 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.31507501006126404, Train Loss: 0.31316548585891724
[32m[0514 05:20:34 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.31508171558380127, Train Loss: 0.3131592571735382
[32m[0514 05:20:35 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.3150883615016937, Train Loss: 0.3131529688835144
[32m[0514 05:20:35 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.31509509682655334, Train Loss: 0.3131467401981354
[32m[0514 05:20:35 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.3151017725467682, Train Loss: 0.31314051151275635
[32m[0514 05:20:35 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.3151085078716278, Train Loss: 0.3131342828273773
[32m[0514 05:20:35 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.31511515378952026, Train Loss: 0.3131280839443207
[32m[0514 05:20:35 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.3151218891143799, Train Loss: 0.31312182545661926
[32m[0514 05:20:35 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.31512850522994995, Train Loss: 0.31311559677124023
[32m[0514 05:20:35 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.3151352107524872, Train Loss: 0.3131093978881836
[32m[0514 05:20:35 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.315141886472702, Train Loss: 0.31310319900512695
[32m[0514 05:20:35 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.31514856219291687, Train Loss: 0.3130970001220703
[32m[0514 05:20:35 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.3151552081108093, Train Loss: 0.3130907416343689
[32m[0514 05:20:35 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.3151618540287018, Train Loss: 0.31308454275131226
[32m[0514 05:20:35 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.315168559551239, Train Loss: 0.3130783438682556
[32m[0514 05:20:35 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.3151751756668091, Train Loss: 0.3130721151828766
[32m[0514 05:20:35 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.3151818513870239, Train Loss: 0.31306594610214233
[32m[0514 05:20:35 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.31518852710723877, Train Loss: 0.3130597472190857
[32m[0514 05:20:35 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.31519514322280884, Train Loss: 0.31305354833602905
[32m[0514 05:20:35 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.3152017593383789, Train Loss: 0.3130473494529724
[32m[0514 05:20:36 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.31520840525627136, Train Loss: 0.31304118037223816
[32m[0514 05:20:36 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.31521502137184143, Train Loss: 0.3130349814891815
[32m[0514 05:20:36 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.3152216970920563, Train Loss: 0.3130287826061249
[32m[0514 05:20:36 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.31522825360298157, Train Loss: 0.3130226135253906
[32m[0514 05:20:36 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.31523483991622925, Train Loss: 0.3130163848400116
[32m[0514 05:20:36 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.3152414858341217, Train Loss: 0.31301024556159973
[32m[0514 05:20:36 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.3152480721473694, Train Loss: 0.3130040764808655
[32m[0514 05:20:36 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.31525468826293945, Train Loss: 0.31299787759780884
[32m[0514 05:20:36 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.31526124477386475, Train Loss: 0.3129917085170746
[32m[0514 05:20:36 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.3152678608894348, Train Loss: 0.31298550963401794
[32m[0514 05:20:36 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.3152744174003601, Train Loss: 0.3129793405532837
[32m[0514 05:20:36 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.3152810335159302, Train Loss: 0.31297317147254944
[32m[0514 05:20:36 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.3152875602245331, Train Loss: 0.3129670321941376
[32m[0514 05:20:36 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.31529414653778076, Train Loss: 0.31296083331108093
[32m[0514 05:20:36 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.31530070304870605, Train Loss: 0.31295472383499146
[32m[0514 05:20:36 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.31530725955963135, Train Loss: 0.3129485547542572
[32m[0514 05:20:36 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.31531384587287903, Train Loss: 0.3129424452781677
[32m[0514 05:20:36 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.3153204023838043, Train Loss: 0.3129362463951111
[32m[0514 05:20:37 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.31532686948776245, Train Loss: 0.3129301071166992
[32m[0514 05:20:37 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.31533342599868774, Train Loss: 0.31292396783828735
[32m[0514 05:20:37 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.31533992290496826, Train Loss: 0.3129177987575531
[32m[0514 05:20:37 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.31534647941589355, Train Loss: 0.31291162967681885
[32m[0514 05:20:37 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.3153529763221741, Train Loss: 0.31290552020072937
[32m[0514 05:20:37 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.31535953283309937, Train Loss: 0.3128994107246399
[32m[0514 05:20:37 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.3153659701347351, Train Loss: 0.312893271446228
[32m[0514 05:20:37 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.3153725266456604, Train Loss: 0.31288713216781616
[32m[0514 05:20:37 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.31537896394729614, Train Loss: 0.3128810226917267
[32m[0514 05:20:37 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.3153854310512543, Train Loss: 0.31287485361099243
[32m[0514 05:20:37 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.3153919279575348, Train Loss: 0.31286871433258057
[32m[0514 05:20:37 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.31539836525917053, Train Loss: 0.3128625750541687
[32m[0514 05:20:37 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.31540483236312866, Train Loss: 0.3128564953804016
[32m[0514 05:20:37 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.3154113292694092, Train Loss: 0.31285038590431213
[32m[0514 05:20:37 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.3154177665710449, Train Loss: 0.31284427642822266
[32m[0514 05:20:37 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.3154241740703583, Train Loss: 0.3128381371498108
[32m[0514 05:20:37 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.3154306411743164, Train Loss: 0.3128320276737213
[32m[0514 05:20:37 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.31543704867362976, Train Loss: 0.3128259479999542
[32m[0514 05:20:38 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.3154434263706207, Train Loss: 0.31281980872154236
[32m[0514 05:20:38 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.31544992327690125, Train Loss: 0.31281372904777527
[32m[0514 05:20:38 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.3154562711715698, Train Loss: 0.3128076195716858
[32m[0514 05:20:38 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.3154626488685608, Train Loss: 0.3128015100955963
[32m[0514 05:20:38 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.31546905636787415, Train Loss: 0.3127954304218292
[32m[0514 05:20:38 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.3154754340648651, Train Loss: 0.31278935074806213
[32m[0514 05:20:38 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.3154817819595337, Train Loss: 0.31278321146965027
[32m[0514 05:20:38 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.31548815965652466, Train Loss: 0.3127771317958832
[32m[0514 05:20:38 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.31549450755119324, Train Loss: 0.3127710223197937
[32m[0514 05:20:38 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.3155008852481842, Train Loss: 0.3127650022506714
[32m[0514 05:20:38 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.3155072331428528, Train Loss: 0.3127588927745819
[32m[0514 05:20:38 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.3155135214328766, Train Loss: 0.3127528131008148
[32m[0514 05:20:38 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.31551986932754517, Train Loss: 0.31274670362472534
[32m[0514 05:20:38 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.3155261278152466, Train Loss: 0.31274065375328064
[32m[0514 05:20:38 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.31553250551223755, Train Loss: 0.31273454427719116
[32m[0514 05:20:38 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.31553876399993896, Train Loss: 0.31272849440574646
[32m[0514 05:20:38 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.31554505228996277, Train Loss: 0.31272247433662415
[32m[0514 05:20:38 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.3155513405799866, Train Loss: 0.31271636486053467
[32m[0514 05:20:39 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.3155575692653656, Train Loss: 0.3127102851867676
[32m[0514 05:20:39 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.315563827753067, Train Loss: 0.3127042055130005
[32m[0514 05:20:39 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.3155701160430908, Train Loss: 0.3126981854438782
[32m[0514 05:20:39 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.31557634472846985, Train Loss: 0.3126921057701111
[32m[0514 05:20:39 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.3155825734138489, Train Loss: 0.3126860558986664
[32m[0514 05:20:39 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.3155888319015503, Train Loss: 0.3126799762248993
[32m[0514 05:20:39 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.31559500098228455, Train Loss: 0.31267398595809937
[32m[0514 05:20:39 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.3156012296676636, Train Loss: 0.3126678466796875
[32m[0514 05:20:39 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.3156073987483978, Train Loss: 0.3126618266105652
[32m[0514 05:20:39 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.31561362743377686, Train Loss: 0.31265580654144287
[32m[0514 05:20:39 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.3156198263168335, Train Loss: 0.31264978647232056
[32m[0514 05:20:39 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.31562596559524536, Train Loss: 0.31264370679855347
[32m[0514 05:20:39 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.3156321346759796, Train Loss: 0.31263768672943115
[32m[0514 05:20:39 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.3156382739543915, Train Loss: 0.31263163685798645
[32m[0514 05:20:39 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.31564441323280334, Train Loss: 0.31262561678886414
[32m[0514 05:20:39 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.3156505525112152, Train Loss: 0.3126195967197418
[32m[0514 05:20:39 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.3156566917896271, Train Loss: 0.31261351704597473
[32m[0514 05:20:39 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.31566277146339417, Train Loss: 0.31260746717453003
[32m[0514 05:20:39 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.31566888093948364, Train Loss: 0.3126014769077301
[32m[0514 05:20:40 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.3156749904155731, Train Loss: 0.3125954568386078
[32m[0514 05:20:40 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.3156810700893402, Train Loss: 0.31258946657180786
[32m[0514 05:20:40 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.3156871199607849, Train Loss: 0.31258344650268555
[32m[0514 05:20:40 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.315693199634552, Train Loss: 0.31257736682891846
[32m[0514 05:20:40 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.3156992495059967, Train Loss: 0.3125714063644409
[32m[0514 05:20:40 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.315705269575119, Train Loss: 0.3125653564929962
[32m[0514 05:20:40 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.31571128964424133, Train Loss: 0.3125593364238739
[32m[0514 05:20:40 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.31571733951568604, Train Loss: 0.312553346157074
[32m[0514 05:20:40 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.31572332978248596, Train Loss: 0.31254732608795166
[32m[0514 05:20:40 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.31572937965393066, Train Loss: 0.3125413656234741
[32m[0514 05:20:40 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.3157353401184082, Train Loss: 0.3125353455543518
[32m[0514 05:20:40 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.31574133038520813, Train Loss: 0.3125293552875519
[32m[0514 05:20:40 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.31574729084968567, Train Loss: 0.31252333521842957
[32m[0514 05:20:40 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.3157532215118408, Train Loss: 0.31251731514930725
[32m[0514 05:20:40 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.31575921177864075, Train Loss: 0.3125113546848297
[32m[0514 05:20:40 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.3157651126384735, Train Loss: 0.3125053644180298
[32m[0514 05:20:40 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.31577104330062866, Train Loss: 0.31249934434890747
[32m[0514 05:20:40 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.3157769739627838, Train Loss: 0.31249335408210754
[32m[0514 05:20:41 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.31578290462493896, Train Loss: 0.31248739361763
[32m[0514 05:20:41 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.31578877568244934, Train Loss: 0.3124813735485077
[32m[0514 05:20:41 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.3157947361469269, Train Loss: 0.31247538328170776
[32m[0514 05:20:41 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.3158005475997925, Train Loss: 0.3124694228172302
[32m[0514 05:20:41 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.31580638885498047, Train Loss: 0.3124634623527527
[32m[0514 05:20:41 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.31581225991249084, Train Loss: 0.31245750188827515
[32m[0514 05:20:41 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.3158181309700012, Train Loss: 0.31245148181915283
[32m[0514 05:20:41 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.3158239722251892, Train Loss: 0.3124455213546753
[32m[0514 05:20:41 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.3158298134803772, Train Loss: 0.312439501285553
[32m[0514 05:20:41 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.3158355951309204, Train Loss: 0.3124336004257202
[32m[0514 05:20:41 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.315841406583786, Train Loss: 0.3124276399612427
[32m[0514 05:20:41 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.3158471882343292, Train Loss: 0.31242167949676514
[32m[0514 05:20:42 @mbmf_sampler.py:98][0m Finished 9th episode
[32m[0514 05:20:42 @mbmf_sampler.py:102][0m 1809 timesteps from 9 episodes collected
[32m[0514 05:26:05 @mbmf_trainer.py:160][0m Mean reward: -339.5537884061875
[32m[0514 05:26:05 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.31159597635269165, Train Loss: 0.3132093846797943
[32m[0514 05:26:05 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.3117227852344513, Train Loss: 0.3131280839443207
[32m[0514 05:26:05 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.3117581307888031, Train Loss: 0.31309986114501953
[32m[0514 05:26:05 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.31181851029396057, Train Loss: 0.31306537985801697
[32m[0514 05:26:05 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.31187382340431213, Train Loss: 0.3130338490009308
[32m[0514 05:26:05 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.3119172751903534, Train Loss: 0.3130069673061371
[32m[0514 05:26:05 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.31195634603500366, Train Loss: 0.3129822015762329
[32m[0514 05:26:05 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.31199246644973755, Train Loss: 0.31295889616012573
[32m[0514 05:26:05 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.3120255172252655, Train Loss: 0.31293702125549316
[32m[0514 05:26:05 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.31205615401268005, Train Loss: 0.3129163682460785
[32m[0514 05:26:06 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.31208476424217224, Train Loss: 0.3128966987133026
[32m[0514 05:26:06 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.3121117949485779, Train Loss: 0.31287798285484314
[32m[0514 05:26:06 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.3121373653411865, Train Loss: 0.31286007165908813
[32m[0514 05:26:06 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.3121616840362549, Train Loss: 0.31284284591674805
[32m[0514 05:26:06 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.3121848404407501, Train Loss: 0.3128262460231781
[32m[0514 05:26:06 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.31220710277557373, Train Loss: 0.31281018257141113
[32m[0514 05:26:06 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.3122284412384033, Train Loss: 0.31279468536376953
[32m[0514 05:26:06 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.31224900484085083, Train Loss: 0.31277966499328613
[32m[0514 05:26:06 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.31226882338523865, Train Loss: 0.3127650320529938
[32m[0514 05:26:06 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.31228795647621155, Train Loss: 0.3127508759498596
[32m[0514 05:26:06 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.31230640411376953, Train Loss: 0.3127370774745941
[32m[0514 05:26:06 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.3123243749141693, Train Loss: 0.3127235770225525
[32m[0514 05:26:06 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.31234174966812134, Train Loss: 0.3127104640007019
[32m[0514 05:26:06 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.3123586177825928, Train Loss: 0.31269755959510803
[32m[0514 05:26:06 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.312375009059906, Train Loss: 0.3126850128173828
[32m[0514 05:26:06 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.3123909533023834, Train Loss: 0.3126727044582367
[32m[0514 05:26:07 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.3124065399169922, Train Loss: 0.3126606047153473
[32m[0514 05:26:07 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.31242167949676514, Train Loss: 0.31264883279800415
[32m[0514 05:26:07 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.31243640184402466, Train Loss: 0.31263720989227295
[32m[0514 05:26:07 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.3124508857727051, Train Loss: 0.31262582540512085
[32m[0514 05:26:07 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.31246495246887207, Train Loss: 0.31261464953422546
[32m[0514 05:26:07 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.31247878074645996, Train Loss: 0.312603622674942
[32m[0514 05:26:07 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.3124922215938568, Train Loss: 0.3125927746295929
[32m[0514 05:26:07 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.31250542402267456, Train Loss: 0.3125821352005005
[32m[0514 05:26:07 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.3125183880329132, Train Loss: 0.31257161498069763
[32m[0514 05:26:07 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.312531054019928, Train Loss: 0.3125613331794739
[32m[0514 05:26:07 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.3125435411930084, Train Loss: 0.3125511407852173
[32m[0514 05:26:07 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.312555730342865, Train Loss: 0.31254106760025024
[32m[0514 05:26:07 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.31256768107414246, Train Loss: 0.31253117322921753
[32m[0514 05:26:07 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.3125793933868408, Train Loss: 0.312521368265152
[32m[0514 05:26:08 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.312591016292572, Train Loss: 0.312511682510376
[32m[0514 05:26:08 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.31260234117507935, Train Loss: 0.3125021755695343
[32m[0514 05:26:08 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.31261351704597473, Train Loss: 0.3124927580356598
[32m[0514 05:26:08 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.3126245141029358, Train Loss: 0.31248342990875244
[32m[0514 05:26:08 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.31263530254364014, Train Loss: 0.31247419118881226
[32m[0514 05:26:08 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.31264597177505493, Train Loss: 0.312465101480484
[32m[0514 05:26:08 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.3126564621925354, Train Loss: 0.31245607137680054
[32m[0514 05:26:08 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.31266674399375916, Train Loss: 0.312447190284729
[32m[0514 05:26:08 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.31267693638801575, Train Loss: 0.31243836879730225
[32m[0514 05:26:08 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.312686949968338, Train Loss: 0.31242963671684265
[32m[0514 05:26:08 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.3126968741416931, Train Loss: 0.31242096424102783
[32m[0514 05:26:08 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.3127066195011139, Train Loss: 0.3124123513698578
[32m[0514 05:26:08 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.3127162754535675, Train Loss: 0.3124038875102997
[32m[0514 05:26:08 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.3127257525920868, Train Loss: 0.31239548325538635
[32m[0514 05:26:08 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.3127351403236389, Train Loss: 0.3123871088027954
[32m[0514 05:26:09 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.3127444088459015, Train Loss: 0.31237882375717163
[32m[0514 05:26:09 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.3127535283565521, Train Loss: 0.312370628118515
[32m[0514 05:26:09 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.3127625584602356, Train Loss: 0.3123624920845032
[32m[0514 05:26:09 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.31277143955230713, Train Loss: 0.3123544156551361
[32m[0514 05:26:09 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.3127802610397339, Train Loss: 0.3123463988304138
[32m[0514 05:26:09 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.3127889335155487, Train Loss: 0.3123384714126587
[32m[0514 05:26:09 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.31279754638671875, Train Loss: 0.31233054399490356
[32m[0514 05:26:09 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.31280601024627686, Train Loss: 0.3123227059841156
[32m[0514 05:26:09 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.31281447410583496, Train Loss: 0.3123149275779724
[32m[0514 05:26:09 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.31282272934913635, Train Loss: 0.3123072683811188
[32m[0514 05:26:09 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.31283092498779297, Train Loss: 0.3122994899749756
[32m[0514 05:26:09 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.3128390908241272, Train Loss: 0.3122919201850891
[32m[0514 05:26:09 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.3128471374511719, Train Loss: 0.31228432059288025
[32m[0514 05:26:09 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.3128551244735718, Train Loss: 0.31227681040763855
[32m[0514 05:26:09 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.31286293268203735, Train Loss: 0.31226933002471924
[32m[0514 05:26:10 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.31287074089050293, Train Loss: 0.3122619092464447
[32m[0514 05:26:10 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.31287848949432373, Train Loss: 0.31225448846817017
[32m[0514 05:26:10 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.3128860592842102, Train Loss: 0.3122471570968628
[32m[0514 05:26:10 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.3128936290740967, Train Loss: 0.3122398257255554
[32m[0514 05:26:10 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.3129011392593384, Train Loss: 0.3122325539588928
[32m[0514 05:26:10 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.3129085302352905, Train Loss: 0.3122252821922302
[32m[0514 05:26:10 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.3129158914089203, Train Loss: 0.3122180998325348
[32m[0514 05:26:10 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.3129231631755829, Train Loss: 0.31221094727516174
[32m[0514 05:26:10 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.31293028593063354, Train Loss: 0.3122038245201111
[32m[0514 05:26:10 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.3129374384880066, Train Loss: 0.3121967613697052
[32m[0514 05:26:10 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.3129444718360901, Train Loss: 0.3121896982192993
[32m[0514 05:26:10 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.3129514455795288, Train Loss: 0.3121826648712158
[32m[0514 05:26:10 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.31295838952064514, Train Loss: 0.3121756911277771
[32m[0514 05:26:10 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.3129652440547943, Train Loss: 0.312168687582016
[32m[0514 05:26:10 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.3129720687866211, Train Loss: 0.3121618330478668
[32m[0514 05:26:11 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.3129788041114807, Train Loss: 0.3121549189090729
[32m[0514 05:26:11 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.31298547983169556, Train Loss: 0.3121480643749237
[32m[0514 05:26:11 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.31299206614494324, Train Loss: 0.3121412396430969
[32m[0514 05:26:11 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.31299862265586853, Train Loss: 0.31213441491127014
[32m[0514 05:26:11 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.31300508975982666, Train Loss: 0.31212764978408813
[32m[0514 05:26:11 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.3130115568637848, Train Loss: 0.31212088465690613
[32m[0514 05:26:11 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.31301796436309814, Train Loss: 0.3121141493320465
[32m[0514 05:26:11 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.3130243122577667, Train Loss: 0.3121074438095093
[32m[0514 05:26:11 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.31303057074546814, Train Loss: 0.31210076808929443
[32m[0514 05:26:11 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.31303679943084717, Train Loss: 0.312094122171402
[32m[0514 05:26:11 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.3130429685115814, Train Loss: 0.3120874762535095
[32m[0514 05:26:11 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.3130490779876709, Train Loss: 0.31208091974258423
[32m[0514 05:26:11 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.3130551278591156, Train Loss: 0.31207436323165894
[32m[0514 05:26:11 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.3130611479282379, Train Loss: 0.31206774711608887
[32m[0514 05:26:11 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.31306710839271545, Train Loss: 0.31206122040748596
[32m[0514 05:26:12 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.3130730390548706, Train Loss: 0.31205472350120544
[32m[0514 05:26:12 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.3130788803100586, Train Loss: 0.31204819679260254
[32m[0514 05:26:12 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.3130846917629242, Train Loss: 0.3120417296886444
[32m[0514 05:26:12 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.3130905330181122, Train Loss: 0.31203532218933105
[32m[0514 05:26:12 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.31309622526168823, Train Loss: 0.3120288550853729
[32m[0514 05:26:12 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.3131018877029419, Train Loss: 0.31202244758605957
[32m[0514 05:26:12 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.31310752034187317, Train Loss: 0.3120160698890686
[32m[0514 05:26:12 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.31311312317848206, Train Loss: 0.3120097219944
[32m[0514 05:26:12 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.31311869621276855, Train Loss: 0.31200337409973145
[32m[0514 05:26:12 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.3131241798400879, Train Loss: 0.3119969964027405
[32m[0514 05:26:12 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.3131296634674072, Train Loss: 0.3119906485080719
[32m[0514 05:26:12 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.3131350874900818, Train Loss: 0.3119843900203705
[32m[0514 05:26:12 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.3131404519081116, Train Loss: 0.3119781017303467
[32m[0514 05:26:12 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.31314581632614136, Train Loss: 0.3119718134403229
[32m[0514 05:26:12 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.31315118074417114, Train Loss: 0.31196555495262146
[32m[0514 05:26:13 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.3131564259529114, Train Loss: 0.31195932626724243
[32m[0514 05:26:13 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.31316161155700684, Train Loss: 0.3119530975818634
[32m[0514 05:26:13 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.3131667673587799, Train Loss: 0.31194692850112915
[32m[0514 05:26:13 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.31317195296287537, Train Loss: 0.3119406998157501
[32m[0514 05:26:13 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.31317704916000366, Train Loss: 0.31193453073501587
[32m[0514 05:26:13 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.31318211555480957, Train Loss: 0.3119283616542816
[32m[0514 05:26:13 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.3131871521472931, Train Loss: 0.31192222237586975
[32m[0514 05:26:13 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.3131921589374542, Train Loss: 0.3119160830974579
[32m[0514 05:26:13 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.3131971061229706, Train Loss: 0.311909943819046
[32m[0514 05:26:13 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.3132020831108093, Train Loss: 0.31190383434295654
[32m[0514 05:26:13 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.31320691108703613, Train Loss: 0.31189778447151184
[32m[0514 05:26:13 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.3132117986679077, Train Loss: 0.31189167499542236
[32m[0514 05:26:13 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.31321659684181213, Train Loss: 0.3118855953216553
[32m[0514 05:26:13 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.31322139501571655, Train Loss: 0.31187954545021057
[32m[0514 05:26:13 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.3132261037826538, Train Loss: 0.31187349557876587
[32m[0514 05:26:14 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.31323087215423584, Train Loss: 0.31186747550964355
[32m[0514 05:26:14 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.3132355809211731, Train Loss: 0.31186142563819885
[32m[0514 05:26:14 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.3132402300834656, Train Loss: 0.31185540556907654
[32m[0514 05:26:14 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.31324484944343567, Train Loss: 0.3118494749069214
[32m[0514 05:26:14 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.31324946880340576, Train Loss: 0.31184348464012146
[32m[0514 05:26:14 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.31325405836105347, Train Loss: 0.3118375241756439
[32m[0514 05:26:14 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.3132585883140564, Train Loss: 0.311831533908844
[32m[0514 05:26:14 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.3132631182670593, Train Loss: 0.31182554364204407
[32m[0514 05:26:14 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.3132675290107727, Train Loss: 0.3118196427822113
[32m[0514 05:26:14 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.31327196955680847, Train Loss: 0.31181371212005615
[32m[0514 05:26:14 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.3132764399051666, Train Loss: 0.3118077516555786
[32m[0514 05:26:14 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.31328079104423523, Train Loss: 0.31180188059806824
[32m[0514 05:26:14 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.31328514218330383, Train Loss: 0.3117959797382355
[32m[0514 05:26:14 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.31328946352005005, Train Loss: 0.3117900788784027
[32m[0514 05:26:15 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.31329378485679626, Train Loss: 0.31178420782089233
[32m[0514 05:26:15 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.3132980763912201, Train Loss: 0.31177830696105957
[32m[0514 05:26:15 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.31330233812332153, Train Loss: 0.3117724657058716
[32m[0514 05:26:15 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.3133065402507782, Train Loss: 0.3117665946483612
[32m[0514 05:26:15 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.31331074237823486, Train Loss: 0.3117607533931732
[32m[0514 05:26:15 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.31331494450569153, Train Loss: 0.3117549419403076
[32m[0514 05:26:15 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.3133191466331482, Train Loss: 0.311749130487442
[32m[0514 05:26:15 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.3133231997489929, Train Loss: 0.31174328923225403
[32m[0514 05:26:15 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.31332728266716003, Train Loss: 0.31173744797706604
[32m[0514 05:26:15 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.31333136558532715, Train Loss: 0.3117316961288452
[32m[0514 05:26:15 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.3133353888988495, Train Loss: 0.3117258846759796
[32m[0514 05:26:15 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.3133394420146942, Train Loss: 0.3117201328277588
[32m[0514 05:26:15 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.31334346532821655, Train Loss: 0.3117142915725708
[32m[0514 05:26:15 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.3133474290370941, Train Loss: 0.31170856952667236
[32m[0514 05:26:15 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.3133513629436493, Train Loss: 0.31170281767845154
[32m[0514 05:26:16 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.31335529685020447, Train Loss: 0.3116970658302307
[32m[0514 05:26:16 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.31335923075675964, Train Loss: 0.3116912841796875
[32m[0514 05:26:16 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.31336310505867004, Train Loss: 0.31168559193611145
[32m[0514 05:26:16 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.31336694955825806, Train Loss: 0.3116798400878906
[32m[0514 05:26:16 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.31337085366249084, Train Loss: 0.3116741180419922
[32m[0514 05:26:16 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.31337466835975647, Train Loss: 0.31166839599609375
[32m[0514 05:26:16 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.3133785128593445, Train Loss: 0.3116626739501953
[32m[0514 05:26:16 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.31338223814964294, Train Loss: 0.31165701150894165
[32m[0514 05:26:16 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.3133860230445862, Train Loss: 0.3116512894630432
[32m[0514 05:26:16 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.31338974833488464, Train Loss: 0.31164559721946716
[32m[0514 05:26:16 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.3133934736251831, Train Loss: 0.3116399347782135
[32m[0514 05:26:16 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.3133971691131592, Train Loss: 0.31163421273231506
[32m[0514 05:26:16 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.31340083479881287, Train Loss: 0.3116285800933838
[32m[0514 05:26:16 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.31340453028678894, Train Loss: 0.3116229176521301
[32m[0514 05:26:16 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.31340816617012024, Train Loss: 0.3116172254085541
[32m[0514 05:26:17 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.31341177225112915, Train Loss: 0.3116115927696228
[32m[0514 05:26:17 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.31341540813446045, Train Loss: 0.31160596013069153
[32m[0514 05:26:17 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.3134189248085022, Train Loss: 0.31160029768943787
[32m[0514 05:26:17 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.3134225606918335, Train Loss: 0.31159472465515137
[32m[0514 05:26:17 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.31342610716819763, Train Loss: 0.3115890622138977
[32m[0514 05:26:17 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.31342965364456177, Train Loss: 0.31158342957496643
[32m[0514 05:26:17 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.31343314051628113, Train Loss: 0.31157779693603516
[32m[0514 05:26:17 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.31343668699264526, Train Loss: 0.31157222390174866
[32m[0514 05:26:17 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.31344014406204224, Train Loss: 0.31156662106513977
[32m[0514 05:26:17 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.3134436011314392, Train Loss: 0.3115610182285309
[32m[0514 05:26:17 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.31344708800315857, Train Loss: 0.311555415391922
[32m[0514 05:26:17 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.31345048546791077, Train Loss: 0.3115498125553131
[32m[0514 05:26:17 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.31345388293266296, Train Loss: 0.311544269323349
[32m[0514 05:26:17 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.31345728039741516, Train Loss: 0.3115386962890625
[32m[0514 05:26:18 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.31346070766448975, Train Loss: 0.311533123254776
[32m[0514 05:26:18 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.31346407532691956, Train Loss: 0.3115275204181671
[32m[0514 05:26:18 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.313467413187027, Train Loss: 0.311521977186203
[32m[0514 05:26:18 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.3134707510471344, Train Loss: 0.3115164041519165
[32m[0514 05:26:18 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.31347405910491943, Train Loss: 0.3115108907222748
[32m[0514 05:26:18 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.31347739696502686, Train Loss: 0.31150534749031067
[32m[0514 05:26:18 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.3134806454181671, Train Loss: 0.31149980425834656
[32m[0514 05:26:18 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.31348395347595215, Train Loss: 0.31149426102638245
[32m[0514 05:26:18 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.3134872317314148, Train Loss: 0.31148871779441833
[32m[0514 05:26:18 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.31349045038223267, Train Loss: 0.311483234167099
[32m[0514 05:26:18 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.3134937584400177, Train Loss: 0.3114776611328125
[32m[0514 05:26:18 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.3134969472885132, Train Loss: 0.3114721477031708
[32m[0514 05:26:18 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.3135001063346863, Train Loss: 0.31146660447120667
[32m[0514 05:26:18 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.31350332498550415, Train Loss: 0.3114611506462097
[32m[0514 05:26:18 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.313506543636322, Train Loss: 0.311455637216568
[32m[0514 05:26:19 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.3135097324848175, Train Loss: 0.31145015358924866
[32m[0514 05:26:19 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.3135128617286682, Train Loss: 0.3114446699619293
[32m[0514 05:26:19 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.3135160207748413, Train Loss: 0.3114391267299652
[32m[0514 05:26:19 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.313519150018692, Train Loss: 0.31143367290496826
[32m[0514 05:26:19 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.31352224946022034, Train Loss: 0.31142815947532654
[32m[0514 05:26:19 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.31352537870407104, Train Loss: 0.3114227056503296
[32m[0514 05:26:19 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.31352847814559937, Train Loss: 0.31141722202301025
[32m[0514 05:26:19 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.3135315477848053, Train Loss: 0.3114117681980133
[32m[0514 05:26:19 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.31353461742401123, Train Loss: 0.31140631437301636
[32m[0514 05:26:19 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.31353771686553955, Train Loss: 0.31140080094337463
[32m[0514 05:26:19 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.3135407269001007, Train Loss: 0.3113953769207001
[32m[0514 05:26:19 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.31354376673698425, Train Loss: 0.31138989329338074
[32m[0514 05:26:19 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.3135468065738678, Train Loss: 0.31138449907302856
[32m[0514 05:26:19 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.31354984641075134, Train Loss: 0.31137901544570923
[32m[0514 05:26:19 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.3135528266429901, Train Loss: 0.31137359142303467
[32m[0514 05:26:20 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.3135558068752289, Train Loss: 0.3113681375980377
[32m[0514 05:26:20 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.31355881690979004, Train Loss: 0.31136271357536316
[32m[0514 05:26:20 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.3135617971420288, Train Loss: 0.3113572597503662
[32m[0514 05:26:20 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.3135647475719452, Train Loss: 0.31135186553001404
[32m[0514 05:26:20 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.3135676980018616, Train Loss: 0.3113464117050171
[32m[0514 05:26:20 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.31357061862945557, Train Loss: 0.31134098768234253
[32m[0514 05:26:20 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.31357353925704956, Train Loss: 0.31133556365966797
[32m[0514 05:26:20 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.31357643008232117, Train Loss: 0.3113301694393158
[32m[0514 05:26:20 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.31357938051223755, Train Loss: 0.31132474541664124
[32m[0514 05:26:20 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.31358224153518677, Train Loss: 0.3113193213939667
[32m[0514 05:26:20 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.31358516216278076, Train Loss: 0.3113139271736145
[32m[0514 05:26:20 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.31358802318573, Train Loss: 0.3113085627555847
[32m[0514 05:26:20 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.3135909140110016, Train Loss: 0.31130316853523254
[32m[0514 05:26:20 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.3135938048362732, Train Loss: 0.31129777431488037
[32m[0514 05:26:20 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.3135966658592224, Train Loss: 0.3112923800945282
[32m[0514 05:26:21 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.31359952688217163, Train Loss: 0.31128695607185364
[32m[0514 05:26:21 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.3136023283004761, Train Loss: 0.31128159165382385
[32m[0514 05:26:21 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.3136051595211029, Train Loss: 0.3112761974334717
[32m[0514 05:26:21 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.31360796093940735, Train Loss: 0.3112708628177643
[32m[0514 05:26:21 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.3136107921600342, Train Loss: 0.3112654685974121
[32m[0514 05:26:21 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.3136135935783386, Train Loss: 0.3112601041793823
[32m[0514 05:26:21 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.31361639499664307, Train Loss: 0.31125470995903015
[32m[0514 05:26:21 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.31361913681030273, Train Loss: 0.31124934554100037
[32m[0514 05:26:21 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.31362196803092957, Train Loss: 0.31124404072761536
[32m[0514 05:26:21 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.31362468004226685, Train Loss: 0.3112386465072632
[32m[0514 05:26:21 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.3136274218559265, Train Loss: 0.3112332820892334
[32m[0514 05:26:21 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.31363022327423096, Train Loss: 0.311227947473526
[32m[0514 05:26:21 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.3136329650878906, Train Loss: 0.3112225830554962
[32m[0514 05:26:21 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.3136356472969055, Train Loss: 0.3112172484397888
[32m[0514 05:26:22 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.31363844871520996, Train Loss: 0.31121185421943665
[32m[0514 05:26:22 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.31364116072654724, Train Loss: 0.311206579208374
[32m[0514 05:26:22 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.3136438727378845, Train Loss: 0.31120121479034424
[32m[0514 05:26:22 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.3136465847492218, Train Loss: 0.31119588017463684
[32m[0514 05:26:22 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.3136492669582367, Train Loss: 0.31119054555892944
[32m[0514 05:26:22 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.3136519491672516, Train Loss: 0.31118521094322205
[32m[0514 05:26:22 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.31365466117858887, Train Loss: 0.31117987632751465
[32m[0514 05:26:22 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.31365734338760376, Train Loss: 0.311174601316452
[32m[0514 05:26:22 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.31366002559661865, Train Loss: 0.31116923689842224
[32m[0514 05:26:22 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.31366273760795593, Train Loss: 0.3111639618873596
[32m[0514 05:26:22 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.3136653006076813, Train Loss: 0.3111586272716522
[32m[0514 05:26:22 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.31366801261901855, Train Loss: 0.3111533224582672
[32m[0514 05:26:22 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.31367066502571106, Train Loss: 0.3111480474472046
[32m[0514 05:26:22 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.31367331743240356, Train Loss: 0.3111426830291748
[32m[0514 05:26:23 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.3136758804321289, Train Loss: 0.3111374080181122
[32m[0514 05:26:23 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.3136785626411438, Train Loss: 0.3111320734024048
[32m[0514 05:26:23 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.3136812150478363, Train Loss: 0.31112679839134216
[32m[0514 05:26:23 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.31368374824523926, Train Loss: 0.31112149357795715
[32m[0514 05:26:23 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.31368640065193176, Train Loss: 0.31111618876457214
[32m[0514 05:26:23 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.3136889934539795, Train Loss: 0.3111109137535095
[32m[0514 05:26:23 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.3136916160583496, Train Loss: 0.3111056089401245
[32m[0514 05:26:23 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.31369417905807495, Train Loss: 0.3111003339290619
[32m[0514 05:26:23 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.3136967718601227, Train Loss: 0.3110949993133545
[32m[0514 05:26:23 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.3136993944644928, Train Loss: 0.31108975410461426
[32m[0514 05:26:23 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.31370192766189575, Train Loss: 0.311084508895874
[32m[0514 05:26:23 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.31370455026626587, Train Loss: 0.3110792338848114
[32m[0514 05:26:23 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.3137070834636688, Train Loss: 0.3110739588737488
[32m[0514 05:26:23 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.31370967626571655, Train Loss: 0.31106871366500854
[32m[0514 05:26:23 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.3137122392654419, Train Loss: 0.31106340885162354
[32m[0514 05:26:24 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.31371474266052246, Train Loss: 0.3110581338405609
[32m[0514 05:26:24 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.3137173056602478, Train Loss: 0.3110528886318207
[32m[0514 05:26:24 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.31371989846229553, Train Loss: 0.31104764342308044
[32m[0514 05:26:24 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.3137223720550537, Train Loss: 0.3110423982143402
[32m[0514 05:26:24 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.31372490525245667, Train Loss: 0.3110371232032776
[32m[0514 05:26:24 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.313727468252182, Train Loss: 0.31103187799453735
[32m[0514 05:26:24 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.31373000144958496, Train Loss: 0.31102660298347473
[32m[0514 05:26:24 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.3137325346469879, Train Loss: 0.3110213875770569
[32m[0514 05:26:24 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.3137350082397461, Train Loss: 0.31101611256599426
[32m[0514 05:26:24 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.31373754143714905, Train Loss: 0.3110108971595764
[32m[0514 05:26:24 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.3137400150299072, Train Loss: 0.3110056519508362
[32m[0514 05:26:24 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.3137425482273102, Train Loss: 0.31100037693977356
[32m[0514 05:26:24 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.31374502182006836, Train Loss: 0.3109951913356781
[32m[0514 05:26:24 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.3137475550174713, Train Loss: 0.31098994612693787
[32m[0514 05:26:24 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.3137500286102295, Train Loss: 0.31098470091819763
[32m[0514 05:26:25 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.31375253200531006, Train Loss: 0.3109794557094574
[32m[0514 05:26:25 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.31375497579574585, Train Loss: 0.31097427010536194
[32m[0514 05:26:25 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.3137575089931488, Train Loss: 0.3109689950942993
[32m[0514 05:26:25 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.3137599527835846, Train Loss: 0.31096377968788147
[32m[0514 05:26:25 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.31376245617866516, Train Loss: 0.3109585642814636
[32m[0514 05:26:25 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.31376489996910095, Train Loss: 0.3109533488750458
[32m[0514 05:26:25 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.31376734375953674, Train Loss: 0.31094813346862793
[32m[0514 05:26:25 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.3137698173522949, Train Loss: 0.3109429180622101
[32m[0514 05:26:25 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.3137723207473755, Train Loss: 0.3109377324581146
[32m[0514 05:26:26 @mbmf_sampler.py:98][0m Finished 9th episode
[32m[0514 05:26:26 @mbmf_sampler.py:102][0m 1809 timesteps from 9 episodes collected
[32m[0514 05:31:47 @mbmf_trainer.py:160][0m Mean reward: -365.7920970444239
[32m[0514 05:31:47 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.3134724199771881, Train Loss: 0.3114370107650757
[32m[0514 05:31:47 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.3134724497795105, Train Loss: 0.3113778233528137
[32m[0514 05:31:47 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.3135184347629547, Train Loss: 0.3113367557525635
[32m[0514 05:31:47 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.313570499420166, Train Loss: 0.31130385398864746
[32m[0514 05:31:47 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.31361323595046997, Train Loss: 0.3112781345844269
[32m[0514 05:31:47 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.31365424394607544, Train Loss: 0.3112545609474182
[32m[0514 05:31:47 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.31369200348854065, Train Loss: 0.31123363971710205
[32m[0514 05:31:47 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.3137272298336029, Train Loss: 0.31121447682380676
[32m[0514 05:31:47 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.313760370016098, Train Loss: 0.3111967146396637
[32m[0514 05:31:47 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.31379184126853943, Train Loss: 0.3111799955368042
[32m[0514 05:31:47 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.3138217628002167, Train Loss: 0.3111642301082611
[32m[0514 05:31:48 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.31385040283203125, Train Loss: 0.3111491799354553
[32m[0514 05:31:48 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.31387796998023987, Train Loss: 0.31113478541374207
[32m[0514 05:31:48 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.3139045834541321, Train Loss: 0.3111209571361542
[32m[0514 05:31:48 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.3139304220676422, Train Loss: 0.3111076056957245
[32m[0514 05:31:48 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.3139554560184479, Train Loss: 0.3110947012901306
[32m[0514 05:31:48 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.3139799237251282, Train Loss: 0.31108224391937256
[32m[0514 05:31:48 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.3140038251876831, Train Loss: 0.31107011437416077
[32m[0514 05:31:48 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.31402716040611267, Train Loss: 0.31105831265449524
[32m[0514 05:31:48 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.3140500485897064, Train Loss: 0.3110468089580536
[32m[0514 05:31:48 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.31407251954078674, Train Loss: 0.3110356032848358
[32m[0514 05:31:48 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.31409457325935364, Train Loss: 0.31102463603019714
[32m[0514 05:31:48 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.3141162395477295, Train Loss: 0.31101393699645996
[32m[0514 05:31:49 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.3141375482082367, Train Loss: 0.3110034465789795
[32m[0514 05:31:49 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.3141585886478424, Train Loss: 0.3109932243824005
[32m[0514 05:31:49 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.31417930126190186, Train Loss: 0.3109830915927887
[32m[0514 05:31:49 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.3141997158527374, Train Loss: 0.310973197221756
[32m[0514 05:31:49 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.31421977281570435, Train Loss: 0.31096351146698
[32m[0514 05:31:49 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.31423965096473694, Train Loss: 0.3109539747238159
[32m[0514 05:31:49 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.31425926089286804, Train Loss: 0.3109445571899414
[32m[0514 05:31:49 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.31427857279777527, Train Loss: 0.31093528866767883
[32m[0514 05:31:49 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.3142976462841034, Train Loss: 0.3109261989593506
[32m[0514 05:31:49 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.31431645154953003, Train Loss: 0.3109172284603119
[32m[0514 05:31:49 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.31433507800102234, Train Loss: 0.3109084367752075
[32m[0514 05:31:49 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.31435343623161316, Train Loss: 0.31089964509010315
[32m[0514 05:31:49 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.31437161564826965, Train Loss: 0.3108910620212555
[32m[0514 05:31:50 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.31438955664634705, Train Loss: 0.3108825981616974
[32m[0514 05:31:50 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.31440725922584534, Train Loss: 0.31087419390678406
[32m[0514 05:31:50 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.3144247531890869, Train Loss: 0.3108659088611603
[32m[0514 05:31:50 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.31444206833839417, Train Loss: 0.31085774302482605
[32m[0514 05:31:50 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.3144591152667999, Train Loss: 0.3108496069908142
[32m[0514 05:31:50 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.31447604298591614, Train Loss: 0.3108415901660919
[32m[0514 05:31:50 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.314492791891098, Train Loss: 0.3108336627483368
[32m[0514 05:31:50 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.3145093023777008, Train Loss: 0.31082579493522644
[32m[0514 05:31:50 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.31452566385269165, Train Loss: 0.31081804633140564
[32m[0514 05:31:50 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.3145418167114258, Train Loss: 0.3108103275299072
[32m[0514 05:31:50 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.3145577907562256, Train Loss: 0.310802698135376
[32m[0514 05:31:50 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.31457361578941345, Train Loss: 0.3107951283454895
[32m[0514 05:31:50 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.3145892024040222, Train Loss: 0.3107876479625702
[32m[0514 05:31:51 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.3146046996116638, Train Loss: 0.31078028678894043
[32m[0514 05:31:51 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.3146199584007263, Train Loss: 0.3107728660106659
[32m[0514 05:31:51 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.31463515758514404, Train Loss: 0.3107655942440033
[32m[0514 05:31:51 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.3146500885486603, Train Loss: 0.3107583224773407
[32m[0514 05:31:51 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.31466493010520935, Train Loss: 0.31075114011764526
[32m[0514 05:31:51 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.3146795928478241, Train Loss: 0.310744047164917
[32m[0514 05:31:51 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.3146941065788269, Train Loss: 0.31073689460754395
[32m[0514 05:31:51 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.3147084712982178, Train Loss: 0.31072989106178284
[32m[0514 05:31:51 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.3147227168083191, Train Loss: 0.31072285771369934
[32m[0514 05:31:51 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.3147367835044861, Train Loss: 0.3107159435749054
[32m[0514 05:31:51 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.3147507309913635, Train Loss: 0.31070902943611145
[32m[0514 05:31:51 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.3147645592689514, Train Loss: 0.31070220470428467
[32m[0514 05:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.31477826833724976, Train Loss: 0.3106953799724579
[32m[0514 05:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.31479179859161377, Train Loss: 0.3106885850429535
[32m[0514 05:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.31480520963668823, Train Loss: 0.31068187952041626
[32m[0514 05:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.31481853127479553, Train Loss: 0.31067517399787903
[32m[0514 05:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.3148316740989685, Train Loss: 0.3106685280799866
[32m[0514 05:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.3148447573184967, Train Loss: 0.3106619119644165
[32m[0514 05:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.31485772132873535, Train Loss: 0.3106553256511688
[32m[0514 05:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.3148705065250397, Train Loss: 0.3106487989425659
[32m[0514 05:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.31488320231437683, Train Loss: 0.3106422424316406
[32m[0514 05:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.31489574909210205, Train Loss: 0.3106357455253601
[32m[0514 05:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.3149082064628601, Train Loss: 0.310629278421402
[32m[0514 05:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.3149206042289734, Train Loss: 0.3106228709220886
[32m[0514 05:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.3149328827857971, Train Loss: 0.31061646342277527
[32m[0514 05:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.3149450421333313, Train Loss: 0.3106100857257843
[32m[0514 05:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.3149570822715759, Train Loss: 0.3106037676334381
[32m[0514 05:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.31496909260749817, Train Loss: 0.3105974793434143
[32m[0514 05:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.3149809241294861, Train Loss: 0.3105911910533905
[32m[0514 05:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.3149926960468292, Train Loss: 0.3105849325656891
[32m[0514 05:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.3150043487548828, Train Loss: 0.31057870388031006
[32m[0514 05:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.31501591205596924, Train Loss: 0.31057247519493103
[32m[0514 05:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.3150274157524109, Train Loss: 0.3105662763118744
[32m[0514 05:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.315038800239563, Train Loss: 0.3105601370334625
[32m[0514 05:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.3150500953197479, Train Loss: 0.31055399775505066
[32m[0514 05:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.3150613307952881, Train Loss: 0.3105478882789612
[32m[0514 05:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.3150724470615387, Train Loss: 0.3105417490005493
[32m[0514 05:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.31508347392082214, Train Loss: 0.31053563952445984
[32m[0514 05:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.3150944709777832, Train Loss: 0.3105296492576599
[32m[0514 05:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.3151053786277771, Train Loss: 0.3105235695838928
[32m[0514 05:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.31511616706848145, Train Loss: 0.3105175793170929
[32m[0514 05:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.315126895904541, Train Loss: 0.3105115592479706
[32m[0514 05:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.3151375651359558, Train Loss: 0.31050559878349304
[32m[0514 05:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.31514811515808105, Train Loss: 0.3104996383190155
[32m[0514 05:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.3151586353778839, Train Loss: 0.31049373745918274
[32m[0514 05:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.3151690661907196, Train Loss: 0.3104878067970276
[32m[0514 05:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.3151794373989105, Train Loss: 0.31048187613487244
[32m[0514 05:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.3151896893978119, Train Loss: 0.31047600507736206
[32m[0514 05:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.31519991159439087, Train Loss: 0.3104701042175293
[32m[0514 05:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.3152100741863251, Train Loss: 0.3104642629623413
[32m[0514 05:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.3152201771736145, Train Loss: 0.3104584217071533
[32m[0514 05:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.31523022055625916, Train Loss: 0.31045258045196533
[32m[0514 05:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.31524020433425903, Train Loss: 0.31044676899909973
[32m[0514 05:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.315250039100647, Train Loss: 0.3104409873485565
[32m[0514 05:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.3152598440647125, Train Loss: 0.3104351758956909
[32m[0514 05:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.3152696490287781, Train Loss: 0.3104294240474701
[32m[0514 05:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.31527936458587646, Train Loss: 0.3104236423969269
[32m[0514 05:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.31528905034065247, Train Loss: 0.31041795015335083
[32m[0514 05:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.3152986168861389, Train Loss: 0.3104122281074524
[32m[0514 05:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.31530818343162537, Train Loss: 0.31040647625923157
[32m[0514 05:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.31531763076782227, Train Loss: 0.3104007840156555
[32m[0514 05:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.31532707810401917, Train Loss: 0.31039509177207947
[32m[0514 05:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.3153364360332489, Train Loss: 0.3103894293308258
[32m[0514 05:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.31534576416015625, Train Loss: 0.31038376688957214
[32m[0514 05:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.31535500288009644, Train Loss: 0.3103781044483185
[32m[0514 05:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.31536421179771423, Train Loss: 0.3103724718093872
[32m[0514 05:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.31537336111068726, Train Loss: 0.31036683917045593
[32m[0514 05:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.3153824806213379, Train Loss: 0.31036123633384705
[32m[0514 05:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.31539151072502136, Train Loss: 0.31035560369491577
[32m[0514 05:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.31540054082870483, Train Loss: 0.31035006046295166
[32m[0514 05:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.3154095411300659, Train Loss: 0.3103444278240204
[32m[0514 05:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.31541842222213745, Train Loss: 0.31033891439437866
[32m[0514 05:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.3154272735118866, Train Loss: 0.3103333115577698
[32m[0514 05:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.31543606519699097, Train Loss: 0.31032776832580566
[32m[0514 05:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.3154448866844177, Train Loss: 0.31032225489616394
[32m[0514 05:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.31545358896255493, Train Loss: 0.31031668186187744
[32m[0514 05:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.3154623210430145, Train Loss: 0.31031113862991333
[32m[0514 05:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.31547093391418457, Train Loss: 0.3103056848049164
[32m[0514 05:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.3154795467853546, Train Loss: 0.31030014157295227
[32m[0514 05:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.3154881000518799, Train Loss: 0.3102946877479553
[32m[0514 05:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.315496563911438, Train Loss: 0.310289204120636
[32m[0514 05:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.3155050575733185, Train Loss: 0.31028369069099426
[32m[0514 05:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.3155134916305542, Train Loss: 0.3102782070636749
[32m[0514 05:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.31552189588546753, Train Loss: 0.31027281284332275
[32m[0514 05:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.31553027033805847, Train Loss: 0.3102673292160034
[32m[0514 05:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.315538614988327, Train Loss: 0.31026193499565125
[32m[0514 05:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.31554684042930603, Train Loss: 0.3102564811706543
[32m[0514 05:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.3155550956726074, Train Loss: 0.31025105714797974
[32m[0514 05:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.31556326150894165, Train Loss: 0.3102456331253052
[32m[0514 05:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.31557145714759827, Train Loss: 0.3102402687072754
[32m[0514 05:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.31557953357696533, Train Loss: 0.3102348744869232
[32m[0514 05:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.3155876696109772, Train Loss: 0.31022951006889343
[32m[0514 05:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.31559571623802185, Train Loss: 0.31022408604621887
[32m[0514 05:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.31560376286506653, Train Loss: 0.3102187514305115
[32m[0514 05:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.31561174988746643, Train Loss: 0.3102133572101593
[32m[0514 05:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.31561967730522156, Train Loss: 0.3102079927921295
[32m[0514 05:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.3156275749206543, Train Loss: 0.3102027177810669
[32m[0514 05:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.3156355023384094, Train Loss: 0.3101973533630371
[32m[0514 05:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.3156433701515198, Train Loss: 0.3101920187473297
[32m[0514 05:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.31565117835998535, Train Loss: 0.3101866543292999
[32m[0514 05:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.31565892696380615, Train Loss: 0.3101814091205597
[32m[0514 05:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.31566667556762695, Train Loss: 0.3101760447025299
[32m[0514 05:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.31567442417144775, Train Loss: 0.3101707994937897
[32m[0514 05:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.3156821131706238, Train Loss: 0.3101654350757599
[32m[0514 05:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.3156898021697998, Train Loss: 0.31016018986701965
[32m[0514 05:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.31569740176200867, Train Loss: 0.31015488505363464
[32m[0514 05:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.31570500135421753, Train Loss: 0.31014958024024963
[32m[0514 05:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.3157126009464264, Train Loss: 0.3101443350315094
[32m[0514 05:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.31572017073631287, Train Loss: 0.31013908982276917
[32m[0514 05:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.31572768092155457, Train Loss: 0.31013381481170654
[32m[0514 05:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.3157351613044739, Train Loss: 0.3101285696029663
[32m[0514 05:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.3157426118850708, Train Loss: 0.3101233243942261
[32m[0514 05:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.3157500624656677, Train Loss: 0.31011807918548584
[32m[0514 05:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.31575748324394226, Train Loss: 0.310112863779068
[32m[0514 05:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.315764844417572, Train Loss: 0.31010767817497253
[32m[0514 05:32:00 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.3157722055912018, Train Loss: 0.3101024627685547
[32m[0514 05:32:00 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.3157794773578644, Train Loss: 0.31009724736213684
[32m[0514 05:32:00 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.31578680872917175, Train Loss: 0.3100920021533966
[32m[0514 05:32:00 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.31579411029815674, Train Loss: 0.31008684635162354
[32m[0514 05:32:00 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.31580135226249695, Train Loss: 0.3100816011428833
[32m[0514 05:32:00 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.31580856442451477, Train Loss: 0.31007644534111023
[32m[0514 05:32:00 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.3158157765865326, Train Loss: 0.31007125973701477
[32m[0514 05:32:00 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.31582289934158325, Train Loss: 0.3100660443305969
[32m[0514 05:32:00 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.3158300817012787, Train Loss: 0.31006085872650146
[32m[0514 05:32:00 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.31583720445632935, Train Loss: 0.3100557327270508
[32m[0514 05:32:00 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.31584432721138, Train Loss: 0.3100505769252777
[32m[0514 05:32:00 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.31585144996643066, Train Loss: 0.31004542112350464
[32m[0514 05:32:00 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.3158584535121918, Train Loss: 0.31004026532173157
[32m[0514 05:32:01 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.31586548686027527, Train Loss: 0.3100351095199585
[32m[0514 05:32:01 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.3158724904060364, Train Loss: 0.3100300133228302
[32m[0514 05:32:01 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.31587955355644226, Train Loss: 0.31002485752105713
[32m[0514 05:32:01 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.3158864378929138, Train Loss: 0.31001976132392883
[32m[0514 05:32:01 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.31589338183403015, Train Loss: 0.31001460552215576
[32m[0514 05:32:01 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.3159003257751465, Train Loss: 0.3100094497203827
[32m[0514 05:32:01 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.31590723991394043, Train Loss: 0.3100043535232544
[32m[0514 05:32:01 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.315914124250412, Train Loss: 0.3099992573261261
[32m[0514 05:32:01 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.3159209191799164, Train Loss: 0.3099941909313202
[32m[0514 05:32:01 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.31592780351638794, Train Loss: 0.3099890947341919
[32m[0514 05:32:01 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.31593459844589233, Train Loss: 0.3099839985370636
[32m[0514 05:32:01 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.31594139337539673, Train Loss: 0.3099788725376129
[32m[0514 05:32:01 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.3159482181072235, Train Loss: 0.3099738359451294
[32m[0514 05:32:02 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.31595492362976074, Train Loss: 0.3099687397480011
[32m[0514 05:32:02 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.31596168875694275, Train Loss: 0.3099636733531952
[32m[0514 05:32:02 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.3159683644771576, Train Loss: 0.3099585771560669
[32m[0514 05:32:02 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.3159750699996948, Train Loss: 0.3099535405635834
[32m[0514 05:32:02 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.31598174571990967, Train Loss: 0.30994847416877747
[32m[0514 05:32:02 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.3159884214401245, Train Loss: 0.30994340777397156
[32m[0514 05:32:02 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.3159950375556946, Train Loss: 0.30993837118148804
[32m[0514 05:32:02 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.31600168347358704, Train Loss: 0.30993330478668213
[32m[0514 05:32:02 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.31600823998451233, Train Loss: 0.3099282681941986
[32m[0514 05:32:02 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.31601482629776, Train Loss: 0.3099232017993927
[32m[0514 05:32:02 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.3160214126110077, Train Loss: 0.30991822481155396
[32m[0514 05:32:02 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.316027969121933, Train Loss: 0.30991312861442566
[32m[0514 05:32:02 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.3160344660282135, Train Loss: 0.3099081218242645
[32m[0514 05:32:03 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.3160409927368164, Train Loss: 0.309903085231781
[32m[0514 05:32:03 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.31604745984077454, Train Loss: 0.30989813804626465
[32m[0514 05:32:03 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.31605398654937744, Train Loss: 0.30989310145378113
[32m[0514 05:32:03 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.31606045365333557, Train Loss: 0.30988809466362
[32m[0514 05:32:03 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.31606683135032654, Train Loss: 0.30988308787345886
[32m[0514 05:32:03 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.31607329845428467, Train Loss: 0.30987808108329773
[32m[0514 05:32:03 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.316079705953598, Train Loss: 0.309873104095459
[32m[0514 05:32:03 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.3160861134529114, Train Loss: 0.30986809730529785
[32m[0514 05:32:03 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.31609249114990234, Train Loss: 0.3098631203174591
[32m[0514 05:32:03 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.31609877943992615, Train Loss: 0.309858113527298
[32m[0514 05:32:03 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.3161051273345947, Train Loss: 0.309853196144104
[32m[0514 05:32:03 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.3161114752292633, Train Loss: 0.30984818935394287
[32m[0514 05:32:03 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.3161177933216095, Train Loss: 0.3098432421684265
[32m[0514 05:32:04 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.3161240518093109, Train Loss: 0.30983826518058777
[32m[0514 05:32:04 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.3161303699016571, Train Loss: 0.309833288192749
[32m[0514 05:32:04 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.31613659858703613, Train Loss: 0.3098282814025879
[32m[0514 05:32:04 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.31614282727241516, Train Loss: 0.3098233640193939
[32m[0514 05:32:04 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.31614911556243896, Train Loss: 0.3098183870315552
[32m[0514 05:32:04 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.3161553144454956, Train Loss: 0.3098134696483612
[32m[0514 05:32:04 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.31616151332855225, Train Loss: 0.30980852246284485
[32m[0514 05:32:04 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.3161677122116089, Train Loss: 0.3098036050796509
[32m[0514 05:32:04 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.31617388129234314, Train Loss: 0.30979862809181213
[32m[0514 05:32:04 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.3161799907684326, Train Loss: 0.30979371070861816
[32m[0514 05:32:04 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.31618615984916687, Train Loss: 0.3097887933254242
[32m[0514 05:32:04 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.31619229912757874, Train Loss: 0.3097839057445526
[32m[0514 05:32:04 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.3161984384059906, Train Loss: 0.3097788989543915
[32m[0514 05:32:05 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.3162045180797577, Train Loss: 0.3097740113735199
[32m[0514 05:32:05 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.31621065735816956, Train Loss: 0.3097690939903259
[32m[0514 05:32:05 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.31621673703193665, Train Loss: 0.30976420640945435
[32m[0514 05:32:05 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.31622278690338135, Train Loss: 0.309759259223938
[32m[0514 05:32:05 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.31622883677482605, Train Loss: 0.3097543716430664
[32m[0514 05:32:05 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.31623485684394836, Train Loss: 0.3097494840621948
[32m[0514 05:32:05 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.3162408471107483, Train Loss: 0.30974456667900085
[32m[0514 05:32:05 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.3162468671798706, Train Loss: 0.3097396492958069
[32m[0514 05:32:05 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.31625285744667053, Train Loss: 0.3097347915172577
[32m[0514 05:32:05 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.31625884771347046, Train Loss: 0.3097298741340637
[32m[0514 05:32:05 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.316264808177948, Train Loss: 0.30972498655319214
[32m[0514 05:32:05 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.3162707984447479, Train Loss: 0.30972006916999817
[32m[0514 05:32:06 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.3162767291069031, Train Loss: 0.30971524119377136
[32m[0514 05:32:06 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.3162826597690582, Train Loss: 0.3097103536128998
[32m[0514 05:32:06 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.3162885904312134, Train Loss: 0.3097054660320282
[32m[0514 05:32:06 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.3162945508956909, Train Loss: 0.309700608253479
[32m[0514 05:32:06 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.3163003921508789, Train Loss: 0.3096957206726074
[32m[0514 05:32:06 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.3163062334060669, Train Loss: 0.3096908628940582
[32m[0514 05:32:06 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.31631216406822205, Train Loss: 0.30968600511550903
[32m[0514 05:32:06 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.31631797552108765, Train Loss: 0.30968114733695984
[32m[0514 05:32:06 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.316323846578598, Train Loss: 0.30967628955841064
[32m[0514 05:32:06 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.3163296580314636, Train Loss: 0.30967143177986145
[32m[0514 05:32:06 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.316335529088974, Train Loss: 0.30966660380363464
[32m[0514 05:32:06 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.3163413107395172, Train Loss: 0.30966174602508545
[32m[0514 05:32:07 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.3163471221923828, Train Loss: 0.30965688824653625
[32m[0514 05:32:07 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.3163529336452484, Train Loss: 0.30965206027030945
[32m[0514 05:32:07 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.31635868549346924, Train Loss: 0.30964726209640503
[32m[0514 05:32:07 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.3163645267486572, Train Loss: 0.3096424341201782
[32m[0514 05:32:07 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.31637024879455566, Train Loss: 0.30963757634162903
[32m[0514 05:32:07 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.3163760006427765, Train Loss: 0.3096327483654022
[32m[0514 05:32:07 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.3163817226886749, Train Loss: 0.309627890586853
[32m[0514 05:32:07 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.31638747453689575, Train Loss: 0.3096230626106262
[32m[0514 05:32:07 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.3163931965827942, Train Loss: 0.3096182644367218
[32m[0514 05:32:07 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.31639888882637024, Train Loss: 0.309613436460495
[32m[0514 05:32:07 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.3164045810699463, Train Loss: 0.3096086382865906
[32m[0514 05:32:07 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.31641024351119995, Train Loss: 0.30960381031036377
[32m[0514 05:32:07 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.316415935754776, Train Loss: 0.30959901213645935
[32m[0514 05:32:08 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.3164215683937073, Train Loss: 0.30959418416023254
[32m[0514 05:32:08 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.31642723083496094, Train Loss: 0.3095893859863281
[32m[0514 05:32:08 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.3164328634738922, Train Loss: 0.3095846176147461
[32m[0514 05:32:08 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.3164385259151459, Train Loss: 0.3095797896385193
[32m[0514 05:32:08 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.31644415855407715, Train Loss: 0.30957499146461487
[32m[0514 05:32:08 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.31644976139068604, Train Loss: 0.30957022309303284
[32m[0514 05:32:08 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.3164553940296173, Train Loss: 0.3095654249191284
[32m[0514 05:32:08 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.3164609670639038, Train Loss: 0.309560626745224
[32m[0514 05:32:08 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.3164665400981903, Train Loss: 0.30955588817596436
[32m[0514 05:32:08 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.3164721429347992, Train Loss: 0.30955103039741516
[32m[0514 05:32:08 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.3164777159690857, Train Loss: 0.30954623222351074
[32m[0514 05:32:08 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.3164832293987274, Train Loss: 0.3095415234565735
[32m[0514 05:32:09 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.3164888620376587, Train Loss: 0.30953672528266907
[32m[0514 05:32:09 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.3164943754673004, Train Loss: 0.30953195691108704
[32m[0514 05:32:09 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.31649985909461975, Train Loss: 0.30952712893486023
[32m[0514 05:32:09 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.31650543212890625, Train Loss: 0.3095223903656006
[32m[0514 05:32:09 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.316510945558548, Train Loss: 0.30951762199401855
[32m[0514 05:32:09 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.3165164589881897, Train Loss: 0.3095128834247589
[32m[0514 05:32:09 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.31652194261550903, Train Loss: 0.3095081150531769
[32m[0514 05:32:09 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.31652742624282837, Train Loss: 0.30950334668159485
[32m[0514 05:32:09 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.3165329098701477, Train Loss: 0.3094985783100128
[32m[0514 05:32:09 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.31653836369514465, Train Loss: 0.30949386954307556
[32m[0514 05:32:09 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.3165438175201416, Train Loss: 0.30948910117149353
[32m[0514 05:32:09 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.31654927134513855, Train Loss: 0.3094843626022339
[32m[0514 05:32:09 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.3165547549724579, Train Loss: 0.30947962403297424
[32m[0514 05:32:10 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.31656020879745483, Train Loss: 0.3094748258590698
[32m[0514 05:32:10 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.316565603017807, Train Loss: 0.30947011709213257
[32m[0514 05:32:10 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.31657102704048157, Train Loss: 0.3094653785228729
[32m[0514 05:32:10 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.31657645106315613, Train Loss: 0.3094606399536133
[32m[0514 05:32:10 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.3165818452835083, Train Loss: 0.30945590138435364
[32m[0514 05:32:10 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.31658726930618286, Train Loss: 0.309451162815094
[32m[0514 05:32:10 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.31659266352653503, Train Loss: 0.30944645404815674
[32m[0514 05:32:10 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.3165980279445648, Train Loss: 0.3094417154788971
[32m[0514 05:32:10 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.3166033923625946, Train Loss: 0.30943700671195984
[32m[0514 05:32:10 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 05:32:10 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 05:32:10 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 05:32:10 @mbmf_main.py:227][0m batch size for trpo is 1000
[32m[0514 05:32:10 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 05:32:10 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 05:32:10 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 05:32:10 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 05:32:10 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 05:32:10 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 05:32:10 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 05:32:10 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 05:32:10 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 05:32:10 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 05:32:10 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 05:32:10 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 05:32:10 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 05:32:10 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 05:32:10 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 05:32:10 @mbmf_main.py:132][0m Training starts at /root/mbbl
[32m[0514 05:32:10 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 05:32:10 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 05:32:10 @base_worker.py:45][0m Worker 0 online
[32m[0514 05:32:10 @base_worker.py:45][0m Worker 1 online
[32m[0514 05:32:10 @base_worker.py:45][0m Worker 2 online
[32m[0514 05:32:10 @base_worker.py:45][0m Worker 3 online
[32m[0514 05:32:10 @base_worker.py:45][0m Worker 4 online
[32m[0514 05:32:10 @base_worker.py:45][0m Worker 5 online
[32m[0514 05:32:10 @base_worker.py:45][0m Worker 6 online
[32m[0514 05:32:10 @base_worker.py:45][0m Worker 7 online
[32m[0514 05:32:10 @base_worker.py:45][0m Worker 8 online
[32m[0514 05:32:10 @base_worker.py:45][0m Worker 9 online
[32m[0514 05:32:10 @base_worker.py:45][0m Worker 10 online
[32m[0514 05:32:10 @base_worker.py:45][0m Worker 11 online
[32m[0514 05:32:10 @base_worker.py:45][0m Worker 12 online
[32m[0514 05:32:10 @base_worker.py:45][0m Worker 13 online
[32m[0514 05:32:10 @base_worker.py:45][0m Worker 14 online
[32m[0514 05:32:10 @base_worker.py:45][0m Worker 15 online
[32m[0514 05:32:10 @base_worker.py:45][0m Worker 16 online
[32m[0514 05:32:10 @base_worker.py:45][0m Worker 17 online
[32m[0514 05:32:10 @base_worker.py:45][0m Worker 18 online
[32m[0514 05:32:10 @base_worker.py:45][0m Worker 19 online
[32m[0514 05:32:12 @base_trainer.py:152][0m Trainer maintains [1] policy network
[32m[0514 05:32:12 @base_trainer.py:152][0m Trainer maintains [1] dynamics network
[32m[0514 05:32:12 @base_trainer.py:152][0m Trainer maintains [1] reward network
[32m[0514 05:32:13 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:32:13 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:32:13 @base_trainer.py:216][0m Mean reward: -488.7166240458766
[32m[0514 05:32:14 @base_main.py:38][0m --------------- Iteration 1 ---------------
[32m[0514 05:32:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0000 mins
[32m[0514 05:32:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0075 mins
[32m[0514 05:32:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0242 mins
[32m[0514 05:32:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:32:14 @base_main.py:47][0m 1005 total steps have happened
[32m[0514 05:32:14 @base_main.py:52][0m [avg_reward]: -488.7166240458766
[32m[0514 05:32:14 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:32:14 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:32:14 @base_trainer.py:216][0m Mean reward: -519.2368777099981
[32m[0514 05:32:15 @base_main.py:38][0m --------------- Iteration 2 ---------------
[32m[0514 05:32:15 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0320 mins
[32m[0514 05:32:15 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0080 mins
[32m[0514 05:32:15 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0154 mins
[32m[0514 05:32:15 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:32:15 @base_main.py:47][0m 2010 total steps have happened
[32m[0514 05:32:15 @base_main.py:52][0m [avg_reward]: -519.2368777099981
[32m[0514 05:32:16 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:32:16 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:32:16 @base_trainer.py:216][0m Mean reward: -412.5161095290865
[32m[0514 05:32:17 @base_main.py:38][0m --------------- Iteration 3 ---------------
[32m[0514 05:32:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0558 mins
[32m[0514 05:32:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0081 mins
[32m[0514 05:32:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0147 mins
[32m[0514 05:32:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:32:17 @base_main.py:47][0m 3015 total steps have happened
[32m[0514 05:32:17 @base_main.py:52][0m [avg_reward]: -412.5161095290865
[32m[0514 05:32:17 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:32:17 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:32:17 @base_trainer.py:216][0m Mean reward: -261.67726108909784
[32m[0514 05:32:18 @base_main.py:38][0m --------------- Iteration 4 ---------------
[32m[0514 05:32:18 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0786 mins
[32m[0514 05:32:18 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0075 mins
[32m[0514 05:32:18 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0149 mins
[32m[0514 05:32:18 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:32:18 @base_main.py:47][0m 4020 total steps have happened
[32m[0514 05:32:18 @base_main.py:52][0m [avg_reward]: -261.67726108909784
[32m[0514 05:32:19 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:32:19 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:32:19 @base_trainer.py:216][0m Mean reward: -258.34356220269115
[32m[0514 05:32:20 @base_main.py:38][0m --------------- Iteration 5 ---------------
[32m[0514 05:32:20 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1011 mins
[32m[0514 05:32:20 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0078 mins
[32m[0514 05:32:20 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0149 mins
[32m[0514 05:32:20 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 05:32:20 @base_main.py:47][0m 5025 total steps have happened
[32m[0514 05:32:20 @base_main.py:52][0m [avg_reward]: -258.34356220269115
[32m[0514 05:32:20 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:32:20 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:32:20 @base_trainer.py:216][0m Mean reward: -253.82275227704608
[32m[0514 05:32:21 @base_main.py:38][0m --------------- Iteration 6 ---------------
[32m[0514 05:32:21 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1242 mins
[32m[0514 05:32:21 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0066 mins
[32m[0514 05:32:21 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0145 mins
[32m[0514 05:32:21 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 05:32:21 @base_main.py:47][0m 6030 total steps have happened
[32m[0514 05:32:21 @base_main.py:52][0m [avg_reward]: -253.82275227704608
[32m[0514 05:32:21 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:32:21 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:32:21 @base_trainer.py:216][0m Mean reward: -264.7890041403448
[32m[0514 05:32:22 @base_main.py:38][0m --------------- Iteration 7 ---------------
[32m[0514 05:32:22 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1455 mins
[32m[0514 05:32:22 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0068 mins
[32m[0514 05:32:22 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0140 mins
[32m[0514 05:32:22 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:32:22 @base_main.py:47][0m 7035 total steps have happened
[32m[0514 05:32:22 @base_main.py:52][0m [avg_reward]: -264.7890041403448
[32m[0514 05:32:22 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:32:22 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:32:22 @base_trainer.py:216][0m Mean reward: -215.87654815965834
[32m[0514 05:32:23 @base_main.py:38][0m --------------- Iteration 8 ---------------
[32m[0514 05:32:23 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1666 mins
[32m[0514 05:32:23 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0053 mins
[32m[0514 05:32:23 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0146 mins
[32m[0514 05:32:23 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:32:23 @base_main.py:47][0m 8040 total steps have happened
[32m[0514 05:32:23 @base_main.py:52][0m [avg_reward]: -215.87654815965834
[32m[0514 05:32:24 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:32:24 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:32:24 @base_trainer.py:216][0m Mean reward: -242.210661118075
[32m[0514 05:32:25 @base_main.py:38][0m --------------- Iteration 9 ---------------
[32m[0514 05:32:25 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1868 mins
[32m[0514 05:32:25 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0054 mins
[32m[0514 05:32:25 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0147 mins
[32m[0514 05:32:25 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 05:32:25 @base_main.py:47][0m 9045 total steps have happened
[32m[0514 05:32:25 @base_main.py:52][0m [avg_reward]: -242.210661118075
[32m[0514 05:32:25 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:32:25 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:32:25 @base_trainer.py:216][0m Mean reward: -187.77833287056177
[32m[0514 05:32:26 @base_main.py:38][0m --------------- Iteration 10 ---------------
[32m[0514 05:32:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2071 mins
[32m[0514 05:32:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0056 mins
[32m[0514 05:32:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0152 mins
[32m[0514 05:32:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 05:32:26 @base_main.py:47][0m 10050 total steps have happened
[32m[0514 05:32:26 @base_main.py:52][0m [avg_reward]: -187.77833287056177
[32m[0514 05:32:26 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:32:26 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:32:26 @base_trainer.py:216][0m Mean reward: -164.5294651209158
[32m[0514 05:32:27 @base_main.py:38][0m --------------- Iteration 11 ---------------
[32m[0514 05:32:27 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2283 mins
[32m[0514 05:32:27 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0054 mins
[32m[0514 05:32:27 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0159 mins
[32m[0514 05:32:27 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 05:32:27 @base_main.py:47][0m 11055 total steps have happened
[32m[0514 05:32:27 @base_main.py:52][0m [avg_reward]: -164.5294651209158
[32m[0514 05:32:27 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:32:27 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:32:27 @base_trainer.py:216][0m Mean reward: -201.23688707420848
[32m[0514 05:32:28 @base_main.py:38][0m --------------- Iteration 12 ---------------
[32m[0514 05:32:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2498 mins
[32m[0514 05:32:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0061 mins
[32m[0514 05:32:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0147 mins
[32m[0514 05:32:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 05:32:28 @base_main.py:47][0m 12060 total steps have happened
[32m[0514 05:32:28 @base_main.py:52][0m [avg_reward]: -201.23688707420848
[32m[0514 05:32:29 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:32:29 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:32:29 @base_trainer.py:216][0m Mean reward: -212.34014716978294
[32m[0514 05:32:30 @base_main.py:38][0m --------------- Iteration 13 ---------------
[32m[0514 05:32:30 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2709 mins
[32m[0514 05:32:30 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0056 mins
[32m[0514 05:32:30 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0153 mins
[32m[0514 05:32:30 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:32:30 @base_main.py:47][0m 13065 total steps have happened
[32m[0514 05:32:30 @base_main.py:52][0m [avg_reward]: -212.34014716978294
[32m[0514 05:32:30 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:32:30 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:32:30 @base_trainer.py:216][0m Mean reward: -141.71075273449785
[32m[0514 05:32:31 @base_main.py:38][0m --------------- Iteration 14 ---------------
[32m[0514 05:32:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2920 mins
[32m[0514 05:32:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0055 mins
[32m[0514 05:32:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0153 mins
[32m[0514 05:32:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:32:31 @base_main.py:47][0m 14070 total steps have happened
[32m[0514 05:32:31 @base_main.py:52][0m [avg_reward]: -141.71075273449785
[32m[0514 05:32:31 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:32:31 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:32:31 @base_trainer.py:216][0m Mean reward: -137.23887610314017
[32m[0514 05:32:32 @base_main.py:38][0m --------------- Iteration 15 ---------------
[32m[0514 05:32:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3131 mins
[32m[0514 05:32:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0053 mins
[32m[0514 05:32:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0156 mins
[32m[0514 05:32:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:32:32 @base_main.py:47][0m 15075 total steps have happened
[32m[0514 05:32:32 @base_main.py:52][0m [avg_reward]: -137.23887610314017
[32m[0514 05:32:32 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:32:32 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:32:32 @base_trainer.py:216][0m Mean reward: -165.43041837048096
[32m[0514 05:32:33 @base_main.py:38][0m --------------- Iteration 16 ---------------
[32m[0514 05:32:33 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3343 mins
[32m[0514 05:32:33 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0057 mins
[32m[0514 05:32:33 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0154 mins
[32m[0514 05:32:33 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:32:33 @base_main.py:47][0m 16080 total steps have happened
[32m[0514 05:32:33 @base_main.py:52][0m [avg_reward]: -165.43041837048096
[32m[0514 05:32:34 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:32:34 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:32:34 @base_trainer.py:216][0m Mean reward: -189.19638841467105
[32m[0514 05:32:35 @base_main.py:38][0m --------------- Iteration 17 ---------------
[32m[0514 05:32:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3556 mins
[32m[0514 05:32:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0055 mins
[32m[0514 05:32:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0150 mins
[32m[0514 05:32:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:32:35 @base_main.py:47][0m 17085 total steps have happened
[32m[0514 05:32:35 @base_main.py:52][0m [avg_reward]: -189.19638841467105
[32m[0514 05:32:35 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:32:35 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:32:35 @base_trainer.py:216][0m Mean reward: -164.51037328241674
[32m[0514 05:32:36 @base_main.py:38][0m --------------- Iteration 18 ---------------
[32m[0514 05:32:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3764 mins
[32m[0514 05:32:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0061 mins
[32m[0514 05:32:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0157 mins
[32m[0514 05:32:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:32:36 @base_main.py:47][0m 18090 total steps have happened
[32m[0514 05:32:36 @base_main.py:52][0m [avg_reward]: -164.51037328241674
[32m[0514 05:32:36 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:32:36 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:32:36 @base_trainer.py:216][0m Mean reward: -154.52171943034176
[32m[0514 05:32:37 @base_main.py:38][0m --------------- Iteration 19 ---------------
[32m[0514 05:32:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3985 mins
[32m[0514 05:32:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0063 mins
[32m[0514 05:32:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0146 mins
[32m[0514 05:32:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:32:37 @base_main.py:47][0m 19095 total steps have happened
[32m[0514 05:32:37 @base_main.py:52][0m [avg_reward]: -154.52171943034176
[32m[0514 05:32:38 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:32:38 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:32:38 @base_trainer.py:216][0m Mean reward: -148.3723953634961
[32m[0514 05:32:38 @base_main.py:38][0m --------------- Iteration 20 ---------------
[32m[0514 05:32:38 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4198 mins
[32m[0514 05:32:38 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0057 mins
[32m[0514 05:32:38 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0143 mins
[32m[0514 05:32:38 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:32:38 @base_main.py:47][0m 20100 total steps have happened
[32m[0514 05:32:38 @base_main.py:52][0m [avg_reward]: -148.3723953634961
[32m[0514 05:32:39 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:32:39 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:32:39 @base_trainer.py:216][0m Mean reward: -187.50976348756726
[32m[0514 05:32:40 @base_main.py:38][0m --------------- Iteration 21 ---------------
[32m[0514 05:32:40 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4399 mins
[32m[0514 05:32:40 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0061 mins
[32m[0514 05:32:40 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0145 mins
[32m[0514 05:32:40 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 05:32:40 @base_main.py:47][0m 21105 total steps have happened
[32m[0514 05:32:40 @base_main.py:52][0m [avg_reward]: -187.50976348756726
[32m[0514 05:32:40 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:32:40 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:32:40 @base_trainer.py:216][0m Mean reward: -200.88228505971716
[32m[0514 05:32:41 @base_main.py:38][0m --------------- Iteration 22 ---------------
[32m[0514 05:32:41 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4608 mins
[32m[0514 05:32:41 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0061 mins
[32m[0514 05:32:41 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0154 mins
[32m[0514 05:32:41 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:32:41 @base_main.py:47][0m 22110 total steps have happened
[32m[0514 05:32:41 @base_main.py:52][0m [avg_reward]: -200.88228505971716
[32m[0514 05:32:41 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:32:41 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:32:41 @base_trainer.py:216][0m Mean reward: -175.2618029698909
[32m[0514 05:32:42 @base_main.py:38][0m --------------- Iteration 23 ---------------
[32m[0514 05:32:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4825 mins
[32m[0514 05:32:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0058 mins
[32m[0514 05:32:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0149 mins
[32m[0514 05:32:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:32:42 @base_main.py:47][0m 23115 total steps have happened
[32m[0514 05:32:42 @base_main.py:52][0m [avg_reward]: -175.2618029698909
[32m[0514 05:32:43 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:32:43 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:32:43 @base_trainer.py:216][0m Mean reward: -158.40160151098507
[32m[0514 05:32:43 @base_main.py:38][0m --------------- Iteration 24 ---------------
[32m[0514 05:32:43 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5035 mins
[32m[0514 05:32:43 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0057 mins
[32m[0514 05:32:43 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0140 mins
[32m[0514 05:32:43 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 05:32:43 @base_main.py:47][0m 24120 total steps have happened
[32m[0514 05:32:43 @base_main.py:52][0m [avg_reward]: -158.40160151098507
[32m[0514 05:32:44 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:32:44 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:32:44 @base_trainer.py:216][0m Mean reward: -162.21558810371488
[32m[0514 05:32:45 @base_main.py:38][0m --------------- Iteration 25 ---------------
[32m[0514 05:32:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5236 mins
[32m[0514 05:32:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0051 mins
[32m[0514 05:32:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0145 mins
[32m[0514 05:32:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:32:45 @base_main.py:47][0m 25125 total steps have happened
[32m[0514 05:32:45 @base_main.py:52][0m [avg_reward]: -162.21558810371488
[32m[0514 05:32:45 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:32:45 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:32:45 @base_trainer.py:216][0m Mean reward: -155.642254474895
[32m[0514 05:32:46 @base_main.py:38][0m --------------- Iteration 26 ---------------
[32m[0514 05:32:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5435 mins
[32m[0514 05:32:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0058 mins
[32m[0514 05:32:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0139 mins
[32m[0514 05:32:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 05:32:46 @base_main.py:47][0m 26130 total steps have happened
[32m[0514 05:32:46 @base_main.py:52][0m [avg_reward]: -155.642254474895
[32m[0514 05:32:46 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:32:46 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:32:46 @base_trainer.py:216][0m Mean reward: -164.6430520065515
[32m[0514 05:32:47 @base_main.py:38][0m --------------- Iteration 27 ---------------
[32m[0514 05:32:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5634 mins
[32m[0514 05:32:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0056 mins
[32m[0514 05:32:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0134 mins
[32m[0514 05:32:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0004 mins
[32m[0514 05:32:47 @base_main.py:47][0m 27135 total steps have happened
[32m[0514 05:32:47 @base_main.py:52][0m [avg_reward]: -164.6430520065515
[32m[0514 05:32:47 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:32:47 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:32:47 @base_trainer.py:216][0m Mean reward: -161.0323885668261
[32m[0514 05:32:48 @base_main.py:38][0m --------------- Iteration 28 ---------------
[32m[0514 05:32:48 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5829 mins
[32m[0514 05:32:48 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0053 mins
[32m[0514 05:32:48 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0154 mins
[32m[0514 05:32:48 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 05:32:48 @base_main.py:47][0m 28140 total steps have happened
[32m[0514 05:32:48 @base_main.py:52][0m [avg_reward]: -161.0323885668261
[32m[0514 05:32:49 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:32:49 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:32:49 @base_trainer.py:216][0m Mean reward: -159.69164654678985
[32m[0514 05:32:49 @base_main.py:38][0m --------------- Iteration 29 ---------------
[32m[0514 05:32:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6039 mins
[32m[0514 05:32:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0058 mins
[32m[0514 05:32:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0139 mins
[32m[0514 05:32:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:32:49 @base_main.py:47][0m 29145 total steps have happened
[32m[0514 05:32:49 @base_main.py:52][0m [avg_reward]: -159.69164654678985
[32m[0514 05:32:50 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:32:50 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:32:50 @base_trainer.py:216][0m Mean reward: -158.62822904186052
[32m[0514 05:32:51 @base_main.py:38][0m --------------- Iteration 30 ---------------
[32m[0514 05:32:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6237 mins
[32m[0514 05:32:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0063 mins
[32m[0514 05:32:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0135 mins
[32m[0514 05:32:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 05:32:51 @base_main.py:47][0m 30150 total steps have happened
[32m[0514 05:32:51 @base_main.py:52][0m [avg_reward]: -158.62822904186052
[32m[0514 05:32:51 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:32:51 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:32:51 @base_trainer.py:216][0m Mean reward: -155.11690651548616
[32m[0514 05:32:52 @base_main.py:38][0m --------------- Iteration 31 ---------------
[32m[0514 05:32:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6438 mins
[32m[0514 05:32:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0060 mins
[32m[0514 05:32:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0132 mins
[32m[0514 05:32:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:32:52 @base_main.py:47][0m 31155 total steps have happened
[32m[0514 05:32:52 @base_main.py:52][0m [avg_reward]: -155.11690651548616
[32m[0514 05:32:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:32:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:32:52 @base_trainer.py:216][0m Mean reward: -140.59453028157506
[32m[0514 05:32:53 @base_main.py:38][0m --------------- Iteration 32 ---------------
[32m[0514 05:32:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6632 mins
[32m[0514 05:32:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0054 mins
[32m[0514 05:32:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0137 mins
[32m[0514 05:32:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:32:53 @base_main.py:47][0m 32160 total steps have happened
[32m[0514 05:32:53 @base_main.py:52][0m [avg_reward]: -140.59453028157506
[32m[0514 05:32:53 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:32:53 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:32:53 @base_trainer.py:216][0m Mean reward: -151.36436317419506
[32m[0514 05:32:54 @base_main.py:38][0m --------------- Iteration 33 ---------------
[32m[0514 05:32:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6824 mins
[32m[0514 05:32:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0060 mins
[32m[0514 05:32:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0145 mins
[32m[0514 05:32:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:32:54 @base_main.py:47][0m 33165 total steps have happened
[32m[0514 05:32:54 @base_main.py:52][0m [avg_reward]: -151.36436317419506
[32m[0514 05:32:55 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:32:55 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:32:55 @base_trainer.py:216][0m Mean reward: -137.1539848865727
[32m[0514 05:32:55 @base_main.py:38][0m --------------- Iteration 34 ---------------
[32m[0514 05:32:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7032 mins
[32m[0514 05:32:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0053 mins
[32m[0514 05:32:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0145 mins
[32m[0514 05:32:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:32:55 @base_main.py:47][0m 34170 total steps have happened
[32m[0514 05:32:55 @base_main.py:52][0m [avg_reward]: -137.1539848865727
[32m[0514 05:32:56 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:32:56 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:32:56 @base_trainer.py:216][0m Mean reward: -147.59891824388316
[32m[0514 05:32:57 @base_main.py:38][0m --------------- Iteration 35 ---------------
[32m[0514 05:32:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7231 mins
[32m[0514 05:32:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0059 mins
[32m[0514 05:32:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0142 mins
[32m[0514 05:32:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0005 mins
[32m[0514 05:32:57 @base_main.py:47][0m 35175 total steps have happened
[32m[0514 05:32:57 @base_main.py:52][0m [avg_reward]: -147.59891824388316
[32m[0514 05:32:57 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:32:57 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:32:57 @base_trainer.py:216][0m Mean reward: -152.42573664251242
[32m[0514 05:32:58 @base_main.py:38][0m --------------- Iteration 36 ---------------
[32m[0514 05:32:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7437 mins
[32m[0514 05:32:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0057 mins
[32m[0514 05:32:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0138 mins
[32m[0514 05:32:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:32:58 @base_main.py:47][0m 36180 total steps have happened
[32m[0514 05:32:58 @base_main.py:52][0m [avg_reward]: -152.42573664251242
[32m[0514 05:32:58 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:32:58 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:32:58 @base_trainer.py:216][0m Mean reward: -133.76324295403862
[32m[0514 05:32:59 @base_main.py:38][0m --------------- Iteration 37 ---------------
[32m[0514 05:32:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7634 mins
[32m[0514 05:32:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0048 mins
[32m[0514 05:32:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0142 mins
[32m[0514 05:32:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 05:32:59 @base_main.py:47][0m 37185 total steps have happened
[32m[0514 05:32:59 @base_main.py:52][0m [avg_reward]: -133.76324295403862
[32m[0514 05:32:59 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:32:59 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:32:59 @base_trainer.py:216][0m Mean reward: -127.8357829787642
[32m[0514 05:33:00 @base_main.py:38][0m --------------- Iteration 38 ---------------
[32m[0514 05:33:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7828 mins
[32m[0514 05:33:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0059 mins
[32m[0514 05:33:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0141 mins
[32m[0514 05:33:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:33:00 @base_main.py:47][0m 38190 total steps have happened
[32m[0514 05:33:00 @base_main.py:52][0m [avg_reward]: -127.8357829787642
[32m[0514 05:33:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:01 @base_trainer.py:216][0m Mean reward: -146.8638774347093
[32m[0514 05:33:01 @base_main.py:38][0m --------------- Iteration 39 ---------------
[32m[0514 05:33:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8030 mins
[32m[0514 05:33:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0048 mins
[32m[0514 05:33:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0138 mins
[32m[0514 05:33:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:01 @base_main.py:47][0m 39195 total steps have happened
[32m[0514 05:33:01 @base_main.py:52][0m [avg_reward]: -146.8638774347093
[32m[0514 05:33:02 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:02 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:02 @base_trainer.py:216][0m Mean reward: -138.22120689286612
[32m[0514 05:33:03 @base_main.py:38][0m --------------- Iteration 40 ---------------
[32m[0514 05:33:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8218 mins
[32m[0514 05:33:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0054 mins
[32m[0514 05:33:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0133 mins
[32m[0514 05:33:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:33:03 @base_main.py:47][0m 40200 total steps have happened
[32m[0514 05:33:03 @base_main.py:52][0m [avg_reward]: -138.22120689286612
[32m[0514 05:33:03 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:03 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:03 @base_trainer.py:216][0m Mean reward: -130.2291057145423
[32m[0514 05:33:04 @base_main.py:38][0m --------------- Iteration 41 ---------------
[32m[0514 05:33:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8407 mins
[32m[0514 05:33:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0050 mins
[32m[0514 05:33:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0141 mins
[32m[0514 05:33:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 05:33:04 @base_main.py:47][0m 41205 total steps have happened
[32m[0514 05:33:04 @base_main.py:52][0m [avg_reward]: -130.2291057145423
[32m[0514 05:33:04 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:04 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:04 @base_trainer.py:216][0m Mean reward: -121.2458292037611
[32m[0514 05:33:05 @base_main.py:38][0m --------------- Iteration 42 ---------------
[32m[0514 05:33:05 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8601 mins
[32m[0514 05:33:05 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0058 mins
[32m[0514 05:33:05 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0137 mins
[32m[0514 05:33:05 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0004 mins
[32m[0514 05:33:05 @base_main.py:47][0m 42210 total steps have happened
[32m[0514 05:33:05 @base_main.py:52][0m [avg_reward]: -121.2458292037611
[32m[0514 05:33:05 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:05 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:05 @base_trainer.py:216][0m Mean reward: -99.09394591465573
[32m[0514 05:33:06 @base_main.py:38][0m --------------- Iteration 43 ---------------
[32m[0514 05:33:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8800 mins
[32m[0514 05:33:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0056 mins
[32m[0514 05:33:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0135 mins
[32m[0514 05:33:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:33:06 @base_main.py:47][0m 43215 total steps have happened
[32m[0514 05:33:06 @base_main.py:52][0m [avg_reward]: -99.09394591465573
[32m[0514 05:33:06 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:06 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:06 @base_trainer.py:216][0m Mean reward: -88.57144024529087
[32m[0514 05:33:07 @base_main.py:38][0m --------------- Iteration 44 ---------------
[32m[0514 05:33:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8994 mins
[32m[0514 05:33:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0055 mins
[32m[0514 05:33:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0139 mins
[32m[0514 05:33:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:07 @base_main.py:47][0m 44220 total steps have happened
[32m[0514 05:33:07 @base_main.py:52][0m [avg_reward]: -88.57144024529087
[32m[0514 05:33:08 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:08 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:08 @base_trainer.py:216][0m Mean reward: -109.61896079640835
[32m[0514 05:33:08 @base_main.py:38][0m --------------- Iteration 45 ---------------
[32m[0514 05:33:08 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9191 mins
[32m[0514 05:33:08 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0061 mins
[32m[0514 05:33:08 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0141 mins
[32m[0514 05:33:08 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:33:08 @base_main.py:47][0m 45225 total steps have happened
[32m[0514 05:33:08 @base_main.py:52][0m [avg_reward]: -109.61896079640835
[32m[0514 05:33:09 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:09 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:09 @base_trainer.py:216][0m Mean reward: -97.4346370271704
[32m[0514 05:33:10 @base_main.py:38][0m --------------- Iteration 46 ---------------
[32m[0514 05:33:10 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9395 mins
[32m[0514 05:33:10 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0054 mins
[32m[0514 05:33:10 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0134 mins
[32m[0514 05:33:10 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:33:10 @base_main.py:47][0m 46230 total steps have happened
[32m[0514 05:33:10 @base_main.py:52][0m [avg_reward]: -97.4346370271704
[32m[0514 05:33:10 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:10 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:10 @base_trainer.py:216][0m Mean reward: -85.93412972453288
[32m[0514 05:33:10 @base_main.py:38][0m --------------- Iteration 47 ---------------
[32m[0514 05:33:10 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9585 mins
[32m[0514 05:33:10 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 05:33:10 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0514 05:33:10 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:33:10 @base_main.py:47][0m 47235 total steps have happened
[32m[0514 05:33:10 @base_main.py:52][0m [avg_reward]: -85.93412972453288
[32m[0514 05:33:11 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:11 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:11 @base_trainer.py:216][0m Mean reward: -65.6608201131003
[32m[0514 05:33:11 @base_main.py:38][0m --------------- Iteration 48 ---------------
[32m[0514 05:33:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9714 mins
[32m[0514 05:33:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0033 mins
[32m[0514 05:33:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 05:33:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:11 @base_main.py:47][0m 48240 total steps have happened
[32m[0514 05:33:11 @base_main.py:52][0m [avg_reward]: -65.6608201131003
[32m[0514 05:33:11 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:11 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:11 @base_trainer.py:216][0m Mean reward: -54.64925098654
[32m[0514 05:33:12 @base_main.py:38][0m --------------- Iteration 49 ---------------
[32m[0514 05:33:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9840 mins
[32m[0514 05:33:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 05:33:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0514 05:33:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:33:12 @base_main.py:47][0m 49245 total steps have happened
[32m[0514 05:33:12 @base_main.py:52][0m [avg_reward]: -54.64925098654
[32m[0514 05:33:12 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:12 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:12 @base_trainer.py:216][0m Mean reward: -53.662067009614226
[32m[0514 05:33:13 @base_main.py:38][0m --------------- Iteration 50 ---------------
[32m[0514 05:33:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9968 mins
[32m[0514 05:33:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0514 05:33:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0514 05:33:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:13 @base_main.py:47][0m 50250 total steps have happened
[32m[0514 05:33:13 @base_main.py:52][0m [avg_reward]: -53.662067009614226
[32m[0514 05:33:13 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:13 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:13 @base_trainer.py:216][0m Mean reward: -54.37558588019093
[32m[0514 05:33:13 @base_main.py:38][0m --------------- Iteration 51 ---------------
[32m[0514 05:33:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0100 mins
[32m[0514 05:33:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0514 05:33:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0514 05:33:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:13 @base_main.py:47][0m 51255 total steps have happened
[32m[0514 05:33:13 @base_main.py:52][0m [avg_reward]: -54.37558588019093
[32m[0514 05:33:14 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:14 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:14 @base_trainer.py:216][0m Mean reward: -46.48807275749233
[32m[0514 05:33:14 @base_main.py:38][0m --------------- Iteration 52 ---------------
[32m[0514 05:33:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0230 mins
[32m[0514 05:33:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0514 05:33:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0514 05:33:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:33:14 @base_main.py:47][0m 52260 total steps have happened
[32m[0514 05:33:14 @base_main.py:52][0m [avg_reward]: -46.48807275749233
[32m[0514 05:33:14 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:14 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:14 @base_trainer.py:216][0m Mean reward: -50.17265463636958
[32m[0514 05:33:15 @base_main.py:38][0m --------------- Iteration 53 ---------------
[32m[0514 05:33:15 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0364 mins
[32m[0514 05:33:15 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 05:33:15 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 05:33:15 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:33:15 @base_main.py:47][0m 53265 total steps have happened
[32m[0514 05:33:15 @base_main.py:52][0m [avg_reward]: -50.17265463636958
[32m[0514 05:33:15 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:15 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:15 @base_trainer.py:216][0m Mean reward: -49.537088646162495
[32m[0514 05:33:16 @base_main.py:38][0m --------------- Iteration 54 ---------------
[32m[0514 05:33:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0485 mins
[32m[0514 05:33:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 05:33:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0514 05:33:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:16 @base_main.py:47][0m 54270 total steps have happened
[32m[0514 05:33:16 @base_main.py:52][0m [avg_reward]: -49.537088646162495
[32m[0514 05:33:16 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:16 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:16 @base_trainer.py:216][0m Mean reward: -49.13700441361775
[32m[0514 05:33:17 @base_main.py:38][0m --------------- Iteration 55 ---------------
[32m[0514 05:33:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0613 mins
[32m[0514 05:33:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 05:33:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0514 05:33:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:33:17 @base_main.py:47][0m 55275 total steps have happened
[32m[0514 05:33:17 @base_main.py:52][0m [avg_reward]: -49.13700441361775
[32m[0514 05:33:17 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:17 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:17 @base_trainer.py:216][0m Mean reward: -42.86633333632483
[32m[0514 05:33:17 @base_main.py:38][0m --------------- Iteration 56 ---------------
[32m[0514 05:33:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0741 mins
[32m[0514 05:33:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 05:33:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0514 05:33:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:33:17 @base_main.py:47][0m 56280 total steps have happened
[32m[0514 05:33:17 @base_main.py:52][0m [avg_reward]: -42.86633333632483
[32m[0514 05:33:17 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:17 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:17 @base_trainer.py:216][0m Mean reward: -43.53092482059753
[32m[0514 05:33:18 @base_main.py:38][0m --------------- Iteration 57 ---------------
[32m[0514 05:33:18 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0867 mins
[32m[0514 05:33:18 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0033 mins
[32m[0514 05:33:18 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0514 05:33:18 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:18 @base_main.py:47][0m 57285 total steps have happened
[32m[0514 05:33:18 @base_main.py:52][0m [avg_reward]: -43.53092482059753
[32m[0514 05:33:18 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:18 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:18 @base_trainer.py:216][0m Mean reward: -43.77016963816914
[32m[0514 05:33:19 @base_main.py:38][0m --------------- Iteration 58 ---------------
[32m[0514 05:33:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0999 mins
[32m[0514 05:33:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 05:33:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0514 05:33:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:33:19 @base_main.py:47][0m 58290 total steps have happened
[32m[0514 05:33:19 @base_main.py:52][0m [avg_reward]: -43.77016963816914
[32m[0514 05:33:19 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:19 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:19 @base_trainer.py:216][0m Mean reward: -45.13468975987123
[32m[0514 05:33:20 @base_main.py:38][0m --------------- Iteration 59 ---------------
[32m[0514 05:33:20 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1130 mins
[32m[0514 05:33:20 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 05:33:20 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0514 05:33:20 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:33:20 @base_main.py:47][0m 59295 total steps have happened
[32m[0514 05:33:20 @base_main.py:52][0m [avg_reward]: -45.13468975987123
[32m[0514 05:33:20 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:20 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:20 @base_trainer.py:216][0m Mean reward: -41.97515446699786
[32m[0514 05:33:20 @base_main.py:38][0m --------------- Iteration 60 ---------------
[32m[0514 05:33:20 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1260 mins
[32m[0514 05:33:20 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 05:33:20 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0514 05:33:20 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:20 @base_main.py:47][0m 60300 total steps have happened
[32m[0514 05:33:20 @base_main.py:52][0m [avg_reward]: -41.97515446699786
[32m[0514 05:33:21 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:21 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:21 @base_trainer.py:216][0m Mean reward: -38.01943666670644
[32m[0514 05:33:21 @base_main.py:38][0m --------------- Iteration 61 ---------------
[32m[0514 05:33:21 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1385 mins
[32m[0514 05:33:21 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0514 05:33:21 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 05:33:21 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:21 @base_main.py:47][0m 61305 total steps have happened
[32m[0514 05:33:21 @base_main.py:52][0m [avg_reward]: -38.01943666670644
[32m[0514 05:33:21 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:21 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:21 @base_trainer.py:216][0m Mean reward: -39.60865446722658
[32m[0514 05:33:22 @base_main.py:38][0m --------------- Iteration 62 ---------------
[32m[0514 05:33:22 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1509 mins
[32m[0514 05:33:22 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0032 mins
[32m[0514 05:33:22 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0514 05:33:22 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:22 @base_main.py:47][0m 62310 total steps have happened
[32m[0514 05:33:22 @base_main.py:52][0m [avg_reward]: -39.60865446722658
[32m[0514 05:33:22 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:22 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:22 @base_trainer.py:216][0m Mean reward: -40.28407211886766
[32m[0514 05:33:23 @base_main.py:38][0m --------------- Iteration 63 ---------------
[32m[0514 05:33:23 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1636 mins
[32m[0514 05:33:23 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0032 mins
[32m[0514 05:33:23 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0514 05:33:23 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:23 @base_main.py:47][0m 63315 total steps have happened
[32m[0514 05:33:23 @base_main.py:52][0m [avg_reward]: -40.28407211886766
[32m[0514 05:33:23 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:23 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:23 @base_trainer.py:216][0m Mean reward: -47.79127302984437
[32m[0514 05:33:23 @base_main.py:38][0m --------------- Iteration 64 ---------------
[32m[0514 05:33:23 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1773 mins
[32m[0514 05:33:23 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0033 mins
[32m[0514 05:33:23 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 05:33:23 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:23 @base_main.py:47][0m 64320 total steps have happened
[32m[0514 05:33:23 @base_main.py:52][0m [avg_reward]: -47.79127302984437
[32m[0514 05:33:24 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:24 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:24 @base_trainer.py:216][0m Mean reward: -41.19930033998323
[32m[0514 05:33:24 @base_main.py:38][0m --------------- Iteration 65 ---------------
[32m[0514 05:33:24 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1900 mins
[32m[0514 05:33:24 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 05:33:24 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 05:33:24 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:33:24 @base_main.py:47][0m 65325 total steps have happened
[32m[0514 05:33:24 @base_main.py:52][0m [avg_reward]: -41.19930033998323
[32m[0514 05:33:24 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:24 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:24 @base_trainer.py:216][0m Mean reward: -40.07167240723026
[32m[0514 05:33:25 @base_main.py:38][0m --------------- Iteration 66 ---------------
[32m[0514 05:33:25 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2018 mins
[32m[0514 05:33:25 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 05:33:25 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0514 05:33:25 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:33:25 @base_main.py:47][0m 66330 total steps have happened
[32m[0514 05:33:25 @base_main.py:52][0m [avg_reward]: -40.07167240723026
[32m[0514 05:33:25 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:25 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:25 @base_trainer.py:216][0m Mean reward: -40.03663429389301
[32m[0514 05:33:26 @base_main.py:38][0m --------------- Iteration 67 ---------------
[32m[0514 05:33:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2141 mins
[32m[0514 05:33:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 05:33:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 05:33:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:33:26 @base_main.py:47][0m 67335 total steps have happened
[32m[0514 05:33:26 @base_main.py:52][0m [avg_reward]: -40.03663429389301
[32m[0514 05:33:26 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:26 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:26 @base_trainer.py:216][0m Mean reward: -38.421939519183574
[32m[0514 05:33:26 @base_main.py:38][0m --------------- Iteration 68 ---------------
[32m[0514 05:33:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2259 mins
[32m[0514 05:33:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 05:33:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0514 05:33:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:26 @base_main.py:47][0m 68340 total steps have happened
[32m[0514 05:33:26 @base_main.py:52][0m [avg_reward]: -38.421939519183574
[32m[0514 05:33:27 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:27 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:27 @base_trainer.py:216][0m Mean reward: -40.060433916110455
[32m[0514 05:33:27 @base_main.py:38][0m --------------- Iteration 69 ---------------
[32m[0514 05:33:27 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2376 mins
[32m[0514 05:33:27 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 05:33:27 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 05:33:27 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:33:27 @base_main.py:47][0m 69345 total steps have happened
[32m[0514 05:33:27 @base_main.py:52][0m [avg_reward]: -40.060433916110455
[32m[0514 05:33:27 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:27 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:27 @base_trainer.py:216][0m Mean reward: -43.20020620636999
[32m[0514 05:33:28 @base_main.py:38][0m --------------- Iteration 70 ---------------
[32m[0514 05:33:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2497 mins
[32m[0514 05:33:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 05:33:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 05:33:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:33:28 @base_main.py:47][0m 70350 total steps have happened
[32m[0514 05:33:28 @base_main.py:52][0m [avg_reward]: -43.20020620636999
[32m[0514 05:33:28 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:28 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:28 @base_trainer.py:216][0m Mean reward: -38.07230790093534
[32m[0514 05:33:29 @base_main.py:38][0m --------------- Iteration 71 ---------------
[32m[0514 05:33:29 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2613 mins
[32m[0514 05:33:29 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 05:33:29 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0514 05:33:29 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 05:33:29 @base_main.py:47][0m 71355 total steps have happened
[32m[0514 05:33:29 @base_main.py:52][0m [avg_reward]: -38.07230790093534
[32m[0514 05:33:29 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:29 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:29 @base_trainer.py:216][0m Mean reward: -42.01935902208752
[32m[0514 05:33:29 @base_main.py:38][0m --------------- Iteration 72 ---------------
[32m[0514 05:33:29 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2738 mins
[32m[0514 05:33:29 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 05:33:29 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0514 05:33:29 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:33:29 @base_main.py:47][0m 72360 total steps have happened
[32m[0514 05:33:29 @base_main.py:52][0m [avg_reward]: -42.01935902208752
[32m[0514 05:33:29 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:29 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:29 @base_trainer.py:216][0m Mean reward: -39.942238948207
[32m[0514 05:33:30 @base_main.py:38][0m --------------- Iteration 73 ---------------
[32m[0514 05:33:30 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2863 mins
[32m[0514 05:33:30 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0034 mins
[32m[0514 05:33:30 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0514 05:33:30 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:30 @base_main.py:47][0m 73365 total steps have happened
[32m[0514 05:33:30 @base_main.py:52][0m [avg_reward]: -39.942238948207
[32m[0514 05:33:30 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:30 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:30 @base_trainer.py:216][0m Mean reward: -39.07225688032996
[32m[0514 05:33:31 @base_main.py:38][0m --------------- Iteration 74 ---------------
[32m[0514 05:33:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2996 mins
[32m[0514 05:33:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 05:33:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 05:33:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:31 @base_main.py:47][0m 74370 total steps have happened
[32m[0514 05:33:31 @base_main.py:52][0m [avg_reward]: -39.07225688032996
[32m[0514 05:33:31 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:31 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:31 @base_trainer.py:216][0m Mean reward: -38.363431667324996
[32m[0514 05:33:31 @base_main.py:38][0m --------------- Iteration 75 ---------------
[32m[0514 05:33:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3117 mins
[32m[0514 05:33:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 05:33:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 05:33:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:33:31 @base_main.py:47][0m 75375 total steps have happened
[32m[0514 05:33:31 @base_main.py:52][0m [avg_reward]: -38.363431667324996
[32m[0514 05:33:32 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:32 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:32 @base_trainer.py:216][0m Mean reward: -38.30120674720108
[32m[0514 05:33:32 @base_main.py:38][0m --------------- Iteration 76 ---------------
[32m[0514 05:33:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3234 mins
[32m[0514 05:33:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 05:33:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0514 05:33:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:33:32 @base_main.py:47][0m 76380 total steps have happened
[32m[0514 05:33:32 @base_main.py:52][0m [avg_reward]: -38.30120674720108
[32m[0514 05:33:32 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:32 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:32 @base_trainer.py:216][0m Mean reward: -40.333846639074
[32m[0514 05:33:33 @base_main.py:38][0m --------------- Iteration 77 ---------------
[32m[0514 05:33:33 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3357 mins
[32m[0514 05:33:33 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 05:33:33 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0514 05:33:33 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:33 @base_main.py:47][0m 77385 total steps have happened
[32m[0514 05:33:33 @base_main.py:52][0m [avg_reward]: -40.333846639074
[32m[0514 05:33:33 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:33 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:33 @base_trainer.py:216][0m Mean reward: -37.47672997341648
[32m[0514 05:33:34 @base_main.py:38][0m --------------- Iteration 78 ---------------
[32m[0514 05:33:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3479 mins
[32m[0514 05:33:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 05:33:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0514 05:33:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:34 @base_main.py:47][0m 78390 total steps have happened
[32m[0514 05:33:34 @base_main.py:52][0m [avg_reward]: -37.47672997341648
[32m[0514 05:33:34 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:34 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:34 @base_trainer.py:216][0m Mean reward: -39.31963578585756
[32m[0514 05:33:34 @base_main.py:38][0m --------------- Iteration 79 ---------------
[32m[0514 05:33:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3604 mins
[32m[0514 05:33:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 05:33:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 05:33:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:34 @base_main.py:47][0m 79395 total steps have happened
[32m[0514 05:33:34 @base_main.py:52][0m [avg_reward]: -39.31963578585756
[32m[0514 05:33:35 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:35 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:35 @base_trainer.py:216][0m Mean reward: -38.0985094416949
[32m[0514 05:33:35 @base_main.py:38][0m --------------- Iteration 80 ---------------
[32m[0514 05:33:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3727 mins
[32m[0514 05:33:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 05:33:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 05:33:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:35 @base_main.py:47][0m 80400 total steps have happened
[32m[0514 05:33:35 @base_main.py:52][0m [avg_reward]: -38.0985094416949
[32m[0514 05:33:35 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:35 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:35 @base_trainer.py:216][0m Mean reward: -39.99515018826264
[32m[0514 05:33:36 @base_main.py:38][0m --------------- Iteration 81 ---------------
[32m[0514 05:33:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3846 mins
[32m[0514 05:33:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0514 05:33:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0514 05:33:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:33:36 @base_main.py:47][0m 81405 total steps have happened
[32m[0514 05:33:36 @base_main.py:52][0m [avg_reward]: -39.99515018826264
[32m[0514 05:33:36 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:36 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:36 @base_trainer.py:216][0m Mean reward: -37.88994203970161
[32m[0514 05:33:37 @base_main.py:38][0m --------------- Iteration 82 ---------------
[32m[0514 05:33:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3964 mins
[32m[0514 05:33:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 05:33:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 05:33:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:37 @base_main.py:47][0m 82410 total steps have happened
[32m[0514 05:33:37 @base_main.py:52][0m [avg_reward]: -37.88994203970161
[32m[0514 05:33:37 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:37 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:37 @base_trainer.py:216][0m Mean reward: -36.257221137120915
[32m[0514 05:33:37 @base_main.py:38][0m --------------- Iteration 83 ---------------
[32m[0514 05:33:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4082 mins
[32m[0514 05:33:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 05:33:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 05:33:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:37 @base_main.py:47][0m 83415 total steps have happened
[32m[0514 05:33:37 @base_main.py:52][0m [avg_reward]: -36.257221137120915
[32m[0514 05:33:37 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:37 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:37 @base_trainer.py:216][0m Mean reward: -36.6015819330607
[32m[0514 05:33:38 @base_main.py:38][0m --------------- Iteration 84 ---------------
[32m[0514 05:33:38 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4204 mins
[32m[0514 05:33:38 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0514 05:33:38 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 05:33:38 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:38 @base_main.py:47][0m 84420 total steps have happened
[32m[0514 05:33:38 @base_main.py:52][0m [avg_reward]: -36.6015819330607
[32m[0514 05:33:38 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:38 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:38 @base_trainer.py:216][0m Mean reward: -37.04266037892836
[32m[0514 05:33:39 @base_main.py:38][0m --------------- Iteration 85 ---------------
[32m[0514 05:33:39 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4327 mins
[32m[0514 05:33:39 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 05:33:39 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0514 05:33:39 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:33:39 @base_main.py:47][0m 85425 total steps have happened
[32m[0514 05:33:39 @base_main.py:52][0m [avg_reward]: -37.04266037892836
[32m[0514 05:33:39 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:39 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:39 @base_trainer.py:216][0m Mean reward: -37.820434853921014
[32m[0514 05:33:39 @base_main.py:38][0m --------------- Iteration 86 ---------------
[32m[0514 05:33:39 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4450 mins
[32m[0514 05:33:39 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0514 05:33:39 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0514 05:33:39 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:39 @base_main.py:47][0m 86430 total steps have happened
[32m[0514 05:33:39 @base_main.py:52][0m [avg_reward]: -37.820434853921014
[32m[0514 05:33:40 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:40 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:40 @base_trainer.py:216][0m Mean reward: -36.09366736229127
[32m[0514 05:33:40 @base_main.py:38][0m --------------- Iteration 87 ---------------
[32m[0514 05:33:40 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4568 mins
[32m[0514 05:33:40 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 05:33:40 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 05:33:40 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:40 @base_main.py:47][0m 87435 total steps have happened
[32m[0514 05:33:40 @base_main.py:52][0m [avg_reward]: -36.09366736229127
[32m[0514 05:33:40 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:40 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:40 @base_trainer.py:216][0m Mean reward: -36.16383325869452
[32m[0514 05:33:41 @base_main.py:38][0m --------------- Iteration 88 ---------------
[32m[0514 05:33:41 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4691 mins
[32m[0514 05:33:41 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 05:33:41 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 05:33:41 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:41 @base_main.py:47][0m 88440 total steps have happened
[32m[0514 05:33:41 @base_main.py:52][0m [avg_reward]: -36.16383325869452
[32m[0514 05:33:41 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:41 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:41 @base_trainer.py:216][0m Mean reward: -36.05589280418738
[32m[0514 05:33:42 @base_main.py:38][0m --------------- Iteration 89 ---------------
[32m[0514 05:33:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4811 mins
[32m[0514 05:33:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 05:33:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0514 05:33:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:42 @base_main.py:47][0m 89445 total steps have happened
[32m[0514 05:33:42 @base_main.py:52][0m [avg_reward]: -36.05589280418738
[32m[0514 05:33:42 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:42 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:42 @base_trainer.py:216][0m Mean reward: -35.388720890556854
[32m[0514 05:33:42 @base_main.py:38][0m --------------- Iteration 90 ---------------
[32m[0514 05:33:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4928 mins
[32m[0514 05:33:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 05:33:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0514 05:33:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:42 @base_main.py:47][0m 90450 total steps have happened
[32m[0514 05:33:42 @base_main.py:52][0m [avg_reward]: -35.388720890556854
[32m[0514 05:33:43 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:43 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:43 @base_trainer.py:216][0m Mean reward: -34.8162621054551
[32m[0514 05:33:43 @base_main.py:38][0m --------------- Iteration 91 ---------------
[32m[0514 05:33:43 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5052 mins
[32m[0514 05:33:43 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0032 mins
[32m[0514 05:33:43 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 05:33:43 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:43 @base_main.py:47][0m 91455 total steps have happened
[32m[0514 05:33:43 @base_main.py:52][0m [avg_reward]: -34.8162621054551
[32m[0514 05:33:43 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:43 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:43 @base_trainer.py:216][0m Mean reward: -35.341697550922085
[32m[0514 05:33:44 @base_main.py:38][0m --------------- Iteration 92 ---------------
[32m[0514 05:33:44 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5178 mins
[32m[0514 05:33:44 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 05:33:44 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 05:33:44 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:33:44 @base_main.py:47][0m 92460 total steps have happened
[32m[0514 05:33:44 @base_main.py:52][0m [avg_reward]: -35.341697550922085
[32m[0514 05:33:44 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:44 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:44 @base_trainer.py:216][0m Mean reward: -33.62474894680143
[32m[0514 05:33:45 @base_main.py:38][0m --------------- Iteration 93 ---------------
[32m[0514 05:33:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5298 mins
[32m[0514 05:33:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 05:33:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 05:33:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:45 @base_main.py:47][0m 93465 total steps have happened
[32m[0514 05:33:45 @base_main.py:52][0m [avg_reward]: -33.62474894680143
[32m[0514 05:33:45 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:45 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:45 @base_trainer.py:216][0m Mean reward: -32.37271428180132
[32m[0514 05:33:45 @base_main.py:38][0m --------------- Iteration 94 ---------------
[32m[0514 05:33:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5418 mins
[32m[0514 05:33:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0514 05:33:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 05:33:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:45 @base_main.py:47][0m 94470 total steps have happened
[32m[0514 05:33:45 @base_main.py:52][0m [avg_reward]: -32.37271428180132
[32m[0514 05:33:45 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:45 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:45 @base_trainer.py:216][0m Mean reward: -31.536900464838755
[32m[0514 05:33:46 @base_main.py:38][0m --------------- Iteration 95 ---------------
[32m[0514 05:33:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5540 mins
[32m[0514 05:33:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 05:33:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 05:33:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:46 @base_main.py:47][0m 95475 total steps have happened
[32m[0514 05:33:46 @base_main.py:52][0m [avg_reward]: -31.536900464838755
[32m[0514 05:33:46 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:46 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:46 @base_trainer.py:216][0m Mean reward: -32.14588349935866
[32m[0514 05:33:47 @base_main.py:38][0m --------------- Iteration 96 ---------------
[32m[0514 05:33:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5662 mins
[32m[0514 05:33:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 05:33:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0514 05:33:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:47 @base_main.py:47][0m 96480 total steps have happened
[32m[0514 05:33:47 @base_main.py:52][0m [avg_reward]: -32.14588349935866
[32m[0514 05:33:47 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:47 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:47 @base_trainer.py:216][0m Mean reward: -32.53343432639993
[32m[0514 05:33:48 @base_main.py:38][0m --------------- Iteration 97 ---------------
[32m[0514 05:33:48 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5785 mins
[32m[0514 05:33:48 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 05:33:48 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 05:33:48 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:48 @base_main.py:47][0m 97485 total steps have happened
[32m[0514 05:33:48 @base_main.py:52][0m [avg_reward]: -32.53343432639993
[32m[0514 05:33:48 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:48 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:48 @base_trainer.py:216][0m Mean reward: -32.58736593214756
[32m[0514 05:33:48 @base_main.py:38][0m --------------- Iteration 98 ---------------
[32m[0514 05:33:48 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5907 mins
[32m[0514 05:33:48 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 05:33:48 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 05:33:48 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:48 @base_main.py:47][0m 98490 total steps have happened
[32m[0514 05:33:48 @base_main.py:52][0m [avg_reward]: -32.58736593214756
[32m[0514 05:33:48 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:48 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:48 @base_trainer.py:216][0m Mean reward: -31.035343782420888
[32m[0514 05:33:49 @base_main.py:38][0m --------------- Iteration 99 ---------------
[32m[0514 05:33:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6026 mins
[32m[0514 05:33:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 05:33:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 05:33:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:33:49 @base_main.py:47][0m 99495 total steps have happened
[32m[0514 05:33:49 @base_main.py:52][0m [avg_reward]: -31.035343782420888
[32m[0514 05:33:49 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:49 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:49 @base_trainer.py:216][0m Mean reward: -31.06968759060772
[32m[0514 05:33:50 @base_main.py:38][0m --------------- Iteration 100 ---------------
[32m[0514 05:33:50 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6147 mins
[32m[0514 05:33:50 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 05:33:50 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 05:33:50 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:33:50 @base_main.py:47][0m 100500 total steps have happened
[32m[0514 05:33:50 @base_main.py:52][0m [avg_reward]: -31.06968759060772
[32m[0514 05:33:50 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:50 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:50 @base_trainer.py:216][0m Mean reward: -29.85064810044018
[32m[0514 05:33:50 @base_main.py:38][0m --------------- Iteration 101 ---------------
[32m[0514 05:33:50 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6267 mins
[32m[0514 05:33:50 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 05:33:50 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 05:33:50 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:50 @base_main.py:47][0m 101505 total steps have happened
[32m[0514 05:33:50 @base_main.py:52][0m [avg_reward]: -29.85064810044018
[32m[0514 05:33:51 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:51 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:51 @base_trainer.py:216][0m Mean reward: -31.358791161134224
[32m[0514 05:33:51 @base_main.py:38][0m --------------- Iteration 102 ---------------
[32m[0514 05:33:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6388 mins
[32m[0514 05:33:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 05:33:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 05:33:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:51 @base_main.py:47][0m 102510 total steps have happened
[32m[0514 05:33:51 @base_main.py:52][0m [avg_reward]: -31.358791161134224
[32m[0514 05:33:51 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:51 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:51 @base_trainer.py:216][0m Mean reward: -29.299476896130862
[32m[0514 05:33:52 @base_main.py:38][0m --------------- Iteration 103 ---------------
[32m[0514 05:33:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6509 mins
[32m[0514 05:33:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0032 mins
[32m[0514 05:33:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0514 05:33:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:52 @base_main.py:47][0m 103515 total steps have happened
[32m[0514 05:33:52 @base_main.py:52][0m [avg_reward]: -29.299476896130862
[32m[0514 05:33:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:52 @base_trainer.py:216][0m Mean reward: -28.511302776754718
[32m[0514 05:33:53 @base_main.py:38][0m --------------- Iteration 104 ---------------
[32m[0514 05:33:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6627 mins
[32m[0514 05:33:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0514 05:33:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 05:33:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:53 @base_main.py:47][0m 104520 total steps have happened
[32m[0514 05:33:53 @base_main.py:52][0m [avg_reward]: -28.511302776754718
[32m[0514 05:33:53 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:53 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:53 @base_trainer.py:216][0m Mean reward: -29.624895185018925
[32m[0514 05:33:53 @base_main.py:38][0m --------------- Iteration 105 ---------------
[32m[0514 05:33:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6749 mins
[32m[0514 05:33:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0033 mins
[32m[0514 05:33:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0514 05:33:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:53 @base_main.py:47][0m 105525 total steps have happened
[32m[0514 05:33:53 @base_main.py:52][0m [avg_reward]: -29.624895185018925
[32m[0514 05:33:53 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:53 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:53 @base_trainer.py:216][0m Mean reward: -28.337835887674743
[32m[0514 05:33:54 @base_main.py:38][0m --------------- Iteration 106 ---------------
[32m[0514 05:33:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6869 mins
[32m[0514 05:33:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 05:33:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 05:33:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:33:54 @base_main.py:47][0m 106530 total steps have happened
[32m[0514 05:33:54 @base_main.py:52][0m [avg_reward]: -28.337835887674743
[32m[0514 05:33:54 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:54 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:54 @base_trainer.py:216][0m Mean reward: -28.76547529638618
[32m[0514 05:33:55 @base_main.py:38][0m --------------- Iteration 107 ---------------
[32m[0514 05:33:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6991 mins
[32m[0514 05:33:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 05:33:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0514 05:33:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:33:55 @base_main.py:47][0m 107535 total steps have happened
[32m[0514 05:33:55 @base_main.py:52][0m [avg_reward]: -28.76547529638618
[32m[0514 05:33:55 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:55 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:55 @base_trainer.py:216][0m Mean reward: -29.131951163724313
[32m[0514 05:33:55 @base_main.py:38][0m --------------- Iteration 108 ---------------
[32m[0514 05:33:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7114 mins
[32m[0514 05:33:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 05:33:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 05:33:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:55 @base_main.py:47][0m 108540 total steps have happened
[32m[0514 05:33:55 @base_main.py:52][0m [avg_reward]: -29.131951163724313
[32m[0514 05:33:56 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:56 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:56 @base_trainer.py:216][0m Mean reward: -28.96369369268495
[32m[0514 05:33:56 @base_main.py:38][0m --------------- Iteration 109 ---------------
[32m[0514 05:33:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7233 mins
[32m[0514 05:33:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 05:33:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0514 05:33:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:56 @base_main.py:47][0m 109545 total steps have happened
[32m[0514 05:33:56 @base_main.py:52][0m [avg_reward]: -28.96369369268495
[32m[0514 05:33:56 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:56 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:56 @base_trainer.py:216][0m Mean reward: -28.426578385241847
[32m[0514 05:33:57 @base_main.py:38][0m --------------- Iteration 110 ---------------
[32m[0514 05:33:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7358 mins
[32m[0514 05:33:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 05:33:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 05:33:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:33:57 @base_main.py:47][0m 110550 total steps have happened
[32m[0514 05:33:57 @base_main.py:52][0m [avg_reward]: -28.426578385241847
[32m[0514 05:33:57 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:57 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:57 @base_trainer.py:216][0m Mean reward: -27.431958886345605
[32m[0514 05:33:58 @base_main.py:38][0m --------------- Iteration 111 ---------------
[32m[0514 05:33:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7476 mins
[32m[0514 05:33:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 05:33:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0514 05:33:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:58 @base_main.py:47][0m 111555 total steps have happened
[32m[0514 05:33:58 @base_main.py:52][0m [avg_reward]: -27.431958886345605
[32m[0514 05:33:58 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:58 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:58 @base_trainer.py:216][0m Mean reward: -27.48553496205296
[32m[0514 05:33:58 @base_main.py:38][0m --------------- Iteration 112 ---------------
[32m[0514 05:33:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7600 mins
[32m[0514 05:33:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 05:33:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 05:33:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:58 @base_main.py:47][0m 112560 total steps have happened
[32m[0514 05:33:58 @base_main.py:52][0m [avg_reward]: -27.48553496205296
[32m[0514 05:33:59 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:59 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:59 @base_trainer.py:216][0m Mean reward: -28.155700444831364
[32m[0514 05:33:59 @base_main.py:38][0m --------------- Iteration 113 ---------------
[32m[0514 05:33:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7720 mins
[32m[0514 05:33:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 05:33:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 05:33:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:33:59 @base_main.py:47][0m 113565 total steps have happened
[32m[0514 05:33:59 @base_main.py:52][0m [avg_reward]: -28.155700444831364
[32m[0514 05:33:59 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:33:59 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:33:59 @base_trainer.py:216][0m Mean reward: -26.731058068759673
[32m[0514 05:34:00 @base_main.py:38][0m --------------- Iteration 114 ---------------
[32m[0514 05:34:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7842 mins
[32m[0514 05:34:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0514 05:34:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 05:34:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:00 @base_main.py:47][0m 114570 total steps have happened
[32m[0514 05:34:00 @base_main.py:52][0m [avg_reward]: -26.731058068759673
[32m[0514 05:34:00 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:00 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:00 @base_trainer.py:216][0m Mean reward: -27.670851345191142
[32m[0514 05:34:01 @base_main.py:38][0m --------------- Iteration 115 ---------------
[32m[0514 05:34:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7963 mins
[32m[0514 05:34:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 05:34:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 05:34:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:01 @base_main.py:47][0m 115575 total steps have happened
[32m[0514 05:34:01 @base_main.py:52][0m [avg_reward]: -27.670851345191142
[32m[0514 05:34:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:01 @base_trainer.py:216][0m Mean reward: -28.246501437754382
[32m[0514 05:34:01 @base_main.py:38][0m --------------- Iteration 116 ---------------
[32m[0514 05:34:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8084 mins
[32m[0514 05:34:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 05:34:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 05:34:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:01 @base_main.py:47][0m 116580 total steps have happened
[32m[0514 05:34:01 @base_main.py:52][0m [avg_reward]: -28.246501437754382
[32m[0514 05:34:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:01 @base_trainer.py:216][0m Mean reward: -27.532395937859395
[32m[0514 05:34:02 @base_main.py:38][0m --------------- Iteration 117 ---------------
[32m[0514 05:34:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8205 mins
[32m[0514 05:34:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 05:34:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 05:34:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:02 @base_main.py:47][0m 117585 total steps have happened
[32m[0514 05:34:02 @base_main.py:52][0m [avg_reward]: -27.532395937859395
[32m[0514 05:34:02 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:02 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:02 @base_trainer.py:216][0m Mean reward: -26.945433023835527
[32m[0514 05:34:03 @base_main.py:38][0m --------------- Iteration 118 ---------------
[32m[0514 05:34:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8328 mins
[32m[0514 05:34:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 05:34:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 05:34:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:34:03 @base_main.py:47][0m 118590 total steps have happened
[32m[0514 05:34:03 @base_main.py:52][0m [avg_reward]: -26.945433023835527
[32m[0514 05:34:03 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:03 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:03 @base_trainer.py:216][0m Mean reward: -27.07396152014827
[32m[0514 05:34:03 @base_main.py:38][0m --------------- Iteration 119 ---------------
[32m[0514 05:34:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8447 mins
[32m[0514 05:34:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 05:34:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 05:34:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:03 @base_main.py:47][0m 119595 total steps have happened
[32m[0514 05:34:03 @base_main.py:52][0m [avg_reward]: -27.07396152014827
[32m[0514 05:34:04 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:04 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:04 @base_trainer.py:216][0m Mean reward: -27.445305510981484
[32m[0514 05:34:04 @base_main.py:38][0m --------------- Iteration 120 ---------------
[32m[0514 05:34:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8565 mins
[32m[0514 05:34:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 05:34:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 05:34:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:04 @base_main.py:47][0m 120600 total steps have happened
[32m[0514 05:34:04 @base_main.py:52][0m [avg_reward]: -27.445305510981484
[32m[0514 05:34:04 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:04 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:04 @base_trainer.py:216][0m Mean reward: -26.51210804694288
[32m[0514 05:34:05 @base_main.py:38][0m --------------- Iteration 121 ---------------
[32m[0514 05:34:05 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8685 mins
[32m[0514 05:34:05 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 05:34:05 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 05:34:05 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:05 @base_main.py:47][0m 121605 total steps have happened
[32m[0514 05:34:05 @base_main.py:52][0m [avg_reward]: -26.51210804694288
[32m[0514 05:34:05 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:05 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:05 @base_trainer.py:216][0m Mean reward: -26.896936032873715
[32m[0514 05:34:06 @base_main.py:38][0m --------------- Iteration 122 ---------------
[32m[0514 05:34:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8803 mins
[32m[0514 05:34:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 05:34:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 05:34:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:06 @base_main.py:47][0m 122610 total steps have happened
[32m[0514 05:34:06 @base_main.py:52][0m [avg_reward]: -26.896936032873715
[32m[0514 05:34:06 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:06 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:06 @base_trainer.py:216][0m Mean reward: -26.914899868661404
[32m[0514 05:34:06 @base_main.py:38][0m --------------- Iteration 123 ---------------
[32m[0514 05:34:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8923 mins
[32m[0514 05:34:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 05:34:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 05:34:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:34:06 @base_main.py:47][0m 123615 total steps have happened
[32m[0514 05:34:06 @base_main.py:52][0m [avg_reward]: -26.914899868661404
[32m[0514 05:34:06 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:06 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:06 @base_trainer.py:216][0m Mean reward: -25.16561258862622
[32m[0514 05:34:07 @base_main.py:38][0m --------------- Iteration 124 ---------------
[32m[0514 05:34:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9041 mins
[32m[0514 05:34:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 05:34:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0084 mins
[32m[0514 05:34:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:07 @base_main.py:47][0m 124620 total steps have happened
[32m[0514 05:34:07 @base_main.py:52][0m [avg_reward]: -25.16561258862622
[32m[0514 05:34:07 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:07 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:07 @base_trainer.py:216][0m Mean reward: -26.64017922185356
[32m[0514 05:34:08 @base_main.py:38][0m --------------- Iteration 125 ---------------
[32m[0514 05:34:08 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9153 mins
[32m[0514 05:34:08 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 05:34:08 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 05:34:08 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:34:08 @base_main.py:47][0m 125625 total steps have happened
[32m[0514 05:34:08 @base_main.py:52][0m [avg_reward]: -26.64017922185356
[32m[0514 05:34:08 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:08 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:08 @base_trainer.py:216][0m Mean reward: -27.23872354691901
[32m[0514 05:34:08 @base_main.py:38][0m --------------- Iteration 126 ---------------
[32m[0514 05:34:08 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9272 mins
[32m[0514 05:34:08 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 05:34:08 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 05:34:08 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:08 @base_main.py:47][0m 126630 total steps have happened
[32m[0514 05:34:08 @base_main.py:52][0m [avg_reward]: -27.23872354691901
[32m[0514 05:34:09 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:09 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:09 @base_trainer.py:216][0m Mean reward: -26.748653365863685
[32m[0514 05:34:09 @base_main.py:38][0m --------------- Iteration 127 ---------------
[32m[0514 05:34:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9391 mins
[32m[0514 05:34:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 05:34:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 05:34:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:09 @base_main.py:47][0m 127635 total steps have happened
[32m[0514 05:34:09 @base_main.py:52][0m [avg_reward]: -26.748653365863685
[32m[0514 05:34:09 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:09 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:09 @base_trainer.py:216][0m Mean reward: -25.962846990008774
[32m[0514 05:34:10 @base_main.py:38][0m --------------- Iteration 128 ---------------
[32m[0514 05:34:10 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9511 mins
[32m[0514 05:34:10 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 05:34:10 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 05:34:10 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:10 @base_main.py:47][0m 128640 total steps have happened
[32m[0514 05:34:10 @base_main.py:52][0m [avg_reward]: -25.962846990008774
[32m[0514 05:34:10 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:10 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:10 @base_trainer.py:216][0m Mean reward: -26.13061071195898
[32m[0514 05:34:11 @base_main.py:38][0m --------------- Iteration 129 ---------------
[32m[0514 05:34:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9632 mins
[32m[0514 05:34:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 05:34:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 05:34:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 05:34:11 @base_main.py:47][0m 129645 total steps have happened
[32m[0514 05:34:11 @base_main.py:52][0m [avg_reward]: -26.13061071195898
[32m[0514 05:34:11 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:11 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:11 @base_trainer.py:216][0m Mean reward: -25.76614489573788
[32m[0514 05:34:11 @base_main.py:38][0m --------------- Iteration 130 ---------------
[32m[0514 05:34:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9751 mins
[32m[0514 05:34:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 05:34:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0514 05:34:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:11 @base_main.py:47][0m 130650 total steps have happened
[32m[0514 05:34:11 @base_main.py:52][0m [avg_reward]: -25.76614489573788
[32m[0514 05:34:12 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:12 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:12 @base_trainer.py:216][0m Mean reward: -27.19444629546099
[32m[0514 05:34:12 @base_main.py:38][0m --------------- Iteration 131 ---------------
[32m[0514 05:34:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9876 mins
[32m[0514 05:34:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 05:34:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 05:34:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:12 @base_main.py:47][0m 131655 total steps have happened
[32m[0514 05:34:12 @base_main.py:52][0m [avg_reward]: -27.19444629546099
[32m[0514 05:34:12 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:12 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:12 @base_trainer.py:216][0m Mean reward: -25.94244469749694
[32m[0514 05:34:13 @base_main.py:38][0m --------------- Iteration 132 ---------------
[32m[0514 05:34:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9998 mins
[32m[0514 05:34:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 05:34:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 05:34:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 05:34:13 @base_main.py:47][0m 132660 total steps have happened
[32m[0514 05:34:13 @base_main.py:52][0m [avg_reward]: -25.94244469749694
[32m[0514 05:34:13 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:13 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:13 @base_trainer.py:216][0m Mean reward: -28.226197516655652
[32m[0514 05:34:14 @base_main.py:38][0m --------------- Iteration 133 ---------------
[32m[0514 05:34:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0118 mins
[32m[0514 05:34:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 05:34:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 05:34:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:14 @base_main.py:47][0m 133665 total steps have happened
[32m[0514 05:34:14 @base_main.py:52][0m [avg_reward]: -28.226197516655652
[32m[0514 05:34:14 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:14 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:14 @base_trainer.py:216][0m Mean reward: -25.903073526423828
[32m[0514 05:34:14 @base_main.py:38][0m --------------- Iteration 134 ---------------
[32m[0514 05:34:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0239 mins
[32m[0514 05:34:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 05:34:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 05:34:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:14 @base_main.py:47][0m 134670 total steps have happened
[32m[0514 05:34:14 @base_main.py:52][0m [avg_reward]: -25.903073526423828
[32m[0514 05:34:14 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:14 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:14 @base_trainer.py:216][0m Mean reward: -26.733658541330772
[32m[0514 05:34:15 @base_main.py:38][0m --------------- Iteration 135 ---------------
[32m[0514 05:34:15 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0359 mins
[32m[0514 05:34:15 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 05:34:15 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 05:34:15 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:15 @base_main.py:47][0m 135675 total steps have happened
[32m[0514 05:34:15 @base_main.py:52][0m [avg_reward]: -26.733658541330772
[32m[0514 05:34:15 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:15 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:15 @base_trainer.py:216][0m Mean reward: -26.844118758409547
[32m[0514 05:34:16 @base_main.py:38][0m --------------- Iteration 136 ---------------
[32m[0514 05:34:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0480 mins
[32m[0514 05:34:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 05:34:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0083 mins
[32m[0514 05:34:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:34:16 @base_main.py:47][0m 136680 total steps have happened
[32m[0514 05:34:16 @base_main.py:52][0m [avg_reward]: -26.844118758409547
[32m[0514 05:34:16 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:16 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:16 @base_trainer.py:216][0m Mean reward: -26.950071378632497
[32m[0514 05:34:16 @base_main.py:38][0m --------------- Iteration 137 ---------------
[32m[0514 05:34:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0593 mins
[32m[0514 05:34:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 05:34:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 05:34:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:16 @base_main.py:47][0m 137685 total steps have happened
[32m[0514 05:34:16 @base_main.py:52][0m [avg_reward]: -26.950071378632497
[32m[0514 05:34:16 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:16 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:17 @base_trainer.py:216][0m Mean reward: -27.676677374663445
[32m[0514 05:34:17 @base_main.py:38][0m --------------- Iteration 138 ---------------
[32m[0514 05:34:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0709 mins
[32m[0514 05:34:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 05:34:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0514 05:34:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:17 @base_main.py:47][0m 138690 total steps have happened
[32m[0514 05:34:17 @base_main.py:52][0m [avg_reward]: -27.676677374663445
[32m[0514 05:34:17 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:17 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:17 @base_trainer.py:216][0m Mean reward: -27.380312120207567
[32m[0514 05:34:18 @base_main.py:38][0m --------------- Iteration 139 ---------------
[32m[0514 05:34:18 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0834 mins
[32m[0514 05:34:18 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 05:34:18 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 05:34:18 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:18 @base_main.py:47][0m 139695 total steps have happened
[32m[0514 05:34:18 @base_main.py:52][0m [avg_reward]: -27.380312120207567
[32m[0514 05:34:18 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:18 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:18 @base_trainer.py:216][0m Mean reward: -27.2145550646642
[32m[0514 05:34:19 @base_main.py:38][0m --------------- Iteration 140 ---------------
[32m[0514 05:34:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0951 mins
[32m[0514 05:34:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 05:34:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 05:34:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:19 @base_main.py:47][0m 140700 total steps have happened
[32m[0514 05:34:19 @base_main.py:52][0m [avg_reward]: -27.2145550646642
[32m[0514 05:34:19 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:19 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:19 @base_trainer.py:216][0m Mean reward: -26.6036317604646
[32m[0514 05:34:19 @base_main.py:38][0m --------------- Iteration 141 ---------------
[32m[0514 05:34:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1072 mins
[32m[0514 05:34:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 05:34:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 05:34:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:19 @base_main.py:47][0m 141705 total steps have happened
[32m[0514 05:34:19 @base_main.py:52][0m [avg_reward]: -26.6036317604646
[32m[0514 05:34:19 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:19 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:19 @base_trainer.py:216][0m Mean reward: -26.5819543211958
[32m[0514 05:34:20 @base_main.py:38][0m --------------- Iteration 142 ---------------
[32m[0514 05:34:20 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1193 mins
[32m[0514 05:34:20 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 05:34:20 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0514 05:34:20 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:20 @base_main.py:47][0m 142710 total steps have happened
[32m[0514 05:34:20 @base_main.py:52][0m [avg_reward]: -26.5819543211958
[32m[0514 05:34:20 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:20 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:20 @base_trainer.py:216][0m Mean reward: -28.09585894715459
[32m[0514 05:34:21 @base_main.py:38][0m --------------- Iteration 143 ---------------
[32m[0514 05:34:21 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1317 mins
[32m[0514 05:34:21 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0514 05:34:21 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0084 mins
[32m[0514 05:34:21 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:34:21 @base_main.py:47][0m 143715 total steps have happened
[32m[0514 05:34:21 @base_main.py:52][0m [avg_reward]: -28.09585894715459
[32m[0514 05:34:21 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:21 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:21 @base_trainer.py:216][0m Mean reward: -28.62412446300636
[32m[0514 05:34:21 @base_main.py:38][0m --------------- Iteration 144 ---------------
[32m[0514 05:34:21 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1434 mins
[32m[0514 05:34:21 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 05:34:21 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 05:34:21 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:34:21 @base_main.py:47][0m 144720 total steps have happened
[32m[0514 05:34:21 @base_main.py:52][0m [avg_reward]: -28.62412446300636
[32m[0514 05:34:22 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:22 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:22 @base_trainer.py:216][0m Mean reward: -27.055564793267173
[32m[0514 05:34:22 @base_main.py:38][0m --------------- Iteration 145 ---------------
[32m[0514 05:34:22 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1554 mins
[32m[0514 05:34:22 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 05:34:22 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0514 05:34:22 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:22 @base_main.py:47][0m 145725 total steps have happened
[32m[0514 05:34:22 @base_main.py:52][0m [avg_reward]: -27.055564793267173
[32m[0514 05:34:22 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:22 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:22 @base_trainer.py:216][0m Mean reward: -27.487357272444136
[32m[0514 05:34:23 @base_main.py:38][0m --------------- Iteration 146 ---------------
[32m[0514 05:34:23 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1671 mins
[32m[0514 05:34:23 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 05:34:23 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 05:34:23 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:23 @base_main.py:47][0m 146730 total steps have happened
[32m[0514 05:34:23 @base_main.py:52][0m [avg_reward]: -27.487357272444136
[32m[0514 05:34:23 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:23 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:23 @base_trainer.py:216][0m Mean reward: -28.432225490927728
[32m[0514 05:34:24 @base_main.py:38][0m --------------- Iteration 147 ---------------
[32m[0514 05:34:24 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1790 mins
[32m[0514 05:34:24 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 05:34:24 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 05:34:24 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:24 @base_main.py:47][0m 147735 total steps have happened
[32m[0514 05:34:24 @base_main.py:52][0m [avg_reward]: -28.432225490927728
[32m[0514 05:34:24 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:24 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:24 @base_trainer.py:216][0m Mean reward: -29.171507170303734
[32m[0514 05:34:24 @base_main.py:38][0m --------------- Iteration 148 ---------------
[32m[0514 05:34:24 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1912 mins
[32m[0514 05:34:24 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 05:34:24 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 05:34:24 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:24 @base_main.py:47][0m 148740 total steps have happened
[32m[0514 05:34:24 @base_main.py:52][0m [avg_reward]: -29.171507170303734
[32m[0514 05:34:24 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:24 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:24 @base_trainer.py:216][0m Mean reward: -31.177641578821202
[32m[0514 05:34:25 @base_main.py:38][0m --------------- Iteration 149 ---------------
[32m[0514 05:34:25 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2030 mins
[32m[0514 05:34:25 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 05:34:25 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 05:34:25 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:25 @base_main.py:47][0m 149745 total steps have happened
[32m[0514 05:34:25 @base_main.py:52][0m [avg_reward]: -31.177641578821202
[32m[0514 05:34:25 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:25 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:25 @base_trainer.py:216][0m Mean reward: -30.853980998166453
[32m[0514 05:34:26 @base_main.py:38][0m --------------- Iteration 150 ---------------
[32m[0514 05:34:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2150 mins
[32m[0514 05:34:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 05:34:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0514 05:34:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:26 @base_main.py:47][0m 150750 total steps have happened
[32m[0514 05:34:26 @base_main.py:52][0m [avg_reward]: -30.853980998166453
[32m[0514 05:34:26 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:26 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:26 @base_trainer.py:216][0m Mean reward: -29.173898602176585
[32m[0514 05:34:26 @base_main.py:38][0m --------------- Iteration 151 ---------------
[32m[0514 05:34:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2273 mins
[32m[0514 05:34:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 05:34:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 05:34:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:26 @base_main.py:47][0m 151755 total steps have happened
[32m[0514 05:34:26 @base_main.py:52][0m [avg_reward]: -29.173898602176585
[32m[0514 05:34:27 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:27 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:27 @base_trainer.py:216][0m Mean reward: -26.793230931548614
[32m[0514 05:34:27 @base_main.py:38][0m --------------- Iteration 152 ---------------
[32m[0514 05:34:27 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2395 mins
[32m[0514 05:34:27 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 05:34:27 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0514 05:34:27 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:27 @base_main.py:47][0m 152760 total steps have happened
[32m[0514 05:34:27 @base_main.py:52][0m [avg_reward]: -26.793230931548614
[32m[0514 05:34:27 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:27 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:27 @base_trainer.py:216][0m Mean reward: -28.560537093678455
[32m[0514 05:34:28 @base_main.py:38][0m --------------- Iteration 153 ---------------
[32m[0514 05:34:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2518 mins
[32m[0514 05:34:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 05:34:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 05:34:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:28 @base_main.py:47][0m 153765 total steps have happened
[32m[0514 05:34:28 @base_main.py:52][0m [avg_reward]: -28.560537093678455
[32m[0514 05:34:28 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:28 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:28 @base_trainer.py:216][0m Mean reward: -30.075923858475015
[32m[0514 05:34:29 @base_main.py:38][0m --------------- Iteration 154 ---------------
[32m[0514 05:34:29 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2636 mins
[32m[0514 05:34:29 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 05:34:29 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0514 05:34:29 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 05:34:29 @base_main.py:47][0m 154770 total steps have happened
[32m[0514 05:34:29 @base_main.py:52][0m [avg_reward]: -30.075923858475015
[32m[0514 05:34:29 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:29 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:29 @base_trainer.py:216][0m Mean reward: -28.966241167499284
[32m[0514 05:34:29 @base_main.py:38][0m --------------- Iteration 155 ---------------
[32m[0514 05:34:29 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2761 mins
[32m[0514 05:34:29 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 05:34:29 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 05:34:29 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:29 @base_main.py:47][0m 155775 total steps have happened
[32m[0514 05:34:29 @base_main.py:52][0m [avg_reward]: -28.966241167499284
[32m[0514 05:34:30 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:30 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:30 @base_trainer.py:216][0m Mean reward: -28.0106474396892
[32m[0514 05:34:30 @base_main.py:38][0m --------------- Iteration 156 ---------------
[32m[0514 05:34:30 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2880 mins
[32m[0514 05:34:30 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 05:34:30 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 05:34:30 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:30 @base_main.py:47][0m 156780 total steps have happened
[32m[0514 05:34:30 @base_main.py:52][0m [avg_reward]: -28.0106474396892
[32m[0514 05:34:30 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:30 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:30 @base_trainer.py:216][0m Mean reward: -27.41574742809134
[32m[0514 05:34:31 @base_main.py:38][0m --------------- Iteration 157 ---------------
[32m[0514 05:34:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2994 mins
[32m[0514 05:34:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 05:34:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 05:34:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:34:31 @base_main.py:47][0m 157785 total steps have happened
[32m[0514 05:34:31 @base_main.py:52][0m [avg_reward]: -27.41574742809134
[32m[0514 05:34:31 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:31 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:31 @base_trainer.py:216][0m Mean reward: -27.68229018430818
[32m[0514 05:34:31 @base_main.py:38][0m --------------- Iteration 158 ---------------
[32m[0514 05:34:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3111 mins
[32m[0514 05:34:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 05:34:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0514 05:34:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:31 @base_main.py:47][0m 158790 total steps have happened
[32m[0514 05:34:31 @base_main.py:52][0m [avg_reward]: -27.68229018430818
[32m[0514 05:34:32 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:32 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:32 @base_trainer.py:216][0m Mean reward: -27.208268836711778
[32m[0514 05:34:32 @base_main.py:38][0m --------------- Iteration 159 ---------------
[32m[0514 05:34:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3235 mins
[32m[0514 05:34:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 05:34:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 05:34:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 05:34:32 @base_main.py:47][0m 159795 total steps have happened
[32m[0514 05:34:32 @base_main.py:52][0m [avg_reward]: -27.208268836711778
[32m[0514 05:34:32 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:32 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:32 @base_trainer.py:216][0m Mean reward: -26.79201224676192
[32m[0514 05:34:33 @base_main.py:38][0m --------------- Iteration 160 ---------------
[32m[0514 05:34:33 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3355 mins
[32m[0514 05:34:33 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 05:34:33 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 05:34:33 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:33 @base_main.py:47][0m 160800 total steps have happened
[32m[0514 05:34:33 @base_main.py:52][0m [avg_reward]: -26.79201224676192
[32m[0514 05:34:33 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:33 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:33 @base_trainer.py:216][0m Mean reward: -27.127596599257128
[32m[0514 05:34:34 @base_main.py:38][0m --------------- Iteration 161 ---------------
[32m[0514 05:34:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3473 mins
[32m[0514 05:34:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 05:34:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0514 05:34:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:34 @base_main.py:47][0m 161805 total steps have happened
[32m[0514 05:34:34 @base_main.py:52][0m [avg_reward]: -27.127596599257128
[32m[0514 05:34:34 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:34 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:34 @base_trainer.py:216][0m Mean reward: -26.661395460421936
[32m[0514 05:34:34 @base_main.py:38][0m --------------- Iteration 162 ---------------
[32m[0514 05:34:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3596 mins
[32m[0514 05:34:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 05:34:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 05:34:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:34 @base_main.py:47][0m 162810 total steps have happened
[32m[0514 05:34:34 @base_main.py:52][0m [avg_reward]: -26.661395460421936
[32m[0514 05:34:35 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:35 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:35 @base_trainer.py:216][0m Mean reward: -25.164279305828558
[32m[0514 05:34:35 @base_main.py:38][0m --------------- Iteration 163 ---------------
[32m[0514 05:34:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3714 mins
[32m[0514 05:34:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 05:34:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 05:34:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:34:35 @base_main.py:47][0m 163815 total steps have happened
[32m[0514 05:34:35 @base_main.py:52][0m [avg_reward]: -25.164279305828558
[32m[0514 05:34:35 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:35 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:35 @base_trainer.py:216][0m Mean reward: -25.509586120551212
[32m[0514 05:34:36 @base_main.py:38][0m --------------- Iteration 164 ---------------
[32m[0514 05:34:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3833 mins
[32m[0514 05:34:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0514 05:34:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 05:34:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:34:36 @base_main.py:47][0m 164820 total steps have happened
[32m[0514 05:34:36 @base_main.py:52][0m [avg_reward]: -25.509586120551212
[32m[0514 05:34:36 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:36 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:36 @base_trainer.py:216][0m Mean reward: -25.798723979573815
[32m[0514 05:34:37 @base_main.py:38][0m --------------- Iteration 165 ---------------
[32m[0514 05:34:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3958 mins
[32m[0514 05:34:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 05:34:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 05:34:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:37 @base_main.py:47][0m 165825 total steps have happened
[32m[0514 05:34:37 @base_main.py:52][0m [avg_reward]: -25.798723979573815
[32m[0514 05:34:37 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:37 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:37 @base_trainer.py:216][0m Mean reward: -25.948935753261527
[32m[0514 05:34:37 @base_main.py:38][0m --------------- Iteration 166 ---------------
[32m[0514 05:34:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4079 mins
[32m[0514 05:34:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0033 mins
[32m[0514 05:34:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 05:34:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:37 @base_main.py:47][0m 166830 total steps have happened
[32m[0514 05:34:37 @base_main.py:52][0m [avg_reward]: -25.948935753261527
[32m[0514 05:34:37 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:37 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:37 @base_trainer.py:216][0m Mean reward: -25.8682152915534
[32m[0514 05:34:38 @base_main.py:38][0m --------------- Iteration 167 ---------------
[32m[0514 05:34:38 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4200 mins
[32m[0514 05:34:38 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0514 05:34:38 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 05:34:38 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:34:38 @base_main.py:47][0m 167835 total steps have happened
[32m[0514 05:34:38 @base_main.py:52][0m [avg_reward]: -25.8682152915534
[32m[0514 05:34:38 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:38 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:38 @base_trainer.py:216][0m Mean reward: -26.191874771779162
[32m[0514 05:34:39 @base_main.py:38][0m --------------- Iteration 168 ---------------
[32m[0514 05:34:39 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4319 mins
[32m[0514 05:34:39 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 05:34:39 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 05:34:39 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:39 @base_main.py:47][0m 168840 total steps have happened
[32m[0514 05:34:39 @base_main.py:52][0m [avg_reward]: -26.191874771779162
[32m[0514 05:34:39 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:39 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:39 @base_trainer.py:216][0m Mean reward: -25.31619502443315
[32m[0514 05:34:39 @base_main.py:38][0m --------------- Iteration 169 ---------------
[32m[0514 05:34:39 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4435 mins
[32m[0514 05:34:39 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 05:34:39 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0514 05:34:39 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:39 @base_main.py:47][0m 169845 total steps have happened
[32m[0514 05:34:39 @base_main.py:52][0m [avg_reward]: -25.31619502443315
[32m[0514 05:34:40 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:40 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:40 @base_trainer.py:216][0m Mean reward: -26.30866519041741
[32m[0514 05:34:40 @base_main.py:38][0m --------------- Iteration 170 ---------------
[32m[0514 05:34:40 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4561 mins
[32m[0514 05:34:40 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 05:34:40 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 05:34:40 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 05:34:40 @base_main.py:47][0m 170850 total steps have happened
[32m[0514 05:34:40 @base_main.py:52][0m [avg_reward]: -26.30866519041741
[32m[0514 05:34:40 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:40 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:40 @base_trainer.py:216][0m Mean reward: -27.04478733713014
[32m[0514 05:34:41 @base_main.py:38][0m --------------- Iteration 171 ---------------
[32m[0514 05:34:41 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4681 mins
[32m[0514 05:34:41 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 05:34:41 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 05:34:41 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:41 @base_main.py:47][0m 171855 total steps have happened
[32m[0514 05:34:41 @base_main.py:52][0m [avg_reward]: -27.04478733713014
[32m[0514 05:34:41 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:41 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:41 @base_trainer.py:216][0m Mean reward: -25.216785477896206
[32m[0514 05:34:42 @base_main.py:38][0m --------------- Iteration 172 ---------------
[32m[0514 05:34:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4797 mins
[32m[0514 05:34:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 05:34:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0514 05:34:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:42 @base_main.py:47][0m 172860 total steps have happened
[32m[0514 05:34:42 @base_main.py:52][0m [avg_reward]: -25.216785477896206
[32m[0514 05:34:42 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:42 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:42 @base_trainer.py:216][0m Mean reward: -26.45896100485164
[32m[0514 05:34:42 @base_main.py:38][0m --------------- Iteration 173 ---------------
[32m[0514 05:34:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4919 mins
[32m[0514 05:34:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 05:34:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 05:34:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:42 @base_main.py:47][0m 173865 total steps have happened
[32m[0514 05:34:42 @base_main.py:52][0m [avg_reward]: -26.45896100485164
[32m[0514 05:34:42 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:42 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:42 @base_trainer.py:216][0m Mean reward: -26.383396859737495
[32m[0514 05:34:43 @base_main.py:38][0m --------------- Iteration 174 ---------------
[32m[0514 05:34:43 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.5038 mins
[32m[0514 05:34:43 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 05:34:43 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 05:34:43 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:43 @base_main.py:47][0m 174870 total steps have happened
[32m[0514 05:34:43 @base_main.py:52][0m [avg_reward]: -26.383396859737495
[32m[0514 05:34:43 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:43 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:43 @base_trainer.py:216][0m Mean reward: -25.14627576696011
[32m[0514 05:34:44 @base_main.py:38][0m --------------- Iteration 175 ---------------
[32m[0514 05:34:44 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.5156 mins
[32m[0514 05:34:44 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0032 mins
[32m[0514 05:34:44 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 05:34:44 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:44 @base_main.py:47][0m 175875 total steps have happened
[32m[0514 05:34:44 @base_main.py:52][0m [avg_reward]: -25.14627576696011
[32m[0514 05:34:44 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:44 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:44 @base_trainer.py:216][0m Mean reward: -26.571483783435845
[32m[0514 05:34:44 @base_main.py:38][0m --------------- Iteration 176 ---------------
[32m[0514 05:34:44 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.5278 mins
[32m[0514 05:34:44 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 05:34:44 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0084 mins
[32m[0514 05:34:44 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:44 @base_main.py:47][0m 176880 total steps have happened
[32m[0514 05:34:44 @base_main.py:52][0m [avg_reward]: -26.571483783435845
[32m[0514 05:34:45 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:45 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:45 @base_trainer.py:216][0m Mean reward: -27.218213983756677
[32m[0514 05:34:45 @base_main.py:38][0m --------------- Iteration 177 ---------------
[32m[0514 05:34:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.5391 mins
[32m[0514 05:34:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 05:34:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 05:34:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:45 @base_main.py:47][0m 177885 total steps have happened
[32m[0514 05:34:45 @base_main.py:52][0m [avg_reward]: -27.218213983756677
[32m[0514 05:34:45 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:45 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:45 @base_trainer.py:216][0m Mean reward: -25.82651546749247
[32m[0514 05:34:46 @base_main.py:38][0m --------------- Iteration 178 ---------------
[32m[0514 05:34:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.5506 mins
[32m[0514 05:34:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 05:34:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 05:34:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:46 @base_main.py:47][0m 178890 total steps have happened
[32m[0514 05:34:46 @base_main.py:52][0m [avg_reward]: -25.82651546749247
[32m[0514 05:34:46 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:46 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:46 @base_trainer.py:216][0m Mean reward: -25.930969192854615
[32m[0514 05:34:47 @base_main.py:38][0m --------------- Iteration 179 ---------------
[32m[0514 05:34:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.5622 mins
[32m[0514 05:34:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 05:34:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 05:34:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:47 @base_main.py:47][0m 179895 total steps have happened
[32m[0514 05:34:47 @base_main.py:52][0m [avg_reward]: -25.930969192854615
[32m[0514 05:34:47 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:47 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:47 @base_trainer.py:216][0m Mean reward: -26.10331770484608
[32m[0514 05:34:47 @base_main.py:38][0m --------------- Iteration 180 ---------------
[32m[0514 05:34:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.5738 mins
[32m[0514 05:34:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0514 05:34:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0084 mins
[32m[0514 05:34:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:47 @base_main.py:47][0m 180900 total steps have happened
[32m[0514 05:34:47 @base_main.py:52][0m [avg_reward]: -26.10331770484608
[32m[0514 05:34:47 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:47 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:47 @base_trainer.py:216][0m Mean reward: -25.949680272318165
[32m[0514 05:34:48 @base_main.py:38][0m --------------- Iteration 181 ---------------
[32m[0514 05:34:48 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.5854 mins
[32m[0514 05:34:48 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 05:34:48 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0083 mins
[32m[0514 05:34:48 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:48 @base_main.py:47][0m 181905 total steps have happened
[32m[0514 05:34:48 @base_main.py:52][0m [avg_reward]: -25.949680272318165
[32m[0514 05:34:48 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:48 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:48 @base_trainer.py:216][0m Mean reward: -26.519402468488956
[32m[0514 05:34:49 @base_main.py:38][0m --------------- Iteration 182 ---------------
[32m[0514 05:34:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.5967 mins
[32m[0514 05:34:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 05:34:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 05:34:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:49 @base_main.py:47][0m 182910 total steps have happened
[32m[0514 05:34:49 @base_main.py:52][0m [avg_reward]: -26.519402468488956
[32m[0514 05:34:49 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:49 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:49 @base_trainer.py:216][0m Mean reward: -26.45165853145083
[32m[0514 05:34:49 @base_main.py:38][0m --------------- Iteration 183 ---------------
[32m[0514 05:34:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.6088 mins
[32m[0514 05:34:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 05:34:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 05:34:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:49 @base_main.py:47][0m 183915 total steps have happened
[32m[0514 05:34:49 @base_main.py:52][0m [avg_reward]: -26.45165853145083
[32m[0514 05:34:50 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:50 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:50 @base_trainer.py:216][0m Mean reward: -26.058228472306098
[32m[0514 05:34:50 @base_main.py:38][0m --------------- Iteration 184 ---------------
[32m[0514 05:34:50 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.6212 mins
[32m[0514 05:34:50 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 05:34:50 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 05:34:50 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:34:50 @base_main.py:47][0m 184920 total steps have happened
[32m[0514 05:34:50 @base_main.py:52][0m [avg_reward]: -26.058228472306098
[32m[0514 05:34:50 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:50 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:50 @base_trainer.py:216][0m Mean reward: -27.676196287268226
[32m[0514 05:34:51 @base_main.py:38][0m --------------- Iteration 185 ---------------
[32m[0514 05:34:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.6334 mins
[32m[0514 05:34:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 05:34:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 05:34:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:51 @base_main.py:47][0m 185925 total steps have happened
[32m[0514 05:34:51 @base_main.py:52][0m [avg_reward]: -27.676196287268226
[32m[0514 05:34:51 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:51 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:51 @base_trainer.py:216][0m Mean reward: -27.38425933428339
[32m[0514 05:34:52 @base_main.py:38][0m --------------- Iteration 186 ---------------
[32m[0514 05:34:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.6453 mins
[32m[0514 05:34:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 05:34:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 05:34:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:52 @base_main.py:47][0m 186930 total steps have happened
[32m[0514 05:34:52 @base_main.py:52][0m [avg_reward]: -27.38425933428339
[32m[0514 05:34:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:52 @base_trainer.py:216][0m Mean reward: -28.979122309755134
[32m[0514 05:34:52 @base_main.py:38][0m --------------- Iteration 187 ---------------
[32m[0514 05:34:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.6573 mins
[32m[0514 05:34:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0032 mins
[32m[0514 05:34:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 05:34:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:52 @base_main.py:47][0m 187935 total steps have happened
[32m[0514 05:34:52 @base_main.py:52][0m [avg_reward]: -28.979122309755134
[32m[0514 05:34:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:52 @base_trainer.py:216][0m Mean reward: -31.354970683994367
[32m[0514 05:34:53 @base_main.py:38][0m --------------- Iteration 188 ---------------
[32m[0514 05:34:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.6695 mins
[32m[0514 05:34:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 05:34:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0514 05:34:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:53 @base_main.py:47][0m 188940 total steps have happened
[32m[0514 05:34:53 @base_main.py:52][0m [avg_reward]: -31.354970683994367
[32m[0514 05:34:53 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:53 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:53 @base_trainer.py:216][0m Mean reward: -29.782504396565248
[32m[0514 05:34:54 @base_main.py:38][0m --------------- Iteration 189 ---------------
[32m[0514 05:34:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.6819 mins
[32m[0514 05:34:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 05:34:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 05:34:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:54 @base_main.py:47][0m 189945 total steps have happened
[32m[0514 05:34:54 @base_main.py:52][0m [avg_reward]: -29.782504396565248
[32m[0514 05:34:54 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:54 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:54 @base_trainer.py:216][0m Mean reward: -30.48886356313834
[32m[0514 05:34:54 @base_main.py:38][0m --------------- Iteration 190 ---------------
[32m[0514 05:34:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.6938 mins
[32m[0514 05:34:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 05:34:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 05:34:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:54 @base_main.py:47][0m 190950 total steps have happened
[32m[0514 05:34:54 @base_main.py:52][0m [avg_reward]: -30.48886356313834
[32m[0514 05:34:55 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:55 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:55 @base_trainer.py:216][0m Mean reward: -31.44519619306675
[32m[0514 05:34:55 @base_main.py:38][0m --------------- Iteration 191 ---------------
[32m[0514 05:34:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.7058 mins
[32m[0514 05:34:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 05:34:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 05:34:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:55 @base_main.py:47][0m 191955 total steps have happened
[32m[0514 05:34:55 @base_main.py:52][0m [avg_reward]: -31.44519619306675
[32m[0514 05:34:55 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:55 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:55 @base_trainer.py:216][0m Mean reward: -31.869913448641068
[32m[0514 05:34:56 @base_main.py:38][0m --------------- Iteration 192 ---------------
[32m[0514 05:34:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.7177 mins
[32m[0514 05:34:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0514 05:34:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0514 05:34:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:56 @base_main.py:47][0m 192960 total steps have happened
[32m[0514 05:34:56 @base_main.py:52][0m [avg_reward]: -31.869913448641068
[32m[0514 05:34:56 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:56 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:56 @base_trainer.py:216][0m Mean reward: -36.83408575091112
[32m[0514 05:34:57 @base_main.py:38][0m --------------- Iteration 193 ---------------
[32m[0514 05:34:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.7302 mins
[32m[0514 05:34:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 05:34:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0514 05:34:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:34:57 @base_main.py:47][0m 193965 total steps have happened
[32m[0514 05:34:57 @base_main.py:52][0m [avg_reward]: -36.83408575091112
[32m[0514 05:34:57 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:57 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:57 @base_trainer.py:216][0m Mean reward: -39.95124771658065
[32m[0514 05:34:57 @base_main.py:38][0m --------------- Iteration 194 ---------------
[32m[0514 05:34:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.7426 mins
[32m[0514 05:34:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 05:34:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 05:34:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:57 @base_main.py:47][0m 194970 total steps have happened
[32m[0514 05:34:57 @base_main.py:52][0m [avg_reward]: -39.95124771658065
[32m[0514 05:34:57 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:57 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:57 @base_trainer.py:216][0m Mean reward: -60.84140947724181
[32m[0514 05:34:58 @base_main.py:38][0m --------------- Iteration 195 ---------------
[32m[0514 05:34:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.7543 mins
[32m[0514 05:34:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 05:34:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0514 05:34:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:58 @base_main.py:47][0m 195975 total steps have happened
[32m[0514 05:34:58 @base_main.py:52][0m [avg_reward]: -60.84140947724181
[32m[0514 05:34:58 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:58 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:58 @base_trainer.py:216][0m Mean reward: -60.11121112207887
[32m[0514 05:34:59 @base_main.py:38][0m --------------- Iteration 196 ---------------
[32m[0514 05:34:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.7662 mins
[32m[0514 05:34:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 05:34:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 05:34:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:59 @base_main.py:47][0m 196980 total steps have happened
[32m[0514 05:34:59 @base_main.py:52][0m [avg_reward]: -60.11121112207887
[32m[0514 05:34:59 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:34:59 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:34:59 @base_trainer.py:216][0m Mean reward: -40.728118306932544
[32m[0514 05:34:59 @base_main.py:38][0m --------------- Iteration 197 ---------------
[32m[0514 05:34:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.7784 mins
[32m[0514 05:34:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 05:34:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 05:34:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:34:59 @base_main.py:47][0m 197985 total steps have happened
[32m[0514 05:34:59 @base_main.py:52][0m [avg_reward]: -40.728118306932544
[32m[0514 05:35:00 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:00 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:00 @base_trainer.py:216][0m Mean reward: -39.78264194386401
[32m[0514 05:35:00 @base_main.py:38][0m --------------- Iteration 198 ---------------
[32m[0514 05:35:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.7900 mins
[32m[0514 05:35:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 05:35:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 05:35:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:35:00 @base_main.py:47][0m 198990 total steps have happened
[32m[0514 05:35:00 @base_main.py:52][0m [avg_reward]: -39.78264194386401
[32m[0514 05:35:00 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:00 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:00 @base_trainer.py:216][0m Mean reward: -51.41050387904752
[32m[0514 05:35:01 @base_main.py:38][0m --------------- Iteration 199 ---------------
[32m[0514 05:35:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.8018 mins
[32m[0514 05:35:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 05:35:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 05:35:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 05:35:01 @base_main.py:47][0m 199995 total steps have happened
[32m[0514 05:35:01 @base_main.py:52][0m [avg_reward]: -51.41050387904752
[32m[0514 05:35:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 05:35:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:01 @base_trainer.py:216][0m Mean reward: -39.148680475318336
[32m[0514 05:35:02 @base_main.py:38][0m --------------- Iteration 200 ---------------
[32m[0514 05:35:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.8142 mins
[32m[0514 05:35:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 05:35:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 05:35:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 05:35:02 @base_main.py:47][0m 201000 total steps have happened
[32m[0514 05:35:02 @base_main.py:52][0m [avg_reward]: -39.148680475318336
[32m[0514 05:35:02 @base_worker.py:111][0m kill message for worker 16
[32m[0514 05:35:02 @base_worker.py:111][0m kill message for worker 19
[32m[0514 05:35:02 @base_worker.py:111][0m kill message for worker 14
[32m[0514 05:35:02 @base_worker.py:111][0m kill message for worker 9
[32m[0514 05:35:02 @base_worker.py:111][0m kill message for worker 12
[32m[0514 05:35:02 @base_worker.py:111][0m kill message for worker 13
[32m[0514 05:35:02 @base_worker.py:111][0m kill message for worker 10
[32m[0514 05:35:02 @base_worker.py:111][0m kill message for worker 8
[32m[0514 05:35:02 @base_worker.py:111][0m kill message for worker 7
[32m[0514 05:35:02 @base_worker.py:111][0m kill message for worker 17
[32m[0514 05:35:02 @base_worker.py:111][0m kill message for worker 11
[32m[0514 05:35:02 @base_worker.py:111][0m kill message for worker 6
[32m[0514 05:35:02 @base_worker.py:111][0m kill message for worker 3
[32m[0514 05:35:02 @base_worker.py:111][0m kill message for worker 1
[32m[0514 05:35:02 @base_worker.py:111][0m kill message for worker 18
[32m[0514 05:35:02 @base_worker.py:111][0m kill message for worker 0
[32m[0514 05:35:02 @base_worker.py:111][0m kill message for worker 5
[32m[0514 05:35:02 @base_worker.py:111][0m kill message for worker 2
[32m[0514 05:35:02 @base_worker.py:111][0m kill message for worker 4
[32m[0514 05:35:02 @base_worker.py:111][0m kill message for worker 15
