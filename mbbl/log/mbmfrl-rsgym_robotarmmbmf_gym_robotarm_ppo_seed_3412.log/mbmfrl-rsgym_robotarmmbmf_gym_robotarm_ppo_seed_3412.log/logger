[32m[0512 02:53:07 @logger.py:103][0m Log file set to /root/mbbl/log/mbmfrl-rsgym_robotarmmbmf_gym_robotarm_ppo_seed_3412.log/mbmfrl-rsgym_robotarmmbmf_gym_robotarm_ppo_seed_3412.log
[32m[0512 02:53:07 @mbmf_main.py:23][0m Training starts at /root/mbbl
[32m[0512 02:53:07 @base_worker.py:45][0m Worker 0 online
[32m[0512 02:53:08 @base_worker.py:45][0m Worker 1 online
[32m[0512 02:53:08 @base_worker.py:45][0m Worker 2 online
[32m[0512 02:53:08 @base_worker.py:45][0m Worker 3 online
[32m[0512 02:53:08 @base_worker.py:45][0m Worker 4 online
[32m[0512 02:53:08 @base_worker.py:45][0m Worker 5 online
[32m[0512 02:53:08 @base_worker.py:45][0m Worker 6 online
[32m[0512 02:53:08 @base_worker.py:45][0m Worker 7 online
[32m[0512 02:53:08 @base_worker.py:45][0m Worker 8 online
[32m[0512 02:53:08 @base_worker.py:45][0m Worker 9 online
[32m[0512 02:53:08 @base_worker.py:45][0m Worker 10 online
[32m[0512 02:53:08 @base_worker.py:45][0m Worker 11 online
[32m[0512 02:53:08 @base_worker.py:45][0m Worker 12 online
[32m[0512 02:53:08 @base_worker.py:45][0m Worker 13 online
[32m[0512 02:53:08 @base_worker.py:45][0m Worker 14 online
[32m[0512 02:53:08 @base_worker.py:45][0m Worker 15 online
[32m[0512 02:53:08 @base_worker.py:45][0m Worker 16 online
[32m[0512 02:53:08 @base_worker.py:45][0m Worker 17 online
[32m[0512 02:53:08 @base_worker.py:45][0m Worker 18 online
[32m[0512 02:53:08 @base_worker.py:45][0m Worker 19 online
[32m[0512 02:53:09 @base_trainer.py:152][0m Trainer maintains [1] policy network
[32m[0512 02:53:09 @base_trainer.py:152][0m Trainer maintains [1] dynamics network
[32m[0512 02:53:09 @base_trainer.py:152][0m Trainer maintains [1] reward network
[32m[0512 02:53:10 @mbmf_main.py:46][0m Generating 1000 random timesteps
[32m[0512 02:53:10 @mbmf_sampler.py:39][0m done with episode
[32m[0512 02:53:10 @mbmf_sampler.py:39][0m done with episode
[32m[0512 02:53:10 @mbmf_sampler.py:39][0m done with episode
[32m[0512 02:53:10 @mbmf_sampler.py:39][0m done with episode
[32m[0512 02:53:10 @mbmf_sampler.py:39][0m done with episode
[32m[0512 02:53:10 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0512 02:53:10 @base_trainer.py:216][0m Mean reward: -363.49235319094186
[32m[0512 02:53:10 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9269362092018127, Train Loss: 0.9040476679801941
[32m[0512 02:53:10 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9269508123397827, Train Loss: 0.9040404558181763
[32m[0512 02:53:10 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9269653558731079, Train Loss: 0.9040331840515137
[32m[0512 02:53:10 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9269802570343018, Train Loss: 0.9040265083312988
[32m[0512 02:53:10 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9269952178001404, Train Loss: 0.9040197134017944
[32m[0512 02:53:10 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9270104169845581, Train Loss: 0.9040132761001587
[32m[0512 02:53:10 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.927025556564331, Train Loss: 0.9040069580078125
[32m[0512 02:53:10 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9270408749580383, Train Loss: 0.9040007591247559
[32m[0512 02:53:10 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9270563721656799, Train Loss: 0.9039947986602783
[32m[0512 02:53:10 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9270719289779663, Train Loss: 0.9039891958236694
[32m[0512 02:53:10 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9270874857902527, Train Loss: 0.9039837718009949
[32m[0512 02:53:10 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9271031618118286, Train Loss: 0.9039784073829651
[32m[0512 02:53:10 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9271189570426941, Train Loss: 0.9039732813835144
[32m[0512 02:53:10 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9271346926689148, Train Loss: 0.9039684534072876
[32m[0512 02:53:10 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9271504878997803, Train Loss: 0.903963565826416
[32m[0512 02:53:10 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.927166223526001, Train Loss: 0.9039590954780579
[32m[0512 02:53:10 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9271820187568665, Train Loss: 0.9039546847343445
[32m[0512 02:53:10 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9271976947784424, Train Loss: 0.903950572013855
[32m[0512 02:53:11 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9272134304046631, Train Loss: 0.903946578502655
[32m[0512 02:53:11 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9272289276123047, Train Loss: 0.9039427638053894
[32m[0512 02:53:11 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9272444248199463, Train Loss: 0.9039391875267029
[32m[0512 02:53:11 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9272598028182983, Train Loss: 0.9039356708526611
[32m[0512 02:53:11 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9272750616073608, Train Loss: 0.9039323925971985
[32m[0512 02:53:11 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.927290141582489, Train Loss: 0.9039291739463806
[32m[0512 02:53:11 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9273052215576172, Train Loss: 0.9039262533187866
[32m[0512 02:53:11 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9273199439048767, Train Loss: 0.9039233922958374
[32m[0512 02:53:11 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9273343086242676, Train Loss: 0.9039207100868225
[32m[0512 02:53:11 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9273486137390137, Train Loss: 0.9039180874824524
[32m[0512 02:53:11 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9273627996444702, Train Loss: 0.9039157032966614
[32m[0512 02:53:11 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9273766279220581, Train Loss: 0.9039133191108704
[32m[0512 02:53:11 @base_main.py:38][0m --------------- Iteration 1 ---------------
[32m[0512 02:53:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0000 mins
[32m[0512 02:53:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0047 mins
[32m[0512 02:53:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0129 mins
[32m[0512 02:53:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0034 mins
[32m[0512 02:53:11 @base_main.py:47][0m 1005 total steps have happened
[32m[0512 02:53:11 @base_main.py:52][0m [avg_reward]: -363.49235319094186
[32m[0512 02:53:11 @base_main.py:52][0m [update_op]: None
[32m[0512 02:53:11 @base_main.py:52][0m [train_loss]: 0.9039133191108704
[32m[0512 02:53:11 @base_main.py:52][0m [val_loss]: 0.9273766279220581
[32m[0512 02:53:11 @base_main.py:52][0m [avg_train_loss]: 0.9039133191108704
[32m[0512 02:55:34 @mbmf_sampler.py:39][0m done with episode
[32m[0512 02:57:55 @mbmf_sampler.py:39][0m done with episode
[32m[0512 03:00:15 @mbmf_sampler.py:39][0m done with episode
[32m[0512 03:02:36 @mbmf_sampler.py:39][0m done with episode
[32m[0512 03:04:55 @mbmf_sampler.py:39][0m done with episode
[32m[0512 03:04:55 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0512 03:04:55 @base_trainer.py:216][0m Mean reward: -258.46903845936765
[32m[0512 03:04:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7946643829345703, Train Loss: 0.9535117745399475
[32m[0512 03:04:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7946615815162659, Train Loss: 0.9535134434700012
[32m[0512 03:04:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.794660747051239, Train Loss: 0.9535071849822998
[32m[0512 03:04:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7946617007255554, Train Loss: 0.9534966349601746
[32m[0512 03:04:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7946642637252808, Train Loss: 0.9534837603569031
[32m[0512 03:04:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.794668436050415, Train Loss: 0.9534700512886047
[32m[0512 03:04:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7946737408638, Train Loss: 0.9534563422203064
[32m[0512 03:04:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7946804165840149, Train Loss: 0.9534429907798767
[32m[0512 03:04:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7946879863739014, Train Loss: 0.9534304738044739
[32m[0512 03:04:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7946964502334595, Train Loss: 0.9534187912940979
[32m[0512 03:04:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7947053909301758, Train Loss: 0.9534082412719727
[32m[0512 03:04:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7947148084640503, Train Loss: 0.9533985257148743
[32m[0512 03:04:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7947244644165039, Train Loss: 0.9533899426460266
[32m[0512 03:04:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7947343587875366, Train Loss: 0.9533821940422058
[32m[0512 03:04:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7947444915771484, Train Loss: 0.9533752799034119
[32m[0512 03:04:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7947543263435364, Train Loss: 0.9533692002296448
[32m[0512 03:04:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7947640419006348, Train Loss: 0.953363835811615
[32m[0512 03:04:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7947738170623779, Train Loss: 0.9533591270446777
[32m[0512 03:04:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7947832345962524, Train Loss: 0.9533550143241882
[32m[0512 03:04:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7947924137115479, Train Loss: 0.9533512592315674
[32m[0512 03:04:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7948012948036194, Train Loss: 0.9533479809761047
[32m[0512 03:04:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7948097586631775, Train Loss: 0.9533452391624451
[32m[0512 03:04:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7948181629180908, Train Loss: 0.9533427357673645
[32m[0512 03:04:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7948259711265564, Train Loss: 0.9533405303955078
[32m[0512 03:04:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7948334813117981, Train Loss: 0.9533386826515198
[32m[0512 03:04:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7948407530784607, Train Loss: 0.9533370137214661
[32m[0512 03:04:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7948475480079651, Train Loss: 0.9533355832099915
[32m[0512 03:04:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7948540449142456, Train Loss: 0.9533343315124512
[32m[0512 03:04:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7948600053787231, Train Loss: 0.9533331394195557
[32m[0512 03:04:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7948659062385559, Train Loss: 0.9533321857452393
[32m[0512 03:04:57 @base_main.py:38][0m --------------- Iteration 2 ---------------
[32m[0512 03:04:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0212 mins
[32m[0512 03:04:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 11.7395 mins
[32m[0512 03:04:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0204 mins
[32m[0512 03:04:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0047 mins
[32m[0512 03:04:57 @base_main.py:47][0m 2010 total steps have happened
[32m[0512 03:04:57 @base_main.py:52][0m [avg_reward]: -258.46903845936765
[32m[0512 03:04:57 @base_main.py:52][0m [update_op]: None
[32m[0512 03:04:57 @base_main.py:52][0m [train_loss]: 1.36147141456604
[32m[0512 03:04:57 @base_main.py:52][0m [val_loss]: 0.7948659062385559
[32m[0512 03:04:57 @base_main.py:52][0m [avg_train_loss]: 0.9533321857452393
[32m[0512 03:07:17 @mbmf_sampler.py:39][0m done with episode
[32m[0512 03:09:37 @mbmf_sampler.py:39][0m done with episode
[32m[0512 03:11:57 @mbmf_sampler.py:39][0m done with episode
[32m[0512 03:14:16 @mbmf_sampler.py:39][0m done with episode
[32m[0512 03:16:36 @mbmf_sampler.py:39][0m done with episode
[32m[0512 03:16:36 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0512 03:16:36 @base_trainer.py:216][0m Mean reward: -233.97122018952805
[32m[0512 03:16:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8132310509681702, Train Loss: 1.0601909160614014
[32m[0512 03:16:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8132465481758118, Train Loss: 1.0601903200149536
[32m[0512 03:16:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8132606148719788, Train Loss: 1.060189127922058
[32m[0512 03:16:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8132730722427368, Train Loss: 1.0601879358291626
[32m[0512 03:16:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.813284158706665, Train Loss: 1.060186743736267
[32m[0512 03:16:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8132937550544739, Train Loss: 1.0601856708526611
[32m[0512 03:16:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8133020401000977, Train Loss: 1.0601847171783447
[32m[0512 03:16:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8133093118667603, Train Loss: 1.0601838827133179
[32m[0512 03:16:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8133153915405273, Train Loss: 1.0601832866668701
[32m[0512 03:16:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8133206367492676, Train Loss: 1.060182809829712
[32m[0512 03:16:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8133251070976257, Train Loss: 1.0601823329925537
[32m[0512 03:16:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8133288621902466, Train Loss: 1.060181975364685
[32m[0512 03:16:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8133320212364197, Train Loss: 1.060181736946106
[32m[0512 03:16:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8133346438407898, Train Loss: 1.0601813793182373
[32m[0512 03:16:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8133369088172913, Train Loss: 1.0601812601089478
[32m[0512 03:16:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8133386969566345, Train Loss: 1.0601810216903687
[32m[0512 03:16:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8133403062820435, Train Loss: 1.0601810216903687
[32m[0512 03:16:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8133416771888733, Train Loss: 1.060180902481079
[32m[0512 03:16:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8133426904678345, Train Loss: 1.060180902481079
[32m[0512 03:16:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8133435249328613, Train Loss: 1.0601807832717896
[32m[0512 03:16:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.813344419002533, Train Loss: 1.0601806640625
[32m[0512 03:16:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8133448958396912, Train Loss: 1.0601806640625
[32m[0512 03:16:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8133456707000732, Train Loss: 1.0601805448532104
[32m[0512 03:16:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8133460283279419, Train Loss: 1.0601806640625
[32m[0512 03:16:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8133463859558105, Train Loss: 1.0601805448532104
[32m[0512 03:16:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8133467435836792, Train Loss: 1.0601805448532104
[32m[0512 03:16:38 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8133469223976135, Train Loss: 1.060180425643921
[32m[0512 03:16:38 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8133471012115479, Train Loss: 1.060180425643921
[32m[0512 03:16:38 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8133472800254822, Train Loss: 1.060180425643921
[32m[0512 03:16:38 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8133474588394165, Train Loss: 1.060180425643921
[32m[0512 03:16:38 @base_main.py:38][0m --------------- Iteration 3 ---------------
[32m[0512 03:16:38 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 11.7858 mins
[32m[0512 03:16:38 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 11.6495 mins
[32m[0512 03:16:38 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0328 mins
[32m[0512 03:16:38 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0041 mins
[32m[0512 03:16:38 @base_main.py:47][0m 3015 total steps have happened
[32m[0512 03:16:38 @base_main.py:52][0m [avg_reward]: -233.97122018952805
[32m[0512 03:16:38 @base_main.py:52][0m [update_op]: None
[32m[0512 03:16:38 @base_main.py:52][0m [train_loss]: 1.0005731582641602
[32m[0512 03:16:38 @base_main.py:52][0m [val_loss]: 0.8133474588394165
[32m[0512 03:16:38 @base_main.py:52][0m [avg_train_loss]: 1.060180425643921
[32m[0512 03:18:57 @mbmf_sampler.py:39][0m done with episode
[32m[0512 03:21:16 @mbmf_sampler.py:39][0m done with episode
[32m[0512 03:23:35 @mbmf_sampler.py:39][0m done with episode
[32m[0512 03:25:54 @mbmf_sampler.py:39][0m done with episode
[32m[0512 03:28:13 @mbmf_sampler.py:39][0m done with episode
[32m[0512 03:28:13 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0512 03:28:13 @base_trainer.py:216][0m Mean reward: -290.0402035909037
[32m[0512 03:28:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1258234977722168, Train Loss: 0.9912676811218262
[32m[0512 03:28:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1258567571640015, Train Loss: 0.9912610650062561
[32m[0512 03:28:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.125888466835022, Train Loss: 0.9912537932395935
[32m[0512 03:28:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.125918984413147, Train Loss: 0.9912474751472473
[32m[0512 03:28:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.125947117805481, Train Loss: 0.9912427067756653
[32m[0512 03:28:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1259732246398926, Train Loss: 0.991239070892334
[32m[0512 03:28:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1259970664978027, Train Loss: 0.9912365078926086
[32m[0512 03:28:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1260185241699219, Train Loss: 0.9912347197532654
[32m[0512 03:28:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.126037836074829, Train Loss: 0.9912334084510803
[32m[0512 03:28:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1260552406311035, Train Loss: 0.9912325143814087
[32m[0512 03:28:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1260709762573242, Train Loss: 0.9912319779396057
[32m[0512 03:28:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1260850429534912, Train Loss: 0.9912315011024475
[32m[0512 03:28:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.126097559928894, Train Loss: 0.9912310242652893
[32m[0512 03:28:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.126109004020691, Train Loss: 0.9912307858467102
[32m[0512 03:28:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1261191368103027, Train Loss: 0.9912304878234863
[32m[0512 03:28:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1261283159255981, Train Loss: 0.9912303686141968
[32m[0512 03:28:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1261366605758667, Train Loss: 0.9912301301956177
[32m[0512 03:28:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.126144289970398, Train Loss: 0.9912300705909729
[32m[0512 03:28:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1261509656906128, Train Loss: 0.9912299513816833
[32m[0512 03:28:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.126157283782959, Train Loss: 0.9912298321723938
[32m[0512 03:28:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1261630058288574, Train Loss: 0.9912297129631042
[32m[0512 03:28:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1261680126190186, Train Loss: 0.9912296533584595
[32m[0512 03:28:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1261729001998901, Train Loss: 0.9912297129631042
[32m[0512 03:28:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1261770725250244, Train Loss: 0.9912295937538147
[32m[0512 03:28:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1261810064315796, Train Loss: 0.9912296533584595
[32m[0512 03:28:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1261847019195557, Train Loss: 0.9912294745445251
[32m[0512 03:28:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1261879205703735, Train Loss: 0.9912294745445251
[32m[0512 03:28:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1261909008026123, Train Loss: 0.9912294745445251
[32m[0512 03:28:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1261935234069824, Train Loss: 0.9912294745445251
[32m[0512 03:28:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.126196026802063, Train Loss: 0.9912294149398804
[32m[0512 03:28:16 @base_main.py:38][0m --------------- Iteration 4 ---------------
[32m[0512 03:28:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 23.4722 mins
[32m[0512 03:28:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 11.5856 mins
[32m[0512 03:28:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0425 mins
[32m[0512 03:28:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0045 mins
[32m[0512 03:28:16 @base_main.py:47][0m 4020 total steps have happened
[32m[0512 03:28:16 @base_main.py:52][0m [avg_reward]: -290.0402035909037
[32m[0512 03:28:16 @base_main.py:52][0m [update_op]: None
[32m[0512 03:28:16 @base_main.py:52][0m [train_loss]: 0.9414239525794983
[32m[0512 03:28:16 @base_main.py:52][0m [val_loss]: 1.126196026802063
[32m[0512 03:28:16 @base_main.py:52][0m [avg_train_loss]: 0.9912294149398804
[32m[0512 03:30:35 @mbmf_sampler.py:39][0m done with episode
[32m[0512 03:32:55 @mbmf_sampler.py:39][0m done with episode
[32m[0512 03:35:14 @mbmf_sampler.py:39][0m done with episode
[32m[0512 03:37:33 @mbmf_sampler.py:39][0m done with episode
[32m[0512 03:39:52 @mbmf_sampler.py:39][0m done with episode
[32m[0512 03:39:52 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0512 03:39:52 @base_trainer.py:216][0m Mean reward: -335.0849687445469
[32m[0512 03:39:52 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3407090902328491, Train Loss: 0.9574222564697266
[32m[0512 03:39:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3407933712005615, Train Loss: 0.9574134349822998
[32m[0512 03:39:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3408818244934082, Train Loss: 0.957403302192688
[32m[0512 03:39:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.340967059135437, Train Loss: 0.9573939442634583
[32m[0512 03:39:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.34104585647583, Train Loss: 0.9573860168457031
[32m[0512 03:39:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.34111750125885, Train Loss: 0.9573795795440674
[32m[0512 03:39:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3411823511123657, Train Loss: 0.9573742747306824
[32m[0512 03:39:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3412408828735352, Train Loss: 0.9573699235916138
[32m[0512 03:39:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3412936925888062, Train Loss: 0.957366406917572
[32m[0512 03:39:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3413411378860474, Train Loss: 0.9573636651039124
[32m[0512 03:39:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3413840532302856, Train Loss: 0.9573614597320557
[32m[0512 03:39:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3414226770401, Train Loss: 0.9573594331741333
[32m[0512 03:39:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3414573669433594, Train Loss: 0.9573579430580139
[32m[0512 03:39:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3414889574050903, Train Loss: 0.9573566913604736
[32m[0512 03:39:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3415172100067139, Train Loss: 0.9573557376861572
[32m[0512 03:39:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3415427207946777, Train Loss: 0.9573548436164856
[32m[0512 03:39:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3415658473968506, Train Loss: 0.9573542475700378
[32m[0512 03:39:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3415865898132324, Train Loss: 0.9573535919189453
[32m[0512 03:39:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3416054248809814, Train Loss: 0.9573531746864319
[32m[0512 03:39:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3416224718093872, Train Loss: 0.9573527574539185
[32m[0512 03:39:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3416379690170288, Train Loss: 0.9573525190353394
[32m[0512 03:39:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3416515588760376, Train Loss: 0.9573522210121155
[32m[0512 03:39:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3416640758514404, Train Loss: 0.9573519825935364
[32m[0512 03:39:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3416754007339478, Train Loss: 0.9573519229888916
[32m[0512 03:39:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3416856527328491, Train Loss: 0.9573516845703125
[32m[0512 03:39:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.341694951057434, Train Loss: 0.9573516845703125
[32m[0512 03:39:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3417030572891235, Train Loss: 0.957351565361023
[32m[0512 03:39:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3417106866836548, Train Loss: 0.9573514461517334
[32m[0512 03:39:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3417173624038696, Train Loss: 0.9573513865470886
[32m[0512 03:39:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3417235612869263, Train Loss: 0.9573514461517334
[32m[0512 03:39:56 @base_main.py:38][0m --------------- Iteration 5 ---------------
[32m[0512 03:39:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 35.1049 mins
[32m[0512 03:39:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 11.6058 mins
[32m[0512 03:39:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0554 mins
[32m[0512 03:39:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0044 mins
[32m[0512 03:39:56 @base_main.py:47][0m 5025 total steps have happened
[32m[0512 03:39:56 @base_main.py:52][0m [avg_reward]: -335.0849687445469
[32m[0512 03:39:56 @base_main.py:52][0m [update_op]: None
[32m[0512 03:39:56 @base_main.py:52][0m [train_loss]: 0.6859533786773682
[32m[0512 03:39:56 @base_main.py:52][0m [val_loss]: 1.3417235612869263
[32m[0512 03:39:56 @base_main.py:52][0m [avg_train_loss]: 0.9573514461517334
[32m[0512 03:42:15 @mbmf_sampler.py:39][0m done with episode
[32m[0512 03:44:34 @mbmf_sampler.py:39][0m done with episode
[32m[0512 03:46:53 @mbmf_sampler.py:39][0m done with episode
[32m[0512 03:49:13 @mbmf_sampler.py:39][0m done with episode
[32m[0512 03:51:32 @mbmf_sampler.py:39][0m done with episode
[32m[0512 03:51:32 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0512 03:51:32 @base_trainer.py:216][0m Mean reward: -356.218257291554
[32m[0512 03:51:32 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.4777756929397583, Train Loss: 0.922284722328186
[32m[0512 03:51:32 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.4778659343719482, Train Loss: 0.9222751259803772
[32m[0512 03:51:32 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.477960228919983, Train Loss: 0.9222643375396729
[32m[0512 03:51:32 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.478048324584961, Train Loss: 0.922254741191864
[32m[0512 03:51:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.4781278371810913, Train Loss: 0.9222469925880432
[32m[0512 03:51:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.4781984090805054, Train Loss: 0.9222409725189209
[32m[0512 03:51:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.4782607555389404, Train Loss: 0.9222362041473389
[32m[0512 03:51:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.478315830230713, Train Loss: 0.9222325682640076
[32m[0512 03:51:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.4783644676208496, Train Loss: 0.922229528427124
[32m[0512 03:51:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.478407621383667, Train Loss: 0.9222273230552673
[32m[0512 03:51:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.4784457683563232, Train Loss: 0.9222254157066345
[32m[0512 03:51:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.4784795045852661, Train Loss: 0.9222241044044495
[32m[0512 03:51:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.4785093069076538, Train Loss: 0.9222230315208435
[32m[0512 03:51:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.4785356521606445, Train Loss: 0.9222221374511719
[32m[0512 03:51:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.4785590171813965, Train Loss: 0.9222215414047241
[32m[0512 03:51:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.4785795211791992, Train Loss: 0.9222210049629211
[32m[0512 03:51:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.478597640991211, Train Loss: 0.9222204685211182
[32m[0512 03:51:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.4786137342453003, Train Loss: 0.9222201704978943
[32m[0512 03:51:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.4786276817321777, Train Loss: 0.92221999168396
[32m[0512 03:51:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.478640079498291, Train Loss: 0.9222198724746704
[32m[0512 03:51:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.4786510467529297, Train Loss: 0.9222196340560913
[32m[0512 03:51:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.4786607027053833, Train Loss: 0.922219455242157
[32m[0512 03:51:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.4786689281463623, Train Loss: 0.9222193360328674
[32m[0512 03:51:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.478676438331604, Train Loss: 0.9222192764282227
[32m[0512 03:51:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.4786828756332397, Train Loss: 0.9222192168235779
[32m[0512 03:51:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.4786887168884277, Train Loss: 0.9222192168235779
[32m[0512 03:51:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.4786936044692993, Train Loss: 0.9222192168235779
[32m[0512 03:51:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.4786980152130127, Train Loss: 0.9222190976142883
[32m[0512 03:51:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.4787018299102783, Train Loss: 0.9222190976142883
[32m[0512 03:51:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.4787052869796753, Train Loss: 0.9222190380096436
[32m[0512 03:51:36 @base_main.py:38][0m --------------- Iteration 6 ---------------
[32m[0512 03:51:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 46.7707 mins
[32m[0512 03:51:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 11.5988 mins
[32m[0512 03:51:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0669 mins
[32m[0512 03:51:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0042 mins
[32m[0512 03:51:36 @base_main.py:47][0m 6030 total steps have happened
[32m[0512 03:51:36 @base_main.py:52][0m [avg_reward]: -356.218257291554
[32m[0512 03:51:36 @base_main.py:52][0m [update_op]: None
[32m[0512 03:51:36 @base_main.py:52][0m [train_loss]: 0.8383361101150513
[32m[0512 03:51:36 @base_main.py:52][0m [val_loss]: 1.4787052869796753
[32m[0512 03:51:36 @base_main.py:52][0m [avg_train_loss]: 0.9222190380096436
[32m[0512 03:53:56 @mbmf_sampler.py:39][0m done with episode
[32m[0512 03:56:15 @mbmf_sampler.py:39][0m done with episode
[32m[0512 03:58:34 @mbmf_sampler.py:39][0m done with episode
[32m[0512 04:00:54 @mbmf_sampler.py:39][0m done with episode
[32m[0512 04:03:13 @mbmf_sampler.py:39][0m done with episode
[32m[0512 04:03:13 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0512 04:03:13 @base_trainer.py:216][0m Mean reward: -296.6755474289995
[32m[0512 04:03:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8582158088684082, Train Loss: 1.0227121114730835
[32m[0512 04:03:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8582455515861511, Train Loss: 1.0227075815200806
[32m[0512 04:03:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8582623600959778, Train Loss: 1.0227038860321045
[32m[0512 04:03:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8582706451416016, Train Loss: 1.0227012634277344
[32m[0512 04:03:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8582744598388672, Train Loss: 1.0226993560791016
[32m[0512 04:03:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8582760095596313, Train Loss: 1.0226982831954956
[32m[0512 04:03:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8582767248153687, Train Loss: 1.0226974487304688
[32m[0512 04:03:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8582770228385925, Train Loss: 1.022696852684021
[32m[0512 04:03:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8582772016525269, Train Loss: 1.0226963758468628
[32m[0512 04:03:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8582773804664612, Train Loss: 1.0226961374282837
[32m[0512 04:03:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8582775592803955, Train Loss: 1.0226958990097046
[32m[0512 04:03:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8582776784896851, Train Loss: 1.022695779800415
[32m[0512 04:03:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8582778573036194, Train Loss: 1.0226956605911255
[32m[0512 04:03:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8582780361175537, Train Loss: 1.022695541381836
[32m[0512 04:03:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.858278214931488, Train Loss: 1.0226954221725464
[32m[0512 04:03:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8582783937454224, Train Loss: 1.022695541381836
[32m[0512 04:03:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8582785129547119, Train Loss: 1.0226954221725464
[32m[0512 04:03:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8582786917686462, Train Loss: 1.0226954221725464
[32m[0512 04:03:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8582788705825806, Train Loss: 1.0226954221725464
[32m[0512 04:03:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8582788705825806, Train Loss: 1.022695541381836
[32m[0512 04:03:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8582790493965149, Train Loss: 1.0226954221725464
[32m[0512 04:03:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8582791090011597, Train Loss: 1.0226954221725464
[32m[0512 04:03:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8582791090011597, Train Loss: 1.0226954221725464
[32m[0512 04:03:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.858279287815094, Train Loss: 1.0226954221725464
[32m[0512 04:03:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8582794070243835, Train Loss: 1.0226954221725464
[32m[0512 04:03:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8582794070243835, Train Loss: 1.0226954221725464
[32m[0512 04:03:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8582794070243835, Train Loss: 1.0226954221725464
[32m[0512 04:03:18 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8582795858383179, Train Loss: 1.0226954221725464
[32m[0512 04:03:18 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8582795858383179, Train Loss: 1.0226954221725464
[32m[0512 04:03:18 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8582797050476074, Train Loss: 1.0226954221725464
[32m[0512 04:03:18 @base_main.py:38][0m --------------- Iteration 7 ---------------
[32m[0512 04:03:18 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 58.4406 mins
[32m[0512 04:03:18 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 11.6184 mins
[32m[0512 04:03:18 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0777 mins
[32m[0512 04:03:18 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0046 mins
[32m[0512 04:03:18 @base_main.py:47][0m 7035 total steps have happened
[32m[0512 04:03:18 @base_main.py:52][0m [avg_reward]: -296.6755474289995
[32m[0512 04:03:18 @base_main.py:52][0m [update_op]: None
[32m[0512 04:03:18 @base_main.py:52][0m [train_loss]: 1.8901584148406982
[32m[0512 04:03:18 @base_main.py:52][0m [val_loss]: 0.8582797050476074
[32m[0512 04:03:18 @base_main.py:52][0m [avg_train_loss]: 1.0226954221725464
[32m[0512 04:03:18 @mbmf_trainer.py:160][0m Mean reward: -304.85022698512023
[32m[0512 04:03:18 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.22848039865493774, Train Loss: 0.2227943390607834
[32m[0512 04:03:18 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.228692889213562, Train Loss: 0.2226252555847168
[32m[0512 04:03:18 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.22882430255413055, Train Loss: 0.22257672250270844
[32m[0512 04:03:18 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.22888650000095367, Train Loss: 0.2225525826215744
[32m[0512 04:03:18 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.22891640663146973, Train Loss: 0.22252963483333588
[32m[0512 04:03:18 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.22893674671649933, Train Loss: 0.2225060611963272
[32m[0512 04:03:19 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.22895504534244537, Train Loss: 0.2224828004837036
[32m[0512 04:03:19 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.22897233068943024, Train Loss: 0.22246038913726807
[32m[0512 04:03:19 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.22898821532726288, Train Loss: 0.22243888676166534
[32m[0512 04:03:19 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.22900262475013733, Train Loss: 0.2224181890487671
[32m[0512 04:03:19 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.2290157526731491, Train Loss: 0.22239811718463898
[32m[0512 04:03:19 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.22902797162532806, Train Loss: 0.22237856686115265
[32m[0512 04:03:19 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.22903956472873688, Train Loss: 0.22235946357250214
[32m[0512 04:03:19 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.2290506362915039, Train Loss: 0.22234082221984863
[32m[0512 04:03:19 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.22906136512756348, Train Loss: 0.22232259809970856
[32m[0512 04:03:19 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.22907179594039917, Train Loss: 0.22230488061904907
[32m[0512 04:03:19 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.22908204793930054, Train Loss: 0.22228758037090302
[32m[0512 04:03:19 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.22909212112426758, Train Loss: 0.22227071225643158
[32m[0512 04:03:19 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.22910207509994507, Train Loss: 0.22225423157215118
[32m[0512 04:03:19 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.22911196947097778, Train Loss: 0.222238227725029
[32m[0512 04:03:19 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.2291218340396881, Train Loss: 0.22222258150577545
[32m[0512 04:03:19 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.22913162410259247, Train Loss: 0.22220736742019653
[32m[0512 04:03:19 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.22914138436317444, Train Loss: 0.22219258546829224
[32m[0512 04:03:19 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.2291511595249176, Train Loss: 0.22217820584774017
[32m[0512 04:03:19 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.22916099429130554, Train Loss: 0.22216419875621796
[32m[0512 04:03:19 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.22917088866233826, Train Loss: 0.22215062379837036
[32m[0512 04:03:19 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.22918078303337097, Train Loss: 0.22213739156723022
[32m[0512 04:03:19 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.22919076681137085, Train Loss: 0.22212453186511993
[32m[0512 04:03:19 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.2292007952928543, Train Loss: 0.22211205959320068
[32m[0512 04:03:19 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.22921091318130493, Train Loss: 0.22209995985031128
[32m[0512 04:03:19 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.22922110557556152, Train Loss: 0.22208820283412933
[32m[0512 04:03:19 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.2292313575744629, Train Loss: 0.22207677364349365
[32m[0512 04:03:19 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.2292417585849762, Train Loss: 0.22206567227840424
[32m[0512 04:03:19 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.2292521446943283, Train Loss: 0.22205489873886108
[32m[0512 04:03:19 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.22926269471645355, Train Loss: 0.2220444232225418
[32m[0512 04:03:19 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.2292732447385788, Train Loss: 0.2220342755317688
[32m[0512 04:03:19 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.2292838990688324, Train Loss: 0.22202439606189728
[32m[0512 04:03:19 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.22929464280605316, Train Loss: 0.22201482951641083
[32m[0512 04:03:19 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.2293054163455963, Train Loss: 0.22200548648834229
[32m[0512 04:03:19 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.22931629419326782, Train Loss: 0.22199641168117523
[32m[0512 04:03:19 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.22932720184326172, Train Loss: 0.2219875454902649
[32m[0512 04:03:20 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.2293381690979004, Train Loss: 0.22197896242141724
[32m[0512 04:03:20 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.22934921085834503, Train Loss: 0.22197061777114868
[32m[0512 04:03:20 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.22936023771762848, Train Loss: 0.22196245193481445
[32m[0512 04:03:20 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.2293713390827179, Train Loss: 0.22195450961589813
[32m[0512 04:03:20 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.2293824404478073, Train Loss: 0.22194676101207733
[32m[0512 04:03:20 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.2293935865163803, Train Loss: 0.22193916141986847
[32m[0512 04:03:20 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.2294047623872757, Train Loss: 0.22193177044391632
[32m[0512 04:03:20 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.22941593825817108, Train Loss: 0.2219245582818985
[32m[0512 04:03:20 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.22942714393138885, Train Loss: 0.22191746532917023
[32m[0512 04:03:20 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.22943833470344543, Train Loss: 0.2219105362892151
[32m[0512 04:03:20 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.22944951057434082, Train Loss: 0.22190378606319427
[32m[0512 04:03:20 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.2294606864452362, Train Loss: 0.22189712524414062
[32m[0512 04:03:20 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.22947189211845398, Train Loss: 0.2218906134366989
[32m[0512 04:03:20 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.22948306798934937, Train Loss: 0.22188423573970795
[32m[0512 04:03:20 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.22949419915676117, Train Loss: 0.22187793254852295
[32m[0512 04:03:20 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.22950531542301178, Train Loss: 0.22187180817127228
[32m[0512 04:03:20 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.22951647639274597, Train Loss: 0.2218657284975052
[32m[0512 04:03:20 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.2295275628566742, Train Loss: 0.22185976803302765
[32m[0512 04:03:20 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.22953863441944122, Train Loss: 0.22185391187667847
[32m[0512 04:03:20 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.22954964637756348, Train Loss: 0.22184813022613525
[32m[0512 04:03:20 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.22956067323684692, Train Loss: 0.2218424528837204
[32m[0512 04:03:20 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.2295716553926468, Train Loss: 0.22183680534362793
[32m[0512 04:03:20 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.22958256304264069, Train Loss: 0.221831277012825
[32m[0512 04:03:20 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.22959347069263458, Train Loss: 0.22182579338550568
[32m[0512 04:03:20 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.2296043336391449, Train Loss: 0.2218204140663147
[32m[0512 04:03:20 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.22961515188217163, Train Loss: 0.22181503474712372
[32m[0512 04:03:20 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.2296259105205536, Train Loss: 0.2218097597360611
[32m[0512 04:03:20 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.22963665425777435, Train Loss: 0.22180451452732086
[32m[0512 04:03:20 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.22964735329151154, Train Loss: 0.22179937362670898
[32m[0512 04:03:20 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.22965797781944275, Train Loss: 0.2217942476272583
[32m[0512 04:03:20 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.22966855764389038, Train Loss: 0.2217891663312912
[32m[0512 04:03:20 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.22967910766601562, Train Loss: 0.22178412973880768
[32m[0512 04:03:20 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.2296896129846573, Train Loss: 0.22177916765213013
[32m[0512 04:03:20 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.22970007359981537, Train Loss: 0.221774160861969
[32m[0512 04:03:20 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.22971047461032867, Train Loss: 0.2217692732810974
[32m[0512 04:03:20 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.22972087562084198, Train Loss: 0.22176440060138702
[32m[0512 04:03:21 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.22973115742206573, Train Loss: 0.2217596024274826
[32m[0512 04:03:21 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.22974145412445068, Train Loss: 0.2217547744512558
[32m[0512 04:03:21 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.22975167632102966, Train Loss: 0.22175002098083496
[32m[0512 04:03:21 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.22976180911064148, Train Loss: 0.22174525260925293
[32m[0512 04:03:21 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.2297719419002533, Train Loss: 0.22174054384231567
[32m[0512 04:03:21 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.22978204488754272, Train Loss: 0.221735879778862
[32m[0512 04:03:21 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.22979207336902618, Train Loss: 0.22173118591308594
[32m[0512 04:03:21 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.22980202734470367, Train Loss: 0.22172658145427704
[32m[0512 04:03:21 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.22981199622154236, Train Loss: 0.22172196209430695
[32m[0512 04:03:21 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.2298218458890915, Train Loss: 0.22171737253665924
[32m[0512 04:03:21 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.22983168065547943, Train Loss: 0.22171281278133392
[32m[0512 04:03:21 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.2298414707183838, Train Loss: 0.2217082530260086
[32m[0512 04:03:21 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.22985118627548218, Train Loss: 0.22170372307300568
[32m[0512 04:03:21 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.22986090183258057, Train Loss: 0.22169922292232513
[32m[0512 04:03:21 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.22987055778503418, Train Loss: 0.2216947227716446
[32m[0512 04:03:21 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.22988012433052063, Train Loss: 0.22169025242328644
[32m[0512 04:03:21 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.2298896759748459, Train Loss: 0.22168581187725067
[32m[0512 04:03:21 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.22989918291568756, Train Loss: 0.2216813564300537
[32m[0512 04:03:21 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.22990864515304565, Train Loss: 0.22167690098285675
[32m[0512 04:03:21 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.22991806268692017, Train Loss: 0.22167252004146576
[32m[0512 04:03:21 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.2299274355173111, Train Loss: 0.22166810929775238
[32m[0512 04:03:21 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.22993674874305725, Train Loss: 0.2216637134552002
[32m[0512 04:03:21 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.2299460470676422, Train Loss: 0.221659317612648
[32m[0512 04:03:21 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.2299552708864212, Train Loss: 0.2216549664735794
[32m[0512 04:03:21 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.2299644649028778, Train Loss: 0.2216506004333496
[32m[0512 04:03:21 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.22997362911701202, Train Loss: 0.221646249294281
[32m[0512 04:03:21 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.22998271882534027, Train Loss: 0.2216418981552124
[32m[0512 04:03:21 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.22999179363250732, Train Loss: 0.22163760662078857
[32m[0512 04:03:21 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.2300008237361908, Train Loss: 0.22163327038288116
[32m[0512 04:03:21 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.2300097942352295, Train Loss: 0.22162896394729614
[32m[0512 04:03:21 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.2300187200307846, Train Loss: 0.22162467241287231
[32m[0512 04:03:21 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.23002763092517853, Train Loss: 0.2216203659772873
[32m[0512 04:03:21 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.23003649711608887, Train Loss: 0.22161607444286346
[32m[0512 04:03:21 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.23004531860351562, Train Loss: 0.22161179780960083
[32m[0512 04:03:21 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.23005411028862, Train Loss: 0.2216075211763382
[32m[0512 04:03:21 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.2300628423690796, Train Loss: 0.22160322964191437
[32m[0512 04:03:21 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.2300715446472168, Train Loss: 0.22159899771213531
[32m[0512 04:03:22 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.23008018732070923, Train Loss: 0.22159475088119507
[32m[0512 04:03:22 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.23008881509304047, Train Loss: 0.22159045934677124
[32m[0512 04:03:22 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.23009739816188812, Train Loss: 0.22158627212047577
[32m[0512 04:03:22 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.2301059514284134, Train Loss: 0.22158201038837433
[32m[0512 04:03:22 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.23011445999145508, Train Loss: 0.22157776355743408
[32m[0512 04:03:22 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.23012296855449677, Train Loss: 0.22157353162765503
[32m[0512 04:03:22 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.2301313877105713, Train Loss: 0.22156929969787598
[32m[0512 04:03:22 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.23013976216316223, Train Loss: 0.22156508266925812
[32m[0512 04:03:22 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.23014813661575317, Train Loss: 0.22156088054180145
[32m[0512 04:03:22 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.23015645146369934, Train Loss: 0.2215566635131836
[32m[0512 04:03:22 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.2301647961139679, Train Loss: 0.22155243158340454
[32m[0512 04:03:22 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.2301730364561081, Train Loss: 0.22154821455478668
[32m[0512 04:03:22 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.2301812469959259, Train Loss: 0.2215440273284912
[32m[0512 04:03:22 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.23018942773342133, Train Loss: 0.22153984010219574
[32m[0512 04:03:22 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.23019760847091675, Train Loss: 0.22153562307357788
[32m[0512 04:03:22 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.230205699801445, Train Loss: 0.2215314358472824
[32m[0512 04:03:22 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.23021377623081207, Train Loss: 0.22152721881866455
[32m[0512 04:03:22 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.23022185266017914, Train Loss: 0.22152303159236908
[32m[0512 04:03:22 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.23022986948490143, Train Loss: 0.2215188592672348
[32m[0512 04:03:22 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.23023787140846252, Train Loss: 0.22151465713977814
[32m[0512 04:03:22 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.23024581372737885, Train Loss: 0.22151048481464386
[32m[0512 04:03:22 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.23025371134281158, Train Loss: 0.22150631248950958
[32m[0512 04:03:22 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.2302616387605667, Train Loss: 0.2215021252632141
[32m[0512 04:03:22 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.23026947677135468, Train Loss: 0.22149793803691864
[32m[0512 04:03:22 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.23027728497982025, Train Loss: 0.22149376571178436
[32m[0512 04:03:22 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.23028506338596344, Train Loss: 0.22148959338665009
[32m[0512 04:03:22 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.23029285669326782, Train Loss: 0.221485435962677
[32m[0512 04:03:22 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.23030057549476624, Train Loss: 0.22148121893405914
[32m[0512 04:03:22 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.23030827939510345, Train Loss: 0.22147709131240845
[32m[0512 04:03:22 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.23031596839427948, Train Loss: 0.22147291898727417
[32m[0512 04:03:22 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.23032358288764954, Train Loss: 0.2214687615633011
[32m[0512 04:03:22 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.23033122718334198, Train Loss: 0.2214645892381668
[32m[0512 04:03:22 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.23033879697322845, Train Loss: 0.22146041691303253
[32m[0512 04:03:22 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.23034635186195374, Train Loss: 0.22145628929138184
[32m[0512 04:03:22 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.23035389184951782, Train Loss: 0.22145211696624756
[32m[0512 04:03:23 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.23036140203475952, Train Loss: 0.22144795954227448
[32m[0512 04:03:23 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.23036883771419525, Train Loss: 0.22144381701946259
[32m[0512 04:03:23 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.23037628829479218, Train Loss: 0.2214396595954895
[32m[0512 04:03:23 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.23038366436958313, Train Loss: 0.2214355319738388
[32m[0512 04:03:23 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.23039108514785767, Train Loss: 0.22143135964870453
[32m[0512 04:03:23 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.23039840161800385, Train Loss: 0.22142721712589264
[32m[0512 04:03:23 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.23040573298931122, Train Loss: 0.22142308950424194
[32m[0512 04:03:23 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.2304130345582962, Train Loss: 0.22141893208026886
[32m[0512 04:03:23 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.2304203063249588, Train Loss: 0.22141480445861816
[32m[0512 04:03:23 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.230427548289299, Train Loss: 0.22141067683696747
[32m[0512 04:03:23 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.23043476045131683, Train Loss: 0.22140651941299438
[32m[0512 04:03:23 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.23044197261333466, Train Loss: 0.22140240669250488
[32m[0512 04:03:23 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.2304491251707077, Train Loss: 0.2213982343673706
[32m[0512 04:03:23 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.23045626282691956, Train Loss: 0.2213941216468811
[32m[0512 04:03:23 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.23046338558197021, Train Loss: 0.2213900089263916
[32m[0512 04:03:23 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.2304704487323761, Train Loss: 0.22138585150241852
[32m[0512 04:03:23 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.23047751188278198, Train Loss: 0.22138173878192902
[32m[0512 04:03:23 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.23048457503318787, Train Loss: 0.22137761116027832
[32m[0512 04:03:23 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.23049156367778778, Train Loss: 0.22137351334095
[32m[0512 04:03:23 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.2304985523223877, Train Loss: 0.22136938571929932
[32m[0512 04:03:23 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.23050548136234283, Train Loss: 0.22136527299880981
[32m[0512 04:03:23 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.23051242530345917, Train Loss: 0.22136114537715912
[32m[0512 04:03:23 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.23051932454109192, Train Loss: 0.22135703265666962
[32m[0512 04:03:23 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.23052622377872467, Train Loss: 0.2213529348373413
[32m[0512 04:03:23 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.23053310811519623, Train Loss: 0.2213488221168518
[32m[0512 04:03:23 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.23053991794586182, Train Loss: 0.2213447093963623
[32m[0512 04:03:23 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.2305467426776886, Train Loss: 0.22134064137935638
[32m[0512 04:03:23 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.2305535078048706, Train Loss: 0.22133652865886688
[32m[0512 04:03:23 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.2305602878332138, Train Loss: 0.22133241593837738
[32m[0512 04:03:23 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.23056703805923462, Train Loss: 0.22132831811904907
[32m[0512 04:03:23 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.23057374358177185, Train Loss: 0.22132425010204315
[32m[0512 04:03:23 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.23058044910430908, Train Loss: 0.22132015228271484
[32m[0512 04:03:23 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.23058710992336273, Train Loss: 0.22131605446338654
[32m[0512 04:03:23 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.23059377074241638, Train Loss: 0.22131197154521942
[32m[0512 04:03:24 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.23060038685798645, Train Loss: 0.2213078886270523
[32m[0512 04:03:24 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.23060698807239532, Train Loss: 0.2213038206100464
[32m[0512 04:03:24 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.230613574385643, Train Loss: 0.22129972279071808
[32m[0512 04:03:24 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.2306201159954071, Train Loss: 0.22129565477371216
[32m[0512 04:03:24 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.23062662780284882, Train Loss: 0.22129158675670624
[32m[0512 04:03:24 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.2306331843137741, Train Loss: 0.2212875336408615
[32m[0512 04:03:24 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.23063965141773224, Train Loss: 0.2212834358215332
[32m[0512 04:03:24 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.23064611852169037, Train Loss: 0.22127938270568848
[32m[0512 04:03:24 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.2306525707244873, Train Loss: 0.22127531468868256
[32m[0512 04:03:24 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.23065902292728424, Train Loss: 0.22127126157283783
[32m[0512 04:03:24 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.2306654006242752, Train Loss: 0.2212672084569931
[32m[0512 04:03:24 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.23067180812358856, Train Loss: 0.22126315534114838
[32m[0512 04:03:24 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.23067814111709595, Train Loss: 0.22125911712646484
[32m[0512 04:03:24 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.23068447411060333, Train Loss: 0.22125506401062012
[32m[0512 04:03:24 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.2306908220052719, Train Loss: 0.2212510108947754
[32m[0512 04:03:24 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.23069709539413452, Train Loss: 0.22124700248241425
[32m[0512 04:03:24 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.23070339858531952, Train Loss: 0.22124294936656952
[32m[0512 04:03:24 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.23070965707302094, Train Loss: 0.2212388962507248
[32m[0512 04:03:24 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.23071588575839996, Train Loss: 0.22123490273952484
[32m[0512 04:03:24 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.230722114443779, Train Loss: 0.2212308645248413
[32m[0512 04:03:24 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.23072829842567444, Train Loss: 0.22122682631015778
[32m[0512 04:03:24 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.23073448240756989, Train Loss: 0.22122281789779663
[32m[0512 04:03:24 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.23074063658714294, Train Loss: 0.2212187796831131
[32m[0512 04:03:24 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.230746790766716, Train Loss: 0.22121478617191315
[32m[0512 04:03:24 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.23075291514396667, Train Loss: 0.221210777759552
[32m[0512 04:03:24 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.23075899481773376, Train Loss: 0.22120676934719086
[32m[0512 04:03:24 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.23076507449150085, Train Loss: 0.22120274603366852
[32m[0512 04:03:24 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.23077112436294556, Train Loss: 0.22119875252246857
[32m[0512 04:03:24 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.23077715933322906, Train Loss: 0.22119475901126862
[32m[0512 04:03:24 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.23078317940235138, Train Loss: 0.22119076550006866
[32m[0512 04:03:24 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.2307891845703125, Train Loss: 0.22118675708770752
[32m[0512 04:03:24 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.23079515993595123, Train Loss: 0.22118276357650757
[32m[0512 04:03:24 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.23080112040042877, Train Loss: 0.2211787849664688
[32m[0512 04:03:24 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.2308070957660675, Train Loss: 0.22117479145526886
[32m[0512 04:03:24 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.23081301152706146, Train Loss: 0.2211708277463913
[32m[0512 04:03:25 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.2308189421892166, Train Loss: 0.22116684913635254
[32m[0512 04:03:25 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.23082484304904938, Train Loss: 0.22116287052631378
[32m[0512 04:03:25 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.23083071410655975, Train Loss: 0.22115890681743622
[32m[0512 04:03:25 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.23083654046058655, Train Loss: 0.22115492820739746
[32m[0512 04:03:25 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.23084236681461334, Train Loss: 0.2211509793996811
[32m[0512 04:03:25 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.23084822297096252, Train Loss: 0.22114701569080353
[32m[0512 04:03:25 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.23085401952266693, Train Loss: 0.22114306688308716
[32m[0512 04:03:25 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.23085981607437134, Train Loss: 0.22113913297653198
[32m[0512 04:03:25 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.23086556792259216, Train Loss: 0.2211351841688156
[32m[0512 04:03:25 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.2308712899684906, Train Loss: 0.22113122045993805
[32m[0512 04:03:25 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.23087704181671143, Train Loss: 0.22112727165222168
[32m[0512 04:03:25 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.23088274896144867, Train Loss: 0.2211233377456665
[32m[0512 04:03:25 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.23088844120502472, Train Loss: 0.22111938893795013
[32m[0512 04:03:25 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.23089414834976196, Train Loss: 0.22111546993255615
[32m[0512 04:03:25 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.23089981079101562, Train Loss: 0.22111153602600098
[32m[0512 04:03:25 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.2309054583311081, Train Loss: 0.221107617020607
[32m[0512 04:03:25 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.23091107606887817, Train Loss: 0.22110368311405182
[32m[0512 04:03:25 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.23091672360897064, Train Loss: 0.22109977900981903
[32m[0512 04:03:25 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.23092232644557953, Train Loss: 0.22109586000442505
[32m[0512 04:03:25 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.23092788457870483, Train Loss: 0.22109194099903107
[32m[0512 04:03:25 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.23093345761299133, Train Loss: 0.2210880070924759
[32m[0512 04:03:25 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.23093901574611664, Train Loss: 0.2210841178894043
[32m[0512 04:03:25 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.23094452917575836, Train Loss: 0.22108019888401031
[32m[0512 04:03:25 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.23095005750656128, Train Loss: 0.22107630968093872
[32m[0512 04:03:25 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.230955570936203, Train Loss: 0.22107242047786713
[32m[0512 04:03:25 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.23096103966236115, Train Loss: 0.22106851637363434
[32m[0512 04:03:25 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.23096653819084167, Train Loss: 0.22106462717056274
[32m[0512 04:03:25 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.23097196221351624, Train Loss: 0.22106075286865234
[32m[0512 04:03:25 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.23097741603851318, Train Loss: 0.22105687856674194
[32m[0512 04:03:25 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.23098285496234894, Train Loss: 0.22105298936367035
[32m[0512 04:03:25 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.2309882938861847, Train Loss: 0.22104911506175995
[32m[0512 04:03:25 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.23099367320537567, Train Loss: 0.22104521095752716
[32m[0512 04:03:25 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.23099905252456665, Train Loss: 0.22104133665561676
[32m[0512 04:03:25 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.23100443184375763, Train Loss: 0.22103749215602875
[32m[0512 04:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.23100979626178741, Train Loss: 0.22103363275527954
[32m[0512 04:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.23101511597633362, Train Loss: 0.22102975845336914
[32m[0512 04:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.23102043569087982, Train Loss: 0.22102589905261993
[32m[0512 04:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.23102575540542603, Train Loss: 0.22102205455303192
[32m[0512 04:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.23103103041648865, Train Loss: 0.22101818025112152
[32m[0512 04:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.23103632032871246, Train Loss: 0.2210143357515335
[32m[0512 04:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.23104159533977509, Train Loss: 0.2210105061531067
[32m[0512 04:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.23104684054851532, Train Loss: 0.22100664675235748
[32m[0512 04:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.23105211555957794, Train Loss: 0.22100280225276947
[32m[0512 04:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.2310573160648346, Train Loss: 0.22099898755550385
[32m[0512 04:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.23106251657009125, Train Loss: 0.22099512815475464
[32m[0512 04:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.2310677319765091, Train Loss: 0.22099129855632782
[32m[0512 04:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.23107293248176575, Train Loss: 0.2209874540567398
[32m[0512 04:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.2310781031847, Train Loss: 0.22098363935947418
[32m[0512 04:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.2310832440853119, Train Loss: 0.22097980976104736
[32m[0512 04:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.23108838498592377, Train Loss: 0.22097599506378174
[32m[0512 04:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.23109355568885803, Train Loss: 0.2209721952676773
[32m[0512 04:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.23109865188598633, Train Loss: 0.2209683656692505
[32m[0512 04:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.23110376298427582, Train Loss: 0.22096455097198486
[32m[0512 04:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.2311088740825653, Train Loss: 0.22096073627471924
[32m[0512 04:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.23111394047737122, Train Loss: 0.2209569364786148
[32m[0512 04:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.2311190366744995, Train Loss: 0.22095312178134918
[32m[0512 04:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.23112407326698303, Train Loss: 0.22094933688640594
[32m[0512 04:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.23112912476062775, Train Loss: 0.2209455370903015
[32m[0512 04:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.23113419115543365, Train Loss: 0.2209417223930359
[32m[0512 04:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.2311391830444336, Train Loss: 0.22093795239925385
[32m[0512 04:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.23114417493343353, Train Loss: 0.22093415260314941
[32m[0512 04:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.23114921152591705, Train Loss: 0.2209303379058838
[32m[0512 04:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.231154203414917, Train Loss: 0.22092658281326294
[32m[0512 04:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.23115916550159454, Train Loss: 0.2209227830171585
[32m[0512 04:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.2311641424894333, Train Loss: 0.22091899812221527
[32m[0512 04:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.23116908967494965, Train Loss: 0.22091521322727203
[32m[0512 04:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.2311740219593048, Train Loss: 0.22091144323349
[32m[0512 04:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.23117896914482117, Train Loss: 0.22090768814086914
[32m[0512 04:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.23118387162685394, Train Loss: 0.2209039330482483
[32m[0512 04:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.23118877410888672, Train Loss: 0.22090013325214386
[32m[0512 04:03:27 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.23119370639324188, Train Loss: 0.220896378159523
[32m[0512 04:03:27 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.23119859397411346, Train Loss: 0.22089260816574097
[32m[0512 04:03:27 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.23120345175266266, Train Loss: 0.22088885307312012
[32m[0512 04:03:27 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.23120833933353424, Train Loss: 0.22088508307933807
[32m[0512 04:03:27 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.23121318221092224, Train Loss: 0.22088134288787842
[32m[0512 04:03:27 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.23121803998947144, Train Loss: 0.22087757289409637
[32m[0512 04:03:27 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.23122288286685944, Train Loss: 0.22087383270263672
[32m[0512 04:03:27 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.23122768104076385, Train Loss: 0.22087009251117706
[32m[0512 04:03:27 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.23123246431350708, Train Loss: 0.2208663374185562
[32m[0512 04:03:27 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.23123730719089508, Train Loss: 0.22086258232593536
[32m[0512 04:03:27 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.2312421053647995, Train Loss: 0.2208588570356369
[32m[0512 04:03:27 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.23124688863754272, Train Loss: 0.22085511684417725
[32m[0512 04:03:27 @mbmf_sampler.py:98][0m Finished 9th episode
[32m[0512 04:03:27 @mbmf_sampler.py:102][0m 1809 timesteps from 9 episodes collected
[32m[0512 04:24:20 @mbmf_trainer.py:160][0m Mean reward: -348.1978342034416
[32m[0512 04:24:20 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.22059732675552368, Train Loss: 0.21746373176574707
[32m[0512 04:24:20 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.22077538073062897, Train Loss: 0.21733365952968597
[32m[0512 04:24:20 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.22083936631679535, Train Loss: 0.21728834509849548
[32m[0512 04:24:20 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.22089441120624542, Train Loss: 0.21726632118225098
[32m[0512 04:24:20 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.22094781696796417, Train Loss: 0.21724098920822144
[32m[0512 04:24:20 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.22098766267299652, Train Loss: 0.21721778810024261
[32m[0512 04:24:20 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.22102101147174835, Train Loss: 0.21719971299171448
[32m[0512 04:24:20 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.22105276584625244, Train Loss: 0.21718446910381317
[32m[0512 04:24:20 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.22108221054077148, Train Loss: 0.2171703726053238
[32m[0512 04:24:20 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.22110868990421295, Train Loss: 0.21715736389160156
[32m[0512 04:24:20 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.22113245725631714, Train Loss: 0.21714548766613007
[32m[0512 04:24:20 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.2211538851261139, Train Loss: 0.2171345055103302
[32m[0512 04:24:20 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.22117318212985992, Train Loss: 0.21712420880794525
[32m[0512 04:24:20 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.22119061648845673, Train Loss: 0.21711453795433044
[32m[0512 04:24:20 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.22120636701583862, Train Loss: 0.21710532903671265
[32m[0512 04:24:21 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.22122064232826233, Train Loss: 0.21709661185741425
[32m[0512 04:24:21 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.22123362123966217, Train Loss: 0.21708829700946808
[32m[0512 04:24:21 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.22124549746513367, Train Loss: 0.2170802801847458
[32m[0512 04:24:21 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.22125627100467682, Train Loss: 0.21707254648208618
[32m[0512 04:24:21 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.22126615047454834, Train Loss: 0.21706511080265045
[32m[0512 04:24:21 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.221275195479393, Train Loss: 0.21705792844295502
[32m[0512 04:24:21 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.22128351032733917, Train Loss: 0.21705089509487152
[32m[0512 04:24:21 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.2212912142276764, Train Loss: 0.21704410016536713
[32m[0512 04:24:21 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.22129829227924347, Train Loss: 0.21703746914863586
[32m[0512 04:24:21 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.22130484879016876, Train Loss: 0.21703095734119415
[32m[0512 04:24:21 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.22131095826625824, Train Loss: 0.21702462434768677
[32m[0512 04:24:21 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.2213166058063507, Train Loss: 0.21701839566230774
[32m[0512 04:24:21 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.22132189571857452, Train Loss: 0.21701231598854065
[32m[0512 04:24:21 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.22132684290409088, Train Loss: 0.21700631082057953
[32m[0512 04:24:21 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.2213314324617386, Train Loss: 0.21700040996074677
[32m[0512 04:24:21 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.22133579850196838, Train Loss: 0.21699458360671997
[32m[0512 04:24:21 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.2213398814201355, Train Loss: 0.21698886156082153
[32m[0512 04:24:21 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.2213437557220459, Train Loss: 0.21698322892189026
[32m[0512 04:24:21 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.2213474065065384, Train Loss: 0.21697764098644257
[32m[0512 04:24:21 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.22135087847709656, Train Loss: 0.21697215735912323
[32m[0512 04:24:21 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.221354141831398, Train Loss: 0.21696670353412628
[32m[0512 04:24:21 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.2213572859764099, Train Loss: 0.2169613242149353
[32m[0512 04:24:21 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.22136029601097107, Train Loss: 0.2169560343027115
[32m[0512 04:24:21 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.2213631570339203, Train Loss: 0.21695074439048767
[32m[0512 04:24:21 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.22136589884757996, Train Loss: 0.21694554388523102
[32m[0512 04:24:21 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.22136853635311127, Train Loss: 0.21694037318229675
[32m[0512 04:24:21 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.22137106955051422, Train Loss: 0.21693523228168488
[32m[0512 04:24:21 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.2213735431432724, Train Loss: 0.21693015098571777
[32m[0512 04:24:22 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.22137591242790222, Train Loss: 0.21692511439323425
[32m[0512 04:24:22 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.22137820720672607, Train Loss: 0.21692012250423431
[32m[0512 04:24:22 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.22138048708438873, Train Loss: 0.21691514551639557
[32m[0512 04:24:22 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.22138264775276184, Train Loss: 0.2169102281332016
[32m[0512 04:24:22 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.22138476371765137, Train Loss: 0.21690532565116882
[32m[0512 04:24:22 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.2213868349790573, Train Loss: 0.21690048277378082
[32m[0512 04:24:22 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.22138887643814087, Train Loss: 0.21689562499523163
[32m[0512 04:24:22 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.22139084339141846, Train Loss: 0.2168908268213272
[32m[0512 04:24:22 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.22139281034469604, Train Loss: 0.21688604354858398
[32m[0512 04:24:22 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.22139470279216766, Train Loss: 0.21688129007816315
[32m[0512 04:24:22 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.22139661014080048, Train Loss: 0.2168765664100647
[32m[0512 04:24:22 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.2213984578847885, Train Loss: 0.21687184274196625
[32m[0512 04:24:22 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.22140027582645416, Train Loss: 0.21686717867851257
[32m[0512 04:24:22 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.2214020937681198, Train Loss: 0.2168624997138977
[32m[0512 04:24:22 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.22140389680862427, Train Loss: 0.2168578952550888
[32m[0512 04:24:22 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.22140565514564514, Train Loss: 0.2168532758951187
[32m[0512 04:24:22 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.22140741348266602, Train Loss: 0.21684867143630981
[32m[0512 04:24:22 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.2214091420173645, Train Loss: 0.2168441116809845
[32m[0512 04:24:22 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.22141088545322418, Train Loss: 0.21683955192565918
[32m[0512 04:24:22 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.22141258418560028, Train Loss: 0.21683500707149506
[32m[0512 04:24:22 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.22141431272029877, Train Loss: 0.21683050692081451
[32m[0512 04:24:22 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.22141601145267487, Train Loss: 0.21682600677013397
[32m[0512 04:24:22 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.22141769528388977, Train Loss: 0.21682150661945343
[32m[0512 04:24:22 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.22141939401626587, Train Loss: 0.21681705117225647
[32m[0512 04:24:22 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.22142106294631958, Train Loss: 0.21681258082389832
[32m[0512 04:24:22 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.2214227318763733, Train Loss: 0.21680814027786255
[32m[0512 04:24:22 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.2214244306087494, Train Loss: 0.21680372953414917
[32m[0512 04:24:22 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.2214260846376419, Train Loss: 0.21679933369159698
[32m[0512 04:24:23 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.22142773866653442, Train Loss: 0.2167949080467224
[32m[0512 04:24:23 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.22142940759658813, Train Loss: 0.21679054200649261
[32m[0512 04:24:23 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.22143109142780304, Train Loss: 0.21678616106510162
[32m[0512 04:24:23 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.22143274545669556, Train Loss: 0.21678180992603302
[32m[0512 04:24:23 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.22143444418907166, Train Loss: 0.2167774885892868
[32m[0512 04:24:23 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.22143612802028656, Train Loss: 0.2167731374502182
[32m[0512 04:24:23 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.22143779695034027, Train Loss: 0.21676881611347198
[32m[0512 04:24:23 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.2214394509792328, Train Loss: 0.21676450967788696
[32m[0512 04:24:23 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.2214411050081253, Train Loss: 0.21676021814346313
[32m[0512 04:24:23 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.2214428037405014, Train Loss: 0.21675589680671692
[32m[0512 04:24:23 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.2214444875717163, Train Loss: 0.21675162017345428
[32m[0512 04:24:23 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.2214461863040924, Train Loss: 0.21674734354019165
[32m[0512 04:24:23 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.22144785523414612, Train Loss: 0.2167430967092514
[32m[0512 04:24:23 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.2214495688676834, Train Loss: 0.21673883497714996
[32m[0512 04:24:23 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.22145125269889832, Train Loss: 0.2167346030473709
[32m[0512 04:24:23 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.22145295143127441, Train Loss: 0.21673034131526947
[32m[0512 04:24:23 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.2214546650648117, Train Loss: 0.2167261242866516
[32m[0512 04:24:23 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.2214563637971878, Train Loss: 0.21672192215919495
[32m[0512 04:24:23 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.2214580923318863, Train Loss: 0.21671773493289948
[32m[0512 04:24:23 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.22145982086658478, Train Loss: 0.21671348810195923
[32m[0512 04:24:23 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.22146151959896088, Train Loss: 0.21670931577682495
[32m[0512 04:24:23 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.22146323323249817, Train Loss: 0.2167051136493683
[32m[0512 04:24:23 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.22146499156951904, Train Loss: 0.216700941324234
[32m[0512 04:24:23 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.22146672010421753, Train Loss: 0.21669676899909973
[32m[0512 04:24:23 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.22146844863891602, Train Loss: 0.21669262647628784
[32m[0512 04:24:23 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.22147022187709808, Train Loss: 0.21668843924999237
[32m[0512 04:24:23 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.22147198021411896, Train Loss: 0.21668431162834167
[32m[0512 04:24:23 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.22147372364997864, Train Loss: 0.21668018400669098
[32m[0512 04:24:23 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.2214754819869995, Train Loss: 0.2166760116815567
[32m[0512 04:24:23 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.22147728502750397, Train Loss: 0.2166719138622284
[32m[0512 04:24:24 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.22147904336452484, Train Loss: 0.21666781604290009
[32m[0512 04:24:24 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.2214808464050293, Train Loss: 0.216663658618927
[32m[0512 04:24:24 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.22148261964321136, Train Loss: 0.2166595458984375
[32m[0512 04:24:24 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.22148439288139343, Train Loss: 0.21665546298027039
[32m[0512 04:24:24 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.22148622572422028, Train Loss: 0.21665135025978088
[32m[0512 04:24:24 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.22148801386356354, Train Loss: 0.21664728224277496
[32m[0512 04:24:24 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.221489816904068, Train Loss: 0.21664315462112427
[32m[0512 04:24:24 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.22149163484573364, Train Loss: 0.21663907170295715
[32m[0512 04:24:24 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.22149346768856049, Train Loss: 0.21663498878479004
[32m[0512 04:24:24 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.22149528563022614, Train Loss: 0.21663090586662292
[32m[0512 04:24:24 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.22149710357189178, Train Loss: 0.216626837849617
[32m[0512 04:24:24 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.22149896621704102, Train Loss: 0.21662276983261108
[32m[0512 04:24:24 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.22150075435638428, Train Loss: 0.21661873161792755
[32m[0512 04:24:24 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.2215026170015335, Train Loss: 0.21661466360092163
[32m[0512 04:24:24 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.22150446474552155, Train Loss: 0.2166105955839157
[32m[0512 04:24:24 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.22150635719299316, Train Loss: 0.21660660207271576
[32m[0512 04:24:24 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.2215082198381424, Train Loss: 0.21660253405570984
[32m[0512 04:24:24 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.22151008248329163, Train Loss: 0.2165984809398651
[32m[0512 04:24:24 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.22151194512844086, Train Loss: 0.21659445762634277
[32m[0512 04:24:24 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.22151383757591248, Train Loss: 0.21659043431282043
[32m[0512 04:24:24 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.2215157449245453, Train Loss: 0.2165864109992981
[32m[0512 04:24:24 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.2215176373720169, Train Loss: 0.21658240258693695
[32m[0512 04:24:24 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.22151951491832733, Train Loss: 0.21657834947109222
[32m[0512 04:24:24 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.22152140736579895, Train Loss: 0.21657435595989227
[32m[0512 04:24:24 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.22152331471443176, Train Loss: 0.21657034754753113
[32m[0512 04:24:24 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.22152523696422577, Train Loss: 0.2165663242340088
[32m[0512 04:24:24 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.22152714431285858, Train Loss: 0.21656233072280884
[32m[0512 04:24:24 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.22152908146381378, Train Loss: 0.2165583223104477
[32m[0512 04:24:25 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.2215310037136078, Train Loss: 0.21655434370040894
[32m[0512 04:24:25 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.221532940864563, Train Loss: 0.2165503352880478
[32m[0512 04:24:25 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.2215348482131958, Train Loss: 0.21654635667800903
[32m[0512 04:24:25 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.2215368151664734, Train Loss: 0.21654239296913147
[32m[0512 04:24:25 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.22153876721858978, Train Loss: 0.21653839945793152
[32m[0512 04:24:25 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.22154070436954498, Train Loss: 0.21653440594673157
[32m[0512 04:24:25 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.22154267132282257, Train Loss: 0.2165304571390152
[32m[0512 04:24:25 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.22154462337493896, Train Loss: 0.21652646362781525
[32m[0512 04:24:25 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.22154659032821655, Train Loss: 0.2165224850177765
[32m[0512 04:24:25 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.22154854238033295, Train Loss: 0.21651853621006012
[32m[0512 04:24:25 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.22155053913593292, Train Loss: 0.21651455760002136
[32m[0512 04:24:25 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.2215525060892105, Train Loss: 0.216510608792305
[32m[0512 04:24:25 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.2215544879436493, Train Loss: 0.21650664508342743
[32m[0512 04:24:25 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.22155648469924927, Train Loss: 0.21650268137454987
[32m[0512 04:24:25 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.22155848145484924, Train Loss: 0.21649876236915588
[32m[0512 04:24:25 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.22156046330928802, Train Loss: 0.21649478375911713
[32m[0512 04:24:25 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.2215624451637268, Train Loss: 0.21649083495140076
[32m[0512 04:24:25 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.22156445682048798, Train Loss: 0.2164868861436844
[32m[0512 04:24:25 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.22156646847724915, Train Loss: 0.21648293733596802
[32m[0512 04:24:25 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.2215684950351715, Train Loss: 0.21647901833057404
[32m[0512 04:24:25 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.22157049179077148, Train Loss: 0.21647508442401886
[32m[0512 04:24:25 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.22157256305217743, Train Loss: 0.2164711356163025
[32m[0512 04:24:25 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.2215745449066162, Train Loss: 0.21646720170974731
[32m[0512 04:24:25 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.22157657146453857, Train Loss: 0.21646326780319214
[32m[0512 04:24:25 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.22157861292362213, Train Loss: 0.21645936369895935
[32m[0512 04:24:25 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.2215806394815445, Train Loss: 0.21645544469356537
[32m[0512 04:24:25 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.22158271074295044, Train Loss: 0.216451495885849
[32m[0512 04:24:25 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.2215847373008728, Train Loss: 0.2164476066827774
[32m[0512 04:24:25 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.22158680856227875, Train Loss: 0.21644368767738342
[32m[0512 04:24:26 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.2215888351202011, Train Loss: 0.21643975377082825
[32m[0512 04:24:26 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.22159089148044586, Train Loss: 0.21643584966659546
[32m[0512 04:24:26 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.2215929627418518, Train Loss: 0.21643193066120148
[32m[0512 04:24:26 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.22159503400325775, Train Loss: 0.2164280265569687
[32m[0512 04:24:26 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.2215971052646637, Train Loss: 0.2164240926504135
[32m[0512 04:24:26 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.22159917652606964, Train Loss: 0.21642020344734192
[32m[0512 04:24:26 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.22160124778747559, Train Loss: 0.21641631424427032
[32m[0512 04:24:26 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.22160334885120392, Train Loss: 0.21641239523887634
[32m[0512 04:24:26 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.22160543501377106, Train Loss: 0.21640849113464355
[32m[0512 04:24:26 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.221607506275177, Train Loss: 0.21640461683273315
[32m[0512 04:24:26 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.22160960733890533, Train Loss: 0.21640069782733917
[32m[0512 04:24:26 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.22161167860031128, Train Loss: 0.21639680862426758
[32m[0512 04:24:26 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.2216138243675232, Train Loss: 0.21639293432235718
[32m[0512 04:24:26 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.22161589562892914, Train Loss: 0.2163890153169632
[32m[0512 04:24:26 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.22161799669265747, Train Loss: 0.216385155916214
[32m[0512 04:24:26 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.2216200977563858, Train Loss: 0.2163812518119812
[32m[0512 04:24:26 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.22162221372127533, Train Loss: 0.2163773477077484
[32m[0512 04:24:26 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.22162432968616486, Train Loss: 0.2163735032081604
[32m[0512 04:24:26 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.22162646055221558, Train Loss: 0.2163695991039276
[32m[0512 04:24:26 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.2216285616159439, Train Loss: 0.2163657546043396
[32m[0512 04:24:26 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.22163067758083344, Train Loss: 0.2163618505001068
[32m[0512 04:24:26 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.22163280844688416, Train Loss: 0.2163579761981964
[32m[0512 04:24:26 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.22163492441177368, Train Loss: 0.2163541167974472
[32m[0512 04:24:26 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.2216370701789856, Train Loss: 0.2163502424955368
[32m[0512 04:24:26 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.2216392308473587, Train Loss: 0.2163463979959488
[32m[0512 04:24:26 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.22164136171340942, Train Loss: 0.2163425087928772
[32m[0512 04:24:26 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.22164350748062134, Train Loss: 0.2163386344909668
[32m[0512 04:24:26 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.22164565324783325, Train Loss: 0.2163347750902176
[32m[0512 04:24:26 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.22164779901504517, Train Loss: 0.2163309007883072
[32m[0512 04:24:26 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.22164995968341827, Train Loss: 0.2163270115852356
[32m[0512 04:24:27 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.22165212035179138, Train Loss: 0.21632319688796997
[32m[0512 04:24:27 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.2216542810201645, Train Loss: 0.21631932258605957
[32m[0512 04:24:27 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.2216564416885376, Train Loss: 0.21631547808647156
[32m[0512 04:24:27 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.2216586172580719, Train Loss: 0.21631161868572235
[32m[0512 04:24:27 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.2216607630252838, Train Loss: 0.21630772948265076
[32m[0512 04:24:27 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.2216629832983017, Train Loss: 0.21630391478538513
[32m[0512 04:24:27 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.22166511416435242, Train Loss: 0.21630005538463593
[32m[0512 04:24:27 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.2216673344373703, Train Loss: 0.2162962108850479
[32m[0512 04:24:27 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.2216695100069046, Train Loss: 0.2162923365831375
[32m[0512 04:24:27 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.2216716855764389, Train Loss: 0.2162885069847107
[32m[0512 04:24:27 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.2216738760471344, Train Loss: 0.2162846475839615
[32m[0512 04:24:27 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.2216760665178299, Train Loss: 0.21628084778785706
[32m[0512 04:24:27 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.2216782569885254, Train Loss: 0.21627698838710785
[32m[0512 04:24:27 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.22168046236038208, Train Loss: 0.21627311408519745
[32m[0512 04:24:27 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.22168265283107758, Train Loss: 0.21626929938793182
[32m[0512 04:24:27 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.22168487310409546, Train Loss: 0.21626542508602142
[32m[0512 04:24:27 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.22168707847595215, Train Loss: 0.21626164019107819
[32m[0512 04:24:27 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.22168928384780884, Train Loss: 0.21625778079032898
[32m[0512 04:24:27 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.22169148921966553, Train Loss: 0.21625396609306335
[32m[0512 04:24:27 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.2216937392950058, Train Loss: 0.21625012159347534
[32m[0512 04:24:27 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.2216959446668625, Train Loss: 0.21624627709388733
[32m[0512 04:24:27 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.22169815003871918, Train Loss: 0.2162424623966217
[32m[0512 04:24:27 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.22170038521289825, Train Loss: 0.2162386029958725
[32m[0512 04:24:27 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.22170260548591614, Train Loss: 0.21623481810092926
[32m[0512 04:24:27 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.2217048555612564, Train Loss: 0.21623095870018005
[32m[0512 04:24:27 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.22170709073543549, Train Loss: 0.21622712910175323
[32m[0512 04:24:27 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.22170932590961456, Train Loss: 0.2162233293056488
[32m[0512 04:24:27 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.22171159088611603, Train Loss: 0.21621949970722198
[32m[0512 04:24:27 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.2217138260602951, Train Loss: 0.21621568500995636
[32m[0512 04:24:28 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.22171607613563538, Train Loss: 0.21621188521385193
[32m[0512 04:24:28 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.22171834111213684, Train Loss: 0.21620804071426392
[32m[0512 04:24:28 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.2217205911874771, Train Loss: 0.2162042260169983
[32m[0512 04:24:28 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.22172284126281738, Train Loss: 0.21620042622089386
[32m[0512 04:24:28 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.22172510623931885, Train Loss: 0.21619659662246704
[32m[0512 04:24:28 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.22172735631465912, Train Loss: 0.21619278192520142
[32m[0512 04:24:28 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.22172963619232178, Train Loss: 0.2161889672279358
[32m[0512 04:24:28 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.22173191606998444, Train Loss: 0.21618516743183136
[32m[0512 04:24:28 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.2217341661453247, Train Loss: 0.21618138253688812
[32m[0512 04:24:28 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.22173647582530975, Train Loss: 0.2161775380373001
[32m[0512 04:24:28 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.2217387557029724, Train Loss: 0.21617375314235687
[32m[0512 04:24:28 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.22174103558063507, Train Loss: 0.21616993844509125
[32m[0512 04:24:28 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.22174331545829773, Train Loss: 0.216166153550148
[32m[0512 04:24:28 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.22174562513828278, Train Loss: 0.21616233885288239
[32m[0512 04:24:28 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.22174791991710663, Train Loss: 0.21615855395793915
[32m[0512 04:24:28 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.2217501997947693, Train Loss: 0.2161547690629959
[32m[0512 04:24:28 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.22175249457359314, Train Loss: 0.2161509394645691
[32m[0512 04:24:28 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.22175481915473938, Train Loss: 0.21614713966846466
[32m[0512 04:24:28 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.22175711393356323, Train Loss: 0.21614333987236023
[32m[0512 04:24:28 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.22175943851470947, Train Loss: 0.2161395400762558
[32m[0512 04:24:28 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.2217617630958557, Train Loss: 0.21613577008247375
[32m[0512 04:24:28 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.22176408767700195, Train Loss: 0.21613197028636932
[32m[0512 04:24:28 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.2217664122581482, Train Loss: 0.2161281853914261
[32m[0512 04:24:28 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.22176875174045563, Train Loss: 0.21612438559532166
[32m[0512 04:24:28 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.22177106142044067, Train Loss: 0.21612058579921722
[32m[0512 04:24:28 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.2217734009027481, Train Loss: 0.21611683070659637
[32m[0512 04:24:28 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.22177572548389435, Train Loss: 0.21611303091049194
[32m[0512 04:24:28 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.22177807986736298, Train Loss: 0.2161092460155487
[32m[0512 04:24:29 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.2217804193496704, Train Loss: 0.21610546112060547
[32m[0512 04:24:29 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.22178277373313904, Train Loss: 0.21610169112682343
[32m[0512 04:24:29 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.22178511321544647, Train Loss: 0.2160979062318802
[32m[0512 04:24:29 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.2217874675989151, Train Loss: 0.21609412133693695
[32m[0512 04:24:29 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.2217898666858673, Train Loss: 0.2160903513431549
[32m[0512 04:24:29 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.22179219126701355, Train Loss: 0.21608658134937286
[32m[0512 04:24:29 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.22179456055164337, Train Loss: 0.21608279645442963
[32m[0512 04:24:29 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.2217969447374344, Train Loss: 0.21607902646064758
[32m[0512 04:24:29 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.2217993140220642, Train Loss: 0.21607527136802673
[32m[0512 04:24:29 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.22180171310901642, Train Loss: 0.2160714715719223
[32m[0512 04:24:29 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.22180406749248505, Train Loss: 0.21606773138046265
[32m[0512 04:24:29 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.22180645167827606, Train Loss: 0.2160639464855194
[32m[0512 04:24:29 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.22180885076522827, Train Loss: 0.21606019139289856
[32m[0512 04:24:29 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.22181124985218048, Train Loss: 0.2160564363002777
[32m[0512 04:24:29 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.2218136340379715, Train Loss: 0.21605266630649567
[32m[0512 04:24:29 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.2218160331249237, Train Loss: 0.21604889631271362
[32m[0512 04:24:29 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.2218184471130371, Train Loss: 0.21604512631893158
[32m[0512 04:24:29 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.22182084619998932, Train Loss: 0.21604138612747192
[32m[0512 04:24:29 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.22182326018810272, Train Loss: 0.21603761613368988
[32m[0512 04:24:29 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.22182568907737732, Train Loss: 0.21603387594223022
[32m[0512 04:24:29 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.22182811796665192, Train Loss: 0.216030091047287
[32m[0512 04:24:29 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.22183051705360413, Train Loss: 0.21602636575698853
[32m[0512 04:24:29 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.22183296084403992, Train Loss: 0.21602262556552887
[32m[0512 04:24:29 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.22183538973331451, Train Loss: 0.21601887047290802
[32m[0512 04:24:29 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.2218378186225891, Train Loss: 0.21601511538028717
[32m[0512 04:24:29 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.2218402624130249, Train Loss: 0.21601137518882751
[32m[0512 04:24:29 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.2218427062034607, Train Loss: 0.21600762009620667
[32m[0512 04:24:29 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.22184517979621887, Train Loss: 0.21600386500358582
[32m[0512 04:24:30 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.22184762358665466, Train Loss: 0.21600010991096497
[32m[0512 04:24:30 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.22185008227825165, Train Loss: 0.2159963697195053
[32m[0512 04:24:30 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.22185254096984863, Train Loss: 0.21599262952804565
[32m[0512 04:24:30 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.22185498476028442, Train Loss: 0.2159889042377472
[32m[0512 04:24:30 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.2218574732542038, Train Loss: 0.21598516404628754
[32m[0512 04:24:30 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.22185996174812317, Train Loss: 0.21598142385482788
[32m[0512 04:24:30 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.22186242043972015, Train Loss: 0.2159777283668518
[32m[0512 04:24:30 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.22186490893363953, Train Loss: 0.21597394347190857
[32m[0512 04:24:30 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.2218674123287201, Train Loss: 0.2159702628850937
[32m[0512 04:24:30 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.22186990082263947, Train Loss: 0.21596649289131165
[32m[0512 04:24:30 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.22187237441539764, Train Loss: 0.21596278250217438
[32m[0512 04:24:30 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.2218748778104782, Train Loss: 0.21595905721187592
[32m[0512 04:24:30 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.22187738120555878, Train Loss: 0.21595531702041626
[32m[0512 04:24:30 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.22187991440296173, Train Loss: 0.21595162153244019
[32m[0512 04:24:30 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.2218824028968811, Train Loss: 0.21594789624214172
[32m[0512 04:24:30 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.22188493609428406, Train Loss: 0.21594414114952087
[32m[0512 04:24:30 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.22188745439052582, Train Loss: 0.215940460562706
[32m[0512 04:24:30 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.22188995778560638, Train Loss: 0.21593672037124634
[32m[0512 04:24:30 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.22189252078533173, Train Loss: 0.21593300998210907
[32m[0512 04:24:30 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.2218950390815735, Train Loss: 0.2159292995929718
[32m[0512 04:24:30 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.22189758718013763, Train Loss: 0.21592560410499573
[32m[0512 04:24:30 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.2219001054763794, Train Loss: 0.21592186391353607
[32m[0512 04:24:30 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.22190266847610474, Train Loss: 0.2159181386232376
[32m[0512 04:24:30 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.22190521657466888, Train Loss: 0.21591445803642273
[32m[0512 04:24:30 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.2219078093767166, Train Loss: 0.21591074764728546
[32m[0512 04:24:30 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.22191035747528076, Train Loss: 0.2159070372581482
[32m[0512 04:24:30 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.2219129055738449, Train Loss: 0.21590334177017212
[32m[0512 04:24:31 @mbmf_sampler.py:98][0m Finished 9th episode
[32m[0512 04:24:31 @mbmf_sampler.py:102][0m 1809 timesteps from 9 episodes collected
[32m[0512 04:45:25 @mbmf_trainer.py:160][0m Mean reward: -372.9617441230818
[32m[0512 04:45:25 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.20935292541980743, Train Loss: 0.21694326400756836
[32m[0512 04:45:25 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.20933619141578674, Train Loss: 0.216859370470047
[32m[0512 04:45:25 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.20940354466438293, Train Loss: 0.21681705117225647
[32m[0512 04:45:25 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.20947064459323883, Train Loss: 0.21677057445049286
[32m[0512 04:45:25 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.20952215790748596, Train Loss: 0.21673458814620972
[32m[0512 04:45:25 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.20957070589065552, Train Loss: 0.21670576930046082
[32m[0512 04:45:25 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.2096148133277893, Train Loss: 0.2166803777217865
[32m[0512 04:45:25 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.20965442061424255, Train Loss: 0.2166583389043808
[32m[0512 04:45:25 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.20969052612781525, Train Loss: 0.21663899719715118
[32m[0512 04:45:25 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.20972345769405365, Train Loss: 0.21662162244319916
[32m[0512 04:45:25 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.20975352823734283, Train Loss: 0.21660585701465607
[32m[0512 04:45:25 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.20978109538555145, Train Loss: 0.21659140288829803
[32m[0512 04:45:25 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.209806427359581, Train Loss: 0.21657808125019073
[32m[0512 04:45:25 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.20982983708381653, Train Loss: 0.21656560897827148
[32m[0512 04:45:25 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.20985147356987, Train Loss: 0.2165539413690567
[32m[0512 04:45:25 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.20987160503864288, Train Loss: 0.21654291450977325
[32m[0512 04:45:25 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.20989030599594116, Train Loss: 0.21653242409229279
[32m[0512 04:45:25 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.20990782976150513, Train Loss: 0.21652241051197052
[32m[0512 04:45:25 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.20992428064346313, Train Loss: 0.21651285886764526
[32m[0512 04:45:26 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.20993971824645996, Train Loss: 0.21650364995002747
[32m[0512 04:45:26 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.20995429158210754, Train Loss: 0.21649481356143951
[32m[0512 04:45:26 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.20996813476085663, Train Loss: 0.21648623049259186
[32m[0512 04:45:26 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.2099812924861908, Train Loss: 0.21647794544696808
[32m[0512 04:45:26 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.20999377965927124, Train Loss: 0.2164699137210846
[32m[0512 04:45:26 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.2100057303905487, Train Loss: 0.21646209061145782
[32m[0512 04:45:26 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.21001718938350677, Train Loss: 0.21645447611808777
[32m[0512 04:45:26 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.21002820134162903, Train Loss: 0.21644707024097443
[32m[0512 04:45:26 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.21003879606723785, Train Loss: 0.21643982827663422
[32m[0512 04:45:26 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.21004895865917206, Train Loss: 0.21643276512622833
[32m[0512 04:45:26 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.21005883812904358, Train Loss: 0.216425821185112
[32m[0512 04:45:26 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.21006840467453003, Train Loss: 0.2164190411567688
[32m[0512 04:45:26 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.2100776582956314, Train Loss: 0.21641239523887634
[32m[0512 04:45:26 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.21008668839931488, Train Loss: 0.21640589833259583
[32m[0512 04:45:26 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.21009548008441925, Train Loss: 0.21639952063560486
[32m[0512 04:45:26 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.21010401844978333, Train Loss: 0.21639324724674225
[32m[0512 04:45:26 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.21011236310005188, Train Loss: 0.2163870483636856
[32m[0512 04:45:26 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.2101205289363861, Train Loss: 0.2163809984922409
[32m[0512 04:45:26 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.210128515958786, Train Loss: 0.21637499332427979
[32m[0512 04:45:26 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.21013635396957397, Train Loss: 0.2163691222667694
[32m[0512 04:45:26 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.21014398336410522, Train Loss: 0.2163633555173874
[32m[0512 04:45:26 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.2101515233516693, Train Loss: 0.21635763347148895
[32m[0512 04:45:27 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.21015892922878265, Train Loss: 0.21635201573371887
[32m[0512 04:45:27 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.21016621589660645, Train Loss: 0.21634645760059357
[32m[0512 04:45:27 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.2101733684539795, Train Loss: 0.21634098887443542
[32m[0512 04:45:27 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.210180401802063, Train Loss: 0.21633557975292206
[32m[0512 04:45:27 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.21018731594085693, Train Loss: 0.21633024513721466
[32m[0512 04:45:27 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.2101941704750061, Train Loss: 0.21632492542266846
[32m[0512 04:45:27 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.21020089089870453, Train Loss: 0.2163197547197342
[32m[0512 04:45:27 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.21020755171775818, Train Loss: 0.21631459891796112
[32m[0512 04:45:27 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.21021410822868347, Train Loss: 0.21630950272083282
[32m[0512 04:45:27 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.2102205455303192, Train Loss: 0.2163044512271881
[32m[0512 04:45:27 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.21022698283195496, Train Loss: 0.21629945933818817
[32m[0512 04:45:27 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.21023330092430115, Train Loss: 0.21629451215267181
[32m[0512 04:45:27 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.21023951470851898, Train Loss: 0.21628963947296143
[32m[0512 04:45:27 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.21024569869041443, Train Loss: 0.21628479659557343
[32m[0512 04:45:27 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.2102518379688263, Train Loss: 0.2162800133228302
[32m[0512 04:45:27 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.2102578580379486, Train Loss: 0.21627524495124817
[32m[0512 04:45:27 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.21026384830474854, Train Loss: 0.2162705510854721
[32m[0512 04:45:27 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.2102697342634201, Train Loss: 0.21626587212085724
[32m[0512 04:45:27 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.21027560532093048, Train Loss: 0.21626123785972595
[32m[0512 04:45:27 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.2102814018726349, Train Loss: 0.21625666320323944
[32m[0512 04:45:27 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.21028713881969452, Train Loss: 0.21625210344791412
[32m[0512 04:45:27 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.21029281616210938, Train Loss: 0.2162475883960724
[32m[0512 04:45:28 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.21029846370220184, Train Loss: 0.21624311804771423
[32m[0512 04:45:28 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.21030400693416595, Train Loss: 0.21623864769935608
[32m[0512 04:45:28 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.21030953526496887, Train Loss: 0.2162342518568039
[32m[0512 04:45:28 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.2103150486946106, Train Loss: 0.2162298709154129
[32m[0512 04:45:28 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.21032044291496277, Train Loss: 0.2162255197763443
[32m[0512 04:45:28 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.21032583713531494, Train Loss: 0.21622121334075928
[32m[0512 04:45:28 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.21033115684986115, Train Loss: 0.21621692180633545
[32m[0512 04:45:28 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.21033646166324615, Train Loss: 0.21621263027191162
[32m[0512 04:45:28 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.21034172177314758, Train Loss: 0.21620841324329376
[32m[0512 04:45:28 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.21034689247608185, Train Loss: 0.2162042111158371
[32m[0512 04:45:28 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.21035204827785492, Train Loss: 0.21620002388954163
[32m[0512 04:45:28 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.21035714447498322, Train Loss: 0.21619588136672974
[32m[0512 04:45:28 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.21036222577095032, Train Loss: 0.21619173884391785
[32m[0512 04:45:28 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.21036727726459503, Train Loss: 0.21618762612342834
[32m[0512 04:45:28 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.21037226915359497, Train Loss: 0.21618354320526123
[32m[0512 04:45:28 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.21037720143795013, Train Loss: 0.2161794751882553
[32m[0512 04:45:28 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.2103821188211441, Train Loss: 0.21617545187473297
[32m[0512 04:45:28 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.2103869915008545, Train Loss: 0.21617144346237183
[32m[0512 04:45:28 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.2103918343782425, Train Loss: 0.2161674201488495
[32m[0512 04:45:28 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.21039661765098572, Train Loss: 0.21616345643997192
[32m[0512 04:45:28 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.21040140092372894, Train Loss: 0.21615952253341675
[32m[0512 04:45:28 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.2104061245918274, Train Loss: 0.21615560352802277
[32m[0512 04:45:29 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.21041078865528107, Train Loss: 0.2161516696214676
[32m[0512 04:45:29 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.21041549742221832, Train Loss: 0.216147780418396
[32m[0512 04:45:29 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.21042010188102722, Train Loss: 0.2161439061164856
[32m[0512 04:45:29 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.21042469143867493, Train Loss: 0.2161400467157364
[32m[0512 04:45:29 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.21042926609516144, Train Loss: 0.21613620221614838
[32m[0512 04:45:29 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.21043379604816437, Train Loss: 0.21613235771656036
[32m[0512 04:45:29 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.21043828129768372, Train Loss: 0.21612857282161713
[32m[0512 04:45:29 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.2104427069425583, Train Loss: 0.2161247879266739
[32m[0512 04:45:29 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.21044717729091644, Train Loss: 0.21612100303173065
[32m[0512 04:45:29 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.21045157313346863, Train Loss: 0.216117262840271
[32m[0512 04:45:29 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.21045593917369843, Train Loss: 0.21611352264881134
[32m[0512 04:45:29 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.21046027541160583, Train Loss: 0.21610979735851288
[32m[0512 04:45:29 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.21046458184719086, Train Loss: 0.2161060869693756
[32m[0512 04:45:29 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.2104688584804535, Train Loss: 0.21610237658023834
[32m[0512 04:45:29 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.21047310531139374, Train Loss: 0.21609871089458466
[32m[0512 04:45:29 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.21047735214233398, Train Loss: 0.21609501540660858
[32m[0512 04:45:29 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.21048152446746826, Train Loss: 0.21609137952327728
[32m[0512 04:45:29 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.21048569679260254, Train Loss: 0.21608774363994598
[32m[0512 04:45:29 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.21048983931541443, Train Loss: 0.21608410775661469
[32m[0512 04:45:29 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.21049393713474274, Train Loss: 0.21608051657676697
[32m[0512 04:45:29 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.21049802005290985, Train Loss: 0.21607688069343567
[32m[0512 04:45:29 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.21050205826759338, Train Loss: 0.21607331931591034
[32m[0512 04:45:29 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.21050609648227692, Train Loss: 0.21606974303722382
[32m[0512 04:45:29 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.21051008999347687, Train Loss: 0.2160661667585373
[32m[0512 04:45:30 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.21051405370235443, Train Loss: 0.21606262028217316
[32m[0512 04:45:30 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.210518017411232, Train Loss: 0.21605908870697021
[32m[0512 04:45:30 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.21052195131778717, Train Loss: 0.21605554223060608
[32m[0512 04:45:30 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.21052584052085876, Train Loss: 0.21605202555656433
[32m[0512 04:45:30 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.21052972972393036, Train Loss: 0.21604852378368378
[32m[0512 04:45:30 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.21053357422351837, Train Loss: 0.21604502201080322
[32m[0512 04:45:30 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.2105374038219452, Train Loss: 0.21604156494140625
[32m[0512 04:45:30 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.21054120361804962, Train Loss: 0.2160380780696869
[32m[0512 04:45:30 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.21054497361183167, Train Loss: 0.21603460609912872
[32m[0512 04:45:30 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.2105487436056137, Train Loss: 0.21603117883205414
[32m[0512 04:45:30 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.21055246889591217, Train Loss: 0.21602773666381836
[32m[0512 04:45:30 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.21055619418621063, Train Loss: 0.2160242795944214
[32m[0512 04:45:30 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.21055984497070312, Train Loss: 0.216020867228508
[32m[0512 04:45:30 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.2105635404586792, Train Loss: 0.2160174399614334
[32m[0512 04:45:30 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.2105671465396881, Train Loss: 0.2160140573978424
[32m[0512 04:45:30 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.2105707824230194, Train Loss: 0.2160106748342514
[32m[0512 04:45:30 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.21057438850402832, Train Loss: 0.2160072773694992
[32m[0512 04:45:30 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.21057792007923126, Train Loss: 0.2160039246082306
[32m[0512 04:45:30 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.21058149635791779, Train Loss: 0.2160005271434784
[32m[0512 04:45:30 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.21058501303195953, Train Loss: 0.21599717438220978
[32m[0512 04:45:30 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.21058854460716248, Train Loss: 0.21599383652210236
[32m[0512 04:45:30 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.21059201657772064, Train Loss: 0.21599049866199493
[32m[0512 04:45:31 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.21059547364711761, Train Loss: 0.2159871757030487
[32m[0512 04:45:31 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.2105989307165146, Train Loss: 0.21598383784294128
[32m[0512 04:45:31 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.21060234308242798, Train Loss: 0.21598052978515625
[32m[0512 04:45:31 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.21060575544834137, Train Loss: 0.21597722172737122
[32m[0512 04:45:31 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.21060913801193237, Train Loss: 0.21597392857074738
[32m[0512 04:45:31 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.210612490773201, Train Loss: 0.21597063541412354
[32m[0512 04:45:31 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.2106158435344696, Train Loss: 0.2159673571586609
[32m[0512 04:45:31 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.21061916649341583, Train Loss: 0.21596406400203705
[32m[0512 04:45:31 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.21062247455120087, Train Loss: 0.2159608006477356
[32m[0512 04:45:31 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.2106257826089859, Train Loss: 0.21595756709575653
[32m[0512 04:45:31 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.21062904596328735, Train Loss: 0.21595430374145508
[32m[0512 04:45:31 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.21063227951526642, Train Loss: 0.2159510850906372
[32m[0512 04:45:31 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.21063551306724548, Train Loss: 0.21594782173633575
[32m[0512 04:45:31 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.21063870191574097, Train Loss: 0.2159445881843567
[32m[0512 04:45:31 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.21064192056655884, Train Loss: 0.2159413993358612
[32m[0512 04:45:31 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.21064509451389313, Train Loss: 0.21593819558620453
[32m[0512 04:45:31 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.21064825356006622, Train Loss: 0.21593497693538666
[32m[0512 04:45:31 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.21065136790275574, Train Loss: 0.21593177318572998
[32m[0512 04:45:31 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.21065449714660645, Train Loss: 0.2159285843372345
[32m[0512 04:45:31 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.21065756678581238, Train Loss: 0.215925395488739
[32m[0512 04:45:31 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.21066069602966309, Train Loss: 0.21592220664024353
[32m[0512 04:45:31 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.21066376566886902, Train Loss: 0.21591904759407043
[32m[0512 04:45:31 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.21066680550575256, Train Loss: 0.21591587364673615
[32m[0512 04:45:31 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.2106698453426361, Train Loss: 0.21591271460056305
[32m[0512 04:45:32 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.21067284047603607, Train Loss: 0.21590955555438995
[32m[0512 04:45:32 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.21067586541175842, Train Loss: 0.21590642631053925
[32m[0512 04:45:32 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.2106788605451584, Train Loss: 0.21590328216552734
[32m[0512 04:45:32 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.21068184077739716, Train Loss: 0.21590016782283783
[32m[0512 04:45:32 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.21068476140499115, Train Loss: 0.21589703857898712
[32m[0512 04:45:32 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.21068768203258514, Train Loss: 0.2158939242362976
[32m[0512 04:45:32 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.21069063246250153, Train Loss: 0.2158908098936081
[32m[0512 04:45:32 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.21069353818893433, Train Loss: 0.21588769555091858
[32m[0512 04:45:32 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.21069642901420593, Train Loss: 0.21588461101055145
[32m[0512 04:45:32 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.21069930493831635, Train Loss: 0.21588149666786194
[32m[0512 04:45:32 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.21070216596126556, Train Loss: 0.2158784121274948
[32m[0512 04:45:32 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.2107050120830536, Train Loss: 0.21587532758712769
[32m[0512 04:45:32 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.21070782840251923, Train Loss: 0.21587224304676056
[32m[0512 04:45:32 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.21071065962314606, Train Loss: 0.21586917340755463
[32m[0512 04:45:32 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.2107134610414505, Train Loss: 0.2158661186695099
[32m[0512 04:45:32 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.21071624755859375, Train Loss: 0.21586304903030396
[32m[0512 04:45:32 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.2107190042734146, Train Loss: 0.2158600091934204
[32m[0512 04:45:32 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.21072176098823547, Train Loss: 0.21585695445537567
[32m[0512 04:45:32 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.21072450280189514, Train Loss: 0.21585388481616974
[32m[0512 04:45:32 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.21072722971439362, Train Loss: 0.21585087478160858
[32m[0512 04:45:32 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.21072997152805328, Train Loss: 0.21584786474704742
[32m[0512 04:45:32 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.21073265373706818, Train Loss: 0.21584481000900269
[32m[0512 04:45:33 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.21073533594608307, Train Loss: 0.21584179997444153
[32m[0512 04:45:33 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.21073804795742035, Train Loss: 0.21583878993988037
[32m[0512 04:45:33 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.21074067056179047, Train Loss: 0.21583576500415802
[32m[0512 04:45:33 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.21074335277080536, Train Loss: 0.21583275496959686
[32m[0512 04:45:33 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.21074600517749786, Train Loss: 0.2158297747373581
[32m[0512 04:45:33 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.21074862778186798, Train Loss: 0.21582679450511932
[32m[0512 04:45:33 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.2107512205839157, Train Loss: 0.21582376956939697
[32m[0512 04:45:33 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.21075382828712463, Train Loss: 0.2158207893371582
[32m[0512 04:45:33 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.21075639128684998, Train Loss: 0.21581782400608063
[32m[0512 04:45:33 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.2107589989900589, Train Loss: 0.21581487357616425
[32m[0512 04:45:33 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.21076157689094543, Train Loss: 0.21581187844276428
[32m[0512 04:45:33 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.210764080286026, Train Loss: 0.2158089131116867
[32m[0512 04:45:33 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.21076665818691254, Train Loss: 0.21580596268177032
[32m[0512 04:45:33 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.2107691615819931, Train Loss: 0.21580302715301514
[32m[0512 04:45:33 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.21077172458171844, Train Loss: 0.21580006182193756
[32m[0512 04:45:33 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.21077421307563782, Train Loss: 0.21579712629318237
[32m[0512 04:45:33 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.210776686668396, Train Loss: 0.21579419076442719
[32m[0512 04:45:33 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.21077917516231537, Train Loss: 0.215791255235672
[32m[0512 04:45:33 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.21078164875507355, Train Loss: 0.2157883197069168
[32m[0512 04:45:33 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.21078410744667053, Train Loss: 0.21578539907932281
[32m[0512 04:45:33 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.21078656613826752, Train Loss: 0.21578246355056763
[32m[0512 04:45:33 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.2107890099287033, Train Loss: 0.21577955782413483
[32m[0512 04:45:33 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.2107914239168167, Train Loss: 0.21577666699886322
[32m[0512 04:45:34 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.2107938826084137, Train Loss: 0.21577373147010803
[32m[0512 04:45:34 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.2107962667942047, Train Loss: 0.21577084064483643
[32m[0512 04:45:34 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.2107986956834793, Train Loss: 0.215767964720726
[32m[0512 04:45:34 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.21080106496810913, Train Loss: 0.2157650738954544
[32m[0512 04:45:34 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.21080343425273895, Train Loss: 0.2157621681690216
[32m[0512 04:45:34 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.21080581843852997, Train Loss: 0.21575927734375
[32m[0512 04:45:34 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.2108081728219986, Train Loss: 0.21575641632080078
[32m[0512 04:45:34 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.21081054210662842, Train Loss: 0.21575352549552917
[32m[0512 04:45:34 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.21081289649009705, Train Loss: 0.21575066447257996
[32m[0512 04:45:34 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.21081523597240448, Train Loss: 0.21574780344963074
[32m[0512 04:45:34 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.21081753075122833, Train Loss: 0.21574494242668152
[32m[0512 04:45:34 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.21081985533237457, Train Loss: 0.2157421112060547
[32m[0512 04:45:34 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.210822194814682, Train Loss: 0.21573925018310547
[32m[0512 04:45:34 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.21082448959350586, Train Loss: 0.21573638916015625
[32m[0512 04:45:34 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.21082675457000732, Train Loss: 0.21573355793952942
[32m[0512 04:45:34 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.2108290195465088, Train Loss: 0.2157307118177414
[32m[0512 04:45:34 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.21083129942417145, Train Loss: 0.21572788059711456
[32m[0512 04:45:34 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.2108335942029953, Train Loss: 0.21572504937648773
[32m[0512 04:45:34 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.21083585917949677, Train Loss: 0.2157222330570221
[32m[0512 04:45:34 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.21083810925483704, Train Loss: 0.21571941673755646
[32m[0512 04:45:34 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.2108403444290161, Train Loss: 0.21571658551692963
[32m[0512 04:45:34 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.2108425796031952, Train Loss: 0.21571378409862518
[32m[0512 04:45:34 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.21084482967853546, Train Loss: 0.21571096777915955
[32m[0512 04:45:35 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.21084703505039215, Train Loss: 0.2157081812620163
[32m[0512 04:45:35 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.21084924042224884, Train Loss: 0.21570536494255066
[32m[0512 04:45:35 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.21085144579410553, Train Loss: 0.2157025784254074
[32m[0512 04:45:35 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.21085365116596222, Train Loss: 0.21569977700710297
[32m[0512 04:45:35 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.21085582673549652, Train Loss: 0.21569699048995972
[32m[0512 04:45:35 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.2108580470085144, Train Loss: 0.21569423377513885
[32m[0512 04:45:35 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.21086019277572632, Train Loss: 0.21569141745567322
[32m[0512 04:45:35 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.21086235344409943, Train Loss: 0.21568866074085236
[32m[0512 04:45:35 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.21086452901363373, Train Loss: 0.2156858742237091
[32m[0512 04:45:35 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.21086668968200684, Train Loss: 0.21568310260772705
[32m[0512 04:45:35 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.21086885035037994, Train Loss: 0.2156803458929062
[32m[0512 04:45:35 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.21087099611759186, Train Loss: 0.21567758917808533
[32m[0512 04:45:35 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.21087311208248138, Train Loss: 0.21567483246326447
[32m[0512 04:45:35 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.2108752578496933, Train Loss: 0.21567204594612122
[32m[0512 04:45:35 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.21087738871574402, Train Loss: 0.21566930413246155
[32m[0512 04:45:35 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.21087948977947235, Train Loss: 0.21566657721996307
[32m[0512 04:45:35 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.21088160574436188, Train Loss: 0.2156638354063034
[32m[0512 04:45:35 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.2108837068080902, Train Loss: 0.21566109359264374
[32m[0512 04:45:35 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.21088583767414093, Train Loss: 0.21565833687782288
[32m[0512 04:45:35 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.21088789403438568, Train Loss: 0.2156556099653244
[32m[0512 04:45:35 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.210889995098114, Train Loss: 0.21565289795398712
[32m[0512 04:45:35 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.21089211106300354, Train Loss: 0.21565015614032745
[32m[0512 04:45:35 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.2108941674232483, Train Loss: 0.21564744412899017
[32m[0512 04:45:36 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.21089623868465424, Train Loss: 0.2156447321176529
[32m[0512 04:45:36 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.21089832484722137, Train Loss: 0.21564200520515442
[32m[0512 04:45:36 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.21090039610862732, Train Loss: 0.21563929319381714
[32m[0512 04:45:36 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.21090243756771088, Train Loss: 0.21563661098480225
[32m[0512 04:45:36 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.21090450882911682, Train Loss: 0.21563389897346497
[32m[0512 04:45:36 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.21090656518936157, Train Loss: 0.21563118696212769
[32m[0512 04:45:36 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.21090860664844513, Train Loss: 0.2156284749507904
[32m[0512 04:45:36 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.2109106332063675, Train Loss: 0.2156258076429367
[32m[0512 04:45:36 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.21091268956661224, Train Loss: 0.21562309563159943
[32m[0512 04:45:36 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.2109147161245346, Train Loss: 0.21562044322490692
[32m[0512 04:45:36 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.21091672778129578, Train Loss: 0.21561773121356964
[32m[0512 04:45:36 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.21091872453689575, Train Loss: 0.21561504900455475
[32m[0512 04:45:36 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.2109207659959793, Train Loss: 0.21561238169670105
[32m[0512 04:45:36 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.21092279255390167, Train Loss: 0.21560969948768616
[32m[0512 04:45:36 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.21092475950717926, Train Loss: 0.21560701727867126
[32m[0512 04:45:36 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.210926815867424, Train Loss: 0.21560437977313995
[32m[0512 04:45:36 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.2109287828207016, Train Loss: 0.21560172736644745
[32m[0512 04:45:36 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.21093077957630157, Train Loss: 0.21559903025627136
[32m[0512 04:45:36 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.21093279123306274, Train Loss: 0.21559637784957886
[32m[0512 04:45:36 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.21093477308750153, Train Loss: 0.21559371054172516
[32m[0512 04:45:36 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.2109367549419403, Train Loss: 0.21559107303619385
[32m[0512 04:45:36 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.21093875169754028, Train Loss: 0.21558842062950134
[32m[0512 04:45:36 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.21094070374965668, Train Loss: 0.21558578312397003
[32m[0512 04:45:36 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.21094268560409546, Train Loss: 0.21558313071727753
[32m[0512 04:45:37 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.21094463765621185, Train Loss: 0.21558049321174622
[32m[0512 04:45:37 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.21094661951065063, Train Loss: 0.2155778557062149
[32m[0512 04:45:37 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.21094857156276703, Train Loss: 0.2155752182006836
[32m[0512 04:45:37 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.21095053851604462, Train Loss: 0.21557261049747467
[32m[0512 04:45:37 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.210952490568161, Train Loss: 0.21556994318962097
[32m[0512 04:45:37 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.2109544426202774, Train Loss: 0.21556733548641205
[32m[0512 04:45:37 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.2109563797712326, Train Loss: 0.21556469798088074
[32m[0512 04:45:37 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.2109583169221878, Train Loss: 0.21556209027767181
[32m[0512 04:45:37 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.210960254073143, Train Loss: 0.2155594825744629
[32m[0512 04:45:37 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.2109622061252594, Train Loss: 0.21555687487125397
[32m[0512 04:45:37 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.2109641134738922, Train Loss: 0.21555426716804504
[32m[0512 04:45:37 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.2109660655260086, Train Loss: 0.21555162966251373
[32m[0512 04:45:37 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.2109679877758026, Train Loss: 0.215549036860466
[32m[0512 04:45:37 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.21096991002559662, Train Loss: 0.21554642915725708
[32m[0512 04:45:37 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.21097183227539062, Train Loss: 0.21554385125637054
[32m[0512 04:45:37 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.21097375452518463, Train Loss: 0.21554124355316162
[32m[0512 04:45:37 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.21097564697265625, Train Loss: 0.2155386209487915
[32m[0512 04:45:37 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.21097758412361145, Train Loss: 0.21553604304790497
[32m[0512 04:45:37 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.21097949147224426, Train Loss: 0.21553345024585724
[32m[0512 04:45:37 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.21098141372203827, Train Loss: 0.2155308723449707
[32m[0512 04:45:37 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.2109833061695099, Train Loss: 0.21552829444408417
[32m[0512 04:45:37 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.2109851986169815, Train Loss: 0.21552570164203644
[32m[0512 04:45:37 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.21098710596561432, Train Loss: 0.2155231386423111
[32m[0512 04:45:38 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.21098901331424713, Train Loss: 0.21552056074142456
[32m[0512 04:45:38 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.21099090576171875, Train Loss: 0.21551795303821564
[32m[0512 04:45:38 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.21099276840686798, Train Loss: 0.2155153900384903
[32m[0512 04:45:38 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.210994690656662, Train Loss: 0.21551282703876495
[32m[0512 04:45:38 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.21099653840065002, Train Loss: 0.2155102640390396
[32m[0512 04:45:38 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.21099844574928284, Train Loss: 0.21550768613815308
[32m[0512 04:45:38 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.21100029349327087, Train Loss: 0.21550515294075012
[32m[0512 04:45:38 @mbmf_sampler.py:98][0m Finished 9th episode
[32m[0512 04:45:38 @mbmf_sampler.py:102][0m 1809 timesteps from 9 episodes collected
[32m[0512 05:06:28 @mbmf_trainer.py:160][0m Mean reward: -396.56042076259865
[32m[0512 05:06:28 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.20841196179389954, Train Loss: 0.21543698012828827
[32m[0512 05:06:28 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.2084670513868332, Train Loss: 0.2153521627187729
[32m[0512 05:06:28 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.20856018364429474, Train Loss: 0.21531230211257935
[32m[0512 05:06:28 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.20864760875701904, Train Loss: 0.21527747809886932
[32m[0512 05:06:28 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.2087145894765854, Train Loss: 0.21525122225284576
[32m[0512 05:06:28 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.20877189934253693, Train Loss: 0.21523012220859528
[32m[0512 05:06:28 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.20882128179073334, Train Loss: 0.21521201729774475
[32m[0512 05:06:28 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.20886461436748505, Train Loss: 0.2151963859796524
[32m[0512 05:06:28 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.20890302956104279, Train Loss: 0.21518245339393616
[32m[0512 05:06:28 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.20893746614456177, Train Loss: 0.21516984701156616
[32m[0512 05:06:28 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.20896854996681213, Train Loss: 0.21515832841396332
[32m[0512 05:06:29 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.20899686217308044, Train Loss: 0.21514759957790375
[32m[0512 05:06:29 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.20902273058891296, Train Loss: 0.21513761579990387
[32m[0512 05:06:29 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.20904655754566193, Train Loss: 0.21512813866138458
[32m[0512 05:06:29 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.20906862616539001, Train Loss: 0.2151191234588623
[32m[0512 05:06:29 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.20908915996551514, Train Loss: 0.21511054039001465
[32m[0512 05:06:29 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.20910827815532684, Train Loss: 0.21510228514671326
[32m[0512 05:06:29 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.209126278758049, Train Loss: 0.21509431302547455
[32m[0512 05:06:29 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.20914320647716522, Train Loss: 0.21508663892745972
[32m[0512 05:06:29 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.2091592699289322, Train Loss: 0.2150791585445404
[32m[0512 05:06:29 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.2091745138168335, Train Loss: 0.2150719165802002
[32m[0512 05:06:29 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.2091890573501587, Train Loss: 0.2150648683309555
[32m[0512 05:06:29 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.20920294523239136, Train Loss: 0.21505798399448395
[32m[0512 05:06:29 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.20921626687049866, Train Loss: 0.2150513082742691
[32m[0512 05:06:29 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.20922908186912537, Train Loss: 0.21504473686218262
[32m[0512 05:06:29 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.20924144983291626, Train Loss: 0.21503831446170807
[32m[0512 05:06:29 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.2092534303665161, Train Loss: 0.21503201127052307
[32m[0512 05:06:29 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.20926500856876373, Train Loss: 0.21502585709095
[32m[0512 05:06:29 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.2092762440443039, Train Loss: 0.2150198370218277
[32m[0512 05:06:29 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.20928719639778137, Train Loss: 0.21501387655735016
[32m[0512 05:06:29 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.20929788053035736, Train Loss: 0.21500802040100098
[32m[0512 05:06:30 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.20930826663970947, Train Loss: 0.21500228345394135
[32m[0512 05:06:30 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.20931850373744965, Train Loss: 0.21499663591384888
[32m[0512 05:06:30 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.20932844281196594, Train Loss: 0.21499109268188477
[32m[0512 05:06:30 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.2093382179737091, Train Loss: 0.21498559415340424
[32m[0512 05:06:30 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.20934784412384033, Train Loss: 0.21498021483421326
[32m[0512 05:06:30 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.20935721695423126, Train Loss: 0.21497486531734467
[32m[0512 05:06:30 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.20936648547649384, Train Loss: 0.21496963500976562
[32m[0512 05:06:30 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.20937557518482208, Train Loss: 0.21496440470218658
[32m[0512 05:06:30 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.20938456058502197, Train Loss: 0.21495932340621948
[32m[0512 05:06:30 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.20939336717128754, Train Loss: 0.21495428681373596
[32m[0512 05:06:30 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.20940209925174713, Train Loss: 0.21494926512241364
[32m[0512 05:06:30 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.20941069722175598, Train Loss: 0.21494436264038086
[32m[0512 05:06:30 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.2094191610813141, Train Loss: 0.21493946015834808
[32m[0512 05:06:30 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.20942749083042145, Train Loss: 0.21493464708328247
[32m[0512 05:06:30 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.2094358205795288, Train Loss: 0.21492987871170044
[32m[0512 05:06:30 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.20944392681121826, Train Loss: 0.2149251401424408
[32m[0512 05:06:30 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.20945200324058533, Train Loss: 0.21492047607898712
[32m[0512 05:06:30 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.20945997536182404, Train Loss: 0.21491584181785583
[32m[0512 05:06:30 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.20946787297725677, Train Loss: 0.21491126716136932
[32m[0512 05:06:31 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.20947569608688354, Train Loss: 0.214906707406044
[32m[0512 05:06:31 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.20948342978954315, Train Loss: 0.21490217745304108
[32m[0512 05:06:31 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.20949111878871918, Train Loss: 0.2148977667093277
[32m[0512 05:06:31 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.20949867367744446, Train Loss: 0.21489335596561432
[32m[0512 05:06:31 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.20950616896152496, Train Loss: 0.21488898992538452
[32m[0512 05:06:31 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.2095136046409607, Train Loss: 0.21488460898399353
[32m[0512 05:06:31 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.20952098071575165, Train Loss: 0.21488028764724731
[32m[0512 05:06:31 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.20952828228473663, Train Loss: 0.21487604081630707
[32m[0512 05:06:31 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.20953555405139923, Train Loss: 0.21487177908420563
[32m[0512 05:06:31 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.20954273641109467, Train Loss: 0.21486757695674896
[32m[0512 05:06:31 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.20954982936382294, Train Loss: 0.21486340463161469
[32m[0512 05:06:31 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.20955689251422882, Train Loss: 0.21485929191112518
[32m[0512 05:06:31 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.20956386625766754, Train Loss: 0.2148551493883133
[32m[0512 05:06:31 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.20957082509994507, Train Loss: 0.21485105156898499
[32m[0512 05:06:31 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.20957772433757782, Train Loss: 0.21484699845314026
[32m[0512 05:06:31 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.2095845639705658, Train Loss: 0.2148429900407791
[32m[0512 05:06:31 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.209591343998909, Train Loss: 0.21483896672725677
[32m[0512 05:06:31 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.20959807932376862, Train Loss: 0.21483497321605682
[32m[0512 05:06:31 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.20960476994514465, Train Loss: 0.21483102440834045
[32m[0512 05:06:31 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.20961140096187592, Train Loss: 0.21482707560062408
[32m[0512 05:06:32 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.2096179723739624, Train Loss: 0.21482323110103607
[32m[0512 05:06:32 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.2096245139837265, Train Loss: 0.21481932699680328
[32m[0512 05:06:32 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.2096310257911682, Train Loss: 0.21481546759605408
[32m[0512 05:06:32 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.20963744819164276, Train Loss: 0.21481160819530487
[32m[0512 05:06:32 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.2096438854932785, Train Loss: 0.21480779349803925
[32m[0512 05:06:32 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.20965023338794708, Train Loss: 0.21480399370193481
[32m[0512 05:06:32 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.2096565216779709, Train Loss: 0.21480022370815277
[32m[0512 05:06:32 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.2096628099679947, Train Loss: 0.21479648351669312
[32m[0512 05:06:32 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.20966903865337372, Train Loss: 0.21479272842407227
[32m[0512 05:06:32 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.20967523753643036, Train Loss: 0.2147890031337738
[32m[0512 05:06:32 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.20968137681484222, Train Loss: 0.21478532254695892
[32m[0512 05:06:32 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.2096875011920929, Train Loss: 0.21478161215782166
[32m[0512 05:06:32 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.20969358086585999, Train Loss: 0.21477794647216797
[32m[0512 05:06:32 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.2096996009349823, Train Loss: 0.21477432548999786
[32m[0512 05:06:32 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.20970560610294342, Train Loss: 0.21477065980434418
[32m[0512 05:06:32 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.20971155166625977, Train Loss: 0.21476706862449646
[32m[0512 05:06:32 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.2097175270318985, Train Loss: 0.21476346254348755
[32m[0512 05:06:32 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.20972341299057007, Train Loss: 0.21475988626480103
[32m[0512 05:06:32 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.20972928404808044, Train Loss: 0.21475635468959808
[32m[0512 05:06:32 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.20973509550094604, Train Loss: 0.21475273370742798
[32m[0512 05:06:33 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.20974087715148926, Train Loss: 0.21474920213222504
[32m[0512 05:06:33 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.2097465991973877, Train Loss: 0.21474571526050568
[32m[0512 05:06:33 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.2097523808479309, Train Loss: 0.21474219858646393
[32m[0512 05:06:33 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.20975804328918457, Train Loss: 0.21473871171474457
[32m[0512 05:06:33 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.20976370573043823, Train Loss: 0.2147352248430252
[32m[0512 05:06:33 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.2097693532705307, Train Loss: 0.21473173797130585
[32m[0512 05:06:33 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.2097749412059784, Train Loss: 0.21472826600074768
[32m[0512 05:06:33 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.2097804993391037, Train Loss: 0.2147248387336731
[32m[0512 05:06:33 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.209786057472229, Train Loss: 0.21472139656543732
[32m[0512 05:06:33 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.20979154109954834, Train Loss: 0.2147180140018463
[32m[0512 05:06:33 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.20979705452919006, Train Loss: 0.21471461653709412
[32m[0512 05:06:33 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.20980244874954224, Train Loss: 0.21471120417118073
[32m[0512 05:06:33 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.20980790257453918, Train Loss: 0.21470783650875092
[32m[0512 05:06:33 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.20981332659721375, Train Loss: 0.2147044539451599
[32m[0512 05:06:33 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.20981869101524353, Train Loss: 0.2147010713815689
[32m[0512 05:06:33 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.20982402563095093, Train Loss: 0.2146977037191391
[32m[0512 05:06:33 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.20982934534549713, Train Loss: 0.21469439566135406
[32m[0512 05:06:33 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.20983463525772095, Train Loss: 0.21469105780124664
[32m[0512 05:06:33 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.2098398655653, Train Loss: 0.21468773484230042
[32m[0512 05:06:33 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.20984508097171783, Train Loss: 0.21468442678451538
[32m[0512 05:06:33 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.20985032618045807, Train Loss: 0.21468113362789154
[32m[0512 05:06:34 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.20985552668571472, Train Loss: 0.2146778255701065
[32m[0512 05:06:34 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.2098606377840042, Train Loss: 0.21467453241348267
[32m[0512 05:06:34 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.2098657786846161, Train Loss: 0.2146712839603424
[32m[0512 05:06:34 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.20987090468406677, Train Loss: 0.21466803550720215
[32m[0512 05:06:34 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.20987600088119507, Train Loss: 0.2146647572517395
[32m[0512 05:06:34 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.20988106727600098, Train Loss: 0.21466153860092163
[32m[0512 05:06:34 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.2098860889673233, Train Loss: 0.21465830504894257
[32m[0512 05:06:34 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.20989108085632324, Train Loss: 0.2146550714969635
[32m[0512 05:06:34 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.20989608764648438, Train Loss: 0.21465186774730682
[32m[0512 05:06:34 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.20990107953548431, Train Loss: 0.21464866399765015
[32m[0512 05:06:34 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.20990602672100067, Train Loss: 0.21464547514915466
[32m[0512 05:06:34 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.20991094410419464, Train Loss: 0.21464227139949799
[32m[0512 05:06:34 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.20991584658622742, Train Loss: 0.21463905274868011
[32m[0512 05:06:34 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.2099207490682602, Train Loss: 0.21463586390018463
[32m[0512 05:06:34 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.209925577044487, Train Loss: 0.21463270485401154
[32m[0512 05:06:34 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.209930419921875, Train Loss: 0.21462956070899963
[32m[0512 05:06:34 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.2099352478981018, Train Loss: 0.21462641656398773
[32m[0512 05:06:34 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.20994004607200623, Train Loss: 0.21462325751781464
[32m[0512 05:06:34 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.20994481444358826, Train Loss: 0.21462012827396393
[32m[0512 05:06:35 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.2099495530128479, Train Loss: 0.21461701393127441
[32m[0512 05:06:35 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.20995430648326874, Train Loss: 0.2146138697862625
[32m[0512 05:06:35 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.2099590301513672, Train Loss: 0.2146107703447342
[32m[0512 05:06:35 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.20996372401714325, Train Loss: 0.21460765600204468
[32m[0512 05:06:35 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.20996838808059692, Train Loss: 0.21460455656051636
[32m[0512 05:06:35 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.20997308194637299, Train Loss: 0.21460147202014923
[32m[0512 05:06:35 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.20997768640518188, Train Loss: 0.2145983725786209
[32m[0512 05:06:35 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.20998232066631317, Train Loss: 0.21459530293941498
[32m[0512 05:06:35 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.20998695492744446, Train Loss: 0.21459223330020905
[32m[0512 05:06:35 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.20999155938625336, Train Loss: 0.2145891636610031
[32m[0512 05:06:35 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.20999610424041748, Train Loss: 0.214586079120636
[32m[0512 05:06:35 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.2100006639957428, Train Loss: 0.21458302438259125
[32m[0512 05:06:35 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.21000522375106812, Train Loss: 0.2145799994468689
[32m[0512 05:06:35 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.21000967919826508, Train Loss: 0.21457695960998535
[32m[0512 05:06:35 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.21001417934894562, Train Loss: 0.2145739048719406
[32m[0512 05:06:35 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.21001866459846497, Train Loss: 0.21457089483737946
[32m[0512 05:06:35 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.21002314984798431, Train Loss: 0.2145678848028183
[32m[0512 05:06:35 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.2100275605916977, Train Loss: 0.21456481516361237
[32m[0512 05:06:35 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.21003201603889465, Train Loss: 0.2145618349313736
[32m[0512 05:06:36 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.21003642678260803, Train Loss: 0.21455885469913483
[32m[0512 05:06:36 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.21004080772399902, Train Loss: 0.21455584466457367
[32m[0512 05:06:36 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.21004517376422882, Train Loss: 0.21455281972885132
[32m[0512 05:06:36 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.2100495547056198, Train Loss: 0.21454982459545135
[32m[0512 05:06:36 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.21005389094352722, Train Loss: 0.2145468294620514
[32m[0512 05:06:36 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.2100582718849182, Train Loss: 0.21454383432865143
[32m[0512 05:06:36 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.21006256341934204, Train Loss: 0.21454089879989624
[32m[0512 05:06:36 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.21006686985492706, Train Loss: 0.21453791856765747
[32m[0512 05:06:36 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.2100711315870285, Train Loss: 0.21453498303890228
[32m[0512 05:06:36 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.21007539331912994, Train Loss: 0.2145320326089859
[32m[0512 05:06:36 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.210079625248909, Train Loss: 0.21452908217906952
[32m[0512 05:06:36 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.21008391678333282, Train Loss: 0.21452613174915314
[32m[0512 05:06:36 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.21008813381195068, Train Loss: 0.21452318131923676
[32m[0512 05:06:36 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.21009232103824615, Train Loss: 0.21452023088932037
[32m[0512 05:06:36 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.21009652316570282, Train Loss: 0.21451731026172638
[32m[0512 05:06:36 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.2101007103919983, Train Loss: 0.21451438963413239
[32m[0512 05:06:36 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.21010489761829376, Train Loss: 0.2145114541053772
[32m[0512 05:06:36 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.21010904014110565, Train Loss: 0.2145085483789444
[32m[0512 05:06:36 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.21011318266391754, Train Loss: 0.21450567245483398
[32m[0512 05:06:36 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.21011729538440704, Train Loss: 0.21450276672840118
[32m[0512 05:06:37 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.21012139320373535, Train Loss: 0.2144998162984848
[32m[0512 05:06:37 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.21012550592422485, Train Loss: 0.21449695527553558
[32m[0512 05:06:37 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.21012961864471436, Train Loss: 0.21449404954910278
[32m[0512 05:06:37 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.2101336568593979, Train Loss: 0.21449117362499237
[32m[0512 05:06:37 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.2101377248764038, Train Loss: 0.21448826789855957
[32m[0512 05:06:37 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.21014173328876495, Train Loss: 0.21448540687561035
[32m[0512 05:06:37 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.21014580130577087, Train Loss: 0.21448254585266113
[32m[0512 05:06:37 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.2101498246192932, Train Loss: 0.21447968482971191
[32m[0512 05:06:37 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.21015381813049316, Train Loss: 0.2144768089056015
[32m[0512 05:06:37 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.21015781164169312, Train Loss: 0.21447396278381348
[32m[0512 05:06:37 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.21016177535057068, Train Loss: 0.21447111666202545
[32m[0512 05:06:37 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.21016576886177063, Train Loss: 0.21446825563907623
[32m[0512 05:06:37 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.2101697325706482, Train Loss: 0.21446539461612701
[32m[0512 05:06:37 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.21017365157604218, Train Loss: 0.21446256339550018
[32m[0512 05:06:37 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.21017760038375854, Train Loss: 0.21445974707603455
[32m[0512 05:06:37 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.21018151938915253, Train Loss: 0.21445690095424652
[32m[0512 05:06:37 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.21018540859222412, Train Loss: 0.21445408463478088
[32m[0512 05:06:37 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.21018929779529572, Train Loss: 0.21445126831531525
[32m[0512 05:06:37 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.2101932018995285, Train Loss: 0.2144484519958496
[32m[0512 05:06:37 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.2101970762014389, Train Loss: 0.21444563567638397
[32m[0512 05:06:37 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.2102009356021881, Train Loss: 0.21444281935691833
[32m[0512 05:06:38 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.21020478010177612, Train Loss: 0.2144400179386139
[32m[0512 05:06:38 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.21020860970020294, Train Loss: 0.21443720161914825
[32m[0512 05:06:38 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.21021245419979095, Train Loss: 0.21443438529968262
[32m[0512 05:06:38 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.21021626889705658, Train Loss: 0.21443161368370056
[32m[0512 05:06:38 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.210220068693161, Train Loss: 0.2144288420677185
[32m[0512 05:06:38 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.21022386848926544, Train Loss: 0.21442604064941406
[32m[0512 05:06:38 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.21022765338420868, Train Loss: 0.214423269033432
[32m[0512 05:06:38 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.21023143827915192, Train Loss: 0.21442049741744995
[32m[0512 05:06:38 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.21023514866828918, Train Loss: 0.2144176959991455
[32m[0512 05:06:38 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.21023893356323242, Train Loss: 0.21441493928432465
[32m[0512 05:06:38 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.21024267375469208, Train Loss: 0.2144121676683426
[32m[0512 05:06:38 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.21024639904499054, Train Loss: 0.21440941095352173
[32m[0512 05:06:38 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.210250124335289, Train Loss: 0.21440666913986206
[32m[0512 05:06:38 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.21025381982326508, Train Loss: 0.2144039124250412
[32m[0512 05:06:38 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.21025754511356354, Train Loss: 0.21440118551254272
[32m[0512 05:06:38 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.21026121079921722, Train Loss: 0.21439838409423828
[32m[0512 05:06:38 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.2102648913860321, Train Loss: 0.2143956571817398
[32m[0512 05:06:38 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.2102685570716858, Train Loss: 0.21439290046691895
[32m[0512 05:06:38 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.21027220785617828, Train Loss: 0.21439018845558167
[32m[0512 05:06:38 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.21027585864067078, Train Loss: 0.2143874615430832
[32m[0512 05:06:39 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.21027947962284088, Train Loss: 0.21438470482826233
[32m[0512 05:06:39 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.21028313040733337, Train Loss: 0.21438199281692505
[32m[0512 05:06:39 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.21028676629066467, Train Loss: 0.21437931060791016
[32m[0512 05:06:39 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.2102903574705124, Train Loss: 0.21437658369541168
[32m[0512 05:06:39 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.2102939635515213, Train Loss: 0.21437384188175201
[32m[0512 05:06:39 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.21029753983020782, Train Loss: 0.21437115967273712
[32m[0512 05:06:39 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.21030116081237793, Train Loss: 0.21436843276023865
[32m[0512 05:06:39 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.21030473709106445, Train Loss: 0.21436573565006256
[32m[0512 05:06:39 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.2103082835674286, Train Loss: 0.21436305344104767
[32m[0512 05:06:39 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.21031181514263153, Train Loss: 0.21436037123203278
[32m[0512 05:06:39 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.21031539142131805, Train Loss: 0.2143576741218567
[32m[0512 05:06:39 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.210318922996521, Train Loss: 0.2143549919128418
[32m[0512 05:06:39 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.21032242476940155, Train Loss: 0.2143523097038269
[32m[0512 05:06:39 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.21032600104808807, Train Loss: 0.21434961259365082
[32m[0512 05:06:39 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.21032947301864624, Train Loss: 0.21434694528579712
[32m[0512 05:06:39 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.21033300459384918, Train Loss: 0.21434427797794342
[32m[0512 05:06:39 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.21033647656440735, Train Loss: 0.21434159576892853
[32m[0512 05:06:39 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.2103399634361267, Train Loss: 0.21433895826339722
[32m[0512 05:06:39 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.21034343540668488, Train Loss: 0.21433629095554352
[32m[0512 05:06:39 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.21034686267375946, Train Loss: 0.214333638548851
[32m[0512 05:06:40 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.21035034954547882, Train Loss: 0.21433095633983612
[32m[0512 05:06:40 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.2103537917137146, Train Loss: 0.2143283486366272
[32m[0512 05:06:40 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.21035727858543396, Train Loss: 0.2143256664276123
[32m[0512 05:06:40 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.21036067605018616, Train Loss: 0.214323028922081
[32m[0512 05:06:40 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.21036413311958313, Train Loss: 0.21432040631771088
[32m[0512 05:06:40 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.21036756038665771, Train Loss: 0.21431775391101837
[32m[0512 05:06:40 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.21037094295024872, Train Loss: 0.21431508660316467
[32m[0512 05:06:40 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.21037434041500092, Train Loss: 0.21431246399879456
[32m[0512 05:06:40 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.2103777527809143, Train Loss: 0.21430984139442444
[32m[0512 05:06:40 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.2103811353445053, Train Loss: 0.2143072485923767
[32m[0512 05:06:40 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.21038450300693512, Train Loss: 0.2143045961856842
[32m[0512 05:06:40 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.21038784086704254, Train Loss: 0.21430201828479767
[32m[0512 05:06:40 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.21039122343063354, Train Loss: 0.21429939568042755
[32m[0512 05:06:40 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.21039454638957977, Train Loss: 0.21429680287837982
[32m[0512 05:06:40 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.21039792895317078, Train Loss: 0.2142941802740097
[32m[0512 05:06:40 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.2104012668132782, Train Loss: 0.2142915576696396
[32m[0512 05:06:40 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.21040458977222443, Train Loss: 0.21428894996643066
[32m[0512 05:06:40 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.21040789783000946, Train Loss: 0.21428637206554413
[32m[0512 05:06:40 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.2104112058877945, Train Loss: 0.214283749461174
[32m[0512 05:06:40 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.21041454374790192, Train Loss: 0.21428117156028748
[32m[0512 05:06:40 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.21041782200336456, Train Loss: 0.21427860856056213
[32m[0512 05:06:41 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.2104211002588272, Train Loss: 0.2142760157585144
[32m[0512 05:06:41 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.21042443811893463, Train Loss: 0.21427343785762787
[32m[0512 05:06:41 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.2104276865720749, Train Loss: 0.21427081525325775
[32m[0512 05:06:41 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.21043094992637634, Train Loss: 0.2142682671546936
[32m[0512 05:06:41 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.210434228181839, Train Loss: 0.21426571905612946
[32m[0512 05:06:41 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.21043746173381805, Train Loss: 0.21426314115524292
[32m[0512 05:06:41 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.2104407250881195, Train Loss: 0.21426057815551758
[32m[0512 05:06:41 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.21044395864009857, Train Loss: 0.21425801515579224
[32m[0512 05:06:41 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.21044720709323883, Train Loss: 0.2142554372549057
[32m[0512 05:06:41 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.21045039594173431, Train Loss: 0.21425290405750275
[32m[0512 05:06:41 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.21045365929603577, Train Loss: 0.2142503410577774
[32m[0512 05:06:41 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.21045686304569244, Train Loss: 0.21424779295921326
[32m[0512 05:06:41 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.21046003699302673, Train Loss: 0.21424522995948792
[32m[0512 05:06:41 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.2104632705450058, Train Loss: 0.21424271166324615
[32m[0512 05:06:41 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.21046645939350128, Train Loss: 0.214240163564682
[32m[0512 05:06:41 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.21046964824199677, Train Loss: 0.21423760056495667
[32m[0512 05:06:41 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.21047285199165344, Train Loss: 0.2142351120710373
[32m[0512 05:06:41 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.21047601103782654, Train Loss: 0.21423254907131195
[32m[0512 05:06:41 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.21047917008399963, Train Loss: 0.21423004567623138
[32m[0512 05:06:41 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.21048235893249512, Train Loss: 0.21422752737998962
[32m[0512 05:06:42 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.21048548817634583, Train Loss: 0.2142249494791031
[32m[0512 05:06:42 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.21048863232135773, Train Loss: 0.21422244608402252
[32m[0512 05:06:42 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.21049179136753082, Train Loss: 0.21421995759010315
[32m[0512 05:06:42 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.21049492061138153, Train Loss: 0.2142174243927002
[32m[0512 05:06:42 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.21049800515174866, Train Loss: 0.21421495079994202
[32m[0512 05:06:42 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.21050111949443817, Train Loss: 0.21421240270137787
[32m[0512 05:06:42 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.21050424873828888, Train Loss: 0.2142098993062973
[32m[0512 05:06:42 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.21050739288330078, Train Loss: 0.21420741081237793
[32m[0512 05:06:42 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.2105104774236679, Train Loss: 0.21420492231845856
[32m[0512 05:06:42 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.21051356196403503, Train Loss: 0.2142024040222168
[32m[0512 05:06:42 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.21051667630672455, Train Loss: 0.21419993042945862
[32m[0512 05:06:42 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.2105197310447693, Train Loss: 0.21419745683670044
[32m[0512 05:06:42 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.21052277088165283, Train Loss: 0.21419495344161987
[32m[0512 05:06:42 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.21052582561969757, Train Loss: 0.2141924947500229
[32m[0512 05:06:42 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.2105289101600647, Train Loss: 0.21418999135494232
[32m[0512 05:06:42 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.21053197979927063, Train Loss: 0.21418751776218414
[32m[0512 05:06:42 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.21053503453731537, Train Loss: 0.21418505907058716
[32m[0512 05:06:42 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.2105380743741989, Train Loss: 0.21418257057666779
[32m[0512 05:06:42 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.21054111421108246, Train Loss: 0.2141800969839096
[32m[0512 05:06:42 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.21054412424564362, Train Loss: 0.21417762339115143
[32m[0512 05:06:42 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.21054716408252716, Train Loss: 0.21417517960071564
[32m[0512 05:06:43 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.21055015921592712, Train Loss: 0.21417273581027985
[32m[0512 05:06:43 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.21055318415164948, Train Loss: 0.21417026221752167
[32m[0512 05:06:43 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.21055620908737183, Train Loss: 0.21416781842708588
[32m[0512 05:06:43 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.2105591595172882, Train Loss: 0.2141653597354889
[32m[0512 05:06:43 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.21056219935417175, Train Loss: 0.2141628861427307
[32m[0512 05:06:43 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.21056519448757172, Train Loss: 0.21416045725345612
[32m[0512 05:06:43 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.2105681598186493, Train Loss: 0.21415801346302032
[32m[0512 05:06:43 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.21057114005088806, Train Loss: 0.21415561437606812
[32m[0512 05:06:43 @mbmf_main.py:224][0m batch size for trpo is 1000
[32m[0512 05:06:43 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 05:06:43 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 05:06:43 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 05:06:43 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 05:06:43 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 05:06:43 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 05:06:43 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 05:06:43 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 05:06:43 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 05:06:43 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 05:06:43 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 05:06:43 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 05:06:43 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 05:06:43 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 05:06:43 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 05:06:43 @mbmf_main.py:132][0m Training starts at /root/mbbl
[32m[0512 05:06:43 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 05:06:43 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 05:06:43 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 05:06:43 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 05:06:43 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 05:06:43 @base_worker.py:45][0m Worker 0 online
[32m[0512 05:06:43 @base_worker.py:45][0m Worker 1 online
[32m[0512 05:06:43 @base_worker.py:45][0m Worker 2 online
[32m[0512 05:06:43 @base_worker.py:45][0m Worker 3 online
[32m[0512 05:06:43 @base_worker.py:45][0m Worker 4 online
[32m[0512 05:06:43 @base_worker.py:45][0m Worker 5 online
[32m[0512 05:06:43 @base_worker.py:45][0m Worker 6 online
[32m[0512 05:06:43 @base_worker.py:45][0m Worker 7 online
[32m[0512 05:06:43 @base_worker.py:45][0m Worker 8 online
[32m[0512 05:06:43 @base_worker.py:45][0m Worker 9 online
[32m[0512 05:06:43 @base_worker.py:45][0m Worker 10 online
[32m[0512 05:06:43 @base_worker.py:45][0m Worker 11 online
[32m[0512 05:06:43 @base_worker.py:45][0m Worker 12 online
[32m[0512 05:06:43 @base_worker.py:45][0m Worker 13 online
[32m[0512 05:06:43 @base_worker.py:45][0m Worker 14 online
[32m[0512 05:06:43 @base_worker.py:45][0m Worker 15 online
[32m[0512 05:06:43 @base_worker.py:45][0m Worker 16 online
[32m[0512 05:06:43 @base_worker.py:45][0m Worker 17 online
[32m[0512 05:06:43 @base_worker.py:45][0m Worker 18 online
[32m[0512 05:06:43 @base_worker.py:45][0m Worker 19 online
[32m[0512 05:06:44 @base_trainer.py:152][0m Trainer maintains [1] policy network
[32m[0512 05:06:44 @base_trainer.py:152][0m Trainer maintains [1] dynamics network
[32m[0512 05:06:44 @base_trainer.py:152][0m Trainer maintains [1] reward network
[32m[0512 05:06:44 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:06:44 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:06:44 @base_trainer.py:216][0m Mean reward: -298.64690722550915
[32m[0512 05:06:45 @base_main.py:38][0m --------------- Iteration 1 ---------------
[32m[0512 05:06:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0000 mins
[32m[0512 05:06:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0054 mins
[32m[0512 05:06:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0153 mins
[32m[0512 05:06:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:06:45 @base_main.py:47][0m 1005 total steps have happened
[32m[0512 05:06:45 @base_main.py:52][0m [avg_reward]: -298.64690722550915
[32m[0512 05:06:46 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:06:46 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:06:46 @base_trainer.py:216][0m Mean reward: -388.2449142050799
[32m[0512 05:06:46 @base_main.py:38][0m --------------- Iteration 2 ---------------
[32m[0512 05:06:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0208 mins
[32m[0512 05:06:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0048 mins
[32m[0512 05:06:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 05:06:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:06:46 @base_main.py:47][0m 2010 total steps have happened
[32m[0512 05:06:46 @base_main.py:52][0m [avg_reward]: -388.2449142050799
[32m[0512 05:06:46 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:06:46 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:06:46 @base_trainer.py:216][0m Mean reward: -205.78496229938543
[32m[0512 05:06:47 @base_main.py:38][0m --------------- Iteration 3 ---------------
[32m[0512 05:06:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0345 mins
[32m[0512 05:06:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0049 mins
[32m[0512 05:06:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0512 05:06:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:06:47 @base_main.py:47][0m 3015 total steps have happened
[32m[0512 05:06:47 @base_main.py:52][0m [avg_reward]: -205.78496229938543
[32m[0512 05:06:47 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:06:47 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:06:47 @base_trainer.py:216][0m Mean reward: -362.3171679788835
[32m[0512 05:06:48 @base_main.py:38][0m --------------- Iteration 4 ---------------
[32m[0512 05:06:48 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0483 mins
[32m[0512 05:06:48 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0044 mins
[32m[0512 05:06:48 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0512 05:06:48 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 05:06:48 @base_main.py:47][0m 4020 total steps have happened
[32m[0512 05:06:48 @base_main.py:52][0m [avg_reward]: -362.3171679788835
[32m[0512 05:06:48 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:06:48 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:06:48 @base_trainer.py:216][0m Mean reward: -444.7814117523791
[32m[0512 05:06:49 @base_main.py:38][0m --------------- Iteration 5 ---------------
[32m[0512 05:06:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0623 mins
[32m[0512 05:06:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 05:06:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 05:06:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 05:06:49 @base_main.py:47][0m 5025 total steps have happened
[32m[0512 05:06:49 @base_main.py:52][0m [avg_reward]: -444.7814117523791
[32m[0512 05:06:49 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:06:49 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:06:49 @base_trainer.py:216][0m Mean reward: -354.8300212508435
[32m[0512 05:06:49 @base_main.py:38][0m --------------- Iteration 6 ---------------
[32m[0512 05:06:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0741 mins
[32m[0512 05:06:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 05:06:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 05:06:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:06:49 @base_main.py:47][0m 6030 total steps have happened
[32m[0512 05:06:49 @base_main.py:52][0m [avg_reward]: -354.8300212508435
[32m[0512 05:06:49 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:06:49 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:06:49 @base_trainer.py:216][0m Mean reward: -360.1763939086164
[32m[0512 05:06:50 @base_main.py:38][0m --------------- Iteration 7 ---------------
[32m[0512 05:06:50 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0859 mins
[32m[0512 05:06:50 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0040 mins
[32m[0512 05:06:50 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 05:06:50 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:06:50 @base_main.py:47][0m 7035 total steps have happened
[32m[0512 05:06:50 @base_main.py:52][0m [avg_reward]: -360.1763939086164
[32m[0512 05:06:50 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:06:50 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:06:50 @base_trainer.py:216][0m Mean reward: -228.47680466854263
[32m[0512 05:06:51 @base_main.py:38][0m --------------- Iteration 8 ---------------
[32m[0512 05:06:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0990 mins
[32m[0512 05:06:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 05:06:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0084 mins
[32m[0512 05:06:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:06:51 @base_main.py:47][0m 8040 total steps have happened
[32m[0512 05:06:51 @base_main.py:52][0m [avg_reward]: -228.47680466854263
[32m[0512 05:06:51 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:06:51 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:06:51 @base_trainer.py:216][0m Mean reward: -267.26160238585305
[32m[0512 05:06:51 @base_main.py:38][0m --------------- Iteration 9 ---------------
[32m[0512 05:06:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1102 mins
[32m[0512 05:06:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 05:06:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 05:06:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:06:51 @base_main.py:47][0m 9045 total steps have happened
[32m[0512 05:06:51 @base_main.py:52][0m [avg_reward]: -267.26160238585305
[32m[0512 05:06:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:06:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:06:52 @base_trainer.py:216][0m Mean reward: -256.6911373326211
[32m[0512 05:06:52 @base_main.py:38][0m --------------- Iteration 10 ---------------
[32m[0512 05:06:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1221 mins
[32m[0512 05:06:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0035 mins
[32m[0512 05:06:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0512 05:06:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:06:52 @base_main.py:47][0m 10050 total steps have happened
[32m[0512 05:06:52 @base_main.py:52][0m [avg_reward]: -256.6911373326211
[32m[0512 05:06:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:06:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:06:52 @base_trainer.py:216][0m Mean reward: -243.40391027173737
[32m[0512 05:06:53 @base_main.py:38][0m --------------- Iteration 11 ---------------
[32m[0512 05:06:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1343 mins
[32m[0512 05:06:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0512 05:06:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0512 05:06:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:06:53 @base_main.py:47][0m 11055 total steps have happened
[32m[0512 05:06:53 @base_main.py:52][0m [avg_reward]: -243.40391027173737
[32m[0512 05:06:53 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:06:53 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:06:53 @base_trainer.py:216][0m Mean reward: -322.97236862675544
[32m[0512 05:06:54 @base_main.py:38][0m --------------- Iteration 12 ---------------
[32m[0512 05:06:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1463 mins
[32m[0512 05:06:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 05:06:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0512 05:06:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 05:06:54 @base_main.py:47][0m 12060 total steps have happened
[32m[0512 05:06:54 @base_main.py:52][0m [avg_reward]: -322.97236862675544
[32m[0512 05:06:54 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:06:54 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:06:54 @base_trainer.py:216][0m Mean reward: -199.56116396094384
[32m[0512 05:06:54 @base_main.py:38][0m --------------- Iteration 13 ---------------
[32m[0512 05:06:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1581 mins
[32m[0512 05:06:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 05:06:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0512 05:06:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 05:06:54 @base_main.py:47][0m 13065 total steps have happened
[32m[0512 05:06:54 @base_main.py:52][0m [avg_reward]: -199.56116396094384
[32m[0512 05:06:54 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:06:54 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:06:54 @base_trainer.py:216][0m Mean reward: -299.76342617785974
[32m[0512 05:06:55 @base_main.py:38][0m --------------- Iteration 14 ---------------
[32m[0512 05:06:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1706 mins
[32m[0512 05:06:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 05:06:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 05:06:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 05:06:55 @base_main.py:47][0m 14070 total steps have happened
[32m[0512 05:06:55 @base_main.py:52][0m [avg_reward]: -299.76342617785974
[32m[0512 05:06:55 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:06:55 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:06:55 @base_trainer.py:216][0m Mean reward: -367.3101608555081
[32m[0512 05:06:56 @base_main.py:38][0m --------------- Iteration 15 ---------------
[32m[0512 05:06:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1824 mins
[32m[0512 05:06:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 05:06:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0512 05:06:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 05:06:56 @base_main.py:47][0m 15075 total steps have happened
[32m[0512 05:06:56 @base_main.py:52][0m [avg_reward]: -367.3101608555081
[32m[0512 05:06:56 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:06:56 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:06:56 @base_trainer.py:216][0m Mean reward: -274.37604155190036
[32m[0512 05:06:56 @base_main.py:38][0m --------------- Iteration 16 ---------------
[32m[0512 05:06:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1943 mins
[32m[0512 05:06:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 05:06:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 05:06:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:06:56 @base_main.py:47][0m 16080 total steps have happened
[32m[0512 05:06:56 @base_main.py:52][0m [avg_reward]: -274.37604155190036
[32m[0512 05:06:57 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:06:57 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:06:57 @base_trainer.py:216][0m Mean reward: -254.3700821599901
[32m[0512 05:06:57 @base_main.py:38][0m --------------- Iteration 17 ---------------
[32m[0512 05:06:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2056 mins
[32m[0512 05:06:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 05:06:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 05:06:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 05:06:57 @base_main.py:47][0m 17085 total steps have happened
[32m[0512 05:06:57 @base_main.py:52][0m [avg_reward]: -254.3700821599901
[32m[0512 05:06:57 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:06:57 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:06:57 @base_trainer.py:216][0m Mean reward: -240.20616402393793
[32m[0512 05:06:58 @base_main.py:38][0m --------------- Iteration 18 ---------------
[32m[0512 05:06:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2175 mins
[32m[0512 05:06:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:06:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0512 05:06:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 05:06:58 @base_main.py:47][0m 18090 total steps have happened
[32m[0512 05:06:58 @base_main.py:52][0m [avg_reward]: -240.20616402393793
[32m[0512 05:06:58 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:06:58 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:06:58 @base_trainer.py:216][0m Mean reward: -333.9610704673886
[32m[0512 05:06:59 @base_main.py:38][0m --------------- Iteration 19 ---------------
[32m[0512 05:06:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2291 mins
[32m[0512 05:06:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:06:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0512 05:06:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:06:59 @base_main.py:47][0m 19095 total steps have happened
[32m[0512 05:06:59 @base_main.py:52][0m [avg_reward]: -333.9610704673886
[32m[0512 05:06:59 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:06:59 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:06:59 @base_trainer.py:216][0m Mean reward: -292.8628046711785
[32m[0512 05:06:59 @base_main.py:38][0m --------------- Iteration 20 ---------------
[32m[0512 05:06:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2409 mins
[32m[0512 05:06:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:06:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0512 05:06:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:06:59 @base_main.py:47][0m 20100 total steps have happened
[32m[0512 05:06:59 @base_main.py:52][0m [avg_reward]: -292.8628046711785
[32m[0512 05:06:59 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:06:59 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:06:59 @base_trainer.py:216][0m Mean reward: -269.3446696679872
[32m[0512 05:07:00 @base_main.py:38][0m --------------- Iteration 21 ---------------
[32m[0512 05:07:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2524 mins
[32m[0512 05:07:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 05:07:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0082 mins
[32m[0512 05:07:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:00 @base_main.py:47][0m 21105 total steps have happened
[32m[0512 05:07:00 @base_main.py:52][0m [avg_reward]: -269.3446696679872
[32m[0512 05:07:00 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:00 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:00 @base_trainer.py:216][0m Mean reward: -179.41567169887827
[32m[0512 05:07:01 @base_main.py:38][0m --------------- Iteration 22 ---------------
[32m[0512 05:07:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2634 mins
[32m[0512 05:07:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 05:07:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0512 05:07:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:01 @base_main.py:47][0m 22110 total steps have happened
[32m[0512 05:07:01 @base_main.py:52][0m [avg_reward]: -179.41567169887827
[32m[0512 05:07:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:01 @base_trainer.py:216][0m Mean reward: -223.2040156507216
[32m[0512 05:07:01 @base_main.py:38][0m --------------- Iteration 23 ---------------
[32m[0512 05:07:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2747 mins
[32m[0512 05:07:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:07:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 05:07:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:01 @base_main.py:47][0m 23115 total steps have happened
[32m[0512 05:07:01 @base_main.py:52][0m [avg_reward]: -223.2040156507216
[32m[0512 05:07:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:01 @base_trainer.py:216][0m Mean reward: -233.09901652660605
[32m[0512 05:07:02 @base_main.py:38][0m --------------- Iteration 24 ---------------
[32m[0512 05:07:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2866 mins
[32m[0512 05:07:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:07:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0512 05:07:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:02 @base_main.py:47][0m 24120 total steps have happened
[32m[0512 05:07:02 @base_main.py:52][0m [avg_reward]: -233.09901652660605
[32m[0512 05:07:02 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:02 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:02 @base_trainer.py:216][0m Mean reward: -186.69009388135305
[32m[0512 05:07:03 @base_main.py:38][0m --------------- Iteration 25 ---------------
[32m[0512 05:07:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2986 mins
[32m[0512 05:07:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 05:07:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0081 mins
[32m[0512 05:07:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 05:07:03 @base_main.py:47][0m 25125 total steps have happened
[32m[0512 05:07:03 @base_main.py:52][0m [avg_reward]: -186.69009388135305
[32m[0512 05:07:03 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:03 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:03 @base_trainer.py:216][0m Mean reward: -179.48980886173652
[32m[0512 05:07:03 @base_main.py:38][0m --------------- Iteration 26 ---------------
[32m[0512 05:07:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3096 mins
[32m[0512 05:07:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:07:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0512 05:07:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:03 @base_main.py:47][0m 26130 total steps have happened
[32m[0512 05:07:03 @base_main.py:52][0m [avg_reward]: -179.48980886173652
[32m[0512 05:07:04 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:04 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:04 @base_trainer.py:216][0m Mean reward: -167.2453188813617
[32m[0512 05:07:04 @base_main.py:38][0m --------------- Iteration 27 ---------------
[32m[0512 05:07:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3214 mins
[32m[0512 05:07:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0512 05:07:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0512 05:07:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:04 @base_main.py:47][0m 27135 total steps have happened
[32m[0512 05:07:04 @base_main.py:52][0m [avg_reward]: -167.2453188813617
[32m[0512 05:07:04 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:04 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:04 @base_trainer.py:216][0m Mean reward: -198.53083814205647
[32m[0512 05:07:05 @base_main.py:38][0m --------------- Iteration 28 ---------------
[32m[0512 05:07:05 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3339 mins
[32m[0512 05:07:05 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0032 mins
[32m[0512 05:07:05 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0512 05:07:05 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:05 @base_main.py:47][0m 28140 total steps have happened
[32m[0512 05:07:05 @base_main.py:52][0m [avg_reward]: -198.53083814205647
[32m[0512 05:07:05 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:05 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:05 @base_trainer.py:216][0m Mean reward: -196.16119200226245
[32m[0512 05:07:06 @base_main.py:38][0m --------------- Iteration 29 ---------------
[32m[0512 05:07:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3469 mins
[32m[0512 05:07:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 05:07:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 05:07:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:06 @base_main.py:47][0m 29145 total steps have happened
[32m[0512 05:07:06 @base_main.py:52][0m [avg_reward]: -196.16119200226245
[32m[0512 05:07:06 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:06 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:06 @base_trainer.py:216][0m Mean reward: -204.6858612653679
[32m[0512 05:07:06 @base_main.py:38][0m --------------- Iteration 30 ---------------
[32m[0512 05:07:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3587 mins
[32m[0512 05:07:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:07:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 05:07:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:06 @base_main.py:47][0m 30150 total steps have happened
[32m[0512 05:07:06 @base_main.py:52][0m [avg_reward]: -204.6858612653679
[32m[0512 05:07:06 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:06 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:06 @base_trainer.py:216][0m Mean reward: -238.5598301585939
[32m[0512 05:07:07 @base_main.py:38][0m --------------- Iteration 31 ---------------
[32m[0512 05:07:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3703 mins
[32m[0512 05:07:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:07:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0512 05:07:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:07 @base_main.py:47][0m 31155 total steps have happened
[32m[0512 05:07:07 @base_main.py:52][0m [avg_reward]: -238.5598301585939
[32m[0512 05:07:07 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:07 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:07 @base_trainer.py:216][0m Mean reward: -251.9158145416597
[32m[0512 05:07:08 @base_main.py:38][0m --------------- Iteration 32 ---------------
[32m[0512 05:07:08 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3821 mins
[32m[0512 05:07:08 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 05:07:08 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0512 05:07:08 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:08 @base_main.py:47][0m 32160 total steps have happened
[32m[0512 05:07:08 @base_main.py:52][0m [avg_reward]: -251.9158145416597
[32m[0512 05:07:08 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:08 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:08 @base_trainer.py:216][0m Mean reward: -188.20503000085955
[32m[0512 05:07:09 @base_main.py:38][0m --------------- Iteration 33 ---------------
[32m[0512 05:07:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3943 mins
[32m[0512 05:07:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0512 05:07:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0512 05:07:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:09 @base_main.py:47][0m 33165 total steps have happened
[32m[0512 05:07:09 @base_main.py:52][0m [avg_reward]: -188.20503000085955
[32m[0512 05:07:09 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:09 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:09 @base_trainer.py:216][0m Mean reward: -198.98647366820325
[32m[0512 05:07:09 @base_main.py:38][0m --------------- Iteration 34 ---------------
[32m[0512 05:07:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4073 mins
[32m[0512 05:07:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 05:07:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0512 05:07:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 05:07:09 @base_main.py:47][0m 34170 total steps have happened
[32m[0512 05:07:09 @base_main.py:52][0m [avg_reward]: -198.98647366820325
[32m[0512 05:07:09 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:09 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:09 @base_trainer.py:216][0m Mean reward: -213.89222865132925
[32m[0512 05:07:10 @base_main.py:38][0m --------------- Iteration 35 ---------------
[32m[0512 05:07:10 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4198 mins
[32m[0512 05:07:10 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 05:07:10 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0512 05:07:10 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:10 @base_main.py:47][0m 35175 total steps have happened
[32m[0512 05:07:10 @base_main.py:52][0m [avg_reward]: -213.89222865132925
[32m[0512 05:07:10 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:10 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:10 @base_trainer.py:216][0m Mean reward: -145.54686021885735
[32m[0512 05:07:11 @base_main.py:38][0m --------------- Iteration 36 ---------------
[32m[0512 05:07:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4314 mins
[32m[0512 05:07:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 05:07:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0512 05:07:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:11 @base_main.py:47][0m 36180 total steps have happened
[32m[0512 05:07:11 @base_main.py:52][0m [avg_reward]: -145.54686021885735
[32m[0512 05:07:11 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:11 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:11 @base_trainer.py:216][0m Mean reward: -211.41963420870076
[32m[0512 05:07:11 @base_main.py:38][0m --------------- Iteration 37 ---------------
[32m[0512 05:07:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4427 mins
[32m[0512 05:07:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 05:07:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0512 05:07:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:11 @base_main.py:47][0m 37185 total steps have happened
[32m[0512 05:07:11 @base_main.py:52][0m [avg_reward]: -211.41963420870076
[32m[0512 05:07:11 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:11 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:11 @base_trainer.py:216][0m Mean reward: -184.4667049329552
[32m[0512 05:07:12 @base_main.py:38][0m --------------- Iteration 38 ---------------
[32m[0512 05:07:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4539 mins
[32m[0512 05:07:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 05:07:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0512 05:07:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:12 @base_main.py:47][0m 38190 total steps have happened
[32m[0512 05:07:12 @base_main.py:52][0m [avg_reward]: -184.4667049329552
[32m[0512 05:07:12 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:12 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:12 @base_trainer.py:216][0m Mean reward: -148.0875261844414
[32m[0512 05:07:13 @base_main.py:38][0m --------------- Iteration 39 ---------------
[32m[0512 05:07:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4654 mins
[32m[0512 05:07:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 05:07:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0512 05:07:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 05:07:13 @base_main.py:47][0m 39195 total steps have happened
[32m[0512 05:07:13 @base_main.py:52][0m [avg_reward]: -148.0875261844414
[32m[0512 05:07:13 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:13 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:13 @base_trainer.py:216][0m Mean reward: -153.8946333480981
[32m[0512 05:07:13 @base_main.py:38][0m --------------- Iteration 40 ---------------
[32m[0512 05:07:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4774 mins
[32m[0512 05:07:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0032 mins
[32m[0512 05:07:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 05:07:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 05:07:13 @base_main.py:47][0m 40200 total steps have happened
[32m[0512 05:07:13 @base_main.py:52][0m [avg_reward]: -153.8946333480981
[32m[0512 05:07:14 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:14 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:14 @base_trainer.py:216][0m Mean reward: -155.7558738160072
[32m[0512 05:07:14 @base_main.py:38][0m --------------- Iteration 41 ---------------
[32m[0512 05:07:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4898 mins
[32m[0512 05:07:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:07:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 05:07:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:14 @base_main.py:47][0m 41205 total steps have happened
[32m[0512 05:07:14 @base_main.py:52][0m [avg_reward]: -155.7558738160072
[32m[0512 05:07:14 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:14 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:14 @base_trainer.py:216][0m Mean reward: -170.01954683617078
[32m[0512 05:07:15 @base_main.py:38][0m --------------- Iteration 42 ---------------
[32m[0512 05:07:15 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5017 mins
[32m[0512 05:07:15 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:07:15 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0512 05:07:15 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:15 @base_main.py:47][0m 42210 total steps have happened
[32m[0512 05:07:15 @base_main.py:52][0m [avg_reward]: -170.01954683617078
[32m[0512 05:07:15 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:15 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:15 @base_trainer.py:216][0m Mean reward: -193.5717264955897
[32m[0512 05:07:16 @base_main.py:38][0m --------------- Iteration 43 ---------------
[32m[0512 05:07:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5135 mins
[32m[0512 05:07:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:07:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0512 05:07:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:16 @base_main.py:47][0m 43215 total steps have happened
[32m[0512 05:07:16 @base_main.py:52][0m [avg_reward]: -193.5717264955897
[32m[0512 05:07:16 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:16 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:16 @base_trainer.py:216][0m Mean reward: -196.26020637066773
[32m[0512 05:07:16 @base_main.py:38][0m --------------- Iteration 44 ---------------
[32m[0512 05:07:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5251 mins
[32m[0512 05:07:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 05:07:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0512 05:07:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 05:07:16 @base_main.py:47][0m 44220 total steps have happened
[32m[0512 05:07:16 @base_main.py:52][0m [avg_reward]: -196.26020637066773
[32m[0512 05:07:16 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:16 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:16 @base_trainer.py:216][0m Mean reward: -176.56228782015174
[32m[0512 05:07:17 @base_main.py:38][0m --------------- Iteration 45 ---------------
[32m[0512 05:07:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5365 mins
[32m[0512 05:07:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 05:07:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 05:07:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:17 @base_main.py:47][0m 45225 total steps have happened
[32m[0512 05:07:17 @base_main.py:52][0m [avg_reward]: -176.56228782015174
[32m[0512 05:07:17 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:17 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:17 @base_trainer.py:216][0m Mean reward: -180.8705241279623
[32m[0512 05:07:18 @base_main.py:38][0m --------------- Iteration 46 ---------------
[32m[0512 05:07:18 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5485 mins
[32m[0512 05:07:18 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:07:18 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0084 mins
[32m[0512 05:07:18 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 05:07:18 @base_main.py:47][0m 46230 total steps have happened
[32m[0512 05:07:18 @base_main.py:52][0m [avg_reward]: -180.8705241279623
[32m[0512 05:07:18 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:18 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:18 @base_trainer.py:216][0m Mean reward: -201.8763481481082
[32m[0512 05:07:18 @base_main.py:38][0m --------------- Iteration 47 ---------------
[32m[0512 05:07:18 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5599 mins
[32m[0512 05:07:18 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 05:07:18 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0084 mins
[32m[0512 05:07:18 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:18 @base_main.py:47][0m 47235 total steps have happened
[32m[0512 05:07:18 @base_main.py:52][0m [avg_reward]: -201.8763481481082
[32m[0512 05:07:18 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:18 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:18 @base_trainer.py:216][0m Mean reward: -206.66704535013824
[32m[0512 05:07:19 @base_main.py:38][0m --------------- Iteration 48 ---------------
[32m[0512 05:07:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5709 mins
[32m[0512 05:07:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0512 05:07:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0512 05:07:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:19 @base_main.py:47][0m 48240 total steps have happened
[32m[0512 05:07:19 @base_main.py:52][0m [avg_reward]: -206.66704535013824
[32m[0512 05:07:19 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:19 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:19 @base_trainer.py:216][0m Mean reward: -182.0141411101324
[32m[0512 05:07:20 @base_main.py:38][0m --------------- Iteration 49 ---------------
[32m[0512 05:07:20 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5819 mins
[32m[0512 05:07:20 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 05:07:20 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 05:07:20 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0512 05:07:20 @base_main.py:47][0m 49245 total steps have happened
[32m[0512 05:07:20 @base_main.py:52][0m [avg_reward]: -182.0141411101324
[32m[0512 05:07:20 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:20 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:20 @base_trainer.py:216][0m Mean reward: -184.9832879305081
[32m[0512 05:07:20 @base_main.py:38][0m --------------- Iteration 50 ---------------
[32m[0512 05:07:20 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5942 mins
[32m[0512 05:07:20 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 05:07:20 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0081 mins
[32m[0512 05:07:20 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:20 @base_main.py:47][0m 50250 total steps have happened
[32m[0512 05:07:20 @base_main.py:52][0m [avg_reward]: -184.9832879305081
[32m[0512 05:07:21 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:21 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:21 @base_trainer.py:216][0m Mean reward: -201.31949931890207
[32m[0512 05:07:21 @base_main.py:38][0m --------------- Iteration 51 ---------------
[32m[0512 05:07:21 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6054 mins
[32m[0512 05:07:21 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 05:07:21 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0512 05:07:21 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:21 @base_main.py:47][0m 51255 total steps have happened
[32m[0512 05:07:21 @base_main.py:52][0m [avg_reward]: -201.31949931890207
[32m[0512 05:07:21 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:21 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:21 @base_trainer.py:216][0m Mean reward: -185.47960495814303
[32m[0512 05:07:22 @base_main.py:38][0m --------------- Iteration 52 ---------------
[32m[0512 05:07:22 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6169 mins
[32m[0512 05:07:22 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0512 05:07:22 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 05:07:22 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:22 @base_main.py:47][0m 52260 total steps have happened
[32m[0512 05:07:22 @base_main.py:52][0m [avg_reward]: -185.47960495814303
[32m[0512 05:07:22 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:22 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:22 @base_trainer.py:216][0m Mean reward: -200.70381153245543
[32m[0512 05:07:23 @base_main.py:38][0m --------------- Iteration 53 ---------------
[32m[0512 05:07:23 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6297 mins
[32m[0512 05:07:23 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:07:23 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0512 05:07:23 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 05:07:23 @base_main.py:47][0m 53265 total steps have happened
[32m[0512 05:07:23 @base_main.py:52][0m [avg_reward]: -200.70381153245543
[32m[0512 05:07:23 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:23 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:23 @base_trainer.py:216][0m Mean reward: -199.84582030484052
[32m[0512 05:07:23 @base_main.py:38][0m --------------- Iteration 54 ---------------
[32m[0512 05:07:23 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6419 mins
[32m[0512 05:07:23 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0512 05:07:23 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0082 mins
[32m[0512 05:07:23 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:23 @base_main.py:47][0m 54270 total steps have happened
[32m[0512 05:07:23 @base_main.py:52][0m [avg_reward]: -199.84582030484052
[32m[0512 05:07:23 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:23 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:23 @base_trainer.py:216][0m Mean reward: -193.1406001510472
[32m[0512 05:07:24 @base_main.py:38][0m --------------- Iteration 55 ---------------
[32m[0512 05:07:24 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6534 mins
[32m[0512 05:07:24 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 05:07:24 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0512 05:07:24 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 05:07:24 @base_main.py:47][0m 55275 total steps have happened
[32m[0512 05:07:24 @base_main.py:52][0m [avg_reward]: -193.1406001510472
[32m[0512 05:07:24 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:24 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:24 @base_trainer.py:216][0m Mean reward: -205.84036081180165
[32m[0512 05:07:25 @base_main.py:38][0m --------------- Iteration 56 ---------------
[32m[0512 05:07:25 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6656 mins
[32m[0512 05:07:25 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0512 05:07:25 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 05:07:25 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 05:07:25 @base_main.py:47][0m 56280 total steps have happened
[32m[0512 05:07:25 @base_main.py:52][0m [avg_reward]: -205.84036081180165
[32m[0512 05:07:25 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:25 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:25 @base_trainer.py:216][0m Mean reward: -187.90361386718646
[32m[0512 05:07:25 @base_main.py:38][0m --------------- Iteration 57 ---------------
[32m[0512 05:07:25 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6780 mins
[32m[0512 05:07:25 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:07:25 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0084 mins
[32m[0512 05:07:25 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:25 @base_main.py:47][0m 57285 total steps have happened
[32m[0512 05:07:25 @base_main.py:52][0m [avg_reward]: -187.90361386718646
[32m[0512 05:07:26 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:26 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:26 @base_trainer.py:216][0m Mean reward: -203.12942129425784
[32m[0512 05:07:26 @base_main.py:38][0m --------------- Iteration 58 ---------------
[32m[0512 05:07:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6893 mins
[32m[0512 05:07:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:07:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0512 05:07:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:26 @base_main.py:47][0m 58290 total steps have happened
[32m[0512 05:07:26 @base_main.py:52][0m [avg_reward]: -203.12942129425784
[32m[0512 05:07:26 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:26 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:26 @base_trainer.py:216][0m Mean reward: -147.6021236114087
[32m[0512 05:07:27 @base_main.py:38][0m --------------- Iteration 59 ---------------
[32m[0512 05:07:27 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7011 mins
[32m[0512 05:07:27 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:07:27 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 05:07:27 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0512 05:07:27 @base_main.py:47][0m 59295 total steps have happened
[32m[0512 05:07:27 @base_main.py:52][0m [avg_reward]: -147.6021236114087
[32m[0512 05:07:27 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:27 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:27 @base_trainer.py:216][0m Mean reward: -150.33284626275207
[32m[0512 05:07:28 @base_main.py:38][0m --------------- Iteration 60 ---------------
[32m[0512 05:07:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7129 mins
[32m[0512 05:07:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:07:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0512 05:07:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:28 @base_main.py:47][0m 60300 total steps have happened
[32m[0512 05:07:28 @base_main.py:52][0m [avg_reward]: -150.33284626275207
[32m[0512 05:07:28 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:28 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:28 @base_trainer.py:216][0m Mean reward: -158.45113614318836
[32m[0512 05:07:28 @base_main.py:38][0m --------------- Iteration 61 ---------------
[32m[0512 05:07:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7247 mins
[32m[0512 05:07:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 05:07:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0512 05:07:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:28 @base_main.py:47][0m 61305 total steps have happened
[32m[0512 05:07:28 @base_main.py:52][0m [avg_reward]: -158.45113614318836
[32m[0512 05:07:28 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:28 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:28 @base_trainer.py:216][0m Mean reward: -131.82410373280504
[32m[0512 05:07:29 @base_main.py:38][0m --------------- Iteration 62 ---------------
[32m[0512 05:07:29 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7369 mins
[32m[0512 05:07:29 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 05:07:29 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 05:07:29 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:29 @base_main.py:47][0m 62310 total steps have happened
[32m[0512 05:07:29 @base_main.py:52][0m [avg_reward]: -131.82410373280504
[32m[0512 05:07:29 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:29 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:29 @base_trainer.py:216][0m Mean reward: -163.6395832660374
[32m[0512 05:07:30 @base_main.py:38][0m --------------- Iteration 63 ---------------
[32m[0512 05:07:30 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7485 mins
[32m[0512 05:07:30 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 05:07:30 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0083 mins
[32m[0512 05:07:30 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:30 @base_main.py:47][0m 63315 total steps have happened
[32m[0512 05:07:30 @base_main.py:52][0m [avg_reward]: -163.6395832660374
[32m[0512 05:07:30 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:30 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:30 @base_trainer.py:216][0m Mean reward: -153.48144903044778
[32m[0512 05:07:30 @base_main.py:38][0m --------------- Iteration 64 ---------------
[32m[0512 05:07:30 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7598 mins
[32m[0512 05:07:30 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 05:07:30 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 05:07:30 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 05:07:30 @base_main.py:47][0m 64320 total steps have happened
[32m[0512 05:07:30 @base_main.py:52][0m [avg_reward]: -153.48144903044778
[32m[0512 05:07:31 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:31 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:31 @base_trainer.py:216][0m Mean reward: -117.71912808974302
[32m[0512 05:07:31 @base_main.py:38][0m --------------- Iteration 65 ---------------
[32m[0512 05:07:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7720 mins
[32m[0512 05:07:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:07:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0084 mins
[32m[0512 05:07:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:31 @base_main.py:47][0m 65325 total steps have happened
[32m[0512 05:07:31 @base_main.py:52][0m [avg_reward]: -117.71912808974302
[32m[0512 05:07:31 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:31 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:31 @base_trainer.py:216][0m Mean reward: -132.81357343907516
[32m[0512 05:07:32 @base_main.py:38][0m --------------- Iteration 66 ---------------
[32m[0512 05:07:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7833 mins
[32m[0512 05:07:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 05:07:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0084 mins
[32m[0512 05:07:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 05:07:32 @base_main.py:47][0m 66330 total steps have happened
[32m[0512 05:07:32 @base_main.py:52][0m [avg_reward]: -132.81357343907516
[32m[0512 05:07:32 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:32 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:32 @base_trainer.py:216][0m Mean reward: -112.70260263266982
[32m[0512 05:07:32 @base_main.py:38][0m --------------- Iteration 67 ---------------
[32m[0512 05:07:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7945 mins
[32m[0512 05:07:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:07:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0084 mins
[32m[0512 05:07:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:32 @base_main.py:47][0m 67335 total steps have happened
[32m[0512 05:07:32 @base_main.py:52][0m [avg_reward]: -112.70260263266982
[32m[0512 05:07:33 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:33 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:33 @base_trainer.py:216][0m Mean reward: -124.07890800727846
[32m[0512 05:07:33 @base_main.py:38][0m --------------- Iteration 68 ---------------
[32m[0512 05:07:33 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8059 mins
[32m[0512 05:07:33 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 05:07:33 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0512 05:07:33 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:33 @base_main.py:47][0m 68340 total steps have happened
[32m[0512 05:07:33 @base_main.py:52][0m [avg_reward]: -124.07890800727846
[32m[0512 05:07:33 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:33 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:33 @base_trainer.py:216][0m Mean reward: -139.28879549330048
[32m[0512 05:07:34 @base_main.py:38][0m --------------- Iteration 69 ---------------
[32m[0512 05:07:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8175 mins
[32m[0512 05:07:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:07:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0512 05:07:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:34 @base_main.py:47][0m 69345 total steps have happened
[32m[0512 05:07:34 @base_main.py:52][0m [avg_reward]: -139.28879549330048
[32m[0512 05:07:34 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:34 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:34 @base_trainer.py:216][0m Mean reward: -126.70170535167794
[32m[0512 05:07:34 @base_main.py:38][0m --------------- Iteration 70 ---------------
[32m[0512 05:07:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8293 mins
[32m[0512 05:07:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 05:07:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0084 mins
[32m[0512 05:07:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:34 @base_main.py:47][0m 70350 total steps have happened
[32m[0512 05:07:34 @base_main.py:52][0m [avg_reward]: -126.70170535167794
[32m[0512 05:07:35 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:35 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:35 @base_trainer.py:216][0m Mean reward: -154.3211376185446
[32m[0512 05:07:35 @base_main.py:38][0m --------------- Iteration 71 ---------------
[32m[0512 05:07:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8405 mins
[32m[0512 05:07:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 05:07:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 05:07:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:35 @base_main.py:47][0m 71355 total steps have happened
[32m[0512 05:07:35 @base_main.py:52][0m [avg_reward]: -154.3211376185446
[32m[0512 05:07:35 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:35 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:35 @base_trainer.py:216][0m Mean reward: -124.56365590918367
[32m[0512 05:07:36 @base_main.py:38][0m --------------- Iteration 72 ---------------
[32m[0512 05:07:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8526 mins
[32m[0512 05:07:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:07:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0082 mins
[32m[0512 05:07:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:36 @base_main.py:47][0m 72360 total steps have happened
[32m[0512 05:07:36 @base_main.py:52][0m [avg_reward]: -124.56365590918367
[32m[0512 05:07:36 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:36 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:36 @base_trainer.py:216][0m Mean reward: -141.5898594886738
[32m[0512 05:07:37 @base_main.py:38][0m --------------- Iteration 73 ---------------
[32m[0512 05:07:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8637 mins
[32m[0512 05:07:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 05:07:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 05:07:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:37 @base_main.py:47][0m 73365 total steps have happened
[32m[0512 05:07:37 @base_main.py:52][0m [avg_reward]: -141.5898594886738
[32m[0512 05:07:37 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:37 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:37 @base_trainer.py:216][0m Mean reward: -154.25335460826147
[32m[0512 05:07:37 @base_main.py:38][0m --------------- Iteration 74 ---------------
[32m[0512 05:07:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8757 mins
[32m[0512 05:07:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:07:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 05:07:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:37 @base_main.py:47][0m 74370 total steps have happened
[32m[0512 05:07:37 @base_main.py:52][0m [avg_reward]: -154.25335460826147
[32m[0512 05:07:38 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:38 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:38 @base_trainer.py:216][0m Mean reward: -131.65367176521858
[32m[0512 05:07:38 @base_main.py:38][0m --------------- Iteration 75 ---------------
[32m[0512 05:07:38 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8877 mins
[32m[0512 05:07:38 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0512 05:07:38 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 05:07:38 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 05:07:38 @base_main.py:47][0m 75375 total steps have happened
[32m[0512 05:07:38 @base_main.py:52][0m [avg_reward]: -131.65367176521858
[32m[0512 05:07:38 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:38 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:38 @base_trainer.py:216][0m Mean reward: -141.86673228519018
[32m[0512 05:07:39 @base_main.py:38][0m --------------- Iteration 76 ---------------
[32m[0512 05:07:39 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8998 mins
[32m[0512 05:07:39 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 05:07:39 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0512 05:07:39 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 05:07:39 @base_main.py:47][0m 76380 total steps have happened
[32m[0512 05:07:39 @base_main.py:52][0m [avg_reward]: -141.86673228519018
[32m[0512 05:07:39 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:39 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:39 @base_trainer.py:216][0m Mean reward: -154.50488195472684
[32m[0512 05:07:39 @base_main.py:38][0m --------------- Iteration 77 ---------------
[32m[0512 05:07:39 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9117 mins
[32m[0512 05:07:39 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 05:07:39 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 05:07:39 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 05:07:39 @base_main.py:47][0m 77385 total steps have happened
[32m[0512 05:07:39 @base_main.py:52][0m [avg_reward]: -154.50488195472684
[32m[0512 05:07:40 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:40 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:40 @base_trainer.py:216][0m Mean reward: -107.96613960794403
[32m[0512 05:07:40 @base_main.py:38][0m --------------- Iteration 78 ---------------
[32m[0512 05:07:40 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9239 mins
[32m[0512 05:07:40 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 05:07:40 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 05:07:40 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:40 @base_main.py:47][0m 78390 total steps have happened
[32m[0512 05:07:40 @base_main.py:52][0m [avg_reward]: -107.96613960794403
[32m[0512 05:07:40 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:40 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:40 @base_trainer.py:216][0m Mean reward: -125.8441665741642
[32m[0512 05:07:41 @base_main.py:38][0m --------------- Iteration 79 ---------------
[32m[0512 05:07:41 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9360 mins
[32m[0512 05:07:41 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 05:07:41 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0512 05:07:41 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 05:07:41 @base_main.py:47][0m 79395 total steps have happened
[32m[0512 05:07:41 @base_main.py:52][0m [avg_reward]: -125.8441665741642
[32m[0512 05:07:41 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:41 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:41 @base_trainer.py:216][0m Mean reward: -120.93004276344467
[32m[0512 05:07:42 @base_main.py:38][0m --------------- Iteration 80 ---------------
[32m[0512 05:07:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9479 mins
[32m[0512 05:07:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 05:07:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0512 05:07:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:42 @base_main.py:47][0m 80400 total steps have happened
[32m[0512 05:07:42 @base_main.py:52][0m [avg_reward]: -120.93004276344467
[32m[0512 05:07:42 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:42 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:42 @base_trainer.py:216][0m Mean reward: -119.97129033811322
[32m[0512 05:07:42 @base_main.py:38][0m --------------- Iteration 81 ---------------
[32m[0512 05:07:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9599 mins
[32m[0512 05:07:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 05:07:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0512 05:07:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:42 @base_main.py:47][0m 81405 total steps have happened
[32m[0512 05:07:42 @base_main.py:52][0m [avg_reward]: -119.97129033811322
[32m[0512 05:07:43 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:43 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:43 @base_trainer.py:216][0m Mean reward: -98.3820256338903
[32m[0512 05:07:43 @base_main.py:38][0m --------------- Iteration 82 ---------------
[32m[0512 05:07:43 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9716 mins
[32m[0512 05:07:43 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:07:43 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0512 05:07:43 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 05:07:43 @base_main.py:47][0m 82410 total steps have happened
[32m[0512 05:07:43 @base_main.py:52][0m [avg_reward]: -98.3820256338903
[32m[0512 05:07:43 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:43 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:43 @base_trainer.py:216][0m Mean reward: -142.10948647143942
[32m[0512 05:07:44 @base_main.py:38][0m --------------- Iteration 83 ---------------
[32m[0512 05:07:44 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9831 mins
[32m[0512 05:07:44 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 05:07:44 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0512 05:07:44 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:44 @base_main.py:47][0m 83415 total steps have happened
[32m[0512 05:07:44 @base_main.py:52][0m [avg_reward]: -142.10948647143942
[32m[0512 05:07:44 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:44 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:44 @base_trainer.py:216][0m Mean reward: -155.3982253480366
[32m[0512 05:07:44 @base_main.py:38][0m --------------- Iteration 84 ---------------
[32m[0512 05:07:44 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9945 mins
[32m[0512 05:07:44 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 05:07:44 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0512 05:07:44 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:44 @base_main.py:47][0m 84420 total steps have happened
[32m[0512 05:07:44 @base_main.py:52][0m [avg_reward]: -155.3982253480366
[32m[0512 05:07:45 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:45 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:45 @base_trainer.py:216][0m Mean reward: -123.81529385778717
[32m[0512 05:07:45 @base_main.py:38][0m --------------- Iteration 85 ---------------
[32m[0512 05:07:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0061 mins
[32m[0512 05:07:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:07:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0512 05:07:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:45 @base_main.py:47][0m 85425 total steps have happened
[32m[0512 05:07:45 @base_main.py:52][0m [avg_reward]: -123.81529385778717
[32m[0512 05:07:45 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:45 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:45 @base_trainer.py:216][0m Mean reward: -141.9697521246997
[32m[0512 05:07:46 @base_main.py:38][0m --------------- Iteration 86 ---------------
[32m[0512 05:07:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0183 mins
[32m[0512 05:07:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 05:07:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0512 05:07:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:46 @base_main.py:47][0m 86430 total steps have happened
[32m[0512 05:07:46 @base_main.py:52][0m [avg_reward]: -141.9697521246997
[32m[0512 05:07:46 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:46 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:46 @base_trainer.py:216][0m Mean reward: -77.59773081516434
[32m[0512 05:07:47 @base_main.py:38][0m --------------- Iteration 87 ---------------
[32m[0512 05:07:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0302 mins
[32m[0512 05:07:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0512 05:07:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0512 05:07:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 05:07:47 @base_main.py:47][0m 87435 total steps have happened
[32m[0512 05:07:47 @base_main.py:52][0m [avg_reward]: -77.59773081516434
[32m[0512 05:07:47 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:47 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:47 @base_trainer.py:216][0m Mean reward: -121.4422765640962
[32m[0512 05:07:47 @base_main.py:38][0m --------------- Iteration 88 ---------------
[32m[0512 05:07:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0424 mins
[32m[0512 05:07:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 05:07:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0512 05:07:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:47 @base_main.py:47][0m 88440 total steps have happened
[32m[0512 05:07:47 @base_main.py:52][0m [avg_reward]: -121.4422765640962
[32m[0512 05:07:48 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:48 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:48 @base_trainer.py:216][0m Mean reward: -188.99473578630838
[32m[0512 05:07:48 @base_main.py:38][0m --------------- Iteration 89 ---------------
[32m[0512 05:07:48 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0548 mins
[32m[0512 05:07:48 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 05:07:48 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 05:07:48 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:48 @base_main.py:47][0m 89445 total steps have happened
[32m[0512 05:07:48 @base_main.py:52][0m [avg_reward]: -188.99473578630838
[32m[0512 05:07:48 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:48 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:48 @base_trainer.py:216][0m Mean reward: -192.4791933490174
[32m[0512 05:07:49 @base_main.py:38][0m --------------- Iteration 90 ---------------
[32m[0512 05:07:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0668 mins
[32m[0512 05:07:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 05:07:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 05:07:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:49 @base_main.py:47][0m 90450 total steps have happened
[32m[0512 05:07:49 @base_main.py:52][0m [avg_reward]: -192.4791933490174
[32m[0512 05:07:49 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:49 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:49 @base_trainer.py:216][0m Mean reward: -109.40294521635326
[32m[0512 05:07:49 @base_main.py:38][0m --------------- Iteration 91 ---------------
[32m[0512 05:07:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0789 mins
[32m[0512 05:07:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 05:07:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0080 mins
[32m[0512 05:07:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:49 @base_main.py:47][0m 91455 total steps have happened
[32m[0512 05:07:49 @base_main.py:52][0m [avg_reward]: -109.40294521635326
[32m[0512 05:07:50 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:50 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:50 @base_trainer.py:216][0m Mean reward: -195.06893145470977
[32m[0512 05:07:50 @base_main.py:38][0m --------------- Iteration 92 ---------------
[32m[0512 05:07:50 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0899 mins
[32m[0512 05:07:50 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 05:07:50 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0512 05:07:50 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:50 @base_main.py:47][0m 92460 total steps have happened
[32m[0512 05:07:50 @base_main.py:52][0m [avg_reward]: -195.06893145470977
[32m[0512 05:07:50 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:50 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:50 @base_trainer.py:216][0m Mean reward: -129.9831870318169
[32m[0512 05:07:51 @base_main.py:38][0m --------------- Iteration 93 ---------------
[32m[0512 05:07:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1017 mins
[32m[0512 05:07:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 05:07:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0512 05:07:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:51 @base_main.py:47][0m 93465 total steps have happened
[32m[0512 05:07:51 @base_main.py:52][0m [avg_reward]: -129.9831870318169
[32m[0512 05:07:51 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:51 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:51 @base_trainer.py:216][0m Mean reward: -167.70893699195005
[32m[0512 05:07:52 @base_main.py:38][0m --------------- Iteration 94 ---------------
[32m[0512 05:07:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1132 mins
[32m[0512 05:07:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 05:07:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0512 05:07:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 05:07:52 @base_main.py:47][0m 94470 total steps have happened
[32m[0512 05:07:52 @base_main.py:52][0m [avg_reward]: -167.70893699195005
[32m[0512 05:07:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:52 @base_trainer.py:216][0m Mean reward: -116.57692297860794
[32m[0512 05:07:52 @base_main.py:38][0m --------------- Iteration 95 ---------------
[32m[0512 05:07:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1253 mins
[32m[0512 05:07:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 05:07:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 05:07:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:52 @base_main.py:47][0m 95475 total steps have happened
[32m[0512 05:07:52 @base_main.py:52][0m [avg_reward]: -116.57692297860794
[32m[0512 05:07:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:52 @base_trainer.py:216][0m Mean reward: -130.04348045216378
[32m[0512 05:07:53 @base_main.py:38][0m --------------- Iteration 96 ---------------
[32m[0512 05:07:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1373 mins
[32m[0512 05:07:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0512 05:07:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0512 05:07:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:53 @base_main.py:47][0m 96480 total steps have happened
[32m[0512 05:07:53 @base_main.py:52][0m [avg_reward]: -130.04348045216378
[32m[0512 05:07:53 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:53 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:53 @base_trainer.py:216][0m Mean reward: -118.58716625343452
[32m[0512 05:07:54 @base_main.py:38][0m --------------- Iteration 97 ---------------
[32m[0512 05:07:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1495 mins
[32m[0512 05:07:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:07:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0512 05:07:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:54 @base_main.py:47][0m 97485 total steps have happened
[32m[0512 05:07:54 @base_main.py:52][0m [avg_reward]: -118.58716625343452
[32m[0512 05:07:54 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:54 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:54 @base_trainer.py:216][0m Mean reward: -71.95849822162353
[32m[0512 05:07:55 @base_main.py:38][0m --------------- Iteration 98 ---------------
[32m[0512 05:07:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1618 mins
[32m[0512 05:07:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0512 05:07:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0512 05:07:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:55 @base_main.py:47][0m 98490 total steps have happened
[32m[0512 05:07:55 @base_main.py:52][0m [avg_reward]: -71.95849822162353
[32m[0512 05:07:55 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:55 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:55 @base_trainer.py:216][0m Mean reward: -66.15466279926885
[32m[0512 05:07:55 @base_main.py:38][0m --------------- Iteration 99 ---------------
[32m[0512 05:07:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1744 mins
[32m[0512 05:07:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:07:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0512 05:07:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:55 @base_main.py:47][0m 99495 total steps have happened
[32m[0512 05:07:55 @base_main.py:52][0m [avg_reward]: -66.15466279926885
[32m[0512 05:07:55 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:55 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:55 @base_trainer.py:216][0m Mean reward: -51.86585209160048
[32m[0512 05:07:56 @base_main.py:38][0m --------------- Iteration 100 ---------------
[32m[0512 05:07:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1861 mins
[32m[0512 05:07:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 05:07:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 05:07:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:56 @base_main.py:47][0m 100500 total steps have happened
[32m[0512 05:07:56 @base_main.py:52][0m [avg_reward]: -51.86585209160048
[32m[0512 05:07:56 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:56 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:56 @base_trainer.py:216][0m Mean reward: -62.46338294836981
[32m[0512 05:07:57 @base_main.py:38][0m --------------- Iteration 101 ---------------
[32m[0512 05:07:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1976 mins
[32m[0512 05:07:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:07:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 05:07:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:57 @base_main.py:47][0m 101505 total steps have happened
[32m[0512 05:07:57 @base_main.py:52][0m [avg_reward]: -62.46338294836981
[32m[0512 05:07:57 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:57 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:57 @base_trainer.py:216][0m Mean reward: -56.851083422511735
[32m[0512 05:07:57 @base_main.py:38][0m --------------- Iteration 102 ---------------
[32m[0512 05:07:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2095 mins
[32m[0512 05:07:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 05:07:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0512 05:07:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:57 @base_main.py:47][0m 102510 total steps have happened
[32m[0512 05:07:57 @base_main.py:52][0m [avg_reward]: -56.851083422511735
[32m[0512 05:07:58 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:58 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:58 @base_trainer.py:216][0m Mean reward: -54.563658254601066
[32m[0512 05:07:58 @base_main.py:38][0m --------------- Iteration 103 ---------------
[32m[0512 05:07:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2211 mins
[32m[0512 05:07:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 05:07:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0512 05:07:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:07:58 @base_main.py:47][0m 103515 total steps have happened
[32m[0512 05:07:58 @base_main.py:52][0m [avg_reward]: -54.563658254601066
[32m[0512 05:07:58 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:58 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:58 @base_trainer.py:216][0m Mean reward: -54.53084806193804
[32m[0512 05:07:59 @base_main.py:38][0m --------------- Iteration 104 ---------------
[32m[0512 05:07:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2330 mins
[32m[0512 05:07:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:07:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0512 05:07:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 05:07:59 @base_main.py:47][0m 104520 total steps have happened
[32m[0512 05:07:59 @base_main.py:52][0m [avg_reward]: -54.53084806193804
[32m[0512 05:07:59 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:07:59 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:07:59 @base_trainer.py:216][0m Mean reward: -53.116498194846294
[32m[0512 05:07:59 @base_main.py:38][0m --------------- Iteration 105 ---------------
[32m[0512 05:07:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2448 mins
[32m[0512 05:07:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:07:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0512 05:07:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 05:07:59 @base_main.py:47][0m 105525 total steps have happened
[32m[0512 05:07:59 @base_main.py:52][0m [avg_reward]: -53.116498194846294
[32m[0512 05:08:00 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:00 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:00 @base_trainer.py:216][0m Mean reward: -48.44794354246618
[32m[0512 05:08:00 @base_main.py:38][0m --------------- Iteration 106 ---------------
[32m[0512 05:08:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2569 mins
[32m[0512 05:08:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 05:08:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 05:08:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:00 @base_main.py:47][0m 106530 total steps have happened
[32m[0512 05:08:00 @base_main.py:52][0m [avg_reward]: -48.44794354246618
[32m[0512 05:08:00 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:00 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:00 @base_trainer.py:216][0m Mean reward: -51.238303017107754
[32m[0512 05:08:01 @base_main.py:38][0m --------------- Iteration 107 ---------------
[32m[0512 05:08:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2689 mins
[32m[0512 05:08:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 05:08:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0512 05:08:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:01 @base_main.py:47][0m 107535 total steps have happened
[32m[0512 05:08:01 @base_main.py:52][0m [avg_reward]: -51.238303017107754
[32m[0512 05:08:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:01 @base_trainer.py:216][0m Mean reward: -51.86065806689976
[32m[0512 05:08:02 @base_main.py:38][0m --------------- Iteration 108 ---------------
[32m[0512 05:08:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2805 mins
[32m[0512 05:08:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 05:08:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0080 mins
[32m[0512 05:08:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 05:08:02 @base_main.py:47][0m 108540 total steps have happened
[32m[0512 05:08:02 @base_main.py:52][0m [avg_reward]: -51.86065806689976
[32m[0512 05:08:02 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:02 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:02 @base_trainer.py:216][0m Mean reward: -50.89995778566858
[32m[0512 05:08:02 @base_main.py:38][0m --------------- Iteration 109 ---------------
[32m[0512 05:08:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2914 mins
[32m[0512 05:08:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:08:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0512 05:08:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 05:08:02 @base_main.py:47][0m 109545 total steps have happened
[32m[0512 05:08:02 @base_main.py:52][0m [avg_reward]: -50.89995778566858
[32m[0512 05:08:02 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:02 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:02 @base_trainer.py:216][0m Mean reward: -49.26875433894853
[32m[0512 05:08:03 @base_main.py:38][0m --------------- Iteration 110 ---------------
[32m[0512 05:08:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3037 mins
[32m[0512 05:08:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0032 mins
[32m[0512 05:08:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 05:08:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:03 @base_main.py:47][0m 110550 total steps have happened
[32m[0512 05:08:03 @base_main.py:52][0m [avg_reward]: -49.26875433894853
[32m[0512 05:08:03 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:03 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:03 @base_trainer.py:216][0m Mean reward: -48.14026883643502
[32m[0512 05:08:04 @base_main.py:38][0m --------------- Iteration 111 ---------------
[32m[0512 05:08:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3161 mins
[32m[0512 05:08:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:08:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 05:08:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 05:08:04 @base_main.py:47][0m 111555 total steps have happened
[32m[0512 05:08:04 @base_main.py:52][0m [avg_reward]: -48.14026883643502
[32m[0512 05:08:04 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:04 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:04 @base_trainer.py:216][0m Mean reward: -45.98747929142835
[32m[0512 05:08:04 @base_main.py:38][0m --------------- Iteration 112 ---------------
[32m[0512 05:08:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3281 mins
[32m[0512 05:08:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:08:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 05:08:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:04 @base_main.py:47][0m 112560 total steps have happened
[32m[0512 05:08:04 @base_main.py:52][0m [avg_reward]: -45.98747929142835
[32m[0512 05:08:05 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:05 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:05 @base_trainer.py:216][0m Mean reward: -46.19540955218663
[32m[0512 05:08:05 @base_main.py:38][0m --------------- Iteration 113 ---------------
[32m[0512 05:08:05 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3402 mins
[32m[0512 05:08:05 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 05:08:05 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0083 mins
[32m[0512 05:08:05 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:05 @base_main.py:47][0m 113565 total steps have happened
[32m[0512 05:08:05 @base_main.py:52][0m [avg_reward]: -46.19540955218663
[32m[0512 05:08:05 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:05 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:05 @base_trainer.py:216][0m Mean reward: -46.471020742150884
[32m[0512 05:08:06 @base_main.py:38][0m --------------- Iteration 114 ---------------
[32m[0512 05:08:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3515 mins
[32m[0512 05:08:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 05:08:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0512 05:08:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:06 @base_main.py:47][0m 114570 total steps have happened
[32m[0512 05:08:06 @base_main.py:52][0m [avg_reward]: -46.471020742150884
[32m[0512 05:08:06 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:06 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:06 @base_trainer.py:216][0m Mean reward: -46.828015082057114
[32m[0512 05:08:07 @base_main.py:38][0m --------------- Iteration 115 ---------------
[32m[0512 05:08:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3633 mins
[32m[0512 05:08:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:08:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0512 05:08:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:07 @base_main.py:47][0m 115575 total steps have happened
[32m[0512 05:08:07 @base_main.py:52][0m [avg_reward]: -46.828015082057114
[32m[0512 05:08:07 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:07 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:07 @base_trainer.py:216][0m Mean reward: -46.76172422340318
[32m[0512 05:08:07 @base_main.py:38][0m --------------- Iteration 116 ---------------
[32m[0512 05:08:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3748 mins
[32m[0512 05:08:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 05:08:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0083 mins
[32m[0512 05:08:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:07 @base_main.py:47][0m 116580 total steps have happened
[32m[0512 05:08:07 @base_main.py:52][0m [avg_reward]: -46.76172422340318
[32m[0512 05:08:07 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:07 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:07 @base_trainer.py:216][0m Mean reward: -46.58316297916862
[32m[0512 05:08:08 @base_main.py:38][0m --------------- Iteration 117 ---------------
[32m[0512 05:08:08 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3860 mins
[32m[0512 05:08:08 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 05:08:08 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0083 mins
[32m[0512 05:08:08 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 05:08:08 @base_main.py:47][0m 117585 total steps have happened
[32m[0512 05:08:08 @base_main.py:52][0m [avg_reward]: -46.58316297916862
[32m[0512 05:08:08 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:08 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:08 @base_trainer.py:216][0m Mean reward: -47.002983936222634
[32m[0512 05:08:09 @base_main.py:38][0m --------------- Iteration 118 ---------------
[32m[0512 05:08:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3971 mins
[32m[0512 05:08:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 05:08:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0512 05:08:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:09 @base_main.py:47][0m 118590 total steps have happened
[32m[0512 05:08:09 @base_main.py:52][0m [avg_reward]: -47.002983936222634
[32m[0512 05:08:09 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:09 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:09 @base_trainer.py:216][0m Mean reward: -45.998167900955046
[32m[0512 05:08:09 @base_main.py:38][0m --------------- Iteration 119 ---------------
[32m[0512 05:08:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4088 mins
[32m[0512 05:08:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:08:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0512 05:08:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 05:08:09 @base_main.py:47][0m 119595 total steps have happened
[32m[0512 05:08:09 @base_main.py:52][0m [avg_reward]: -45.998167900955046
[32m[0512 05:08:09 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:09 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:09 @base_trainer.py:216][0m Mean reward: -47.301200311759246
[32m[0512 05:08:10 @base_main.py:38][0m --------------- Iteration 120 ---------------
[32m[0512 05:08:10 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4207 mins
[32m[0512 05:08:10 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 05:08:10 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0512 05:08:10 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:10 @base_main.py:47][0m 120600 total steps have happened
[32m[0512 05:08:10 @base_main.py:52][0m [avg_reward]: -47.301200311759246
[32m[0512 05:08:10 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:10 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:10 @base_trainer.py:216][0m Mean reward: -50.02766173189578
[32m[0512 05:08:11 @base_main.py:38][0m --------------- Iteration 121 ---------------
[32m[0512 05:08:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4333 mins
[32m[0512 05:08:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0032 mins
[32m[0512 05:08:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0512 05:08:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:11 @base_main.py:47][0m 121605 total steps have happened
[32m[0512 05:08:11 @base_main.py:52][0m [avg_reward]: -50.02766173189578
[32m[0512 05:08:11 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:11 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:11 @base_trainer.py:216][0m Mean reward: -45.472626590739026
[32m[0512 05:08:12 @base_main.py:38][0m --------------- Iteration 122 ---------------
[32m[0512 05:08:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4461 mins
[32m[0512 05:08:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 05:08:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0512 05:08:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:12 @base_main.py:47][0m 122610 total steps have happened
[32m[0512 05:08:12 @base_main.py:52][0m [avg_reward]: -45.472626590739026
[32m[0512 05:08:12 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:12 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:12 @base_trainer.py:216][0m Mean reward: -48.286978240827395
[32m[0512 05:08:12 @base_main.py:38][0m --------------- Iteration 123 ---------------
[32m[0512 05:08:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4581 mins
[32m[0512 05:08:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 05:08:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0512 05:08:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 05:08:12 @base_main.py:47][0m 123615 total steps have happened
[32m[0512 05:08:12 @base_main.py:52][0m [avg_reward]: -48.286978240827395
[32m[0512 05:08:12 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:12 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:12 @base_trainer.py:216][0m Mean reward: -45.83358151872487
[32m[0512 05:08:13 @base_main.py:38][0m --------------- Iteration 124 ---------------
[32m[0512 05:08:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4701 mins
[32m[0512 05:08:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 05:08:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0512 05:08:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:13 @base_main.py:47][0m 124620 total steps have happened
[32m[0512 05:08:13 @base_main.py:52][0m [avg_reward]: -45.83358151872487
[32m[0512 05:08:13 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:13 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:13 @base_trainer.py:216][0m Mean reward: -46.17578088675331
[32m[0512 05:08:14 @base_main.py:38][0m --------------- Iteration 125 ---------------
[32m[0512 05:08:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4813 mins
[32m[0512 05:08:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 05:08:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0512 05:08:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:14 @base_main.py:47][0m 125625 total steps have happened
[32m[0512 05:08:14 @base_main.py:52][0m [avg_reward]: -46.17578088675331
[32m[0512 05:08:14 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:14 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:14 @base_trainer.py:216][0m Mean reward: -46.03410078313
[32m[0512 05:08:14 @base_main.py:38][0m --------------- Iteration 126 ---------------
[32m[0512 05:08:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4936 mins
[32m[0512 05:08:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:08:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0512 05:08:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:14 @base_main.py:47][0m 126630 total steps have happened
[32m[0512 05:08:14 @base_main.py:52][0m [avg_reward]: -46.03410078313
[32m[0512 05:08:15 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:15 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:15 @base_trainer.py:216][0m Mean reward: -48.070353165164065
[32m[0512 05:08:15 @base_main.py:38][0m --------------- Iteration 127 ---------------
[32m[0512 05:08:15 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5051 mins
[32m[0512 05:08:15 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 05:08:15 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0512 05:08:15 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:15 @base_main.py:47][0m 127635 total steps have happened
[32m[0512 05:08:15 @base_main.py:52][0m [avg_reward]: -48.070353165164065
[32m[0512 05:08:15 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:15 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:15 @base_trainer.py:216][0m Mean reward: -49.50841066084583
[32m[0512 05:08:16 @base_main.py:38][0m --------------- Iteration 128 ---------------
[32m[0512 05:08:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5163 mins
[32m[0512 05:08:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 05:08:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0081 mins
[32m[0512 05:08:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 05:08:16 @base_main.py:47][0m 128640 total steps have happened
[32m[0512 05:08:16 @base_main.py:52][0m [avg_reward]: -49.50841066084583
[32m[0512 05:08:16 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:16 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:16 @base_trainer.py:216][0m Mean reward: -49.788372123148314
[32m[0512 05:08:16 @base_main.py:38][0m --------------- Iteration 129 ---------------
[32m[0512 05:08:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5276 mins
[32m[0512 05:08:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:08:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0512 05:08:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 05:08:16 @base_main.py:47][0m 129645 total steps have happened
[32m[0512 05:08:16 @base_main.py:52][0m [avg_reward]: -49.788372123148314
[32m[0512 05:08:17 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:17 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:17 @base_trainer.py:216][0m Mean reward: -47.607520316484454
[32m[0512 05:08:17 @base_main.py:38][0m --------------- Iteration 130 ---------------
[32m[0512 05:08:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5398 mins
[32m[0512 05:08:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 05:08:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0512 05:08:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:17 @base_main.py:47][0m 130650 total steps have happened
[32m[0512 05:08:17 @base_main.py:52][0m [avg_reward]: -47.607520316484454
[32m[0512 05:08:17 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:17 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:17 @base_trainer.py:216][0m Mean reward: -42.30379950031938
[32m[0512 05:08:18 @base_main.py:38][0m --------------- Iteration 131 ---------------
[32m[0512 05:08:18 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5515 mins
[32m[0512 05:08:18 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:08:18 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0512 05:08:18 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:18 @base_main.py:47][0m 131655 total steps have happened
[32m[0512 05:08:18 @base_main.py:52][0m [avg_reward]: -42.30379950031938
[32m[0512 05:08:18 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:18 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:18 @base_trainer.py:216][0m Mean reward: -42.73646727284498
[32m[0512 05:08:19 @base_main.py:38][0m --------------- Iteration 132 ---------------
[32m[0512 05:08:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5636 mins
[32m[0512 05:08:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 05:08:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0512 05:08:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:19 @base_main.py:47][0m 132660 total steps have happened
[32m[0512 05:08:19 @base_main.py:52][0m [avg_reward]: -42.73646727284498
[32m[0512 05:08:19 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:19 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:19 @base_trainer.py:216][0m Mean reward: -41.86807760695061
[32m[0512 05:08:19 @base_main.py:38][0m --------------- Iteration 133 ---------------
[32m[0512 05:08:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5753 mins
[32m[0512 05:08:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0032 mins
[32m[0512 05:08:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0512 05:08:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:19 @base_main.py:47][0m 133665 total steps have happened
[32m[0512 05:08:19 @base_main.py:52][0m [avg_reward]: -41.86807760695061
[32m[0512 05:08:19 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:19 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:19 @base_trainer.py:216][0m Mean reward: -39.66615409690185
[32m[0512 05:08:20 @base_main.py:38][0m --------------- Iteration 134 ---------------
[32m[0512 05:08:20 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5871 mins
[32m[0512 05:08:20 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:08:20 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0082 mins
[32m[0512 05:08:20 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:20 @base_main.py:47][0m 134670 total steps have happened
[32m[0512 05:08:20 @base_main.py:52][0m [avg_reward]: -39.66615409690185
[32m[0512 05:08:20 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:20 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:20 @base_trainer.py:216][0m Mean reward: -38.78091661582329
[32m[0512 05:08:21 @base_main.py:38][0m --------------- Iteration 135 ---------------
[32m[0512 05:08:21 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5983 mins
[32m[0512 05:08:21 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:08:21 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 05:08:21 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 05:08:21 @base_main.py:47][0m 135675 total steps have happened
[32m[0512 05:08:21 @base_main.py:52][0m [avg_reward]: -38.78091661582329
[32m[0512 05:08:21 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:21 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:21 @base_trainer.py:216][0m Mean reward: -34.85775475133716
[32m[0512 05:08:21 @base_main.py:38][0m --------------- Iteration 136 ---------------
[32m[0512 05:08:21 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6100 mins
[32m[0512 05:08:21 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 05:08:21 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 05:08:21 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:21 @base_main.py:47][0m 136680 total steps have happened
[32m[0512 05:08:21 @base_main.py:52][0m [avg_reward]: -34.85775475133716
[32m[0512 05:08:22 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:22 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:22 @base_trainer.py:216][0m Mean reward: -39.354601729501454
[32m[0512 05:08:22 @base_main.py:38][0m --------------- Iteration 137 ---------------
[32m[0512 05:08:22 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6222 mins
[32m[0512 05:08:22 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:08:22 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0512 05:08:22 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:22 @base_main.py:47][0m 137685 total steps have happened
[32m[0512 05:08:22 @base_main.py:52][0m [avg_reward]: -39.354601729501454
[32m[0512 05:08:22 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:22 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:22 @base_trainer.py:216][0m Mean reward: -35.10190258922494
[32m[0512 05:08:23 @base_main.py:38][0m --------------- Iteration 138 ---------------
[32m[0512 05:08:23 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6336 mins
[32m[0512 05:08:23 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 05:08:23 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0512 05:08:23 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:23 @base_main.py:47][0m 138690 total steps have happened
[32m[0512 05:08:23 @base_main.py:52][0m [avg_reward]: -35.10190258922494
[32m[0512 05:08:23 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:23 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:23 @base_trainer.py:216][0m Mean reward: -37.66180735348025
[32m[0512 05:08:24 @base_main.py:38][0m --------------- Iteration 139 ---------------
[32m[0512 05:08:24 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6460 mins
[32m[0512 05:08:24 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:08:24 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 05:08:24 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:24 @base_main.py:47][0m 139695 total steps have happened
[32m[0512 05:08:24 @base_main.py:52][0m [avg_reward]: -37.66180735348025
[32m[0512 05:08:24 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:24 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:24 @base_trainer.py:216][0m Mean reward: -38.96404501838923
[32m[0512 05:08:24 @base_main.py:38][0m --------------- Iteration 140 ---------------
[32m[0512 05:08:24 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6579 mins
[32m[0512 05:08:24 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 05:08:24 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0512 05:08:24 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:24 @base_main.py:47][0m 140700 total steps have happened
[32m[0512 05:08:24 @base_main.py:52][0m [avg_reward]: -38.96404501838923
[32m[0512 05:08:24 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:24 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:24 @base_trainer.py:216][0m Mean reward: -42.08627071320857
[32m[0512 05:08:25 @base_main.py:38][0m --------------- Iteration 141 ---------------
[32m[0512 05:08:25 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6706 mins
[32m[0512 05:08:25 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:08:25 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0083 mins
[32m[0512 05:08:25 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 05:08:25 @base_main.py:47][0m 141705 total steps have happened
[32m[0512 05:08:25 @base_main.py:52][0m [avg_reward]: -42.08627071320857
[32m[0512 05:08:25 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:25 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:25 @base_trainer.py:216][0m Mean reward: -37.645198944573394
[32m[0512 05:08:26 @base_main.py:38][0m --------------- Iteration 142 ---------------
[32m[0512 05:08:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6818 mins
[32m[0512 05:08:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0034 mins
[32m[0512 05:08:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0512 05:08:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:26 @base_main.py:47][0m 142710 total steps have happened
[32m[0512 05:08:26 @base_main.py:52][0m [avg_reward]: -37.645198944573394
[32m[0512 05:08:26 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:26 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:26 @base_trainer.py:216][0m Mean reward: -34.761446509799036
[32m[0512 05:08:26 @base_main.py:38][0m --------------- Iteration 143 ---------------
[32m[0512 05:08:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6938 mins
[32m[0512 05:08:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 05:08:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0512 05:08:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:26 @base_main.py:47][0m 143715 total steps have happened
[32m[0512 05:08:26 @base_main.py:52][0m [avg_reward]: -34.761446509799036
[32m[0512 05:08:27 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:27 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:27 @base_trainer.py:216][0m Mean reward: -32.743980868260685
[32m[0512 05:08:27 @base_main.py:38][0m --------------- Iteration 144 ---------------
[32m[0512 05:08:27 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7057 mins
[32m[0512 05:08:27 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:08:27 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0512 05:08:27 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:27 @base_main.py:47][0m 144720 total steps have happened
[32m[0512 05:08:27 @base_main.py:52][0m [avg_reward]: -32.743980868260685
[32m[0512 05:08:27 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:27 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:27 @base_trainer.py:216][0m Mean reward: -32.09288480532013
[32m[0512 05:08:28 @base_main.py:38][0m --------------- Iteration 145 ---------------
[32m[0512 05:08:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7175 mins
[32m[0512 05:08:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:08:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0512 05:08:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:28 @base_main.py:47][0m 145725 total steps have happened
[32m[0512 05:08:28 @base_main.py:52][0m [avg_reward]: -32.09288480532013
[32m[0512 05:08:28 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:28 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:28 @base_trainer.py:216][0m Mean reward: -32.50083551557845
[32m[0512 05:08:28 @base_main.py:38][0m --------------- Iteration 146 ---------------
[32m[0512 05:08:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7289 mins
[32m[0512 05:08:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 05:08:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0084 mins
[32m[0512 05:08:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 05:08:28 @base_main.py:47][0m 146730 total steps have happened
[32m[0512 05:08:28 @base_main.py:52][0m [avg_reward]: -32.50083551557845
[32m[0512 05:08:29 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:29 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:29 @base_trainer.py:216][0m Mean reward: -29.182473374580315
[32m[0512 05:08:29 @base_main.py:38][0m --------------- Iteration 147 ---------------
[32m[0512 05:08:29 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7402 mins
[32m[0512 05:08:29 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:08:29 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0081 mins
[32m[0512 05:08:29 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:29 @base_main.py:47][0m 147735 total steps have happened
[32m[0512 05:08:29 @base_main.py:52][0m [avg_reward]: -29.182473374580315
[32m[0512 05:08:29 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:29 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:29 @base_trainer.py:216][0m Mean reward: -30.9538436144524
[32m[0512 05:08:30 @base_main.py:38][0m --------------- Iteration 148 ---------------
[32m[0512 05:08:30 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7513 mins
[32m[0512 05:08:30 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 05:08:30 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 05:08:30 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:30 @base_main.py:47][0m 148740 total steps have happened
[32m[0512 05:08:30 @base_main.py:52][0m [avg_reward]: -30.9538436144524
[32m[0512 05:08:30 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:30 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:30 @base_trainer.py:216][0m Mean reward: -32.05982863130138
[32m[0512 05:08:31 @base_main.py:38][0m --------------- Iteration 149 ---------------
[32m[0512 05:08:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7629 mins
[32m[0512 05:08:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 05:08:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0512 05:08:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 05:08:31 @base_main.py:47][0m 149745 total steps have happened
[32m[0512 05:08:31 @base_main.py:52][0m [avg_reward]: -32.05982863130138
[32m[0512 05:08:31 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:31 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:31 @base_trainer.py:216][0m Mean reward: -31.770961749610894
[32m[0512 05:08:31 @base_main.py:38][0m --------------- Iteration 150 ---------------
[32m[0512 05:08:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7755 mins
[32m[0512 05:08:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 05:08:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 05:08:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:31 @base_main.py:47][0m 150750 total steps have happened
[32m[0512 05:08:31 @base_main.py:52][0m [avg_reward]: -31.770961749610894
[32m[0512 05:08:31 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:31 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:31 @base_trainer.py:216][0m Mean reward: -31.42081047940643
[32m[0512 05:08:32 @base_main.py:38][0m --------------- Iteration 151 ---------------
[32m[0512 05:08:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7872 mins
[32m[0512 05:08:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 05:08:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0512 05:08:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:32 @base_main.py:47][0m 151755 total steps have happened
[32m[0512 05:08:32 @base_main.py:52][0m [avg_reward]: -31.42081047940643
[32m[0512 05:08:32 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:32 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:32 @base_trainer.py:216][0m Mean reward: -31.04377922778611
[32m[0512 05:08:33 @base_main.py:38][0m --------------- Iteration 152 ---------------
[32m[0512 05:08:33 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7986 mins
[32m[0512 05:08:33 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:08:33 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0512 05:08:33 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:33 @base_main.py:47][0m 152760 total steps have happened
[32m[0512 05:08:33 @base_main.py:52][0m [avg_reward]: -31.04377922778611
[32m[0512 05:08:33 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:33 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:33 @base_trainer.py:216][0m Mean reward: -31.171880528063546
[32m[0512 05:08:33 @base_main.py:38][0m --------------- Iteration 153 ---------------
[32m[0512 05:08:33 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8102 mins
[32m[0512 05:08:33 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0032 mins
[32m[0512 05:08:33 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0512 05:08:33 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:33 @base_main.py:47][0m 153765 total steps have happened
[32m[0512 05:08:33 @base_main.py:52][0m [avg_reward]: -31.171880528063546
[32m[0512 05:08:34 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:34 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:34 @base_trainer.py:216][0m Mean reward: -33.060806183609806
[32m[0512 05:08:34 @base_main.py:38][0m --------------- Iteration 154 ---------------
[32m[0512 05:08:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8224 mins
[32m[0512 05:08:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:08:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0512 05:08:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:34 @base_main.py:47][0m 154770 total steps have happened
[32m[0512 05:08:34 @base_main.py:52][0m [avg_reward]: -33.060806183609806
[32m[0512 05:08:34 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:34 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:34 @base_trainer.py:216][0m Mean reward: -37.316757918187825
[32m[0512 05:08:35 @base_main.py:38][0m --------------- Iteration 155 ---------------
[32m[0512 05:08:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8340 mins
[32m[0512 05:08:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 05:08:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0512 05:08:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:35 @base_main.py:47][0m 155775 total steps have happened
[32m[0512 05:08:35 @base_main.py:52][0m [avg_reward]: -37.316757918187825
[32m[0512 05:08:35 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:35 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:35 @base_trainer.py:216][0m Mean reward: -32.965820773509265
[32m[0512 05:08:36 @base_main.py:38][0m --------------- Iteration 156 ---------------
[32m[0512 05:08:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8463 mins
[32m[0512 05:08:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 05:08:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 05:08:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:36 @base_main.py:47][0m 156780 total steps have happened
[32m[0512 05:08:36 @base_main.py:52][0m [avg_reward]: -32.965820773509265
[32m[0512 05:08:36 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:36 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:36 @base_trainer.py:216][0m Mean reward: -31.79532718136044
[32m[0512 05:08:36 @base_main.py:38][0m --------------- Iteration 157 ---------------
[32m[0512 05:08:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8584 mins
[32m[0512 05:08:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 05:08:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0078 mins
[32m[0512 05:08:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:36 @base_main.py:47][0m 157785 total steps have happened
[32m[0512 05:08:36 @base_main.py:52][0m [avg_reward]: -31.79532718136044
[32m[0512 05:08:36 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:36 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:36 @base_trainer.py:216][0m Mean reward: -31.335388246605884
[32m[0512 05:08:37 @base_main.py:38][0m --------------- Iteration 158 ---------------
[32m[0512 05:08:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8689 mins
[32m[0512 05:08:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0512 05:08:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0082 mins
[32m[0512 05:08:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:37 @base_main.py:47][0m 158790 total steps have happened
[32m[0512 05:08:37 @base_main.py:52][0m [avg_reward]: -31.335388246605884
[32m[0512 05:08:37 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:37 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:37 @base_trainer.py:216][0m Mean reward: -29.95390754567145
[32m[0512 05:08:38 @base_main.py:38][0m --------------- Iteration 159 ---------------
[32m[0512 05:08:38 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8796 mins
[32m[0512 05:08:38 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 05:08:38 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0083 mins
[32m[0512 05:08:38 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:38 @base_main.py:47][0m 159795 total steps have happened
[32m[0512 05:08:38 @base_main.py:52][0m [avg_reward]: -29.95390754567145
[32m[0512 05:08:38 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:38 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:38 @base_trainer.py:216][0m Mean reward: -29.936359372572536
[32m[0512 05:08:38 @base_main.py:38][0m --------------- Iteration 160 ---------------
[32m[0512 05:08:38 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8906 mins
[32m[0512 05:08:38 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 05:08:38 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 05:08:38 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:38 @base_main.py:47][0m 160800 total steps have happened
[32m[0512 05:08:38 @base_main.py:52][0m [avg_reward]: -29.936359372572536
[32m[0512 05:08:38 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:38 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:38 @base_trainer.py:216][0m Mean reward: -28.998572378863468
[32m[0512 05:08:39 @base_main.py:38][0m --------------- Iteration 161 ---------------
[32m[0512 05:08:39 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9021 mins
[32m[0512 05:08:39 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:08:39 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0081 mins
[32m[0512 05:08:39 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:39 @base_main.py:47][0m 161805 total steps have happened
[32m[0512 05:08:39 @base_main.py:52][0m [avg_reward]: -28.998572378863468
[32m[0512 05:08:39 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:39 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:39 @base_trainer.py:216][0m Mean reward: -30.231935703462977
[32m[0512 05:08:40 @base_main.py:38][0m --------------- Iteration 162 ---------------
[32m[0512 05:08:40 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9132 mins
[32m[0512 05:08:40 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 05:08:40 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0084 mins
[32m[0512 05:08:40 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0512 05:08:40 @base_main.py:47][0m 162810 total steps have happened
[32m[0512 05:08:40 @base_main.py:52][0m [avg_reward]: -30.231935703462977
[32m[0512 05:08:40 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:40 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:40 @base_trainer.py:216][0m Mean reward: -31.39110061367012
[32m[0512 05:08:40 @base_main.py:38][0m --------------- Iteration 163 ---------------
[32m[0512 05:08:40 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9248 mins
[32m[0512 05:08:40 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 05:08:40 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 05:08:40 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 05:08:40 @base_main.py:47][0m 163815 total steps have happened
[32m[0512 05:08:40 @base_main.py:52][0m [avg_reward]: -31.39110061367012
[32m[0512 05:08:40 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:40 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:40 @base_trainer.py:216][0m Mean reward: -32.27166043675882
[32m[0512 05:08:41 @base_main.py:38][0m --------------- Iteration 164 ---------------
[32m[0512 05:08:41 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9370 mins
[32m[0512 05:08:41 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 05:08:41 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0512 05:08:41 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:41 @base_main.py:47][0m 164820 total steps have happened
[32m[0512 05:08:41 @base_main.py:52][0m [avg_reward]: -32.27166043675882
[32m[0512 05:08:41 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:41 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:41 @base_trainer.py:216][0m Mean reward: -30.844639224163863
[32m[0512 05:08:42 @base_main.py:38][0m --------------- Iteration 165 ---------------
[32m[0512 05:08:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9488 mins
[32m[0512 05:08:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0512 05:08:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0512 05:08:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:42 @base_main.py:47][0m 165825 total steps have happened
[32m[0512 05:08:42 @base_main.py:52][0m [avg_reward]: -30.844639224163863
[32m[0512 05:08:42 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:42 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:42 @base_trainer.py:216][0m Mean reward: -31.856079495970686
[32m[0512 05:08:42 @base_main.py:38][0m --------------- Iteration 166 ---------------
[32m[0512 05:08:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9605 mins
[32m[0512 05:08:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 05:08:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0512 05:08:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:42 @base_main.py:47][0m 166830 total steps have happened
[32m[0512 05:08:42 @base_main.py:52][0m [avg_reward]: -31.856079495970686
[32m[0512 05:08:43 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:43 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:43 @base_trainer.py:216][0m Mean reward: -34.44447367902969
[32m[0512 05:08:43 @base_main.py:38][0m --------------- Iteration 167 ---------------
[32m[0512 05:08:43 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9723 mins
[32m[0512 05:08:43 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0512 05:08:43 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 05:08:43 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:43 @base_main.py:47][0m 167835 total steps have happened
[32m[0512 05:08:43 @base_main.py:52][0m [avg_reward]: -34.44447367902969
[32m[0512 05:08:43 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:43 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:43 @base_trainer.py:216][0m Mean reward: -33.298262368110365
[32m[0512 05:08:44 @base_main.py:38][0m --------------- Iteration 168 ---------------
[32m[0512 05:08:44 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9841 mins
[32m[0512 05:08:44 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0033 mins
[32m[0512 05:08:44 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0512 05:08:44 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:44 @base_main.py:47][0m 168840 total steps have happened
[32m[0512 05:08:44 @base_main.py:52][0m [avg_reward]: -33.298262368110365
[32m[0512 05:08:44 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:44 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:44 @base_trainer.py:216][0m Mean reward: -30.840119642027815
[32m[0512 05:08:45 @base_main.py:38][0m --------------- Iteration 169 ---------------
[32m[0512 05:08:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9961 mins
[32m[0512 05:08:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 05:08:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0512 05:08:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:45 @base_main.py:47][0m 169845 total steps have happened
[32m[0512 05:08:45 @base_main.py:52][0m [avg_reward]: -30.840119642027815
[32m[0512 05:08:45 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:45 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:45 @base_trainer.py:216][0m Mean reward: -29.34417980414467
[32m[0512 05:08:45 @base_main.py:38][0m --------------- Iteration 170 ---------------
[32m[0512 05:08:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0077 mins
[32m[0512 05:08:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:08:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0512 05:08:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:45 @base_main.py:47][0m 170850 total steps have happened
[32m[0512 05:08:45 @base_main.py:52][0m [avg_reward]: -29.34417980414467
[32m[0512 05:08:45 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:45 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:45 @base_trainer.py:216][0m Mean reward: -29.417304287226678
[32m[0512 05:08:46 @base_main.py:38][0m --------------- Iteration 171 ---------------
[32m[0512 05:08:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0195 mins
[32m[0512 05:08:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:08:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0512 05:08:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:46 @base_main.py:47][0m 171855 total steps have happened
[32m[0512 05:08:46 @base_main.py:52][0m [avg_reward]: -29.417304287226678
[32m[0512 05:08:46 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:46 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:46 @base_trainer.py:216][0m Mean reward: -29.961494531564362
[32m[0512 05:08:47 @base_main.py:38][0m --------------- Iteration 172 ---------------
[32m[0512 05:08:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0310 mins
[32m[0512 05:08:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 05:08:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0082 mins
[32m[0512 05:08:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:47 @base_main.py:47][0m 172860 total steps have happened
[32m[0512 05:08:47 @base_main.py:52][0m [avg_reward]: -29.961494531564362
[32m[0512 05:08:47 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:47 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:47 @base_trainer.py:216][0m Mean reward: -28.457008471119774
[32m[0512 05:08:47 @base_main.py:38][0m --------------- Iteration 173 ---------------
[32m[0512 05:08:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0419 mins
[32m[0512 05:08:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 05:08:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0083 mins
[32m[0512 05:08:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:47 @base_main.py:47][0m 173865 total steps have happened
[32m[0512 05:08:47 @base_main.py:52][0m [avg_reward]: -28.457008471119774
[32m[0512 05:08:47 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:47 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:47 @base_trainer.py:216][0m Mean reward: -28.28382991302895
[32m[0512 05:08:48 @base_main.py:38][0m --------------- Iteration 174 ---------------
[32m[0512 05:08:48 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0531 mins
[32m[0512 05:08:48 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 05:08:48 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0512 05:08:48 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:48 @base_main.py:47][0m 174870 total steps have happened
[32m[0512 05:08:48 @base_main.py:52][0m [avg_reward]: -28.28382991302895
[32m[0512 05:08:48 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:48 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:48 @base_trainer.py:216][0m Mean reward: -29.175477333771674
[32m[0512 05:08:49 @base_main.py:38][0m --------------- Iteration 175 ---------------
[32m[0512 05:08:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0643 mins
[32m[0512 05:08:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 05:08:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 05:08:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:49 @base_main.py:47][0m 175875 total steps have happened
[32m[0512 05:08:49 @base_main.py:52][0m [avg_reward]: -29.175477333771674
[32m[0512 05:08:49 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:49 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:49 @base_trainer.py:216][0m Mean reward: -29.44330500035586
[32m[0512 05:08:49 @base_main.py:38][0m --------------- Iteration 176 ---------------
[32m[0512 05:08:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0757 mins
[32m[0512 05:08:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:08:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0512 05:08:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:49 @base_main.py:47][0m 176880 total steps have happened
[32m[0512 05:08:49 @base_main.py:52][0m [avg_reward]: -29.44330500035586
[32m[0512 05:08:49 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:49 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:49 @base_trainer.py:216][0m Mean reward: -29.347110759006966
[32m[0512 05:08:50 @base_main.py:38][0m --------------- Iteration 177 ---------------
[32m[0512 05:08:50 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0872 mins
[32m[0512 05:08:50 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 05:08:50 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0081 mins
[32m[0512 05:08:50 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:50 @base_main.py:47][0m 177885 total steps have happened
[32m[0512 05:08:50 @base_main.py:52][0m [avg_reward]: -29.347110759006966
[32m[0512 05:08:50 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:50 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:50 @base_trainer.py:216][0m Mean reward: -29.155820629351307
[32m[0512 05:08:51 @base_main.py:38][0m --------------- Iteration 178 ---------------
[32m[0512 05:08:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0979 mins
[32m[0512 05:08:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:08:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 05:08:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:51 @base_main.py:47][0m 178890 total steps have happened
[32m[0512 05:08:51 @base_main.py:52][0m [avg_reward]: -29.155820629351307
[32m[0512 05:08:51 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:51 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:51 @base_trainer.py:216][0m Mean reward: -29.59223215532429
[32m[0512 05:08:51 @base_main.py:38][0m --------------- Iteration 179 ---------------
[32m[0512 05:08:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1095 mins
[32m[0512 05:08:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:08:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0512 05:08:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:51 @base_main.py:47][0m 179895 total steps have happened
[32m[0512 05:08:51 @base_main.py:52][0m [avg_reward]: -29.59223215532429
[32m[0512 05:08:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:52 @base_trainer.py:216][0m Mean reward: -36.321366889695824
[32m[0512 05:08:52 @base_main.py:38][0m --------------- Iteration 180 ---------------
[32m[0512 05:08:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1211 mins
[32m[0512 05:08:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 05:08:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0083 mins
[32m[0512 05:08:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:52 @base_main.py:47][0m 180900 total steps have happened
[32m[0512 05:08:52 @base_main.py:52][0m [avg_reward]: -36.321366889695824
[32m[0512 05:08:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:52 @base_trainer.py:216][0m Mean reward: -29.502811192083488
[32m[0512 05:08:53 @base_main.py:38][0m --------------- Iteration 181 ---------------
[32m[0512 05:08:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1325 mins
[32m[0512 05:08:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 05:08:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 05:08:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:53 @base_main.py:47][0m 181905 total steps have happened
[32m[0512 05:08:53 @base_main.py:52][0m [avg_reward]: -29.502811192083488
[32m[0512 05:08:53 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:53 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:53 @base_trainer.py:216][0m Mean reward: -34.94848062650104
[32m[0512 05:08:53 @base_main.py:38][0m --------------- Iteration 182 ---------------
[32m[0512 05:08:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1444 mins
[32m[0512 05:08:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:08:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0512 05:08:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:53 @base_main.py:47][0m 182910 total steps have happened
[32m[0512 05:08:53 @base_main.py:52][0m [avg_reward]: -34.94848062650104
[32m[0512 05:08:54 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:54 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:54 @base_trainer.py:216][0m Mean reward: -34.41577977434707
[32m[0512 05:08:54 @base_main.py:38][0m --------------- Iteration 183 ---------------
[32m[0512 05:08:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1559 mins
[32m[0512 05:08:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 05:08:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0512 05:08:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:54 @base_main.py:47][0m 183915 total steps have happened
[32m[0512 05:08:54 @base_main.py:52][0m [avg_reward]: -34.41577977434707
[32m[0512 05:08:54 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:54 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:54 @base_trainer.py:216][0m Mean reward: -34.72434111229161
[32m[0512 05:08:55 @base_main.py:38][0m --------------- Iteration 184 ---------------
[32m[0512 05:08:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1679 mins
[32m[0512 05:08:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:08:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0512 05:08:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:55 @base_main.py:47][0m 184920 total steps have happened
[32m[0512 05:08:55 @base_main.py:52][0m [avg_reward]: -34.72434111229161
[32m[0512 05:08:55 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:55 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:55 @base_trainer.py:216][0m Mean reward: -37.35769614020355
[32m[0512 05:08:56 @base_main.py:38][0m --------------- Iteration 185 ---------------
[32m[0512 05:08:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1797 mins
[32m[0512 05:08:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:08:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0512 05:08:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 05:08:56 @base_main.py:47][0m 185925 total steps have happened
[32m[0512 05:08:56 @base_main.py:52][0m [avg_reward]: -37.35769614020355
[32m[0512 05:08:56 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:56 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:56 @base_trainer.py:216][0m Mean reward: -35.515733455323065
[32m[0512 05:08:56 @base_main.py:38][0m --------------- Iteration 186 ---------------
[32m[0512 05:08:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1913 mins
[32m[0512 05:08:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 05:08:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0512 05:08:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:56 @base_main.py:47][0m 186930 total steps have happened
[32m[0512 05:08:56 @base_main.py:52][0m [avg_reward]: -35.515733455323065
[32m[0512 05:08:56 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:56 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:56 @base_trainer.py:216][0m Mean reward: -71.50488552663998
[32m[0512 05:08:57 @base_main.py:38][0m --------------- Iteration 187 ---------------
[32m[0512 05:08:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2032 mins
[32m[0512 05:08:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 05:08:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0512 05:08:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:57 @base_main.py:47][0m 187935 total steps have happened
[32m[0512 05:08:57 @base_main.py:52][0m [avg_reward]: -71.50488552663998
[32m[0512 05:08:57 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:57 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:57 @base_trainer.py:216][0m Mean reward: -32.96461747199122
[32m[0512 05:08:58 @base_main.py:38][0m --------------- Iteration 188 ---------------
[32m[0512 05:08:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2144 mins
[32m[0512 05:08:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:08:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0512 05:08:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 05:08:58 @base_main.py:47][0m 188940 total steps have happened
[32m[0512 05:08:58 @base_main.py:52][0m [avg_reward]: -32.96461747199122
[32m[0512 05:08:58 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:58 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:58 @base_trainer.py:216][0m Mean reward: -34.80410993715575
[32m[0512 05:08:58 @base_main.py:38][0m --------------- Iteration 189 ---------------
[32m[0512 05:08:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2266 mins
[32m[0512 05:08:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 05:08:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 05:08:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:58 @base_main.py:47][0m 189945 total steps have happened
[32m[0512 05:08:58 @base_main.py:52][0m [avg_reward]: -34.80410993715575
[32m[0512 05:08:59 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:59 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:59 @base_trainer.py:216][0m Mean reward: -30.482586735535296
[32m[0512 05:08:59 @base_main.py:38][0m --------------- Iteration 190 ---------------
[32m[0512 05:08:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2383 mins
[32m[0512 05:08:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0512 05:08:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 05:08:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:08:59 @base_main.py:47][0m 190950 total steps have happened
[32m[0512 05:08:59 @base_main.py:52][0m [avg_reward]: -30.482586735535296
[32m[0512 05:08:59 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:08:59 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:08:59 @base_trainer.py:216][0m Mean reward: -62.94620239201872
[32m[0512 05:09:00 @base_main.py:38][0m --------------- Iteration 191 ---------------
[32m[0512 05:09:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2495 mins
[32m[0512 05:09:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0512 05:09:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0512 05:09:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:09:00 @base_main.py:47][0m 191955 total steps have happened
[32m[0512 05:09:00 @base_main.py:52][0m [avg_reward]: -62.94620239201872
[32m[0512 05:09:00 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:09:00 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:09:00 @base_trainer.py:216][0m Mean reward: -52.5656916907011
[32m[0512 05:09:00 @base_main.py:38][0m --------------- Iteration 192 ---------------
[32m[0512 05:09:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2607 mins
[32m[0512 05:09:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:09:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0512 05:09:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:09:00 @base_main.py:47][0m 192960 total steps have happened
[32m[0512 05:09:00 @base_main.py:52][0m [avg_reward]: -52.5656916907011
[32m[0512 05:09:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:09:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:09:01 @base_trainer.py:216][0m Mean reward: -60.89440032829849
[32m[0512 05:09:01 @base_main.py:38][0m --------------- Iteration 193 ---------------
[32m[0512 05:09:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2724 mins
[32m[0512 05:09:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 05:09:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0512 05:09:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:09:01 @base_main.py:47][0m 193965 total steps have happened
[32m[0512 05:09:01 @base_main.py:52][0m [avg_reward]: -60.89440032829849
[32m[0512 05:09:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:09:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:09:01 @base_trainer.py:216][0m Mean reward: -31.218035166333983
[32m[0512 05:09:02 @base_main.py:38][0m --------------- Iteration 194 ---------------
[32m[0512 05:09:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2839 mins
[32m[0512 05:09:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 05:09:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0512 05:09:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:09:02 @base_main.py:47][0m 194970 total steps have happened
[32m[0512 05:09:02 @base_main.py:52][0m [avg_reward]: -31.218035166333983
[32m[0512 05:09:02 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:09:02 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:09:02 @base_trainer.py:216][0m Mean reward: -29.25062688872145
[32m[0512 05:09:02 @base_main.py:38][0m --------------- Iteration 195 ---------------
[32m[0512 05:09:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2953 mins
[32m[0512 05:09:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 05:09:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0512 05:09:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:09:02 @base_main.py:47][0m 195975 total steps have happened
[32m[0512 05:09:02 @base_main.py:52][0m [avg_reward]: -29.25062688872145
[32m[0512 05:09:03 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:09:03 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:09:03 @base_trainer.py:216][0m Mean reward: -29.21680160363561
[32m[0512 05:09:03 @base_main.py:38][0m --------------- Iteration 196 ---------------
[32m[0512 05:09:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3069 mins
[32m[0512 05:09:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0512 05:09:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0083 mins
[32m[0512 05:09:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:09:03 @base_main.py:47][0m 196980 total steps have happened
[32m[0512 05:09:03 @base_main.py:52][0m [avg_reward]: -29.21680160363561
[32m[0512 05:09:03 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:09:03 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:09:03 @base_trainer.py:216][0m Mean reward: -31.320069671299205
[32m[0512 05:09:04 @base_main.py:38][0m --------------- Iteration 197 ---------------
[32m[0512 05:09:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3184 mins
[32m[0512 05:09:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0512 05:09:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 05:09:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:09:04 @base_main.py:47][0m 197985 total steps have happened
[32m[0512 05:09:04 @base_main.py:52][0m [avg_reward]: -31.320069671299205
[32m[0512 05:09:04 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:09:04 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:09:04 @base_trainer.py:216][0m Mean reward: -52.245530610344474
[32m[0512 05:09:05 @base_main.py:38][0m --------------- Iteration 198 ---------------
[32m[0512 05:09:05 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3307 mins
[32m[0512 05:09:05 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 05:09:05 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0512 05:09:05 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:09:05 @base_main.py:47][0m 198990 total steps have happened
[32m[0512 05:09:05 @base_main.py:52][0m [avg_reward]: -52.245530610344474
[32m[0512 05:09:05 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:09:05 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:09:05 @base_trainer.py:216][0m Mean reward: -32.525348725802004
[32m[0512 05:09:05 @base_main.py:38][0m --------------- Iteration 199 ---------------
[32m[0512 05:09:05 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3422 mins
[32m[0512 05:09:05 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0512 05:09:05 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 05:09:05 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:09:05 @base_main.py:47][0m 199995 total steps have happened
[32m[0512 05:09:05 @base_main.py:52][0m [avg_reward]: -32.525348725802004
[32m[0512 05:09:06 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 05:09:06 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 05:09:06 @base_trainer.py:216][0m Mean reward: -48.73362988800377
[32m[0512 05:09:06 @base_main.py:38][0m --------------- Iteration 200 ---------------
[32m[0512 05:09:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3546 mins
[32m[0512 05:09:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 05:09:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0512 05:09:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 05:09:06 @base_main.py:47][0m 201000 total steps have happened
[32m[0512 05:09:06 @base_main.py:52][0m [avg_reward]: -48.73362988800377
[32m[0512 05:09:06 @base_worker.py:111][0m kill message for worker 11
[32m[0512 05:09:06 @base_worker.py:111][0m kill message for worker 17
[32m[0512 05:09:06 @base_worker.py:111][0m kill message for worker 19
[32m[0512 05:09:06 @base_worker.py:111][0m kill message for worker 18
[32m[0512 05:09:06 @base_worker.py:111][0m kill message for worker 13
[32m[0512 05:09:06 @base_worker.py:111][0m kill message for worker 15
[32m[0512 05:09:06 @base_worker.py:111][0m kill message for worker 16
[32m[0512 05:09:06 @base_worker.py:111][0m kill message for worker 5
[32m[0512 05:09:06 @base_worker.py:111][0m kill message for worker 1
[32m[0512 05:09:06 @base_worker.py:111][0m kill message for worker 9
[32m[0512 05:09:06 @base_worker.py:111][0m kill message for worker 4
[32m[0512 05:09:06 @base_worker.py:111][0m kill message for worker 14
[32m[0512 05:09:06 @base_worker.py:111][0m kill message for worker 6
[32m[0512 05:09:06 @base_worker.py:111][0m kill message for worker 8
[32m[0512 05:09:06 @base_worker.py:111][0m kill message for worker 10
[32m[0512 05:09:06 @base_worker.py:111][0m kill message for worker 2
[32m[0512 05:09:06 @base_worker.py:111][0m kill message for worker 12
[32m[0512 05:09:06 @base_worker.py:111][0m kill message for worker 0
[32m[0512 05:09:06 @base_worker.py:111][0m kill message for worker 7
[32m[0512 05:09:06 @base_worker.py:111][0m kill message for worker 3
