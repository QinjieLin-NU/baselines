[32m[0511 03:27:14 @logger.py:103][0m Log file set to /root/mbbl/log/mbmfrl-rsgym_pendulummbmf_gym_pendulum_ppo_seed_1234.log/mbmfrl-rsgym_pendulummbmf_gym_pendulum_ppo_seed_1234.log
[32m[0511 03:27:14 @mbmf_main.py:23][0m Training starts at /root/mbbl
[32m[0511 03:27:14 @base_worker.py:45][0m Worker 0 online
[32m[0511 03:27:14 @base_worker.py:45][0m Worker 1 online
[32m[0511 03:27:14 @base_worker.py:45][0m Worker 2 online
[32m[0511 03:27:14 @base_worker.py:45][0m Worker 3 online
[32m[0511 03:27:14 @base_worker.py:45][0m Worker 4 online
[32m[0511 03:27:14 @base_worker.py:45][0m Worker 5 online
[32m[0511 03:27:14 @base_worker.py:45][0m Worker 6 online
[32m[0511 03:27:14 @base_worker.py:45][0m Worker 7 online
[32m[0511 03:27:14 @base_worker.py:45][0m Worker 8 online
[32m[0511 03:27:14 @base_worker.py:45][0m Worker 9 online
[32m[0511 03:27:14 @base_worker.py:45][0m Worker 10 online
[32m[0511 03:27:14 @base_worker.py:45][0m Worker 11 online
[32m[0511 03:27:14 @base_worker.py:45][0m Worker 12 online
[32m[0511 03:27:14 @base_worker.py:45][0m Worker 13 online
[32m[0511 03:27:14 @base_worker.py:45][0m Worker 14 online
[32m[0511 03:27:14 @base_worker.py:45][0m Worker 15 online
[32m[0511 03:27:14 @base_worker.py:45][0m Worker 16 online
[32m[0511 03:27:14 @base_worker.py:45][0m Worker 17 online
[32m[0511 03:27:14 @base_worker.py:45][0m Worker 18 online
[32m[0511 03:27:14 @base_worker.py:45][0m Worker 19 online
[32m[0511 03:27:15 @base_trainer.py:152][0m Trainer maintains [1] policy network
[32m[0511 03:27:15 @base_trainer.py:152][0m Trainer maintains [1] dynamics network
[32m[0511 03:27:15 @base_trainer.py:152][0m Trainer maintains [1] reward network
[32m[0511 03:27:16 @mbmf_main.py:46][0m Generating 1000 random timesteps
[32m[0511 03:27:16 @mbmf_sampler.py:39][0m done with episode
[32m[0511 03:27:16 @mbmf_sampler.py:39][0m done with episode
[32m[0511 03:27:16 @mbmf_sampler.py:39][0m done with episode
[32m[0511 03:27:16 @mbmf_sampler.py:39][0m done with episode
[32m[0511 03:27:16 @mbmf_sampler.py:39][0m done with episode
[32m[0511 03:27:16 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0511 03:27:16 @base_trainer.py:216][0m Mean reward: -1219.7744452539182
[32m[0511 03:27:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0464565753936768, Train Loss: 0.9833637475967407
[32m[0511 03:27:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0464869737625122, Train Loss: 0.9833543300628662
[32m[0511 03:27:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0465174913406372, Train Loss: 0.9833450317382812
[32m[0511 03:27:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0465482473373413, Train Loss: 0.9833359122276306
[32m[0511 03:27:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0465790033340454, Train Loss: 0.9833271503448486
[32m[0511 03:27:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.046609878540039, Train Loss: 0.9833184480667114
[32m[0511 03:27:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0466405153274536, Train Loss: 0.983309805393219
[32m[0511 03:27:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0466715097427368, Train Loss: 0.98330157995224
[32m[0511 03:27:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.046702265739441, Train Loss: 0.9832932949066162
[32m[0511 03:27:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0467329025268555, Train Loss: 0.9832854866981506
[32m[0511 03:27:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0467637777328491, Train Loss: 0.9832777380943298
[32m[0511 03:27:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.046794056892395, Train Loss: 0.9832702875137329
[32m[0511 03:27:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.046824336051941, Train Loss: 0.9832627773284912
[32m[0511 03:27:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0468544960021973, Train Loss: 0.9832556843757629
[32m[0511 03:27:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0468841791152954, Train Loss: 0.9832487106323242
[32m[0511 03:27:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.046913743019104, Train Loss: 0.9832420349121094
[32m[0511 03:27:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0469425916671753, Train Loss: 0.9832353591918945
[32m[0511 03:27:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.046971321105957, Train Loss: 0.983228862285614
[32m[0511 03:27:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0469996929168701, Train Loss: 0.9832226037979126
[32m[0511 03:27:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.047027349472046, Train Loss: 0.9832165241241455
[32m[0511 03:27:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.047054648399353, Train Loss: 0.9832105040550232
[32m[0511 03:27:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0470812320709229, Train Loss: 0.9832047820091248
[32m[0511 03:27:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.047107458114624, Train Loss: 0.9831990003585815
[32m[0511 03:27:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0471330881118774, Train Loss: 0.9831935167312622
[32m[0511 03:27:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0471582412719727, Train Loss: 0.9831880927085876
[32m[0511 03:27:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0471826791763306, Train Loss: 0.9831827878952026
[32m[0511 03:27:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0472068786621094, Train Loss: 0.983177661895752
[32m[0511 03:27:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0472303628921509, Train Loss: 0.9831727743148804
[32m[0511 03:27:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0472534894943237, Train Loss: 0.983167827129364
[32m[0511 03:27:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0472761392593384, Train Loss: 0.983163058757782
[32m[0511 03:27:17 @base_main.py:38][0m --------------- Iteration 1 ---------------
[32m[0511 03:27:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0000 mins
[32m[0511 03:27:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 03:27:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0115 mins
[32m[0511 03:27:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0037 mins
[32m[0511 03:27:17 @base_main.py:47][0m 1005 total steps have happened
[32m[0511 03:27:17 @base_main.py:52][0m [avg_reward]: -1219.7744452539182
[32m[0511 03:27:17 @base_main.py:52][0m [update_op]: None
[32m[0511 03:27:17 @base_main.py:52][0m [train_loss]: 0.983163058757782
[32m[0511 03:27:17 @base_main.py:52][0m [val_loss]: 1.0472761392593384
[32m[0511 03:27:17 @base_main.py:52][0m [avg_train_loss]: 0.983163058757782
[32m[0511 03:29:27 @mbmf_sampler.py:39][0m done with episode
[32m[0511 03:31:36 @mbmf_sampler.py:39][0m done with episode
[32m[0511 03:33:45 @mbmf_sampler.py:39][0m done with episode
[32m[0511 03:35:54 @mbmf_sampler.py:39][0m done with episode
[32m[0511 03:38:02 @mbmf_sampler.py:39][0m done with episode
[32m[0511 03:38:02 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0511 03:38:02 @base_trainer.py:216][0m Mean reward: -1174.1746291654688
[32m[0511 03:38:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.086165189743042, Train Loss: 0.9418168067932129
[32m[0511 03:38:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0861693620681763, Train Loss: 0.9418220520019531
[32m[0511 03:38:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0861835479736328, Train Loss: 0.9418213963508606
[32m[0511 03:38:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0862046480178833, Train Loss: 0.9418168067932129
[32m[0511 03:38:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0862300395965576, Train Loss: 0.9418098330497742
[32m[0511 03:38:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0862586498260498, Train Loss: 0.9418012499809265
[32m[0511 03:38:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0862888097763062, Train Loss: 0.9417921900749207
[32m[0511 03:38:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.086320400238037, Train Loss: 0.9417828917503357
[32m[0511 03:38:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0863522291183472, Train Loss: 0.9417737126350403
[32m[0511 03:38:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0863841772079468, Train Loss: 0.9417650103569031
[32m[0511 03:38:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0864160060882568, Train Loss: 0.9417567253112793
[32m[0511 03:38:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0864471197128296, Train Loss: 0.941749095916748
[32m[0511 03:38:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.086477518081665, Train Loss: 0.9417421221733093
[32m[0511 03:38:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0865072011947632, Train Loss: 0.941735565662384
[32m[0511 03:38:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0865358114242554, Train Loss: 0.941729724407196
[32m[0511 03:38:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0865635871887207, Train Loss: 0.9417243003845215
[32m[0511 03:38:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.086590051651001, Train Loss: 0.9417194724082947
[32m[0511 03:38:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0866153240203857, Train Loss: 0.9417150616645813
[32m[0511 03:38:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0866397619247437, Train Loss: 0.9417111873626709
[32m[0511 03:38:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0866631269454956, Train Loss: 0.9417076110839844
[32m[0511 03:38:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.086685299873352, Train Loss: 0.9417044520378113
[32m[0511 03:38:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0867063999176025, Train Loss: 0.9417015910148621
[32m[0511 03:38:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0867263078689575, Train Loss: 0.9416989684104919
[32m[0511 03:38:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.086745262145996, Train Loss: 0.9416964650154114
[32m[0511 03:38:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0867633819580078, Train Loss: 0.9416945576667786
[32m[0511 03:38:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.086780309677124, Train Loss: 0.9416926503181458
[32m[0511 03:38:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.086796522140503, Train Loss: 0.9416908621788025
[32m[0511 03:38:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0868116617202759, Train Loss: 0.9416893124580383
[32m[0511 03:38:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0868260860443115, Train Loss: 0.9416878819465637
[32m[0511 03:38:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0868395566940308, Train Loss: 0.9416866302490234
[32m[0511 03:38:04 @base_main.py:38][0m --------------- Iteration 2 ---------------
[32m[0511 03:38:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0172 mins
[32m[0511 03:38:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 10.7623 mins
[32m[0511 03:38:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0181 mins
[32m[0511 03:38:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0050 mins
[32m[0511 03:38:04 @base_main.py:47][0m 2010 total steps have happened
[32m[0511 03:38:04 @base_main.py:52][0m [avg_reward]: -1174.1746291654688
[32m[0511 03:38:04 @base_main.py:52][0m [update_op]: None
[32m[0511 03:38:04 @base_main.py:52][0m [train_loss]: 1.0424977540969849
[32m[0511 03:38:04 @base_main.py:52][0m [val_loss]: 1.0868395566940308
[32m[0511 03:38:04 @base_main.py:52][0m [avg_train_loss]: 0.9416866302490234
[32m[0511 03:40:12 @mbmf_sampler.py:39][0m done with episode
[32m[0511 03:42:21 @mbmf_sampler.py:39][0m done with episode
[32m[0511 03:44:30 @mbmf_sampler.py:39][0m done with episode
[32m[0511 03:46:38 @mbmf_sampler.py:39][0m done with episode
[32m[0511 03:48:46 @mbmf_sampler.py:39][0m done with episode
[32m[0511 03:48:46 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0511 03:48:46 @base_trainer.py:216][0m Mean reward: -1328.7402171557626
[32m[0511 03:48:46 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6872920989990234, Train Loss: 1.095415472984314
[32m[0511 03:48:47 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6872912645339966, Train Loss: 1.0954139232635498
[32m[0511 03:48:47 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6872897744178772, Train Loss: 1.095410943031311
[32m[0511 03:48:47 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6872882843017578, Train Loss: 1.095407247543335
[32m[0511 03:48:47 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6872871518135071, Train Loss: 1.0954036712646484
[32m[0511 03:48:47 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6872862577438354, Train Loss: 1.0954002141952515
[32m[0511 03:48:47 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6872859597206116, Train Loss: 1.095396876335144
[32m[0511 03:48:47 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6872861385345459, Train Loss: 1.0953938961029053
[32m[0511 03:48:47 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6872866153717041, Train Loss: 1.0953912734985352
[32m[0511 03:48:47 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.687287449836731, Train Loss: 1.0953890085220337
[32m[0511 03:48:47 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6872885823249817, Train Loss: 1.0953868627548218
[32m[0511 03:48:47 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.687289834022522, Train Loss: 1.095384955406189
[32m[0511 03:48:47 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6872914433479309, Train Loss: 1.0953834056854248
[32m[0511 03:48:47 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6872930526733398, Train Loss: 1.0953820943832397
[32m[0511 03:48:47 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6872947812080383, Train Loss: 1.0953807830810547
[32m[0511 03:48:47 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6872966289520264, Train Loss: 1.0953795909881592
[32m[0511 03:48:47 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6872984766960144, Train Loss: 1.0953786373138428
[32m[0511 03:48:47 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.687300443649292, Train Loss: 1.0953776836395264
[32m[0511 03:48:47 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6873023509979248, Train Loss: 1.095376968383789
[32m[0511 03:48:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6873041987419128, Train Loss: 1.0953762531280518
[32m[0511 03:48:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6873061656951904, Train Loss: 1.095375657081604
[32m[0511 03:48:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6873079538345337, Train Loss: 1.0953752994537354
[32m[0511 03:48:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6873098015785217, Train Loss: 1.0953747034072876
[32m[0511 03:48:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.687311589717865, Train Loss: 1.095374345779419
[32m[0511 03:48:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6873133778572083, Train Loss: 1.0953738689422607
[32m[0511 03:48:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.687315046787262, Train Loss: 1.095373511314392
[32m[0511 03:48:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6873166561126709, Train Loss: 1.095373272895813
[32m[0511 03:48:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6873182654380798, Train Loss: 1.0953730344772339
[32m[0511 03:48:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6873197555541992, Train Loss: 1.0953729152679443
[32m[0511 03:48:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6873212456703186, Train Loss: 1.0953727960586548
[32m[0511 03:48:48 @base_main.py:38][0m --------------- Iteration 3 ---------------
[32m[0511 03:48:48 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 10.8026 mins
[32m[0511 03:48:48 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 10.7120 mins
[32m[0511 03:48:48 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0281 mins
[32m[0511 03:48:48 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0051 mins
[32m[0511 03:48:48 @base_main.py:47][0m 3015 total steps have happened
[32m[0511 03:48:48 @base_main.py:52][0m [avg_reward]: -1328.7402171557626
[32m[0511 03:48:48 @base_main.py:52][0m [update_op]: None
[32m[0511 03:48:48 @base_main.py:52][0m [train_loss]: 1.3615206480026245
[32m[0511 03:48:48 @base_main.py:52][0m [val_loss]: 0.6873212456703186
[32m[0511 03:48:48 @base_main.py:52][0m [avg_train_loss]: 1.0953727960586548
[32m[0511 03:50:58 @mbmf_sampler.py:39][0m done with episode
[32m[0511 03:53:06 @mbmf_sampler.py:39][0m done with episode
[32m[0511 03:55:15 @mbmf_sampler.py:39][0m done with episode
[32m[0511 03:57:23 @mbmf_sampler.py:39][0m done with episode
[32m[0511 03:59:31 @mbmf_sampler.py:39][0m done with episode
[32m[0511 03:59:31 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0511 03:59:31 @base_trainer.py:216][0m Mean reward: -1443.9435891119645
[32m[0511 03:59:32 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6560359597206116, Train Loss: 1.005631446838379
[32m[0511 03:59:32 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6560418009757996, Train Loss: 1.0056289434432983
[32m[0511 03:59:32 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6560474038124084, Train Loss: 1.0056259632110596
[32m[0511 03:59:32 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6560525894165039, Train Loss: 1.0056228637695312
[32m[0511 03:59:32 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6560571789741516, Train Loss: 1.0056202411651611
[32m[0511 03:59:32 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6560614109039307, Train Loss: 1.0056179761886597
[32m[0511 03:59:32 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6560649871826172, Train Loss: 1.0056164264678955
[32m[0511 03:59:32 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6560682058334351, Train Loss: 1.0056148767471313
[32m[0511 03:59:32 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6560707688331604, Train Loss: 1.0056138038635254
[32m[0511 03:59:32 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6560728549957275, Train Loss: 1.0056129693984985
[32m[0511 03:59:32 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.656074583530426, Train Loss: 1.0056121349334717
[32m[0511 03:59:32 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6560759544372559, Train Loss: 1.0056116580963135
[32m[0511 03:59:32 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6560770273208618, Train Loss: 1.0056113004684448
[32m[0511 03:59:32 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6560776829719543, Train Loss: 1.0056109428405762
[32m[0511 03:59:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6560781598091125, Train Loss: 1.0056105852127075
[32m[0511 03:59:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6560783982276917, Train Loss: 1.005610466003418
[32m[0511 03:59:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6560784578323364, Train Loss: 1.0056102275848389
[32m[0511 03:59:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6560783386230469, Train Loss: 1.0056101083755493
[32m[0511 03:59:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6560781598091125, Train Loss: 1.0056099891662598
[32m[0511 03:59:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6560778617858887, Train Loss: 1.0056098699569702
[32m[0511 03:59:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6560773849487305, Train Loss: 1.0056097507476807
[32m[0511 03:59:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6560769081115723, Train Loss: 1.0056097507476807
[32m[0511 03:59:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6560763716697693, Train Loss: 1.0056097507476807
[32m[0511 03:59:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6560757160186768, Train Loss: 1.0056097507476807
[32m[0511 03:59:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.656075119972229, Train Loss: 1.0056097507476807
[32m[0511 03:59:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6560745239257812, Train Loss: 1.0056096315383911
[32m[0511 03:59:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6560739874839783, Train Loss: 1.0056096315383911
[32m[0511 03:59:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6560732126235962, Train Loss: 1.0056095123291016
[32m[0511 03:59:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6560726165771484, Train Loss: 1.0056096315383911
[32m[0511 03:59:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.6560720205307007, Train Loss: 1.0056096315383911
[32m[0511 03:59:34 @base_main.py:38][0m --------------- Iteration 4 ---------------
[32m[0511 03:59:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 21.5478 mins
[32m[0511 03:59:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 10.7181 mins
[32m[0511 03:59:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0358 mins
[32m[0511 03:59:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0047 mins
[32m[0511 03:59:34 @base_main.py:47][0m 4020 total steps have happened
[32m[0511 03:59:34 @base_main.py:52][0m [avg_reward]: -1443.9435891119645
[32m[0511 03:59:34 @base_main.py:52][0m [update_op]: None
[32m[0511 03:59:34 @base_main.py:52][0m [train_loss]: 0.6240668892860413
[32m[0511 03:59:34 @base_main.py:52][0m [val_loss]: 0.6560720205307007
[32m[0511 03:59:34 @base_main.py:52][0m [avg_train_loss]: 1.0056096315383911
[32m[0511 04:01:43 @mbmf_sampler.py:39][0m done with episode
[32m[0511 04:03:51 @mbmf_sampler.py:39][0m done with episode
[32m[0511 04:05:59 @mbmf_sampler.py:39][0m done with episode
[32m[0511 04:08:07 @mbmf_sampler.py:39][0m done with episode
[32m[0511 04:10:15 @mbmf_sampler.py:39][0m done with episode
[32m[0511 04:10:15 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0511 04:10:15 @base_trainer.py:216][0m Mean reward: -1412.8963815975455
[32m[0511 04:10:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9038925170898438, Train Loss: 1.045428991317749
[32m[0511 04:10:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9039608836174011, Train Loss: 1.0454230308532715
[32m[0511 04:10:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9040344953536987, Train Loss: 1.0454151630401611
[32m[0511 04:10:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9041041731834412, Train Loss: 1.0454081296920776
[32m[0511 04:10:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9041667580604553, Train Loss: 1.0454024076461792
[32m[0511 04:10:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9042209982872009, Train Loss: 1.045398235321045
[32m[0511 04:10:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9042676687240601, Train Loss: 1.045395016670227
[32m[0511 04:10:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9043072462081909, Train Loss: 1.0453927516937256
[32m[0511 04:10:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9043408036231995, Train Loss: 1.0453910827636719
[32m[0511 04:10:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9043691158294678, Train Loss: 1.0453897714614868
[32m[0511 04:10:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9043929576873779, Train Loss: 1.0453888177871704
[32m[0511 04:10:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9044129252433777, Train Loss: 1.045388102531433
[32m[0511 04:10:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9044299125671387, Train Loss: 1.0453877449035645
[32m[0511 04:10:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9044440388679504, Train Loss: 1.0453872680664062
[32m[0511 04:10:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9044560194015503, Train Loss: 1.0453869104385376
[32m[0511 04:10:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9044662117958069, Train Loss: 1.045386791229248
[32m[0511 04:10:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.904474675655365, Train Loss: 1.045386552810669
[32m[0511 04:10:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9044818878173828, Train Loss: 1.045386552810669
[32m[0511 04:10:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9044878482818604, Train Loss: 1.0453863143920898
[32m[0511 04:10:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9044930338859558, Train Loss: 1.0453863143920898
[32m[0511 04:10:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9044973254203796, Train Loss: 1.0453861951828003
[32m[0511 04:10:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9045010805130005, Train Loss: 1.0453861951828003
[32m[0511 04:10:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9045042395591736, Train Loss: 1.0453860759735107
[32m[0511 04:10:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9045069813728333, Train Loss: 1.0453859567642212
[32m[0511 04:10:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9045093059539795, Train Loss: 1.0453859567642212
[32m[0511 04:10:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9045111536979675, Train Loss: 1.0453859567642212
[32m[0511 04:10:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9045128226280212, Train Loss: 1.0453860759735107
[32m[0511 04:10:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9045142531394958, Train Loss: 1.0453859567642212
[32m[0511 04:10:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9045155644416809, Train Loss: 1.0453859567642212
[32m[0511 04:10:18 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9045166969299316, Train Loss: 1.0453859567642212
[32m[0511 04:10:18 @base_main.py:38][0m --------------- Iteration 5 ---------------
[32m[0511 04:10:18 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 32.3065 mins
[32m[0511 04:10:18 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 10.6817 mins
[32m[0511 04:10:18 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0459 mins
[32m[0511 04:10:18 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0044 mins
[32m[0511 04:10:18 @base_main.py:47][0m 5025 total steps have happened
[32m[0511 04:10:18 @base_main.py:52][0m [avg_reward]: -1412.8963815975455
[32m[0511 04:10:18 @base_main.py:52][0m [update_op]: None
[32m[0511 04:10:18 @base_main.py:52][0m [train_loss]: 1.1717555522918701
[32m[0511 04:10:18 @base_main.py:52][0m [val_loss]: 0.9045166969299316
[32m[0511 04:10:18 @base_main.py:52][0m [avg_train_loss]: 1.0453859567642212
[32m[0511 04:12:26 @mbmf_sampler.py:39][0m done with episode
[32m[0511 04:14:35 @mbmf_sampler.py:39][0m done with episode
[32m[0511 04:16:43 @mbmf_sampler.py:39][0m done with episode
[32m[0511 04:18:51 @mbmf_sampler.py:39][0m done with episode
[32m[0511 04:21:00 @mbmf_sampler.py:39][0m done with episode
[32m[0511 04:21:00 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0511 04:21:00 @base_trainer.py:216][0m Mean reward: -1143.00574768416
[32m[0511 04:21:00 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3050448894500732, Train Loss: 0.9829311966896057
[32m[0511 04:21:00 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3051483631134033, Train Loss: 0.9829217791557312
[32m[0511 04:21:00 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3052515983581543, Train Loss: 0.9829110503196716
[32m[0511 04:21:00 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.305342197418213, Train Loss: 0.9829025864601135
[32m[0511 04:21:00 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3054182529449463, Train Loss: 0.9828965663909912
[32m[0511 04:21:00 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.305480718612671, Train Loss: 0.9828923940658569
[32m[0511 04:21:01 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3055318593978882, Train Loss: 0.9828894138336182
[32m[0511 04:21:01 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.30557382106781, Train Loss: 0.9828872680664062
[32m[0511 04:21:01 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3056085109710693, Train Loss: 0.9828857779502869
[32m[0511 04:21:01 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3056373596191406, Train Loss: 0.9828847646713257
[32m[0511 04:21:01 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3056614398956299, Train Loss: 0.982883870601654
[32m[0511 04:21:01 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3056817054748535, Train Loss: 0.9828832745552063
[32m[0511 04:21:01 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3056992292404175, Train Loss: 0.9828827381134033
[32m[0511 04:21:01 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3057138919830322, Train Loss: 0.9828824400901794
[32m[0511 04:21:01 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3057266473770142, Train Loss: 0.9828820824623108
[32m[0511 04:21:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3057376146316528, Train Loss: 0.9828817844390869
[32m[0511 04:21:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3057470321655273, Train Loss: 0.9828816056251526
[32m[0511 04:21:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.305755376815796, Train Loss: 0.9828813672065735
[32m[0511 04:21:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3057624101638794, Train Loss: 0.9828813076019287
[32m[0511 04:21:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3057689666748047, Train Loss: 0.9828813076019287
[32m[0511 04:21:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3057745695114136, Train Loss: 0.9828810095787048
[32m[0511 04:21:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3057793378829956, Train Loss: 0.9828811287879944
[32m[0511 04:21:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.305783748626709, Train Loss: 0.9828811287879944
[32m[0511 04:21:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3057875633239746, Train Loss: 0.9828811287879944
[32m[0511 04:21:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.305790901184082, Train Loss: 0.9828810095787048
[32m[0511 04:21:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3057940006256104, Train Loss: 0.9828809499740601
[32m[0511 04:21:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3057969808578491, Train Loss: 0.9828808307647705
[32m[0511 04:21:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.305799126625061, Train Loss: 0.9828807711601257
[32m[0511 04:21:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3058013916015625, Train Loss: 0.9828809499740601
[32m[0511 04:21:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.3058031797409058, Train Loss: 0.9828808307647705
[32m[0511 04:21:03 @base_main.py:38][0m --------------- Iteration 6 ---------------
[32m[0511 04:21:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 43.0386 mins
[32m[0511 04:21:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 10.6991 mins
[32m[0511 04:21:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0556 mins
[32m[0511 04:21:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0047 mins
[32m[0511 04:21:03 @base_main.py:47][0m 6030 total steps have happened
[32m[0511 04:21:03 @base_main.py:52][0m [avg_reward]: -1143.00574768416
[32m[0511 04:21:03 @base_main.py:52][0m [update_op]: None
[32m[0511 04:21:03 @base_main.py:52][0m [train_loss]: 1.1916821002960205
[32m[0511 04:21:03 @base_main.py:52][0m [val_loss]: 1.3058031797409058
[32m[0511 04:21:03 @base_main.py:52][0m [avg_train_loss]: 0.9828808307647705
[32m[0511 04:23:12 @mbmf_sampler.py:39][0m done with episode
[32m[0511 04:25:20 @mbmf_sampler.py:39][0m done with episode
[32m[0511 04:27:29 @mbmf_sampler.py:39][0m done with episode
[32m[0511 04:29:38 @mbmf_sampler.py:39][0m done with episode
[32m[0511 04:31:47 @mbmf_sampler.py:39][0m done with episode
[32m[0511 04:31:47 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0511 04:31:47 @base_trainer.py:216][0m Mean reward: -1025.9228657064946
[32m[0511 04:31:47 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2496474981307983, Train Loss: 0.9712815880775452
[32m[0511 04:31:47 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2496458292007446, Train Loss: 0.9712787866592407
[32m[0511 04:31:47 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2496421337127686, Train Loss: 0.971276581287384
[32m[0511 04:31:47 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2496381998062134, Train Loss: 0.9712752103805542
[32m[0511 04:31:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2496347427368164, Train Loss: 0.9712740778923035
[32m[0511 04:31:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.249631643295288, Train Loss: 0.9712734222412109
[32m[0511 04:31:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2496289014816284, Train Loss: 0.9712730050086975
[32m[0511 04:31:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2496261596679688, Train Loss: 0.9712727069854736
[32m[0511 04:31:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2496237754821777, Train Loss: 0.9712724089622498
[32m[0511 04:31:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2496217489242554, Train Loss: 0.971272349357605
[32m[0511 04:31:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.249619722366333, Train Loss: 0.9712721705436707
[32m[0511 04:31:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2496179342269897, Train Loss: 0.9712721705436707
[32m[0511 04:31:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2496165037155151, Train Loss: 0.9712721109390259
[32m[0511 04:31:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.249614953994751, Train Loss: 0.9712721109390259
[32m[0511 04:31:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2496137619018555, Train Loss: 0.9712719321250916
[32m[0511 04:31:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2496126890182495, Train Loss: 0.9712721705436707
[32m[0511 04:31:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.249611496925354, Train Loss: 0.9712721109390259
[32m[0511 04:31:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2496107816696167, Train Loss: 0.9712721109390259
[32m[0511 04:31:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2496100664138794, Train Loss: 0.9712719321250916
[32m[0511 04:31:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2496092319488525, Train Loss: 0.9712719321250916
[32m[0511 04:31:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2496086359024048, Train Loss: 0.9712720513343811
[32m[0511 04:31:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.249608039855957, Train Loss: 0.9712719321250916
[32m[0511 04:31:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2496074438095093, Train Loss: 0.9712718725204468
[32m[0511 04:31:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2496072053909302, Train Loss: 0.9712719321250916
[32m[0511 04:31:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.249606728553772, Train Loss: 0.9712720513343811
[32m[0511 04:31:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2496064901351929, Train Loss: 0.9712718725204468
[32m[0511 04:31:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2496060132980347, Train Loss: 0.9712719321250916
[32m[0511 04:31:51 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2496057748794556, Train Loss: 0.9712719321250916
[32m[0511 04:31:51 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.249605655670166, Train Loss: 0.9712719321250916
[32m[0511 04:31:51 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.249605417251587, Train Loss: 0.9712719321250916
[32m[0511 04:31:51 @base_main.py:38][0m --------------- Iteration 7 ---------------
[32m[0511 04:31:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 53.7980 mins
[32m[0511 04:31:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 10.7252 mins
[32m[0511 04:31:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0645 mins
[32m[0511 04:31:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0049 mins
[32m[0511 04:31:51 @base_main.py:47][0m 7035 total steps have happened
[32m[0511 04:31:51 @base_main.py:52][0m [avg_reward]: -1025.9228657064946
[32m[0511 04:31:51 @base_main.py:52][0m [update_op]: None
[32m[0511 04:31:51 @base_main.py:52][0m [train_loss]: 1.0567487478256226
[32m[0511 04:31:51 @base_main.py:52][0m [val_loss]: 1.249605417251587
[32m[0511 04:31:51 @base_main.py:52][0m [avg_train_loss]: 0.9712719321250916
[32m[0511 04:31:51 @mbmf_trainer.py:160][0m Mean reward: -1249.7796965250448
[32m[0511 04:31:51 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.17704357206821442, Train Loss: 0.1895667165517807
[32m[0511 04:31:51 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.17719338834285736, Train Loss: 0.18945984542369843
[32m[0511 04:31:51 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.177326962351799, Train Loss: 0.18941903114318848
[32m[0511 04:31:51 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.17742601037025452, Train Loss: 0.18939505517482758
[32m[0511 04:31:51 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.17750807106494904, Train Loss: 0.18937020003795624
[32m[0511 04:31:51 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.17757850885391235, Train Loss: 0.18934865295886993
[32m[0511 04:31:51 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.1776382178068161, Train Loss: 0.1893308311700821
[32m[0511 04:31:51 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.17768993973731995, Train Loss: 0.18931472301483154
[32m[0511 04:31:51 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.1777370721101761, Train Loss: 0.18929947912693024
[32m[0511 04:31:51 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.1777811348438263, Train Loss: 0.18928547203540802
[32m[0511 04:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.17782258987426758, Train Loss: 0.1892726868391037
[32m[0511 04:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.17786194384098053, Train Loss: 0.18926088511943817
[32m[0511 04:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.17789946496486664, Train Loss: 0.1892499327659607
[32m[0511 04:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.17793531715869904, Train Loss: 0.18923979997634888
[32m[0511 04:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.1779695451259613, Train Loss: 0.18923039734363556
[32m[0511 04:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.17800211906433105, Train Loss: 0.18922168016433716
[32m[0511 04:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.17803312838077545, Train Loss: 0.1892135590314865
[32m[0511 04:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.1780625432729721, Train Loss: 0.18920600414276123
[32m[0511 04:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.17809037864208221, Train Loss: 0.18919889628887177
[32m[0511 04:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.17811667919158936, Train Loss: 0.18919223546981812
[32m[0511 04:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.17814147472381592, Train Loss: 0.1891859620809555
[32m[0511 04:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.1781647950410843, Train Loss: 0.18918000161647797
[32m[0511 04:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.17818668484687805, Train Loss: 0.1891743540763855
[32m[0511 04:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.17820720374584198, Train Loss: 0.18916897475719452
[32m[0511 04:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.17822639644145966, Train Loss: 0.18916380405426025
[32m[0511 04:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.17824429273605347, Train Loss: 0.1891588568687439
[32m[0511 04:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.17826096713542938, Train Loss: 0.18915407359600067
[32m[0511 04:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.17827649414539337, Train Loss: 0.18914943933486938
[32m[0511 04:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.17829091846942902, Train Loss: 0.18914490938186646
[32m[0511 04:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.1783042848110199, Train Loss: 0.18914051353931427
[32m[0511 04:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.17831666767597198, Train Loss: 0.18913620710372925
[32m[0511 04:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.17832809686660767, Train Loss: 0.1891319751739502
[32m[0511 04:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.1783386468887329, Train Loss: 0.18912780284881592
[32m[0511 04:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.1783483773469925, Train Loss: 0.1891237050294876
[32m[0511 04:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.17835733294487, Train Loss: 0.18911965191364288
[32m[0511 04:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.178365558385849, Train Loss: 0.18911562860012054
[32m[0511 04:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.17837309837341309, Train Loss: 0.1891116350889206
[32m[0511 04:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.17837998270988464, Train Loss: 0.18910765647888184
[32m[0511 04:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.17838628590106964, Train Loss: 0.18910372257232666
[32m[0511 04:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.17839202284812927, Train Loss: 0.1890997737646103
[32m[0511 04:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.1783972531557083, Train Loss: 0.1890958547592163
[32m[0511 04:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.17840199172496796, Train Loss: 0.18909193575382233
[32m[0511 04:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.17840628325939178, Train Loss: 0.18908804655075073
[32m[0511 04:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.178410142660141, Train Loss: 0.18908415734767914
[32m[0511 04:31:52 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.17841362953186035, Train Loss: 0.18908025324344635
[32m[0511 04:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.17841677367687225, Train Loss: 0.18907634913921356
[32m[0511 04:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.1784195601940155, Train Loss: 0.18907244503498077
[32m[0511 04:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.17842203378677368, Train Loss: 0.18906855583190918
[32m[0511 04:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.17842425405979156, Train Loss: 0.1890646368265152
[32m[0511 04:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.17842620611190796, Train Loss: 0.1890607327222824
[32m[0511 04:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.17842787504196167, Train Loss: 0.18905681371688843
[32m[0511 04:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.17842938005924225, Train Loss: 0.18905289471149445
[32m[0511 04:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.17843063175678253, Train Loss: 0.18904894590377808
[32m[0511 04:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.1784317046403885, Train Loss: 0.1890450119972229
[32m[0511 04:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.1784326285123825, Train Loss: 0.18904109299182892
[32m[0511 04:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.1784333735704422, Train Loss: 0.18903714418411255
[32m[0511 04:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.17843395471572876, Train Loss: 0.18903319537639618
[32m[0511 04:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.17843440175056458, Train Loss: 0.18902923166751862
[32m[0511 04:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.17843474447727203, Train Loss: 0.18902528285980225
[32m[0511 04:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.17843496799468994, Train Loss: 0.1890212893486023
[32m[0511 04:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.1784350723028183, Train Loss: 0.18901729583740234
[32m[0511 04:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.17843511700630188, Train Loss: 0.1890133172273636
[32m[0511 04:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.1784350574016571, Train Loss: 0.18900932371616364
[32m[0511 04:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.17843492329120636, Train Loss: 0.1890053153038025
[32m[0511 04:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.17843472957611084, Train Loss: 0.18900132179260254
[32m[0511 04:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.17843446135520935, Train Loss: 0.1889973133802414
[32m[0511 04:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.17843414843082428, Train Loss: 0.18899329006671906
[32m[0511 04:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.17843374609947205, Train Loss: 0.18898926675319672
[32m[0511 04:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.1784333437681198, Train Loss: 0.18898524343967438
[32m[0511 04:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.178432896733284, Train Loss: 0.18898122012615204
[32m[0511 04:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.1784323900938034, Train Loss: 0.1889771819114685
[32m[0511 04:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.178431898355484, Train Loss: 0.18897314369678497
[32m[0511 04:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.17843134701251984, Train Loss: 0.18896912038326263
[32m[0511 04:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.17843076586723328, Train Loss: 0.1889650672674179
[32m[0511 04:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.1784301996231079, Train Loss: 0.18896101415157318
[32m[0511 04:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.17842958867549896, Train Loss: 0.18895697593688965
[32m[0511 04:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.1784289926290512, Train Loss: 0.18895293772220612
[32m[0511 04:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.17842839658260345, Train Loss: 0.1889488697052002
[32m[0511 04:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.1784277707338333, Train Loss: 0.18894480168819427
[32m[0511 04:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.17842715978622437, Train Loss: 0.18894076347351074
[32m[0511 04:31:53 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.17842654883861542, Train Loss: 0.18893671035766602
[32m[0511 04:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.17842593789100647, Train Loss: 0.1889326423406601
[32m[0511 04:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.1784253567457199, Train Loss: 0.18892855942249298
[32m[0511 04:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.17842474579811096, Train Loss: 0.18892453610897064
[32m[0511 04:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.1784241497516632, Train Loss: 0.18892045319080353
[32m[0511 04:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.17842359840869904, Train Loss: 0.1889163851737976
[32m[0511 04:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.17842304706573486, Train Loss: 0.18891233205795288
[32m[0511 04:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.1784224957227707, Train Loss: 0.18890826404094696
[32m[0511 04:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.1784219890832901, Train Loss: 0.18890421092510223
[32m[0511 04:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.1784214973449707, Train Loss: 0.1889001578092575
[32m[0511 04:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.1784210056066513, Train Loss: 0.18889610469341278
[32m[0511 04:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.1784205436706543, Train Loss: 0.18889200687408447
[32m[0511 04:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.17842012643814087, Train Loss: 0.18888796865940094
[32m[0511 04:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.17841972410678864, Train Loss: 0.18888390064239502
[32m[0511 04:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.1784193366765976, Train Loss: 0.1888798624277115
[32m[0511 04:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.17841900885105133, Train Loss: 0.18887580931186676
[32m[0511 04:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.17841866612434387, Train Loss: 0.18887175619602203
[32m[0511 04:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.17841839790344238, Train Loss: 0.1888677328824997
[32m[0511 04:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.1784181445837021, Train Loss: 0.18886364996433258
[32m[0511 04:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.17841790616512299, Train Loss: 0.18885962665081024
[32m[0511 04:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.17841772735118866, Train Loss: 0.1888555884361267
[32m[0511 04:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.17841756343841553, Train Loss: 0.18885155022144318
[32m[0511 04:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.17841744422912598, Train Loss: 0.18884752690792084
[32m[0511 04:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.17841736972332, Train Loss: 0.1888434886932373
[32m[0511 04:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.17841732501983643, Train Loss: 0.18883945047855377
[32m[0511 04:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.17841732501983643, Train Loss: 0.18883542716503143
[32m[0511 04:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.17841733992099762, Train Loss: 0.18883143365383148
[32m[0511 04:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.1784173995256424, Train Loss: 0.18882739543914795
[32m[0511 04:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.17841751873493195, Train Loss: 0.188823401927948
[32m[0511 04:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.1784176528453827, Train Loss: 0.18881939351558685
[32m[0511 04:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.1784178465604782, Train Loss: 0.18881537020206451
[32m[0511 04:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.1784180849790573, Train Loss: 0.18881137669086456
[32m[0511 04:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.1784183531999588, Train Loss: 0.18880736827850342
[32m[0511 04:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.17841866612434387, Train Loss: 0.18880338966846466
[32m[0511 04:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.17841902375221252, Train Loss: 0.18879938125610352
[32m[0511 04:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.17841944098472595, Train Loss: 0.18879540264606476
[32m[0511 04:31:54 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.17841988801956177, Train Loss: 0.1887914389371872
[32m[0511 04:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.17842036485671997, Train Loss: 0.18878746032714844
[32m[0511 04:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.17842090129852295, Train Loss: 0.1887834668159485
[32m[0511 04:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.17842146754264832, Train Loss: 0.18877951800823212
[32m[0511 04:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.17842207849025726, Train Loss: 0.18877553939819336
[32m[0511 04:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.1784227341413498, Train Loss: 0.188771590590477
[32m[0511 04:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.1784234642982483, Train Loss: 0.18876762688159943
[32m[0511 04:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.17842420935630798, Train Loss: 0.18876367807388306
[32m[0511 04:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.17842496931552887, Train Loss: 0.18875975906848907
[32m[0511 04:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.1784258335828781, Train Loss: 0.1887558102607727
[32m[0511 04:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.17842669785022736, Train Loss: 0.18875187635421753
[32m[0511 04:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.17842763662338257, Train Loss: 0.18874794244766235
[32m[0511 04:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.17842860519886017, Train Loss: 0.18874402344226837
[32m[0511 04:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.17842960357666016, Train Loss: 0.1887400895357132
[32m[0511 04:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.1784306913614273, Train Loss: 0.1887361854314804
[32m[0511 04:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.17843179404735565, Train Loss: 0.18873228132724762
[32m[0511 04:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.17843294143676758, Train Loss: 0.18872834742069244
[32m[0511 04:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.1784341186285019, Train Loss: 0.18872445821762085
[32m[0511 04:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.1784353405237198, Train Loss: 0.18872058391571045
[32m[0511 04:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.17843662202358246, Train Loss: 0.18871669471263885
[32m[0511 04:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.17843793332576752, Train Loss: 0.18871279060840607
[32m[0511 04:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.17843930423259735, Train Loss: 0.18870891630649567
[32m[0511 04:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.17844070494174957, Train Loss: 0.18870502710342407
[32m[0511 04:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.17844213545322418, Train Loss: 0.18870115280151367
[32m[0511 04:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.17844364047050476, Train Loss: 0.18869729340076447
[32m[0511 04:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.17844516038894653, Train Loss: 0.18869341909885406
[32m[0511 04:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.17844673991203308, Train Loss: 0.18868957459926605
[32m[0511 04:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.17844833433628082, Train Loss: 0.18868573009967804
[32m[0511 04:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.17845000326633453, Train Loss: 0.18868190050125122
[32m[0511 04:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.17845167219638824, Train Loss: 0.18867804110050201
[32m[0511 04:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.17845340073108673, Train Loss: 0.1886742115020752
[32m[0511 04:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.1784551590681076, Train Loss: 0.18867038190364838
[32m[0511 04:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.17845697700977325, Train Loss: 0.18866653740406036
[32m[0511 04:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.1784588098526001, Train Loss: 0.18866272270679474
[32m[0511 04:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.17846070230007172, Train Loss: 0.1886589378118515
[32m[0511 04:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.17846259474754333, Train Loss: 0.18865512311458588
[32m[0511 04:31:55 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.17846454679965973, Train Loss: 0.18865130841732025
[32m[0511 04:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.1784665435552597, Train Loss: 0.18864750862121582
[32m[0511 04:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.17846857011318207, Train Loss: 0.1886436939239502
[32m[0511 04:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.17847061157226562, Train Loss: 0.18863992393016815
[32m[0511 04:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.17847272753715515, Train Loss: 0.18863613903522491
[32m[0511 04:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.17847482860088348, Train Loss: 0.18863235414028168
[32m[0511 04:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.17847700417041779, Train Loss: 0.18862859904766083
[32m[0511 04:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.17847919464111328, Train Loss: 0.1886248141527176
[32m[0511 04:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.17848141491413116, Train Loss: 0.18862105906009674
[32m[0511 04:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.17848367989063263, Train Loss: 0.1886172890663147
[32m[0511 04:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.1784859448671341, Train Loss: 0.18861353397369385
[32m[0511 04:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.17848828434944153, Train Loss: 0.1886097937822342
[32m[0511 04:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.17849060893058777, Train Loss: 0.18860606849193573
[32m[0511 04:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.17849300801753998, Train Loss: 0.18860232830047607
[32m[0511 04:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.178495392203331, Train Loss: 0.18859858810901642
[32m[0511 04:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.1784978210926056, Train Loss: 0.18859486281871796
[32m[0511 04:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.17850027978420258, Train Loss: 0.1885911375284195
[32m[0511 04:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.17850276827812195, Train Loss: 0.18858742713928223
[32m[0511 04:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.1785052865743637, Train Loss: 0.18858373165130615
[32m[0511 04:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.17850781977176666, Train Loss: 0.18858002126216888
[32m[0511 04:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.178510382771492, Train Loss: 0.188576340675354
[32m[0511 04:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.17851299047470093, Train Loss: 0.18857264518737793
[32m[0511 04:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.17851556837558746, Train Loss: 0.18856894969940186
[32m[0511 04:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.17851822078227997, Train Loss: 0.18856526911258698
[32m[0511 04:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.17852085828781128, Train Loss: 0.1885616034269333
[32m[0511 04:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.17852355539798737, Train Loss: 0.1885579228401184
[32m[0511 04:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.17852625250816345, Train Loss: 0.1885542869567871
[32m[0511 04:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.17852896451950073, Train Loss: 0.18855063617229462
[32m[0511 04:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.1785317212343216, Train Loss: 0.18854697048664093
[32m[0511 04:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.17853447794914246, Train Loss: 0.18854333460330963
[32m[0511 04:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.1785372495651245, Train Loss: 0.18853969871997833
[32m[0511 04:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.17854008078575134, Train Loss: 0.18853606283664703
[32m[0511 04:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.1785428822040558, Train Loss: 0.18853242695331573
[32m[0511 04:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.17854571342468262, Train Loss: 0.18852882087230682
[32m[0511 04:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.17854857444763184, Train Loss: 0.18852519989013672
[32m[0511 04:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.17855143547058105, Train Loss: 0.188521608710289
[32m[0511 04:31:56 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.17855434119701385, Train Loss: 0.1885180026292801
[32m[0511 04:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.17855721712112427, Train Loss: 0.18851441144943237
[32m[0511 04:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.17856013774871826, Train Loss: 0.18851083517074585
[32m[0511 04:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.17856305837631226, Train Loss: 0.18850724399089813
[32m[0511 04:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.17856599390506744, Train Loss: 0.1885036677122116
[32m[0511 04:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.17856895923614502, Train Loss: 0.18850012123584747
[32m[0511 04:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.1785719394683838, Train Loss: 0.18849654495716095
[32m[0511 04:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.17857490479946136, Train Loss: 0.18849299848079681
[32m[0511 04:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.17857789993286133, Train Loss: 0.18848945200443268
[32m[0511 04:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.1785808950662613, Train Loss: 0.18848590552806854
[32m[0511 04:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.17858392000198364, Train Loss: 0.1884823441505432
[32m[0511 04:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.1785869300365448, Train Loss: 0.18847884237766266
[32m[0511 04:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.17858995497226715, Train Loss: 0.18847531080245972
[32m[0511 04:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.1785929948091507, Train Loss: 0.18847180902957916
[32m[0511 04:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.17859604954719543, Train Loss: 0.18846827745437622
[32m[0511 04:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.17859911918640137, Train Loss: 0.18846477568149567
[32m[0511 04:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.1786021739244461, Train Loss: 0.1884612888097763
[32m[0511 04:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.17860524356365204, Train Loss: 0.18845780193805695
[32m[0511 04:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.17860829830169678, Train Loss: 0.18845431506633759
[32m[0511 04:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.1786113977432251, Train Loss: 0.18845082819461823
[32m[0511 04:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.17861446738243103, Train Loss: 0.18844735622406006
[32m[0511 04:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.17861756682395935, Train Loss: 0.18844391405582428
[32m[0511 04:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.17862065136432648, Train Loss: 0.1884404569864273
[32m[0511 04:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.178623765707016, Train Loss: 0.18843699991703033
[32m[0511 04:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.1786268651485443, Train Loss: 0.18843357264995575
[32m[0511 04:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.17862996459007263, Train Loss: 0.18843011558055878
[32m[0511 04:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.17863307893276215, Train Loss: 0.188426673412323
[32m[0511 04:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.17863616347312927, Train Loss: 0.1884232610464096
[32m[0511 04:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.17863929271697998, Train Loss: 0.1884198635816574
[32m[0511 04:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.1786424070596695, Train Loss: 0.18841643631458282
[32m[0511 04:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.178645521402359, Train Loss: 0.18841306865215302
[32m[0511 04:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.17864860594272614, Train Loss: 0.18840967118740082
[32m[0511 04:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.17865175008773804, Train Loss: 0.18840627372264862
[32m[0511 04:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.17865484952926636, Train Loss: 0.18840287625789642
[32m[0511 04:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.17865796387195587, Train Loss: 0.1883995085954666
[32m[0511 04:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.1786610633134842, Train Loss: 0.188396155834198
[32m[0511 04:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.1786641776561737, Train Loss: 0.188392773270607
[32m[0511 04:31:57 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.17866729199886322, Train Loss: 0.18838942050933838
[32m[0511 04:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.17867037653923035, Train Loss: 0.18838609755039215
[32m[0511 04:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.17867349088191986, Train Loss: 0.18838272988796234
[32m[0511 04:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.17867660522460938, Train Loss: 0.1883794069290161
[32m[0511 04:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.1786796897649765, Train Loss: 0.1883760690689087
[32m[0511 04:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.17868278920650482, Train Loss: 0.18837277591228485
[32m[0511 04:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.17868587374687195, Train Loss: 0.18836945295333862
[32m[0511 04:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.17868894338607788, Train Loss: 0.18836615979671478
[32m[0511 04:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.178692027926445, Train Loss: 0.18836283683776855
[32m[0511 04:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.17869509756565094, Train Loss: 0.1883595585823059
[32m[0511 04:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.17869818210601807, Train Loss: 0.18835626542568207
[32m[0511 04:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.1787012368440628, Train Loss: 0.18835300207138062
[32m[0511 04:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.17870427668094635, Train Loss: 0.18834973871707916
[32m[0511 04:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.1787073165178299, Train Loss: 0.18834646046161652
[32m[0511 04:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.17871038615703583, Train Loss: 0.18834322690963745
[32m[0511 04:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.17871344089508057, Train Loss: 0.188339963555336
[32m[0511 04:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.17871645092964172, Train Loss: 0.18833673000335693
[32m[0511 04:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.17871947586536407, Train Loss: 0.18833351135253906
[32m[0511 04:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.17872250080108643, Train Loss: 0.18833027780056
[32m[0511 04:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.1787254959344864, Train Loss: 0.18832705914974213
[32m[0511 04:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.17872849106788635, Train Loss: 0.18832384049892426
[32m[0511 04:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.17873148620128632, Train Loss: 0.18832062184810638
[32m[0511 04:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.17873448133468628, Train Loss: 0.1883174031972885
[32m[0511 04:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.17873744666576385, Train Loss: 0.18831419944763184
[32m[0511 04:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.17874042689800262, Train Loss: 0.18831102550029755
[32m[0511 04:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.1787433922290802, Train Loss: 0.18830786645412445
[32m[0511 04:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.17874634265899658, Train Loss: 0.18830466270446777
[32m[0511 04:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.17874927818775177, Train Loss: 0.18830150365829468
[32m[0511 04:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.17875221371650696, Train Loss: 0.18829834461212158
[32m[0511 04:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.17875513434410095, Train Loss: 0.1882951855659485
[32m[0511 04:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.17875805497169495, Train Loss: 0.18829204142093658
[32m[0511 04:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.17876096069812775, Train Loss: 0.18828892707824707
[32m[0511 04:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.17876383662223816, Train Loss: 0.18828576803207397
[32m[0511 04:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.17876671254634857, Train Loss: 0.18828265368938446
[32m[0511 04:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.17876960337162018, Train Loss: 0.18827952444553375
[32m[0511 04:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.1787724643945694, Train Loss: 0.18827642500400543
[32m[0511 04:31:58 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.17877531051635742, Train Loss: 0.18827329576015472
[32m[0511 04:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.17877817153930664, Train Loss: 0.1882702112197876
[32m[0511 04:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.17878098785877228, Train Loss: 0.18826711177825928
[32m[0511 04:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.1787838190793991, Train Loss: 0.18826402723789215
[32m[0511 04:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.17878663539886475, Train Loss: 0.18826095759868622
[32m[0511 04:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.1787894368171692, Train Loss: 0.18825788795948029
[32m[0511 04:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.17879222333431244, Train Loss: 0.18825481832027435
[32m[0511 04:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.1787949949502945, Train Loss: 0.18825174868106842
[32m[0511 04:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.17879775166511536, Train Loss: 0.18824869394302368
[32m[0511 04:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.17880050837993622, Train Loss: 0.18824565410614014
[32m[0511 04:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.1788032501935959, Train Loss: 0.18824262917041779
[32m[0511 04:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.17880599200725555, Train Loss: 0.18823957443237305
[32m[0511 04:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.17880870401859283, Train Loss: 0.1882365494966507
[32m[0511 04:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.17881141602993011, Train Loss: 0.18823353946208954
[32m[0511 04:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.1788141280412674, Train Loss: 0.1882305145263672
[32m[0511 04:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.1788167953491211, Train Loss: 0.18822751939296722
[32m[0511 04:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.178819477558136, Train Loss: 0.18822450935840607
[32m[0511 04:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.1788221299648285, Train Loss: 0.1882215142250061
[32m[0511 04:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.1788247972726822, Train Loss: 0.18821851909160614
[32m[0511 04:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.1788274347782135, Train Loss: 0.18821555376052856
[32m[0511 04:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.17883005738258362, Train Loss: 0.188212588429451
[32m[0511 04:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.17883267998695374, Train Loss: 0.18820960819721222
[32m[0511 04:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.17883528769016266, Train Loss: 0.18820665776729584
[32m[0511 04:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.17883789539337158, Train Loss: 0.18820367753505707
[32m[0511 04:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.17884045839309692, Train Loss: 0.1882007122039795
[32m[0511 04:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.17884300649166107, Train Loss: 0.1881977915763855
[32m[0511 04:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.1788455694913864, Train Loss: 0.1881948560476303
[32m[0511 04:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.17884813249111176, Train Loss: 0.18819190561771393
[32m[0511 04:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.17885065078735352, Train Loss: 0.18818901479244232
[32m[0511 04:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.17885316908359528, Train Loss: 0.18818606436252594
[32m[0511 04:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.17885567247867584, Train Loss: 0.18818314373493195
[32m[0511 04:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.1788581758737564, Train Loss: 0.18818025290966034
[32m[0511 04:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.17886066436767578, Train Loss: 0.18817734718322754
[32m[0511 04:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.17886313796043396, Train Loss: 0.18817447125911713
[32m[0511 04:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.17886561155319214, Train Loss: 0.18817158043384552
[32m[0511 04:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.17886805534362793, Train Loss: 0.1881687045097351
[32m[0511 04:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.17887049913406372, Train Loss: 0.1881658285856247
[32m[0511 04:31:59 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.17887291312217712, Train Loss: 0.18816296756267548
[32m[0511 04:32:00 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.17887532711029053, Train Loss: 0.18816007673740387
[32m[0511 04:32:00 @mbmf_sampler.py:98][0m Finished 9th episode
[32m[0511 04:32:00 @mbmf_sampler.py:102][0m 1809 timesteps from 9 episodes collected
[32m[0511 04:51:27 @mbmf_trainer.py:160][0m Mean reward: -1249.4821822367
[32m[0511 04:51:27 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.18892666697502136, Train Loss: 0.18247301876544952
[32m[0511 04:51:27 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.18892502784729004, Train Loss: 0.1823979914188385
[32m[0511 04:51:27 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.1888420730829239, Train Loss: 0.18239428102970123
[32m[0511 04:51:27 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.18891440331935883, Train Loss: 0.18236199021339417
[32m[0511 04:51:27 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.18888713419437408, Train Loss: 0.18236108124256134
[32m[0511 04:51:27 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.1889045536518097, Train Loss: 0.18235039710998535
[32m[0511 04:51:27 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.18891392648220062, Train Loss: 0.18234404921531677
[32m[0511 04:51:27 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.1889212280511856, Train Loss: 0.1823389083147049
[32m[0511 04:51:27 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.18893185257911682, Train Loss: 0.18233361840248108
[32m[0511 04:51:27 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.18894028663635254, Train Loss: 0.18232935667037964
[32m[0511 04:51:27 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.1889488846063614, Train Loss: 0.1823253035545349
[32m[0511 04:51:27 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.1889571100473404, Train Loss: 0.18232159316539764
[32m[0511 04:51:27 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.1889648735523224, Train Loss: 0.18231819570064545
[32m[0511 04:51:27 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.18897239863872528, Train Loss: 0.1823149174451828
[32m[0511 04:51:27 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.1889795958995819, Train Loss: 0.18231187760829926
[32m[0511 04:51:27 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.18898649513721466, Train Loss: 0.18230895698070526
[32m[0511 04:51:27 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.18899311125278473, Train Loss: 0.18230612576007843
[32m[0511 04:51:27 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.1889994889497757, Train Loss: 0.18230339884757996
[32m[0511 04:51:27 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.18900561332702637, Train Loss: 0.18230079114437103
[32m[0511 04:51:27 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.18901152908802032, Train Loss: 0.1822982281446457
[32m[0511 04:51:28 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.18901723623275757, Train Loss: 0.18229572474956512
[32m[0511 04:51:28 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.1890227347612381, Train Loss: 0.18229331076145172
[32m[0511 04:51:28 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.1890280842781067, Train Loss: 0.1822909563779831
[32m[0511 04:51:28 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.18903328478336334, Train Loss: 0.18228861689567566
[32m[0511 04:51:28 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.18903830647468567, Train Loss: 0.1822863519191742
[32m[0511 04:51:28 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.18904317915439606, Train Loss: 0.1822841316461563
[32m[0511 04:51:28 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.1890479326248169, Train Loss: 0.182281956076622
[32m[0511 04:51:28 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.18905258178710938, Train Loss: 0.1822798252105713
[32m[0511 04:51:28 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.1890570968389511, Train Loss: 0.18227772414684296
[32m[0511 04:51:28 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.18906152248382568, Train Loss: 0.1822756677865982
[32m[0511 04:51:28 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.1890658438205719, Train Loss: 0.18227362632751465
[32m[0511 04:51:28 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.18907004594802856, Train Loss: 0.18227161467075348
[32m[0511 04:51:28 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.18907418847084045, Train Loss: 0.18226966261863708
[32m[0511 04:51:28 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.18907827138900757, Train Loss: 0.18226772546768188
[32m[0511 04:51:28 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.18908224999904633, Train Loss: 0.18226583302021027
[32m[0511 04:51:28 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.18908613920211792, Train Loss: 0.18226392567157745
[32m[0511 04:51:28 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.18908998370170593, Train Loss: 0.1822620928287506
[32m[0511 04:51:28 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.18909375369548798, Train Loss: 0.18226025998592377
[32m[0511 04:51:28 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.18909749388694763, Train Loss: 0.18225844204425812
[32m[0511 04:51:28 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.18910115957260132, Train Loss: 0.18225665390491486
[32m[0511 04:51:28 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.18910478055477142, Train Loss: 0.1822548806667328
[32m[0511 04:51:28 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.18910834193229675, Train Loss: 0.1822531372308731
[32m[0511 04:51:28 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.1891118437051773, Train Loss: 0.18225142359733582
[32m[0511 04:51:28 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.18911528587341309, Train Loss: 0.1822497397661209
[32m[0511 04:51:28 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.18911871314048767, Train Loss: 0.1822480410337448
[32m[0511 04:51:28 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.18912209570407867, Train Loss: 0.1822463870048523
[32m[0511 04:51:28 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.1891254186630249, Train Loss: 0.18224471807479858
[32m[0511 04:51:28 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.18912872672080994, Train Loss: 0.18224309384822845
[32m[0511 04:51:28 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.1891319900751114, Train Loss: 0.18224148452281952
[32m[0511 04:51:29 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.18913519382476807, Train Loss: 0.18223987519741058
[32m[0511 04:51:29 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.18913838267326355, Train Loss: 0.18223829567432404
[32m[0511 04:51:29 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.18914154171943665, Train Loss: 0.18223673105239868
[32m[0511 04:51:29 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.18914467096328735, Train Loss: 0.18223518133163452
[32m[0511 04:51:29 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.18914775550365448, Train Loss: 0.18223363161087036
[32m[0511 04:51:29 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.1891508251428604, Train Loss: 0.1822320967912674
[32m[0511 04:51:29 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.18915385007858276, Train Loss: 0.18223056197166443
[32m[0511 04:51:29 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.18915686011314392, Train Loss: 0.18222910165786743
[32m[0511 04:51:29 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.18915987014770508, Train Loss: 0.18222761154174805
[32m[0511 04:51:29 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.18916280567646027, Train Loss: 0.18222615122795105
[32m[0511 04:51:29 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.18916574120521545, Train Loss: 0.18222469091415405
[32m[0511 04:51:29 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.18916864693164825, Train Loss: 0.18222321569919586
[32m[0511 04:51:29 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.18917152285575867, Train Loss: 0.18222178518772125
[32m[0511 04:51:29 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.18917439877986908, Train Loss: 0.18222035467624664
[32m[0511 04:51:29 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.1891772449016571, Train Loss: 0.18221893906593323
[32m[0511 04:51:29 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.18918006122112274, Train Loss: 0.1822175234556198
[32m[0511 04:51:29 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.189182847738266, Train Loss: 0.1822161227464676
[32m[0511 04:51:29 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.18918564915657043, Train Loss: 0.18221475183963776
[32m[0511 04:51:29 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.1891883760690689, Train Loss: 0.18221336603164673
[32m[0511 04:51:29 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.18919111788272858, Train Loss: 0.1822119802236557
[32m[0511 04:51:29 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.18919385969638824, Train Loss: 0.18221063911914825
[32m[0511 04:51:29 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.18919655680656433, Train Loss: 0.1822092980146408
[32m[0511 04:51:29 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.18919923901557922, Train Loss: 0.18220795691013336
[32m[0511 04:51:29 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.18920190632343292, Train Loss: 0.18220661580562592
[32m[0511 04:51:29 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.18920454382896423, Train Loss: 0.18220528960227966
[32m[0511 04:51:29 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.18920721113681793, Train Loss: 0.1822039783000946
[32m[0511 04:51:29 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.18920981884002686, Train Loss: 0.18220266699790955
[32m[0511 04:51:29 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.18921242654323578, Train Loss: 0.1822013556957245
[32m[0511 04:51:29 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.18921500444412231, Train Loss: 0.182200089097023
[32m[0511 04:51:30 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.18921758234500885, Train Loss: 0.18219879269599915
[32m[0511 04:51:30 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.1892201453447342, Train Loss: 0.18219751119613647
[32m[0511 04:51:30 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.18922270834445953, Train Loss: 0.1821962296962738
[32m[0511 04:51:30 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.1892252266407013, Train Loss: 0.18219496309757233
[32m[0511 04:51:30 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.18922774493694305, Train Loss: 0.18219371140003204
[32m[0511 04:51:30 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.18923026323318481, Train Loss: 0.18219245970249176
[32m[0511 04:51:30 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.1892327517271042, Train Loss: 0.18219123780727386
[32m[0511 04:51:30 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.18923524022102356, Train Loss: 0.18219000101089478
[32m[0511 04:51:30 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.18923772871494293, Train Loss: 0.18218876421451569
[32m[0511 04:51:30 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.18924018740653992, Train Loss: 0.1821875274181366
[32m[0511 04:51:30 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.18924261629581451, Train Loss: 0.1821863055229187
[32m[0511 04:51:30 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.1892450749874115, Train Loss: 0.182185098528862
[32m[0511 04:51:30 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.1892474889755249, Train Loss: 0.1821838766336441
[32m[0511 04:51:30 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.1892499029636383, Train Loss: 0.1821826994419098
[32m[0511 04:51:30 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.18925228714942932, Train Loss: 0.18218150734901428
[32m[0511 04:51:30 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.18925468623638153, Train Loss: 0.18218030035495758
[32m[0511 04:51:30 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.18925708532333374, Train Loss: 0.18217913806438446
[32m[0511 04:51:30 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.18925945460796356, Train Loss: 0.18217794597148895
[32m[0511 04:51:30 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.18926182389259338, Train Loss: 0.18217676877975464
[32m[0511 04:51:30 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.189264178276062, Train Loss: 0.18217560648918152
[32m[0511 04:51:30 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.18926653265953064, Train Loss: 0.182174414396286
[32m[0511 04:51:30 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.18926885724067688, Train Loss: 0.1821732521057129
[32m[0511 04:51:30 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.1892712116241455, Train Loss: 0.18217211961746216
[32m[0511 04:51:30 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.18927350640296936, Train Loss: 0.18217095732688904
[32m[0511 04:51:30 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.1892758160829544, Train Loss: 0.1821698248386383
[32m[0511 04:51:30 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.18927815556526184, Train Loss: 0.18216867744922638
[32m[0511 04:51:30 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.1892804503440857, Train Loss: 0.18216753005981445
[32m[0511 04:51:30 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.18928270041942596, Train Loss: 0.18216641247272491
[32m[0511 04:51:31 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.18928499519824982, Train Loss: 0.18216527998447418
[32m[0511 04:51:31 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.18928726017475128, Train Loss: 0.18216416239738464
[32m[0511 04:51:31 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.18928954005241394, Train Loss: 0.1821630299091339
[32m[0511 04:51:31 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.1892917901277542, Train Loss: 0.18216191232204437
[32m[0511 04:51:31 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.1892940253019333, Train Loss: 0.18216080963611603
[32m[0511 04:51:31 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.18929627537727356, Train Loss: 0.18215970695018768
[32m[0511 04:51:31 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.18929851055145264, Train Loss: 0.18215857446193695
[32m[0511 04:51:31 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.1893007457256317, Train Loss: 0.1821574866771698
[32m[0511 04:51:31 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.1893029510974884, Train Loss: 0.18215636909008026
[32m[0511 04:51:31 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.1893051564693451, Train Loss: 0.1821552962064743
[32m[0511 04:51:31 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.18930737674236298, Train Loss: 0.18215422332286835
[32m[0511 04:51:31 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.18930958211421967, Train Loss: 0.18215312063694
[32m[0511 04:51:31 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.18931177258491516, Train Loss: 0.18215204775333405
[32m[0511 04:51:31 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.18931394815444946, Train Loss: 0.1821509748697281
[32m[0511 04:51:31 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.18931613862514496, Train Loss: 0.18214988708496094
[32m[0511 04:51:31 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.18931832909584045, Train Loss: 0.1821487993001938
[32m[0511 04:51:31 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.18932047486305237, Train Loss: 0.18214775621891022
[32m[0511 04:51:31 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.18932265043258667, Train Loss: 0.18214668333530426
[32m[0511 04:51:31 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.18932481110095978, Train Loss: 0.1821456253528595
[32m[0511 04:51:31 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.1893269568681717, Train Loss: 0.18214456737041473
[32m[0511 04:51:31 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.1893291026353836, Train Loss: 0.18214349448680878
[32m[0511 04:51:31 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.18933124840259552, Train Loss: 0.1821424514055252
[32m[0511 04:51:31 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.18933336436748505, Train Loss: 0.18214136362075806
[32m[0511 04:51:31 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.18933551013469696, Train Loss: 0.18214033544063568
[32m[0511 04:51:31 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.18933764100074768, Train Loss: 0.1821393072605133
[32m[0511 04:51:31 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.1893397569656372, Train Loss: 0.18213824927806854
[32m[0511 04:51:31 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.18934187293052673, Train Loss: 0.18213722109794617
[32m[0511 04:51:31 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.18934395909309387, Train Loss: 0.1821361929178238
[32m[0511 04:51:31 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.1893460750579834, Train Loss: 0.18213513493537903
[32m[0511 04:51:31 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.18934817612171173, Train Loss: 0.18213410675525665
[32m[0511 04:51:32 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.18935026228427887, Train Loss: 0.18213309347629547
[32m[0511 04:51:32 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.189352348446846, Train Loss: 0.1821320503950119
[32m[0511 04:51:32 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.18935444951057434, Train Loss: 0.18213102221488953
[32m[0511 04:51:32 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.18935653567314148, Train Loss: 0.18213000893592834
[32m[0511 04:51:32 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.18935860693454742, Train Loss: 0.18212896585464478
[32m[0511 04:51:32 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.18936067819595337, Train Loss: 0.18212798237800598
[32m[0511 04:51:32 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.18936273455619812, Train Loss: 0.1821269690990448
[32m[0511 04:51:32 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.18936480581760406, Train Loss: 0.18212595582008362
[32m[0511 04:51:32 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.18936684727668762, Train Loss: 0.18212494254112244
[32m[0511 04:51:32 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.18936888873577118, Train Loss: 0.18212392926216125
[32m[0511 04:51:32 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.18937094509601593, Train Loss: 0.18212293088436127
[32m[0511 04:51:32 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.1893729865550995, Train Loss: 0.18212191760540009
[32m[0511 04:51:32 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.18937501311302185, Train Loss: 0.1821209043264389
[32m[0511 04:51:32 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.1893770694732666, Train Loss: 0.18211989104747772
[32m[0511 04:51:32 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.18937911093235016, Train Loss: 0.18211892247200012
[32m[0511 04:51:32 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.18938112258911133, Train Loss: 0.18211792409420013
[32m[0511 04:51:32 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.1893831342458725, Train Loss: 0.18211694061756134
[32m[0511 04:51:32 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.18938514590263367, Train Loss: 0.18211595714092255
[32m[0511 04:51:32 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.18938718736171722, Train Loss: 0.18211497366428375
[32m[0511 04:51:32 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.1893892139196396, Train Loss: 0.18211396038532257
[32m[0511 04:51:32 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.18939121067523956, Train Loss: 0.18211296200752258
[32m[0511 04:51:32 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.18939319252967834, Train Loss: 0.1821119785308838
[32m[0511 04:51:32 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.18939520418643951, Train Loss: 0.1821110099554062
[32m[0511 04:51:32 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.1893972009420395, Train Loss: 0.1821100264787674
[32m[0511 04:51:32 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.18939919769763947, Train Loss: 0.182109072804451
[32m[0511 04:51:32 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.18940117955207825, Train Loss: 0.1821080893278122
[32m[0511 04:51:32 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.18940317630767822, Train Loss: 0.1821071207523346
[32m[0511 04:51:32 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.189405158162117, Train Loss: 0.1821061223745346
[32m[0511 04:51:32 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.1894071251153946, Train Loss: 0.182105153799057
[32m[0511 04:51:33 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.18940910696983337, Train Loss: 0.1821041852235794
[32m[0511 04:51:33 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.18941107392311096, Train Loss: 0.182103231549263
[32m[0511 04:51:33 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.18941304087638855, Train Loss: 0.1821022480726242
[32m[0511 04:51:33 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.18941499292850494, Train Loss: 0.1821012943983078
[32m[0511 04:51:33 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.18941695988178253, Train Loss: 0.1821003407239914
[32m[0511 04:51:33 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.18941892683506012, Train Loss: 0.1820993572473526
[32m[0511 04:51:33 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.1894208788871765, Train Loss: 0.1820984184741974
[32m[0511 04:51:33 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.1894228160381317, Train Loss: 0.1820974498987198
[32m[0511 04:51:33 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.1894247680902481, Train Loss: 0.18209649622440338
[32m[0511 04:51:33 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.1894267350435257, Train Loss: 0.18209552764892578
[32m[0511 04:51:33 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.1894286423921585, Train Loss: 0.18209458887577057
[32m[0511 04:51:33 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.1894305795431137, Train Loss: 0.18209363520145416
[32m[0511 04:51:33 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.1894325315952301, Train Loss: 0.18209266662597656
[32m[0511 04:51:33 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.1894344687461853, Train Loss: 0.18209172785282135
[32m[0511 04:51:33 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.1894364058971405, Train Loss: 0.18209077417850494
[32m[0511 04:51:33 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.18943829834461212, Train Loss: 0.18208983540534973
[32m[0511 04:51:33 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.18944025039672852, Train Loss: 0.18208889663219452
[32m[0511 04:51:33 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.18944214284420013, Train Loss: 0.1820879578590393
[32m[0511 04:51:33 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.18944406509399414, Train Loss: 0.1820870041847229
[32m[0511 04:51:33 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.18944597244262695, Train Loss: 0.1820860356092453
[32m[0511 04:51:33 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.18944789469242096, Train Loss: 0.18208512663841248
[32m[0511 04:51:33 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.18944981694221497, Train Loss: 0.18208417296409607
[32m[0511 04:51:33 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.18945170938968658, Train Loss: 0.18208321928977966
[32m[0511 04:51:33 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.1894536018371582, Train Loss: 0.18208228051662445
[32m[0511 04:51:33 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.18945550918579102, Train Loss: 0.18208135664463043
[32m[0511 04:51:33 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.18945740163326263, Train Loss: 0.1820804327726364
[32m[0511 04:51:33 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.18945926427841187, Train Loss: 0.1820794939994812
[32m[0511 04:51:33 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.18946118652820587, Train Loss: 0.1820785403251648
[32m[0511 04:51:33 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.1894630789756775, Train Loss: 0.18207761645317078
[32m[0511 04:51:34 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.1894649714231491, Train Loss: 0.18207667768001556
[32m[0511 04:51:34 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.18946683406829834, Train Loss: 0.18207575380802155
[32m[0511 04:51:34 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.18946871161460876, Train Loss: 0.18207481503486633
[32m[0511 04:51:34 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.189470574259758, Train Loss: 0.1820739060640335
[32m[0511 04:51:34 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.1894724816083908, Train Loss: 0.1820729523897171
[32m[0511 04:51:34 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.18947434425354004, Train Loss: 0.18207205832004547
[32m[0511 04:51:34 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.18947620689868927, Train Loss: 0.18207111954689026
[32m[0511 04:51:34 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.1894780546426773, Train Loss: 0.18207018077373505
[32m[0511 04:51:34 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.18947991728782654, Train Loss: 0.18206928670406342
[32m[0511 04:51:34 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.18948177993297577, Train Loss: 0.1820683479309082
[32m[0511 04:51:34 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.189483642578125, Train Loss: 0.182067409157753
[32m[0511 04:51:34 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.18948550522327423, Train Loss: 0.18206648528575897
[32m[0511 04:51:34 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.18948736786842346, Train Loss: 0.18206559121608734
[32m[0511 04:51:34 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.1894892007112503, Train Loss: 0.18206466734409332
[32m[0511 04:51:34 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.18949104845523834, Train Loss: 0.1820637434720993
[32m[0511 04:51:34 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.18949289619922638, Train Loss: 0.18206283450126648
[32m[0511 04:51:34 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.18949474394321442, Train Loss: 0.18206189572811127
[32m[0511 04:51:34 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.18949660658836365, Train Loss: 0.18206098675727844
[32m[0511 04:51:34 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.1894984245300293, Train Loss: 0.18206007778644562
[32m[0511 04:51:34 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.18950022757053375, Train Loss: 0.1820591390132904
[32m[0511 04:51:34 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.18950209021568298, Train Loss: 0.18205824494361877
[32m[0511 04:51:34 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.18950392305850983, Train Loss: 0.18205732107162476
[32m[0511 04:51:34 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.18950575590133667, Train Loss: 0.18205641210079193
[32m[0511 04:51:34 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.18950757384300232, Train Loss: 0.1820555180311203
[32m[0511 04:51:34 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.18950937688350677, Train Loss: 0.18205460906028748
[32m[0511 04:51:34 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.18951120972633362, Train Loss: 0.18205370008945465
[32m[0511 04:51:34 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.18951304256916046, Train Loss: 0.18205279111862183
[32m[0511 04:51:34 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.18951483070850372, Train Loss: 0.1820518523454666
[32m[0511 04:51:34 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.18951663374900818, Train Loss: 0.18205095827579498
[32m[0511 04:51:35 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.18951845169067383, Train Loss: 0.18205003440380096
[32m[0511 04:51:35 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.18952026963233948, Train Loss: 0.18204912543296814
[32m[0511 04:51:35 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.18952208757400513, Train Loss: 0.1820482313632965
[32m[0511 04:51:35 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.18952389061450958, Train Loss: 0.18204733729362488
[32m[0511 04:51:35 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.18952569365501404, Train Loss: 0.18204639852046967
[32m[0511 04:51:35 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.1895274817943573, Train Loss: 0.18204548954963684
[32m[0511 04:51:35 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.18952926993370056, Train Loss: 0.18204458057880402
[32m[0511 04:51:35 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.1895310878753662, Train Loss: 0.18204368650913239
[32m[0511 04:51:35 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.18953289091587067, Train Loss: 0.18204279243946075
[32m[0511 04:51:35 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.18953467905521393, Train Loss: 0.18204186856746674
[32m[0511 04:51:35 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.1895364671945572, Train Loss: 0.1820409595966339
[32m[0511 04:51:35 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.18953822553157806, Train Loss: 0.18204008042812347
[32m[0511 04:51:35 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.18954001367092133, Train Loss: 0.18203917145729065
[32m[0511 04:51:35 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.1895418018102646, Train Loss: 0.18203827738761902
[32m[0511 04:51:35 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.18954358994960785, Train Loss: 0.1820373684167862
[32m[0511 04:51:35 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.18954536318778992, Train Loss: 0.18203645944595337
[32m[0511 04:51:35 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.18954715132713318, Train Loss: 0.18203558027744293
[32m[0511 04:51:35 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.18954890966415405, Train Loss: 0.1820346564054489
[32m[0511 04:51:35 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.18955068290233612, Train Loss: 0.18203377723693848
[32m[0511 04:51:35 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.189552441239357, Train Loss: 0.18203285336494446
[32m[0511 04:51:35 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.18955422937870026, Train Loss: 0.18203194439411163
[32m[0511 04:51:35 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.18955598771572113, Train Loss: 0.1820310801267624
[32m[0511 04:51:35 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.189557746052742, Train Loss: 0.18203015625476837
[32m[0511 04:51:35 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.18955951929092407, Train Loss: 0.18202926218509674
[32m[0511 04:51:35 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.18956126272678375, Train Loss: 0.18202835321426392
[32m[0511 04:51:35 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.1895630657672882, Train Loss: 0.1820274442434311
[32m[0511 04:51:35 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.1895648092031479, Train Loss: 0.18202656507492065
[32m[0511 04:51:35 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.18956655263900757, Train Loss: 0.18202565610408783
[32m[0511 04:51:35 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.18956829607486725, Train Loss: 0.182024747133255
[32m[0511 04:51:36 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.18957005441188812, Train Loss: 0.18202383816242218
[32m[0511 04:51:36 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.1895717978477478, Train Loss: 0.18202297389507294
[32m[0511 04:51:36 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.18957354128360748, Train Loss: 0.1820220798254013
[32m[0511 04:51:36 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.18957528471946716, Train Loss: 0.18202118575572968
[32m[0511 04:51:36 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.18957704305648804, Train Loss: 0.18202026188373566
[32m[0511 04:51:36 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.18957875669002533, Train Loss: 0.18201938271522522
[32m[0511 04:51:36 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.1895805150270462, Train Loss: 0.1820184737443924
[32m[0511 04:51:36 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.1895822435617447, Train Loss: 0.18201757967472076
[32m[0511 04:51:36 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.18958400189876556, Train Loss: 0.18201665580272675
[32m[0511 04:51:36 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.18958570063114166, Train Loss: 0.1820157915353775
[32m[0511 04:51:36 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.18958744406700134, Train Loss: 0.18201488256454468
[32m[0511 04:51:36 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.18958917260169983, Train Loss: 0.18201397359371185
[32m[0511 04:51:36 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.1895909160375595, Train Loss: 0.18201307952404022
[32m[0511 04:51:36 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.1895926296710968, Train Loss: 0.1820121705532074
[32m[0511 04:51:36 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.18959437310695648, Train Loss: 0.18201129138469696
[32m[0511 04:51:36 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.1895960569381714, Train Loss: 0.18201038241386414
[32m[0511 04:51:36 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.18959780037403107, Train Loss: 0.18200945854187012
[32m[0511 04:51:36 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.18959951400756836, Train Loss: 0.18200857937335968
[32m[0511 04:51:36 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.18960124254226685, Train Loss: 0.18200770020484924
[32m[0511 04:51:36 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.18960295617580414, Train Loss: 0.18200679123401642
[32m[0511 04:51:36 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.18960466980934143, Train Loss: 0.1820058822631836
[32m[0511 04:51:36 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.18960638344287872, Train Loss: 0.18200498819351196
[32m[0511 04:51:36 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.18960809707641602, Train Loss: 0.18200407922267914
[32m[0511 04:51:36 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.1896098107099533, Train Loss: 0.1820032000541687
[32m[0511 04:51:36 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.1896115094423294, Train Loss: 0.18200230598449707
[32m[0511 04:51:36 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.1896132081747055, Train Loss: 0.18200138211250305
[32m[0511 04:51:36 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.1896149069070816, Train Loss: 0.18200048804283142
[32m[0511 04:51:36 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.1896166354417801, Train Loss: 0.1819995939731598
[32m[0511 04:51:36 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.1896183341741562, Train Loss: 0.18199867010116577
[32m[0511 04:51:37 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.18962006270885468, Train Loss: 0.18199779093265533
[32m[0511 04:51:37 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.1896217316389084, Train Loss: 0.1819968819618225
[32m[0511 04:51:37 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.18962344527244568, Train Loss: 0.1819959580898285
[32m[0511 04:51:37 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.1896251142024994, Train Loss: 0.18199509382247925
[32m[0511 04:51:37 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.18962682783603668, Train Loss: 0.18199416995048523
[32m[0511 04:51:37 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.18962852656841278, Train Loss: 0.1819932758808136
[32m[0511 04:51:37 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.18963024020195007, Train Loss: 0.18199238181114197
[32m[0511 04:51:37 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.18963190913200378, Train Loss: 0.18199148774147034
[32m[0511 04:51:37 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.1896335929632187, Train Loss: 0.1819905787706375
[32m[0511 04:51:37 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.1896352767944336, Train Loss: 0.18198969960212708
[32m[0511 04:51:37 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.1896369606256485, Train Loss: 0.18198876082897186
[32m[0511 04:51:37 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.1896386444568634, Train Loss: 0.18198786675930023
[32m[0511 04:51:37 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.1896403431892395, Train Loss: 0.1819869577884674
[32m[0511 04:51:37 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.1896420270204544, Train Loss: 0.18198606371879578
[32m[0511 04:51:37 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.1896437257528305, Train Loss: 0.18198515474796295
[32m[0511 04:51:37 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.18964539468288422, Train Loss: 0.18198424577713013
[32m[0511 04:51:37 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.18964706361293793, Train Loss: 0.1819833368062973
[32m[0511 04:51:37 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.18964876234531403, Train Loss: 0.18198242783546448
[32m[0511 04:51:37 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.18965043127536774, Train Loss: 0.18198153376579285
[32m[0511 04:51:37 @mbmf_sampler.py:98][0m Finished 9th episode
[32m[0511 04:51:37 @mbmf_sampler.py:102][0m 1809 timesteps from 9 episodes collected
[32m[0511 05:11:04 @mbmf_trainer.py:160][0m Mean reward: -1261.3817391446157
[32m[0511 05:11:04 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.19120360910892487, Train Loss: 0.17571890354156494
[32m[0511 05:11:05 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.19126355648040771, Train Loss: 0.17561377584934235
[32m[0511 05:11:05 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.19129550457000732, Train Loss: 0.17560848593711853
[32m[0511 05:11:05 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.19131770730018616, Train Loss: 0.1756008267402649
[32m[0511 05:11:05 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.19134001433849335, Train Loss: 0.1755909025669098
[32m[0511 05:11:05 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.1913612186908722, Train Loss: 0.17558535933494568
[32m[0511 05:11:05 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.19138237833976746, Train Loss: 0.17557905614376068
[32m[0511 05:11:05 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.19140246510505676, Train Loss: 0.17557378113269806
[32m[0511 05:11:05 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.19142144918441772, Train Loss: 0.17556896805763245
[32m[0511 05:11:05 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.1914394497871399, Train Loss: 0.17556452751159668
[32m[0511 05:11:05 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.19145649671554565, Train Loss: 0.17556042969226837
[32m[0511 05:11:05 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.19147269427776337, Train Loss: 0.17555665969848633
[32m[0511 05:11:05 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.1914881020784378, Train Loss: 0.175553098320961
[32m[0511 05:11:05 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.19150276482105255, Train Loss: 0.17554976046085358
[32m[0511 05:11:05 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.1915166974067688, Train Loss: 0.1755465716123581
[32m[0511 05:11:05 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.1915300041437149, Train Loss: 0.17554357647895813
[32m[0511 05:11:05 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.19154268503189087, Train Loss: 0.17554068565368652
[32m[0511 05:11:05 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.19155481457710266, Train Loss: 0.17553794384002686
[32m[0511 05:11:05 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.19156642258167267, Train Loss: 0.17553527653217316
[32m[0511 05:11:05 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.19157753884792328, Train Loss: 0.17553269863128662
[32m[0511 05:11:05 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.1915881633758545, Train Loss: 0.17553023993968964
[32m[0511 05:11:05 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.19159840047359467, Train Loss: 0.17552784085273743
[32m[0511 05:11:05 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.1916082203388214, Train Loss: 0.1755254715681076
[32m[0511 05:11:05 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.1916176676750183, Train Loss: 0.17552323639392853
[32m[0511 05:11:06 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.19162675738334656, Train Loss: 0.17552098631858826
[32m[0511 05:11:06 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.19163556396961212, Train Loss: 0.17551881074905396
[32m[0511 05:11:06 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.19164402782917023, Train Loss: 0.17551670968532562
[32m[0511 05:11:06 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.19165220856666565, Train Loss: 0.17551462352275848
[32m[0511 05:11:06 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.1916601061820984, Train Loss: 0.17551259696483612
[32m[0511 05:11:06 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.19166776537895203, Train Loss: 0.17551060020923615
[32m[0511 05:11:06 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.19167517125606537, Train Loss: 0.17550861835479736
[32m[0511 05:11:06 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.191682368516922, Train Loss: 0.17550671100616455
[32m[0511 05:11:06 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.19168934226036072, Train Loss: 0.17550478875637054
[32m[0511 05:11:06 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.19169610738754272, Train Loss: 0.1755029410123825
[32m[0511 05:11:06 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.1917027086019516, Train Loss: 0.17550107836723328
[32m[0511 05:11:06 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.19170911610126495, Train Loss: 0.17549929022789001
[32m[0511 05:11:06 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.1917153298854828, Train Loss: 0.17549747228622437
[32m[0511 05:11:06 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.19172140955924988, Train Loss: 0.1754956990480423
[32m[0511 05:11:06 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.19172732532024384, Train Loss: 0.17549392580986023
[32m[0511 05:11:06 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.19173310697078705, Train Loss: 0.17549219727516174
[32m[0511 05:11:06 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.19173873960971832, Train Loss: 0.17549051344394684
[32m[0511 05:11:06 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.19174423813819885, Train Loss: 0.17548882961273193
[32m[0511 05:11:06 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.19174958765506744, Train Loss: 0.17548714578151703
[32m[0511 05:11:06 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.19175486266613007, Train Loss: 0.1754854917526245
[32m[0511 05:11:06 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.19175998866558075, Train Loss: 0.175483837723732
[32m[0511 05:11:06 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.19176502525806427, Train Loss: 0.17548222839832306
[32m[0511 05:11:06 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.19176995754241943, Train Loss: 0.17548060417175293
[32m[0511 05:11:07 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.19177478551864624, Train Loss: 0.17547902464866638
[32m[0511 05:11:07 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.1917795091867447, Train Loss: 0.17547743022441864
[32m[0511 05:11:07 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.19178414344787598, Train Loss: 0.17547588050365448
[32m[0511 05:11:07 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.1917886883020401, Train Loss: 0.17547431588172913
[32m[0511 05:11:07 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.19179314374923706, Train Loss: 0.17547278106212616
[32m[0511 05:11:07 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.19179753959178925, Train Loss: 0.1754712462425232
[32m[0511 05:11:07 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.19180183112621307, Train Loss: 0.17546972632408142
[32m[0511 05:11:07 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.19180606305599213, Train Loss: 0.17546823620796204
[32m[0511 05:11:07 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.19181020557880402, Train Loss: 0.17546673119068146
[32m[0511 05:11:07 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.19181430339813232, Train Loss: 0.17546525597572327
[32m[0511 05:11:07 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.19181829690933228, Train Loss: 0.17546378076076508
[32m[0511 05:11:07 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.19182227551937103, Train Loss: 0.17546232044696808
[32m[0511 05:11:07 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.19182616472244263, Train Loss: 0.1754608452320099
[32m[0511 05:11:07 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.19182996451854706, Train Loss: 0.17545942962169647
[32m[0511 05:11:07 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.1918337345123291, Train Loss: 0.17545798420906067
[32m[0511 05:11:07 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.19183745980262756, Train Loss: 0.17545655369758606
[32m[0511 05:11:07 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.19184112548828125, Train Loss: 0.17545513808727264
[32m[0511 05:11:07 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.19184471666812897, Train Loss: 0.17545370757579803
[32m[0511 05:11:07 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.1918482780456543, Train Loss: 0.175452321767807
[32m[0511 05:11:07 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.19185177981853485, Train Loss: 0.17545093595981598
[32m[0511 05:11:07 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.19185525178909302, Train Loss: 0.17544955015182495
[32m[0511 05:11:07 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.19185863435268402, Train Loss: 0.17544816434383392
[32m[0511 05:11:07 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.19186198711395264, Train Loss: 0.1754467934370041
[32m[0511 05:11:08 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.19186532497406006, Train Loss: 0.17544543743133545
[32m[0511 05:11:08 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.1918686032295227, Train Loss: 0.1754440814256668
[32m[0511 05:11:08 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.19187180697917938, Train Loss: 0.17544274032115936
[32m[0511 05:11:08 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.19187501072883606, Train Loss: 0.17544138431549072
[32m[0511 05:11:08 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.19187818467617035, Train Loss: 0.17544004321098328
[32m[0511 05:11:08 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.19188129901885986, Train Loss: 0.17543870210647583
[32m[0511 05:11:08 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.1918843537569046, Train Loss: 0.17543737590312958
[32m[0511 05:11:08 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.19188739359378815, Train Loss: 0.17543606460094452
[32m[0511 05:11:08 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.1918904036283493, Train Loss: 0.17543475329875946
[32m[0511 05:11:08 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.19189336895942688, Train Loss: 0.1754334419965744
[32m[0511 05:11:08 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.19189628958702087, Train Loss: 0.17543214559555054
[32m[0511 05:11:08 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.19189918041229248, Train Loss: 0.17543086409568787
[32m[0511 05:11:08 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.1919020563364029, Train Loss: 0.175429567694664
[32m[0511 05:11:08 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.19190490245819092, Train Loss: 0.17542827129364014
[32m[0511 05:11:08 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.19190768897533417, Train Loss: 0.17542698979377747
[32m[0511 05:11:08 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.19191047549247742, Train Loss: 0.1754257082939148
[32m[0511 05:11:08 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.19191321730613708, Train Loss: 0.1754244565963745
[32m[0511 05:11:08 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.19191592931747437, Train Loss: 0.17542317509651184
[32m[0511 05:11:08 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.19191859662532806, Train Loss: 0.17542190849781036
[32m[0511 05:11:08 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.19192126393318176, Train Loss: 0.17542065680027008
[32m[0511 05:11:08 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.19192387163639069, Train Loss: 0.1754193902015686
[32m[0511 05:11:08 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.191926509141922, Train Loss: 0.1754181683063507
[32m[0511 05:11:08 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.19192907214164734, Train Loss: 0.17541690170764923
[32m[0511 05:11:09 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.1919316053390503, Train Loss: 0.17541566491127014
[32m[0511 05:11:09 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.19193416833877563, Train Loss: 0.17541444301605225
[32m[0511 05:11:09 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.191936656832695, Train Loss: 0.17541319131851196
[32m[0511 05:11:09 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.191939115524292, Train Loss: 0.17541198432445526
[32m[0511 05:11:09 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.19194157421588898, Train Loss: 0.17541073262691498
[32m[0511 05:11:09 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.19194398820400238, Train Loss: 0.17540951073169708
[32m[0511 05:11:09 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.19194641709327698, Train Loss: 0.1754082888364792
[32m[0511 05:11:09 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.1919487863779068, Train Loss: 0.17540708184242249
[32m[0511 05:11:09 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.19195114076137543, Train Loss: 0.1754058599472046
[32m[0511 05:11:09 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.19195351004600525, Train Loss: 0.17540466785430908
[32m[0511 05:11:09 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.1919557899236679, Train Loss: 0.17540346086025238
[32m[0511 05:11:09 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.19195808470249176, Train Loss: 0.17540225386619568
[32m[0511 05:11:09 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.19196034967899323, Train Loss: 0.17540104687213898
[32m[0511 05:11:09 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.1919626146554947, Train Loss: 0.17539985477924347
[32m[0511 05:11:09 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.19196484982967377, Train Loss: 0.17539866268634796
[32m[0511 05:11:09 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.19196707010269165, Train Loss: 0.17539747059345245
[32m[0511 05:11:09 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.19196926057338715, Train Loss: 0.17539629340171814
[32m[0511 05:11:09 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.19197143614292145, Train Loss: 0.17539510130882263
[32m[0511 05:11:09 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.19197361171245575, Train Loss: 0.17539392411708832
[32m[0511 05:11:09 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.19197574257850647, Train Loss: 0.1753927320241928
[32m[0511 05:11:09 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.1919778436422348, Train Loss: 0.1753915548324585
[32m[0511 05:11:09 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.19197994470596313, Train Loss: 0.17539037764072418
[32m[0511 05:11:09 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.19198204576969147, Train Loss: 0.17538923025131226
[32m[0511 05:11:09 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.1919841170310974, Train Loss: 0.17538803815841675
[32m[0511 05:11:10 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.19198615849018097, Train Loss: 0.17538686096668243
[32m[0511 05:11:10 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.19198819994926453, Train Loss: 0.1753857284784317
[32m[0511 05:11:10 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.1919902265071869, Train Loss: 0.17538456618785858
[32m[0511 05:11:10 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.19199222326278687, Train Loss: 0.17538340389728546
[32m[0511 05:11:10 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.19199420511722565, Train Loss: 0.17538225650787354
[32m[0511 05:11:10 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.19199618697166443, Train Loss: 0.17538109421730042
[32m[0511 05:11:10 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.19199813902378082, Train Loss: 0.1753799468278885
[32m[0511 05:11:10 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.19200007617473602, Train Loss: 0.17537881433963776
[32m[0511 05:11:10 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.19200199842453003, Train Loss: 0.17537765204906464
[32m[0511 05:11:10 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.19200390577316284, Train Loss: 0.1753765046596527
[32m[0511 05:11:10 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.19200579822063446, Train Loss: 0.1753753423690796
[32m[0511 05:11:10 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.19200769066810608, Train Loss: 0.17537422478199005
[32m[0511 05:11:10 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.1920095533132553, Train Loss: 0.17537307739257812
[32m[0511 05:11:10 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.19201138615608215, Train Loss: 0.1753719449043274
[32m[0511 05:11:10 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.192013218998909, Train Loss: 0.17537079751491547
[32m[0511 05:11:10 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.19201505184173584, Train Loss: 0.17536967992782593
[32m[0511 05:11:10 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.1920168697834015, Train Loss: 0.1753685474395752
[32m[0511 05:11:10 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.19201867282390594, Train Loss: 0.17536740005016327
[32m[0511 05:11:10 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.1920204758644104, Train Loss: 0.17536628246307373
[32m[0511 05:11:10 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.19202224910259247, Train Loss: 0.1753651648759842
[32m[0511 05:11:10 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.19202399253845215, Train Loss: 0.17536404728889465
[32m[0511 05:11:10 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.19202573597431183, Train Loss: 0.17536292970180511
[32m[0511 05:11:11 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.1920274794101715, Train Loss: 0.1753617823123932
[32m[0511 05:11:11 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.19202920794487, Train Loss: 0.17536066472530365
[32m[0511 05:11:11 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.19203093647956848, Train Loss: 0.1753595769405365
[32m[0511 05:11:11 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.19203263521194458, Train Loss: 0.17535844445228577
[32m[0511 05:11:11 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.1920343041419983, Train Loss: 0.17535731196403503
[32m[0511 05:11:11 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.1920360028743744, Train Loss: 0.17535622417926788
[32m[0511 05:11:11 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.1920376569032669, Train Loss: 0.17535509169101715
[32m[0511 05:11:11 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.19203932583332062, Train Loss: 0.17535400390625
[32m[0511 05:11:11 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.19204097986221313, Train Loss: 0.17535290122032166
[32m[0511 05:11:11 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.19204258918762207, Train Loss: 0.17535176873207092
[32m[0511 05:11:11 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.1920442283153534, Train Loss: 0.17535068094730377
[32m[0511 05:11:11 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.19204582273960114, Train Loss: 0.17534957826137543
[32m[0511 05:11:11 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.19204744696617126, Train Loss: 0.17534847557544708
[32m[0511 05:11:11 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.192049041390419, Train Loss: 0.17534737288951874
[32m[0511 05:11:11 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.19205063581466675, Train Loss: 0.1753462702035904
[32m[0511 05:11:11 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.1920522004365921, Train Loss: 0.17534516751766205
[32m[0511 05:11:11 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.19205376505851746, Train Loss: 0.1753440946340561
[32m[0511 05:11:11 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.19205531477928162, Train Loss: 0.17534299194812775
[32m[0511 05:11:11 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.19205687940120697, Train Loss: 0.1753418892621994
[32m[0511 05:11:11 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.19205841422080994, Train Loss: 0.17534078657627106
[32m[0511 05:11:11 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.1920599341392517, Train Loss: 0.1753397136926651
[32m[0511 05:11:11 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.19206145405769348, Train Loss: 0.17533861100673676
[32m[0511 05:11:11 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.19206295907497406, Train Loss: 0.1753375083208084
[32m[0511 05:11:11 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.19206446409225464, Train Loss: 0.17533642053604126
[32m[0511 05:11:12 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.19206593930721283, Train Loss: 0.1753353327512741
[32m[0511 05:11:12 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.19206742942333221, Train Loss: 0.17533425986766815
[32m[0511 05:11:12 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.1920689046382904, Train Loss: 0.175333172082901
[32m[0511 05:11:12 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.1920703798532486, Train Loss: 0.17533209919929504
[32m[0511 05:11:12 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.1920718550682068, Train Loss: 0.1753309965133667
[32m[0511 05:11:12 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.1920733004808426, Train Loss: 0.17532995343208313
[32m[0511 05:11:12 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.1920747458934784, Train Loss: 0.17532885074615479
[32m[0511 05:11:12 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.192076176404953, Train Loss: 0.17532779276371002
[32m[0511 05:11:12 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.1920776069164276, Train Loss: 0.17532669007778168
[32m[0511 05:11:12 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.19207902252674103, Train Loss: 0.17532561719417572
[32m[0511 05:11:12 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.19208043813705444, Train Loss: 0.17532452940940857
[32m[0511 05:11:12 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.19208185374736786, Train Loss: 0.1753234565258026
[32m[0511 05:11:12 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.19208325445652008, Train Loss: 0.17532238364219666
[32m[0511 05:11:12 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.1920846402645111, Train Loss: 0.1753213107585907
[32m[0511 05:11:12 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.19208602607250214, Train Loss: 0.17532025277614594
[32m[0511 05:11:12 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.19208741188049316, Train Loss: 0.17531917989253998
[32m[0511 05:11:12 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.192088782787323, Train Loss: 0.17531810700893402
[32m[0511 05:11:12 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.19209013879299164, Train Loss: 0.17531703412532806
[32m[0511 05:11:12 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.19209150969982147, Train Loss: 0.1753159761428833
[32m[0511 05:11:12 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.19209285080432892, Train Loss: 0.17531488835811615
[32m[0511 05:11:12 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.19209419190883636, Train Loss: 0.1753138303756714
[32m[0511 05:11:12 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.192095547914505, Train Loss: 0.17531277239322662
[32m[0511 05:11:13 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.19209687411785126, Train Loss: 0.17531169950962067
[32m[0511 05:11:13 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.1920982152223587, Train Loss: 0.1753106415271759
[32m[0511 05:11:13 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.19209952652454376, Train Loss: 0.17530955374240875
[32m[0511 05:11:13 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.19210085272789001, Train Loss: 0.17530851066112518
[32m[0511 05:11:13 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.19210216403007507, Train Loss: 0.17530742287635803
[32m[0511 05:11:13 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.19210346043109894, Train Loss: 0.17530636489391327
[32m[0511 05:11:13 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.192104771733284, Train Loss: 0.1753053218126297
[32m[0511 05:11:13 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.19210606813430786, Train Loss: 0.17530424892902374
[32m[0511 05:11:13 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.19210731983184814, Train Loss: 0.17530320584774017
[32m[0511 05:11:13 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.1921086460351944, Train Loss: 0.17530213296413422
[32m[0511 05:11:13 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.19210989773273468, Train Loss: 0.17530108988285065
[32m[0511 05:11:13 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.19211119413375854, Train Loss: 0.17530003190040588
[32m[0511 05:11:13 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.19211246073246002, Train Loss: 0.17529897391796112
[32m[0511 05:11:13 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.1921137422323227, Train Loss: 0.17529791593551636
[32m[0511 05:11:13 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.19211499392986298, Train Loss: 0.1752968579530716
[32m[0511 05:11:13 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.19211624562740326, Train Loss: 0.17529579997062683
[32m[0511 05:11:13 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.19211749732494354, Train Loss: 0.17529475688934326
[32m[0511 05:11:13 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.19211876392364502, Train Loss: 0.1752936840057373
[32m[0511 05:11:13 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.19211998581886292, Train Loss: 0.17529265582561493
[32m[0511 05:11:13 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.192121222615242, Train Loss: 0.17529158294200897
[32m[0511 05:11:13 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.1921224594116211, Train Loss: 0.1752905398607254
[32m[0511 05:11:13 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.1921236664056778, Train Loss: 0.17528949677944183
[32m[0511 05:11:13 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.19212491810321808, Train Loss: 0.17528843879699707
[32m[0511 05:11:13 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.19212612509727478, Train Loss: 0.1752873808145523
[32m[0511 05:11:14 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.19212734699249268, Train Loss: 0.17528633773326874
[32m[0511 05:11:14 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.19212853908538818, Train Loss: 0.17528529465198517
[32m[0511 05:11:14 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.19212977588176727, Train Loss: 0.1752842515707016
[32m[0511 05:11:14 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.19213098287582397, Train Loss: 0.17528317868709564
[32m[0511 05:11:14 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.19213217496871948, Train Loss: 0.17528213560581207
[32m[0511 05:11:14 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.1921333521604538, Train Loss: 0.1752810925245285
[32m[0511 05:11:14 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.19213458895683289, Train Loss: 0.17528004944324493
[32m[0511 05:11:14 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.1921357810497284, Train Loss: 0.17527900636196136
[32m[0511 05:11:14 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.1921369582414627, Train Loss: 0.175277978181839
[32m[0511 05:11:14 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.19213813543319702, Train Loss: 0.17527692019939423
[32m[0511 05:11:14 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.19213932752609253, Train Loss: 0.17527587711811066
[32m[0511 05:11:14 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.19214050471782684, Train Loss: 0.1752748191356659
[32m[0511 05:11:14 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.19214168190956116, Train Loss: 0.17527379095554352
[32m[0511 05:11:14 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.19214285910129547, Train Loss: 0.17527274787425995
[32m[0511 05:11:14 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.19214403629302979, Train Loss: 0.17527170479297638
[32m[0511 05:11:14 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.1921451985836029, Train Loss: 0.17527064681053162
[32m[0511 05:11:14 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.19214634597301483, Train Loss: 0.17526961863040924
[32m[0511 05:11:14 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.19214752316474915, Train Loss: 0.17526857554912567
[32m[0511 05:11:14 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.19214867055416107, Train Loss: 0.1752675473690033
[32m[0511 05:11:14 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.1921498328447342, Train Loss: 0.17526647448539734
[32m[0511 05:11:14 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.19215098023414612, Train Loss: 0.17526543140411377
[32m[0511 05:11:14 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.19215215742588043, Train Loss: 0.1752644181251526
[32m[0511 05:11:14 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.19215330481529236, Train Loss: 0.17526337504386902
[32m[0511 05:11:14 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.19215445220470428, Train Loss: 0.17526231706142426
[32m[0511 05:11:15 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.1921555995941162, Train Loss: 0.17526128888130188
[32m[0511 05:11:15 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.19215673208236694, Train Loss: 0.1752602607011795
[32m[0511 05:11:15 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.19215787947177887, Train Loss: 0.17525923252105713
[32m[0511 05:11:15 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.1921590119600296, Train Loss: 0.17525817453861237
[32m[0511 05:11:15 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.19216017425060272, Train Loss: 0.17525714635849
[32m[0511 05:11:15 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.19216129183769226, Train Loss: 0.17525608837604523
[32m[0511 05:11:15 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.192162424325943, Train Loss: 0.17525506019592285
[32m[0511 05:11:15 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.19216355681419373, Train Loss: 0.17525401711463928
[32m[0511 05:11:15 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.19216470420360565, Train Loss: 0.1752529889345169
[32m[0511 05:11:15 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.19216583669185638, Train Loss: 0.17525197565555573
[32m[0511 05:11:15 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.19216695427894592, Train Loss: 0.17525091767311096
[32m[0511 05:11:15 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.19216808676719666, Train Loss: 0.1752498894929886
[32m[0511 05:11:15 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.1921692192554474, Train Loss: 0.17524883151054382
[32m[0511 05:11:15 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.19217033684253693, Train Loss: 0.17524780333042145
[32m[0511 05:11:15 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.19217145442962646, Train Loss: 0.17524676024913788
[32m[0511 05:11:15 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.1921725869178772, Train Loss: 0.1752457469701767
[32m[0511 05:11:15 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.19217368960380554, Train Loss: 0.17524468898773193
[32m[0511 05:11:15 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.19217480719089508, Train Loss: 0.17524366080760956
[32m[0511 05:11:15 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.1921759396791458, Train Loss: 0.17524263262748718
[32m[0511 05:11:15 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.19217705726623535, Train Loss: 0.1752415895462036
[32m[0511 05:11:15 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.1921781599521637, Train Loss: 0.17524056136608124
[32m[0511 05:11:15 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.19217927753925323, Train Loss: 0.17523953318595886
[32m[0511 05:11:15 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.19218039512634277, Train Loss: 0.17523851990699768
[32m[0511 05:11:16 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.19218149781227112, Train Loss: 0.1752374917268753
[32m[0511 05:11:16 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.19218263030052185, Train Loss: 0.17523644864559174
[32m[0511 05:11:16 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.1921837478876114, Train Loss: 0.17523542046546936
[32m[0511 05:11:16 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.19218485057353973, Train Loss: 0.17523440718650818
[32m[0511 05:11:16 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.19218596816062927, Train Loss: 0.1752333641052246
[32m[0511 05:11:16 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.1921870857477188, Train Loss: 0.17523232102394104
[32m[0511 05:11:16 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.19218818843364716, Train Loss: 0.17523129284381866
[32m[0511 05:11:16 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.1921892911195755, Train Loss: 0.17523027956485748
[32m[0511 05:11:16 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.19219040870666504, Train Loss: 0.1752292364835739
[32m[0511 05:11:16 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.1921914964914322, Train Loss: 0.17522820830345154
[32m[0511 05:11:16 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.19219261407852173, Train Loss: 0.17522718012332916
[32m[0511 05:11:16 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.19219373166561127, Train Loss: 0.1752261519432068
[32m[0511 05:11:16 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.1921948343515396, Train Loss: 0.1752251237630844
[32m[0511 05:11:16 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.19219593703746796, Train Loss: 0.17522411048412323
[32m[0511 05:11:16 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.1921970546245575, Train Loss: 0.17522306740283966
[32m[0511 05:11:16 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.19219815731048584, Train Loss: 0.17522203922271729
[32m[0511 05:11:16 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.19219927489757538, Train Loss: 0.1752210110425949
[32m[0511 05:11:16 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.19220036268234253, Train Loss: 0.17521998286247253
[32m[0511 05:11:16 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.19220146536827087, Train Loss: 0.17521895468235016
[32m[0511 05:11:16 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.1922025829553604, Train Loss: 0.17521792650222778
[32m[0511 05:11:16 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.19220368564128876, Train Loss: 0.1752168983221054
[32m[0511 05:11:16 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.1922047883272171, Train Loss: 0.17521588504314423
[32m[0511 05:11:16 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.19220589101314545, Train Loss: 0.17521485686302185
[32m[0511 05:11:17 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.19220700860023499, Train Loss: 0.17521381378173828
[32m[0511 05:11:17 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.19220809638500214, Train Loss: 0.1752128154039383
[32m[0511 05:11:17 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.19220922887325287, Train Loss: 0.17521178722381592
[32m[0511 05:11:17 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.1922103315591812, Train Loss: 0.17521075904369354
[32m[0511 05:11:17 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.19221143424510956, Train Loss: 0.17520973086357117
[32m[0511 05:11:17 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.1922125518321991, Train Loss: 0.1752087026834488
[32m[0511 05:11:17 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.19221366941928864, Train Loss: 0.17520765960216522
[32m[0511 05:11:17 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.19221477210521698, Train Loss: 0.17520666122436523
[32m[0511 05:11:17 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.19221588969230652, Train Loss: 0.17520564794540405
[32m[0511 05:11:17 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.19221699237823486, Train Loss: 0.17520460486412048
[32m[0511 05:11:17 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.1922181099653244, Train Loss: 0.1752036064863205
[32m[0511 05:11:17 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.19221921265125275, Train Loss: 0.17520256340503693
[32m[0511 05:11:17 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.1922203153371811, Train Loss: 0.17520153522491455
[32m[0511 05:11:17 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.19222144782543182, Train Loss: 0.17520050704479218
[32m[0511 05:11:17 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.19222256541252136, Train Loss: 0.1751995086669922
[32m[0511 05:11:17 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.1922236829996109, Train Loss: 0.17519846558570862
[32m[0511 05:11:17 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.19222478568553925, Train Loss: 0.17519745230674744
[32m[0511 05:11:17 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.19222590327262878, Train Loss: 0.17519643902778625
[32m[0511 05:11:17 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.19222702085971832, Train Loss: 0.17519541084766388
[32m[0511 05:11:17 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.19222813844680786, Train Loss: 0.1751943826675415
[32m[0511 05:11:17 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.1922292411327362, Train Loss: 0.17519336938858032
[32m[0511 05:11:18 @mbmf_sampler.py:98][0m Finished 9th episode
[32m[0511 05:11:18 @mbmf_sampler.py:102][0m 1809 timesteps from 9 episodes collected
[32m[0511 05:30:40 @mbmf_trainer.py:160][0m Mean reward: -1275.5928632767007
[32m[0511 05:30:40 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.17636054754257202, Train Loss: 0.17326019704341888
[32m[0511 05:30:40 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.1764196753501892, Train Loss: 0.17321965098381042
[32m[0511 05:30:40 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.17643828690052032, Train Loss: 0.1732107698917389
[32m[0511 05:30:40 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.176446795463562, Train Loss: 0.17320704460144043
[32m[0511 05:30:40 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.17645730078220367, Train Loss: 0.1732015162706375
[32m[0511 05:30:40 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.1764678806066513, Train Loss: 0.1731967329978943
[32m[0511 05:30:40 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.17647835612297058, Train Loss: 0.17319200932979584
[32m[0511 05:30:40 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.17648813128471375, Train Loss: 0.17318759858608246
[32m[0511 05:30:40 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.17649756371974945, Train Loss: 0.17318330705165863
[32m[0511 05:30:40 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.17650669813156128, Train Loss: 0.17317916452884674
[32m[0511 05:30:41 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.17651551961898804, Train Loss: 0.1731751561164856
[32m[0511 05:30:41 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.17652413249015808, Train Loss: 0.173171266913414
[32m[0511 05:30:41 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.17653247714042664, Train Loss: 0.17316749691963196
[32m[0511 05:30:41 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.17654067277908325, Train Loss: 0.17316383123397827
[32m[0511 05:30:41 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.17654862999916077, Train Loss: 0.17316026985645294
[32m[0511 05:30:41 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.17655646800994873, Train Loss: 0.17315679788589478
[32m[0511 05:30:41 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.17656415700912476, Train Loss: 0.17315341532230377
[32m[0511 05:30:41 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.17657168209552765, Train Loss: 0.17315012216567993
[32m[0511 05:30:41 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.1765790730714798, Train Loss: 0.17314694821834564
[32m[0511 05:30:41 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.1765863597393036, Train Loss: 0.17314380407333374
[32m[0511 05:30:41 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.17659352719783783, Train Loss: 0.173140749335289
[32m[0511 05:30:41 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.17660054564476013, Train Loss: 0.17313775420188904
[32m[0511 05:30:41 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.17660748958587646, Train Loss: 0.17313486337661743
[32m[0511 05:30:41 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.17661432921886444, Train Loss: 0.1731320023536682
[32m[0511 05:30:41 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.17662104964256287, Train Loss: 0.17312921583652496
[32m[0511 05:30:41 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.17662766575813293, Train Loss: 0.1731264889240265
[32m[0511 05:30:41 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.17663419246673584, Train Loss: 0.1731238216161728
[32m[0511 05:30:41 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.17664062976837158, Train Loss: 0.17312119901180267
[32m[0511 05:30:41 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.17664696276187897, Train Loss: 0.17311863601207733
[32m[0511 05:30:41 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.1766532063484192, Train Loss: 0.17311610281467438
[32m[0511 05:30:41 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.17665936052799225, Train Loss: 0.1731136590242386
[32m[0511 05:30:42 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.17666545510292053, Train Loss: 0.1731112152338028
[32m[0511 05:30:42 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.17667144536972046, Train Loss: 0.17310883104801178
[32m[0511 05:30:42 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.17667736113071442, Train Loss: 0.17310649156570435
[32m[0511 05:30:42 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.17668317258358002, Train Loss: 0.1731042116880417
[32m[0511 05:30:42 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.17668890953063965, Train Loss: 0.17310194671154022
[32m[0511 05:30:42 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.1766945868730545, Train Loss: 0.17309974133968353
[32m[0511 05:30:42 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.1767001748085022, Train Loss: 0.17309755086898804
[32m[0511 05:30:42 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.17670568823814392, Train Loss: 0.17309540510177612
[32m[0511 05:30:42 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.17671111226081848, Train Loss: 0.1730933040380478
[32m[0511 05:30:42 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.17671649158000946, Train Loss: 0.17309120297431946
[32m[0511 05:30:42 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.17672179639339447, Train Loss: 0.1730891615152359
[32m[0511 05:30:42 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.17672699689865112, Train Loss: 0.17308713495731354
[32m[0511 05:30:42 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.1767321676015854, Train Loss: 0.17308512330055237
[32m[0511 05:30:42 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.1767372339963913, Train Loss: 0.17308317124843597
[32m[0511 05:30:42 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.17674224078655243, Train Loss: 0.17308123409748077
[32m[0511 05:30:42 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.17674720287322998, Train Loss: 0.17307932674884796
[32m[0511 05:30:42 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.17675210535526276, Train Loss: 0.17307741940021515
[32m[0511 05:30:42 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.17675688862800598, Train Loss: 0.17307555675506592
[32m[0511 05:30:42 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.1767616719007492, Train Loss: 0.17307372391223907
[32m[0511 05:30:42 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.17676636576652527, Train Loss: 0.17307189106941223
[32m[0511 05:30:43 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.17677100002765656, Train Loss: 0.17307010293006897
[32m[0511 05:30:43 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.17677555978298187, Train Loss: 0.1730683445930481
[32m[0511 05:30:43 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.17678005993366241, Train Loss: 0.17306657135486603
[32m[0511 05:30:43 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.17678454518318176, Train Loss: 0.17306484282016754
[32m[0511 05:30:43 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.17678892612457275, Train Loss: 0.17306314408779144
[32m[0511 05:30:43 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.17679326236248016, Train Loss: 0.17306143045425415
[32m[0511 05:30:43 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.17679756879806519, Train Loss: 0.17305974662303925
[32m[0511 05:30:43 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.17680178582668304, Train Loss: 0.17305806279182434
[32m[0511 05:30:43 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.17680595815181732, Train Loss: 0.1730564385652542
[32m[0511 05:30:43 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.17681008577346802, Train Loss: 0.17305482923984528
[32m[0511 05:30:43 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.17681413888931274, Train Loss: 0.17305320501327515
[32m[0511 05:30:43 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.17681817710399628, Train Loss: 0.1730515956878662
[32m[0511 05:30:43 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.17682214081287384, Train Loss: 0.17305004596710205
[32m[0511 05:30:43 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.17682607471942902, Train Loss: 0.1730484664440155
[32m[0511 05:30:43 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.17682994902133942, Train Loss: 0.17304691672325134
[32m[0511 05:30:43 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.17683377861976624, Train Loss: 0.17304538190364838
[32m[0511 05:30:43 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.17683754861354828, Train Loss: 0.1730438619852066
[32m[0511 05:30:43 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.17684128880500793, Train Loss: 0.17304234206676483
[32m[0511 05:30:43 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.17684495449066162, Train Loss: 0.17304085195064545
[32m[0511 05:30:43 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.17684859037399292, Train Loss: 0.17303937673568726
[32m[0511 05:30:43 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.17685218155384064, Train Loss: 0.17303790152072906
[32m[0511 05:30:44 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.17685575783252716, Train Loss: 0.17303645610809326
[32m[0511 05:30:44 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.1768592745065689, Train Loss: 0.17303499579429626
[32m[0511 05:30:44 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.1768627166748047, Train Loss: 0.17303356528282166
[32m[0511 05:30:44 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.17686615884304047, Train Loss: 0.17303211987018585
[32m[0511 05:30:44 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.17686954140663147, Train Loss: 0.17303071916103363
[32m[0511 05:30:44 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.1768728792667389, Train Loss: 0.1730293184518814
[32m[0511 05:30:44 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.17687620222568512, Train Loss: 0.1730279177427292
[32m[0511 05:30:44 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.17687946557998657, Train Loss: 0.17302654683589935
[32m[0511 05:30:44 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.17688268423080444, Train Loss: 0.1730251908302307
[32m[0511 05:30:44 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.17688588798046112, Train Loss: 0.17302381992340088
[32m[0511 05:30:44 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.17688904702663422, Train Loss: 0.17302246391773224
[32m[0511 05:30:44 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.17689216136932373, Train Loss: 0.173021137714386
[32m[0511 05:30:44 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.17689524590969086, Train Loss: 0.17301981151103973
[32m[0511 05:30:44 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.1768983006477356, Train Loss: 0.17301848530769348
[32m[0511 05:30:44 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.17690131068229675, Train Loss: 0.17301715910434723
[32m[0511 05:30:44 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.17690430581569672, Train Loss: 0.17301586270332336
[32m[0511 05:30:44 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.1769072413444519, Train Loss: 0.1730145514011383
[32m[0511 05:30:44 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.1769101321697235, Train Loss: 0.17301326990127563
[32m[0511 05:30:44 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.1769130527973175, Train Loss: 0.17301200330257416
[32m[0511 05:30:44 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.17691588401794434, Train Loss: 0.17301075160503387
[32m[0511 05:30:45 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.17691870033740997, Train Loss: 0.1730094701051712
[32m[0511 05:30:45 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.17692148685455322, Train Loss: 0.17300821840763092
[32m[0511 05:30:45 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.17692425847053528, Train Loss: 0.17300699651241302
[32m[0511 05:30:45 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.17692698538303375, Train Loss: 0.17300572991371155
[32m[0511 05:30:45 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.17692968249320984, Train Loss: 0.17300449311733246
[32m[0511 05:30:45 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.17693234980106354, Train Loss: 0.17300328612327576
[32m[0511 05:30:45 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.17693498730659485, Train Loss: 0.17300206422805786
[32m[0511 05:30:45 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.17693760991096497, Train Loss: 0.17300087213516235
[32m[0511 05:30:45 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.1769401878118515, Train Loss: 0.17299966514110565
[32m[0511 05:30:45 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.17694273591041565, Train Loss: 0.17299844324588776
[32m[0511 05:30:45 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.1769452840089798, Train Loss: 0.17299729585647583
[32m[0511 05:30:45 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.17694780230522156, Train Loss: 0.17299608886241913
[32m[0511 05:30:45 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.17695026099681854, Train Loss: 0.17299491167068481
[32m[0511 05:30:45 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.17695271968841553, Train Loss: 0.1729937493801117
[32m[0511 05:30:45 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.17695516347885132, Train Loss: 0.17299260199069977
[32m[0511 05:30:45 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.17695757746696472, Train Loss: 0.17299145460128784
[32m[0511 05:30:45 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.17695996165275574, Train Loss: 0.17299029231071472
[32m[0511 05:30:45 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.17696230113506317, Train Loss: 0.172989159822464
[32m[0511 05:30:45 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.1769646406173706, Train Loss: 0.17298801243305206
[32m[0511 05:30:45 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.17696693539619446, Train Loss: 0.17298690974712372
[32m[0511 05:30:45 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.1769692301750183, Train Loss: 0.17298577725887299
[32m[0511 05:30:46 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.17697151005268097, Train Loss: 0.17298464477062225
[32m[0511 05:30:46 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.17697374522686005, Train Loss: 0.17298352718353271
[32m[0511 05:30:46 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.17697598040103912, Train Loss: 0.17298243939876556
[32m[0511 05:30:46 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.1769781857728958, Train Loss: 0.1729813516139984
[32m[0511 05:30:46 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.17698034644126892, Train Loss: 0.17298023402690887
[32m[0511 05:30:46 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.17698253691196442, Train Loss: 0.17297914624214172
[32m[0511 05:30:46 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.17698465287685394, Train Loss: 0.17297805845737457
[32m[0511 05:30:46 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.17698678374290466, Train Loss: 0.17297698557376862
[32m[0511 05:30:46 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.176988884806633, Train Loss: 0.17297591269016266
[32m[0511 05:30:46 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.17699095606803894, Train Loss: 0.1729748398065567
[32m[0511 05:30:46 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.1769930124282837, Train Loss: 0.17297376692295074
[32m[0511 05:30:46 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.17699506878852844, Train Loss: 0.17297270894050598
[32m[0511 05:30:46 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.1769970953464508, Train Loss: 0.1729716658592224
[32m[0511 05:30:46 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.17699910700321198, Train Loss: 0.17297062277793884
[32m[0511 05:30:46 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.17700110375881195, Train Loss: 0.17296956479549408
[32m[0511 05:30:46 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.17700307071208954, Train Loss: 0.1729685217142105
[32m[0511 05:30:46 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.17700500786304474, Train Loss: 0.17296749353408813
[32m[0511 05:30:46 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.17700694501399994, Train Loss: 0.17296645045280457
[32m[0511 05:30:46 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.17700886726379395, Train Loss: 0.172965407371521
[32m[0511 05:30:46 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.17701077461242676, Train Loss: 0.17296439409255981
[32m[0511 05:30:47 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.17701265215873718, Train Loss: 0.17296339571475983
[32m[0511 05:30:47 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.1770145446062088, Train Loss: 0.17296236753463745
[32m[0511 05:30:47 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.17701636254787445, Train Loss: 0.17296136915683746
[32m[0511 05:30:47 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.17701824009418488, Train Loss: 0.17296037077903748
[32m[0511 05:30:47 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.17702004313468933, Train Loss: 0.1729593425989151
[32m[0511 05:30:47 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.1770218461751938, Train Loss: 0.1729583442211151
[32m[0511 05:30:47 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.17702364921569824, Train Loss: 0.17295736074447632
[32m[0511 05:30:47 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.1770254224538803, Train Loss: 0.17295637726783752
[32m[0511 05:30:47 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.17702719569206238, Train Loss: 0.17295537889003754
[32m[0511 05:30:47 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.17702893912792206, Train Loss: 0.17295441031455994
[32m[0511 05:30:47 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.17703068256378174, Train Loss: 0.17295341193675995
[32m[0511 05:30:47 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.17703241109848022, Train Loss: 0.17295244336128235
[32m[0511 05:30:47 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.17703410983085632, Train Loss: 0.17295147478580475
[32m[0511 05:30:47 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.17703580856323242, Train Loss: 0.17295050621032715
[32m[0511 05:30:47 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.17703750729560852, Train Loss: 0.17294955253601074
[32m[0511 05:30:47 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.17703917622566223, Train Loss: 0.17294858396053314
[32m[0511 05:30:47 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.17704081535339355, Train Loss: 0.17294763028621674
[32m[0511 05:30:47 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.17704246938228607, Train Loss: 0.17294667661190033
[32m[0511 05:30:47 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.1770441085100174, Train Loss: 0.17294572293758392
[32m[0511 05:30:47 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.17704573273658752, Train Loss: 0.17294476926326752
[32m[0511 05:30:47 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.17704735696315765, Train Loss: 0.1729438304901123
[32m[0511 05:30:48 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.177048921585083, Train Loss: 0.1729428917169571
[32m[0511 05:30:48 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.17705053091049194, Train Loss: 0.17294196784496307
[32m[0511 05:30:48 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.1770520955324173, Train Loss: 0.17294102907180786
[32m[0511 05:30:48 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.17705366015434265, Train Loss: 0.17294007539749146
[32m[0511 05:30:48 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.177055224776268, Train Loss: 0.17293916642665863
[32m[0511 05:30:48 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.17705675959587097, Train Loss: 0.17293822765350342
[32m[0511 05:30:48 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.17705829441547394, Train Loss: 0.1729373186826706
[32m[0511 05:30:48 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.17705979943275452, Train Loss: 0.17293640971183777
[32m[0511 05:30:48 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.1770613193511963, Train Loss: 0.17293548583984375
[32m[0511 05:30:48 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.17706280946731567, Train Loss: 0.17293456196784973
[32m[0511 05:30:48 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.17706432938575745, Train Loss: 0.1729336678981781
[32m[0511 05:30:48 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.17706578969955444, Train Loss: 0.1729327291250229
[32m[0511 05:30:48 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.17706725001335144, Train Loss: 0.17293182015419006
[32m[0511 05:30:48 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.17706872522830963, Train Loss: 0.17293092608451843
[32m[0511 05:30:48 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.17707017064094543, Train Loss: 0.1729300171136856
[32m[0511 05:30:48 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.17707161605358124, Train Loss: 0.17292915284633636
[32m[0511 05:30:48 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.17707306146621704, Train Loss: 0.17292822897434235
[32m[0511 05:30:48 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.17707446217536926, Train Loss: 0.17292732000350952
[32m[0511 05:30:48 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.17707589268684387, Train Loss: 0.17292644083499908
[32m[0511 05:30:48 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.1770773082971573, Train Loss: 0.17292556166648865
[32m[0511 05:30:49 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.17707869410514832, Train Loss: 0.1729246824979782
[32m[0511 05:30:49 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.17708007991313934, Train Loss: 0.17292378842830658
[32m[0511 05:30:49 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.17708145081996918, Train Loss: 0.17292290925979614
[32m[0511 05:30:49 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.177082821726799, Train Loss: 0.1729220300912857
[32m[0511 05:30:49 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.17708419263362885, Train Loss: 0.17292113602161407
[32m[0511 05:30:49 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.17708554863929749, Train Loss: 0.17292024195194244
[32m[0511 05:30:49 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.17708690464496613, Train Loss: 0.1729193925857544
[32m[0511 05:30:49 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.17708824574947357, Train Loss: 0.17291852831840515
[32m[0511 05:30:49 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.17708958685398102, Train Loss: 0.1729176640510559
[32m[0511 05:30:49 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.17709091305732727, Train Loss: 0.17291679978370667
[32m[0511 05:30:49 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.17709222435951233, Train Loss: 0.17291595041751862
[32m[0511 05:30:49 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.17709355056285858, Train Loss: 0.17291507124900818
[32m[0511 05:30:49 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.17709483206272125, Train Loss: 0.17291420698165894
[32m[0511 05:30:49 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.1770961433649063, Train Loss: 0.1729133576154709
[32m[0511 05:30:49 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.17709742486476898, Train Loss: 0.17291247844696045
[32m[0511 05:30:49 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.17709869146347046, Train Loss: 0.1729116439819336
[32m[0511 05:30:49 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.17709997296333313, Train Loss: 0.17291079461574554
[32m[0511 05:30:49 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.1771012395620346, Train Loss: 0.1729099452495575
[32m[0511 05:30:49 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.17710250616073608, Train Loss: 0.17290908098220825
[32m[0511 05:30:49 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.17710378766059875, Train Loss: 0.1729082465171814
[32m[0511 05:30:50 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.17710500955581665, Train Loss: 0.17290738224983215
[32m[0511 05:30:50 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.17710626125335693, Train Loss: 0.1729065477848053
[32m[0511 05:30:50 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.17710749804973602, Train Loss: 0.17290569841861725
[32m[0511 05:30:50 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.1771087348461151, Train Loss: 0.1729048639535904
[32m[0511 05:30:50 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.177109956741333, Train Loss: 0.17290404438972473
[32m[0511 05:30:50 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.1771111637353897, Train Loss: 0.17290320992469788
[32m[0511 05:30:50 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.1771123707294464, Train Loss: 0.17290236055850983
[32m[0511 05:30:50 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.1771135926246643, Train Loss: 0.17290154099464417
[32m[0511 05:30:50 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.17711478471755981, Train Loss: 0.1729007065296173
[32m[0511 05:30:50 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.17711599171161652, Train Loss: 0.17289988696575165
[32m[0511 05:30:50 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.17711718380451202, Train Loss: 0.1728990375995636
[32m[0511 05:30:50 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.17711836099624634, Train Loss: 0.17289821803569794
[32m[0511 05:30:50 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.17711953818798065, Train Loss: 0.17289738357067108
[32m[0511 05:30:50 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.17712071537971497, Train Loss: 0.17289654910564423
[32m[0511 05:30:50 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.17712189257144928, Train Loss: 0.17289572954177856
[32m[0511 05:30:50 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.1771230548620224, Train Loss: 0.1728949397802353
[32m[0511 05:30:50 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.17712420225143433, Train Loss: 0.17289409041404724
[32m[0511 05:30:50 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.17712536454200745, Train Loss: 0.17289327085018158
[32m[0511 05:30:50 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.17712652683258057, Train Loss: 0.1728924810886383
[32m[0511 05:30:50 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.1771276593208313, Train Loss: 0.17289164662361145
[32m[0511 05:30:51 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.17712880671024323, Train Loss: 0.1728908270597458
[32m[0511 05:30:51 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.17712995409965515, Train Loss: 0.17289000749588013
[32m[0511 05:30:51 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.1771310716867447, Train Loss: 0.17288921773433685
[32m[0511 05:30:51 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.17713220417499542, Train Loss: 0.1728883981704712
[32m[0511 05:30:51 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.17713333666324615, Train Loss: 0.1728876233100891
[32m[0511 05:30:51 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.1771344393491745, Train Loss: 0.17288677394390106
[32m[0511 05:30:51 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.17713557183742523, Train Loss: 0.1728859841823578
[32m[0511 05:30:51 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.17713668942451477, Train Loss: 0.17288517951965332
[32m[0511 05:30:51 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.1771378070116043, Train Loss: 0.17288438975811005
[32m[0511 05:30:51 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.17713890969753265, Train Loss: 0.17288357019424438
[32m[0511 05:30:51 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.1771399974822998, Train Loss: 0.1728827804327011
[32m[0511 05:30:51 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.17714110016822815, Train Loss: 0.17288194596767426
[32m[0511 05:30:51 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.1771421879529953, Train Loss: 0.17288118600845337
[32m[0511 05:30:51 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.17714327573776245, Train Loss: 0.1728803813457489
[32m[0511 05:30:51 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.1771443486213684, Train Loss: 0.17287959158420563
[32m[0511 05:30:51 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.17714545130729675, Train Loss: 0.17287878692150116
[32m[0511 05:30:51 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.1771465241909027, Train Loss: 0.17287799715995789
[32m[0511 05:30:51 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.17714758217334747, Train Loss: 0.17287719249725342
[32m[0511 05:30:51 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.17714866995811462, Train Loss: 0.17287641763687134
[32m[0511 05:30:51 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.17714974284172058, Train Loss: 0.17287562787532806
[32m[0511 05:30:51 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.17715080082416534, Train Loss: 0.17287485301494598
[32m[0511 05:30:52 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.1771518737077713, Train Loss: 0.17287404835224152
[32m[0511 05:30:52 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.17715293169021606, Train Loss: 0.17287327349185944
[32m[0511 05:30:52 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.17715398967266083, Train Loss: 0.17287248373031616
[32m[0511 05:30:52 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.1771550476551056, Train Loss: 0.1728716939687729
[32m[0511 05:30:52 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.17715609073638916, Train Loss: 0.17287088930606842
[32m[0511 05:30:52 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.17715713381767273, Train Loss: 0.17287011444568634
[32m[0511 05:30:52 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.1771581918001175, Train Loss: 0.17286933958530426
[32m[0511 05:30:52 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.17715923488140106, Train Loss: 0.172868549823761
[32m[0511 05:30:52 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.17716027796268463, Train Loss: 0.1728677749633789
[32m[0511 05:30:52 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.177161306142807, Train Loss: 0.17286700010299683
[32m[0511 05:30:52 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.17716233432292938, Train Loss: 0.17286622524261475
[32m[0511 05:30:52 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.17716336250305176, Train Loss: 0.17286546528339386
[32m[0511 05:30:52 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.17716440558433533, Train Loss: 0.17286467552185059
[32m[0511 05:30:52 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.1771654188632965, Train Loss: 0.1728639155626297
[32m[0511 05:30:52 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.17716646194458008, Train Loss: 0.17286314070224762
[32m[0511 05:30:52 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.17716747522354126, Train Loss: 0.17286233603954315
[32m[0511 05:30:52 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.17716850340366364, Train Loss: 0.17286159098148346
[32m[0511 05:30:52 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.17716951668262482, Train Loss: 0.17286083102226257
[32m[0511 05:30:52 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.1771705150604248, Train Loss: 0.1728600710630417
[32m[0511 05:30:52 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.17717155814170837, Train Loss: 0.1728592813014984
[32m[0511 05:30:53 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.17717255651950836, Train Loss: 0.17285852134227753
[32m[0511 05:30:53 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.17717353999614716, Train Loss: 0.17285777628421783
[32m[0511 05:30:53 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.17717456817626953, Train Loss: 0.17285698652267456
[32m[0511 05:30:53 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.17717555165290833, Train Loss: 0.17285622656345367
[32m[0511 05:30:53 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.1771765649318695, Train Loss: 0.1728554666042328
[32m[0511 05:30:53 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.17717759311199188, Train Loss: 0.1728546917438507
[32m[0511 05:30:53 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.17717856168746948, Train Loss: 0.17285393178462982
[32m[0511 05:30:53 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.17717957496643066, Train Loss: 0.17285317182540894
[32m[0511 05:30:53 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.17718055844306946, Train Loss: 0.17285241186618805
[32m[0511 05:30:53 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.17718155682086945, Train Loss: 0.17285165190696716
[32m[0511 05:30:53 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.17718255519866943, Train Loss: 0.17285087704658508
[32m[0511 05:30:53 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.17718355357646942, Train Loss: 0.17285014688968658
[32m[0511 05:30:53 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.17718452215194702, Train Loss: 0.1728493571281433
[32m[0511 05:30:53 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.17718550562858582, Train Loss: 0.17284861207008362
[32m[0511 05:30:53 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.1771865040063858, Train Loss: 0.17284785211086273
[32m[0511 05:30:53 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.1771874874830246, Train Loss: 0.17284712195396423
[32m[0511 05:30:53 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.1771884560585022, Train Loss: 0.17284636199474335
[32m[0511 05:30:53 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.177189439535141, Train Loss: 0.17284561693668365
[32m[0511 05:30:53 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.17719042301177979, Train Loss: 0.17284487187862396
[32m[0511 05:30:53 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.17719142138957977, Train Loss: 0.17284409701824188
[32m[0511 05:30:54 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.17719237506389618, Train Loss: 0.17284336686134338
[32m[0511 05:30:54 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.17719332873821259, Train Loss: 0.1728425920009613
[32m[0511 05:30:54 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.17719431221485138, Train Loss: 0.172841876745224
[32m[0511 05:30:54 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.17719529569149017, Train Loss: 0.1728411316871643
[32m[0511 05:30:54 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.17719626426696777, Train Loss: 0.17284037172794342
[32m[0511 05:30:54 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.17719721794128418, Train Loss: 0.17283961176872253
[32m[0511 05:30:54 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.17719818651676178, Train Loss: 0.17283886671066284
[32m[0511 05:30:54 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.17719916999340057, Train Loss: 0.17283813655376434
[32m[0511 05:30:54 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.17720012366771698, Train Loss: 0.17283739149570465
[32m[0511 05:30:54 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.17720109224319458, Train Loss: 0.17283664643764496
[32m[0511 05:30:54 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.177202045917511, Train Loss: 0.17283588647842407
[32m[0511 05:30:54 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.1772030144929886, Train Loss: 0.17283514142036438
[32m[0511 05:30:54 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.177203968167305, Train Loss: 0.17283441126346588
[32m[0511 05:30:54 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.1772049367427826, Train Loss: 0.1728336662054062
[32m[0511 05:30:54 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.177205890417099, Train Loss: 0.17283295094966888
[32m[0511 05:30:54 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.1772068291902542, Train Loss: 0.172832190990448
[32m[0511 05:30:54 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.17720778286457062, Train Loss: 0.1728314459323883
[32m[0511 05:30:54 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.17720873653888702, Train Loss: 0.1728307157754898
[32m[0511 05:30:54 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.17720970511436462, Train Loss: 0.17282997071743011
[32m[0511 05:30:54 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.17721064388751984, Train Loss: 0.1728292554616928
[32m[0511 05:30:55 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.17721159756183624, Train Loss: 0.1728285253047943
[32m[0511 05:30:55 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.17721255123615265, Train Loss: 0.17282776534557343
[32m[0511 05:30:55 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.17721347510814667, Train Loss: 0.17282705008983612
[32m[0511 05:30:55 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.17721444368362427, Train Loss: 0.17282630503177643
[32m[0511 05:30:55 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.17721538245677948, Train Loss: 0.17282557487487793
[32m[0511 05:30:55 @mbmf_main.py:224][0m batch size for trpo is 1000
[32m[0511 05:30:55 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 05:30:55 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 05:30:55 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 05:30:55 @mbmf_main.py:132][0m Training starts at /root/mbbl
[32m[0511 05:30:55 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 05:30:55 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 05:30:55 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 05:30:55 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 05:30:55 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 05:30:55 @base_worker.py:45][0m Worker 0 online
[32m[0511 05:30:55 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 05:30:55 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 05:30:55 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 05:30:55 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 05:30:55 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 05:30:55 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 05:30:55 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 05:30:55 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 05:30:55 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 05:30:55 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 05:30:55 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 05:30:55 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 05:30:55 @base_worker.py:45][0m Worker 1 online
[32m[0511 05:30:55 @base_worker.py:45][0m Worker 2 online
[32m[0511 05:30:55 @base_worker.py:45][0m Worker 3 online
[32m[0511 05:30:55 @base_worker.py:45][0m Worker 4 online
[32m[0511 05:30:55 @base_worker.py:45][0m Worker 5 online
[32m[0511 05:30:55 @base_worker.py:45][0m Worker 6 online
[32m[0511 05:30:55 @base_worker.py:45][0m Worker 7 online
[32m[0511 05:30:55 @base_worker.py:45][0m Worker 8 online
[32m[0511 05:30:55 @base_worker.py:45][0m Worker 9 online
[32m[0511 05:30:55 @base_worker.py:45][0m Worker 10 online
[32m[0511 05:30:55 @base_worker.py:45][0m Worker 11 online
[32m[0511 05:30:55 @base_worker.py:45][0m Worker 12 online
[32m[0511 05:30:55 @base_worker.py:45][0m Worker 13 online
[32m[0511 05:30:55 @base_worker.py:45][0m Worker 14 online
[32m[0511 05:30:55 @base_worker.py:45][0m Worker 15 online
[32m[0511 05:30:55 @base_worker.py:45][0m Worker 16 online
[32m[0511 05:30:55 @base_worker.py:45][0m Worker 17 online
[32m[0511 05:30:55 @base_worker.py:45][0m Worker 18 online
[32m[0511 05:30:55 @base_worker.py:45][0m Worker 19 online
[32m[0511 05:30:55 @base_trainer.py:152][0m Trainer maintains [1] policy network
[32m[0511 05:30:55 @base_trainer.py:152][0m Trainer maintains [1] dynamics network
[32m[0511 05:30:55 @base_trainer.py:152][0m Trainer maintains [1] reward network
[32m[0511 05:30:56 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:30:56 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:30:56 @base_trainer.py:216][0m Mean reward: -1224.2839995600707
[32m[0511 05:30:57 @base_main.py:38][0m --------------- Iteration 1 ---------------
[32m[0511 05:30:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0000 mins
[32m[0511 05:30:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0511 05:30:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0156 mins
[32m[0511 05:30:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:30:57 @base_main.py:47][0m 1005 total steps have happened
[32m[0511 05:30:57 @base_main.py:52][0m [avg_reward]: -1224.2839995600707
[32m[0511 05:30:57 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:30:57 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:30:57 @base_trainer.py:216][0m Mean reward: -1019.9464546747197
[32m[0511 05:30:57 @base_main.py:38][0m --------------- Iteration 2 ---------------
[32m[0511 05:30:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0187 mins
[32m[0511 05:30:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0511 05:30:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 05:30:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:30:57 @base_main.py:47][0m 2010 total steps have happened
[32m[0511 05:30:57 @base_main.py:52][0m [avg_reward]: -1019.9464546747197
[32m[0511 05:30:58 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:30:58 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:30:58 @base_trainer.py:216][0m Mean reward: -1073.9425845501205
[32m[0511 05:30:58 @base_main.py:38][0m --------------- Iteration 3 ---------------
[32m[0511 05:30:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0321 mins
[32m[0511 05:30:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0511 05:30:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 05:30:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:30:58 @base_main.py:47][0m 3015 total steps have happened
[32m[0511 05:30:58 @base_main.py:52][0m [avg_reward]: -1073.9425845501205
[32m[0511 05:30:58 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:30:58 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:30:58 @base_trainer.py:216][0m Mean reward: -1280.8860404424013
[32m[0511 05:30:59 @base_main.py:38][0m --------------- Iteration 4 ---------------
[32m[0511 05:30:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0456 mins
[32m[0511 05:30:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0032 mins
[32m[0511 05:30:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 05:30:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:30:59 @base_main.py:47][0m 4020 total steps have happened
[32m[0511 05:30:59 @base_main.py:52][0m [avg_reward]: -1280.8860404424013
[32m[0511 05:30:59 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:30:59 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:30:59 @base_trainer.py:216][0m Mean reward: -1315.2024509059784
[32m[0511 05:31:00 @base_main.py:38][0m --------------- Iteration 5 ---------------
[32m[0511 05:31:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0589 mins
[32m[0511 05:31:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 05:31:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 05:31:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:00 @base_main.py:47][0m 5025 total steps have happened
[32m[0511 05:31:00 @base_main.py:52][0m [avg_reward]: -1315.2024509059784
[32m[0511 05:31:00 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:00 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:00 @base_trainer.py:216][0m Mean reward: -1492.3918490446692
[32m[0511 05:31:01 @base_main.py:38][0m --------------- Iteration 6 ---------------
[32m[0511 05:31:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0709 mins
[32m[0511 05:31:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 05:31:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 05:31:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:01 @base_main.py:47][0m 6030 total steps have happened
[32m[0511 05:31:01 @base_main.py:52][0m [avg_reward]: -1492.3918490446692
[32m[0511 05:31:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:01 @base_trainer.py:216][0m Mean reward: -1079.4673527857562
[32m[0511 05:31:01 @base_main.py:38][0m --------------- Iteration 7 ---------------
[32m[0511 05:31:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0839 mins
[32m[0511 05:31:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 05:31:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 05:31:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:01 @base_main.py:47][0m 7035 total steps have happened
[32m[0511 05:31:01 @base_main.py:52][0m [avg_reward]: -1079.4673527857562
[32m[0511 05:31:02 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:02 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:02 @base_trainer.py:216][0m Mean reward: -1111.6339928863727
[32m[0511 05:31:02 @base_main.py:38][0m --------------- Iteration 8 ---------------
[32m[0511 05:31:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0969 mins
[32m[0511 05:31:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 05:31:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 05:31:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:02 @base_main.py:47][0m 8040 total steps have happened
[32m[0511 05:31:02 @base_main.py:52][0m [avg_reward]: -1111.6339928863727
[32m[0511 05:31:02 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:02 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:02 @base_trainer.py:216][0m Mean reward: -1044.22156458442
[32m[0511 05:31:03 @base_main.py:38][0m --------------- Iteration 9 ---------------
[32m[0511 05:31:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1094 mins
[32m[0511 05:31:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0511 05:31:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 05:31:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:03 @base_main.py:47][0m 9045 total steps have happened
[32m[0511 05:31:03 @base_main.py:52][0m [avg_reward]: -1044.22156458442
[32m[0511 05:31:03 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:03 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:03 @base_trainer.py:216][0m Mean reward: -1116.1792956471652
[32m[0511 05:31:04 @base_main.py:38][0m --------------- Iteration 10 ---------------
[32m[0511 05:31:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1223 mins
[32m[0511 05:31:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 05:31:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 05:31:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:04 @base_main.py:47][0m 10050 total steps have happened
[32m[0511 05:31:04 @base_main.py:52][0m [avg_reward]: -1116.1792956471652
[32m[0511 05:31:04 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:04 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:04 @base_trainer.py:216][0m Mean reward: -969.8417583538458
[32m[0511 05:31:04 @base_main.py:38][0m --------------- Iteration 11 ---------------
[32m[0511 05:31:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1340 mins
[32m[0511 05:31:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 05:31:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 05:31:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:04 @base_main.py:47][0m 11055 total steps have happened
[32m[0511 05:31:04 @base_main.py:52][0m [avg_reward]: -969.8417583538458
[32m[0511 05:31:04 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:04 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:04 @base_trainer.py:216][0m Mean reward: -1303.0415551458896
[32m[0511 05:31:05 @base_main.py:38][0m --------------- Iteration 12 ---------------
[32m[0511 05:31:05 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1468 mins
[32m[0511 05:31:05 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 05:31:05 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 05:31:05 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:05 @base_main.py:47][0m 12060 total steps have happened
[32m[0511 05:31:05 @base_main.py:52][0m [avg_reward]: -1303.0415551458896
[32m[0511 05:31:05 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:05 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:05 @base_trainer.py:216][0m Mean reward: -1269.8153471859537
[32m[0511 05:31:06 @base_main.py:38][0m --------------- Iteration 13 ---------------
[32m[0511 05:31:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1593 mins
[32m[0511 05:31:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 05:31:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 05:31:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:06 @base_main.py:47][0m 13065 total steps have happened
[32m[0511 05:31:06 @base_main.py:52][0m [avg_reward]: -1269.8153471859537
[32m[0511 05:31:06 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:06 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:06 @base_trainer.py:216][0m Mean reward: -1297.4521009645455
[32m[0511 05:31:07 @base_main.py:38][0m --------------- Iteration 14 ---------------
[32m[0511 05:31:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1718 mins
[32m[0511 05:31:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0018 mins
[32m[0511 05:31:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 05:31:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:07 @base_main.py:47][0m 14070 total steps have happened
[32m[0511 05:31:07 @base_main.py:52][0m [avg_reward]: -1297.4521009645455
[32m[0511 05:31:07 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:07 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:07 @base_trainer.py:216][0m Mean reward: -1307.416755400049
[32m[0511 05:31:07 @base_main.py:38][0m --------------- Iteration 15 ---------------
[32m[0511 05:31:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1840 mins
[32m[0511 05:31:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 05:31:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 05:31:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:07 @base_main.py:47][0m 15075 total steps have happened
[32m[0511 05:31:07 @base_main.py:52][0m [avg_reward]: -1307.416755400049
[32m[0511 05:31:07 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:07 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:07 @base_trainer.py:216][0m Mean reward: -1359.2171188334478
[32m[0511 05:31:08 @base_main.py:38][0m --------------- Iteration 16 ---------------
[32m[0511 05:31:08 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1966 mins
[32m[0511 05:31:08 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 05:31:08 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 05:31:08 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:08 @base_main.py:47][0m 16080 total steps have happened
[32m[0511 05:31:08 @base_main.py:52][0m [avg_reward]: -1359.2171188334478
[32m[0511 05:31:08 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:08 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:08 @base_trainer.py:216][0m Mean reward: -1360.9797446824066
[32m[0511 05:31:09 @base_main.py:38][0m --------------- Iteration 17 ---------------
[32m[0511 05:31:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2086 mins
[32m[0511 05:31:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 05:31:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 05:31:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:09 @base_main.py:47][0m 17085 total steps have happened
[32m[0511 05:31:09 @base_main.py:52][0m [avg_reward]: -1360.9797446824066
[32m[0511 05:31:09 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:09 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:09 @base_trainer.py:216][0m Mean reward: -1326.4658519777445
[32m[0511 05:31:10 @base_main.py:38][0m --------------- Iteration 18 ---------------
[32m[0511 05:31:10 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2210 mins
[32m[0511 05:31:10 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 05:31:10 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 05:31:10 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:10 @base_main.py:47][0m 18090 total steps have happened
[32m[0511 05:31:10 @base_main.py:52][0m [avg_reward]: -1326.4658519777445
[32m[0511 05:31:10 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:10 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:10 @base_trainer.py:216][0m Mean reward: -1239.5073711949053
[32m[0511 05:31:10 @base_main.py:38][0m --------------- Iteration 19 ---------------
[32m[0511 05:31:10 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2335 mins
[32m[0511 05:31:10 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 05:31:10 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 05:31:10 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:10 @base_main.py:47][0m 19095 total steps have happened
[32m[0511 05:31:10 @base_main.py:52][0m [avg_reward]: -1239.5073711949053
[32m[0511 05:31:10 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:10 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:10 @base_trainer.py:216][0m Mean reward: -1043.5073480860196
[32m[0511 05:31:11 @base_main.py:38][0m --------------- Iteration 20 ---------------
[32m[0511 05:31:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2458 mins
[32m[0511 05:31:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 05:31:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 05:31:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0511 05:31:11 @base_main.py:47][0m 20100 total steps have happened
[32m[0511 05:31:11 @base_main.py:52][0m [avg_reward]: -1043.5073480860196
[32m[0511 05:31:11 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:11 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:11 @base_trainer.py:216][0m Mean reward: -1427.08909574774
[32m[0511 05:31:12 @base_main.py:38][0m --------------- Iteration 21 ---------------
[32m[0511 05:31:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2587 mins
[32m[0511 05:31:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 05:31:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 05:31:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:12 @base_main.py:47][0m 21105 total steps have happened
[32m[0511 05:31:12 @base_main.py:52][0m [avg_reward]: -1427.08909574774
[32m[0511 05:31:12 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:12 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:12 @base_trainer.py:216][0m Mean reward: -1099.4460962384794
[32m[0511 05:31:13 @base_main.py:38][0m --------------- Iteration 22 ---------------
[32m[0511 05:31:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2708 mins
[32m[0511 05:31:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 05:31:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 05:31:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:13 @base_main.py:47][0m 22110 total steps have happened
[32m[0511 05:31:13 @base_main.py:52][0m [avg_reward]: -1099.4460962384794
[32m[0511 05:31:13 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:13 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:13 @base_trainer.py:216][0m Mean reward: -1104.623940211216
[32m[0511 05:31:13 @base_main.py:38][0m --------------- Iteration 23 ---------------
[32m[0511 05:31:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2834 mins
[32m[0511 05:31:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 05:31:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 05:31:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:13 @base_main.py:47][0m 23115 total steps have happened
[32m[0511 05:31:13 @base_main.py:52][0m [avg_reward]: -1104.623940211216
[32m[0511 05:31:13 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:13 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:13 @base_trainer.py:216][0m Mean reward: -1186.3190699922538
[32m[0511 05:31:14 @base_main.py:38][0m --------------- Iteration 24 ---------------
[32m[0511 05:31:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2964 mins
[32m[0511 05:31:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 05:31:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 05:31:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:14 @base_main.py:47][0m 24120 total steps have happened
[32m[0511 05:31:14 @base_main.py:52][0m [avg_reward]: -1186.3190699922538
[32m[0511 05:31:14 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:14 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:14 @base_trainer.py:216][0m Mean reward: -1148.3938681010743
[32m[0511 05:31:15 @base_main.py:38][0m --------------- Iteration 25 ---------------
[32m[0511 05:31:15 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3092 mins
[32m[0511 05:31:15 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0511 05:31:15 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 05:31:15 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:15 @base_main.py:47][0m 25125 total steps have happened
[32m[0511 05:31:15 @base_main.py:52][0m [avg_reward]: -1148.3938681010743
[32m[0511 05:31:15 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:15 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:15 @base_trainer.py:216][0m Mean reward: -1111.8678678030576
[32m[0511 05:31:16 @base_main.py:38][0m --------------- Iteration 26 ---------------
[32m[0511 05:31:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3220 mins
[32m[0511 05:31:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 05:31:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0511 05:31:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:16 @base_main.py:47][0m 26130 total steps have happened
[32m[0511 05:31:16 @base_main.py:52][0m [avg_reward]: -1111.8678678030576
[32m[0511 05:31:16 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:16 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:16 @base_trainer.py:216][0m Mean reward: -1051.4628397062054
[32m[0511 05:31:16 @base_main.py:38][0m --------------- Iteration 27 ---------------
[32m[0511 05:31:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3340 mins
[32m[0511 05:31:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 05:31:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 05:31:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:16 @base_main.py:47][0m 27135 total steps have happened
[32m[0511 05:31:16 @base_main.py:52][0m [avg_reward]: -1051.4628397062054
[32m[0511 05:31:17 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:17 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:17 @base_trainer.py:216][0m Mean reward: -1615.2364937991347
[32m[0511 05:31:17 @base_main.py:38][0m --------------- Iteration 28 ---------------
[32m[0511 05:31:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3469 mins
[32m[0511 05:31:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 05:31:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0108 mins
[32m[0511 05:31:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:17 @base_main.py:47][0m 28140 total steps have happened
[32m[0511 05:31:17 @base_main.py:52][0m [avg_reward]: -1615.2364937991347
[32m[0511 05:31:17 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:17 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:17 @base_trainer.py:216][0m Mean reward: -1192.6187350870796
[32m[0511 05:31:18 @base_main.py:38][0m --------------- Iteration 29 ---------------
[32m[0511 05:31:18 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3603 mins
[32m[0511 05:31:18 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 05:31:18 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 05:31:18 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:18 @base_main.py:47][0m 29145 total steps have happened
[32m[0511 05:31:18 @base_main.py:52][0m [avg_reward]: -1192.6187350870796
[32m[0511 05:31:18 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:18 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:18 @base_trainer.py:216][0m Mean reward: -992.5870114023635
[32m[0511 05:31:19 @base_main.py:38][0m --------------- Iteration 30 ---------------
[32m[0511 05:31:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3731 mins
[32m[0511 05:31:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0018 mins
[32m[0511 05:31:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 05:31:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:19 @base_main.py:47][0m 30150 total steps have happened
[32m[0511 05:31:19 @base_main.py:52][0m [avg_reward]: -992.5870114023635
[32m[0511 05:31:19 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:19 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:19 @base_trainer.py:216][0m Mean reward: -1034.9642786105749
[32m[0511 05:31:19 @base_main.py:38][0m --------------- Iteration 31 ---------------
[32m[0511 05:31:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3852 mins
[32m[0511 05:31:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 05:31:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 05:31:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:19 @base_main.py:47][0m 31155 total steps have happened
[32m[0511 05:31:19 @base_main.py:52][0m [avg_reward]: -1034.9642786105749
[32m[0511 05:31:20 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:20 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:20 @base_trainer.py:216][0m Mean reward: -1280.3142485510434
[32m[0511 05:31:20 @base_main.py:38][0m --------------- Iteration 32 ---------------
[32m[0511 05:31:20 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3979 mins
[32m[0511 05:31:20 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 05:31:20 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 05:31:20 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:20 @base_main.py:47][0m 32160 total steps have happened
[32m[0511 05:31:20 @base_main.py:52][0m [avg_reward]: -1280.3142485510434
[32m[0511 05:31:20 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:20 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:20 @base_trainer.py:216][0m Mean reward: -1469.436409245204
[32m[0511 05:31:21 @base_main.py:38][0m --------------- Iteration 33 ---------------
[32m[0511 05:31:21 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4105 mins
[32m[0511 05:31:21 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 05:31:21 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 05:31:21 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0511 05:31:21 @base_main.py:47][0m 33165 total steps have happened
[32m[0511 05:31:21 @base_main.py:52][0m [avg_reward]: -1469.436409245204
[32m[0511 05:31:21 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:21 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:21 @base_trainer.py:216][0m Mean reward: -1415.7376599426284
[32m[0511 05:31:22 @base_main.py:38][0m --------------- Iteration 34 ---------------
[32m[0511 05:31:22 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4229 mins
[32m[0511 05:31:22 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 05:31:22 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 05:31:22 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:22 @base_main.py:47][0m 34170 total steps have happened
[32m[0511 05:31:22 @base_main.py:52][0m [avg_reward]: -1415.7376599426284
[32m[0511 05:31:22 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:22 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:22 @base_trainer.py:216][0m Mean reward: -1192.175171692938
[32m[0511 05:31:22 @base_main.py:38][0m --------------- Iteration 35 ---------------
[32m[0511 05:31:22 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4349 mins
[32m[0511 05:31:22 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 05:31:22 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 05:31:22 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:22 @base_main.py:47][0m 35175 total steps have happened
[32m[0511 05:31:22 @base_main.py:52][0m [avg_reward]: -1192.175171692938
[32m[0511 05:31:23 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:23 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:23 @base_trainer.py:216][0m Mean reward: -1084.6993043968107
[32m[0511 05:31:23 @base_main.py:38][0m --------------- Iteration 36 ---------------
[32m[0511 05:31:23 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4474 mins
[32m[0511 05:31:23 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 05:31:23 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 05:31:23 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:23 @base_main.py:47][0m 36180 total steps have happened
[32m[0511 05:31:23 @base_main.py:52][0m [avg_reward]: -1084.6993043968107
[32m[0511 05:31:23 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:23 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:23 @base_trainer.py:216][0m Mean reward: -1261.6756613246548
[32m[0511 05:31:24 @base_main.py:38][0m --------------- Iteration 37 ---------------
[32m[0511 05:31:24 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4597 mins
[32m[0511 05:31:24 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 05:31:24 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 05:31:24 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:24 @base_main.py:47][0m 37185 total steps have happened
[32m[0511 05:31:24 @base_main.py:52][0m [avg_reward]: -1261.6756613246548
[32m[0511 05:31:24 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:24 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:24 @base_trainer.py:216][0m Mean reward: -884.578549406943
[32m[0511 05:31:25 @base_main.py:38][0m --------------- Iteration 38 ---------------
[32m[0511 05:31:25 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4728 mins
[32m[0511 05:31:25 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 05:31:25 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 05:31:25 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:25 @base_main.py:47][0m 38190 total steps have happened
[32m[0511 05:31:25 @base_main.py:52][0m [avg_reward]: -884.578549406943
[32m[0511 05:31:25 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:25 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:25 @base_trainer.py:216][0m Mean reward: -1288.2214107041398
[32m[0511 05:31:25 @base_main.py:38][0m --------------- Iteration 39 ---------------
[32m[0511 05:31:25 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4855 mins
[32m[0511 05:31:25 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 05:31:25 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 05:31:25 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:25 @base_main.py:47][0m 39195 total steps have happened
[32m[0511 05:31:25 @base_main.py:52][0m [avg_reward]: -1288.2214107041398
[32m[0511 05:31:26 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:26 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:26 @base_trainer.py:216][0m Mean reward: -1030.0848639438404
[32m[0511 05:31:26 @base_main.py:38][0m --------------- Iteration 40 ---------------
[32m[0511 05:31:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4978 mins
[32m[0511 05:31:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 05:31:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 05:31:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:26 @base_main.py:47][0m 40200 total steps have happened
[32m[0511 05:31:26 @base_main.py:52][0m [avg_reward]: -1030.0848639438404
[32m[0511 05:31:26 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:26 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:26 @base_trainer.py:216][0m Mean reward: -1290.5739024133286
[32m[0511 05:31:27 @base_main.py:38][0m --------------- Iteration 41 ---------------
[32m[0511 05:31:27 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5107 mins
[32m[0511 05:31:27 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 05:31:27 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 05:31:27 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:27 @base_main.py:47][0m 41205 total steps have happened
[32m[0511 05:31:27 @base_main.py:52][0m [avg_reward]: -1290.5739024133286
[32m[0511 05:31:27 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:27 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:27 @base_trainer.py:216][0m Mean reward: -1161.8944577972557
[32m[0511 05:31:28 @base_main.py:38][0m --------------- Iteration 42 ---------------
[32m[0511 05:31:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5229 mins
[32m[0511 05:31:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 05:31:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 05:31:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:28 @base_main.py:47][0m 42210 total steps have happened
[32m[0511 05:31:28 @base_main.py:52][0m [avg_reward]: -1161.8944577972557
[32m[0511 05:31:28 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:28 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:28 @base_trainer.py:216][0m Mean reward: -1248.1113380443728
[32m[0511 05:31:28 @base_main.py:38][0m --------------- Iteration 43 ---------------
[32m[0511 05:31:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5357 mins
[32m[0511 05:31:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 05:31:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 05:31:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:28 @base_main.py:47][0m 43215 total steps have happened
[32m[0511 05:31:28 @base_main.py:52][0m [avg_reward]: -1248.1113380443728
[32m[0511 05:31:29 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:29 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:29 @base_trainer.py:216][0m Mean reward: -1159.2629872554514
[32m[0511 05:31:29 @base_main.py:38][0m --------------- Iteration 44 ---------------
[32m[0511 05:31:29 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5483 mins
[32m[0511 05:31:29 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 05:31:29 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 05:31:29 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:29 @base_main.py:47][0m 44220 total steps have happened
[32m[0511 05:31:29 @base_main.py:52][0m [avg_reward]: -1159.2629872554514
[32m[0511 05:31:29 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:29 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:29 @base_trainer.py:216][0m Mean reward: -1255.1657177577758
[32m[0511 05:31:30 @base_main.py:38][0m --------------- Iteration 45 ---------------
[32m[0511 05:31:30 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5611 mins
[32m[0511 05:31:30 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 05:31:30 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0511 05:31:30 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:30 @base_main.py:47][0m 45225 total steps have happened
[32m[0511 05:31:30 @base_main.py:52][0m [avg_reward]: -1255.1657177577758
[32m[0511 05:31:30 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:30 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:30 @base_trainer.py:216][0m Mean reward: -1287.0877762821347
[32m[0511 05:31:31 @base_main.py:38][0m --------------- Iteration 46 ---------------
[32m[0511 05:31:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5728 mins
[32m[0511 05:31:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 05:31:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 05:31:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:31 @base_main.py:47][0m 46230 total steps have happened
[32m[0511 05:31:31 @base_main.py:52][0m [avg_reward]: -1287.0877762821347
[32m[0511 05:31:31 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:31 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:31 @base_trainer.py:216][0m Mean reward: -1042.4780398501312
[32m[0511 05:31:31 @base_main.py:38][0m --------------- Iteration 47 ---------------
[32m[0511 05:31:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5855 mins
[32m[0511 05:31:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 05:31:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 05:31:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:31 @base_main.py:47][0m 47235 total steps have happened
[32m[0511 05:31:31 @base_main.py:52][0m [avg_reward]: -1042.4780398501312
[32m[0511 05:31:32 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:32 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:32 @base_trainer.py:216][0m Mean reward: -1228.2421558482265
[32m[0511 05:31:32 @base_main.py:38][0m --------------- Iteration 48 ---------------
[32m[0511 05:31:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5981 mins
[32m[0511 05:31:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 05:31:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 05:31:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:32 @base_main.py:47][0m 48240 total steps have happened
[32m[0511 05:31:32 @base_main.py:52][0m [avg_reward]: -1228.2421558482265
[32m[0511 05:31:32 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:32 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:32 @base_trainer.py:216][0m Mean reward: -1204.7948314987818
[32m[0511 05:31:33 @base_main.py:38][0m --------------- Iteration 49 ---------------
[32m[0511 05:31:33 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6107 mins
[32m[0511 05:31:33 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 05:31:33 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 05:31:33 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:33 @base_main.py:47][0m 49245 total steps have happened
[32m[0511 05:31:33 @base_main.py:52][0m [avg_reward]: -1204.7948314987818
[32m[0511 05:31:33 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:33 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:33 @base_trainer.py:216][0m Mean reward: -1008.1962581917302
[32m[0511 05:31:34 @base_main.py:38][0m --------------- Iteration 50 ---------------
[32m[0511 05:31:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6231 mins
[32m[0511 05:31:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 05:31:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 05:31:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:34 @base_main.py:47][0m 50250 total steps have happened
[32m[0511 05:31:34 @base_main.py:52][0m [avg_reward]: -1008.1962581917302
[32m[0511 05:31:34 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:34 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:34 @base_trainer.py:216][0m Mean reward: -1114.5368368260986
[32m[0511 05:31:34 @base_main.py:38][0m --------------- Iteration 51 ---------------
[32m[0511 05:31:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6356 mins
[32m[0511 05:31:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 05:31:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 05:31:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:34 @base_main.py:47][0m 51255 total steps have happened
[32m[0511 05:31:34 @base_main.py:52][0m [avg_reward]: -1114.5368368260986
[32m[0511 05:31:35 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:35 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:35 @base_trainer.py:216][0m Mean reward: -1092.662782396726
[32m[0511 05:31:35 @base_main.py:38][0m --------------- Iteration 52 ---------------
[32m[0511 05:31:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6486 mins
[32m[0511 05:31:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 05:31:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 05:31:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:35 @base_main.py:47][0m 52260 total steps have happened
[32m[0511 05:31:35 @base_main.py:52][0m [avg_reward]: -1092.662782396726
[32m[0511 05:31:35 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:35 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:35 @base_trainer.py:216][0m Mean reward: -930.2683206571643
[32m[0511 05:31:36 @base_main.py:38][0m --------------- Iteration 53 ---------------
[32m[0511 05:31:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6615 mins
[32m[0511 05:31:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 05:31:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 05:31:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:36 @base_main.py:47][0m 53265 total steps have happened
[32m[0511 05:31:36 @base_main.py:52][0m [avg_reward]: -930.2683206571643
[32m[0511 05:31:36 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:36 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:36 @base_trainer.py:216][0m Mean reward: -1144.3615917417278
[32m[0511 05:31:37 @base_main.py:38][0m --------------- Iteration 54 ---------------
[32m[0511 05:31:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6742 mins
[32m[0511 05:31:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0018 mins
[32m[0511 05:31:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 05:31:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:37 @base_main.py:47][0m 54270 total steps have happened
[32m[0511 05:31:37 @base_main.py:52][0m [avg_reward]: -1144.3615917417278
[32m[0511 05:31:37 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:37 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:37 @base_trainer.py:216][0m Mean reward: -1091.7885098444667
[32m[0511 05:31:37 @base_main.py:38][0m --------------- Iteration 55 ---------------
[32m[0511 05:31:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6863 mins
[32m[0511 05:31:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 05:31:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 05:31:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:37 @base_main.py:47][0m 55275 total steps have happened
[32m[0511 05:31:37 @base_main.py:52][0m [avg_reward]: -1091.7885098444667
[32m[0511 05:31:38 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:38 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:38 @base_trainer.py:216][0m Mean reward: -1019.3280843004937
[32m[0511 05:31:38 @base_main.py:38][0m --------------- Iteration 56 ---------------
[32m[0511 05:31:38 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6988 mins
[32m[0511 05:31:38 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 05:31:38 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 05:31:38 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:38 @base_main.py:47][0m 56280 total steps have happened
[32m[0511 05:31:38 @base_main.py:52][0m [avg_reward]: -1019.3280843004937
[32m[0511 05:31:38 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:38 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:38 @base_trainer.py:216][0m Mean reward: -1037.1236787712353
[32m[0511 05:31:39 @base_main.py:38][0m --------------- Iteration 57 ---------------
[32m[0511 05:31:39 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7113 mins
[32m[0511 05:31:39 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 05:31:39 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 05:31:39 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:39 @base_main.py:47][0m 57285 total steps have happened
[32m[0511 05:31:39 @base_main.py:52][0m [avg_reward]: -1037.1236787712353
[32m[0511 05:31:39 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:39 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:39 @base_trainer.py:216][0m Mean reward: -1171.590111498481
[32m[0511 05:31:40 @base_main.py:38][0m --------------- Iteration 58 ---------------
[32m[0511 05:31:40 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7240 mins
[32m[0511 05:31:40 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 05:31:40 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 05:31:40 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:40 @base_main.py:47][0m 58290 total steps have happened
[32m[0511 05:31:40 @base_main.py:52][0m [avg_reward]: -1171.590111498481
[32m[0511 05:31:40 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:40 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:40 @base_trainer.py:216][0m Mean reward: -1229.5252242609797
[32m[0511 05:31:41 @base_main.py:38][0m --------------- Iteration 59 ---------------
[32m[0511 05:31:41 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7367 mins
[32m[0511 05:31:41 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 05:31:41 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0107 mins
[32m[0511 05:31:41 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:41 @base_main.py:47][0m 59295 total steps have happened
[32m[0511 05:31:41 @base_main.py:52][0m [avg_reward]: -1229.5252242609797
[32m[0511 05:31:41 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:41 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:41 @base_trainer.py:216][0m Mean reward: -1197.755791360448
[32m[0511 05:31:41 @base_main.py:38][0m --------------- Iteration 60 ---------------
[32m[0511 05:31:41 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7501 mins
[32m[0511 05:31:41 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 05:31:41 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 05:31:41 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:41 @base_main.py:47][0m 60300 total steps have happened
[32m[0511 05:31:41 @base_main.py:52][0m [avg_reward]: -1197.755791360448
[32m[0511 05:31:41 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:41 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:41 @base_trainer.py:216][0m Mean reward: -1039.45429742575
[32m[0511 05:31:42 @base_main.py:38][0m --------------- Iteration 61 ---------------
[32m[0511 05:31:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7627 mins
[32m[0511 05:31:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 05:31:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 05:31:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:42 @base_main.py:47][0m 61305 total steps have happened
[32m[0511 05:31:42 @base_main.py:52][0m [avg_reward]: -1039.45429742575
[32m[0511 05:31:42 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:42 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:42 @base_trainer.py:216][0m Mean reward: -957.2241962167058
[32m[0511 05:31:43 @base_main.py:38][0m --------------- Iteration 62 ---------------
[32m[0511 05:31:43 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7748 mins
[32m[0511 05:31:43 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 05:31:43 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 05:31:43 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:43 @base_main.py:47][0m 62310 total steps have happened
[32m[0511 05:31:43 @base_main.py:52][0m [avg_reward]: -957.2241962167058
[32m[0511 05:31:43 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:43 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:43 @base_trainer.py:216][0m Mean reward: -1035.9882909867167
[32m[0511 05:31:44 @base_main.py:38][0m --------------- Iteration 63 ---------------
[32m[0511 05:31:44 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7875 mins
[32m[0511 05:31:44 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 05:31:44 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 05:31:44 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:44 @base_main.py:47][0m 63315 total steps have happened
[32m[0511 05:31:44 @base_main.py:52][0m [avg_reward]: -1035.9882909867167
[32m[0511 05:31:44 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:44 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:44 @base_trainer.py:216][0m Mean reward: -1109.0504865971516
[32m[0511 05:31:44 @base_main.py:38][0m --------------- Iteration 64 ---------------
[32m[0511 05:31:44 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7997 mins
[32m[0511 05:31:44 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0018 mins
[32m[0511 05:31:44 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 05:31:44 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:44 @base_main.py:47][0m 64320 total steps have happened
[32m[0511 05:31:44 @base_main.py:52][0m [avg_reward]: -1109.0504865971516
[32m[0511 05:31:44 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:44 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:44 @base_trainer.py:216][0m Mean reward: -1037.4809592296415
[32m[0511 05:31:45 @base_main.py:38][0m --------------- Iteration 65 ---------------
[32m[0511 05:31:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8115 mins
[32m[0511 05:31:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 05:31:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 05:31:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:45 @base_main.py:47][0m 65325 total steps have happened
[32m[0511 05:31:45 @base_main.py:52][0m [avg_reward]: -1037.4809592296415
[32m[0511 05:31:45 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:45 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:45 @base_trainer.py:216][0m Mean reward: -1072.519896977116
[32m[0511 05:31:46 @base_main.py:38][0m --------------- Iteration 66 ---------------
[32m[0511 05:31:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8239 mins
[32m[0511 05:31:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 05:31:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 05:31:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:46 @base_main.py:47][0m 66330 total steps have happened
[32m[0511 05:31:46 @base_main.py:52][0m [avg_reward]: -1072.519896977116
[32m[0511 05:31:46 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:46 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:46 @base_trainer.py:216][0m Mean reward: -1027.9744873234727
[32m[0511 05:31:46 @base_main.py:38][0m --------------- Iteration 67 ---------------
[32m[0511 05:31:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8363 mins
[32m[0511 05:31:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 05:31:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 05:31:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:46 @base_main.py:47][0m 67335 total steps have happened
[32m[0511 05:31:46 @base_main.py:52][0m [avg_reward]: -1027.9744873234727
[32m[0511 05:31:47 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:47 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:47 @base_trainer.py:216][0m Mean reward: -960.4209423434738
[32m[0511 05:31:47 @base_main.py:38][0m --------------- Iteration 68 ---------------
[32m[0511 05:31:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8483 mins
[32m[0511 05:31:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 05:31:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0511 05:31:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:47 @base_main.py:47][0m 68340 total steps have happened
[32m[0511 05:31:47 @base_main.py:52][0m [avg_reward]: -960.4209423434738
[32m[0511 05:31:47 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:47 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:47 @base_trainer.py:216][0m Mean reward: -1257.562486501502
[32m[0511 05:31:48 @base_main.py:38][0m --------------- Iteration 69 ---------------
[32m[0511 05:31:48 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8600 mins
[32m[0511 05:31:48 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 05:31:48 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 05:31:48 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:48 @base_main.py:47][0m 69345 total steps have happened
[32m[0511 05:31:48 @base_main.py:52][0m [avg_reward]: -1257.562486501502
[32m[0511 05:31:48 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:48 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:48 @base_trainer.py:216][0m Mean reward: -997.1005627394636
[32m[0511 05:31:49 @base_main.py:38][0m --------------- Iteration 70 ---------------
[32m[0511 05:31:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8725 mins
[32m[0511 05:31:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 05:31:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 05:31:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:49 @base_main.py:47][0m 70350 total steps have happened
[32m[0511 05:31:49 @base_main.py:52][0m [avg_reward]: -997.1005627394636
[32m[0511 05:31:49 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:49 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:49 @base_trainer.py:216][0m Mean reward: -1136.7618334212116
[32m[0511 05:31:49 @base_main.py:38][0m --------------- Iteration 71 ---------------
[32m[0511 05:31:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8851 mins
[32m[0511 05:31:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 05:31:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 05:31:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:49 @base_main.py:47][0m 71355 total steps have happened
[32m[0511 05:31:49 @base_main.py:52][0m [avg_reward]: -1136.7618334212116
[32m[0511 05:31:50 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:50 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:50 @base_trainer.py:216][0m Mean reward: -1222.0786528355013
[32m[0511 05:31:50 @base_main.py:38][0m --------------- Iteration 72 ---------------
[32m[0511 05:31:50 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8971 mins
[32m[0511 05:31:50 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 05:31:50 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 05:31:50 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:50 @base_main.py:47][0m 72360 total steps have happened
[32m[0511 05:31:50 @base_main.py:52][0m [avg_reward]: -1222.0786528355013
[32m[0511 05:31:50 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:50 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:50 @base_trainer.py:216][0m Mean reward: -1082.6269132273862
[32m[0511 05:31:51 @base_main.py:38][0m --------------- Iteration 73 ---------------
[32m[0511 05:31:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9100 mins
[32m[0511 05:31:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 05:31:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 05:31:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:51 @base_main.py:47][0m 73365 total steps have happened
[32m[0511 05:31:51 @base_main.py:52][0m [avg_reward]: -1082.6269132273862
[32m[0511 05:31:51 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:51 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:51 @base_trainer.py:216][0m Mean reward: -1019.6838543170816
[32m[0511 05:31:52 @base_main.py:38][0m --------------- Iteration 74 ---------------
[32m[0511 05:31:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9227 mins
[32m[0511 05:31:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 05:31:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 05:31:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:52 @base_main.py:47][0m 74370 total steps have happened
[32m[0511 05:31:52 @base_main.py:52][0m [avg_reward]: -1019.6838543170816
[32m[0511 05:31:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:52 @base_trainer.py:216][0m Mean reward: -1168.272126885119
[32m[0511 05:31:52 @base_main.py:38][0m --------------- Iteration 75 ---------------
[32m[0511 05:31:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9350 mins
[32m[0511 05:31:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 05:31:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 05:31:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:52 @base_main.py:47][0m 75375 total steps have happened
[32m[0511 05:31:52 @base_main.py:52][0m [avg_reward]: -1168.272126885119
[32m[0511 05:31:53 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:53 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:53 @base_trainer.py:216][0m Mean reward: -1279.5160488592317
[32m[0511 05:31:53 @base_main.py:38][0m --------------- Iteration 76 ---------------
[32m[0511 05:31:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9475 mins
[32m[0511 05:31:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 05:31:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 05:31:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:53 @base_main.py:47][0m 76380 total steps have happened
[32m[0511 05:31:53 @base_main.py:52][0m [avg_reward]: -1279.5160488592317
[32m[0511 05:31:53 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:53 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:53 @base_trainer.py:216][0m Mean reward: -1048.0818724840212
[32m[0511 05:31:54 @base_main.py:38][0m --------------- Iteration 77 ---------------
[32m[0511 05:31:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9600 mins
[32m[0511 05:31:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 05:31:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 05:31:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:54 @base_main.py:47][0m 77385 total steps have happened
[32m[0511 05:31:54 @base_main.py:52][0m [avg_reward]: -1048.0818724840212
[32m[0511 05:31:54 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:54 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:54 @base_trainer.py:216][0m Mean reward: -1025.478694625716
[32m[0511 05:31:55 @base_main.py:38][0m --------------- Iteration 78 ---------------
[32m[0511 05:31:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9726 mins
[32m[0511 05:31:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 05:31:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 05:31:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:55 @base_main.py:47][0m 78390 total steps have happened
[32m[0511 05:31:55 @base_main.py:52][0m [avg_reward]: -1025.478694625716
[32m[0511 05:31:55 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:55 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:55 @base_trainer.py:216][0m Mean reward: -1240.1315398444294
[32m[0511 05:31:55 @base_main.py:38][0m --------------- Iteration 79 ---------------
[32m[0511 05:31:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9845 mins
[32m[0511 05:31:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 05:31:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 05:31:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:55 @base_main.py:47][0m 79395 total steps have happened
[32m[0511 05:31:55 @base_main.py:52][0m [avg_reward]: -1240.1315398444294
[32m[0511 05:31:56 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:56 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:56 @base_trainer.py:216][0m Mean reward: -962.8485296210345
[32m[0511 05:31:56 @base_main.py:38][0m --------------- Iteration 80 ---------------
[32m[0511 05:31:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9973 mins
[32m[0511 05:31:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 05:31:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 05:31:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:56 @base_main.py:47][0m 80400 total steps have happened
[32m[0511 05:31:56 @base_main.py:52][0m [avg_reward]: -962.8485296210345
[32m[0511 05:31:56 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:56 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:56 @base_trainer.py:216][0m Mean reward: -1030.1466829837295
[32m[0511 05:31:57 @base_main.py:38][0m --------------- Iteration 81 ---------------
[32m[0511 05:31:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0096 mins
[32m[0511 05:31:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 05:31:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 05:31:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:57 @base_main.py:47][0m 81405 total steps have happened
[32m[0511 05:31:57 @base_main.py:52][0m [avg_reward]: -1030.1466829837295
[32m[0511 05:31:57 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:57 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:57 @base_trainer.py:216][0m Mean reward: -1247.4218362820193
[32m[0511 05:31:58 @base_main.py:38][0m --------------- Iteration 82 ---------------
[32m[0511 05:31:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0221 mins
[32m[0511 05:31:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 05:31:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 05:31:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:58 @base_main.py:47][0m 82410 total steps have happened
[32m[0511 05:31:58 @base_main.py:52][0m [avg_reward]: -1247.4218362820193
[32m[0511 05:31:58 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:58 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:58 @base_trainer.py:216][0m Mean reward: -993.5315897087654
[32m[0511 05:31:58 @base_main.py:38][0m --------------- Iteration 83 ---------------
[32m[0511 05:31:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0343 mins
[32m[0511 05:31:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 05:31:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0511 05:31:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:58 @base_main.py:47][0m 83415 total steps have happened
[32m[0511 05:31:58 @base_main.py:52][0m [avg_reward]: -993.5315897087654
[32m[0511 05:31:58 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:58 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:58 @base_trainer.py:216][0m Mean reward: -1349.5882223345463
[32m[0511 05:31:59 @base_main.py:38][0m --------------- Iteration 84 ---------------
[32m[0511 05:31:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0462 mins
[32m[0511 05:31:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 05:31:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 05:31:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:31:59 @base_main.py:47][0m 84420 total steps have happened
[32m[0511 05:31:59 @base_main.py:52][0m [avg_reward]: -1349.5882223345463
[32m[0511 05:31:59 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:31:59 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:31:59 @base_trainer.py:216][0m Mean reward: -942.8595449676689
[32m[0511 05:32:00 @base_main.py:38][0m --------------- Iteration 85 ---------------
[32m[0511 05:32:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0590 mins
[32m[0511 05:32:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 05:32:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 05:32:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:00 @base_main.py:47][0m 85425 total steps have happened
[32m[0511 05:32:00 @base_main.py:52][0m [avg_reward]: -942.8595449676689
[32m[0511 05:32:00 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:00 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:00 @base_trainer.py:216][0m Mean reward: -1150.7731531269349
[32m[0511 05:32:01 @base_main.py:38][0m --------------- Iteration 86 ---------------
[32m[0511 05:32:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0713 mins
[32m[0511 05:32:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 05:32:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 05:32:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:01 @base_main.py:47][0m 86430 total steps have happened
[32m[0511 05:32:01 @base_main.py:52][0m [avg_reward]: -1150.7731531269349
[32m[0511 05:32:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:01 @base_trainer.py:216][0m Mean reward: -897.7463717708127
[32m[0511 05:32:01 @base_main.py:38][0m --------------- Iteration 87 ---------------
[32m[0511 05:32:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0840 mins
[32m[0511 05:32:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 05:32:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 05:32:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:01 @base_main.py:47][0m 87435 total steps have happened
[32m[0511 05:32:01 @base_main.py:52][0m [avg_reward]: -897.7463717708127
[32m[0511 05:32:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:01 @base_trainer.py:216][0m Mean reward: -942.7200136492417
[32m[0511 05:32:02 @base_main.py:38][0m --------------- Iteration 88 ---------------
[32m[0511 05:32:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0967 mins
[32m[0511 05:32:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 05:32:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 05:32:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:02 @base_main.py:47][0m 88440 total steps have happened
[32m[0511 05:32:02 @base_main.py:52][0m [avg_reward]: -942.7200136492417
[32m[0511 05:32:02 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:02 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:02 @base_trainer.py:216][0m Mean reward: -1067.8782599340898
[32m[0511 05:32:03 @base_main.py:38][0m --------------- Iteration 89 ---------------
[32m[0511 05:32:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1091 mins
[32m[0511 05:32:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 05:32:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 05:32:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:03 @base_main.py:47][0m 89445 total steps have happened
[32m[0511 05:32:03 @base_main.py:52][0m [avg_reward]: -1067.8782599340898
[32m[0511 05:32:03 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:03 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:03 @base_trainer.py:216][0m Mean reward: -1205.3856356401388
[32m[0511 05:32:04 @base_main.py:38][0m --------------- Iteration 90 ---------------
[32m[0511 05:32:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1214 mins
[32m[0511 05:32:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 05:32:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0511 05:32:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:04 @base_main.py:47][0m 90450 total steps have happened
[32m[0511 05:32:04 @base_main.py:52][0m [avg_reward]: -1205.3856356401388
[32m[0511 05:32:04 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:04 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:04 @base_trainer.py:216][0m Mean reward: -1162.0239874693548
[32m[0511 05:32:04 @base_main.py:38][0m --------------- Iteration 91 ---------------
[32m[0511 05:32:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1330 mins
[32m[0511 05:32:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 05:32:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 05:32:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:04 @base_main.py:47][0m 91455 total steps have happened
[32m[0511 05:32:04 @base_main.py:52][0m [avg_reward]: -1162.0239874693548
[32m[0511 05:32:04 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:04 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:04 @base_trainer.py:216][0m Mean reward: -1248.1137032425383
[32m[0511 05:32:05 @base_main.py:38][0m --------------- Iteration 92 ---------------
[32m[0511 05:32:05 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1456 mins
[32m[0511 05:32:05 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 05:32:05 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 05:32:05 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:05 @base_main.py:47][0m 92460 total steps have happened
[32m[0511 05:32:05 @base_main.py:52][0m [avg_reward]: -1248.1137032425383
[32m[0511 05:32:05 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:05 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:05 @base_trainer.py:216][0m Mean reward: -979.495171378175
[32m[0511 05:32:06 @base_main.py:38][0m --------------- Iteration 93 ---------------
[32m[0511 05:32:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1580 mins
[32m[0511 05:32:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 05:32:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 05:32:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:06 @base_main.py:47][0m 93465 total steps have happened
[32m[0511 05:32:06 @base_main.py:52][0m [avg_reward]: -979.495171378175
[32m[0511 05:32:06 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:06 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:06 @base_trainer.py:216][0m Mean reward: -1041.5186941690167
[32m[0511 05:32:06 @base_main.py:38][0m --------------- Iteration 94 ---------------
[32m[0511 05:32:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1706 mins
[32m[0511 05:32:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 05:32:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0511 05:32:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:06 @base_main.py:47][0m 94470 total steps have happened
[32m[0511 05:32:06 @base_main.py:52][0m [avg_reward]: -1041.5186941690167
[32m[0511 05:32:07 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:07 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:07 @base_trainer.py:216][0m Mean reward: -983.9437754007573
[32m[0511 05:32:07 @base_main.py:38][0m --------------- Iteration 95 ---------------
[32m[0511 05:32:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1820 mins
[32m[0511 05:32:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 05:32:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 05:32:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:07 @base_main.py:47][0m 95475 total steps have happened
[32m[0511 05:32:07 @base_main.py:52][0m [avg_reward]: -983.9437754007573
[32m[0511 05:32:07 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:07 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:07 @base_trainer.py:216][0m Mean reward: -1213.2219350875125
[32m[0511 05:32:08 @base_main.py:38][0m --------------- Iteration 96 ---------------
[32m[0511 05:32:08 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1948 mins
[32m[0511 05:32:08 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 05:32:08 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 05:32:08 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:08 @base_main.py:47][0m 96480 total steps have happened
[32m[0511 05:32:08 @base_main.py:52][0m [avg_reward]: -1213.2219350875125
[32m[0511 05:32:08 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:08 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:08 @base_trainer.py:216][0m Mean reward: -1246.7209428116466
[32m[0511 05:32:09 @base_main.py:38][0m --------------- Iteration 97 ---------------
[32m[0511 05:32:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2070 mins
[32m[0511 05:32:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 05:32:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 05:32:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:09 @base_main.py:47][0m 97485 total steps have happened
[32m[0511 05:32:09 @base_main.py:52][0m [avg_reward]: -1246.7209428116466
[32m[0511 05:32:09 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:09 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:09 @base_trainer.py:216][0m Mean reward: -1004.4507831849778
[32m[0511 05:32:09 @base_main.py:38][0m --------------- Iteration 98 ---------------
[32m[0511 05:32:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2197 mins
[32m[0511 05:32:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 05:32:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 05:32:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:09 @base_main.py:47][0m 98490 total steps have happened
[32m[0511 05:32:09 @base_main.py:52][0m [avg_reward]: -1004.4507831849778
[32m[0511 05:32:10 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:10 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:10 @base_trainer.py:216][0m Mean reward: -1086.1399324935585
[32m[0511 05:32:10 @base_main.py:38][0m --------------- Iteration 99 ---------------
[32m[0511 05:32:10 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2324 mins
[32m[0511 05:32:10 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0511 05:32:10 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 05:32:10 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:10 @base_main.py:47][0m 99495 total steps have happened
[32m[0511 05:32:10 @base_main.py:52][0m [avg_reward]: -1086.1399324935585
[32m[0511 05:32:10 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:10 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:10 @base_trainer.py:216][0m Mean reward: -1027.1860684495655
[32m[0511 05:32:11 @base_main.py:38][0m --------------- Iteration 100 ---------------
[32m[0511 05:32:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2456 mins
[32m[0511 05:32:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 05:32:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 05:32:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:11 @base_main.py:47][0m 100500 total steps have happened
[32m[0511 05:32:11 @base_main.py:52][0m [avg_reward]: -1027.1860684495655
[32m[0511 05:32:11 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:11 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:11 @base_trainer.py:216][0m Mean reward: -1220.8895774530415
[32m[0511 05:32:12 @base_main.py:38][0m --------------- Iteration 101 ---------------
[32m[0511 05:32:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2587 mins
[32m[0511 05:32:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 05:32:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 05:32:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:12 @base_main.py:47][0m 101505 total steps have happened
[32m[0511 05:32:12 @base_main.py:52][0m [avg_reward]: -1220.8895774530415
[32m[0511 05:32:12 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:12 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:12 @base_trainer.py:216][0m Mean reward: -1214.8995927928324
[32m[0511 05:32:13 @base_main.py:38][0m --------------- Iteration 102 ---------------
[32m[0511 05:32:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2714 mins
[32m[0511 05:32:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 05:32:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 05:32:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:13 @base_main.py:47][0m 102510 total steps have happened
[32m[0511 05:32:13 @base_main.py:52][0m [avg_reward]: -1214.8995927928324
[32m[0511 05:32:13 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:13 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:13 @base_trainer.py:216][0m Mean reward: -1172.4873772219423
[32m[0511 05:32:13 @base_main.py:38][0m --------------- Iteration 103 ---------------
[32m[0511 05:32:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2837 mins
[32m[0511 05:32:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0018 mins
[32m[0511 05:32:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 05:32:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:13 @base_main.py:47][0m 103515 total steps have happened
[32m[0511 05:32:13 @base_main.py:52][0m [avg_reward]: -1172.4873772219423
[32m[0511 05:32:13 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:13 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:13 @base_trainer.py:216][0m Mean reward: -1036.5060355092871
[32m[0511 05:32:14 @base_main.py:38][0m --------------- Iteration 104 ---------------
[32m[0511 05:32:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2953 mins
[32m[0511 05:32:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 05:32:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 05:32:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:14 @base_main.py:47][0m 104520 total steps have happened
[32m[0511 05:32:14 @base_main.py:52][0m [avg_reward]: -1036.5060355092871
[32m[0511 05:32:14 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:14 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:14 @base_trainer.py:216][0m Mean reward: -1200.3176115527726
[32m[0511 05:32:15 @base_main.py:38][0m --------------- Iteration 105 ---------------
[32m[0511 05:32:15 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3080 mins
[32m[0511 05:32:15 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 05:32:15 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 05:32:15 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:15 @base_main.py:47][0m 105525 total steps have happened
[32m[0511 05:32:15 @base_main.py:52][0m [avg_reward]: -1200.3176115527726
[32m[0511 05:32:15 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:15 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:15 @base_trainer.py:216][0m Mean reward: -1443.2848878548214
[32m[0511 05:32:16 @base_main.py:38][0m --------------- Iteration 106 ---------------
[32m[0511 05:32:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3204 mins
[32m[0511 05:32:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 05:32:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 05:32:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:16 @base_main.py:47][0m 106530 total steps have happened
[32m[0511 05:32:16 @base_main.py:52][0m [avg_reward]: -1443.2848878548214
[32m[0511 05:32:16 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:16 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:16 @base_trainer.py:216][0m Mean reward: -1270.7443689652105
[32m[0511 05:32:16 @base_main.py:38][0m --------------- Iteration 107 ---------------
[32m[0511 05:32:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3326 mins
[32m[0511 05:32:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 05:32:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 05:32:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:16 @base_main.py:47][0m 107535 total steps have happened
[32m[0511 05:32:16 @base_main.py:52][0m [avg_reward]: -1270.7443689652105
[32m[0511 05:32:16 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:16 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:16 @base_trainer.py:216][0m Mean reward: -953.9396308644897
[32m[0511 05:32:17 @base_main.py:38][0m --------------- Iteration 108 ---------------
[32m[0511 05:32:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3451 mins
[32m[0511 05:32:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 05:32:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 05:32:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:17 @base_main.py:47][0m 108540 total steps have happened
[32m[0511 05:32:17 @base_main.py:52][0m [avg_reward]: -953.9396308644897
[32m[0511 05:32:17 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:17 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:17 @base_trainer.py:216][0m Mean reward: -1125.2856521012834
[32m[0511 05:32:18 @base_main.py:38][0m --------------- Iteration 109 ---------------
[32m[0511 05:32:18 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3580 mins
[32m[0511 05:32:18 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 05:32:18 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 05:32:18 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:18 @base_main.py:47][0m 109545 total steps have happened
[32m[0511 05:32:18 @base_main.py:52][0m [avg_reward]: -1125.2856521012834
[32m[0511 05:32:18 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:18 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:18 @base_trainer.py:216][0m Mean reward: -1024.92697782428
[32m[0511 05:32:19 @base_main.py:38][0m --------------- Iteration 110 ---------------
[32m[0511 05:32:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3702 mins
[32m[0511 05:32:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 05:32:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 05:32:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:19 @base_main.py:47][0m 110550 total steps have happened
[32m[0511 05:32:19 @base_main.py:52][0m [avg_reward]: -1024.92697782428
[32m[0511 05:32:19 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:19 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:19 @base_trainer.py:216][0m Mean reward: -1247.2300653800862
[32m[0511 05:32:19 @base_main.py:38][0m --------------- Iteration 111 ---------------
[32m[0511 05:32:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3830 mins
[32m[0511 05:32:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 05:32:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 05:32:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:19 @base_main.py:47][0m 111555 total steps have happened
[32m[0511 05:32:19 @base_main.py:52][0m [avg_reward]: -1247.2300653800862
[32m[0511 05:32:19 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:19 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:19 @base_trainer.py:216][0m Mean reward: -1296.437820960278
[32m[0511 05:32:20 @base_main.py:38][0m --------------- Iteration 112 ---------------
[32m[0511 05:32:20 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3950 mins
[32m[0511 05:32:20 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 05:32:20 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 05:32:20 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:20 @base_main.py:47][0m 112560 total steps have happened
[32m[0511 05:32:20 @base_main.py:52][0m [avg_reward]: -1296.437820960278
[32m[0511 05:32:20 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:20 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:20 @base_trainer.py:216][0m Mean reward: -964.8452352128297
[32m[0511 05:32:21 @base_main.py:38][0m --------------- Iteration 113 ---------------
[32m[0511 05:32:21 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4076 mins
[32m[0511 05:32:21 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 05:32:21 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 05:32:21 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:21 @base_main.py:47][0m 113565 total steps have happened
[32m[0511 05:32:21 @base_main.py:52][0m [avg_reward]: -964.8452352128297
[32m[0511 05:32:21 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:21 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:21 @base_trainer.py:216][0m Mean reward: -1031.1557417988681
[32m[0511 05:32:21 @base_main.py:38][0m --------------- Iteration 114 ---------------
[32m[0511 05:32:21 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4203 mins
[32m[0511 05:32:21 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 05:32:21 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 05:32:21 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:21 @base_main.py:47][0m 114570 total steps have happened
[32m[0511 05:32:21 @base_main.py:52][0m [avg_reward]: -1031.1557417988681
[32m[0511 05:32:22 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:22 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:22 @base_trainer.py:216][0m Mean reward: -1128.5634732072124
[32m[0511 05:32:22 @base_main.py:38][0m --------------- Iteration 115 ---------------
[32m[0511 05:32:22 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4325 mins
[32m[0511 05:32:22 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 05:32:22 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 05:32:22 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:22 @base_main.py:47][0m 115575 total steps have happened
[32m[0511 05:32:22 @base_main.py:52][0m [avg_reward]: -1128.5634732072124
[32m[0511 05:32:22 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:22 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:22 @base_trainer.py:216][0m Mean reward: -1325.3204861169368
[32m[0511 05:32:23 @base_main.py:38][0m --------------- Iteration 116 ---------------
[32m[0511 05:32:23 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4451 mins
[32m[0511 05:32:23 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 05:32:23 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0511 05:32:23 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:23 @base_main.py:47][0m 116580 total steps have happened
[32m[0511 05:32:23 @base_main.py:52][0m [avg_reward]: -1325.3204861169368
[32m[0511 05:32:23 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:23 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:23 @base_trainer.py:216][0m Mean reward: -1424.4884693053632
[32m[0511 05:32:24 @base_main.py:38][0m --------------- Iteration 117 ---------------
[32m[0511 05:32:24 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4570 mins
[32m[0511 05:32:24 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 05:32:24 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 05:32:24 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:24 @base_main.py:47][0m 117585 total steps have happened
[32m[0511 05:32:24 @base_main.py:52][0m [avg_reward]: -1424.4884693053632
[32m[0511 05:32:24 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:24 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:24 @base_trainer.py:216][0m Mean reward: -1190.3979931268227
[32m[0511 05:32:24 @base_main.py:38][0m --------------- Iteration 118 ---------------
[32m[0511 05:32:24 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4694 mins
[32m[0511 05:32:24 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 05:32:24 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 05:32:24 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:24 @base_main.py:47][0m 118590 total steps have happened
[32m[0511 05:32:24 @base_main.py:52][0m [avg_reward]: -1190.3979931268227
[32m[0511 05:32:25 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:25 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:25 @base_trainer.py:216][0m Mean reward: -1082.142179406581
[32m[0511 05:32:25 @base_main.py:38][0m --------------- Iteration 119 ---------------
[32m[0511 05:32:25 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4817 mins
[32m[0511 05:32:25 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0018 mins
[32m[0511 05:32:25 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 05:32:25 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:25 @base_main.py:47][0m 119595 total steps have happened
[32m[0511 05:32:25 @base_main.py:52][0m [avg_reward]: -1082.142179406581
[32m[0511 05:32:25 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:25 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:25 @base_trainer.py:216][0m Mean reward: -1048.8886898830183
[32m[0511 05:32:26 @base_main.py:38][0m --------------- Iteration 120 ---------------
[32m[0511 05:32:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4932 mins
[32m[0511 05:32:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0018 mins
[32m[0511 05:32:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 05:32:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:26 @base_main.py:47][0m 120600 total steps have happened
[32m[0511 05:32:26 @base_main.py:52][0m [avg_reward]: -1048.8886898830183
[32m[0511 05:32:26 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:26 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:26 @base_trainer.py:216][0m Mean reward: -1268.838163326869
[32m[0511 05:32:27 @base_main.py:38][0m --------------- Iteration 121 ---------------
[32m[0511 05:32:27 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5048 mins
[32m[0511 05:32:27 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 05:32:27 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 05:32:27 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:27 @base_main.py:47][0m 121605 total steps have happened
[32m[0511 05:32:27 @base_main.py:52][0m [avg_reward]: -1268.838163326869
[32m[0511 05:32:27 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:27 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:27 @base_trainer.py:216][0m Mean reward: -1101.186010829861
[32m[0511 05:32:27 @base_main.py:38][0m --------------- Iteration 122 ---------------
[32m[0511 05:32:27 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5175 mins
[32m[0511 05:32:27 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 05:32:27 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 05:32:27 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:27 @base_main.py:47][0m 122610 total steps have happened
[32m[0511 05:32:27 @base_main.py:52][0m [avg_reward]: -1101.186010829861
[32m[0511 05:32:27 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:27 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:27 @base_trainer.py:216][0m Mean reward: -1016.6082377249692
[32m[0511 05:32:28 @base_main.py:38][0m --------------- Iteration 123 ---------------
[32m[0511 05:32:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5295 mins
[32m[0511 05:32:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 05:32:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 05:32:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:28 @base_main.py:47][0m 123615 total steps have happened
[32m[0511 05:32:28 @base_main.py:52][0m [avg_reward]: -1016.6082377249692
[32m[0511 05:32:28 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:28 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:28 @base_trainer.py:216][0m Mean reward: -1152.2873653718511
[32m[0511 05:32:29 @base_main.py:38][0m --------------- Iteration 124 ---------------
[32m[0511 05:32:29 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5425 mins
[32m[0511 05:32:29 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 05:32:29 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 05:32:29 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:29 @base_main.py:47][0m 124620 total steps have happened
[32m[0511 05:32:29 @base_main.py:52][0m [avg_reward]: -1152.2873653718511
[32m[0511 05:32:29 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:29 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:29 @base_trainer.py:216][0m Mean reward: -1217.3867972071516
[32m[0511 05:32:30 @base_main.py:38][0m --------------- Iteration 125 ---------------
[32m[0511 05:32:30 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5556 mins
[32m[0511 05:32:30 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 05:32:30 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 05:32:30 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:30 @base_main.py:47][0m 125625 total steps have happened
[32m[0511 05:32:30 @base_main.py:52][0m [avg_reward]: -1217.3867972071516
[32m[0511 05:32:30 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:30 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:30 @base_trainer.py:216][0m Mean reward: -985.5366690111589
[32m[0511 05:32:30 @base_main.py:38][0m --------------- Iteration 126 ---------------
[32m[0511 05:32:30 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5680 mins
[32m[0511 05:32:30 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 05:32:30 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 05:32:30 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:30 @base_main.py:47][0m 126630 total steps have happened
[32m[0511 05:32:30 @base_main.py:52][0m [avg_reward]: -985.5366690111589
[32m[0511 05:32:31 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:31 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:31 @base_trainer.py:216][0m Mean reward: -865.602413359143
[32m[0511 05:32:31 @base_main.py:38][0m --------------- Iteration 127 ---------------
[32m[0511 05:32:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5802 mins
[32m[0511 05:32:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 05:32:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 05:32:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:31 @base_main.py:47][0m 127635 total steps have happened
[32m[0511 05:32:31 @base_main.py:52][0m [avg_reward]: -865.602413359143
[32m[0511 05:32:31 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:31 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:31 @base_trainer.py:216][0m Mean reward: -1100.0045667046782
[32m[0511 05:32:32 @base_main.py:38][0m --------------- Iteration 128 ---------------
[32m[0511 05:32:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5932 mins
[32m[0511 05:32:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 05:32:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 05:32:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:32 @base_main.py:47][0m 128640 total steps have happened
[32m[0511 05:32:32 @base_main.py:52][0m [avg_reward]: -1100.0045667046782
[32m[0511 05:32:32 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:32 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:32 @base_trainer.py:216][0m Mean reward: -1048.8585104918304
[32m[0511 05:32:33 @base_main.py:38][0m --------------- Iteration 129 ---------------
[32m[0511 05:32:33 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6060 mins
[32m[0511 05:32:33 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 05:32:33 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 05:32:33 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:33 @base_main.py:47][0m 129645 total steps have happened
[32m[0511 05:32:33 @base_main.py:52][0m [avg_reward]: -1048.8585104918304
[32m[0511 05:32:33 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:33 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:33 @base_trainer.py:216][0m Mean reward: -1177.5317113527408
[32m[0511 05:32:33 @base_main.py:38][0m --------------- Iteration 130 ---------------
[32m[0511 05:32:33 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6183 mins
[32m[0511 05:32:33 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 05:32:33 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 05:32:33 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:33 @base_main.py:47][0m 130650 total steps have happened
[32m[0511 05:32:33 @base_main.py:52][0m [avg_reward]: -1177.5317113527408
[32m[0511 05:32:34 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:34 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:34 @base_trainer.py:216][0m Mean reward: -1344.2466283060512
[32m[0511 05:32:34 @base_main.py:38][0m --------------- Iteration 131 ---------------
[32m[0511 05:32:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6306 mins
[32m[0511 05:32:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 05:32:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 05:32:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:34 @base_main.py:47][0m 131655 total steps have happened
[32m[0511 05:32:34 @base_main.py:52][0m [avg_reward]: -1344.2466283060512
[32m[0511 05:32:34 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:34 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:34 @base_trainer.py:216][0m Mean reward: -1029.5384638003331
[32m[0511 05:32:35 @base_main.py:38][0m --------------- Iteration 132 ---------------
[32m[0511 05:32:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6434 mins
[32m[0511 05:32:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 05:32:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 05:32:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:35 @base_main.py:47][0m 132660 total steps have happened
[32m[0511 05:32:35 @base_main.py:52][0m [avg_reward]: -1029.5384638003331
[32m[0511 05:32:35 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:35 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:35 @base_trainer.py:216][0m Mean reward: -1037.6656785729006
[32m[0511 05:32:36 @base_main.py:38][0m --------------- Iteration 133 ---------------
[32m[0511 05:32:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6559 mins
[32m[0511 05:32:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 05:32:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 05:32:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:36 @base_main.py:47][0m 133665 total steps have happened
[32m[0511 05:32:36 @base_main.py:52][0m [avg_reward]: -1037.6656785729006
[32m[0511 05:32:36 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:36 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:36 @base_trainer.py:216][0m Mean reward: -1061.0857058828315
[32m[0511 05:32:36 @base_main.py:38][0m --------------- Iteration 134 ---------------
[32m[0511 05:32:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6686 mins
[32m[0511 05:32:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 05:32:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 05:32:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:36 @base_main.py:47][0m 134670 total steps have happened
[32m[0511 05:32:36 @base_main.py:52][0m [avg_reward]: -1061.0857058828315
[32m[0511 05:32:37 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:37 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:37 @base_trainer.py:216][0m Mean reward: -1056.4830863634559
[32m[0511 05:32:37 @base_main.py:38][0m --------------- Iteration 135 ---------------
[32m[0511 05:32:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6807 mins
[32m[0511 05:32:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 05:32:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 05:32:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:37 @base_main.py:47][0m 135675 total steps have happened
[32m[0511 05:32:37 @base_main.py:52][0m [avg_reward]: -1056.4830863634559
[32m[0511 05:32:37 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:37 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:37 @base_trainer.py:216][0m Mean reward: -932.2737823922832
[32m[0511 05:32:38 @base_main.py:38][0m --------------- Iteration 136 ---------------
[32m[0511 05:32:38 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6936 mins
[32m[0511 05:32:38 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 05:32:38 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 05:32:38 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:38 @base_main.py:47][0m 136680 total steps have happened
[32m[0511 05:32:38 @base_main.py:52][0m [avg_reward]: -932.2737823922832
[32m[0511 05:32:38 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:38 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:38 @base_trainer.py:216][0m Mean reward: -1144.0616696172544
[32m[0511 05:32:39 @base_main.py:38][0m --------------- Iteration 137 ---------------
[32m[0511 05:32:39 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7064 mins
[32m[0511 05:32:39 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 05:32:39 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 05:32:39 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:39 @base_main.py:47][0m 137685 total steps have happened
[32m[0511 05:32:39 @base_main.py:52][0m [avg_reward]: -1144.0616696172544
[32m[0511 05:32:39 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:39 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:39 @base_trainer.py:216][0m Mean reward: -932.1940866510898
[32m[0511 05:32:39 @base_main.py:38][0m --------------- Iteration 138 ---------------
[32m[0511 05:32:39 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7187 mins
[32m[0511 05:32:39 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 05:32:39 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 05:32:39 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0511 05:32:39 @base_main.py:47][0m 138690 total steps have happened
[32m[0511 05:32:39 @base_main.py:52][0m [avg_reward]: -932.1940866510898
[32m[0511 05:32:40 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:40 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:40 @base_trainer.py:216][0m Mean reward: -1090.4541057401725
[32m[0511 05:32:40 @base_main.py:38][0m --------------- Iteration 139 ---------------
[32m[0511 05:32:40 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7310 mins
[32m[0511 05:32:40 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 05:32:40 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 05:32:40 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:40 @base_main.py:47][0m 139695 total steps have happened
[32m[0511 05:32:40 @base_main.py:52][0m [avg_reward]: -1090.4541057401725
[32m[0511 05:32:40 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:40 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:40 @base_trainer.py:216][0m Mean reward: -1153.8669045122683
[32m[0511 05:32:41 @base_main.py:38][0m --------------- Iteration 140 ---------------
[32m[0511 05:32:41 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7431 mins
[32m[0511 05:32:41 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0511 05:32:41 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 05:32:41 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:41 @base_main.py:47][0m 140700 total steps have happened
[32m[0511 05:32:41 @base_main.py:52][0m [avg_reward]: -1153.8669045122683
[32m[0511 05:32:41 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:41 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:41 @base_trainer.py:216][0m Mean reward: -1137.6323317760377
[32m[0511 05:32:42 @base_main.py:38][0m --------------- Iteration 141 ---------------
[32m[0511 05:32:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7563 mins
[32m[0511 05:32:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0511 05:32:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 05:32:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:42 @base_main.py:47][0m 141705 total steps have happened
[32m[0511 05:32:42 @base_main.py:52][0m [avg_reward]: -1137.6323317760377
[32m[0511 05:32:42 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:42 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:42 @base_trainer.py:216][0m Mean reward: -1194.9369712979433
[32m[0511 05:32:42 @base_main.py:38][0m --------------- Iteration 142 ---------------
[32m[0511 05:32:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7687 mins
[32m[0511 05:32:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 05:32:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 05:32:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:42 @base_main.py:47][0m 142710 total steps have happened
[32m[0511 05:32:42 @base_main.py:52][0m [avg_reward]: -1194.9369712979433
[32m[0511 05:32:43 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:43 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:43 @base_trainer.py:216][0m Mean reward: -1125.2949979833213
[32m[0511 05:32:43 @base_main.py:38][0m --------------- Iteration 143 ---------------
[32m[0511 05:32:43 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7807 mins
[32m[0511 05:32:43 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 05:32:43 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 05:32:43 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:43 @base_main.py:47][0m 143715 total steps have happened
[32m[0511 05:32:43 @base_main.py:52][0m [avg_reward]: -1125.2949979833213
[32m[0511 05:32:43 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:43 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:43 @base_trainer.py:216][0m Mean reward: -984.7067896123111
[32m[0511 05:32:44 @base_main.py:38][0m --------------- Iteration 144 ---------------
[32m[0511 05:32:44 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7932 mins
[32m[0511 05:32:44 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 05:32:44 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 05:32:44 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:44 @base_main.py:47][0m 144720 total steps have happened
[32m[0511 05:32:44 @base_main.py:52][0m [avg_reward]: -984.7067896123111
[32m[0511 05:32:44 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:44 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:44 @base_trainer.py:216][0m Mean reward: -1000.6860047663043
[32m[0511 05:32:45 @base_main.py:38][0m --------------- Iteration 145 ---------------
[32m[0511 05:32:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8051 mins
[32m[0511 05:32:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 05:32:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 05:32:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:45 @base_main.py:47][0m 145725 total steps have happened
[32m[0511 05:32:45 @base_main.py:52][0m [avg_reward]: -1000.6860047663043
[32m[0511 05:32:45 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:45 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:45 @base_trainer.py:216][0m Mean reward: -1165.0836376325947
[32m[0511 05:32:45 @base_main.py:38][0m --------------- Iteration 146 ---------------
[32m[0511 05:32:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8174 mins
[32m[0511 05:32:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 05:32:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 05:32:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:45 @base_main.py:47][0m 146730 total steps have happened
[32m[0511 05:32:45 @base_main.py:52][0m [avg_reward]: -1165.0836376325947
[32m[0511 05:32:45 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:45 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:45 @base_trainer.py:216][0m Mean reward: -1228.5671298008565
[32m[0511 05:32:46 @base_main.py:38][0m --------------- Iteration 147 ---------------
[32m[0511 05:32:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8298 mins
[32m[0511 05:32:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0018 mins
[32m[0511 05:32:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 05:32:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:46 @base_main.py:47][0m 147735 total steps have happened
[32m[0511 05:32:46 @base_main.py:52][0m [avg_reward]: -1228.5671298008565
[32m[0511 05:32:46 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:46 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:46 @base_trainer.py:216][0m Mean reward: -1208.210018208354
[32m[0511 05:32:47 @base_main.py:38][0m --------------- Iteration 148 ---------------
[32m[0511 05:32:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8414 mins
[32m[0511 05:32:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 05:32:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 05:32:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:47 @base_main.py:47][0m 148740 total steps have happened
[32m[0511 05:32:47 @base_main.py:52][0m [avg_reward]: -1208.210018208354
[32m[0511 05:32:47 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:47 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:47 @base_trainer.py:216][0m Mean reward: -1069.280046976092
[32m[0511 05:32:47 @base_main.py:38][0m --------------- Iteration 149 ---------------
[32m[0511 05:32:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8536 mins
[32m[0511 05:32:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 05:32:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0511 05:32:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:47 @base_main.py:47][0m 149745 total steps have happened
[32m[0511 05:32:47 @base_main.py:52][0m [avg_reward]: -1069.280046976092
[32m[0511 05:32:48 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:48 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:48 @base_trainer.py:216][0m Mean reward: -986.4056475424101
[32m[0511 05:32:48 @base_main.py:38][0m --------------- Iteration 150 ---------------
[32m[0511 05:32:48 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8654 mins
[32m[0511 05:32:48 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 05:32:48 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 05:32:48 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:48 @base_main.py:47][0m 150750 total steps have happened
[32m[0511 05:32:48 @base_main.py:52][0m [avg_reward]: -986.4056475424101
[32m[0511 05:32:48 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:48 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:48 @base_trainer.py:216][0m Mean reward: -977.2370759818307
[32m[0511 05:32:49 @base_main.py:38][0m --------------- Iteration 151 ---------------
[32m[0511 05:32:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8774 mins
[32m[0511 05:32:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0511 05:32:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 05:32:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:49 @base_main.py:47][0m 151755 total steps have happened
[32m[0511 05:32:49 @base_main.py:52][0m [avg_reward]: -977.2370759818307
[32m[0511 05:32:49 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:49 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:49 @base_trainer.py:216][0m Mean reward: -984.4667844864291
[32m[0511 05:32:50 @base_main.py:38][0m --------------- Iteration 152 ---------------
[32m[0511 05:32:50 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8905 mins
[32m[0511 05:32:50 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 05:32:50 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 05:32:50 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:50 @base_main.py:47][0m 152760 total steps have happened
[32m[0511 05:32:50 @base_main.py:52][0m [avg_reward]: -984.4667844864291
[32m[0511 05:32:50 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:50 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:50 @base_trainer.py:216][0m Mean reward: -926.4356942416874
[32m[0511 05:32:50 @base_main.py:38][0m --------------- Iteration 153 ---------------
[32m[0511 05:32:50 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9025 mins
[32m[0511 05:32:50 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 05:32:50 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 05:32:50 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:50 @base_main.py:47][0m 153765 total steps have happened
[32m[0511 05:32:50 @base_main.py:52][0m [avg_reward]: -926.4356942416874
[32m[0511 05:32:51 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:51 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:51 @base_trainer.py:216][0m Mean reward: -973.2959454497447
[32m[0511 05:32:51 @base_main.py:38][0m --------------- Iteration 154 ---------------
[32m[0511 05:32:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9152 mins
[32m[0511 05:32:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 05:32:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 05:32:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:51 @base_main.py:47][0m 154770 total steps have happened
[32m[0511 05:32:51 @base_main.py:52][0m [avg_reward]: -973.2959454497447
[32m[0511 05:32:51 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:51 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:51 @base_trainer.py:216][0m Mean reward: -1041.9847360272477
[32m[0511 05:32:52 @base_main.py:38][0m --------------- Iteration 155 ---------------
[32m[0511 05:32:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9272 mins
[32m[0511 05:32:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 05:32:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 05:32:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:52 @base_main.py:47][0m 155775 total steps have happened
[32m[0511 05:32:52 @base_main.py:52][0m [avg_reward]: -1041.9847360272477
[32m[0511 05:32:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:52 @base_trainer.py:216][0m Mean reward: -795.452108301805
[32m[0511 05:32:53 @base_main.py:38][0m --------------- Iteration 156 ---------------
[32m[0511 05:32:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9399 mins
[32m[0511 05:32:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 05:32:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 05:32:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:53 @base_main.py:47][0m 156780 total steps have happened
[32m[0511 05:32:53 @base_main.py:52][0m [avg_reward]: -795.452108301805
[32m[0511 05:32:53 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:53 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:53 @base_trainer.py:216][0m Mean reward: -786.4457624886127
[32m[0511 05:32:53 @base_main.py:38][0m --------------- Iteration 157 ---------------
[32m[0511 05:32:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9524 mins
[32m[0511 05:32:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 05:32:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 05:32:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:53 @base_main.py:47][0m 157785 total steps have happened
[32m[0511 05:32:53 @base_main.py:52][0m [avg_reward]: -786.4457624886127
[32m[0511 05:32:54 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:54 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:54 @base_trainer.py:216][0m Mean reward: -1019.6621516335359
[32m[0511 05:32:54 @base_main.py:38][0m --------------- Iteration 158 ---------------
[32m[0511 05:32:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9651 mins
[32m[0511 05:32:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 05:32:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 05:32:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:54 @base_main.py:47][0m 158790 total steps have happened
[32m[0511 05:32:54 @base_main.py:52][0m [avg_reward]: -1019.6621516335359
[32m[0511 05:32:54 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:54 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:54 @base_trainer.py:216][0m Mean reward: -1092.4455552979484
[32m[0511 05:32:55 @base_main.py:38][0m --------------- Iteration 159 ---------------
[32m[0511 05:32:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9772 mins
[32m[0511 05:32:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 05:32:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 05:32:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:55 @base_main.py:47][0m 159795 total steps have happened
[32m[0511 05:32:55 @base_main.py:52][0m [avg_reward]: -1092.4455552979484
[32m[0511 05:32:55 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:55 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:55 @base_trainer.py:216][0m Mean reward: -994.2953822492497
[32m[0511 05:32:56 @base_main.py:38][0m --------------- Iteration 160 ---------------
[32m[0511 05:32:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9893 mins
[32m[0511 05:32:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 05:32:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 05:32:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:56 @base_main.py:47][0m 160800 total steps have happened
[32m[0511 05:32:56 @base_main.py:52][0m [avg_reward]: -994.2953822492497
[32m[0511 05:32:56 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:56 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:56 @base_trainer.py:216][0m Mean reward: -867.8662229958987
[32m[0511 05:32:56 @base_main.py:38][0m --------------- Iteration 161 ---------------
[32m[0511 05:32:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0017 mins
[32m[0511 05:32:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 05:32:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 05:32:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:56 @base_main.py:47][0m 161805 total steps have happened
[32m[0511 05:32:56 @base_main.py:52][0m [avg_reward]: -867.8662229958987
[32m[0511 05:32:57 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:57 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:57 @base_trainer.py:216][0m Mean reward: -1110.818120832753
[32m[0511 05:32:57 @base_main.py:38][0m --------------- Iteration 162 ---------------
[32m[0511 05:32:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0145 mins
[32m[0511 05:32:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 05:32:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0511 05:32:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:57 @base_main.py:47][0m 162810 total steps have happened
[32m[0511 05:32:57 @base_main.py:52][0m [avg_reward]: -1110.818120832753
[32m[0511 05:32:57 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:57 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:57 @base_trainer.py:216][0m Mean reward: -875.1813875369577
[32m[0511 05:32:58 @base_main.py:38][0m --------------- Iteration 163 ---------------
[32m[0511 05:32:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0266 mins
[32m[0511 05:32:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 05:32:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0511 05:32:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:58 @base_main.py:47][0m 163815 total steps have happened
[32m[0511 05:32:58 @base_main.py:52][0m [avg_reward]: -875.1813875369577
[32m[0511 05:32:58 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:58 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:58 @base_trainer.py:216][0m Mean reward: -1014.5435890732344
[32m[0511 05:32:59 @base_main.py:38][0m --------------- Iteration 164 ---------------
[32m[0511 05:32:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0383 mins
[32m[0511 05:32:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 05:32:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 05:32:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0511 05:32:59 @base_main.py:47][0m 164820 total steps have happened
[32m[0511 05:32:59 @base_main.py:52][0m [avg_reward]: -1014.5435890732344
[32m[0511 05:32:59 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:59 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:59 @base_trainer.py:216][0m Mean reward: -894.2286459172531
[32m[0511 05:32:59 @base_main.py:38][0m --------------- Iteration 165 ---------------
[32m[0511 05:32:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0502 mins
[32m[0511 05:32:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 05:32:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 05:32:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:32:59 @base_main.py:47][0m 165825 total steps have happened
[32m[0511 05:32:59 @base_main.py:52][0m [avg_reward]: -894.2286459172531
[32m[0511 05:32:59 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:32:59 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:32:59 @base_trainer.py:216][0m Mean reward: -743.6129191326314
[32m[0511 05:33:00 @base_main.py:38][0m --------------- Iteration 166 ---------------
[32m[0511 05:33:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0627 mins
[32m[0511 05:33:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 05:33:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0107 mins
[32m[0511 05:33:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:33:00 @base_main.py:47][0m 166830 total steps have happened
[32m[0511 05:33:00 @base_main.py:52][0m [avg_reward]: -743.6129191326314
[32m[0511 05:33:00 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:33:00 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:33:00 @base_trainer.py:216][0m Mean reward: -915.9654173903593
[32m[0511 05:33:01 @base_main.py:38][0m --------------- Iteration 167 ---------------
[32m[0511 05:33:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0756 mins
[32m[0511 05:33:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 05:33:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 05:33:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:33:01 @base_main.py:47][0m 167835 total steps have happened
[32m[0511 05:33:01 @base_main.py:52][0m [avg_reward]: -915.9654173903593
[32m[0511 05:33:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:33:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:33:01 @base_trainer.py:216][0m Mean reward: -758.2683142701087
[32m[0511 05:33:02 @base_main.py:38][0m --------------- Iteration 168 ---------------
[32m[0511 05:33:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0883 mins
[32m[0511 05:33:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 05:33:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 05:33:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:33:02 @base_main.py:47][0m 168840 total steps have happened
[32m[0511 05:33:02 @base_main.py:52][0m [avg_reward]: -758.2683142701087
[32m[0511 05:33:02 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:33:02 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:33:02 @base_trainer.py:216][0m Mean reward: -859.6120642225953
[32m[0511 05:33:02 @base_main.py:38][0m --------------- Iteration 169 ---------------
[32m[0511 05:33:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1004 mins
[32m[0511 05:33:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 05:33:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 05:33:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:33:02 @base_main.py:47][0m 169845 total steps have happened
[32m[0511 05:33:02 @base_main.py:52][0m [avg_reward]: -859.6120642225953
[32m[0511 05:33:02 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:33:02 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:33:02 @base_trainer.py:216][0m Mean reward: -921.6361857566128
[32m[0511 05:33:03 @base_main.py:38][0m --------------- Iteration 170 ---------------
[32m[0511 05:33:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1130 mins
[32m[0511 05:33:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 05:33:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 05:33:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:33:03 @base_main.py:47][0m 170850 total steps have happened
[32m[0511 05:33:03 @base_main.py:52][0m [avg_reward]: -921.6361857566128
[32m[0511 05:33:03 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:33:03 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:33:03 @base_trainer.py:216][0m Mean reward: -1142.7955131844137
[32m[0511 05:33:04 @base_main.py:38][0m --------------- Iteration 171 ---------------
[32m[0511 05:33:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1261 mins
[32m[0511 05:33:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 05:33:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0511 05:33:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:33:04 @base_main.py:47][0m 171855 total steps have happened
[32m[0511 05:33:04 @base_main.py:52][0m [avg_reward]: -1142.7955131844137
[32m[0511 05:33:04 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:33:04 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:33:04 @base_trainer.py:216][0m Mean reward: -920.6850666317636
[32m[0511 05:33:05 @base_main.py:38][0m --------------- Iteration 172 ---------------
[32m[0511 05:33:05 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1376 mins
[32m[0511 05:33:05 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 05:33:05 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 05:33:05 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:33:05 @base_main.py:47][0m 172860 total steps have happened
[32m[0511 05:33:05 @base_main.py:52][0m [avg_reward]: -920.6850666317636
[32m[0511 05:33:05 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:33:05 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:33:05 @base_trainer.py:216][0m Mean reward: -645.3058261180402
[32m[0511 05:33:05 @base_main.py:38][0m --------------- Iteration 173 ---------------
[32m[0511 05:33:05 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1504 mins
[32m[0511 05:33:05 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 05:33:05 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 05:33:05 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0511 05:33:05 @base_main.py:47][0m 173865 total steps have happened
[32m[0511 05:33:05 @base_main.py:52][0m [avg_reward]: -645.3058261180402
[32m[0511 05:33:06 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:33:06 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:33:06 @base_trainer.py:216][0m Mean reward: -936.1696826445602
[32m[0511 05:33:06 @base_main.py:38][0m --------------- Iteration 174 ---------------
[32m[0511 05:33:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1635 mins
[32m[0511 05:33:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0511 05:33:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 05:33:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:33:06 @base_main.py:47][0m 174870 total steps have happened
[32m[0511 05:33:06 @base_main.py:52][0m [avg_reward]: -936.1696826445602
[32m[0511 05:33:06 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:33:06 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:33:06 @base_trainer.py:216][0m Mean reward: -879.2284046664363
[32m[0511 05:33:07 @base_main.py:38][0m --------------- Iteration 175 ---------------
[32m[0511 05:33:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1765 mins
[32m[0511 05:33:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 05:33:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 05:33:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:33:07 @base_main.py:47][0m 175875 total steps have happened
[32m[0511 05:33:07 @base_main.py:52][0m [avg_reward]: -879.2284046664363
[32m[0511 05:33:07 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:33:07 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:33:07 @base_trainer.py:216][0m Mean reward: -1027.9157877767539
[32m[0511 05:33:08 @base_main.py:38][0m --------------- Iteration 176 ---------------
[32m[0511 05:33:08 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1894 mins
[32m[0511 05:33:08 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0511 05:33:08 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 05:33:08 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:33:08 @base_main.py:47][0m 176880 total steps have happened
[32m[0511 05:33:08 @base_main.py:52][0m [avg_reward]: -1027.9157877767539
[32m[0511 05:33:08 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:33:08 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:33:08 @base_trainer.py:216][0m Mean reward: -849.8127766687097
[32m[0511 05:33:08 @base_main.py:38][0m --------------- Iteration 177 ---------------
[32m[0511 05:33:08 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2024 mins
[32m[0511 05:33:08 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 05:33:08 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 05:33:08 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:33:08 @base_main.py:47][0m 177885 total steps have happened
[32m[0511 05:33:08 @base_main.py:52][0m [avg_reward]: -849.8127766687097
[32m[0511 05:33:09 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:33:09 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:33:09 @base_trainer.py:216][0m Mean reward: -1018.538510503315
[32m[0511 05:33:09 @base_main.py:38][0m --------------- Iteration 178 ---------------
[32m[0511 05:33:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2152 mins
[32m[0511 05:33:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 05:33:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 05:33:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0511 05:33:09 @base_main.py:47][0m 178890 total steps have happened
[32m[0511 05:33:09 @base_main.py:52][0m [avg_reward]: -1018.538510503315
[32m[0511 05:33:09 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:33:09 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:33:09 @base_trainer.py:216][0m Mean reward: -889.8250668038754
[32m[0511 05:33:10 @base_main.py:38][0m --------------- Iteration 179 ---------------
[32m[0511 05:33:10 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2279 mins
[32m[0511 05:33:10 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 05:33:10 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0511 05:33:10 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:33:10 @base_main.py:47][0m 179895 total steps have happened
[32m[0511 05:33:10 @base_main.py:52][0m [avg_reward]: -889.8250668038754
[32m[0511 05:33:10 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:33:10 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:33:10 @base_trainer.py:216][0m Mean reward: -899.6191141679886
[32m[0511 05:33:11 @base_main.py:38][0m --------------- Iteration 180 ---------------
[32m[0511 05:33:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2401 mins
[32m[0511 05:33:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 05:33:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 05:33:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:33:11 @base_main.py:47][0m 180900 total steps have happened
[32m[0511 05:33:11 @base_main.py:52][0m [avg_reward]: -899.6191141679886
[32m[0511 05:33:11 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:33:11 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:33:11 @base_trainer.py:216][0m Mean reward: -779.3930534031649
[32m[0511 05:33:11 @base_main.py:38][0m --------------- Iteration 181 ---------------
[32m[0511 05:33:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2525 mins
[32m[0511 05:33:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 05:33:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 05:33:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:33:11 @base_main.py:47][0m 181905 total steps have happened
[32m[0511 05:33:11 @base_main.py:52][0m [avg_reward]: -779.3930534031649
[32m[0511 05:33:12 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:33:12 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:33:12 @base_trainer.py:216][0m Mean reward: -687.25106936085
[32m[0511 05:33:12 @base_main.py:38][0m --------------- Iteration 182 ---------------
[32m[0511 05:33:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2654 mins
[32m[0511 05:33:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 05:33:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 05:33:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:33:12 @base_main.py:47][0m 182910 total steps have happened
[32m[0511 05:33:12 @base_main.py:52][0m [avg_reward]: -687.25106936085
[32m[0511 05:33:12 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:33:12 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:33:12 @base_trainer.py:216][0m Mean reward: -841.5006753557836
[32m[0511 05:33:13 @base_main.py:38][0m --------------- Iteration 183 ---------------
[32m[0511 05:33:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2780 mins
[32m[0511 05:33:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 05:33:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 05:33:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:33:13 @base_main.py:47][0m 183915 total steps have happened
[32m[0511 05:33:13 @base_main.py:52][0m [avg_reward]: -841.5006753557836
[32m[0511 05:33:13 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:33:13 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:33:13 @base_trainer.py:216][0m Mean reward: -831.121629062568
[32m[0511 05:33:14 @base_main.py:38][0m --------------- Iteration 184 ---------------
[32m[0511 05:33:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2899 mins
[32m[0511 05:33:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 05:33:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 05:33:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:33:14 @base_main.py:47][0m 184920 total steps have happened
[32m[0511 05:33:14 @base_main.py:52][0m [avg_reward]: -831.121629062568
[32m[0511 05:33:14 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:33:14 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:33:14 @base_trainer.py:216][0m Mean reward: -617.9372629678267
[32m[0511 05:33:14 @base_main.py:38][0m --------------- Iteration 185 ---------------
[32m[0511 05:33:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3021 mins
[32m[0511 05:33:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 05:33:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 05:33:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:33:14 @base_main.py:47][0m 185925 total steps have happened
[32m[0511 05:33:14 @base_main.py:52][0m [avg_reward]: -617.9372629678267
[32m[0511 05:33:15 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:33:15 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:33:15 @base_trainer.py:216][0m Mean reward: -893.5747304164037
[32m[0511 05:33:15 @base_main.py:38][0m --------------- Iteration 186 ---------------
[32m[0511 05:33:15 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3150 mins
[32m[0511 05:33:15 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 05:33:15 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 05:33:15 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:33:15 @base_main.py:47][0m 186930 total steps have happened
[32m[0511 05:33:15 @base_main.py:52][0m [avg_reward]: -893.5747304164037
[32m[0511 05:33:15 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:33:15 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:33:15 @base_trainer.py:216][0m Mean reward: -920.0223936797036
[32m[0511 05:33:16 @base_main.py:38][0m --------------- Iteration 187 ---------------
[32m[0511 05:33:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3277 mins
[32m[0511 05:33:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 05:33:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 05:33:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:33:16 @base_main.py:47][0m 187935 total steps have happened
[32m[0511 05:33:16 @base_main.py:52][0m [avg_reward]: -920.0223936797036
[32m[0511 05:33:16 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:33:16 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:33:16 @base_trainer.py:216][0m Mean reward: -1007.1128181572496
[32m[0511 05:33:17 @base_main.py:38][0m --------------- Iteration 188 ---------------
[32m[0511 05:33:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3400 mins
[32m[0511 05:33:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 05:33:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 05:33:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:33:17 @base_main.py:47][0m 188940 total steps have happened
[32m[0511 05:33:17 @base_main.py:52][0m [avg_reward]: -1007.1128181572496
[32m[0511 05:33:17 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:33:17 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:33:17 @base_trainer.py:216][0m Mean reward: -690.8681994446227
[32m[0511 05:33:17 @base_main.py:38][0m --------------- Iteration 189 ---------------
[32m[0511 05:33:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3526 mins
[32m[0511 05:33:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 05:33:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 05:33:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:33:17 @base_main.py:47][0m 189945 total steps have happened
[32m[0511 05:33:17 @base_main.py:52][0m [avg_reward]: -690.8681994446227
[32m[0511 05:33:18 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:33:18 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:33:18 @base_trainer.py:216][0m Mean reward: -705.3304124676513
[32m[0511 05:33:18 @base_main.py:38][0m --------------- Iteration 190 ---------------
[32m[0511 05:33:18 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3647 mins
[32m[0511 05:33:18 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 05:33:18 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 05:33:18 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:33:18 @base_main.py:47][0m 190950 total steps have happened
[32m[0511 05:33:18 @base_main.py:52][0m [avg_reward]: -705.3304124676513
[32m[0511 05:33:18 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:33:18 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:33:18 @base_trainer.py:216][0m Mean reward: -613.3898448679298
[32m[0511 05:33:19 @base_main.py:38][0m --------------- Iteration 191 ---------------
[32m[0511 05:33:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3771 mins
[32m[0511 05:33:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 05:33:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 05:33:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:33:19 @base_main.py:47][0m 191955 total steps have happened
[32m[0511 05:33:19 @base_main.py:52][0m [avg_reward]: -613.3898448679298
[32m[0511 05:33:19 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:33:19 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:33:19 @base_trainer.py:216][0m Mean reward: -850.522670316111
[32m[0511 05:33:20 @base_main.py:38][0m --------------- Iteration 192 ---------------
[32m[0511 05:33:20 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3893 mins
[32m[0511 05:33:20 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 05:33:20 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 05:33:20 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:33:20 @base_main.py:47][0m 192960 total steps have happened
[32m[0511 05:33:20 @base_main.py:52][0m [avg_reward]: -850.522670316111
[32m[0511 05:33:20 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:33:20 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:33:20 @base_trainer.py:216][0m Mean reward: -996.2734917291634
[32m[0511 05:33:20 @base_main.py:38][0m --------------- Iteration 193 ---------------
[32m[0511 05:33:20 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4016 mins
[32m[0511 05:33:20 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 05:33:20 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 05:33:20 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:33:20 @base_main.py:47][0m 193965 total steps have happened
[32m[0511 05:33:20 @base_main.py:52][0m [avg_reward]: -996.2734917291634
[32m[0511 05:33:21 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:33:21 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:33:21 @base_trainer.py:216][0m Mean reward: -651.9236048232855
[32m[0511 05:33:21 @base_main.py:38][0m --------------- Iteration 194 ---------------
[32m[0511 05:33:21 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4145 mins
[32m[0511 05:33:21 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0511 05:33:21 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 05:33:21 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:33:21 @base_main.py:47][0m 194970 total steps have happened
[32m[0511 05:33:21 @base_main.py:52][0m [avg_reward]: -651.9236048232855
[32m[0511 05:33:21 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:33:21 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:33:21 @base_trainer.py:216][0m Mean reward: -784.2108065666146
[32m[0511 05:33:22 @base_main.py:38][0m --------------- Iteration 195 ---------------
[32m[0511 05:33:22 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4272 mins
[32m[0511 05:33:22 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 05:33:22 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 05:33:22 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:33:22 @base_main.py:47][0m 195975 total steps have happened
[32m[0511 05:33:22 @base_main.py:52][0m [avg_reward]: -784.2108065666146
[32m[0511 05:33:22 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:33:22 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:33:22 @base_trainer.py:216][0m Mean reward: -1151.3932556331147
[32m[0511 05:33:23 @base_main.py:38][0m --------------- Iteration 196 ---------------
[32m[0511 05:33:23 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4397 mins
[32m[0511 05:33:23 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 05:33:23 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 05:33:23 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:33:23 @base_main.py:47][0m 196980 total steps have happened
[32m[0511 05:33:23 @base_main.py:52][0m [avg_reward]: -1151.3932556331147
[32m[0511 05:33:23 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:33:23 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:33:23 @base_trainer.py:216][0m Mean reward: -728.825333182849
[32m[0511 05:33:23 @base_main.py:38][0m --------------- Iteration 197 ---------------
[32m[0511 05:33:23 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4519 mins
[32m[0511 05:33:23 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 05:33:23 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 05:33:23 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:33:23 @base_main.py:47][0m 197985 total steps have happened
[32m[0511 05:33:23 @base_main.py:52][0m [avg_reward]: -728.825333182849
[32m[0511 05:33:24 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:33:24 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:33:24 @base_trainer.py:216][0m Mean reward: -884.5283817309921
[32m[0511 05:33:24 @base_main.py:38][0m --------------- Iteration 198 ---------------
[32m[0511 05:33:24 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4647 mins
[32m[0511 05:33:24 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 05:33:24 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 05:33:24 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:33:24 @base_main.py:47][0m 198990 total steps have happened
[32m[0511 05:33:24 @base_main.py:52][0m [avg_reward]: -884.5283817309921
[32m[0511 05:33:24 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:33:24 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:33:24 @base_trainer.py:216][0m Mean reward: -820.6417847627641
[32m[0511 05:33:25 @base_main.py:38][0m --------------- Iteration 199 ---------------
[32m[0511 05:33:25 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4771 mins
[32m[0511 05:33:25 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 05:33:25 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 05:33:25 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:33:25 @base_main.py:47][0m 199995 total steps have happened
[32m[0511 05:33:25 @base_main.py:52][0m [avg_reward]: -820.6417847627641
[32m[0511 05:33:25 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 05:33:25 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 05:33:25 @base_trainer.py:216][0m Mean reward: -754.1482563415818
[32m[0511 05:33:26 @base_main.py:38][0m --------------- Iteration 200 ---------------
[32m[0511 05:33:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4889 mins
[32m[0511 05:33:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 05:33:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 05:33:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 05:33:26 @base_main.py:47][0m 201000 total steps have happened
[32m[0511 05:33:26 @base_main.py:52][0m [avg_reward]: -754.1482563415818
[32m[0511 05:33:26 @base_worker.py:111][0m kill message for worker 0
[32m[0511 05:33:26 @base_worker.py:111][0m kill message for worker 4
[32m[0511 05:33:26 @base_worker.py:111][0m kill message for worker 5
[32m[0511 05:33:26 @base_worker.py:111][0m kill message for worker 9
[32m[0511 05:33:26 @base_worker.py:111][0m kill message for worker 15
[32m[0511 05:33:26 @base_worker.py:111][0m kill message for worker 6
[32m[0511 05:33:26 @base_worker.py:111][0m kill message for worker 12
[32m[0511 05:33:26 @base_worker.py:111][0m kill message for worker 17
[32m[0511 05:33:26 @base_worker.py:111][0m kill message for worker 2
[32m[0511 05:33:26 @base_worker.py:111][0m kill message for worker 18
[32m[0511 05:33:26 @base_worker.py:111][0m kill message for worker 10
[32m[0511 05:33:26 @base_worker.py:111][0m kill message for worker 19
[32m[0511 05:33:26 @base_worker.py:111][0m kill message for worker 13
[32m[0511 05:33:26 @base_worker.py:111][0m kill message for worker 14
[32m[0511 05:33:26 @base_worker.py:111][0m kill message for worker 16
[32m[0511 05:33:26 @base_worker.py:111][0m kill message for worker 11
[32m[0511 05:33:26 @base_worker.py:111][0m kill message for worker 8
[32m[0511 05:33:26 @base_worker.py:111][0m kill message for worker 1
[32m[0511 05:33:26 @base_worker.py:111][0m kill message for worker 3
[32m[0511 05:33:26 @base_worker.py:111][0m kill message for worker 7
