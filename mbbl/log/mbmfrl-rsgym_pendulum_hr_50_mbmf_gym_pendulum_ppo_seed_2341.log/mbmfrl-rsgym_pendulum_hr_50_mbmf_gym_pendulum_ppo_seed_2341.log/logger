[32m[0514 05:36:07 @logger.py:103][0m Log file set to /root/mbbl/log/mbmfrl-rsgym_pendulum_hr_50_mbmf_gym_pendulum_ppo_seed_2341.log/mbmfrl-rsgym_pendulum_hr_50_mbmf_gym_pendulum_ppo_seed_2341.log
[32m[0514 05:36:08 @mbmf_main.py:23][0m Training starts at /root/mbbl
[32m[0514 05:36:08 @base_worker.py:45][0m Worker 0 online
[32m[0514 05:36:08 @base_worker.py:45][0m Worker 1 online
[32m[0514 05:36:08 @base_worker.py:45][0m Worker 2 online
[32m[0514 05:36:08 @base_worker.py:45][0m Worker 3 online
[32m[0514 05:36:08 @base_worker.py:45][0m Worker 4 online
[32m[0514 05:36:08 @base_worker.py:45][0m Worker 5 online
[32m[0514 05:36:08 @base_worker.py:45][0m Worker 6 online
[32m[0514 05:36:08 @base_worker.py:45][0m Worker 7 online
[32m[0514 05:36:08 @base_worker.py:45][0m Worker 8 online
[32m[0514 05:36:08 @base_worker.py:45][0m Worker 9 online
[32m[0514 05:36:08 @base_worker.py:45][0m Worker 10 online
[32m[0514 05:36:08 @base_worker.py:45][0m Worker 11 online
[32m[0514 05:36:08 @base_worker.py:45][0m Worker 12 online
[32m[0514 05:36:08 @base_worker.py:45][0m Worker 13 online
[32m[0514 05:36:08 @base_worker.py:45][0m Worker 14 online
[32m[0514 05:36:08 @base_worker.py:45][0m Worker 15 online
[32m[0514 05:36:08 @base_worker.py:45][0m Worker 16 online
[32m[0514 05:36:08 @base_worker.py:45][0m Worker 17 online
[32m[0514 05:36:08 @base_worker.py:45][0m Worker 18 online
[32m[0514 05:36:08 @base_worker.py:45][0m Worker 19 online
[32m[0514 05:36:10 @base_trainer.py:152][0m Trainer maintains [1] policy network
[32m[0514 05:36:11 @base_trainer.py:152][0m Trainer maintains [1] dynamics network
[32m[0514 05:36:11 @base_trainer.py:152][0m Trainer maintains [1] reward network
[32m[0514 05:36:12 @mbmf_main.py:46][0m Generating 1000 random timesteps
[32m[0514 05:36:12 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:36:12 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:36:12 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:36:12 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:36:12 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:36:12 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:36:12 @base_trainer.py:216][0m Mean reward: -1369.1784312806792
[32m[0514 05:36:12 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9948763251304626, Train Loss: 0.9402626752853394
[32m[0514 05:36:12 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9948983192443848, Train Loss: 0.9402461647987366
[32m[0514 05:36:12 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9949204325675964, Train Loss: 0.9402298331260681
[32m[0514 05:36:12 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.994942843914032, Train Loss: 0.9402135610580444
[32m[0514 05:36:12 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9949653744697571, Train Loss: 0.9401975274085999
[32m[0514 05:36:12 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9949880838394165, Train Loss: 0.9401817917823792
[32m[0514 05:36:12 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9950107932090759, Train Loss: 0.940166175365448
[32m[0514 05:36:12 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9950337409973145, Train Loss: 0.940150797367096
[32m[0514 05:36:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9950568079948425, Train Loss: 0.940135657787323
[32m[0514 05:36:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9950800538063049, Train Loss: 0.9401205778121948
[32m[0514 05:36:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9951034188270569, Train Loss: 0.9401057958602905
[32m[0514 05:36:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9951268434524536, Train Loss: 0.940091073513031
[32m[0514 05:36:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9951503276824951, Train Loss: 0.9400767683982849
[32m[0514 05:36:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9951739311218262, Train Loss: 0.9400626420974731
[32m[0514 05:36:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9951976537704468, Train Loss: 0.9400485754013062
[32m[0514 05:36:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9952214360237122, Train Loss: 0.940034806728363
[32m[0514 05:36:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9952453374862671, Train Loss: 0.9400212168693542
[32m[0514 05:36:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.995269238948822, Train Loss: 0.9400078654289246
[32m[0514 05:36:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9952932596206665, Train Loss: 0.9399948120117188
[32m[0514 05:36:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.995317280292511, Train Loss: 0.9399818778038025
[32m[0514 05:36:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.995341420173645, Train Loss: 0.9399691820144653
[32m[0514 05:36:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9953655004501343, Train Loss: 0.9399566054344177
[32m[0514 05:36:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9953896999359131, Train Loss: 0.9399444460868835
[32m[0514 05:36:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9954137802124023, Train Loss: 0.9399322271347046
[32m[0514 05:36:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9954379200935364, Train Loss: 0.9399204254150391
[32m[0514 05:36:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9954619407653809, Train Loss: 0.9399086833000183
[32m[0514 05:36:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9954860806465149, Train Loss: 0.939897358417511
[32m[0514 05:36:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9955101609230042, Train Loss: 0.9398859143257141
[32m[0514 05:36:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9955341815948486, Train Loss: 0.9398748278617859
[32m[0514 05:36:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9955582618713379, Train Loss: 0.939863920211792
[32m[0514 05:36:14 @base_main.py:38][0m --------------- Iteration 1 ---------------
[32m[0514 05:36:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0000 mins
[32m[0514 05:36:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0045 mins
[32m[0514 05:36:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0193 mins
[32m[0514 05:36:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0068 mins
[32m[0514 05:36:14 @base_main.py:47][0m 1005 total steps have happened
[32m[0514 05:36:14 @base_main.py:52][0m [avg_reward]: -1369.1784312806792
[32m[0514 05:36:14 @base_main.py:52][0m [update_op]: None
[32m[0514 05:36:14 @base_main.py:52][0m [train_loss]: 0.939863920211792
[32m[0514 05:36:14 @base_main.py:52][0m [val_loss]: 0.9955582618713379
[32m[0514 05:36:14 @base_main.py:52][0m [avg_train_loss]: 0.939863920211792
[32m[0514 05:36:52 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:37:31 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:38:08 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:38:45 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:39:23 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:39:23 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:39:23 @base_trainer.py:216][0m Mean reward: -1177.5331185418606
[32m[0514 05:39:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1802290678024292, Train Loss: 0.8826839923858643
[32m[0514 05:39:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1802425384521484, Train Loss: 0.8826892375946045
[32m[0514 05:39:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1802653074264526, Train Loss: 0.8826819062232971
[32m[0514 05:39:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.180293083190918, Train Loss: 0.8826673626899719
[32m[0514 05:39:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1803240776062012, Train Loss: 0.8826485276222229
[32m[0514 05:39:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1803572177886963, Train Loss: 0.8826276659965515
[32m[0514 05:39:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.180391788482666, Train Loss: 0.8826058506965637
[32m[0514 05:39:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.180427074432373, Train Loss: 0.8825840950012207
[32m[0514 05:39:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1804627180099487, Train Loss: 0.8825628161430359
[32m[0514 05:39:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1804986000061035, Train Loss: 0.882542610168457
[32m[0514 05:39:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1805343627929688, Train Loss: 0.8825232982635498
[32m[0514 05:39:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1805697679519653, Train Loss: 0.8825054168701172
[32m[0514 05:39:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1806049346923828, Train Loss: 0.8824885487556458
[32m[0514 05:39:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1806395053863525, Train Loss: 0.8824731707572937
[32m[0514 05:39:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1806734800338745, Train Loss: 0.8824587464332581
[32m[0514 05:39:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1807067394256592, Train Loss: 0.882445752620697
[32m[0514 05:39:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1807396411895752, Train Loss: 0.8824336528778076
[32m[0514 05:39:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1807714700698853, Train Loss: 0.882422685623169
[32m[0514 05:39:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.180802583694458, Train Loss: 0.8824124932289124
[32m[0514 05:39:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.180832862854004, Train Loss: 0.8824033737182617
[32m[0514 05:39:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1808624267578125, Train Loss: 0.8823948502540588
[32m[0514 05:39:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1808911561965942, Train Loss: 0.8823871612548828
[32m[0514 05:39:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.18091881275177, Train Loss: 0.8823801875114441
[32m[0514 05:39:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.180945873260498, Train Loss: 0.8823738694190979
[32m[0514 05:39:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1809719800949097, Train Loss: 0.8823680281639099
[32m[0514 05:39:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1809971332550049, Train Loss: 0.8823625445365906
[32m[0514 05:39:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1810214519500732, Train Loss: 0.8823577761650085
[32m[0514 05:39:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1810452938079834, Train Loss: 0.8823532462120056
[32m[0514 05:39:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1810680627822876, Train Loss: 0.8823491930961609
[32m[0514 05:39:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.181089997291565, Train Loss: 0.8823453783988953
[32m[0514 05:39:26 @base_main.py:38][0m --------------- Iteration 2 ---------------
[32m[0514 05:39:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0307 mins
[32m[0514 05:39:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 3.1596 mins
[32m[0514 05:39:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0355 mins
[32m[0514 05:39:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0080 mins
[32m[0514 05:39:26 @base_main.py:47][0m 2010 total steps have happened
[32m[0514 05:39:26 @base_main.py:52][0m [avg_reward]: -1177.5331185418606
[32m[0514 05:39:26 @base_main.py:52][0m [update_op]: None
[32m[0514 05:39:26 @base_main.py:52][0m [train_loss]: 0.5849171876907349
[32m[0514 05:39:26 @base_main.py:52][0m [val_loss]: 1.181089997291565
[32m[0514 05:39:26 @base_main.py:52][0m [avg_train_loss]: 0.8823453783988953
[32m[0514 05:40:04 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:40:42 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:41:19 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:41:57 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:42:35 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:42:35 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:42:35 @base_trainer.py:216][0m Mean reward: -1202.7176188018161
[32m[0514 05:42:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1827772855758667, Train Loss: 0.9332315325737
[32m[0514 05:42:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1827960014343262, Train Loss: 0.9332306981086731
[32m[0514 05:42:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1828101873397827, Train Loss: 0.9332295656204224
[32m[0514 05:42:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1828210353851318, Train Loss: 0.9332280158996582
[32m[0514 05:42:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1828299760818481, Train Loss: 0.9332265853881836
[32m[0514 05:42:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1828374862670898, Train Loss: 0.9332252740859985
[32m[0514 05:42:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1828442811965942, Train Loss: 0.9332240223884583
[32m[0514 05:42:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1828498840332031, Train Loss: 0.9332230687141418
[32m[0514 05:42:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.182855486869812, Train Loss: 0.9332221746444702
[32m[0514 05:42:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1828601360321045, Train Loss: 0.9332214593887329
[32m[0514 05:42:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.182864785194397, Train Loss: 0.9332207441329956
[32m[0514 05:42:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1828689575195312, Train Loss: 0.9332202076911926
[32m[0514 05:42:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1828728914260864, Train Loss: 0.9332199096679688
[32m[0514 05:42:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.182876706123352, Train Loss: 0.933219313621521
[32m[0514 05:42:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1828800439834595, Train Loss: 0.9332189559936523
[32m[0514 05:42:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1828835010528564, Train Loss: 0.933218777179718
[32m[0514 05:42:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1828863620758057, Train Loss: 0.9332184791564941
[32m[0514 05:42:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.182889461517334, Train Loss: 0.9332181811332703
[32m[0514 05:42:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1828924417495728, Train Loss: 0.9332181215286255
[32m[0514 05:42:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1828949451446533, Train Loss: 0.9332178235054016
[32m[0514 05:42:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1828973293304443, Train Loss: 0.9332177042961121
[32m[0514 05:42:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1828997135162354, Train Loss: 0.9332175254821777
[32m[0514 05:42:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1829017400741577, Train Loss: 0.9332174062728882
[32m[0514 05:42:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1829040050506592, Train Loss: 0.9332173466682434
[32m[0514 05:42:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1829060316085815, Train Loss: 0.9332171678543091
[32m[0514 05:42:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1829079389572144, Train Loss: 0.9332170486450195
[32m[0514 05:42:38 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1829097270965576, Train Loss: 0.9332170486450195
[32m[0514 05:42:38 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1829115152359009, Train Loss: 0.93321692943573
[32m[0514 05:42:38 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.182913064956665, Train Loss: 0.93321692943573
[32m[0514 05:42:38 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1829146146774292, Train Loss: 0.9332167506217957
[32m[0514 05:42:38 @base_main.py:38][0m --------------- Iteration 3 ---------------
[32m[0514 05:42:38 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 3.2338 mins
[32m[0514 05:42:38 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 3.1505 mins
[32m[0514 05:42:38 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0522 mins
[32m[0514 05:42:38 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0073 mins
[32m[0514 05:42:38 @base_main.py:47][0m 3015 total steps have happened
[32m[0514 05:42:38 @base_main.py:52][0m [avg_reward]: -1202.7176188018161
[32m[0514 05:42:38 @base_main.py:52][0m [update_op]: None
[32m[0514 05:42:38 @base_main.py:52][0m [train_loss]: 1.1640597581863403
[32m[0514 05:42:38 @base_main.py:52][0m [val_loss]: 1.1829146146774292
[32m[0514 05:42:38 @base_main.py:52][0m [avg_train_loss]: 0.9332167506217957
[32m[0514 05:43:16 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:43:54 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:44:31 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:45:09 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:45:47 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:45:47 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:45:47 @base_trainer.py:216][0m Mean reward: -1283.7942545552212
[32m[0514 05:45:47 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9185237884521484, Train Loss: 0.9825876951217651
[32m[0514 05:45:47 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9185047149658203, Train Loss: 0.9825852513313293
[32m[0514 05:45:47 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9184771776199341, Train Loss: 0.9825817346572876
[32m[0514 05:45:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9184474349021912, Train Loss: 0.9825783967971802
[32m[0514 05:45:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9184184670448303, Train Loss: 0.9825753569602966
[32m[0514 05:45:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9183915257453918, Train Loss: 0.9825728535652161
[32m[0514 05:45:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9183672070503235, Train Loss: 0.9825707674026489
[32m[0514 05:45:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9183453917503357, Train Loss: 0.98256915807724
[32m[0514 05:45:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9183259010314941, Train Loss: 0.9825678467750549
[32m[0514 05:45:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9183087944984436, Train Loss: 0.9825669527053833
[32m[0514 05:45:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9182935357093811, Train Loss: 0.9825659990310669
[32m[0514 05:45:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9182801246643066, Train Loss: 0.9825654625892639
[32m[0514 05:45:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9182682037353516, Train Loss: 0.9825649857521057
[32m[0514 05:45:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9182577133178711, Train Loss: 0.9825645685195923
[32m[0514 05:45:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9182484149932861, Train Loss: 0.9825643301010132
[32m[0514 05:45:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9182401299476624, Train Loss: 0.9825640916824341
[32m[0514 05:45:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9182328581809998, Train Loss: 0.9825639128684998
[32m[0514 05:45:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9182263612747192, Train Loss: 0.9825637936592102
[32m[0514 05:45:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9182204604148865, Train Loss: 0.9825636744499207
[32m[0514 05:45:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9182153344154358, Train Loss: 0.9825635552406311
[32m[0514 05:45:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9182107448577881, Train Loss: 0.9825635552406311
[32m[0514 05:45:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9182067513465881, Train Loss: 0.9825635552406311
[32m[0514 05:45:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9182029366493225, Train Loss: 0.9825634956359863
[32m[0514 05:45:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9181997179985046, Train Loss: 0.9825634360313416
[32m[0514 05:45:51 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9181969165802002, Train Loss: 0.9825633764266968
[32m[0514 05:45:51 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9181942939758301, Train Loss: 0.9825634360313416
[32m[0514 05:45:51 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9181918501853943, Train Loss: 0.9825633764266968
[32m[0514 05:45:51 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9181899428367615, Train Loss: 0.9825633764266968
[32m[0514 05:45:51 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9181879758834839, Train Loss: 0.9825634360313416
[32m[0514 05:45:51 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.918186366558075, Train Loss: 0.9825634360313416
[32m[0514 05:45:51 @base_main.py:38][0m --------------- Iteration 4 ---------------
[32m[0514 05:45:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 6.4439 mins
[32m[0514 05:45:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 3.1442 mins
[32m[0514 05:45:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0685 mins
[32m[0514 05:45:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0065 mins
[32m[0514 05:45:51 @base_main.py:47][0m 4020 total steps have happened
[32m[0514 05:45:51 @base_main.py:52][0m [avg_reward]: -1283.7942545552212
[32m[0514 05:45:51 @base_main.py:52][0m [update_op]: None
[32m[0514 05:45:51 @base_main.py:52][0m [train_loss]: 0.9336404800415039
[32m[0514 05:45:51 @base_main.py:52][0m [val_loss]: 0.918186366558075
[32m[0514 05:45:51 @base_main.py:52][0m [avg_train_loss]: 0.9825634360313416
[32m[0514 05:46:29 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:47:07 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:47:43 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:48:20 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:48:59 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:48:59 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:48:59 @base_trainer.py:216][0m Mean reward: -1225.6343811315678
[32m[0514 05:48:59 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1018493175506592, Train Loss: 1.0025216341018677
[32m[0514 05:48:59 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1018760204315186, Train Loss: 1.002520203590393
[32m[0514 05:48:59 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1019092798233032, Train Loss: 1.0025181770324707
[32m[0514 05:49:00 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1019426584243774, Train Loss: 1.0025157928466797
[32m[0514 05:49:00 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1019737720489502, Train Loss: 1.0025138854980469
[32m[0514 05:49:00 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1020019054412842, Train Loss: 1.0025124549865723
[32m[0514 05:49:00 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1020265817642212, Train Loss: 1.0025113821029663
[32m[0514 05:49:00 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1020481586456299, Train Loss: 1.00251042842865
[32m[0514 05:49:00 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.102066993713379, Train Loss: 1.0025098323822021
[32m[0514 05:49:01 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1020835638046265, Train Loss: 1.002509355545044
[32m[0514 05:49:01 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1020978689193726, Train Loss: 1.0025087594985962
[32m[0514 05:49:01 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1021103858947754, Train Loss: 1.0025086402893066
[32m[0514 05:49:01 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.102121114730835, Train Loss: 1.002508521080017
[32m[0514 05:49:01 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1021305322647095, Train Loss: 1.0025084018707275
[32m[0514 05:49:01 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.102138638496399, Train Loss: 1.0025081634521484
[32m[0514 05:49:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1021456718444824, Train Loss: 1.0025080442428589
[32m[0514 05:49:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.102151870727539, Train Loss: 1.0025079250335693
[32m[0514 05:49:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1021571159362793, Train Loss: 1.0025079250335693
[32m[0514 05:49:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1021617650985718, Train Loss: 1.0025079250335693
[32m[0514 05:49:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.102165937423706, Train Loss: 1.0025078058242798
[32m[0514 05:49:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.102169394493103, Train Loss: 1.0025078058242798
[32m[0514 05:49:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1021724939346313, Train Loss: 1.0025076866149902
[32m[0514 05:49:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.102175235748291, Train Loss: 1.0025078058242798
[32m[0514 05:49:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1021775007247925, Train Loss: 1.0025076866149902
[32m[0514 05:49:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1021795272827148, Train Loss: 1.0025076866149902
[32m[0514 05:49:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.102181315422058, Train Loss: 1.0025076866149902
[32m[0514 05:49:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1021828651428223, Train Loss: 1.0025076866149902
[32m[0514 05:49:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1021841764450073, Train Loss: 1.0025076866149902
[32m[0514 05:49:04 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1021853685379028, Train Loss: 1.0025076866149902
[32m[0514 05:49:04 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1021863222122192, Train Loss: 1.0025076866149902
[32m[0514 05:49:04 @base_main.py:38][0m --------------- Iteration 5 ---------------
[32m[0514 05:49:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 9.6631 mins
[32m[0514 05:49:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 3.1223 mins
[32m[0514 05:49:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0827 mins
[32m[0514 05:49:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0069 mins
[32m[0514 05:49:04 @base_main.py:47][0m 5025 total steps have happened
[32m[0514 05:49:04 @base_main.py:52][0m [avg_reward]: -1225.6343811315678
[32m[0514 05:49:04 @base_main.py:52][0m [update_op]: None
[32m[0514 05:49:04 @base_main.py:52][0m [train_loss]: 0.8273536562919617
[32m[0514 05:49:04 @base_main.py:52][0m [val_loss]: 1.1021863222122192
[32m[0514 05:49:04 @base_main.py:52][0m [avg_train_loss]: 1.0025076866149902
[32m[0514 05:49:42 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:50:20 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:50:56 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:51:34 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:52:13 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:52:13 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:52:13 @base_trainer.py:216][0m Mean reward: -1308.7216866876304
[32m[0514 05:52:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8202773332595825, Train Loss: 1.0377758741378784
[32m[0514 05:52:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8202921152114868, Train Loss: 1.0377721786499023
[32m[0514 05:52:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8203088641166687, Train Loss: 1.0377676486968994
[32m[0514 05:52:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8203256130218506, Train Loss: 1.0377637147903442
[32m[0514 05:52:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8203412294387817, Train Loss: 1.037760615348816
[32m[0514 05:52:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8203557729721069, Train Loss: 1.0377581119537354
[32m[0514 05:52:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8203689455986023, Train Loss: 1.037756085395813
[32m[0514 05:52:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8203809261322021, Train Loss: 1.0377548933029175
[32m[0514 05:52:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8203915357589722, Train Loss: 1.0377535820007324
[32m[0514 05:52:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8204011917114258, Train Loss: 1.0377528667449951
[32m[0514 05:52:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8204097747802734, Train Loss: 1.0377522706985474
[32m[0514 05:52:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8204174041748047, Train Loss: 1.0377517938613892
[32m[0514 05:52:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8204241394996643, Train Loss: 1.037751317024231
[32m[0514 05:52:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8204301595687866, Train Loss: 1.0377511978149414
[32m[0514 05:52:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8204354047775269, Train Loss: 1.0377509593963623
[32m[0514 05:52:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8204400539398193, Train Loss: 1.0377507209777832
[32m[0514 05:52:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8204441666603088, Train Loss: 1.0377507209777832
[32m[0514 05:52:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8204477429389954, Train Loss: 1.037750482559204
[32m[0514 05:52:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8204509615898132, Train Loss: 1.0377503633499146
[32m[0514 05:52:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8204536437988281, Train Loss: 1.037750244140625
[32m[0514 05:52:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8204560875892639, Train Loss: 1.0377503633499146
[32m[0514 05:52:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8204582333564758, Train Loss: 1.037750244140625
[32m[0514 05:52:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8204601407051086, Train Loss: 1.037750244140625
[32m[0514 05:52:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8204617500305176, Train Loss: 1.0377501249313354
[32m[0514 05:52:18 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8204632997512817, Train Loss: 1.0377501249313354
[32m[0514 05:52:18 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8204643726348877, Train Loss: 1.0377501249313354
[32m[0514 05:52:18 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8204655647277832, Train Loss: 1.0377501249313354
[32m[0514 05:52:18 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8204665184020996, Train Loss: 1.0377501249313354
[32m[0514 05:52:18 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8204673528671265, Train Loss: 1.0377501249313354
[32m[0514 05:52:19 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.820468008518219, Train Loss: 1.0377501249313354
[32m[0514 05:52:19 @base_main.py:38][0m --------------- Iteration 6 ---------------
[32m[0514 05:52:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 12.8750 mins
[32m[0514 05:52:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 3.1408 mins
[32m[0514 05:52:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0998 mins
[32m[0514 05:52:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0071 mins
[32m[0514 05:52:19 @base_main.py:47][0m 6030 total steps have happened
[32m[0514 05:52:19 @base_main.py:52][0m [avg_reward]: -1308.7216866876304
[32m[0514 05:52:19 @base_main.py:52][0m [update_op]: None
[32m[0514 05:52:19 @base_main.py:52][0m [train_loss]: 1.2991706132888794
[32m[0514 05:52:19 @base_main.py:52][0m [val_loss]: 0.820468008518219
[32m[0514 05:52:19 @base_main.py:52][0m [avg_train_loss]: 1.0377501249313354
[32m[0514 05:52:56 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:53:33 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:54:03 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:54:41 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:55:19 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:55:19 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:55:19 @base_trainer.py:216][0m Mean reward: -964.8575320516011
[32m[0514 05:55:19 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.291730523109436, Train Loss: 0.9707065224647522
[32m[0514 05:55:19 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.291783332824707, Train Loss: 0.9707009196281433
[32m[0514 05:55:19 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2918331623077393, Train Loss: 0.9706957340240479
[32m[0514 05:55:19 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.291877031326294, Train Loss: 0.9706916213035583
[32m[0514 05:55:20 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.291914463043213, Train Loss: 0.9706885814666748
[32m[0514 05:55:20 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2919464111328125, Train Loss: 0.9706865549087524
[32m[0514 05:55:20 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.29197359085083, Train Loss: 0.9706849455833435
[32m[0514 05:55:20 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2919963598251343, Train Loss: 0.970683753490448
[32m[0514 05:55:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.292015552520752, Train Loss: 0.9706830382347107
[32m[0514 05:55:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2920317649841309, Train Loss: 0.9706824421882629
[32m[0514 05:55:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2920455932617188, Train Loss: 0.9706820249557495
[32m[0514 05:55:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.292056918144226, Train Loss: 0.9706817269325256
[32m[0514 05:55:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2920666933059692, Train Loss: 0.9706815481185913
[32m[0514 05:55:22 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2920751571655273, Train Loss: 0.9706812500953674
[32m[0514 05:55:22 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2920818328857422, Train Loss: 0.9706813097000122
[32m[0514 05:55:22 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2920877933502197, Train Loss: 0.9706811904907227
[32m[0514 05:55:22 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2920926809310913, Train Loss: 0.9706811308860779
[32m[0514 05:55:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2920968532562256, Train Loss: 0.9706811308860779
[32m[0514 05:55:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2921005487442017, Train Loss: 0.9706811904907227
[32m[0514 05:55:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2921034097671509, Train Loss: 0.9706811308860779
[32m[0514 05:55:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2921059131622314, Train Loss: 0.9706810712814331
[32m[0514 05:55:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2921078205108643, Train Loss: 0.9706809520721436
[32m[0514 05:55:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.292109727859497, Train Loss: 0.9706810712814331
[32m[0514 05:55:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2921110391616821, Train Loss: 0.9706808924674988
[32m[0514 05:55:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2921125888824463, Train Loss: 0.9706809520721436
[32m[0514 05:55:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2921134233474731, Train Loss: 0.9706809520721436
[32m[0514 05:55:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2921143770217896, Train Loss: 0.9706809520721436
[32m[0514 05:55:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2921150922775269, Train Loss: 0.9706809520721436
[32m[0514 05:55:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2921158075332642, Train Loss: 0.9706809520721436
[32m[0514 05:55:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.292116403579712, Train Loss: 0.9706809520721436
[32m[0514 05:55:25 @base_main.py:38][0m --------------- Iteration 7 ---------------
[32m[0514 05:55:25 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 16.1229 mins
[32m[0514 05:55:25 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 2.9916 mins
[32m[0514 05:55:25 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.1062 mins
[32m[0514 05:55:25 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0068 mins
[32m[0514 05:55:25 @base_main.py:47][0m 7035 total steps have happened
[32m[0514 05:55:25 @base_main.py:52][0m [avg_reward]: -964.8575320516011
[32m[0514 05:55:25 @base_main.py:52][0m [update_op]: None
[32m[0514 05:55:25 @base_main.py:52][0m [train_loss]: 0.5357007384300232
[32m[0514 05:55:25 @base_main.py:52][0m [val_loss]: 1.292116403579712
[32m[0514 05:55:25 @base_main.py:52][0m [avg_train_loss]: 0.9706809520721436
[32m[0514 05:55:25 @mbmf_trainer.py:160][0m Mean reward: -1218.9195747214824
[32m[0514 05:55:26 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.29598745703697205, Train Loss: 0.30236074328422546
[32m[0514 05:55:26 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.2960052192211151, Train Loss: 0.30227795243263245
[32m[0514 05:55:26 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.2960352301597595, Train Loss: 0.302264541387558
[32m[0514 05:55:26 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.2960326075553894, Train Loss: 0.3022594749927521
[32m[0514 05:55:26 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.29601749777793884, Train Loss: 0.30225494503974915
[32m[0514 05:55:26 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.2960068881511688, Train Loss: 0.30224981904029846
[32m[0514 05:55:26 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.29600057005882263, Train Loss: 0.30224478244781494
[32m[0514 05:55:26 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.29599395394325256, Train Loss: 0.30224016308784485
[32m[0514 05:55:26 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.2959854006767273, Train Loss: 0.30223581194877625
[32m[0514 05:55:26 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.2959759831428528, Train Loss: 0.3022316098213196
[32m[0514 05:55:26 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.2959664762020111, Train Loss: 0.3022274672985077
[32m[0514 05:55:26 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.29595711827278137, Train Loss: 0.30222344398498535
[32m[0514 05:55:26 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.295947790145874, Train Loss: 0.302219420671463
[32m[0514 05:55:26 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.2959384322166443, Train Loss: 0.3022155463695526
[32m[0514 05:55:26 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.29592907428741455, Train Loss: 0.302211731672287
[32m[0514 05:55:26 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.29591992497444153, Train Loss: 0.30220797657966614
[32m[0514 05:55:26 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.29591086506843567, Train Loss: 0.30220428109169006
[32m[0514 05:55:26 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.29590195417404175, Train Loss: 0.30220064520835876
[32m[0514 05:55:26 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.29589328169822693, Train Loss: 0.30219700932502747
[32m[0514 05:55:26 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.29588475823402405, Train Loss: 0.3021934926509857
[32m[0514 05:55:26 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.2958764135837555, Train Loss: 0.30219003558158875
[32m[0514 05:55:26 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.29586827754974365, Train Loss: 0.30218660831451416
[32m[0514 05:55:26 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.2958603799343109, Train Loss: 0.3021831810474396
[32m[0514 05:55:26 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.2958526611328125, Train Loss: 0.30217987298965454
[32m[0514 05:55:27 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.2958451807498932, Train Loss: 0.3021765947341919
[32m[0514 05:55:27 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.2958379089832306, Train Loss: 0.30217334628105164
[32m[0514 05:55:27 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.2958308458328247, Train Loss: 0.30217012763023376
[32m[0514 05:55:27 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.29582399129867554, Train Loss: 0.30216696858406067
[32m[0514 05:55:27 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.29581737518310547, Train Loss: 0.30216386914253235
[32m[0514 05:55:27 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.2958109378814697, Train Loss: 0.30216076970100403
[32m[0514 05:55:27 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.2958047688007355, Train Loss: 0.30215775966644287
[32m[0514 05:55:27 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.29579877853393555, Train Loss: 0.3021547198295593
[32m[0514 05:55:27 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.2957930266857147, Train Loss: 0.30215173959732056
[32m[0514 05:55:27 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.295787513256073, Train Loss: 0.30214881896972656
[32m[0514 05:55:27 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.2957821786403656, Train Loss: 0.30214592814445496
[32m[0514 05:55:27 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.2957770526409149, Train Loss: 0.30214306712150574
[32m[0514 05:55:27 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.2957721948623657, Train Loss: 0.3021402657032013
[32m[0514 05:55:27 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.29576751589775085, Train Loss: 0.30213746428489685
[32m[0514 05:55:27 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.2957630157470703, Train Loss: 0.3021347224712372
[32m[0514 05:55:27 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.29575875401496887, Train Loss: 0.3021320104598999
[32m[0514 05:55:27 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.29575467109680176, Train Loss: 0.3021293580532074
[32m[0514 05:55:27 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.29575082659721375, Train Loss: 0.3021266758441925
[32m[0514 05:55:27 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.29574716091156006, Train Loss: 0.3021240830421448
[32m[0514 05:55:27 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.2957436442375183, Train Loss: 0.30212146043777466
[32m[0514 05:55:27 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.29574036598205566, Train Loss: 0.3021189272403717
[32m[0514 05:55:27 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.29573729634284973, Train Loss: 0.30211642384529114
[32m[0514 05:55:27 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.29573437571525574, Train Loss: 0.3021138906478882
[32m[0514 05:55:27 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.29573163390159607, Train Loss: 0.30211141705513
[32m[0514 05:55:28 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.29572904109954834, Train Loss: 0.3021089732646942
[32m[0514 05:55:28 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.2957266569137573, Train Loss: 0.3021065294742584
[32m[0514 05:55:28 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.29572445154190063, Train Loss: 0.3021041750907898
[32m[0514 05:55:28 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.2957223951816559, Train Loss: 0.30210182070732117
[32m[0514 05:55:28 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.29572048783302307, Train Loss: 0.30209946632385254
[32m[0514 05:55:28 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.2957187592983246, Train Loss: 0.3020971119403839
[32m[0514 05:55:28 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.2957172095775604, Train Loss: 0.30209478735923767
[32m[0514 05:55:28 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.2957157492637634, Train Loss: 0.3020925521850586
[32m[0514 05:55:28 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.29571449756622314, Train Loss: 0.30209025740623474
[32m[0514 05:55:28 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.2957133650779724, Train Loss: 0.30208805203437805
[32m[0514 05:55:28 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.29571235179901123, Train Loss: 0.3020857870578766
[32m[0514 05:55:28 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.2957115173339844, Train Loss: 0.3020835816860199
[32m[0514 05:55:28 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.29571083188056946, Train Loss: 0.3020813465118408
[32m[0514 05:55:28 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.2957102060317993, Train Loss: 0.3020792007446289
[32m[0514 05:55:28 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.2957097589969635, Train Loss: 0.3020770251750946
[32m[0514 05:55:28 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.29570943117141724, Train Loss: 0.3020748794078827
[32m[0514 05:55:28 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.2957092225551605, Train Loss: 0.30207276344299316
[32m[0514 05:55:28 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.29570913314819336, Train Loss: 0.30207058787345886
[32m[0514 05:55:28 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.29570916295051575, Train Loss: 0.30206847190856934
[32m[0514 05:55:28 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.2957092821598053, Train Loss: 0.3020663559436798
[32m[0514 05:55:28 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.2957095503807068, Train Loss: 0.30206429958343506
[32m[0514 05:55:28 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.29570987820625305, Train Loss: 0.3020622134208679
[32m[0514 05:55:28 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.29571035504341125, Train Loss: 0.302060067653656
[32m[0514 05:55:28 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.295710951089859, Train Loss: 0.30205807089805603
[32m[0514 05:55:28 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.29571157693862915, Train Loss: 0.3020559847354889
[32m[0514 05:55:28 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.29571232199668884, Train Loss: 0.30205392837524414
[32m[0514 05:55:29 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.2957131564617157, Train Loss: 0.3020519018173218
[32m[0514 05:55:29 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.2957140803337097, Train Loss: 0.302049845457077
[32m[0514 05:55:29 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.2957151234149933, Train Loss: 0.3020477890968323
[32m[0514 05:55:29 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.29571622610092163, Train Loss: 0.3020457923412323
[32m[0514 05:55:29 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.2957174479961395, Train Loss: 0.30204376578330994
[32m[0514 05:55:29 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.2957186698913574, Train Loss: 0.3020417392253876
[32m[0514 05:55:29 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.29572001099586487, Train Loss: 0.3020397126674652
[32m[0514 05:55:29 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.29572147130966187, Train Loss: 0.30203768610954285
[32m[0514 05:55:29 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.29572296142578125, Train Loss: 0.3020356595516205
[32m[0514 05:55:29 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.2957245409488678, Train Loss: 0.3020336627960205
[32m[0514 05:55:29 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.2957261800765991, Train Loss: 0.30203160643577576
[32m[0514 05:55:29 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.2957279086112976, Train Loss: 0.3020296096801758
[32m[0514 05:55:29 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.2957296669483185, Train Loss: 0.3020275831222534
[32m[0514 05:55:29 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.2957315146923065, Train Loss: 0.30202558636665344
[32m[0514 05:55:29 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.29573342204093933, Train Loss: 0.3020235598087311
[32m[0514 05:55:29 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.29573535919189453, Train Loss: 0.30202150344848633
[32m[0514 05:55:29 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.2957374155521393, Train Loss: 0.30201950669288635
[32m[0514 05:55:29 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.29573947191238403, Train Loss: 0.30201753973960876
[32m[0514 05:55:29 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.29574158787727356, Train Loss: 0.3020155131816864
[32m[0514 05:55:29 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.29574379324913025, Train Loss: 0.30201345682144165
[32m[0514 05:55:29 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.2957460284233093, Train Loss: 0.3020114600658417
[32m[0514 05:55:29 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.2957483232021332, Train Loss: 0.3020094633102417
[32m[0514 05:55:29 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.2957506477832794, Train Loss: 0.30200740694999695
[32m[0514 05:55:29 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.2957530617713928, Train Loss: 0.3020053803920746
[32m[0514 05:55:29 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.2957554757595062, Train Loss: 0.30200332403182983
[32m[0514 05:55:29 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.2957579493522644, Train Loss: 0.3020012676715851
[32m[0514 05:55:30 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.29576048254966736, Train Loss: 0.3019992411136627
[32m[0514 05:55:30 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.2957630157470703, Train Loss: 0.30199724435806274
[32m[0514 05:55:30 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.29576563835144043, Train Loss: 0.301995187997818
[32m[0514 05:55:30 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.29576829075813293, Train Loss: 0.30199313163757324
[32m[0514 05:55:30 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.2957709729671478, Train Loss: 0.3019910752773285
[32m[0514 05:55:30 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.2957736551761627, Train Loss: 0.30198901891708374
[32m[0514 05:55:30 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.2957764267921448, Train Loss: 0.301986962556839
[32m[0514 05:55:30 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.2957792282104492, Train Loss: 0.30198490619659424
[32m[0514 05:55:30 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.29578205943107605, Train Loss: 0.3019828498363495
[32m[0514 05:55:30 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.29578492045402527, Train Loss: 0.30198076367378235
[32m[0514 05:55:30 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.29578784108161926, Train Loss: 0.3019787073135376
[32m[0514 05:55:30 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.29579073190689087, Train Loss: 0.30197665095329285
[32m[0514 05:55:30 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.29579371213912964, Train Loss: 0.3019745647907257
[32m[0514 05:55:30 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.2957966923713684, Train Loss: 0.30197247862815857
[32m[0514 05:55:30 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.29579973220825195, Train Loss: 0.30197039246559143
[32m[0514 05:55:30 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.2958027720451355, Train Loss: 0.3019683063030243
[32m[0514 05:55:30 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.29580584168434143, Train Loss: 0.30196619033813477
[32m[0514 05:55:30 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.29580891132354736, Train Loss: 0.3019641041755676
[32m[0514 05:55:30 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.29581204056739807, Train Loss: 0.3019619882106781
[32m[0514 05:55:30 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.29581519961357117, Train Loss: 0.3019598722457886
[32m[0514 05:55:30 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.29581838846206665, Train Loss: 0.30195775628089905
[32m[0514 05:55:30 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.29582154750823975, Train Loss: 0.3019556701183319
[32m[0514 05:55:30 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.29582479596138, Train Loss: 0.30195352435112
[32m[0514 05:55:30 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.29582807421684265, Train Loss: 0.3019513785839081
[32m[0514 05:55:30 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.2958313226699829, Train Loss: 0.30194926261901855
[32m[0514 05:55:30 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.29583460092544556, Train Loss: 0.30194708704948425
[32m[0514 05:55:31 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.295837938785553, Train Loss: 0.3019449710845947
[32m[0514 05:55:31 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.295841246843338, Train Loss: 0.3019427955150604
[32m[0514 05:55:31 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.2958446145057678, Train Loss: 0.3019406795501709
[32m[0514 05:55:31 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.29584798216819763, Train Loss: 0.3019385039806366
[32m[0514 05:55:31 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.29585137963294983, Train Loss: 0.3019363582134247
[32m[0514 05:55:31 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.295854777097702, Train Loss: 0.3019341826438904
[32m[0514 05:55:31 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.2958582043647766, Train Loss: 0.3019320070743561
[32m[0514 05:55:31 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.2958616316318512, Train Loss: 0.3019298315048218
[32m[0514 05:55:31 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.29586514830589294, Train Loss: 0.3019276559352875
[32m[0514 05:55:31 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.2958686053752899, Train Loss: 0.3019254505634308
[32m[0514 05:55:31 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.2958720624446869, Train Loss: 0.3019232451915741
[32m[0514 05:55:31 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.29587557911872864, Train Loss: 0.3019210994243622
[32m[0514 05:55:31 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.2958791255950928, Train Loss: 0.3019188642501831
[32m[0514 05:55:31 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.2958826720714569, Train Loss: 0.3019166886806488
[32m[0514 05:55:31 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.29588621854782104, Train Loss: 0.3019144535064697
[32m[0514 05:55:31 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.2958897650241852, Train Loss: 0.3019122779369354
[32m[0514 05:55:31 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.2958933413028717, Train Loss: 0.30191004276275635
[32m[0514 05:55:31 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.2958969473838806, Train Loss: 0.30190780758857727
[32m[0514 05:55:31 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.29590049386024475, Train Loss: 0.3019056022167206
[32m[0514 05:55:31 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.29590412974357605, Train Loss: 0.3019033670425415
[32m[0514 05:55:31 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.29590773582458496, Train Loss: 0.3019011318683624
[32m[0514 05:55:31 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.29591140151023865, Train Loss: 0.30189889669418335
[32m[0514 05:55:31 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.29591500759124756, Train Loss: 0.3018966019153595
[32m[0514 05:55:31 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.29591870307922363, Train Loss: 0.3018944263458252
[32m[0514 05:55:31 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.29592233896255493, Train Loss: 0.30189216136932373
[32m[0514 05:55:32 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.2959260046482086, Train Loss: 0.3018898665904999
[32m[0514 05:55:32 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.2959297001361847, Train Loss: 0.3018876314163208
[32m[0514 05:55:32 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.2959333658218384, Train Loss: 0.30188533663749695
[32m[0514 05:55:32 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.29593706130981445, Train Loss: 0.3018830716609955
[32m[0514 05:55:32 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.2959407866001129, Train Loss: 0.3018808364868164
[32m[0514 05:55:32 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.295944482088089, Train Loss: 0.30187854170799255
[32m[0514 05:55:32 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.29594817757606506, Train Loss: 0.3018762469291687
[32m[0514 05:55:32 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.2959519028663635, Train Loss: 0.3018740117549896
[32m[0514 05:55:32 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.295955628156662, Train Loss: 0.3018716871738434
[32m[0514 05:55:32 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.29595935344696045, Train Loss: 0.3018694221973419
[32m[0514 05:55:32 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.2959630787372589, Train Loss: 0.3018670678138733
[32m[0514 05:55:32 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.29596683382987976, Train Loss: 0.30186477303504944
[32m[0514 05:55:32 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.2959705591201782, Train Loss: 0.3018624782562256
[32m[0514 05:55:32 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.29597434401512146, Train Loss: 0.30186012387275696
[32m[0514 05:55:32 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.2959780693054199, Train Loss: 0.3018578588962555
[32m[0514 05:55:32 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.29598185420036316, Train Loss: 0.30185556411743164
[32m[0514 05:55:32 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.295985609292984, Train Loss: 0.301853209733963
[32m[0514 05:55:32 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.29598939418792725, Train Loss: 0.3018508553504944
[32m[0514 05:55:32 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.2959931492805481, Train Loss: 0.30184856057167053
[32m[0514 05:55:32 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.29599687457084656, Train Loss: 0.3018462359905243
[32m[0514 05:55:32 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.2960006594657898, Train Loss: 0.30184391140937805
[32m[0514 05:55:32 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.29600441455841064, Train Loss: 0.3018415570259094
[32m[0514 05:55:32 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.2960081696510315, Train Loss: 0.3018392324447632
[32m[0514 05:55:32 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.29601192474365234, Train Loss: 0.30183684825897217
[32m[0514 05:55:32 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.2960157096385956, Train Loss: 0.3018345236778259
[32m[0514 05:55:33 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.2960194945335388, Train Loss: 0.3018321692943573
[32m[0514 05:55:33 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.29602324962615967, Train Loss: 0.30182984471321106
[32m[0514 05:55:33 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.2960270345211029, Train Loss: 0.30182746052742004
[32m[0514 05:55:33 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.29603078961372375, Train Loss: 0.3018251061439514
[32m[0514 05:55:33 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.296034574508667, Train Loss: 0.3018227517604828
[32m[0514 05:55:33 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.29603832960128784, Train Loss: 0.30182039737701416
[32m[0514 05:55:33 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.2960420846939087, Train Loss: 0.30181801319122314
[32m[0514 05:55:33 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.29604586958885193, Train Loss: 0.30181562900543213
[32m[0514 05:55:33 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.2960496246814728, Train Loss: 0.3018132746219635
[32m[0514 05:55:33 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.29605337977409363, Train Loss: 0.3018108904361725
[32m[0514 05:55:33 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.2960571348667145, Train Loss: 0.30180850625038147
[32m[0514 05:55:33 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.2960608899593353, Train Loss: 0.30180612206459045
[32m[0514 05:55:33 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.2960646450519562, Train Loss: 0.30180373787879944
[32m[0514 05:55:33 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.296068400144577, Train Loss: 0.3018013536930084
[32m[0514 05:55:33 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.2960721552371979, Train Loss: 0.301798939704895
[32m[0514 05:55:33 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.29607588052749634, Train Loss: 0.301796555519104
[32m[0514 05:55:33 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.2960795760154724, Train Loss: 0.301794171333313
[32m[0514 05:55:33 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.29608333110809326, Train Loss: 0.301791787147522
[32m[0514 05:55:33 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.2960870563983917, Train Loss: 0.30178937315940857
[32m[0514 05:55:33 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.2960907816886902, Train Loss: 0.30178698897361755
[32m[0514 05:55:33 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.29609450697898865, Train Loss: 0.30178457498550415
[32m[0514 05:55:33 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.2960982024669647, Train Loss: 0.30178216099739075
[32m[0514 05:55:33 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.2961018979549408, Train Loss: 0.30177977681159973
[32m[0514 05:55:33 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.29610562324523926, Train Loss: 0.30177736282348633
[32m[0514 05:55:33 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.29610925912857056, Train Loss: 0.3017749488353729
[32m[0514 05:55:34 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.296112984418869, Train Loss: 0.3017725348472595
[32m[0514 05:55:34 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.2961166501045227, Train Loss: 0.3017701208591461
[32m[0514 05:55:34 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.2961203455924988, Train Loss: 0.3017676770687103
[32m[0514 05:55:34 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.29612401127815247, Train Loss: 0.30176523327827454
[32m[0514 05:55:34 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.29612764716148376, Train Loss: 0.3017628490924835
[32m[0514 05:55:34 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.29613128304481506, Train Loss: 0.3017604351043701
[32m[0514 05:55:34 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.29613494873046875, Train Loss: 0.3017579913139343
[32m[0514 05:55:34 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.29613858461380005, Train Loss: 0.3017555773258209
[32m[0514 05:55:34 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.29614219069480896, Train Loss: 0.30175313353538513
[32m[0514 05:55:34 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.29614582657814026, Train Loss: 0.30175068974494934
[32m[0514 05:55:34 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.29614946246147156, Train Loss: 0.30174827575683594
[32m[0514 05:55:34 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.2961530089378357, Train Loss: 0.30174586176872253
[32m[0514 05:55:34 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.2961566150188446, Train Loss: 0.30174341797828674
[32m[0514 05:55:34 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.2961602509021759, Train Loss: 0.3017410337924957
[32m[0514 05:55:34 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.29616379737854004, Train Loss: 0.30173853039741516
[32m[0514 05:55:34 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.29616737365722656, Train Loss: 0.30173611640930176
[32m[0514 05:55:34 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.2961708903312683, Train Loss: 0.30173370242118835
[32m[0514 05:55:34 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.29617443680763245, Train Loss: 0.3017312288284302
[32m[0514 05:55:34 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.2961779832839966, Train Loss: 0.3017288148403168
[32m[0514 05:55:34 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.2961815297603607, Train Loss: 0.301726371049881
[32m[0514 05:55:34 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.29618504643440247, Train Loss: 0.3017239272594452
[32m[0514 05:55:34 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.2961885631084442, Train Loss: 0.3017214834690094
[32m[0514 05:55:34 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.2961920201778412, Train Loss: 0.301719069480896
[32m[0514 05:55:34 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.29619550704956055, Train Loss: 0.3017165958881378
[32m[0514 05:55:34 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.2961989939212799, Train Loss: 0.301714152097702
[32m[0514 05:55:35 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.2962024509906769, Train Loss: 0.30171170830726624
[32m[0514 05:55:35 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.29620587825775146, Train Loss: 0.30170926451683044
[32m[0514 05:55:35 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.29620933532714844, Train Loss: 0.30170682072639465
[32m[0514 05:55:35 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.296212762594223, Train Loss: 0.30170437693595886
[32m[0514 05:55:35 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.2962161600589752, Train Loss: 0.30170193314552307
[32m[0514 05:55:35 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.2962195873260498, Train Loss: 0.3016994893550873
[32m[0514 05:55:35 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.2962229549884796, Train Loss: 0.3016970455646515
[32m[0514 05:55:35 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.2962263226509094, Train Loss: 0.3016946017742157
[32m[0514 05:55:35 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.2962297201156616, Train Loss: 0.3016921579837799
[32m[0514 05:55:35 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.29623305797576904, Train Loss: 0.30168968439102173
[32m[0514 05:55:35 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.29623639583587646, Train Loss: 0.3016872704029083
[32m[0514 05:55:35 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.2962397336959839, Train Loss: 0.30168479681015015
[32m[0514 05:55:35 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.2962430417537689, Train Loss: 0.30168238282203674
[32m[0514 05:55:35 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.29624637961387634, Train Loss: 0.3016798794269562
[32m[0514 05:55:35 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.2962496280670166, Train Loss: 0.3016774356365204
[32m[0514 05:55:35 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.29625287652015686, Train Loss: 0.3016749918460846
[32m[0514 05:55:35 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.2962562143802643, Train Loss: 0.3016725480556488
[32m[0514 05:55:35 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.29625940322875977, Train Loss: 0.301670104265213
[32m[0514 05:55:35 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.2962626814842224, Train Loss: 0.3016676604747772
[32m[0514 05:55:35 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.2962659001350403, Train Loss: 0.30166518688201904
[32m[0514 05:55:35 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.29626908898353577, Train Loss: 0.30166274309158325
[32m[0514 05:55:35 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.29627230763435364, Train Loss: 0.30166029930114746
[32m[0514 05:55:35 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.2962754964828491, Train Loss: 0.3016578257083893
[32m[0514 05:55:35 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.2962786555290222, Train Loss: 0.30165544152259827
[32m[0514 05:55:35 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.2962818443775177, Train Loss: 0.3016529977321625
[32m[0514 05:55:35 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.2962849736213684, Train Loss: 0.3016505241394043
[32m[0514 05:55:36 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.2962881028652191, Train Loss: 0.3016480505466461
[32m[0514 05:55:36 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.29629120230674744, Train Loss: 0.3016456067562103
[32m[0514 05:55:36 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.29629430174827576, Train Loss: 0.3016431927680969
[32m[0514 05:55:36 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.2962973713874817, Train Loss: 0.30164071917533875
[32m[0514 05:55:36 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.29630047082901, Train Loss: 0.30163827538490295
[32m[0514 05:55:36 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.29630351066589355, Train Loss: 0.30163583159446716
[32m[0514 05:55:36 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.2963065803050995, Train Loss: 0.30163338780403137
[32m[0514 05:55:36 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.29630959033966064, Train Loss: 0.3016309440135956
[32m[0514 05:55:36 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.2963126003742218, Train Loss: 0.3016285002231598
[32m[0514 05:55:36 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.29631561040878296, Train Loss: 0.301626056432724
[32m[0514 05:55:36 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.2963186204433441, Train Loss: 0.3016236126422882
[32m[0514 05:55:36 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.2963215708732605, Train Loss: 0.3016211986541748
[32m[0514 05:55:36 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.2963245213031769, Train Loss: 0.3016187846660614
[32m[0514 05:55:36 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.29632747173309326, Train Loss: 0.3016163110733032
[32m[0514 05:55:36 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.29633036255836487, Train Loss: 0.30161386728286743
[32m[0514 05:55:36 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.29633331298828125, Train Loss: 0.30161145329475403
[32m[0514 05:55:36 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.29633620381355286, Train Loss: 0.30160900950431824
[32m[0514 05:55:36 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.29633909463882446, Train Loss: 0.30160656571388245
[32m[0514 05:55:36 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.2963419556617737, Train Loss: 0.30160409212112427
[32m[0514 05:55:36 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.2963448166847229, Train Loss: 0.30160167813301086
[32m[0514 05:55:36 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.29634764790534973, Train Loss: 0.3015992343425751
[32m[0514 05:55:36 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.29635047912597656, Train Loss: 0.3015967905521393
[32m[0514 05:55:36 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.296353280544281, Train Loss: 0.3015943467617035
[32m[0514 05:55:36 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.29635608196258545, Train Loss: 0.3015919327735901
[32m[0514 05:55:36 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.2963588535785675, Train Loss: 0.3015895187854767
[32m[0514 05:55:37 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.29636162519454956, Train Loss: 0.3015870749950409
[32m[0514 05:55:37 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.29636433720588684, Train Loss: 0.3015846312046051
[32m[0514 05:55:37 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.2963670790195465, Train Loss: 0.3015822470188141
[32m[0514 05:55:37 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.2963698208332062, Train Loss: 0.3015798032283783
[32m[0514 05:55:37 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.29637253284454346, Train Loss: 0.3015773594379425
[32m[0514 05:55:37 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.29637518525123596, Train Loss: 0.3015749454498291
[32m[0514 05:55:37 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.29637783765792847, Train Loss: 0.3015725016593933
[32m[0514 05:55:37 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.29638051986694336, Train Loss: 0.3015700876712799
[32m[0514 05:55:37 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.29638317227363586, Train Loss: 0.3015676438808441
[32m[0514 05:55:37 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.296385794878006, Train Loss: 0.3015652298927307
[32m[0514 05:55:37 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.2963883876800537, Train Loss: 0.3015627861022949
[32m[0514 05:55:37 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.29639098048210144, Train Loss: 0.3015603721141815
[32m[0514 05:55:37 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.29639357328414917, Train Loss: 0.3015579581260681
[32m[0514 05:55:37 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.2963961064815521, Train Loss: 0.3015555441379547
[32m[0514 05:55:37 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.29639866948127747, Train Loss: 0.3015531003475189
[32m[0514 05:55:37 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.2964012026786804, Train Loss: 0.3015506863594055
[32m[0514 05:55:37 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.296403706073761, Train Loss: 0.3015482723712921
[32m[0514 05:55:37 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.29640620946884155, Train Loss: 0.3015458285808563
[32m[0514 05:55:37 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.2964087128639221, Train Loss: 0.3015434741973877
[32m[0514 05:55:37 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.2964111566543579, Train Loss: 0.3015410304069519
[32m[0514 05:55:37 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.2964135706424713, Train Loss: 0.3015385866165161
[32m[0514 05:55:37 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.2964160442352295, Train Loss: 0.3015361726284027
[32m[0514 05:55:37 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.2964184582233429, Train Loss: 0.3015337884426117
[32m[0514 05:55:38 @mbmf_sampler.py:98][0m Finished 9th episode
[32m[0514 05:55:38 @mbmf_sampler.py:102][0m 1809 timesteps from 9 episodes collected
[32m[0514 06:01:12 @mbmf_trainer.py:160][0m Mean reward: -1201.479470318032
[32m[0514 06:01:12 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.29562896490097046, Train Loss: 0.29905879497528076
[32m[0514 06:01:12 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.2955716550350189, Train Loss: 0.2990078330039978
[32m[0514 06:01:12 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.2955494523048401, Train Loss: 0.29899099469184875
[32m[0514 06:01:12 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.2955470085144043, Train Loss: 0.2989821135997772
[32m[0514 06:01:12 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.2955400049686432, Train Loss: 0.29897287487983704
[32m[0514 06:01:12 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.2955396771430969, Train Loss: 0.29896652698516846
[32m[0514 06:01:12 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.2955434322357178, Train Loss: 0.29896071553230286
[32m[0514 06:01:13 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.29554712772369385, Train Loss: 0.29895469546318054
[32m[0514 06:01:13 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.29555103182792664, Train Loss: 0.29894912242889404
[32m[0514 06:01:13 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.29555490612983704, Train Loss: 0.2989436984062195
[32m[0514 06:01:13 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.295558363199234, Train Loss: 0.29893845319747925
[32m[0514 06:01:13 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.29556137323379517, Train Loss: 0.2989334166049957
[32m[0514 06:01:13 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.2955639958381653, Train Loss: 0.2989285886287689
[32m[0514 06:01:13 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.2955663204193115, Train Loss: 0.2989238500595093
[32m[0514 06:01:13 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.2955683469772339, Train Loss: 0.29891929030418396
[32m[0514 06:01:13 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.29557010531425476, Train Loss: 0.2989148795604706
[32m[0514 06:01:13 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.29557153582572937, Train Loss: 0.298910528421402
[32m[0514 06:01:13 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.29557278752326965, Train Loss: 0.2989062964916229
[32m[0514 06:01:13 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.2955738604068756, Train Loss: 0.2989021837711334
[32m[0514 06:01:13 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.29557469487190247, Train Loss: 0.2988981604576111
[32m[0514 06:01:13 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.29557543992996216, Train Loss: 0.29889413714408875
[32m[0514 06:01:13 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.2955760061740875, Train Loss: 0.29889029264450073
[32m[0514 06:01:13 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.29557639360427856, Train Loss: 0.2988864481449127
[32m[0514 06:01:13 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.29557672142982483, Train Loss: 0.29888269305229187
[32m[0514 06:01:13 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.29557693004608154, Train Loss: 0.2988790273666382
[32m[0514 06:01:13 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.2955769896507263, Train Loss: 0.2988753318786621
[32m[0514 06:01:13 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.2955770790576935, Train Loss: 0.298871785402298
[32m[0514 06:01:13 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.2955769896507263, Train Loss: 0.2988681495189667
[32m[0514 06:01:13 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.29557690024375916, Train Loss: 0.2988646924495697
[32m[0514 06:01:14 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.29557672142982483, Train Loss: 0.29886123538017273
[32m[0514 06:01:14 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.2955765128135681, Train Loss: 0.29885777831077576
[32m[0514 06:01:14 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.29557621479034424, Train Loss: 0.29885441064834595
[32m[0514 06:01:14 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.29557591676712036, Train Loss: 0.2988510727882385
[32m[0514 06:01:14 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.2955755889415741, Train Loss: 0.2988477349281311
[32m[0514 06:01:14 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.29557523131370544, Train Loss: 0.29884445667266846
[32m[0514 06:01:14 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.295574814081192, Train Loss: 0.2988412082195282
[32m[0514 06:01:14 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.295574426651001, Train Loss: 0.2988379895687103
[32m[0514 06:01:14 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.29557400941848755, Train Loss: 0.29883477091789246
[32m[0514 06:01:14 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.2955735921859741, Train Loss: 0.298831582069397
[32m[0514 06:01:14 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.2955731153488159, Train Loss: 0.29882848262786865
[32m[0514 06:01:14 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.2955726087093353, Train Loss: 0.29882532358169556
[32m[0514 06:01:14 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.2955721914768219, Train Loss: 0.298822283744812
[32m[0514 06:01:14 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.2955717444419861, Train Loss: 0.2988191545009613
[32m[0514 06:01:14 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.29557129740715027, Train Loss: 0.29881611466407776
[32m[0514 06:01:14 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.29557082056999207, Train Loss: 0.2988130748271942
[32m[0514 06:01:14 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.29557034373283386, Train Loss: 0.29881009459495544
[32m[0514 06:01:14 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.29556986689567566, Train Loss: 0.2988071143627167
[32m[0514 06:01:14 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.29556944966316223, Train Loss: 0.2988041043281555
[32m[0514 06:01:15 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.2955690026283264, Train Loss: 0.29880109429359436
[32m[0514 06:01:15 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.295568585395813, Train Loss: 0.29879817366600037
[32m[0514 06:01:15 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.29556816816329956, Train Loss: 0.29879528284072876
[32m[0514 06:01:15 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.29556772112846375, Train Loss: 0.2987923324108124
[32m[0514 06:01:15 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.2955673336982727, Train Loss: 0.29878947138786316
[32m[0514 06:01:15 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.29556697607040405, Train Loss: 0.29878658056259155
[32m[0514 06:01:15 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.2955666184425354, Train Loss: 0.29878368973731995
[32m[0514 06:01:15 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.29556623101234436, Train Loss: 0.2987808287143707
[32m[0514 06:01:15 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.2955658733844757, Train Loss: 0.2987779974937439
[32m[0514 06:01:15 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.29556557536125183, Train Loss: 0.29877516627311707
[32m[0514 06:01:15 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.29556527733802795, Train Loss: 0.29877233505249023
[32m[0514 06:01:15 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.2955649197101593, Train Loss: 0.2987695038318634
[32m[0514 06:01:15 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.2955646812915802, Train Loss: 0.29876670241355896
[32m[0514 06:01:15 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.2955644428730011, Train Loss: 0.2987639307975769
[32m[0514 06:01:15 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.295564204454422, Train Loss: 0.29876115918159485
[32m[0514 06:01:15 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.2955639660358429, Train Loss: 0.2987583875656128
[32m[0514 06:01:15 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.2955637574195862, Train Loss: 0.29875558614730835
[32m[0514 06:01:15 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.29556357860565186, Train Loss: 0.29875287413597107
[32m[0514 06:01:15 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.29556336998939514, Train Loss: 0.298750102519989
[32m[0514 06:01:16 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.2955632507801056, Train Loss: 0.29874736070632935
[32m[0514 06:01:16 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.29556313157081604, Train Loss: 0.29874467849731445
[32m[0514 06:01:16 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.2955629825592041, Train Loss: 0.2987419068813324
[32m[0514 06:01:16 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.29556289315223694, Train Loss: 0.2987392544746399
[32m[0514 06:01:16 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.2955628037452698, Train Loss: 0.2987365424633026
[32m[0514 06:01:16 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.295562744140625, Train Loss: 0.29873383045196533
[32m[0514 06:01:16 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.295562744140625, Train Loss: 0.29873111844062805
[32m[0514 06:01:16 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.2955627143383026, Train Loss: 0.29872843623161316
[32m[0514 06:01:16 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.295562744140625, Train Loss: 0.29872575402259827
[32m[0514 06:01:16 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.295562744140625, Train Loss: 0.29872313141822815
[32m[0514 06:01:16 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.2955628037452698, Train Loss: 0.29872041940689087
[32m[0514 06:01:16 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.29556283354759216, Train Loss: 0.29871776700019836
[32m[0514 06:01:16 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.2955629229545593, Train Loss: 0.29871511459350586
[32m[0514 06:01:16 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.2955630123615265, Train Loss: 0.29871243238449097
[32m[0514 06:01:16 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.2955631613731384, Train Loss: 0.29870980978012085
[32m[0514 06:01:16 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.29556331038475037, Train Loss: 0.29870715737342834
[32m[0514 06:01:16 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.2955634295940399, Train Loss: 0.2987045645713806
[32m[0514 06:01:16 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.29556363821029663, Train Loss: 0.2987019419670105
[32m[0514 06:01:16 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.29556381702423096, Train Loss: 0.2986992597579956
[32m[0514 06:01:16 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.29556408524513245, Train Loss: 0.2986966371536255
[32m[0514 06:01:17 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.29556429386138916, Train Loss: 0.29869404435157776
[32m[0514 06:01:17 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.29556456208229065, Train Loss: 0.29869145154953003
[32m[0514 06:01:17 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.2955648601055145, Train Loss: 0.2986888289451599
[32m[0514 06:01:17 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.2955651581287384, Train Loss: 0.2986862361431122
[32m[0514 06:01:17 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.29556548595428467, Train Loss: 0.29868364334106445
[32m[0514 06:01:17 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.29556581377983093, Train Loss: 0.29868099093437195
[32m[0514 06:01:17 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.2955661714076996, Train Loss: 0.2986784279346466
[32m[0514 06:01:17 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.29556652903556824, Train Loss: 0.29867589473724365
[32m[0514 06:01:17 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.2955669164657593, Train Loss: 0.29867324233055115
[32m[0514 06:01:17 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.2955673635005951, Train Loss: 0.2986707091331482
[32m[0514 06:01:17 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.2955677807331085, Train Loss: 0.29866811633110046
[32m[0514 06:01:17 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.2955682575702667, Train Loss: 0.29866552352905273
[32m[0514 06:01:17 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.29556867480278015, Train Loss: 0.2986629903316498
[32m[0514 06:01:17 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.29556921124458313, Train Loss: 0.29866039752960205
[32m[0514 06:01:17 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.29556968808174133, Train Loss: 0.2986578345298767
[32m[0514 06:01:17 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.2955701947212219, Train Loss: 0.298655241727829
[32m[0514 06:01:17 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.2955707609653473, Train Loss: 0.298652708530426
[32m[0514 06:01:17 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.29557129740715027, Train Loss: 0.2986501455307007
[32m[0514 06:01:17 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.295571893453598, Train Loss: 0.29864755272865295
[32m[0514 06:01:17 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.2955724895000458, Train Loss: 0.2986450493335724
[32m[0514 06:01:17 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.2955731451511383, Train Loss: 0.29864248633384705
[32m[0514 06:01:18 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.29557377099990845, Train Loss: 0.2986399233341217
[32m[0514 06:01:18 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.295574426651001, Train Loss: 0.29863736033439636
[32m[0514 06:01:18 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.2955750823020935, Train Loss: 0.2986348569393158
[32m[0514 06:01:18 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.2955757677555084, Train Loss: 0.29863232374191284
[32m[0514 06:01:18 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.29557642340660095, Train Loss: 0.2986297905445099
[32m[0514 06:01:18 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.29557716846466064, Train Loss: 0.29862722754478455
[32m[0514 06:01:18 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.29557791352272034, Train Loss: 0.2986246943473816
[32m[0514 06:01:18 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.29557865858078003, Train Loss: 0.29862216114997864
[32m[0514 06:01:18 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.29557937383651733, Train Loss: 0.29861965775489807
[32m[0514 06:01:18 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.2955802083015442, Train Loss: 0.29861709475517273
[32m[0514 06:01:18 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.29558098316192627, Train Loss: 0.2986145615577698
[32m[0514 06:01:18 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.2955818474292755, Train Loss: 0.2986120581626892
[32m[0514 06:01:18 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.29558265209198, Train Loss: 0.29860952496528625
[32m[0514 06:01:18 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.29558348655700684, Train Loss: 0.2986069917678833
[32m[0514 06:01:18 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.2955843508243561, Train Loss: 0.29860448837280273
[32m[0514 06:01:18 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.2955852448940277, Train Loss: 0.2986019551753998
[32m[0514 06:01:18 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.29558613896369934, Train Loss: 0.2985994219779968
[32m[0514 06:01:18 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.29558709263801575, Train Loss: 0.29859694838523865
[32m[0514 06:01:18 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.29558801651000977, Train Loss: 0.2985944449901581
[32m[0514 06:01:18 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.2955889403820038, Train Loss: 0.2985919415950775
[32m[0514 06:01:19 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.2955898642539978, Train Loss: 0.29858940839767456
[32m[0514 06:01:19 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.2955908477306366, Train Loss: 0.298586905002594
[32m[0514 06:01:19 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.29559189081192017, Train Loss: 0.2985844314098358
[32m[0514 06:01:19 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.29559287428855896, Train Loss: 0.29858192801475525
[32m[0514 06:01:19 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.29559391736984253, Train Loss: 0.2985793948173523
[32m[0514 06:01:19 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.2955949306488037, Train Loss: 0.2985769212245941
[32m[0514 06:01:19 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.2955959439277649, Train Loss: 0.29857438802719116
[32m[0514 06:01:19 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.29559704661369324, Train Loss: 0.298571914434433
[32m[0514 06:01:19 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.2955981194972992, Train Loss: 0.2985694110393524
[32m[0514 06:01:19 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.29559919238090515, Train Loss: 0.29856690764427185
[32m[0514 06:01:19 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.2956003248691559, Train Loss: 0.2985644042491913
[32m[0514 06:01:19 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.2956014573574066, Train Loss: 0.2985619306564331
[32m[0514 06:01:19 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.29560258984565735, Train Loss: 0.2985594570636749
[32m[0514 06:01:19 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.2956036925315857, Train Loss: 0.298556923866272
[32m[0514 06:01:19 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.2956048846244812, Train Loss: 0.2985544502735138
[32m[0514 06:01:19 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.2956060767173767, Train Loss: 0.2985519766807556
[32m[0514 06:01:19 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.29560720920562744, Train Loss: 0.29854947328567505
[32m[0514 06:01:19 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.2956084609031677, Train Loss: 0.2985469698905945
[32m[0514 06:01:19 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.2956096827983856, Train Loss: 0.2985445559024811
[32m[0514 06:01:19 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.29561087489128113, Train Loss: 0.2985420525074005
[32m[0514 06:01:20 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.295612096786499, Train Loss: 0.29853957891464233
[32m[0514 06:01:20 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.2956133484840393, Train Loss: 0.29853707551956177
[32m[0514 06:01:20 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.295614629983902, Train Loss: 0.2985346019268036
[32m[0514 06:01:20 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.29561591148376465, Train Loss: 0.298532098531723
[32m[0514 06:01:20 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.2956171929836273, Train Loss: 0.29852965474128723
[32m[0514 06:01:20 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.29561847448349, Train Loss: 0.29852721095085144
[32m[0514 06:01:20 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.29561981558799744, Train Loss: 0.29852473735809326
[32m[0514 06:01:20 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.2956211268901825, Train Loss: 0.29852229356765747
[32m[0514 06:01:20 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.29562246799468994, Train Loss: 0.2985197603702545
[32m[0514 06:01:20 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.2956238090991974, Train Loss: 0.2985173165798187
[32m[0514 06:01:20 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.2956251800060272, Train Loss: 0.29851487278938293
[32m[0514 06:01:20 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.29562655091285706, Train Loss: 0.29851236939430237
[32m[0514 06:01:20 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.2956279516220093, Train Loss: 0.2985099256038666
[32m[0514 06:01:20 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.2956293225288391, Train Loss: 0.2985075116157532
[32m[0514 06:01:20 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.29563072323799133, Train Loss: 0.2985050082206726
[32m[0514 06:01:20 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.29563212394714355, Train Loss: 0.2985025644302368
[32m[0514 06:01:20 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.29563358426094055, Train Loss: 0.29850006103515625
[32m[0514 06:01:20 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.29563504457473755, Train Loss: 0.29849764704704285
[32m[0514 06:01:20 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.2956364154815674, Train Loss: 0.29849520325660706
[32m[0514 06:01:20 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.29563793540000916, Train Loss: 0.2984927296638489
[32m[0514 06:01:20 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.2956393361091614, Train Loss: 0.2984902560710907
[32m[0514 06:01:21 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.29564085602760315, Train Loss: 0.2984878122806549
[32m[0514 06:01:21 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.29564234614372253, Train Loss: 0.2984853684902191
[32m[0514 06:01:21 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.2956438660621643, Train Loss: 0.2984829545021057
[32m[0514 06:01:21 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.2956453561782837, Train Loss: 0.2984805107116699
[32m[0514 06:01:21 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.29564690589904785, Train Loss: 0.29847806692123413
[32m[0514 06:01:21 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.29564839601516724, Train Loss: 0.29847562313079834
[32m[0514 06:01:21 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.2956499457359314, Train Loss: 0.29847320914268494
[32m[0514 06:01:21 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.29565149545669556, Train Loss: 0.29847070574760437
[32m[0514 06:01:21 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.2956530451774597, Train Loss: 0.2984682619571686
[32m[0514 06:01:21 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.29565468430519104, Train Loss: 0.2984658181667328
[32m[0514 06:01:21 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.2956562042236328, Train Loss: 0.2984634041786194
[32m[0514 06:01:21 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.29565778374671936, Train Loss: 0.29846101999282837
[32m[0514 06:01:21 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.2956593930721283, Train Loss: 0.2984585762023926
[32m[0514 06:01:21 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.29566100239753723, Train Loss: 0.2984561622142792
[32m[0514 06:01:21 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.2956625819206238, Train Loss: 0.2984537184238434
[32m[0514 06:01:21 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.2956641912460327, Train Loss: 0.2984512746334076
[32m[0514 06:01:21 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.2956658601760864, Train Loss: 0.2984488606452942
[32m[0514 06:01:21 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.29566746950149536, Train Loss: 0.2984464466571808
[32m[0514 06:01:21 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.2956691384315491, Train Loss: 0.298444002866745
[32m[0514 06:01:21 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.2956708073616028, Train Loss: 0.2984415590763092
[32m[0514 06:01:21 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.2956724464893341, Train Loss: 0.2984391450881958
[32m[0514 06:01:22 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.2956741154193878, Train Loss: 0.2984367311000824
[32m[0514 06:01:22 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.2956758141517639, Train Loss: 0.2984342873096466
[32m[0514 06:01:22 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.2956774830818176, Train Loss: 0.298431932926178
[32m[0514 06:01:22 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.2956791818141937, Train Loss: 0.2984294891357422
[32m[0514 06:01:22 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.2956808805465698, Train Loss: 0.29842710494995117
[32m[0514 06:01:22 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.2956825792789459, Train Loss: 0.29842472076416016
[32m[0514 06:01:22 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.2956843078136444, Train Loss: 0.298422247171402
[32m[0514 06:01:22 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.2956859767436981, Train Loss: 0.29841989278793335
[32m[0514 06:01:22 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.295687735080719, Train Loss: 0.29841744899749756
[32m[0514 06:01:22 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.2956894636154175, Train Loss: 0.29841506481170654
[32m[0514 06:01:22 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.29569122195243835, Train Loss: 0.2984126806259155
[32m[0514 06:01:22 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.29569295048713684, Train Loss: 0.2984102666378021
[32m[0514 06:01:22 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.2956947684288025, Train Loss: 0.2984078824520111
[32m[0514 06:01:22 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.295696496963501, Train Loss: 0.2984054982662201
[32m[0514 06:01:22 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.29569825530052185, Train Loss: 0.2984030544757843
[32m[0514 06:01:22 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.2957000732421875, Train Loss: 0.2984007000923157
[32m[0514 06:01:22 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.295701801776886, Train Loss: 0.29839831590652466
[32m[0514 06:01:22 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.29570358991622925, Train Loss: 0.29839593172073364
[32m[0514 06:01:22 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.2957053780555725, Train Loss: 0.29839351773262024
[32m[0514 06:01:22 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.29570719599723816, Train Loss: 0.2983911633491516
[32m[0514 06:01:22 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.2957090139389038, Train Loss: 0.2983887791633606
[32m[0514 06:01:22 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.29571080207824707, Train Loss: 0.2983863651752472
[32m[0514 06:01:23 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.2957126796245575, Train Loss: 0.2983839809894562
[32m[0514 06:01:23 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.29571443796157837, Train Loss: 0.29838162660598755
[32m[0514 06:01:23 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.2957162857055664, Train Loss: 0.29837921261787415
[32m[0514 06:01:23 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.29571810364723206, Train Loss: 0.2983768582344055
[32m[0514 06:01:23 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.2957199215888977, Train Loss: 0.2983744740486145
[32m[0514 06:01:23 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.29572179913520813, Train Loss: 0.29837214946746826
[32m[0514 06:01:23 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.29572364687919617, Train Loss: 0.29836973547935486
[32m[0514 06:01:23 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.2957255244255066, Train Loss: 0.29836738109588623
[32m[0514 06:01:23 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.29572734236717224, Train Loss: 0.2983650267124176
[32m[0514 06:01:23 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.29572921991348267, Train Loss: 0.29836270213127136
[32m[0514 06:01:23 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.2957310974597931, Train Loss: 0.29836028814315796
[32m[0514 06:01:23 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.29573294520378113, Train Loss: 0.29835793375968933
[32m[0514 06:01:23 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.29573479294776917, Train Loss: 0.2983556091785431
[32m[0514 06:01:23 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.295736700296402, Train Loss: 0.2983532249927521
[32m[0514 06:01:23 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.2957386076450348, Train Loss: 0.29835087060928345
[32m[0514 06:01:23 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.2957404553890228, Train Loss: 0.2983485162258148
[32m[0514 06:01:23 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.29574236273765564, Train Loss: 0.2983461618423462
[32m[0514 06:01:23 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.29574427008628845, Train Loss: 0.29834383726119995
[32m[0514 06:01:23 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.29574620723724365, Train Loss: 0.2983414828777313
[32m[0514 06:01:23 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.2957480847835541, Train Loss: 0.2983391582965851
[32m[0514 06:01:24 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.2957500219345093, Train Loss: 0.29833680391311646
[32m[0514 06:01:24 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.2957518994808197, Train Loss: 0.2983344793319702
[32m[0514 06:01:24 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.2957538366317749, Train Loss: 0.298332154750824
[32m[0514 06:01:24 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.2957557141780853, Train Loss: 0.29832983016967773
[32m[0514 06:01:24 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.2957576513290405, Train Loss: 0.2983274757862091
[32m[0514 06:01:24 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.2957595884799957, Train Loss: 0.29832515120506287
[32m[0514 06:01:24 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.2957615256309509, Train Loss: 0.2983228266239166
[32m[0514 06:01:24 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.2957634925842285, Train Loss: 0.29832056164741516
[32m[0514 06:01:24 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.29576539993286133, Train Loss: 0.29831811785697937
[32m[0514 06:01:24 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.29576733708381653, Train Loss: 0.2983158528804779
[32m[0514 06:01:24 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.29576924443244934, Train Loss: 0.29831355810165405
[32m[0514 06:01:24 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.29577121138572693, Train Loss: 0.2983112335205078
[32m[0514 06:01:24 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.2957731783390045, Train Loss: 0.2983088791370392
[32m[0514 06:01:24 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.2957751154899597, Train Loss: 0.2983066439628601
[32m[0514 06:01:24 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.2957770824432373, Train Loss: 0.2983042597770691
[32m[0514 06:01:24 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.2957790195941925, Train Loss: 0.29830202460289
[32m[0514 06:01:24 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.2957810163497925, Train Loss: 0.2982996702194214
[32m[0514 06:01:24 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.2957829236984253, Train Loss: 0.29829737544059753
[32m[0514 06:01:24 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.2957848906517029, Train Loss: 0.2982950806617737
[32m[0514 06:01:24 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.29578688740730286, Train Loss: 0.29829275608062744
[32m[0514 06:01:24 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.29578885436058044, Train Loss: 0.2982904613018036
[32m[0514 06:01:25 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.29579082131385803, Train Loss: 0.2982881963253021
[32m[0514 06:01:25 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.2957927882671356, Train Loss: 0.29828590154647827
[32m[0514 06:01:25 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.2957947552204132, Train Loss: 0.2982836067676544
[32m[0514 06:01:25 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.29579678177833557, Train Loss: 0.29828131198883057
[32m[0514 06:01:25 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.29579874873161316, Train Loss: 0.2982790172100067
[32m[0514 06:01:25 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.29580071568489075, Train Loss: 0.29827675223350525
[32m[0514 06:01:25 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.2958027124404907, Train Loss: 0.2982744574546814
[32m[0514 06:01:25 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.2958046793937683, Train Loss: 0.29827219247817993
[32m[0514 06:01:25 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.2958066463470459, Train Loss: 0.2982698976993561
[32m[0514 06:01:25 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.29580867290496826, Train Loss: 0.298267662525177
[32m[0514 06:01:25 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.29581063985824585, Train Loss: 0.29826536774635315
[32m[0514 06:01:25 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.2958126366138458, Train Loss: 0.2982631027698517
[32m[0514 06:01:25 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.2958146631717682, Train Loss: 0.2982608377933502
[32m[0514 06:01:25 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.2958166301250458, Train Loss: 0.29825857281684875
[32m[0514 06:01:25 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.29581865668296814, Train Loss: 0.2982563078403473
[32m[0514 06:01:25 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.2958206236362457, Train Loss: 0.2982540726661682
[32m[0514 06:01:25 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.2958226203918457, Train Loss: 0.29825177788734436
[32m[0514 06:01:25 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.2958246171474457, Train Loss: 0.29824957251548767
[32m[0514 06:01:25 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.29582658410072327, Train Loss: 0.2982472777366638
[32m[0514 06:01:25 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.295828640460968, Train Loss: 0.29824504256248474
[32m[0514 06:01:26 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.295830637216568, Train Loss: 0.29824283719062805
[32m[0514 06:01:26 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.29583263397216797, Train Loss: 0.2982405424118042
[32m[0514 06:01:26 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.29583460092544556, Train Loss: 0.2982383072376251
[32m[0514 06:01:26 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.2958366870880127, Train Loss: 0.29823604226112366
[32m[0514 06:01:26 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.2958386540412903, Train Loss: 0.29823383688926697
[32m[0514 06:01:26 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.29584068059921265, Train Loss: 0.2982315719127655
[32m[0514 06:01:26 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.295842707157135, Train Loss: 0.2982293367385864
[32m[0514 06:01:26 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.2958446741104126, Train Loss: 0.29822713136672974
[32m[0514 06:01:26 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.29584673047065735, Train Loss: 0.29822486639022827
[32m[0514 06:01:26 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.2958487272262573, Train Loss: 0.2982226610183716
[32m[0514 06:01:26 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.2958507239818573, Train Loss: 0.2982204556465149
[32m[0514 06:01:26 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.2958527207374573, Train Loss: 0.2982181906700134
[32m[0514 06:01:26 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.295854777097702, Train Loss: 0.29821598529815674
[32m[0514 06:01:26 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.295856773853302, Train Loss: 0.29821380972862244
[32m[0514 06:01:26 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.29585883021354675, Train Loss: 0.29821157455444336
[32m[0514 06:01:26 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.29586076736450195, Train Loss: 0.2982093393802643
[32m[0514 06:01:26 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.2958628237247467, Train Loss: 0.29820716381073
[32m[0514 06:01:26 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.29586485028266907, Train Loss: 0.2982049286365509
[32m[0514 06:01:26 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.29586684703826904, Train Loss: 0.2982027232646942
[32m[0514 06:01:26 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.2958688735961914, Train Loss: 0.2982005476951599
[32m[0514 06:01:26 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.29587090015411377, Train Loss: 0.29819831252098083
[32m[0514 06:01:27 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.29587289690971375, Train Loss: 0.29819610714912415
[32m[0514 06:01:27 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.2958748936653137, Train Loss: 0.29819393157958984
[32m[0514 06:01:27 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.2958769202232361, Train Loss: 0.29819175601005554
[32m[0514 06:01:27 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.29587894678115845, Train Loss: 0.29818955063819885
[32m[0514 06:01:27 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.2958809435367584, Train Loss: 0.29818737506866455
[32m[0514 06:01:27 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.2958829402923584, Train Loss: 0.29818516969680786
[32m[0514 06:01:27 @mbmf_sampler.py:98][0m Finished 9th episode
[32m[0514 06:01:27 @mbmf_sampler.py:102][0m 1809 timesteps from 9 episodes collected
[32m[0514 06:06:59 @mbmf_trainer.py:160][0m Mean reward: -1176.9273023668131
[32m[0514 06:06:59 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.31688520312309265, Train Loss: 0.29474756121635437
[32m[0514 06:06:59 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.3169420063495636, Train Loss: 0.29471009969711304
[32m[0514 06:06:59 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.3169715106487274, Train Loss: 0.29468631744384766
[32m[0514 06:06:59 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.31698834896087646, Train Loss: 0.2946704924106598
[32m[0514 06:06:59 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.31700125336647034, Train Loss: 0.29465702176094055
[32m[0514 06:06:59 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.31701332330703735, Train Loss: 0.2946453094482422
[32m[0514 06:06:59 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.31702515482902527, Train Loss: 0.2946348190307617
[32m[0514 06:06:59 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.31703662872314453, Train Loss: 0.2946251928806305
[32m[0514 06:06:59 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.317047655582428, Train Loss: 0.2946164011955261
[32m[0514 06:06:59 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.31705835461616516, Train Loss: 0.2946082353591919
[32m[0514 06:06:59 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.3170686364173889, Train Loss: 0.2946006953716278
[32m[0514 06:06:59 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.317078560590744, Train Loss: 0.29459360241889954
[32m[0514 06:06:59 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.31708812713623047, Train Loss: 0.29458698630332947
[32m[0514 06:07:00 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.31709736585617065, Train Loss: 0.2945806682109833
[32m[0514 06:07:00 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.31710630655288696, Train Loss: 0.2945747375488281
[32m[0514 06:07:00 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.3171148896217346, Train Loss: 0.29456907510757446
[32m[0514 06:07:00 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.3171232342720032, Train Loss: 0.2945636212825775
[32m[0514 06:07:00 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.31713125109672546, Train Loss: 0.2945583760738373
[32m[0514 06:07:00 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.31713902950286865, Train Loss: 0.29455333948135376
[32m[0514 06:07:00 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.31714656949043274, Train Loss: 0.2945483922958374
[32m[0514 06:07:00 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.31715384125709534, Train Loss: 0.29454365372657776
[32m[0514 06:07:00 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.3171609342098236, Train Loss: 0.29453906416893005
[32m[0514 06:07:00 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.3171677887439728, Train Loss: 0.2945345938205719
[32m[0514 06:07:00 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.3171744644641876, Train Loss: 0.2945302128791809
[32m[0514 06:07:00 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.31718096137046814, Train Loss: 0.2945259213447571
[32m[0514 06:07:00 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.3171873092651367, Train Loss: 0.2945217192173004
[32m[0514 06:07:00 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.3171934485435486, Train Loss: 0.2945175766944885
[32m[0514 06:07:00 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.3171994090080261, Train Loss: 0.2945135831832886
[32m[0514 06:07:00 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.3172052800655365, Train Loss: 0.294509619474411
[32m[0514 06:07:00 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.31721100211143494, Train Loss: 0.2945057153701782
[32m[0514 06:07:01 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.31721657514572144, Train Loss: 0.2945018708705902
[32m[0514 06:07:01 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.3172220289707184, Train Loss: 0.29449811577796936
[32m[0514 06:07:01 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.31722739338874817, Train Loss: 0.2944943904876709
[32m[0514 06:07:01 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.317232608795166, Train Loss: 0.2944907248020172
[32m[0514 06:07:01 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.3172377645969391, Train Loss: 0.2944870889186859
[32m[0514 06:07:01 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.3172428011894226, Train Loss: 0.2944835424423218
[32m[0514 06:07:01 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.3172477185726166, Train Loss: 0.29447999596595764
[32m[0514 06:07:01 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.31725260615348816, Train Loss: 0.29447653889656067
[32m[0514 06:07:01 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.3172574043273926, Train Loss: 0.2944730818271637
[32m[0514 06:07:01 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.31726208329200745, Train Loss: 0.2944696247577667
[32m[0514 06:07:01 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.3172667324542999, Train Loss: 0.2944662570953369
[32m[0514 06:07:01 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.31727135181427, Train Loss: 0.2944629192352295
[32m[0514 06:07:01 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.31727588176727295, Train Loss: 0.29445958137512207
[32m[0514 06:07:01 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.3172803223133087, Train Loss: 0.2944563627243042
[32m[0514 06:07:01 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.3172846734523773, Train Loss: 0.29445308446884155
[32m[0514 06:07:01 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.3172890543937683, Train Loss: 0.2944498360157013
[32m[0514 06:07:02 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.31729331612586975, Train Loss: 0.2944466471672058
[32m[0514 06:07:02 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.3172975778579712, Train Loss: 0.2944435179233551
[32m[0514 06:07:02 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.31730183959007263, Train Loss: 0.294440358877182
[32m[0514 06:07:02 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.31730595231056213, Train Loss: 0.2944371998310089
[32m[0514 06:07:02 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.31731006503105164, Train Loss: 0.29443415999412537
[32m[0514 06:07:02 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.31731417775154114, Train Loss: 0.29443106055259705
[32m[0514 06:07:02 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.31731823086738586, Train Loss: 0.2944280505180359
[32m[0514 06:07:02 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.3173222243785858, Train Loss: 0.29442501068115234
[32m[0514 06:07:02 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.31732621788978577, Train Loss: 0.2944220006465912
[32m[0514 06:07:02 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.31733018159866333, Train Loss: 0.2944190204143524
[32m[0514 06:07:02 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.3173340857028961, Train Loss: 0.29441606998443604
[32m[0514 06:07:02 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.3173379600048065, Train Loss: 0.29441311955451965
[32m[0514 06:07:02 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.31734180450439453, Train Loss: 0.29441019892692566
[32m[0514 06:07:02 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.3173457086086273, Train Loss: 0.29440727829933167
[32m[0514 06:07:02 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.31734955310821533, Train Loss: 0.29440438747406006
[32m[0514 06:07:02 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.3173533082008362, Train Loss: 0.29440152645111084
[32m[0514 06:07:03 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.31735706329345703, Train Loss: 0.29439863562583923
[32m[0514 06:07:03 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.3173608183860779, Train Loss: 0.2943958044052124
[32m[0514 06:07:03 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.31736457347869873, Train Loss: 0.29439297318458557
[32m[0514 06:07:03 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.3173682689666748, Train Loss: 0.29439017176628113
[32m[0514 06:07:03 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.3173719346523285, Train Loss: 0.2943873703479767
[32m[0514 06:07:03 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.31737563014030457, Train Loss: 0.294384628534317
[32m[0514 06:07:03 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.31737926602363586, Train Loss: 0.29438185691833496
[32m[0514 06:07:03 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.31738293170928955, Train Loss: 0.2943790555000305
[32m[0514 06:07:03 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.31738656759262085, Train Loss: 0.29437634348869324
[32m[0514 06:07:03 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.31739017367362976, Train Loss: 0.29437360167503357
[32m[0514 06:07:03 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.31739377975463867, Train Loss: 0.2943708896636963
[32m[0514 06:07:03 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.3173973262310028, Train Loss: 0.294368177652359
[32m[0514 06:07:03 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.3174009323120117, Train Loss: 0.2943654954433441
[32m[0514 06:07:03 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.31740450859069824, Train Loss: 0.29436278343200684
[32m[0514 06:07:03 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.31740802526474, Train Loss: 0.29436013102531433
[32m[0514 06:07:03 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.3174115717411041, Train Loss: 0.2943575084209442
[32m[0514 06:07:04 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.3174150884151459, Train Loss: 0.2943548262119293
[32m[0514 06:07:04 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.31741863489151, Train Loss: 0.2943522334098816
[32m[0514 06:07:04 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.31742212176322937, Train Loss: 0.2943495810031891
[32m[0514 06:07:04 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.31742560863494873, Train Loss: 0.29434695839881897
[32m[0514 06:07:04 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.3174290955066681, Train Loss: 0.29434436559677124
[32m[0514 06:07:04 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.31743255257606506, Train Loss: 0.2943417727947235
[32m[0514 06:07:04 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.3174360394477844, Train Loss: 0.2943391799926758
[32m[0514 06:07:04 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.3174394965171814, Train Loss: 0.29433658719062805
[32m[0514 06:07:04 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.31744295358657837, Train Loss: 0.2943340241909027
[32m[0514 06:07:04 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.31744641065597534, Train Loss: 0.29433146119117737
[32m[0514 06:07:04 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.3174498677253723, Train Loss: 0.2943289279937744
[32m[0514 06:07:04 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.3174532651901245, Train Loss: 0.29432639479637146
[32m[0514 06:07:04 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.3174566924571991, Train Loss: 0.2943238317966461
[32m[0514 06:07:04 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.3174600899219513, Train Loss: 0.29432129859924316
[32m[0514 06:07:04 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.3174635171890259, Train Loss: 0.294318825006485
[32m[0514 06:07:04 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.3174669146537781, Train Loss: 0.2943163514137268
[32m[0514 06:07:04 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.31747034192085266, Train Loss: 0.29431381821632385
[32m[0514 06:07:05 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.31747373938560486, Train Loss: 0.2943113148212433
[32m[0514 06:07:05 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.31747710704803467, Train Loss: 0.2943088412284851
[32m[0514 06:07:05 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.31748050451278687, Train Loss: 0.29430636763572693
[32m[0514 06:07:05 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.3174838721752167, Train Loss: 0.29430386424064636
[32m[0514 06:07:05 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.31748726963996887, Train Loss: 0.29430142045021057
[32m[0514 06:07:05 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.3174906075000763, Train Loss: 0.2942989766597748
[32m[0514 06:07:05 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.3174939751625061, Train Loss: 0.294296532869339
[32m[0514 06:07:05 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.3174973428249359, Train Loss: 0.2942940592765808
[32m[0514 06:07:05 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.3175007104873657, Train Loss: 0.2942916750907898
[32m[0514 06:07:05 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.31750404834747314, Train Loss: 0.294289231300354
[32m[0514 06:07:05 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.31750738620758057, Train Loss: 0.2942867875099182
[32m[0514 06:07:05 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.3175106942653656, Train Loss: 0.2942844331264496
[32m[0514 06:07:05 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.317514032125473, Train Loss: 0.2942819595336914
[32m[0514 06:07:05 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.31751736998558044, Train Loss: 0.2942796051502228
[32m[0514 06:07:05 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.31752070784568787, Train Loss: 0.29427722096443176
[32m[0514 06:07:06 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.3175240457057953, Train Loss: 0.29427480697631836
[32m[0514 06:07:06 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.3175273835659027, Train Loss: 0.29427245259284973
[32m[0514 06:07:06 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.31753066182136536, Train Loss: 0.2942700684070587
[32m[0514 06:07:06 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.31753405928611755, Train Loss: 0.2942676842212677
[32m[0514 06:07:06 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.3175373077392578, Train Loss: 0.29426535964012146
[32m[0514 06:07:06 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.31754064559936523, Train Loss: 0.29426297545433044
[32m[0514 06:07:06 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.31754395365715027, Train Loss: 0.29426059126853943
[32m[0514 06:07:06 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.3175472319126129, Train Loss: 0.2942582368850708
[32m[0514 06:07:06 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.31755056977272034, Train Loss: 0.29425594210624695
[32m[0514 06:07:06 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.3175538182258606, Train Loss: 0.2942535877227783
[32m[0514 06:07:06 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.31755712628364563, Train Loss: 0.29425129294395447
[32m[0514 06:07:06 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.31756046414375305, Train Loss: 0.29424893856048584
[32m[0514 06:07:06 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.3175637125968933, Train Loss: 0.294246643781662
[32m[0514 06:07:06 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.31756702065467834, Train Loss: 0.29424431920051575
[32m[0514 06:07:06 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.317570298910141, Train Loss: 0.2942419946193695
[32m[0514 06:07:07 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.31757354736328125, Train Loss: 0.29423969984054565
[32m[0514 06:07:07 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.3175767958164215, Train Loss: 0.2942374050617218
[32m[0514 06:07:07 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.31758013367652893, Train Loss: 0.29423514008522034
[32m[0514 06:07:07 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.3175833821296692, Train Loss: 0.2942328453063965
[32m[0514 06:07:07 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.31758666038513184, Train Loss: 0.294230580329895
[32m[0514 06:07:07 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.31758996844291687, Train Loss: 0.29422828555107117
[32m[0514 06:07:07 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.31759321689605713, Train Loss: 0.2942260205745697
[32m[0514 06:07:07 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.3175964653491974, Train Loss: 0.29422375559806824
[32m[0514 06:07:07 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.31759974360466003, Train Loss: 0.2942214906215668
[32m[0514 06:07:07 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.3176029622554779, Train Loss: 0.2942192554473877
[32m[0514 06:07:07 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.31760627031326294, Train Loss: 0.29421699047088623
[32m[0514 06:07:07 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.3176094591617584, Train Loss: 0.29421475529670715
[32m[0514 06:07:07 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.31761273741722107, Train Loss: 0.2942124903202057
[32m[0514 06:07:07 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.3176160156726837, Train Loss: 0.2942102551460266
[32m[0514 06:07:07 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.3176191747188568, Train Loss: 0.29420801997184753
[32m[0514 06:07:07 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.31762245297431946, Train Loss: 0.29420584440231323
[32m[0514 06:07:08 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.3176257312297821, Train Loss: 0.29420360922813416
[32m[0514 06:07:08 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.3176289498806, Train Loss: 0.2942013740539551
[32m[0514 06:07:08 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.31763219833374023, Train Loss: 0.29419922828674316
[32m[0514 06:07:08 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.3176354169845581, Train Loss: 0.2941969931125641
[32m[0514 06:07:08 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.317638635635376, Train Loss: 0.2941947877407074
[32m[0514 06:07:08 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.31764185428619385, Train Loss: 0.2941925525665283
[32m[0514 06:07:08 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.3176451027393341, Train Loss: 0.294190376996994
[32m[0514 06:07:08 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.317648321390152, Train Loss: 0.2941882014274597
[32m[0514 06:07:08 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.31765154004096985, Train Loss: 0.2941860258579254
[32m[0514 06:07:08 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.3176547586917877, Train Loss: 0.2941838502883911
[32m[0514 06:07:08 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.3176579475402832, Train Loss: 0.2941816747188568
[32m[0514 06:07:08 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.3176611363887787, Train Loss: 0.2941795289516449
[32m[0514 06:07:08 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.31766441464424133, Train Loss: 0.2941773235797882
[32m[0514 06:07:08 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.31766757369041443, Train Loss: 0.2941751480102539
[32m[0514 06:07:08 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.3176707923412323, Train Loss: 0.2941729724407196
[32m[0514 06:07:08 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.3176739811897278, Train Loss: 0.2941707968711853
[32m[0514 06:07:08 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.31767717003822327, Train Loss: 0.2941686511039734
[32m[0514 06:07:09 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.31768035888671875, Train Loss: 0.2941665053367615
[32m[0514 06:07:09 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.31768354773521423, Train Loss: 0.29416438937187195
[32m[0514 06:07:09 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.3176867365837097, Train Loss: 0.29416221380233765
[32m[0514 06:07:09 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.3176898658275604, Train Loss: 0.2941601276397705
[32m[0514 06:07:09 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.3176930844783783, Train Loss: 0.294158011674881
[32m[0514 06:07:09 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.3176962733268738, Train Loss: 0.2941558361053467
[32m[0514 06:07:09 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.31769946217536926, Train Loss: 0.29415377974510193
[32m[0514 06:07:09 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.31770259141921997, Train Loss: 0.29415163397789
[32m[0514 06:07:09 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.31770578026771545, Train Loss: 0.2941495478153229
[32m[0514 06:07:09 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.31770893931388855, Train Loss: 0.29414743185043335
[32m[0514 06:07:09 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.3177121579647064, Train Loss: 0.29414528608322144
[32m[0514 06:07:09 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.31771522760391235, Train Loss: 0.2941431999206543
[32m[0514 06:07:09 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.31771838665008545, Train Loss: 0.29414108395576477
[32m[0514 06:07:09 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.31772157549858093, Train Loss: 0.29413899779319763
[32m[0514 06:07:09 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.31772470474243164, Train Loss: 0.2941369116306305
[32m[0514 06:07:09 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.31772786378860474, Train Loss: 0.29413485527038574
[32m[0514 06:07:10 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.31773099303245544, Train Loss: 0.2941327691078186
[32m[0514 06:07:10 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.31773415207862854, Train Loss: 0.2941306531429291
[32m[0514 06:07:10 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.31773728132247925, Train Loss: 0.2941286265850067
[32m[0514 06:07:10 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.31774041056632996, Train Loss: 0.2941265106201172
[32m[0514 06:07:10 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.3177435100078583, Train Loss: 0.2941244840621948
[32m[0514 06:07:10 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.3177466094493866, Train Loss: 0.29412245750427246
[32m[0514 06:07:10 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.3177497684955597, Train Loss: 0.2941203713417053
[32m[0514 06:07:10 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.3177528977394104, Train Loss: 0.29411831498146057
[32m[0514 06:07:10 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.3177560269832611, Train Loss: 0.29411622881889343
[32m[0514 06:07:10 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.31775909662246704, Train Loss: 0.29411420226097107
[32m[0514 06:07:10 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.31776219606399536, Train Loss: 0.2941121459007263
[32m[0514 06:07:10 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.31776532530784607, Train Loss: 0.29411011934280396
[32m[0514 06:07:10 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.3177684247493744, Train Loss: 0.2941080331802368
[32m[0514 06:07:10 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.3177715241909027, Train Loss: 0.29410600662231445
[32m[0514 06:07:10 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.31777462363243103, Train Loss: 0.2941040098667145
[32m[0514 06:07:10 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.31777769327163696, Train Loss: 0.2941019535064697
[32m[0514 06:07:11 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.3177807629108429, Train Loss: 0.29409995675086975
[32m[0514 06:07:11 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.31778383255004883, Train Loss: 0.294097900390625
[32m[0514 06:07:11 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.31778693199157715, Train Loss: 0.294095903635025
[32m[0514 06:07:11 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.3177900016307831, Train Loss: 0.29409387707710266
[32m[0514 06:07:11 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.317793071269989, Train Loss: 0.2940918505191803
[32m[0514 06:07:11 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.31779617071151733, Train Loss: 0.2940898835659027
[32m[0514 06:07:11 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.31779924035072327, Train Loss: 0.29408782720565796
[32m[0514 06:07:11 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.3178022503852844, Train Loss: 0.29408586025238037
[32m[0514 06:07:11 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.31780532002449036, Train Loss: 0.294083833694458
[32m[0514 06:07:11 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.3178083598613739, Train Loss: 0.29408180713653564
[32m[0514 06:07:11 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.31781142950057983, Train Loss: 0.29407986998558044
[32m[0514 06:07:11 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.3178144693374634, Train Loss: 0.29407787322998047
[32m[0514 06:07:11 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.3178175389766693, Train Loss: 0.2940758764743805
[32m[0514 06:07:11 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.31782054901123047, Train Loss: 0.2940739393234253
[32m[0514 06:07:11 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.317823588848114, Train Loss: 0.29407191276550293
[32m[0514 06:07:11 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.31782662868499756, Train Loss: 0.29406994581222534
[32m[0514 06:07:11 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.3178296387195587, Train Loss: 0.29406794905662537
[32m[0514 06:07:12 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.31783267855644226, Train Loss: 0.29406604170799255
[32m[0514 06:07:12 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.31783565878868103, Train Loss: 0.2940640449523926
[32m[0514 06:07:12 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.3178386688232422, Train Loss: 0.2940620481967926
[32m[0514 06:07:12 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.31784167885780334, Train Loss: 0.2940601110458374
[32m[0514 06:07:12 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.3178446590900421, Train Loss: 0.2940581440925598
[32m[0514 06:07:12 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.31784769892692566, Train Loss: 0.2940561771392822
[32m[0514 06:07:12 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.31785064935684204, Train Loss: 0.2940542697906494
[32m[0514 06:07:12 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.3178536891937256, Train Loss: 0.2940523028373718
[32m[0514 06:07:12 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.31785669922828674, Train Loss: 0.29405033588409424
[32m[0514 06:07:12 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.3178596794605255, Train Loss: 0.29404839873313904
[32m[0514 06:07:12 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.3178626298904419, Train Loss: 0.29404643177986145
[32m[0514 06:07:12 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.31786561012268066, Train Loss: 0.294044554233551
[32m[0514 06:07:12 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.31786859035491943, Train Loss: 0.29404258728027344
[32m[0514 06:07:12 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.3178716003894806, Train Loss: 0.29404065012931824
[32m[0514 06:07:12 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.3178744912147522, Train Loss: 0.2940387427806854
[32m[0514 06:07:12 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.31787750124931335, Train Loss: 0.2940368354320526
[32m[0514 06:07:13 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.31788042187690735, Train Loss: 0.294034868478775
[32m[0514 06:07:13 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.3178834021091461, Train Loss: 0.2940329909324646
[32m[0514 06:07:13 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.3178863227367401, Train Loss: 0.2940310537815094
[32m[0514 06:07:13 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.31788933277130127, Train Loss: 0.2940291464328766
[32m[0514 06:07:13 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.3178922235965729, Train Loss: 0.2940272092819214
[32m[0514 06:07:13 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.31789517402648926, Train Loss: 0.29402533173561096
[32m[0514 06:07:13 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.31789809465408325, Train Loss: 0.29402342438697815
[32m[0514 06:07:13 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.31790104508399963, Train Loss: 0.29402151703834534
[32m[0514 06:07:13 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.31790393590927124, Train Loss: 0.2940196096897125
[32m[0514 06:07:13 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.31790691614151, Train Loss: 0.2940177023410797
[32m[0514 06:07:13 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.3179098069667816, Train Loss: 0.2940158247947693
[32m[0514 06:07:13 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.31791266798973083, Train Loss: 0.2940139174461365
[32m[0514 06:07:13 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.31791555881500244, Train Loss: 0.29401203989982605
[32m[0514 06:07:13 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.31791847944259644, Train Loss: 0.294010192155838
[32m[0514 06:07:13 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.31792137026786804, Train Loss: 0.2940083146095276
[32m[0514 06:07:13 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.3179243206977844, Train Loss: 0.29400634765625
[32m[0514 06:07:14 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.3179272413253784, Train Loss: 0.29400449991226196
[32m[0514 06:07:14 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.31793007254600525, Train Loss: 0.29400262236595154
[32m[0514 06:07:14 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.31793296337127686, Train Loss: 0.2940007746219635
[32m[0514 06:07:14 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.3179358243942261, Train Loss: 0.2939988970756531
[32m[0514 06:07:14 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.3179387152194977, Train Loss: 0.29399704933166504
[32m[0514 06:07:14 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.3179415762424469, Train Loss: 0.2939951717853546
[32m[0514 06:07:14 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.3179444372653961, Train Loss: 0.2939932942390442
[32m[0514 06:07:14 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.3179473280906677, Train Loss: 0.29399141669273376
[32m[0514 06:07:14 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.31795018911361694, Train Loss: 0.2939895987510681
[32m[0514 06:07:14 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.3179530203342438, Train Loss: 0.2939877510070801
[32m[0514 06:07:14 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.317955881357193, Train Loss: 0.29398590326309204
[32m[0514 06:07:14 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.3179587125778198, Train Loss: 0.293984055519104
[32m[0514 06:07:14 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.31796154379844666, Train Loss: 0.2939821481704712
[32m[0514 06:07:14 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.3179643750190735, Train Loss: 0.29398033022880554
[32m[0514 06:07:14 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.3179672360420227, Train Loss: 0.2939785122871399
[32m[0514 06:07:14 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.31797006726264954, Train Loss: 0.29397669434547424
[32m[0514 06:07:14 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.3179728388786316, Train Loss: 0.2939748167991638
[32m[0514 06:07:15 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.3179756999015808, Train Loss: 0.29397305846214294
[32m[0514 06:07:15 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.31797853112220764, Train Loss: 0.29397115111351013
[32m[0514 06:07:15 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.3179813325405121, Train Loss: 0.2939693033695221
[32m[0514 06:07:15 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.31798413395881653, Train Loss: 0.29396748542785645
[32m[0514 06:07:15 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.31798693537712097, Train Loss: 0.2939656972885132
[32m[0514 06:07:15 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.3179897367954254, Train Loss: 0.29396384954452515
[32m[0514 06:07:15 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.31799253821372986, Train Loss: 0.2939620614051819
[32m[0514 06:07:15 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.3179952800273895, Train Loss: 0.29396018385887146
[32m[0514 06:07:15 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.31799808144569397, Train Loss: 0.2939583957195282
[32m[0514 06:07:15 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.3180008828639984, Train Loss: 0.29395657777786255
[32m[0514 06:07:15 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.31800368428230286, Train Loss: 0.2939547598361969
[32m[0514 06:07:15 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.31800639629364014, Train Loss: 0.293953001499176
[32m[0514 06:07:15 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.3180091679096222, Train Loss: 0.2939511835575104
[32m[0514 06:07:15 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.31801193952560425, Train Loss: 0.2939493954181671
[32m[0514 06:07:15 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.3180147409439087, Train Loss: 0.29394757747650146
[32m[0514 06:07:16 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.31801745295524597, Train Loss: 0.2939457893371582
[32m[0514 06:07:16 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.318020224571228, Train Loss: 0.29394397139549255
[32m[0514 06:07:16 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.3180229365825653, Train Loss: 0.2939422130584717
[32m[0514 06:07:16 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.31802570819854736, Train Loss: 0.2939404249191284
[32m[0514 06:07:16 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.31802845001220703, Train Loss: 0.29393863677978516
[32m[0514 06:07:16 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.3180311620235443, Train Loss: 0.2939368188381195
[32m[0514 06:07:16 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.318033903837204, Train Loss: 0.29393506050109863
[32m[0514 06:07:16 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.31803661584854126, Train Loss: 0.29393327236175537
[32m[0514 06:07:16 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.31803932785987854, Train Loss: 0.2939315140247345
[32m[0514 06:07:16 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.3180420696735382, Train Loss: 0.29392969608306885
[32m[0514 06:07:16 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.3180447816848755, Train Loss: 0.293927937746048
[32m[0514 06:07:16 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.31804749369621277, Train Loss: 0.2939261496067047
[32m[0514 06:07:16 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.3180501461029053, Train Loss: 0.2939244210720062
[32m[0514 06:07:16 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.31805288791656494, Train Loss: 0.29392263293266296
[32m[0514 06:07:16 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.31805554032325745, Train Loss: 0.2939209043979645
[32m[0514 06:07:16 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.3180582523345947, Train Loss: 0.2939191162586212
[32m[0514 06:07:17 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.318060964345932, Train Loss: 0.29391738772392273
[32m[0514 06:07:17 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.3180635869503021, Train Loss: 0.29391559958457947
[32m[0514 06:07:17 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.3180662989616394, Train Loss: 0.293913871049881
[32m[0514 06:07:17 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.3180689513683319, Train Loss: 0.2939121127128601
[32m[0514 06:07:17 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.3180716335773468, Train Loss: 0.29391035437583923
[32m[0514 06:07:17 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.3180742859840393, Train Loss: 0.29390859603881836
[32m[0514 06:07:17 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.3180769681930542, Train Loss: 0.29390689730644226
[32m[0514 06:07:17 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.3180796205997467, Train Loss: 0.293905109167099
[32m[0514 06:07:17 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.3180822730064392, Train Loss: 0.2939034104347229
[32m[0514 06:07:17 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.3180848956108093, Train Loss: 0.29390159249305725
[32m[0514 06:07:17 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.31808754801750183, Train Loss: 0.29389989376068115
[32m[0514 06:07:17 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.31809020042419434, Train Loss: 0.29389819502830505
[32m[0514 06:07:17 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.3180927634239197, Train Loss: 0.2938964366912842
[32m[0514 06:07:18 @mbmf_sampler.py:98][0m Finished 9th episode
[32m[0514 06:07:18 @mbmf_sampler.py:102][0m 1809 timesteps from 9 episodes collected
[32m[0514 06:12:17 @mbmf_trainer.py:160][0m Mean reward: -1199.431330750596
[32m[0514 06:12:17 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.3011898696422577, Train Loss: 0.2965639531612396
[32m[0514 06:12:17 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.3012099862098694, Train Loss: 0.29650774598121643
[32m[0514 06:12:17 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.30128663778305054, Train Loss: 0.29648229479789734
[32m[0514 06:12:17 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.30134016275405884, Train Loss: 0.29646167159080505
[32m[0514 06:12:17 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.3013889193534851, Train Loss: 0.29644474387168884
[32m[0514 06:12:17 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.30142948031425476, Train Loss: 0.2964305579662323
[32m[0514 06:12:17 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.30146318674087524, Train Loss: 0.29641860723495483
[32m[0514 06:12:17 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.3014911711215973, Train Loss: 0.29640817642211914
[32m[0514 06:12:17 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.30151450634002686, Train Loss: 0.29639875888824463
[32m[0514 06:12:17 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.3015342950820923, Train Loss: 0.2963901460170746
[32m[0514 06:12:17 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.3015511929988861, Train Loss: 0.2963821291923523
[32m[0514 06:12:17 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.30156582593917847, Train Loss: 0.2963745892047882
[32m[0514 06:12:17 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.3015786409378052, Train Loss: 0.29636743664741516
[32m[0514 06:12:17 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.3015900254249573, Train Loss: 0.29636070132255554
[32m[0514 06:12:17 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.30160024762153625, Train Loss: 0.296354204416275
[32m[0514 06:12:18 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.3016095459461212, Train Loss: 0.2963480055332184
[32m[0514 06:12:18 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.30161815881729126, Train Loss: 0.29634201526641846
[32m[0514 06:12:18 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.30162617564201355, Train Loss: 0.29633629322052
[32m[0514 06:12:18 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.3016337454319, Train Loss: 0.2963307499885559
[32m[0514 06:12:18 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.3016408681869507, Train Loss: 0.2963253855705261
[32m[0514 06:12:18 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.30164772272109985, Train Loss: 0.29632022976875305
[32m[0514 06:12:18 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.30165430903434753, Train Loss: 0.29631516337394714
[32m[0514 06:12:18 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.3016607165336609, Train Loss: 0.29631030559539795
[32m[0514 06:12:18 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.3016669750213623, Train Loss: 0.2963055968284607
[32m[0514 06:12:18 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.3016730844974518, Train Loss: 0.2963009476661682
[32m[0514 06:12:18 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.3016790449619293, Train Loss: 0.29629647731781006
[32m[0514 06:12:18 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.3016848862171173, Train Loss: 0.29629209637641907
[32m[0514 06:12:18 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.3016906678676605, Train Loss: 0.29628786444664
[32m[0514 06:12:18 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.3016963601112366, Train Loss: 0.2962837219238281
[32m[0514 06:12:18 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.30170193314552307, Train Loss: 0.2962796986103058
[32m[0514 06:12:18 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.30170750617980957, Train Loss: 0.2962757349014282
[32m[0514 06:12:18 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.3017130196094513, Train Loss: 0.2962718605995178
[32m[0514 06:12:18 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.30171841382980347, Train Loss: 0.2962680757045746
[32m[0514 06:12:18 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.30172377824783325, Train Loss: 0.2962643802165985
[32m[0514 06:12:18 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.30172914266586304, Train Loss: 0.2962607741355896
[32m[0514 06:12:18 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.30173441767692566, Train Loss: 0.29625722765922546
[32m[0514 06:12:19 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.3017396330833435, Train Loss: 0.2962537705898285
[32m[0514 06:12:19 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.30174481868743896, Train Loss: 0.2962503135204315
[32m[0514 06:12:19 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.30174997448921204, Train Loss: 0.2962469458580017
[32m[0514 06:12:19 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.30175507068634033, Train Loss: 0.29624369740486145
[32m[0514 06:12:19 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.30176010727882385, Train Loss: 0.2962404787540436
[32m[0514 06:12:19 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.30176517367362976, Train Loss: 0.2962373197078705
[32m[0514 06:12:19 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.3017701506614685, Train Loss: 0.2962341606616974
[32m[0514 06:12:19 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.3017750680446625, Train Loss: 0.29623112082481384
[32m[0514 06:12:19 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.30177995562553406, Train Loss: 0.2962281405925751
[32m[0514 06:12:19 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.30178481340408325, Train Loss: 0.29622510075569153
[32m[0514 06:12:19 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.30178964138031006, Train Loss: 0.2962222099304199
[32m[0514 06:12:19 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.3017944395542145, Train Loss: 0.2962193489074707
[32m[0514 06:12:19 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.30179914832115173, Train Loss: 0.2962164878845215
[32m[0514 06:12:19 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.3018038272857666, Train Loss: 0.29621371626853943
[32m[0514 06:12:19 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.30180850625038147, Train Loss: 0.296210914850235
[32m[0514 06:12:19 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.30181315541267395, Train Loss: 0.2962082028388977
[32m[0514 06:12:19 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.30181774497032166, Train Loss: 0.2962054908275604
[32m[0514 06:12:19 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.3018222749233246, Train Loss: 0.2962028980255127
[32m[0514 06:12:19 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.3018268048763275, Train Loss: 0.2962002456188202
[32m[0514 06:12:19 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.30183127522468567, Train Loss: 0.29619765281677246
[32m[0514 06:12:19 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.30183571577072144, Train Loss: 0.2961951196193695
[32m[0514 06:12:19 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.3018400967121124, Train Loss: 0.29619261622428894
[32m[0514 06:12:20 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.3018444776535034, Train Loss: 0.296190083026886
[32m[0514 06:12:20 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.30184879899024963, Train Loss: 0.2961876392364502
[32m[0514 06:12:20 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.30185312032699585, Train Loss: 0.296185165643692
[32m[0514 06:12:20 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.3018573820590973, Train Loss: 0.2961827516555786
[32m[0514 06:12:20 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.30186161398887634, Train Loss: 0.29618039727211
[32m[0514 06:12:20 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.3018657863140106, Train Loss: 0.29617801308631897
[32m[0514 06:12:20 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.3018699288368225, Train Loss: 0.29617568850517273
[32m[0514 06:12:20 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.3018741011619568, Train Loss: 0.2961733639240265
[32m[0514 06:12:20 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.3018781840801239, Train Loss: 0.29617106914520264
[32m[0514 06:12:20 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.30188223719596863, Train Loss: 0.29616883397102356
[32m[0514 06:12:20 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.30188626050949097, Train Loss: 0.2961665689945221
[32m[0514 06:12:20 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.3018902540206909, Train Loss: 0.29616430401802063
[32m[0514 06:12:20 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.3018942177295685, Train Loss: 0.29616209864616394
[32m[0514 06:12:20 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.30189812183380127, Train Loss: 0.29615989327430725
[32m[0514 06:12:20 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.30190205574035645, Train Loss: 0.29615771770477295
[32m[0514 06:12:20 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.30190593004226685, Train Loss: 0.29615554213523865
[32m[0514 06:12:20 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.30190974473953247, Train Loss: 0.2961534261703491
[32m[0514 06:12:20 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.3019135594367981, Train Loss: 0.2961512804031372
[32m[0514 06:12:20 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.30191731452941895, Train Loss: 0.29614922404289246
[32m[0514 06:12:20 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.3019210398197174, Train Loss: 0.29614707827568054
[32m[0514 06:12:20 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.30192479491233826, Train Loss: 0.2961449921131134
[32m[0514 06:12:20 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.30192849040031433, Train Loss: 0.29614293575286865
[32m[0514 06:12:21 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.30193212628364563, Train Loss: 0.2961408793926239
[32m[0514 06:12:21 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.3019357919692993, Train Loss: 0.29613885283470154
[32m[0514 06:12:21 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.30193936824798584, Train Loss: 0.2961368262767792
[32m[0514 06:12:21 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.30194297432899475, Train Loss: 0.2961348295211792
[32m[0514 06:12:21 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.3019464910030365, Train Loss: 0.2961328327655792
[32m[0514 06:12:21 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.301950067281723, Train Loss: 0.29613083600997925
[32m[0514 06:12:21 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.3019534945487976, Train Loss: 0.29612886905670166
[32m[0514 06:12:21 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.3019569516181946, Train Loss: 0.2961268723011017
[32m[0514 06:12:21 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.30196043848991394, Train Loss: 0.2961249053478241
[32m[0514 06:12:21 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.3019638657569885, Train Loss: 0.2961229681968689
[32m[0514 06:12:21 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.30196723341941833, Train Loss: 0.2961210310459137
[32m[0514 06:12:21 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.30197060108184814, Train Loss: 0.2961190938949585
[32m[0514 06:12:21 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.30197396874427795, Train Loss: 0.2961171865463257
[32m[0514 06:12:21 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.3019772469997406, Train Loss: 0.29611527919769287
[32m[0514 06:12:21 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.30198055505752563, Train Loss: 0.29611337184906006
[32m[0514 06:12:21 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.3019838035106659, Train Loss: 0.29611146450042725
[32m[0514 06:12:21 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.30198702216148376, Train Loss: 0.2961096465587616
[32m[0514 06:12:21 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.301990270614624, Train Loss: 0.29610776901245117
[32m[0514 06:12:21 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.3019934296607971, Train Loss: 0.29610589146614075
[32m[0514 06:12:21 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.301996648311615, Train Loss: 0.2961040437221527
[32m[0514 06:12:21 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.3019997775554657, Train Loss: 0.2961021661758423
[32m[0514 06:12:21 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.3020029067993164, Train Loss: 0.29610034823417664
[32m[0514 06:12:22 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.3020060360431671, Train Loss: 0.2960985004901886
[32m[0514 06:12:22 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.30200910568237305, Train Loss: 0.29609671235084534
[32m[0514 06:12:22 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.30201220512390137, Train Loss: 0.2960948944091797
[32m[0514 06:12:22 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.3020152151584625, Train Loss: 0.29609304666519165
[32m[0514 06:12:22 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.30201825499534607, Train Loss: 0.2960912585258484
[32m[0514 06:12:22 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.3020212650299072, Train Loss: 0.29608944058418274
[32m[0514 06:12:22 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.3020242154598236, Train Loss: 0.2960876524448395
[32m[0514 06:12:22 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.3020271956920624, Train Loss: 0.2960858643054962
[32m[0514 06:12:22 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.30203011631965637, Train Loss: 0.29608410596847534
[32m[0514 06:12:22 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.30203303694725037, Train Loss: 0.29608234763145447
[32m[0514 06:12:22 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.30203595757484436, Train Loss: 0.2960805892944336
[32m[0514 06:12:22 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.30203884840011597, Train Loss: 0.29607880115509033
[32m[0514 06:12:22 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.3020417392253876, Train Loss: 0.29607704281806946
[32m[0514 06:12:22 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.3020445704460144, Train Loss: 0.2960752844810486
[32m[0514 06:12:22 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.30204737186431885, Train Loss: 0.2960735261440277
[32m[0514 06:12:22 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.3020502030849457, Train Loss: 0.2960717976093292
[32m[0514 06:12:22 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.3020530343055725, Train Loss: 0.2960700988769531
[32m[0514 06:12:22 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.3020557761192322, Train Loss: 0.29606831073760986
[32m[0514 06:12:22 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.30205851793289185, Train Loss: 0.29606661200523376
[32m[0514 06:12:22 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.3020612299442291, Train Loss: 0.29606494307518005
[32m[0514 06:12:22 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.3020639717578888, Train Loss: 0.2960631847381592
[32m[0514 06:12:22 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.30206671357154846, Train Loss: 0.2960614860057831
[32m[0514 06:12:22 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.30206942558288574, Train Loss: 0.296059787273407
[32m[0514 06:12:23 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.30207210779190063, Train Loss: 0.2960580885410309
[32m[0514 06:12:23 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.30207473039627075, Train Loss: 0.2960563898086548
[32m[0514 06:12:23 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.30207738280296326, Train Loss: 0.2960546910762787
[32m[0514 06:12:23 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.3020800054073334, Train Loss: 0.296053022146225
[32m[0514 06:12:23 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.3020826280117035, Train Loss: 0.2960512936115265
[32m[0514 06:12:23 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.3020852506160736, Train Loss: 0.2960496246814728
[32m[0514 06:12:23 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.30208781361579895, Train Loss: 0.29604795575141907
[32m[0514 06:12:23 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.3020903766155243, Train Loss: 0.29604625701904297
[32m[0514 06:12:23 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.30209293961524963, Train Loss: 0.29604458808898926
[32m[0514 06:12:23 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.3020954728126526, Train Loss: 0.29604294896125793
[32m[0514 06:12:23 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.30209800601005554, Train Loss: 0.2960412800312042
[32m[0514 06:12:23 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.3021005094051361, Train Loss: 0.2960396111011505
[32m[0514 06:12:23 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.30210304260253906, Train Loss: 0.2960379421710968
[32m[0514 06:12:23 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.30210551619529724, Train Loss: 0.2960363030433655
[32m[0514 06:12:23 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.30210795998573303, Train Loss: 0.29603466391563416
[32m[0514 06:12:23 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.3021104633808136, Train Loss: 0.29603302478790283
[32m[0514 06:12:23 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.302112877368927, Train Loss: 0.2960313856601715
[32m[0514 06:12:23 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.3021152913570404, Train Loss: 0.2960297465324402
[32m[0514 06:12:23 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.3021177351474762, Train Loss: 0.29602810740470886
[32m[0514 06:12:23 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.3021201193332672, Train Loss: 0.29602643847465515
[32m[0514 06:12:23 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.3021225035190582, Train Loss: 0.2960248291492462
[32m[0514 06:12:23 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.30212488770484924, Train Loss: 0.2960232198238373
[32m[0514 06:12:24 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.30212724208831787, Train Loss: 0.29602158069610596
[32m[0514 06:12:24 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.3021295964717865, Train Loss: 0.2960200011730194
[32m[0514 06:12:24 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.3021319508552551, Train Loss: 0.2960183620452881
[32m[0514 06:12:24 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.30213430523872375, Train Loss: 0.29601672291755676
[32m[0514 06:12:24 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.3021366000175476, Train Loss: 0.29601508378982544
[32m[0514 06:12:24 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.30213892459869385, Train Loss: 0.29601356387138367
[32m[0514 06:12:24 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.3021412193775177, Train Loss: 0.29601192474365234
[32m[0514 06:12:24 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.30214348435401917, Train Loss: 0.2960103452205658
[32m[0514 06:12:24 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.302145779132843, Train Loss: 0.2960087060928345
[32m[0514 06:12:24 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.3021480143070221, Train Loss: 0.29600709676742554
[32m[0514 06:12:24 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.30215024948120117, Train Loss: 0.296005517244339
[32m[0514 06:12:24 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.30215248465538025, Train Loss: 0.29600393772125244
[32m[0514 06:12:24 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.3021547496318817, Train Loss: 0.2960023581981659
[32m[0514 06:12:24 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.3021569550037384, Train Loss: 0.29600071907043457
[32m[0514 06:12:24 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.3021591603755951, Train Loss: 0.2959991693496704
[32m[0514 06:12:24 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.3021613359451294, Train Loss: 0.2959975600242615
[32m[0514 06:12:24 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.3021635413169861, Train Loss: 0.2959959805011749
[32m[0514 06:12:24 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.3021657168865204, Train Loss: 0.29599443078041077
[32m[0514 06:12:24 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.3021678328514099, Train Loss: 0.2959928512573242
[32m[0514 06:12:24 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.3021700382232666, Train Loss: 0.29599130153656006
[32m[0514 06:12:24 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.3021721839904785, Train Loss: 0.2959896922111511
[32m[0514 06:12:25 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.30217427015304565, Train Loss: 0.29598814249038696
[32m[0514 06:12:25 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.3021763861179352, Train Loss: 0.2959865927696228
[32m[0514 06:12:25 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.3021785020828247, Train Loss: 0.29598501324653625
[32m[0514 06:12:25 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.30218061804771423, Train Loss: 0.2959834337234497
[32m[0514 06:12:25 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.30218273401260376, Train Loss: 0.29598188400268555
[32m[0514 06:12:25 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.3021847903728485, Train Loss: 0.2959803342819214
[32m[0514 06:12:25 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.30218690633773804, Train Loss: 0.29597875475883484
[32m[0514 06:12:25 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.3021889328956604, Train Loss: 0.2959772050380707
[32m[0514 06:12:25 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.30219098925590515, Train Loss: 0.2959756553173065
[32m[0514 06:12:25 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.3021930456161499, Train Loss: 0.29597413539886475
[32m[0514 06:12:25 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.3021950125694275, Train Loss: 0.2959725856781006
[32m[0514 06:12:25 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.30219709873199463, Train Loss: 0.2959710359573364
[32m[0514 06:12:25 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.3021990954875946, Train Loss: 0.29596948623657227
[32m[0514 06:12:25 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.30220112204551697, Train Loss: 0.2959679365158081
[32m[0514 06:12:25 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.30220308899879456, Train Loss: 0.29596638679504395
[32m[0514 06:12:25 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.3022051155567169, Train Loss: 0.29596489667892456
[32m[0514 06:12:25 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.3022070825099945, Train Loss: 0.295963317155838
[32m[0514 06:12:25 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.3022090494632721, Train Loss: 0.29596176743507385
[32m[0514 06:12:25 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.3022110164165497, Train Loss: 0.29596027731895447
[32m[0514 06:12:25 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.30221298336982727, Train Loss: 0.2959587275981903
[32m[0514 06:12:25 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.30221495032310486, Train Loss: 0.29595720767974854
[32m[0514 06:12:25 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.30221688747406006, Train Loss: 0.29595568776130676
[32m[0514 06:12:26 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.30221879482269287, Train Loss: 0.295954167842865
[32m[0514 06:12:26 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.3022207021713257, Train Loss: 0.2959526777267456
[32m[0514 06:12:26 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.3022226095199585, Train Loss: 0.29595109820365906
[32m[0514 06:12:26 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.3022245168685913, Train Loss: 0.2959495782852173
[32m[0514 06:12:26 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.30222639441490173, Train Loss: 0.2959481179714203
[32m[0514 06:12:26 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.30222830176353455, Train Loss: 0.29594656825065613
[32m[0514 06:12:26 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.30223017930984497, Train Loss: 0.29594507813453674
[32m[0514 06:12:26 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.3022320568561554, Train Loss: 0.29594361782073975
[32m[0514 06:12:26 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.30223387479782104, Train Loss: 0.2959420680999756
[32m[0514 06:12:26 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.30223575234413147, Train Loss: 0.2959405481815338
[32m[0514 06:12:26 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.3022376298904419, Train Loss: 0.29593905806541443
[32m[0514 06:12:26 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.30223944783210754, Train Loss: 0.29593753814697266
[32m[0514 06:12:26 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.3022412657737732, Train Loss: 0.2959360182285309
[32m[0514 06:12:26 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.30224311351776123, Train Loss: 0.2959345281124115
[32m[0514 06:12:26 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.3022449314594269, Train Loss: 0.2959330379962921
[32m[0514 06:12:26 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.30224671959877014, Train Loss: 0.29593154788017273
[32m[0514 06:12:26 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.3022485375404358, Train Loss: 0.29593008756637573
[32m[0514 06:12:26 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.30225032567977905, Train Loss: 0.29592856764793396
[32m[0514 06:12:26 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.3022521138191223, Train Loss: 0.2959270477294922
[32m[0514 06:12:26 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.3022538721561432, Train Loss: 0.2959256172180176
[32m[0514 06:12:26 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.30225566029548645, Train Loss: 0.2959240972995758
[32m[0514 06:12:26 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.30225738883018494, Train Loss: 0.2959226071834564
[32m[0514 06:12:26 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.3022591471672058, Train Loss: 0.29592111706733704
[32m[0514 06:12:27 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.3022608757019043, Train Loss: 0.2959196865558624
[32m[0514 06:12:27 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.30226263403892517, Train Loss: 0.29591816663742065
[32m[0514 06:12:27 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.30226436257362366, Train Loss: 0.29591667652130127
[32m[0514 06:12:27 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.30226606130599976, Train Loss: 0.2959151566028595
[32m[0514 06:12:27 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.30226778984069824, Train Loss: 0.2959136962890625
[32m[0514 06:12:27 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.30226948857307434, Train Loss: 0.2959122359752655
[32m[0514 06:12:27 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.3022712171077728, Train Loss: 0.2959107458591461
[32m[0514 06:12:27 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.30227285623550415, Train Loss: 0.29590925574302673
[32m[0514 06:12:27 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.30227455496788025, Train Loss: 0.2959078550338745
[32m[0514 06:12:27 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.30227628350257874, Train Loss: 0.29590633511543274
[32m[0514 06:12:27 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.30227792263031006, Train Loss: 0.29590490460395813
[32m[0514 06:12:27 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.30227962136268616, Train Loss: 0.29590341448783875
[32m[0514 06:12:27 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.3022812306880951, Train Loss: 0.29590198397636414
[32m[0514 06:12:27 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.3022828698158264, Train Loss: 0.29590049386024475
[32m[0514 06:12:27 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.30228450894355774, Train Loss: 0.29589903354644775
[32m[0514 06:12:27 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.30228620767593384, Train Loss: 0.29589757323265076
[32m[0514 06:12:27 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.3022878170013428, Train Loss: 0.295896053314209
[32m[0514 06:12:27 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.3022894263267517, Train Loss: 0.295894593000412
[32m[0514 06:12:27 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.30229106545448303, Train Loss: 0.2958931624889374
[32m[0514 06:12:27 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.3022926449775696, Train Loss: 0.29589173197746277
[32m[0514 06:12:27 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.3022942841053009, Train Loss: 0.2958902418613434
[32m[0514 06:12:28 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.30229586362838745, Train Loss: 0.2958888113498688
[32m[0514 06:12:28 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.302297443151474, Train Loss: 0.29588738083839417
[32m[0514 06:12:28 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.30229902267456055, Train Loss: 0.2958858907222748
[32m[0514 06:12:28 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.3023005723953247, Train Loss: 0.29588449001312256
[32m[0514 06:12:28 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.30230212211608887, Train Loss: 0.29588302969932556
[32m[0514 06:12:28 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.3023037314414978, Train Loss: 0.29588156938552856
[32m[0514 06:12:28 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.30230528116226196, Train Loss: 0.29588010907173157
[32m[0514 06:12:28 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.3023068308830261, Train Loss: 0.29587867856025696
[32m[0514 06:12:28 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.3023083508014679, Train Loss: 0.29587724804878235
[32m[0514 06:12:28 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.30230990052223206, Train Loss: 0.29587578773498535
[32m[0514 06:12:28 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.3023114502429962, Train Loss: 0.29587438702583313
[32m[0514 06:12:28 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.302312970161438, Train Loss: 0.29587292671203613
[32m[0514 06:12:28 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.30231449007987976, Train Loss: 0.29587146639823914
[32m[0514 06:12:28 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.30231598019599915, Train Loss: 0.2958700358867645
[32m[0514 06:12:28 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.3023175001144409, Train Loss: 0.2958686351776123
[32m[0514 06:12:28 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.3023190200328827, Train Loss: 0.2958672046661377
[32m[0514 06:12:28 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.3023204505443573, Train Loss: 0.2958657443523407
[32m[0514 06:12:28 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.3023219406604767, Train Loss: 0.2958643138408661
[32m[0514 06:12:28 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.30232343077659607, Train Loss: 0.29586291313171387
[32m[0514 06:12:28 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.30232492089271545, Train Loss: 0.2958614230155945
[32m[0514 06:12:28 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.30232635140419006, Train Loss: 0.29586002230644226
[32m[0514 06:12:28 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.30232781171798706, Train Loss: 0.29585862159729004
[32m[0514 06:12:29 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.30232927203178406, Train Loss: 0.29585716128349304
[32m[0514 06:12:29 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.30233070254325867, Train Loss: 0.29585573077201843
[32m[0514 06:12:29 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.30233216285705566, Train Loss: 0.2958543598651886
[32m[0514 06:12:29 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.30233362317085266, Train Loss: 0.2958528995513916
[32m[0514 06:12:29 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.3023349940776825, Train Loss: 0.295851469039917
[32m[0514 06:12:29 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.3023364245891571, Train Loss: 0.29585009813308716
[32m[0514 06:12:29 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.3023378551006317, Train Loss: 0.29584863781929016
[32m[0514 06:12:29 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.3023392856121063, Train Loss: 0.29584720730781555
[32m[0514 06:12:29 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.30234068632125854, Train Loss: 0.29584580659866333
[32m[0514 06:12:29 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.30234208703041077, Train Loss: 0.2958444058895111
[32m[0514 06:12:29 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.302343487739563, Train Loss: 0.2958430051803589
[32m[0514 06:12:29 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.3023448586463928, Train Loss: 0.29584163427352905
[32m[0514 06:12:29 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.30234622955322266, Train Loss: 0.29584017395973206
[32m[0514 06:12:29 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.3023476302623749, Train Loss: 0.29583877325057983
[32m[0514 06:12:29 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.3023490011692047, Train Loss: 0.2958373725414276
[32m[0514 06:12:29 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.30235034227371216, Train Loss: 0.295835942029953
[32m[0514 06:12:29 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.3023517429828644, Train Loss: 0.29583457112312317
[32m[0514 06:12:29 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.30235305428504944, Train Loss: 0.29583314061164856
[32m[0514 06:12:29 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.3023544251918793, Train Loss: 0.29583171010017395
[32m[0514 06:12:29 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.3023557662963867, Train Loss: 0.29583027958869934
[32m[0514 06:12:29 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.30235710740089417, Train Loss: 0.2958289384841919
[32m[0514 06:12:29 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.3023584485054016, Train Loss: 0.2958275377750397
[32m[0514 06:12:30 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.3023597300052643, Train Loss: 0.29582613706588745
[32m[0514 06:12:30 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.30236104130744934, Train Loss: 0.29582473635673523
[32m[0514 06:12:30 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.3023623824119568, Train Loss: 0.2958233058452606
[32m[0514 06:12:30 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.30236369371414185, Train Loss: 0.2958219051361084
[32m[0514 06:12:30 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.3023650050163269, Train Loss: 0.29582053422927856
[32m[0514 06:12:30 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.30236631631851196, Train Loss: 0.29581910371780396
[32m[0514 06:12:30 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.30236756801605225, Train Loss: 0.2958177626132965
[32m[0514 06:12:30 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.3023688495159149, Train Loss: 0.2958163917064667
[32m[0514 06:12:30 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.3023701608181, Train Loss: 0.29581496119499207
[32m[0514 06:12:30 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.30237144231796265, Train Loss: 0.29581359028816223
[32m[0514 06:12:30 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.30237269401550293, Train Loss: 0.2958122193813324
[32m[0514 06:12:30 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.3023739755153656, Train Loss: 0.2958107888698578
[32m[0514 06:12:30 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.3023752272129059, Train Loss: 0.29580938816070557
[32m[0514 06:12:30 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.30237650871276855, Train Loss: 0.2958080470561981
[32m[0514 06:12:30 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.30237773060798645, Train Loss: 0.2958066165447235
[32m[0514 06:12:30 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.30237898230552673, Train Loss: 0.2958052158355713
[32m[0514 06:12:30 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.3023802638053894, Train Loss: 0.29580381512641907
[32m[0514 06:12:30 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.3023815155029297, Train Loss: 0.2958024740219116
[32m[0514 06:12:30 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.3023827373981476, Train Loss: 0.2958010733127594
[32m[0514 06:12:30 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.3023839592933655, Train Loss: 0.2957996726036072
[32m[0514 06:12:30 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.302385151386261, Train Loss: 0.29579833149909973
[32m[0514 06:12:30 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.3023863732814789, Train Loss: 0.2957969307899475
[32m[0514 06:12:31 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 06:12:31 @mbmf_main.py:227][0m batch size for trpo is 1000
[32m[0514 06:12:31 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 06:12:31 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 06:12:31 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 06:12:31 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 06:12:31 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 06:12:31 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 06:12:31 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 06:12:31 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 06:12:31 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 06:12:31 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 06:12:31 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 06:12:31 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 06:12:31 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 06:12:31 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 06:12:31 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 06:12:31 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 06:12:31 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 06:12:31 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 06:12:31 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 06:12:31 @mbmf_main.py:132][0m Training starts at /root/mbbl
[32m[0514 06:12:31 @base_worker.py:45][0m Worker 0 online
[32m[0514 06:12:31 @base_worker.py:45][0m Worker 1 online
[32m[0514 06:12:31 @base_worker.py:45][0m Worker 2 online
[32m[0514 06:12:31 @base_worker.py:45][0m Worker 3 online
[32m[0514 06:12:31 @base_worker.py:45][0m Worker 4 online
[32m[0514 06:12:31 @base_worker.py:45][0m Worker 5 online
[32m[0514 06:12:31 @base_worker.py:45][0m Worker 6 online
[32m[0514 06:12:31 @base_worker.py:45][0m Worker 7 online
[32m[0514 06:12:31 @base_worker.py:45][0m Worker 8 online
[32m[0514 06:12:31 @base_worker.py:45][0m Worker 9 online
[32m[0514 06:12:31 @base_worker.py:45][0m Worker 10 online
[32m[0514 06:12:31 @base_worker.py:45][0m Worker 11 online
[32m[0514 06:12:31 @base_worker.py:45][0m Worker 12 online
[32m[0514 06:12:31 @base_worker.py:45][0m Worker 13 online
[32m[0514 06:12:31 @base_worker.py:45][0m Worker 14 online
[32m[0514 06:12:31 @base_worker.py:45][0m Worker 15 online
[32m[0514 06:12:31 @base_worker.py:45][0m Worker 16 online
[32m[0514 06:12:31 @base_worker.py:45][0m Worker 17 online
[32m[0514 06:12:31 @base_worker.py:45][0m Worker 18 online
[32m[0514 06:12:31 @base_worker.py:45][0m Worker 19 online
[32m[0514 06:12:31 @base_trainer.py:152][0m Trainer maintains [1] policy network
[32m[0514 06:12:31 @base_trainer.py:152][0m Trainer maintains [1] dynamics network
[32m[0514 06:12:31 @base_trainer.py:152][0m Trainer maintains [1] reward network
[32m[0514 06:12:32 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:32 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:32 @base_trainer.py:216][0m Mean reward: -1207.7763454504318
[32m[0514 06:12:32 @base_main.py:38][0m --------------- Iteration 1 ---------------
[32m[0514 06:12:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0000 mins
[32m[0514 06:12:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 06:12:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0142 mins
[32m[0514 06:12:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:32 @base_main.py:47][0m 1005 total steps have happened
[32m[0514 06:12:32 @base_main.py:52][0m [avg_reward]: -1207.7763454504318
[32m[0514 06:12:33 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:33 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:33 @base_trainer.py:216][0m Mean reward: -1223.7132678568746
[32m[0514 06:12:33 @base_main.py:38][0m --------------- Iteration 2 ---------------
[32m[0514 06:12:33 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0169 mins
[32m[0514 06:12:33 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 06:12:33 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0514 06:12:33 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:33 @base_main.py:47][0m 2010 total steps have happened
[32m[0514 06:12:33 @base_main.py:52][0m [avg_reward]: -1223.7132678568746
[32m[0514 06:12:33 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:33 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:33 @base_trainer.py:216][0m Mean reward: -1278.80321211658
[32m[0514 06:12:34 @base_main.py:38][0m --------------- Iteration 3 ---------------
[32m[0514 06:12:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0285 mins
[32m[0514 06:12:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 06:12:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0514 06:12:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:34 @base_main.py:47][0m 3015 total steps have happened
[32m[0514 06:12:34 @base_main.py:52][0m [avg_reward]: -1278.80321211658
[32m[0514 06:12:34 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:34 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:34 @base_trainer.py:216][0m Mean reward: -1161.8433575838662
[32m[0514 06:12:35 @base_main.py:38][0m --------------- Iteration 4 ---------------
[32m[0514 06:12:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0402 mins
[32m[0514 06:12:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 06:12:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 06:12:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:35 @base_main.py:47][0m 4020 total steps have happened
[32m[0514 06:12:35 @base_main.py:52][0m [avg_reward]: -1161.8433575838662
[32m[0514 06:12:35 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:35 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:35 @base_trainer.py:216][0m Mean reward: -1040.456957015226
[32m[0514 06:12:35 @base_main.py:38][0m --------------- Iteration 5 ---------------
[32m[0514 06:12:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0521 mins
[32m[0514 06:12:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 06:12:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0084 mins
[32m[0514 06:12:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:35 @base_main.py:47][0m 5025 total steps have happened
[32m[0514 06:12:35 @base_main.py:52][0m [avg_reward]: -1040.456957015226
[32m[0514 06:12:35 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:35 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:35 @base_trainer.py:216][0m Mean reward: -1074.2637019260128
[32m[0514 06:12:36 @base_main.py:38][0m --------------- Iteration 6 ---------------
[32m[0514 06:12:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0631 mins
[32m[0514 06:12:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 06:12:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 06:12:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:36 @base_main.py:47][0m 6030 total steps have happened
[32m[0514 06:12:36 @base_main.py:52][0m [avg_reward]: -1074.2637019260128
[32m[0514 06:12:36 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:36 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:36 @base_trainer.py:216][0m Mean reward: -1121.8031044226123
[32m[0514 06:12:37 @base_main.py:38][0m --------------- Iteration 7 ---------------
[32m[0514 06:12:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0745 mins
[32m[0514 06:12:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 06:12:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 06:12:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:37 @base_main.py:47][0m 7035 total steps have happened
[32m[0514 06:12:37 @base_main.py:52][0m [avg_reward]: -1121.8031044226123
[32m[0514 06:12:37 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:37 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:37 @base_trainer.py:216][0m Mean reward: -1001.892043872807
[32m[0514 06:12:37 @base_main.py:38][0m --------------- Iteration 8 ---------------
[32m[0514 06:12:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0861 mins
[32m[0514 06:12:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 06:12:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 06:12:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:37 @base_main.py:47][0m 8040 total steps have happened
[32m[0514 06:12:37 @base_main.py:52][0m [avg_reward]: -1001.892043872807
[32m[0514 06:12:37 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:37 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:37 @base_trainer.py:216][0m Mean reward: -1301.6740565373555
[32m[0514 06:12:38 @base_main.py:38][0m --------------- Iteration 9 ---------------
[32m[0514 06:12:38 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0981 mins
[32m[0514 06:12:38 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 06:12:38 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 06:12:38 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:38 @base_main.py:47][0m 9045 total steps have happened
[32m[0514 06:12:38 @base_main.py:52][0m [avg_reward]: -1301.6740565373555
[32m[0514 06:12:38 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:38 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:38 @base_trainer.py:216][0m Mean reward: -1167.078555036107
[32m[0514 06:12:39 @base_main.py:38][0m --------------- Iteration 10 ---------------
[32m[0514 06:12:39 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1103 mins
[32m[0514 06:12:39 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 06:12:39 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 06:12:39 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:39 @base_main.py:47][0m 10050 total steps have happened
[32m[0514 06:12:39 @base_main.py:52][0m [avg_reward]: -1167.078555036107
[32m[0514 06:12:39 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:39 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:39 @base_trainer.py:216][0m Mean reward: -1236.0267694979725
[32m[0514 06:12:39 @base_main.py:38][0m --------------- Iteration 11 ---------------
[32m[0514 06:12:39 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1217 mins
[32m[0514 06:12:39 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 06:12:39 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 06:12:39 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:39 @base_main.py:47][0m 11055 total steps have happened
[32m[0514 06:12:39 @base_main.py:52][0m [avg_reward]: -1236.0267694979725
[32m[0514 06:12:40 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:40 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:40 @base_trainer.py:216][0m Mean reward: -1347.203497937743
[32m[0514 06:12:40 @base_main.py:38][0m --------------- Iteration 12 ---------------
[32m[0514 06:12:40 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1335 mins
[32m[0514 06:12:40 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0514 06:12:40 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 06:12:40 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:40 @base_main.py:47][0m 12060 total steps have happened
[32m[0514 06:12:40 @base_main.py:52][0m [avg_reward]: -1347.203497937743
[32m[0514 06:12:40 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:40 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:40 @base_trainer.py:216][0m Mean reward: -1114.128414017625
[32m[0514 06:12:41 @base_main.py:38][0m --------------- Iteration 13 ---------------
[32m[0514 06:12:41 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1447 mins
[32m[0514 06:12:41 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 06:12:41 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 06:12:41 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:41 @base_main.py:47][0m 13065 total steps have happened
[32m[0514 06:12:41 @base_main.py:52][0m [avg_reward]: -1114.128414017625
[32m[0514 06:12:41 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:41 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:41 @base_trainer.py:216][0m Mean reward: -1128.2481060052032
[32m[0514 06:12:41 @base_main.py:38][0m --------------- Iteration 14 ---------------
[32m[0514 06:12:41 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1562 mins
[32m[0514 06:12:41 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0514 06:12:41 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 06:12:41 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:41 @base_main.py:47][0m 14070 total steps have happened
[32m[0514 06:12:41 @base_main.py:52][0m [avg_reward]: -1128.2481060052032
[32m[0514 06:12:42 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:42 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:42 @base_trainer.py:216][0m Mean reward: -1111.8619125947619
[32m[0514 06:12:42 @base_main.py:38][0m --------------- Iteration 15 ---------------
[32m[0514 06:12:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1676 mins
[32m[0514 06:12:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 06:12:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 06:12:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:42 @base_main.py:47][0m 15075 total steps have happened
[32m[0514 06:12:42 @base_main.py:52][0m [avg_reward]: -1111.8619125947619
[32m[0514 06:12:42 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:42 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:42 @base_trainer.py:216][0m Mean reward: -1177.819681078332
[32m[0514 06:12:43 @base_main.py:38][0m --------------- Iteration 16 ---------------
[32m[0514 06:12:43 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1793 mins
[32m[0514 06:12:43 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 06:12:43 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 06:12:43 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:43 @base_main.py:47][0m 16080 total steps have happened
[32m[0514 06:12:43 @base_main.py:52][0m [avg_reward]: -1177.819681078332
[32m[0514 06:12:43 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:43 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:43 @base_trainer.py:216][0m Mean reward: -1380.071969769201
[32m[0514 06:12:44 @base_main.py:38][0m --------------- Iteration 17 ---------------
[32m[0514 06:12:44 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1913 mins
[32m[0514 06:12:44 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 06:12:44 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 06:12:44 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:44 @base_main.py:47][0m 17085 total steps have happened
[32m[0514 06:12:44 @base_main.py:52][0m [avg_reward]: -1380.071969769201
[32m[0514 06:12:44 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:44 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:44 @base_trainer.py:216][0m Mean reward: -1040.4397465083034
[32m[0514 06:12:44 @base_main.py:38][0m --------------- Iteration 18 ---------------
[32m[0514 06:12:44 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2026 mins
[32m[0514 06:12:44 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 06:12:44 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 06:12:44 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:44 @base_main.py:47][0m 18090 total steps have happened
[32m[0514 06:12:44 @base_main.py:52][0m [avg_reward]: -1040.4397465083034
[32m[0514 06:12:44 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:44 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:44 @base_trainer.py:216][0m Mean reward: -1312.3984930272948
[32m[0514 06:12:45 @base_main.py:38][0m --------------- Iteration 19 ---------------
[32m[0514 06:12:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2145 mins
[32m[0514 06:12:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 06:12:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 06:12:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:45 @base_main.py:47][0m 19095 total steps have happened
[32m[0514 06:12:45 @base_main.py:52][0m [avg_reward]: -1312.3984930272948
[32m[0514 06:12:45 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:45 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:45 @base_trainer.py:216][0m Mean reward: -1061.754279424435
[32m[0514 06:12:46 @base_main.py:38][0m --------------- Iteration 20 ---------------
[32m[0514 06:12:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2264 mins
[32m[0514 06:12:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 06:12:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0514 06:12:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:46 @base_main.py:47][0m 20100 total steps have happened
[32m[0514 06:12:46 @base_main.py:52][0m [avg_reward]: -1061.754279424435
[32m[0514 06:12:46 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:46 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:46 @base_trainer.py:216][0m Mean reward: -1019.6379816004849
[32m[0514 06:12:46 @base_main.py:38][0m --------------- Iteration 21 ---------------
[32m[0514 06:12:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2389 mins
[32m[0514 06:12:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 06:12:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 06:12:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:46 @base_main.py:47][0m 21105 total steps have happened
[32m[0514 06:12:46 @base_main.py:52][0m [avg_reward]: -1019.6379816004849
[32m[0514 06:12:47 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:47 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:47 @base_trainer.py:216][0m Mean reward: -1196.6049855190515
[32m[0514 06:12:47 @base_main.py:38][0m --------------- Iteration 22 ---------------
[32m[0514 06:12:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2503 mins
[32m[0514 06:12:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 06:12:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 06:12:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:47 @base_main.py:47][0m 22110 total steps have happened
[32m[0514 06:12:47 @base_main.py:52][0m [avg_reward]: -1196.6049855190515
[32m[0514 06:12:47 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:47 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:47 @base_trainer.py:216][0m Mean reward: -1234.5901873906814
[32m[0514 06:12:48 @base_main.py:38][0m --------------- Iteration 23 ---------------
[32m[0514 06:12:48 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2618 mins
[32m[0514 06:12:48 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 06:12:48 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0514 06:12:48 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:48 @base_main.py:47][0m 23115 total steps have happened
[32m[0514 06:12:48 @base_main.py:52][0m [avg_reward]: -1234.5901873906814
[32m[0514 06:12:48 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:48 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:48 @base_trainer.py:216][0m Mean reward: -1257.1460510318511
[32m[0514 06:12:49 @base_main.py:38][0m --------------- Iteration 24 ---------------
[32m[0514 06:12:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2738 mins
[32m[0514 06:12:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 06:12:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 06:12:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:49 @base_main.py:47][0m 24120 total steps have happened
[32m[0514 06:12:49 @base_main.py:52][0m [avg_reward]: -1257.1460510318511
[32m[0514 06:12:49 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:49 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:49 @base_trainer.py:216][0m Mean reward: -1150.2776356959205
[32m[0514 06:12:49 @base_main.py:38][0m --------------- Iteration 25 ---------------
[32m[0514 06:12:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2853 mins
[32m[0514 06:12:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 06:12:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 06:12:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:49 @base_main.py:47][0m 25125 total steps have happened
[32m[0514 06:12:49 @base_main.py:52][0m [avg_reward]: -1150.2776356959205
[32m[0514 06:12:49 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:49 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:49 @base_trainer.py:216][0m Mean reward: -972.4002224164972
[32m[0514 06:12:50 @base_main.py:38][0m --------------- Iteration 26 ---------------
[32m[0514 06:12:50 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2969 mins
[32m[0514 06:12:50 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 06:12:50 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0083 mins
[32m[0514 06:12:50 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:50 @base_main.py:47][0m 26130 total steps have happened
[32m[0514 06:12:50 @base_main.py:52][0m [avg_reward]: -972.4002224164972
[32m[0514 06:12:50 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:50 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:50 @base_trainer.py:216][0m Mean reward: -1230.3967559071855
[32m[0514 06:12:51 @base_main.py:38][0m --------------- Iteration 27 ---------------
[32m[0514 06:12:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3079 mins
[32m[0514 06:12:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0514 06:12:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 06:12:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:12:51 @base_main.py:47][0m 27135 total steps have happened
[32m[0514 06:12:51 @base_main.py:52][0m [avg_reward]: -1230.3967559071855
[32m[0514 06:12:51 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:51 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:51 @base_trainer.py:216][0m Mean reward: -1146.3555036304565
[32m[0514 06:12:51 @base_main.py:38][0m --------------- Iteration 28 ---------------
[32m[0514 06:12:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3200 mins
[32m[0514 06:12:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0514 06:12:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 06:12:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:12:51 @base_main.py:47][0m 28140 total steps have happened
[32m[0514 06:12:51 @base_main.py:52][0m [avg_reward]: -1146.3555036304565
[32m[0514 06:12:51 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:51 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:52 @base_trainer.py:216][0m Mean reward: -1187.8256135079162
[32m[0514 06:12:52 @base_main.py:38][0m --------------- Iteration 29 ---------------
[32m[0514 06:12:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3317 mins
[32m[0514 06:12:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 06:12:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 06:12:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:12:52 @base_main.py:47][0m 29145 total steps have happened
[32m[0514 06:12:52 @base_main.py:52][0m [avg_reward]: -1187.8256135079162
[32m[0514 06:12:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:52 @base_trainer.py:216][0m Mean reward: -1036.676718719115
[32m[0514 06:12:53 @base_main.py:38][0m --------------- Iteration 30 ---------------
[32m[0514 06:12:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3434 mins
[32m[0514 06:12:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 06:12:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 06:12:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:53 @base_main.py:47][0m 30150 total steps have happened
[32m[0514 06:12:53 @base_main.py:52][0m [avg_reward]: -1036.676718719115
[32m[0514 06:12:53 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:53 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:53 @base_trainer.py:216][0m Mean reward: -1293.5886266953182
[32m[0514 06:12:53 @base_main.py:38][0m --------------- Iteration 31 ---------------
[32m[0514 06:12:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3549 mins
[32m[0514 06:12:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0514 06:12:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 06:12:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:53 @base_main.py:47][0m 31155 total steps have happened
[32m[0514 06:12:53 @base_main.py:52][0m [avg_reward]: -1293.5886266953182
[32m[0514 06:12:54 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:54 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:54 @base_trainer.py:216][0m Mean reward: -981.895770681385
[32m[0514 06:12:54 @base_main.py:38][0m --------------- Iteration 32 ---------------
[32m[0514 06:12:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3665 mins
[32m[0514 06:12:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 06:12:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 06:12:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:54 @base_main.py:47][0m 32160 total steps have happened
[32m[0514 06:12:54 @base_main.py:52][0m [avg_reward]: -981.895770681385
[32m[0514 06:12:54 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:54 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:54 @base_trainer.py:216][0m Mean reward: -1293.2492341702457
[32m[0514 06:12:55 @base_main.py:38][0m --------------- Iteration 33 ---------------
[32m[0514 06:12:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3784 mins
[32m[0514 06:12:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 06:12:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 06:12:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:55 @base_main.py:47][0m 33165 total steps have happened
[32m[0514 06:12:55 @base_main.py:52][0m [avg_reward]: -1293.2492341702457
[32m[0514 06:12:55 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:55 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:55 @base_trainer.py:216][0m Mean reward: -1416.3090692380417
[32m[0514 06:12:56 @base_main.py:38][0m --------------- Iteration 34 ---------------
[32m[0514 06:12:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3900 mins
[32m[0514 06:12:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0514 06:12:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 06:12:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:56 @base_main.py:47][0m 34170 total steps have happened
[32m[0514 06:12:56 @base_main.py:52][0m [avg_reward]: -1416.3090692380417
[32m[0514 06:12:56 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:56 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:56 @base_trainer.py:216][0m Mean reward: -1210.692078111478
[32m[0514 06:12:56 @base_main.py:38][0m --------------- Iteration 35 ---------------
[32m[0514 06:12:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4016 mins
[32m[0514 06:12:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0514 06:12:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 06:12:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:56 @base_main.py:47][0m 35175 total steps have happened
[32m[0514 06:12:56 @base_main.py:52][0m [avg_reward]: -1210.692078111478
[32m[0514 06:12:56 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:56 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:56 @base_trainer.py:216][0m Mean reward: -1066.138276659372
[32m[0514 06:12:57 @base_main.py:38][0m --------------- Iteration 36 ---------------
[32m[0514 06:12:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4130 mins
[32m[0514 06:12:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0514 06:12:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 06:12:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:57 @base_main.py:47][0m 36180 total steps have happened
[32m[0514 06:12:57 @base_main.py:52][0m [avg_reward]: -1066.138276659372
[32m[0514 06:12:57 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:57 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:57 @base_trainer.py:216][0m Mean reward: -1235.4707834000124
[32m[0514 06:12:58 @base_main.py:38][0m --------------- Iteration 37 ---------------
[32m[0514 06:12:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4245 mins
[32m[0514 06:12:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 06:12:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 06:12:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:58 @base_main.py:47][0m 37185 total steps have happened
[32m[0514 06:12:58 @base_main.py:52][0m [avg_reward]: -1235.4707834000124
[32m[0514 06:12:58 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:58 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:58 @base_trainer.py:216][0m Mean reward: -986.6126345451632
[32m[0514 06:12:58 @base_main.py:38][0m --------------- Iteration 38 ---------------
[32m[0514 06:12:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4359 mins
[32m[0514 06:12:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 06:12:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0514 06:12:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:58 @base_main.py:47][0m 38190 total steps have happened
[32m[0514 06:12:58 @base_main.py:52][0m [avg_reward]: -986.6126345451632
[32m[0514 06:12:58 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:58 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:58 @base_trainer.py:216][0m Mean reward: -1205.5247994507656
[32m[0514 06:12:59 @base_main.py:38][0m --------------- Iteration 39 ---------------
[32m[0514 06:12:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4481 mins
[32m[0514 06:12:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 06:12:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 06:12:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:59 @base_main.py:47][0m 39195 total steps have happened
[32m[0514 06:12:59 @base_main.py:52][0m [avg_reward]: -1205.5247994507656
[32m[0514 06:12:59 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:59 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:59 @base_trainer.py:216][0m Mean reward: -1139.6475083061189
[32m[0514 06:13:00 @base_main.py:38][0m --------------- Iteration 40 ---------------
[32m[0514 06:13:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4596 mins
[32m[0514 06:13:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 06:13:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 06:13:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:00 @base_main.py:47][0m 40200 total steps have happened
[32m[0514 06:13:00 @base_main.py:52][0m [avg_reward]: -1139.6475083061189
[32m[0514 06:13:00 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:00 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:00 @base_trainer.py:216][0m Mean reward: -1135.4192111971877
[32m[0514 06:13:00 @base_main.py:38][0m --------------- Iteration 41 ---------------
[32m[0514 06:13:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4711 mins
[32m[0514 06:13:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 06:13:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0514 06:13:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:00 @base_main.py:47][0m 41205 total steps have happened
[32m[0514 06:13:00 @base_main.py:52][0m [avg_reward]: -1135.4192111971877
[32m[0514 06:13:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:01 @base_trainer.py:216][0m Mean reward: -1097.0967419789504
[32m[0514 06:13:01 @base_main.py:38][0m --------------- Iteration 42 ---------------
[32m[0514 06:13:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4823 mins
[32m[0514 06:13:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0514 06:13:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 06:13:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:01 @base_main.py:47][0m 42210 total steps have happened
[32m[0514 06:13:01 @base_main.py:52][0m [avg_reward]: -1097.0967419789504
[32m[0514 06:13:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:01 @base_trainer.py:216][0m Mean reward: -1318.6463827533696
[32m[0514 06:13:02 @base_main.py:38][0m --------------- Iteration 43 ---------------
[32m[0514 06:13:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4936 mins
[32m[0514 06:13:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0514 06:13:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 06:13:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:02 @base_main.py:47][0m 43215 total steps have happened
[32m[0514 06:13:02 @base_main.py:52][0m [avg_reward]: -1318.6463827533696
[32m[0514 06:13:02 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:02 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:02 @base_trainer.py:216][0m Mean reward: -1127.9165112022988
[32m[0514 06:13:02 @base_main.py:38][0m --------------- Iteration 44 ---------------
[32m[0514 06:13:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5048 mins
[32m[0514 06:13:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 06:13:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 06:13:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:02 @base_main.py:47][0m 44220 total steps have happened
[32m[0514 06:13:02 @base_main.py:52][0m [avg_reward]: -1127.9165112022988
[32m[0514 06:13:03 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:03 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:03 @base_trainer.py:216][0m Mean reward: -1085.7979645256532
[32m[0514 06:13:03 @base_main.py:38][0m --------------- Iteration 45 ---------------
[32m[0514 06:13:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5164 mins
[32m[0514 06:13:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 06:13:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 06:13:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:03 @base_main.py:47][0m 45225 total steps have happened
[32m[0514 06:13:03 @base_main.py:52][0m [avg_reward]: -1085.7979645256532
[32m[0514 06:13:03 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:03 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:03 @base_trainer.py:216][0m Mean reward: -1086.2914045333532
[32m[0514 06:13:04 @base_main.py:38][0m --------------- Iteration 46 ---------------
[32m[0514 06:13:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5280 mins
[32m[0514 06:13:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 06:13:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 06:13:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:04 @base_main.py:47][0m 46230 total steps have happened
[32m[0514 06:13:04 @base_main.py:52][0m [avg_reward]: -1086.2914045333532
[32m[0514 06:13:04 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:04 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:04 @base_trainer.py:216][0m Mean reward: -1080.052532153574
[32m[0514 06:13:05 @base_main.py:38][0m --------------- Iteration 47 ---------------
[32m[0514 06:13:05 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5394 mins
[32m[0514 06:13:05 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 06:13:05 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 06:13:05 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:05 @base_main.py:47][0m 47235 total steps have happened
[32m[0514 06:13:05 @base_main.py:52][0m [avg_reward]: -1080.052532153574
[32m[0514 06:13:05 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:05 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:05 @base_trainer.py:216][0m Mean reward: -1120.7249293872885
[32m[0514 06:13:05 @base_main.py:38][0m --------------- Iteration 48 ---------------
[32m[0514 06:13:05 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5512 mins
[32m[0514 06:13:05 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 06:13:05 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 06:13:05 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:05 @base_main.py:47][0m 48240 total steps have happened
[32m[0514 06:13:05 @base_main.py:52][0m [avg_reward]: -1120.7249293872885
[32m[0514 06:13:05 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:05 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:05 @base_trainer.py:216][0m Mean reward: -1213.8504129470557
[32m[0514 06:13:06 @base_main.py:38][0m --------------- Iteration 49 ---------------
[32m[0514 06:13:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5628 mins
[32m[0514 06:13:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0514 06:13:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 06:13:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:06 @base_main.py:47][0m 49245 total steps have happened
[32m[0514 06:13:06 @base_main.py:52][0m [avg_reward]: -1213.8504129470557
[32m[0514 06:13:06 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:06 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:06 @base_trainer.py:216][0m Mean reward: -1269.05336527004
[32m[0514 06:13:07 @base_main.py:38][0m --------------- Iteration 50 ---------------
[32m[0514 06:13:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5739 mins
[32m[0514 06:13:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0514 06:13:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0514 06:13:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:07 @base_main.py:47][0m 50250 total steps have happened
[32m[0514 06:13:07 @base_main.py:52][0m [avg_reward]: -1269.05336527004
[32m[0514 06:13:07 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:07 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:07 @base_trainer.py:216][0m Mean reward: -1062.2445933408183
[32m[0514 06:13:07 @base_main.py:38][0m --------------- Iteration 51 ---------------
[32m[0514 06:13:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5854 mins
[32m[0514 06:13:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0514 06:13:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0514 06:13:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:07 @base_main.py:47][0m 51255 total steps have happened
[32m[0514 06:13:07 @base_main.py:52][0m [avg_reward]: -1062.2445933408183
[32m[0514 06:13:07 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:07 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:07 @base_trainer.py:216][0m Mean reward: -1012.8739557298073
[32m[0514 06:13:08 @base_main.py:38][0m --------------- Iteration 52 ---------------
[32m[0514 06:13:08 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5972 mins
[32m[0514 06:13:08 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 06:13:08 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0514 06:13:08 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:13:08 @base_main.py:47][0m 52260 total steps have happened
[32m[0514 06:13:08 @base_main.py:52][0m [avg_reward]: -1012.8739557298073
[32m[0514 06:13:08 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:08 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:08 @base_trainer.py:216][0m Mean reward: -1119.4498208515438
[32m[0514 06:13:09 @base_main.py:38][0m --------------- Iteration 53 ---------------
[32m[0514 06:13:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6084 mins
[32m[0514 06:13:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0514 06:13:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 06:13:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:09 @base_main.py:47][0m 53265 total steps have happened
[32m[0514 06:13:09 @base_main.py:52][0m [avg_reward]: -1119.4498208515438
[32m[0514 06:13:09 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:09 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:09 @base_trainer.py:216][0m Mean reward: -1191.2329547652766
[32m[0514 06:13:09 @base_main.py:38][0m --------------- Iteration 54 ---------------
[32m[0514 06:13:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6196 mins
[32m[0514 06:13:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 06:13:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 06:13:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:09 @base_main.py:47][0m 54270 total steps have happened
[32m[0514 06:13:09 @base_main.py:52][0m [avg_reward]: -1191.2329547652766
[32m[0514 06:13:09 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:09 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:09 @base_trainer.py:216][0m Mean reward: -1067.0445727374736
[32m[0514 06:13:10 @base_main.py:38][0m --------------- Iteration 55 ---------------
[32m[0514 06:13:10 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6313 mins
[32m[0514 06:13:10 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 06:13:10 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 06:13:10 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:10 @base_main.py:47][0m 55275 total steps have happened
[32m[0514 06:13:10 @base_main.py:52][0m [avg_reward]: -1067.0445727374736
[32m[0514 06:13:10 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:10 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:10 @base_trainer.py:216][0m Mean reward: -1061.5932462481305
[32m[0514 06:13:11 @base_main.py:38][0m --------------- Iteration 56 ---------------
[32m[0514 06:13:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6430 mins
[32m[0514 06:13:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 06:13:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 06:13:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:11 @base_main.py:47][0m 56280 total steps have happened
[32m[0514 06:13:11 @base_main.py:52][0m [avg_reward]: -1061.5932462481305
[32m[0514 06:13:11 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:11 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:11 @base_trainer.py:216][0m Mean reward: -1090.1721346084864
[32m[0514 06:13:11 @base_main.py:38][0m --------------- Iteration 57 ---------------
[32m[0514 06:13:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6547 mins
[32m[0514 06:13:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 06:13:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0514 06:13:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:11 @base_main.py:47][0m 57285 total steps have happened
[32m[0514 06:13:11 @base_main.py:52][0m [avg_reward]: -1090.1721346084864
[32m[0514 06:13:12 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:12 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:12 @base_trainer.py:216][0m Mean reward: -1093.2681346884306
[32m[0514 06:13:12 @base_main.py:38][0m --------------- Iteration 58 ---------------
[32m[0514 06:13:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6666 mins
[32m[0514 06:13:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 06:13:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 06:13:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:12 @base_main.py:47][0m 58290 total steps have happened
[32m[0514 06:13:12 @base_main.py:52][0m [avg_reward]: -1093.2681346884306
[32m[0514 06:13:12 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:12 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:12 @base_trainer.py:216][0m Mean reward: -1069.5720705191984
[32m[0514 06:13:13 @base_main.py:38][0m --------------- Iteration 59 ---------------
[32m[0514 06:13:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6782 mins
[32m[0514 06:13:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 06:13:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 06:13:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:13 @base_main.py:47][0m 59295 total steps have happened
[32m[0514 06:13:13 @base_main.py:52][0m [avg_reward]: -1069.5720705191984
[32m[0514 06:13:13 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:13 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:13 @base_trainer.py:216][0m Mean reward: -1032.8759988824356
[32m[0514 06:13:14 @base_main.py:38][0m --------------- Iteration 60 ---------------
[32m[0514 06:13:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6900 mins
[32m[0514 06:13:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 06:13:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 06:13:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:14 @base_main.py:47][0m 60300 total steps have happened
[32m[0514 06:13:14 @base_main.py:52][0m [avg_reward]: -1032.8759988824356
[32m[0514 06:13:14 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:14 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:14 @base_trainer.py:216][0m Mean reward: -1193.7143476000642
[32m[0514 06:13:14 @base_main.py:38][0m --------------- Iteration 61 ---------------
[32m[0514 06:13:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7018 mins
[32m[0514 06:13:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 06:13:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0084 mins
[32m[0514 06:13:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:14 @base_main.py:47][0m 61305 total steps have happened
[32m[0514 06:13:14 @base_main.py:52][0m [avg_reward]: -1193.7143476000642
[32m[0514 06:13:14 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:14 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:14 @base_trainer.py:216][0m Mean reward: -1110.9559897515169
[32m[0514 06:13:15 @base_main.py:38][0m --------------- Iteration 62 ---------------
[32m[0514 06:13:15 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7128 mins
[32m[0514 06:13:15 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 06:13:15 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 06:13:15 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:15 @base_main.py:47][0m 62310 total steps have happened
[32m[0514 06:13:15 @base_main.py:52][0m [avg_reward]: -1110.9559897515169
[32m[0514 06:13:15 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:15 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:15 @base_trainer.py:216][0m Mean reward: -1168.1770217731412
[32m[0514 06:13:16 @base_main.py:38][0m --------------- Iteration 63 ---------------
[32m[0514 06:13:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7241 mins
[32m[0514 06:13:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 06:13:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 06:13:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:16 @base_main.py:47][0m 63315 total steps have happened
[32m[0514 06:13:16 @base_main.py:52][0m [avg_reward]: -1168.1770217731412
[32m[0514 06:13:16 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:16 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:16 @base_trainer.py:216][0m Mean reward: -1174.501073125575
[32m[0514 06:13:16 @base_main.py:38][0m --------------- Iteration 64 ---------------
[32m[0514 06:13:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7356 mins
[32m[0514 06:13:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 06:13:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0514 06:13:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:16 @base_main.py:47][0m 64320 total steps have happened
[32m[0514 06:13:16 @base_main.py:52][0m [avg_reward]: -1174.501073125575
[32m[0514 06:13:16 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:16 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:16 @base_trainer.py:216][0m Mean reward: -1142.5084597606321
[32m[0514 06:13:17 @base_main.py:38][0m --------------- Iteration 65 ---------------
[32m[0514 06:13:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7477 mins
[32m[0514 06:13:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0514 06:13:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 06:13:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:17 @base_main.py:47][0m 65325 total steps have happened
[32m[0514 06:13:17 @base_main.py:52][0m [avg_reward]: -1142.5084597606321
[32m[0514 06:13:17 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:17 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:17 @base_trainer.py:216][0m Mean reward: -1039.423613436248
[32m[0514 06:13:18 @base_main.py:38][0m --------------- Iteration 66 ---------------
[32m[0514 06:13:18 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7592 mins
[32m[0514 06:13:18 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 06:13:18 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 06:13:18 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:18 @base_main.py:47][0m 66330 total steps have happened
[32m[0514 06:13:18 @base_main.py:52][0m [avg_reward]: -1039.423613436248
[32m[0514 06:13:18 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:18 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:18 @base_trainer.py:216][0m Mean reward: -1174.1863809186057
[32m[0514 06:13:18 @base_main.py:38][0m --------------- Iteration 67 ---------------
[32m[0514 06:13:18 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7710 mins
[32m[0514 06:13:18 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 06:13:18 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 06:13:18 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:18 @base_main.py:47][0m 67335 total steps have happened
[32m[0514 06:13:18 @base_main.py:52][0m [avg_reward]: -1174.1863809186057
[32m[0514 06:13:19 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:19 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:19 @base_trainer.py:216][0m Mean reward: -1225.4768874412882
[32m[0514 06:13:19 @base_main.py:38][0m --------------- Iteration 68 ---------------
[32m[0514 06:13:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7828 mins
[32m[0514 06:13:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 06:13:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 06:13:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:19 @base_main.py:47][0m 68340 total steps have happened
[32m[0514 06:13:19 @base_main.py:52][0m [avg_reward]: -1225.4768874412882
[32m[0514 06:13:19 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:19 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:19 @base_trainer.py:216][0m Mean reward: -1004.5894259631881
[32m[0514 06:13:20 @base_main.py:38][0m --------------- Iteration 69 ---------------
[32m[0514 06:13:20 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7944 mins
[32m[0514 06:13:20 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 06:13:20 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 06:13:20 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:20 @base_main.py:47][0m 69345 total steps have happened
[32m[0514 06:13:20 @base_main.py:52][0m [avg_reward]: -1004.5894259631881
[32m[0514 06:13:20 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:20 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:20 @base_trainer.py:216][0m Mean reward: -1188.8369312914733
[32m[0514 06:13:20 @base_main.py:38][0m --------------- Iteration 70 ---------------
[32m[0514 06:13:20 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8060 mins
[32m[0514 06:13:20 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 06:13:20 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 06:13:20 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:20 @base_main.py:47][0m 70350 total steps have happened
[32m[0514 06:13:20 @base_main.py:52][0m [avg_reward]: -1188.8369312914733
[32m[0514 06:13:21 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:21 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:21 @base_trainer.py:216][0m Mean reward: -1167.007794334907
[32m[0514 06:13:21 @base_main.py:38][0m --------------- Iteration 71 ---------------
[32m[0514 06:13:21 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8175 mins
[32m[0514 06:13:21 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 06:13:21 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 06:13:21 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:21 @base_main.py:47][0m 71355 total steps have happened
[32m[0514 06:13:21 @base_main.py:52][0m [avg_reward]: -1167.007794334907
[32m[0514 06:13:21 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:21 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:21 @base_trainer.py:216][0m Mean reward: -1104.0849484671805
[32m[0514 06:13:22 @base_main.py:38][0m --------------- Iteration 72 ---------------
[32m[0514 06:13:22 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8288 mins
[32m[0514 06:13:22 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 06:13:22 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 06:13:22 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:22 @base_main.py:47][0m 72360 total steps have happened
[32m[0514 06:13:22 @base_main.py:52][0m [avg_reward]: -1104.0849484671805
[32m[0514 06:13:22 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:22 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:22 @base_trainer.py:216][0m Mean reward: -1135.8605925024272
[32m[0514 06:13:23 @base_main.py:38][0m --------------- Iteration 73 ---------------
[32m[0514 06:13:23 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8401 mins
[32m[0514 06:13:23 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 06:13:23 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 06:13:23 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:23 @base_main.py:47][0m 73365 total steps have happened
[32m[0514 06:13:23 @base_main.py:52][0m [avg_reward]: -1135.8605925024272
[32m[0514 06:13:23 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:23 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:23 @base_trainer.py:216][0m Mean reward: -1268.402280045457
[32m[0514 06:13:23 @base_main.py:38][0m --------------- Iteration 74 ---------------
[32m[0514 06:13:23 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8514 mins
[32m[0514 06:13:23 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 06:13:23 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 06:13:23 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:23 @base_main.py:47][0m 74370 total steps have happened
[32m[0514 06:13:23 @base_main.py:52][0m [avg_reward]: -1268.402280045457
[32m[0514 06:13:23 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:23 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:23 @base_trainer.py:216][0m Mean reward: -1135.2186638884125
[32m[0514 06:13:24 @base_main.py:38][0m --------------- Iteration 75 ---------------
[32m[0514 06:13:24 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8630 mins
[32m[0514 06:13:24 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 06:13:24 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 06:13:24 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:24 @base_main.py:47][0m 75375 total steps have happened
[32m[0514 06:13:24 @base_main.py:52][0m [avg_reward]: -1135.2186638884125
[32m[0514 06:13:24 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:24 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:24 @base_trainer.py:216][0m Mean reward: -1199.2473486162994
[32m[0514 06:13:25 @base_main.py:38][0m --------------- Iteration 76 ---------------
[32m[0514 06:13:25 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8748 mins
[32m[0514 06:13:25 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0514 06:13:25 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 06:13:25 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:13:25 @base_main.py:47][0m 76380 total steps have happened
[32m[0514 06:13:25 @base_main.py:52][0m [avg_reward]: -1199.2473486162994
[32m[0514 06:13:25 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:25 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:25 @base_trainer.py:216][0m Mean reward: -1236.8610324336362
[32m[0514 06:13:25 @base_main.py:38][0m --------------- Iteration 77 ---------------
[32m[0514 06:13:25 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8860 mins
[32m[0514 06:13:25 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 06:13:25 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 06:13:25 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:25 @base_main.py:47][0m 77385 total steps have happened
[32m[0514 06:13:25 @base_main.py:52][0m [avg_reward]: -1236.8610324336362
[32m[0514 06:13:25 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:25 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:25 @base_trainer.py:216][0m Mean reward: -1260.8000431759297
[32m[0514 06:13:26 @base_main.py:38][0m --------------- Iteration 78 ---------------
[32m[0514 06:13:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8979 mins
[32m[0514 06:13:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 06:13:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0083 mins
[32m[0514 06:13:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:26 @base_main.py:47][0m 78390 total steps have happened
[32m[0514 06:13:26 @base_main.py:52][0m [avg_reward]: -1260.8000431759297
[32m[0514 06:13:26 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:26 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:26 @base_trainer.py:216][0m Mean reward: -1237.4184885312895
[32m[0514 06:13:27 @base_main.py:38][0m --------------- Iteration 79 ---------------
[32m[0514 06:13:27 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9094 mins
[32m[0514 06:13:27 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 06:13:27 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 06:13:27 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:27 @base_main.py:47][0m 79395 total steps have happened
[32m[0514 06:13:27 @base_main.py:52][0m [avg_reward]: -1237.4184885312895
[32m[0514 06:13:27 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:27 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:27 @base_trainer.py:216][0m Mean reward: -1225.9635941140725
[32m[0514 06:13:27 @base_main.py:38][0m --------------- Iteration 80 ---------------
[32m[0514 06:13:27 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9206 mins
[32m[0514 06:13:27 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 06:13:27 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 06:13:27 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:27 @base_main.py:47][0m 80400 total steps have happened
[32m[0514 06:13:27 @base_main.py:52][0m [avg_reward]: -1225.9635941140725
[32m[0514 06:13:28 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:28 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:28 @base_trainer.py:216][0m Mean reward: -1191.5615444693503
[32m[0514 06:13:28 @base_main.py:38][0m --------------- Iteration 81 ---------------
[32m[0514 06:13:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9320 mins
[32m[0514 06:13:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 06:13:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 06:13:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:13:28 @base_main.py:47][0m 81405 total steps have happened
[32m[0514 06:13:28 @base_main.py:52][0m [avg_reward]: -1191.5615444693503
[32m[0514 06:13:28 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:28 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:28 @base_trainer.py:216][0m Mean reward: -1251.0961192652971
[32m[0514 06:13:29 @base_main.py:38][0m --------------- Iteration 82 ---------------
[32m[0514 06:13:29 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9441 mins
[32m[0514 06:13:29 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 06:13:29 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0514 06:13:29 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:29 @base_main.py:47][0m 82410 total steps have happened
[32m[0514 06:13:29 @base_main.py:52][0m [avg_reward]: -1251.0961192652971
[32m[0514 06:13:29 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:29 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:29 @base_trainer.py:216][0m Mean reward: -1189.9633365458817
[32m[0514 06:13:29 @base_main.py:38][0m --------------- Iteration 83 ---------------
[32m[0514 06:13:29 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9554 mins
[32m[0514 06:13:29 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 06:13:29 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 06:13:29 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:29 @base_main.py:47][0m 83415 total steps have happened
[32m[0514 06:13:29 @base_main.py:52][0m [avg_reward]: -1189.9633365458817
[32m[0514 06:13:30 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:30 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:30 @base_trainer.py:216][0m Mean reward: -1257.926689720924
[32m[0514 06:13:30 @base_main.py:38][0m --------------- Iteration 84 ---------------
[32m[0514 06:13:30 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9666 mins
[32m[0514 06:13:30 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 06:13:30 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 06:13:30 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:30 @base_main.py:47][0m 84420 total steps have happened
[32m[0514 06:13:30 @base_main.py:52][0m [avg_reward]: -1257.926689720924
[32m[0514 06:13:30 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:30 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:30 @base_trainer.py:216][0m Mean reward: -1183.1332966593297
[32m[0514 06:13:31 @base_main.py:38][0m --------------- Iteration 85 ---------------
[32m[0514 06:13:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9780 mins
[32m[0514 06:13:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 06:13:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0514 06:13:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:31 @base_main.py:47][0m 85425 total steps have happened
[32m[0514 06:13:31 @base_main.py:52][0m [avg_reward]: -1183.1332966593297
[32m[0514 06:13:31 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:31 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:31 @base_trainer.py:216][0m Mean reward: -1220.670602120179
[32m[0514 06:13:32 @base_main.py:38][0m --------------- Iteration 86 ---------------
[32m[0514 06:13:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9901 mins
[32m[0514 06:13:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 06:13:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 06:13:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:32 @base_main.py:47][0m 86430 total steps have happened
[32m[0514 06:13:32 @base_main.py:52][0m [avg_reward]: -1220.670602120179
[32m[0514 06:13:32 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:32 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:32 @base_trainer.py:216][0m Mean reward: -1263.6768224547482
[32m[0514 06:13:32 @base_main.py:38][0m --------------- Iteration 87 ---------------
[32m[0514 06:13:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0019 mins
[32m[0514 06:13:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 06:13:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 06:13:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:32 @base_main.py:47][0m 87435 total steps have happened
[32m[0514 06:13:32 @base_main.py:52][0m [avg_reward]: -1263.6768224547482
[32m[0514 06:13:32 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:32 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:32 @base_trainer.py:216][0m Mean reward: -1229.786796431914
[32m[0514 06:13:33 @base_main.py:38][0m --------------- Iteration 88 ---------------
[32m[0514 06:13:33 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0134 mins
[32m[0514 06:13:33 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 06:13:33 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 06:13:33 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:33 @base_main.py:47][0m 88440 total steps have happened
[32m[0514 06:13:33 @base_main.py:52][0m [avg_reward]: -1229.786796431914
[32m[0514 06:13:33 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:33 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:33 @base_trainer.py:216][0m Mean reward: -1259.8653273440555
[32m[0514 06:13:34 @base_main.py:38][0m --------------- Iteration 89 ---------------
[32m[0514 06:13:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0250 mins
[32m[0514 06:13:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 06:13:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 06:13:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:34 @base_main.py:47][0m 89445 total steps have happened
[32m[0514 06:13:34 @base_main.py:52][0m [avg_reward]: -1259.8653273440555
[32m[0514 06:13:34 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:34 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:34 @base_trainer.py:216][0m Mean reward: -1248.6260603157668
[32m[0514 06:13:34 @base_main.py:38][0m --------------- Iteration 90 ---------------
[32m[0514 06:13:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0363 mins
[32m[0514 06:13:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 06:13:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 06:13:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:34 @base_main.py:47][0m 90450 total steps have happened
[32m[0514 06:13:34 @base_main.py:52][0m [avg_reward]: -1248.6260603157668
[32m[0514 06:13:34 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:34 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:34 @base_trainer.py:216][0m Mean reward: -1264.5548288706264
[32m[0514 06:13:35 @base_main.py:38][0m --------------- Iteration 91 ---------------
[32m[0514 06:13:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0481 mins
[32m[0514 06:13:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 06:13:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 06:13:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:13:35 @base_main.py:47][0m 91455 total steps have happened
[32m[0514 06:13:35 @base_main.py:52][0m [avg_reward]: -1264.5548288706264
[32m[0514 06:13:35 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:35 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:35 @base_trainer.py:216][0m Mean reward: -1258.07313356377
[32m[0514 06:13:36 @base_main.py:38][0m --------------- Iteration 92 ---------------
[32m[0514 06:13:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0596 mins
[32m[0514 06:13:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 06:13:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 06:13:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:36 @base_main.py:47][0m 92460 total steps have happened
[32m[0514 06:13:36 @base_main.py:52][0m [avg_reward]: -1258.07313356377
[32m[0514 06:13:36 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:36 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:36 @base_trainer.py:216][0m Mean reward: -1288.9983006925572
[32m[0514 06:13:36 @base_main.py:38][0m --------------- Iteration 93 ---------------
[32m[0514 06:13:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0713 mins
[32m[0514 06:13:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 06:13:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 06:13:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:36 @base_main.py:47][0m 93465 total steps have happened
[32m[0514 06:13:36 @base_main.py:52][0m [avg_reward]: -1288.9983006925572
[32m[0514 06:13:37 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:37 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:37 @base_trainer.py:216][0m Mean reward: -1290.3595736187006
[32m[0514 06:13:37 @base_main.py:38][0m --------------- Iteration 94 ---------------
[32m[0514 06:13:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0828 mins
[32m[0514 06:13:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 06:13:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 06:13:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:37 @base_main.py:47][0m 94470 total steps have happened
[32m[0514 06:13:37 @base_main.py:52][0m [avg_reward]: -1290.3595736187006
[32m[0514 06:13:37 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:37 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:37 @base_trainer.py:216][0m Mean reward: -1303.0638110785014
[32m[0514 06:13:38 @base_main.py:38][0m --------------- Iteration 95 ---------------
[32m[0514 06:13:38 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0943 mins
[32m[0514 06:13:38 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0514 06:13:38 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 06:13:38 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:38 @base_main.py:47][0m 95475 total steps have happened
[32m[0514 06:13:38 @base_main.py:52][0m [avg_reward]: -1303.0638110785014
[32m[0514 06:13:38 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:38 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:38 @base_trainer.py:216][0m Mean reward: -1225.134149524062
[32m[0514 06:13:38 @base_main.py:38][0m --------------- Iteration 96 ---------------
[32m[0514 06:13:38 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1059 mins
[32m[0514 06:13:38 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 06:13:38 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 06:13:38 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:38 @base_main.py:47][0m 96480 total steps have happened
[32m[0514 06:13:38 @base_main.py:52][0m [avg_reward]: -1225.134149524062
[32m[0514 06:13:39 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:39 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:39 @base_trainer.py:216][0m Mean reward: -1231.2086421388833
[32m[0514 06:13:39 @base_main.py:38][0m --------------- Iteration 97 ---------------
[32m[0514 06:13:39 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1171 mins
[32m[0514 06:13:39 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 06:13:39 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 06:13:39 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:39 @base_main.py:47][0m 97485 total steps have happened
[32m[0514 06:13:39 @base_main.py:52][0m [avg_reward]: -1231.2086421388833
[32m[0514 06:13:39 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:39 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:39 @base_trainer.py:216][0m Mean reward: -1139.9674128915078
[32m[0514 06:13:40 @base_main.py:38][0m --------------- Iteration 98 ---------------
[32m[0514 06:13:40 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1288 mins
[32m[0514 06:13:40 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 06:13:40 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0514 06:13:40 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:40 @base_main.py:47][0m 98490 total steps have happened
[32m[0514 06:13:40 @base_main.py:52][0m [avg_reward]: -1139.9674128915078
[32m[0514 06:13:40 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:40 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:40 @base_trainer.py:216][0m Mean reward: -1254.8147894862764
[32m[0514 06:13:41 @base_main.py:38][0m --------------- Iteration 99 ---------------
[32m[0514 06:13:41 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1399 mins
[32m[0514 06:13:41 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 06:13:41 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 06:13:41 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:41 @base_main.py:47][0m 99495 total steps have happened
[32m[0514 06:13:41 @base_main.py:52][0m [avg_reward]: -1254.8147894862764
[32m[0514 06:13:41 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:41 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:41 @base_trainer.py:216][0m Mean reward: -1319.6094755887661
[32m[0514 06:13:41 @base_main.py:38][0m --------------- Iteration 100 ---------------
[32m[0514 06:13:41 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1514 mins
[32m[0514 06:13:41 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 06:13:41 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 06:13:41 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:41 @base_main.py:47][0m 100500 total steps have happened
[32m[0514 06:13:41 @base_main.py:52][0m [avg_reward]: -1319.6094755887661
[32m[0514 06:13:41 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:41 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:41 @base_trainer.py:216][0m Mean reward: -1146.7416937733217
[32m[0514 06:13:42 @base_main.py:38][0m --------------- Iteration 101 ---------------
[32m[0514 06:13:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1630 mins
[32m[0514 06:13:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 06:13:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 06:13:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:42 @base_main.py:47][0m 101505 total steps have happened
[32m[0514 06:13:42 @base_main.py:52][0m [avg_reward]: -1146.7416937733217
[32m[0514 06:13:42 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:42 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:42 @base_trainer.py:216][0m Mean reward: -1315.167804817601
[32m[0514 06:13:43 @base_main.py:38][0m --------------- Iteration 102 ---------------
[32m[0514 06:13:43 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1749 mins
[32m[0514 06:13:43 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 06:13:43 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0084 mins
[32m[0514 06:13:43 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:43 @base_main.py:47][0m 102510 total steps have happened
[32m[0514 06:13:43 @base_main.py:52][0m [avg_reward]: -1315.167804817601
[32m[0514 06:13:43 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:43 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:43 @base_trainer.py:216][0m Mean reward: -1305.9018917076123
[32m[0514 06:13:43 @base_main.py:38][0m --------------- Iteration 103 ---------------
[32m[0514 06:13:43 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1860 mins
[32m[0514 06:13:43 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 06:13:43 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 06:13:43 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:43 @base_main.py:47][0m 103515 total steps have happened
[32m[0514 06:13:43 @base_main.py:52][0m [avg_reward]: -1305.9018917076123
[32m[0514 06:13:43 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:43 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:43 @base_trainer.py:216][0m Mean reward: -1352.547266366095
[32m[0514 06:13:44 @base_main.py:38][0m --------------- Iteration 104 ---------------
[32m[0514 06:13:44 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1974 mins
[32m[0514 06:13:44 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 06:13:44 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 06:13:44 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:44 @base_main.py:47][0m 104520 total steps have happened
[32m[0514 06:13:44 @base_main.py:52][0m [avg_reward]: -1352.547266366095
[32m[0514 06:13:44 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:44 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:44 @base_trainer.py:216][0m Mean reward: -1303.7860613031864
[32m[0514 06:13:45 @base_main.py:38][0m --------------- Iteration 105 ---------------
[32m[0514 06:13:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2093 mins
[32m[0514 06:13:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 06:13:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 06:13:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:45 @base_main.py:47][0m 105525 total steps have happened
[32m[0514 06:13:45 @base_main.py:52][0m [avg_reward]: -1303.7860613031864
[32m[0514 06:13:45 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:45 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:45 @base_trainer.py:216][0m Mean reward: -1210.755221277063
[32m[0514 06:13:45 @base_main.py:38][0m --------------- Iteration 106 ---------------
[32m[0514 06:13:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2205 mins
[32m[0514 06:13:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 06:13:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0082 mins
[32m[0514 06:13:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:45 @base_main.py:47][0m 106530 total steps have happened
[32m[0514 06:13:45 @base_main.py:52][0m [avg_reward]: -1210.755221277063
[32m[0514 06:13:45 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:45 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:45 @base_trainer.py:216][0m Mean reward: -1318.9131124649912
[32m[0514 06:13:46 @base_main.py:38][0m --------------- Iteration 107 ---------------
[32m[0514 06:13:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2313 mins
[32m[0514 06:13:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 06:13:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 06:13:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:46 @base_main.py:47][0m 107535 total steps have happened
[32m[0514 06:13:46 @base_main.py:52][0m [avg_reward]: -1318.9131124649912
[32m[0514 06:13:46 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:46 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:46 @base_trainer.py:216][0m Mean reward: -1360.6141829342757
[32m[0514 06:13:47 @base_main.py:38][0m --------------- Iteration 108 ---------------
[32m[0514 06:13:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2429 mins
[32m[0514 06:13:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 06:13:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 06:13:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:47 @base_main.py:47][0m 108540 total steps have happened
[32m[0514 06:13:47 @base_main.py:52][0m [avg_reward]: -1360.6141829342757
[32m[0514 06:13:47 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:47 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:47 @base_trainer.py:216][0m Mean reward: -1175.7336518335817
[32m[0514 06:13:47 @base_main.py:38][0m --------------- Iteration 109 ---------------
[32m[0514 06:13:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2546 mins
[32m[0514 06:13:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 06:13:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 06:13:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:47 @base_main.py:47][0m 109545 total steps have happened
[32m[0514 06:13:47 @base_main.py:52][0m [avg_reward]: -1175.7336518335817
[32m[0514 06:13:48 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:48 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:48 @base_trainer.py:216][0m Mean reward: -1159.1226810210935
[32m[0514 06:13:48 @base_main.py:38][0m --------------- Iteration 110 ---------------
[32m[0514 06:13:48 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2667 mins
[32m[0514 06:13:48 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 06:13:48 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 06:13:48 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:48 @base_main.py:47][0m 110550 total steps have happened
[32m[0514 06:13:48 @base_main.py:52][0m [avg_reward]: -1159.1226810210935
[32m[0514 06:13:48 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:48 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:48 @base_trainer.py:216][0m Mean reward: -1354.3442618069334
[32m[0514 06:13:49 @base_main.py:38][0m --------------- Iteration 111 ---------------
[32m[0514 06:13:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2782 mins
[32m[0514 06:13:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 06:13:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 06:13:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:49 @base_main.py:47][0m 111555 total steps have happened
[32m[0514 06:13:49 @base_main.py:52][0m [avg_reward]: -1354.3442618069334
[32m[0514 06:13:49 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:49 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:49 @base_trainer.py:216][0m Mean reward: -1201.3290061981825
[32m[0514 06:13:50 @base_main.py:38][0m --------------- Iteration 112 ---------------
[32m[0514 06:13:50 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2898 mins
[32m[0514 06:13:50 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 06:13:50 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 06:13:50 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:50 @base_main.py:47][0m 112560 total steps have happened
[32m[0514 06:13:50 @base_main.py:52][0m [avg_reward]: -1201.3290061981825
[32m[0514 06:13:50 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:50 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:50 @base_trainer.py:216][0m Mean reward: -1305.8815235477505
[32m[0514 06:13:50 @base_main.py:38][0m --------------- Iteration 113 ---------------
[32m[0514 06:13:50 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3012 mins
[32m[0514 06:13:50 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 06:13:50 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 06:13:50 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:50 @base_main.py:47][0m 113565 total steps have happened
[32m[0514 06:13:50 @base_main.py:52][0m [avg_reward]: -1305.8815235477505
[32m[0514 06:13:50 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:50 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:50 @base_trainer.py:216][0m Mean reward: -1277.184470213914
[32m[0514 06:13:51 @base_main.py:38][0m --------------- Iteration 114 ---------------
[32m[0514 06:13:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3130 mins
[32m[0514 06:13:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 06:13:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0514 06:13:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:51 @base_main.py:47][0m 114570 total steps have happened
[32m[0514 06:13:51 @base_main.py:52][0m [avg_reward]: -1277.184470213914
[32m[0514 06:13:51 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:51 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:51 @base_trainer.py:216][0m Mean reward: -1370.3797858087619
[32m[0514 06:13:52 @base_main.py:38][0m --------------- Iteration 115 ---------------
[32m[0514 06:13:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3244 mins
[32m[0514 06:13:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 06:13:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 06:13:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:52 @base_main.py:47][0m 115575 total steps have happened
[32m[0514 06:13:52 @base_main.py:52][0m [avg_reward]: -1370.3797858087619
[32m[0514 06:13:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:52 @base_trainer.py:216][0m Mean reward: -1172.8382355148672
[32m[0514 06:13:52 @base_main.py:38][0m --------------- Iteration 116 ---------------
[32m[0514 06:13:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3362 mins
[32m[0514 06:13:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 06:13:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 06:13:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:52 @base_main.py:47][0m 116580 total steps have happened
[32m[0514 06:13:52 @base_main.py:52][0m [avg_reward]: -1172.8382355148672
[32m[0514 06:13:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:52 @base_trainer.py:216][0m Mean reward: -1338.3980236001219
[32m[0514 06:13:53 @base_main.py:38][0m --------------- Iteration 117 ---------------
[32m[0514 06:13:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3474 mins
[32m[0514 06:13:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 06:13:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 06:13:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:53 @base_main.py:47][0m 117585 total steps have happened
[32m[0514 06:13:53 @base_main.py:52][0m [avg_reward]: -1338.3980236001219
[32m[0514 06:13:53 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:53 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:53 @base_trainer.py:216][0m Mean reward: -1243.2785115373226
[32m[0514 06:13:54 @base_main.py:38][0m --------------- Iteration 118 ---------------
[32m[0514 06:13:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3588 mins
[32m[0514 06:13:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 06:13:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 06:13:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:54 @base_main.py:47][0m 118590 total steps have happened
[32m[0514 06:13:54 @base_main.py:52][0m [avg_reward]: -1243.2785115373226
[32m[0514 06:13:54 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:54 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:54 @base_trainer.py:216][0m Mean reward: -1263.5649978149
[32m[0514 06:13:54 @base_main.py:38][0m --------------- Iteration 119 ---------------
[32m[0514 06:13:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3704 mins
[32m[0514 06:13:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0514 06:13:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 06:13:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:54 @base_main.py:47][0m 119595 total steps have happened
[32m[0514 06:13:54 @base_main.py:52][0m [avg_reward]: -1263.5649978149
[32m[0514 06:13:54 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:54 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:54 @base_trainer.py:216][0m Mean reward: -1145.073057552861
[32m[0514 06:13:55 @base_main.py:38][0m --------------- Iteration 120 ---------------
[32m[0514 06:13:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3817 mins
[32m[0514 06:13:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 06:13:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 06:13:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:55 @base_main.py:47][0m 120600 total steps have happened
[32m[0514 06:13:55 @base_main.py:52][0m [avg_reward]: -1145.073057552861
[32m[0514 06:13:55 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:55 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:55 @base_trainer.py:216][0m Mean reward: -1265.0455941461385
[32m[0514 06:13:56 @base_main.py:38][0m --------------- Iteration 121 ---------------
[32m[0514 06:13:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3934 mins
[32m[0514 06:13:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 06:13:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0514 06:13:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:56 @base_main.py:47][0m 121605 total steps have happened
[32m[0514 06:13:56 @base_main.py:52][0m [avg_reward]: -1265.0455941461385
[32m[0514 06:13:56 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:56 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:56 @base_trainer.py:216][0m Mean reward: -1282.9456598508884
[32m[0514 06:13:56 @base_main.py:38][0m --------------- Iteration 122 ---------------
[32m[0514 06:13:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4056 mins
[32m[0514 06:13:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 06:13:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 06:13:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:56 @base_main.py:47][0m 122610 total steps have happened
[32m[0514 06:13:56 @base_main.py:52][0m [avg_reward]: -1282.9456598508884
[32m[0514 06:13:57 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:57 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:57 @base_trainer.py:216][0m Mean reward: -1175.2934274840036
[32m[0514 06:13:57 @base_main.py:38][0m --------------- Iteration 123 ---------------
[32m[0514 06:13:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4173 mins
[32m[0514 06:13:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0514 06:13:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 06:13:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:57 @base_main.py:47][0m 123615 total steps have happened
[32m[0514 06:13:57 @base_main.py:52][0m [avg_reward]: -1175.2934274840036
[32m[0514 06:13:57 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:57 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:57 @base_trainer.py:216][0m Mean reward: -1184.2911120444433
[32m[0514 06:13:58 @base_main.py:38][0m --------------- Iteration 124 ---------------
[32m[0514 06:13:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4283 mins
[32m[0514 06:13:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 06:13:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0514 06:13:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:58 @base_main.py:47][0m 124620 total steps have happened
[32m[0514 06:13:58 @base_main.py:52][0m [avg_reward]: -1184.2911120444433
[32m[0514 06:13:58 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:58 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:58 @base_trainer.py:216][0m Mean reward: -1217.4426875998445
[32m[0514 06:13:59 @base_main.py:38][0m --------------- Iteration 125 ---------------
[32m[0514 06:13:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4394 mins
[32m[0514 06:13:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0514 06:13:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 06:13:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:59 @base_main.py:47][0m 125625 total steps have happened
[32m[0514 06:13:59 @base_main.py:52][0m [avg_reward]: -1217.4426875998445
[32m[0514 06:13:59 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:59 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:59 @base_trainer.py:216][0m Mean reward: -1178.1689698458063
[32m[0514 06:13:59 @base_main.py:38][0m --------------- Iteration 126 ---------------
[32m[0514 06:13:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4513 mins
[32m[0514 06:13:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 06:13:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 06:13:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:59 @base_main.py:47][0m 126630 total steps have happened
[32m[0514 06:13:59 @base_main.py:52][0m [avg_reward]: -1178.1689698458063
[32m[0514 06:13:59 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:59 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:59 @base_trainer.py:216][0m Mean reward: -1202.4085788857415
[32m[0514 06:14:00 @base_main.py:38][0m --------------- Iteration 127 ---------------
[32m[0514 06:14:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4630 mins
[32m[0514 06:14:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 06:14:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 06:14:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:14:00 @base_main.py:47][0m 127635 total steps have happened
[32m[0514 06:14:00 @base_main.py:52][0m [avg_reward]: -1202.4085788857415
[32m[0514 06:14:00 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:00 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:00 @base_trainer.py:216][0m Mean reward: -1193.5084049109096
[32m[0514 06:14:01 @base_main.py:38][0m --------------- Iteration 128 ---------------
[32m[0514 06:14:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4746 mins
[32m[0514 06:14:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0514 06:14:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0514 06:14:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:14:01 @base_main.py:47][0m 128640 total steps have happened
[32m[0514 06:14:01 @base_main.py:52][0m [avg_reward]: -1193.5084049109096
[32m[0514 06:14:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:01 @base_trainer.py:216][0m Mean reward: -1062.0383875735292
[32m[0514 06:14:01 @base_main.py:38][0m --------------- Iteration 129 ---------------
[32m[0514 06:14:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4855 mins
[32m[0514 06:14:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 06:14:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0514 06:14:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:14:01 @base_main.py:47][0m 129645 total steps have happened
[32m[0514 06:14:01 @base_main.py:52][0m [avg_reward]: -1062.0383875735292
[32m[0514 06:14:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:01 @base_trainer.py:216][0m Mean reward: -1085.6506181916568
[32m[0514 06:14:02 @base_main.py:38][0m --------------- Iteration 130 ---------------
[32m[0514 06:14:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4968 mins
[32m[0514 06:14:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0514 06:14:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 06:14:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:14:02 @base_main.py:47][0m 130650 total steps have happened
[32m[0514 06:14:02 @base_main.py:52][0m [avg_reward]: -1085.6506181916568
[32m[0514 06:14:02 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:02 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:02 @base_trainer.py:216][0m Mean reward: -1148.2478081706429
[32m[0514 06:14:03 @base_main.py:38][0m --------------- Iteration 131 ---------------
[32m[0514 06:14:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5085 mins
[32m[0514 06:14:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 06:14:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 06:14:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:14:03 @base_main.py:47][0m 131655 total steps have happened
[32m[0514 06:14:03 @base_main.py:52][0m [avg_reward]: -1148.2478081706429
[32m[0514 06:14:03 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:03 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:03 @base_trainer.py:216][0m Mean reward: -1011.208293468176
[32m[0514 06:14:03 @base_main.py:38][0m --------------- Iteration 132 ---------------
[32m[0514 06:14:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5204 mins
[32m[0514 06:14:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0514 06:14:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 06:14:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:14:03 @base_main.py:47][0m 132660 total steps have happened
[32m[0514 06:14:03 @base_main.py:52][0m [avg_reward]: -1011.208293468176
[32m[0514 06:14:04 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:04 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:04 @base_trainer.py:216][0m Mean reward: -1121.6785795033804
[32m[0514 06:14:04 @base_main.py:38][0m --------------- Iteration 133 ---------------
[32m[0514 06:14:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5319 mins
[32m[0514 06:14:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 06:14:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 06:14:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:14:04 @base_main.py:47][0m 133665 total steps have happened
[32m[0514 06:14:04 @base_main.py:52][0m [avg_reward]: -1121.6785795033804
[32m[0514 06:14:04 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:04 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:04 @base_trainer.py:216][0m Mean reward: -1219.0471748280984
[32m[0514 06:14:05 @base_main.py:38][0m --------------- Iteration 134 ---------------
[32m[0514 06:14:05 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5436 mins
[32m[0514 06:14:05 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0514 06:14:05 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0514 06:14:05 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:14:05 @base_main.py:47][0m 134670 total steps have happened
[32m[0514 06:14:05 @base_main.py:52][0m [avg_reward]: -1219.0471748280984
[32m[0514 06:14:05 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:05 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:05 @base_trainer.py:216][0m Mean reward: -1116.652629748562
[32m[0514 06:14:05 @base_main.py:38][0m --------------- Iteration 135 ---------------
[32m[0514 06:14:05 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5553 mins
[32m[0514 06:14:05 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0514 06:14:05 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 06:14:05 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:14:05 @base_main.py:47][0m 135675 total steps have happened
[32m[0514 06:14:05 @base_main.py:52][0m [avg_reward]: -1116.652629748562
[32m[0514 06:14:06 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:06 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:06 @base_trainer.py:216][0m Mean reward: -1138.8260380013708
[32m[0514 06:14:06 @base_main.py:38][0m --------------- Iteration 136 ---------------
[32m[0514 06:14:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5664 mins
[32m[0514 06:14:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0514 06:14:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0514 06:14:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:14:06 @base_main.py:47][0m 136680 total steps have happened
[32m[0514 06:14:06 @base_main.py:52][0m [avg_reward]: -1138.8260380013708
[32m[0514 06:14:06 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:06 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:06 @base_trainer.py:216][0m Mean reward: -1161.598949378145
[32m[0514 06:14:07 @base_main.py:38][0m --------------- Iteration 137 ---------------
[32m[0514 06:14:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5773 mins
[32m[0514 06:14:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 06:14:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0514 06:14:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:14:07 @base_main.py:47][0m 137685 total steps have happened
[32m[0514 06:14:07 @base_main.py:52][0m [avg_reward]: -1161.598949378145
[32m[0514 06:14:07 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:07 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:07 @base_trainer.py:216][0m Mean reward: -1010.1391250138947
[32m[0514 06:14:07 @base_main.py:38][0m --------------- Iteration 138 ---------------
[32m[0514 06:14:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5885 mins
[32m[0514 06:14:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0514 06:14:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0514 06:14:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:14:07 @base_main.py:47][0m 138690 total steps have happened
[32m[0514 06:14:07 @base_main.py:52][0m [avg_reward]: -1010.1391250138947
[32m[0514 06:14:08 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:08 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:08 @base_trainer.py:216][0m Mean reward: -1057.7643295318353
[32m[0514 06:14:08 @base_main.py:38][0m --------------- Iteration 139 ---------------
[32m[0514 06:14:08 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5994 mins
[32m[0514 06:14:08 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 06:14:08 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0514 06:14:08 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:14:08 @base_main.py:47][0m 139695 total steps have happened
[32m[0514 06:14:08 @base_main.py:52][0m [avg_reward]: -1057.7643295318353
[32m[0514 06:14:08 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:08 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:08 @base_trainer.py:216][0m Mean reward: -1361.6344467804163
[32m[0514 06:14:09 @base_main.py:38][0m --------------- Iteration 140 ---------------
[32m[0514 06:14:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6114 mins
[32m[0514 06:14:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0514 06:14:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0514 06:14:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:14:09 @base_main.py:47][0m 140700 total steps have happened
[32m[0514 06:14:09 @base_main.py:52][0m [avg_reward]: -1361.6344467804163
[32m[0514 06:14:09 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:09 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:09 @base_trainer.py:216][0m Mean reward: -1230.826453196236
[32m[0514 06:14:10 @base_main.py:38][0m --------------- Iteration 141 ---------------
[32m[0514 06:14:10 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6238 mins
[32m[0514 06:14:10 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 06:14:10 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0129 mins
[32m[0514 06:14:10 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:14:10 @base_main.py:47][0m 141705 total steps have happened
[32m[0514 06:14:10 @base_main.py:52][0m [avg_reward]: -1230.826453196236
[32m[0514 06:14:10 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:10 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:10 @base_trainer.py:216][0m Mean reward: -1180.0888657018354
[32m[0514 06:14:11 @base_main.py:38][0m --------------- Iteration 142 ---------------
[32m[0514 06:14:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6394 mins
[32m[0514 06:14:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0514 06:14:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0134 mins
[32m[0514 06:14:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:14:11 @base_main.py:47][0m 142710 total steps have happened
[32m[0514 06:14:11 @base_main.py:52][0m [avg_reward]: -1180.0888657018354
[32m[0514 06:14:11 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:11 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:11 @base_trainer.py:216][0m Mean reward: -1038.1682159641316
[32m[0514 06:14:12 @base_main.py:38][0m --------------- Iteration 143 ---------------
[32m[0514 06:14:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6570 mins
[32m[0514 06:14:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0037 mins
[32m[0514 06:14:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0128 mins
[32m[0514 06:14:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:14:12 @base_main.py:47][0m 143715 total steps have happened
[32m[0514 06:14:12 @base_main.py:52][0m [avg_reward]: -1038.1682159641316
[32m[0514 06:14:12 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:12 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:12 @base_trainer.py:216][0m Mean reward: -1106.779514279469
[32m[0514 06:14:13 @base_main.py:38][0m --------------- Iteration 144 ---------------
[32m[0514 06:14:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6738 mins
[32m[0514 06:14:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0514 06:14:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0141 mins
[32m[0514 06:14:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:14:13 @base_main.py:47][0m 144720 total steps have happened
[32m[0514 06:14:13 @base_main.py:52][0m [avg_reward]: -1106.779514279469
[32m[0514 06:14:13 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:13 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:13 @base_trainer.py:216][0m Mean reward: -1291.4797365472823
[32m[0514 06:14:14 @base_main.py:38][0m --------------- Iteration 145 ---------------
[32m[0514 06:14:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6923 mins
[32m[0514 06:14:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0047 mins
[32m[0514 06:14:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0149 mins
[32m[0514 06:14:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 06:14:14 @base_main.py:47][0m 145725 total steps have happened
[32m[0514 06:14:14 @base_main.py:52][0m [avg_reward]: -1291.4797365472823
[32m[0514 06:14:14 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:14 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:14 @base_trainer.py:216][0m Mean reward: -1105.307626355817
[32m[0514 06:14:15 @base_main.py:38][0m --------------- Iteration 146 ---------------
[32m[0514 06:14:15 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7122 mins
[32m[0514 06:14:15 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0046 mins
[32m[0514 06:14:15 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0132 mins
[32m[0514 06:14:15 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:14:15 @base_main.py:47][0m 146730 total steps have happened
[32m[0514 06:14:15 @base_main.py:52][0m [avg_reward]: -1105.307626355817
[32m[0514 06:14:16 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:16 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:16 @base_trainer.py:216][0m Mean reward: -1075.4884561352965
[32m[0514 06:14:16 @base_main.py:38][0m --------------- Iteration 147 ---------------
[32m[0514 06:14:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7302 mins
[32m[0514 06:14:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0044 mins
[32m[0514 06:14:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0148 mins
[32m[0514 06:14:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:14:16 @base_main.py:47][0m 147735 total steps have happened
[32m[0514 06:14:16 @base_main.py:52][0m [avg_reward]: -1075.4884561352965
[32m[0514 06:14:17 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:17 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:17 @base_trainer.py:216][0m Mean reward: -1128.8985778097444
[32m[0514 06:14:18 @base_main.py:38][0m --------------- Iteration 148 ---------------
[32m[0514 06:14:18 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7498 mins
[32m[0514 06:14:18 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0044 mins
[32m[0514 06:14:18 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0152 mins
[32m[0514 06:14:18 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:14:18 @base_main.py:47][0m 148740 total steps have happened
[32m[0514 06:14:18 @base_main.py:52][0m [avg_reward]: -1128.8985778097444
[32m[0514 06:14:18 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:18 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:18 @base_trainer.py:216][0m Mean reward: -1103.4361386620067
[32m[0514 06:14:19 @base_main.py:38][0m --------------- Iteration 149 ---------------
[32m[0514 06:14:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7697 mins
[32m[0514 06:14:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0038 mins
[32m[0514 06:14:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0143 mins
[32m[0514 06:14:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:14:19 @base_main.py:47][0m 149745 total steps have happened
[32m[0514 06:14:19 @base_main.py:52][0m [avg_reward]: -1103.4361386620067
[32m[0514 06:14:19 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:19 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:19 @base_trainer.py:216][0m Mean reward: -1226.0886703480755
[32m[0514 06:14:20 @base_main.py:38][0m --------------- Iteration 150 ---------------
[32m[0514 06:14:20 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7880 mins
[32m[0514 06:14:20 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0047 mins
[32m[0514 06:14:20 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0141 mins
[32m[0514 06:14:20 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 06:14:20 @base_main.py:47][0m 150750 total steps have happened
[32m[0514 06:14:20 @base_main.py:52][0m [avg_reward]: -1226.0886703480755
[32m[0514 06:14:20 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:20 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:20 @base_trainer.py:216][0m Mean reward: -1251.3341892135527
[32m[0514 06:14:21 @base_main.py:38][0m --------------- Iteration 151 ---------------
[32m[0514 06:14:21 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8071 mins
[32m[0514 06:14:21 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0047 mins
[32m[0514 06:14:21 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0130 mins
[32m[0514 06:14:21 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:14:21 @base_main.py:47][0m 151755 total steps have happened
[32m[0514 06:14:21 @base_main.py:52][0m [avg_reward]: -1251.3341892135527
[32m[0514 06:14:21 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:21 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:21 @base_trainer.py:216][0m Mean reward: -1122.166163875404
[32m[0514 06:14:22 @base_main.py:38][0m --------------- Iteration 152 ---------------
[32m[0514 06:14:22 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8251 mins
[32m[0514 06:14:22 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0047 mins
[32m[0514 06:14:22 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0149 mins
[32m[0514 06:14:22 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:14:22 @base_main.py:47][0m 152760 total steps have happened
[32m[0514 06:14:22 @base_main.py:52][0m [avg_reward]: -1122.166163875404
[32m[0514 06:14:22 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:22 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:22 @base_trainer.py:216][0m Mean reward: -1014.4311953980471
[32m[0514 06:14:23 @base_main.py:38][0m --------------- Iteration 153 ---------------
[32m[0514 06:14:23 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8450 mins
[32m[0514 06:14:23 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0047 mins
[32m[0514 06:14:23 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0142 mins
[32m[0514 06:14:23 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 06:14:23 @base_main.py:47][0m 153765 total steps have happened
[32m[0514 06:14:23 @base_main.py:52][0m [avg_reward]: -1014.4311953980471
[32m[0514 06:14:24 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:24 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:24 @base_trainer.py:216][0m Mean reward: -1202.4210406509999
[32m[0514 06:14:24 @base_main.py:38][0m --------------- Iteration 154 ---------------
[32m[0514 06:14:24 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8642 mins
[32m[0514 06:14:24 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0043 mins
[32m[0514 06:14:24 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0134 mins
[32m[0514 06:14:24 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:14:24 @base_main.py:47][0m 154770 total steps have happened
[32m[0514 06:14:24 @base_main.py:52][0m [avg_reward]: -1202.4210406509999
[32m[0514 06:14:25 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:25 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:25 @base_trainer.py:216][0m Mean reward: -1133.7316003730998
[32m[0514 06:14:26 @base_main.py:38][0m --------------- Iteration 155 ---------------
[32m[0514 06:14:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8821 mins
[32m[0514 06:14:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0049 mins
[32m[0514 06:14:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0141 mins
[32m[0514 06:14:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:14:26 @base_main.py:47][0m 155775 total steps have happened
[32m[0514 06:14:26 @base_main.py:52][0m [avg_reward]: -1133.7316003730998
[32m[0514 06:14:26 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:26 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:26 @base_trainer.py:216][0m Mean reward: -1113.3075118654708
[32m[0514 06:14:27 @base_main.py:38][0m --------------- Iteration 156 ---------------
[32m[0514 06:14:27 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9012 mins
[32m[0514 06:14:27 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0047 mins
[32m[0514 06:14:27 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0144 mins
[32m[0514 06:14:27 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:14:27 @base_main.py:47][0m 156780 total steps have happened
[32m[0514 06:14:27 @base_main.py:52][0m [avg_reward]: -1113.3075118654708
[32m[0514 06:14:27 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:27 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:27 @base_trainer.py:216][0m Mean reward: -1210.3136581108247
[32m[0514 06:14:28 @base_main.py:38][0m --------------- Iteration 157 ---------------
[32m[0514 06:14:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9205 mins
[32m[0514 06:14:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0045 mins
[32m[0514 06:14:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0142 mins
[32m[0514 06:14:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:14:28 @base_main.py:47][0m 157785 total steps have happened
[32m[0514 06:14:28 @base_main.py:52][0m [avg_reward]: -1210.3136581108247
[32m[0514 06:14:28 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:28 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:28 @base_trainer.py:216][0m Mean reward: -1084.9322425831492
[32m[0514 06:14:29 @base_main.py:38][0m --------------- Iteration 158 ---------------
[32m[0514 06:14:29 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9394 mins
[32m[0514 06:14:29 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0048 mins
[32m[0514 06:14:29 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0143 mins
[32m[0514 06:14:29 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:14:29 @base_main.py:47][0m 158790 total steps have happened
[32m[0514 06:14:29 @base_main.py:52][0m [avg_reward]: -1084.9322425831492
[32m[0514 06:14:29 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:29 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:29 @base_trainer.py:216][0m Mean reward: -1241.071656440889
[32m[0514 06:14:30 @base_main.py:38][0m --------------- Iteration 159 ---------------
[32m[0514 06:14:30 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9586 mins
[32m[0514 06:14:30 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0043 mins
[32m[0514 06:14:30 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0136 mins
[32m[0514 06:14:30 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:14:30 @base_main.py:47][0m 159795 total steps have happened
[32m[0514 06:14:30 @base_main.py:52][0m [avg_reward]: -1241.071656440889
[32m[0514 06:14:30 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:30 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:30 @base_trainer.py:216][0m Mean reward: -1225.9780989553547
[32m[0514 06:14:31 @base_main.py:38][0m --------------- Iteration 160 ---------------
[32m[0514 06:14:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9768 mins
[32m[0514 06:14:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0048 mins
[32m[0514 06:14:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0148 mins
[32m[0514 06:14:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:14:31 @base_main.py:47][0m 160800 total steps have happened
[32m[0514 06:14:31 @base_main.py:52][0m [avg_reward]: -1225.9780989553547
[32m[0514 06:14:31 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:31 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:31 @base_trainer.py:216][0m Mean reward: -1187.0338316159687
[32m[0514 06:14:32 @base_main.py:38][0m --------------- Iteration 161 ---------------
[32m[0514 06:14:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9966 mins
[32m[0514 06:14:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0043 mins
[32m[0514 06:14:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0133 mins
[32m[0514 06:14:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:14:32 @base_main.py:47][0m 161805 total steps have happened
[32m[0514 06:14:32 @base_main.py:52][0m [avg_reward]: -1187.0338316159687
[32m[0514 06:14:33 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:33 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:33 @base_trainer.py:216][0m Mean reward: -1084.6721012726425
[32m[0514 06:14:33 @base_main.py:38][0m --------------- Iteration 162 ---------------
[32m[0514 06:14:33 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0144 mins
[32m[0514 06:14:33 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0041 mins
[32m[0514 06:14:33 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0146 mins
[32m[0514 06:14:33 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:14:33 @base_main.py:47][0m 162810 total steps have happened
[32m[0514 06:14:33 @base_main.py:52][0m [avg_reward]: -1084.6721012726425
[32m[0514 06:14:34 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:34 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:34 @base_trainer.py:216][0m Mean reward: -1017.2491057181041
[32m[0514 06:14:35 @base_main.py:38][0m --------------- Iteration 163 ---------------
[32m[0514 06:14:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0333 mins
[32m[0514 06:14:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0046 mins
[32m[0514 06:14:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0143 mins
[32m[0514 06:14:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 06:14:35 @base_main.py:47][0m 163815 total steps have happened
[32m[0514 06:14:35 @base_main.py:52][0m [avg_reward]: -1017.2491057181041
[32m[0514 06:14:35 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:35 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:35 @base_trainer.py:216][0m Mean reward: -1083.183511642177
[32m[0514 06:14:36 @base_main.py:38][0m --------------- Iteration 164 ---------------
[32m[0514 06:14:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0525 mins
[32m[0514 06:14:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0514 06:14:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0144 mins
[32m[0514 06:14:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:14:36 @base_main.py:47][0m 164820 total steps have happened
[32m[0514 06:14:36 @base_main.py:52][0m [avg_reward]: -1083.183511642177
[32m[0514 06:14:36 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:36 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:36 @base_trainer.py:216][0m Mean reward: -1118.2337315773755
[32m[0514 06:14:37 @base_main.py:38][0m --------------- Iteration 165 ---------------
[32m[0514 06:14:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0714 mins
[32m[0514 06:14:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0045 mins
[32m[0514 06:14:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0132 mins
[32m[0514 06:14:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:14:37 @base_main.py:47][0m 165825 total steps have happened
[32m[0514 06:14:37 @base_main.py:52][0m [avg_reward]: -1118.2337315773755
[32m[0514 06:14:37 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:37 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:37 @base_trainer.py:216][0m Mean reward: -958.8034439921912
[32m[0514 06:14:38 @base_main.py:38][0m --------------- Iteration 166 ---------------
[32m[0514 06:14:38 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0893 mins
[32m[0514 06:14:38 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0514 06:14:38 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0142 mins
[32m[0514 06:14:38 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:14:38 @base_main.py:47][0m 166830 total steps have happened
[32m[0514 06:14:38 @base_main.py:52][0m [avg_reward]: -958.8034439921912
[32m[0514 06:14:38 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:38 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:38 @base_trainer.py:216][0m Mean reward: -1116.428038824947
[32m[0514 06:14:39 @base_main.py:38][0m --------------- Iteration 167 ---------------
[32m[0514 06:14:39 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1080 mins
[32m[0514 06:14:39 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0514 06:14:39 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0135 mins
[32m[0514 06:14:39 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:14:39 @base_main.py:47][0m 167835 total steps have happened
[32m[0514 06:14:39 @base_main.py:52][0m [avg_reward]: -1116.428038824947
[32m[0514 06:14:39 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:39 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:39 @base_trainer.py:216][0m Mean reward: -1090.6270243984768
[32m[0514 06:14:40 @base_main.py:38][0m --------------- Iteration 168 ---------------
[32m[0514 06:14:40 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1256 mins
[32m[0514 06:14:40 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0043 mins
[32m[0514 06:14:40 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0150 mins
[32m[0514 06:14:40 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 06:14:40 @base_main.py:47][0m 168840 total steps have happened
[32m[0514 06:14:40 @base_main.py:52][0m [avg_reward]: -1090.6270243984768
[32m[0514 06:14:40 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:40 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:40 @base_trainer.py:216][0m Mean reward: -1076.3427862679257
[32m[0514 06:14:41 @base_main.py:38][0m --------------- Iteration 169 ---------------
[32m[0514 06:14:41 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1452 mins
[32m[0514 06:14:41 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0047 mins
[32m[0514 06:14:41 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0150 mins
[32m[0514 06:14:41 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:14:41 @base_main.py:47][0m 169845 total steps have happened
[32m[0514 06:14:41 @base_main.py:52][0m [avg_reward]: -1076.3427862679257
[32m[0514 06:14:42 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:42 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:42 @base_trainer.py:216][0m Mean reward: -891.693661199632
[32m[0514 06:14:42 @base_main.py:38][0m --------------- Iteration 170 ---------------
[32m[0514 06:14:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1651 mins
[32m[0514 06:14:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0044 mins
[32m[0514 06:14:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0135 mins
[32m[0514 06:14:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:14:42 @base_main.py:47][0m 170850 total steps have happened
[32m[0514 06:14:42 @base_main.py:52][0m [avg_reward]: -891.693661199632
[32m[0514 06:14:43 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:43 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:43 @base_trainer.py:216][0m Mean reward: -1058.4513946682632
[32m[0514 06:14:44 @base_main.py:38][0m --------------- Iteration 171 ---------------
[32m[0514 06:14:44 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1832 mins
[32m[0514 06:14:44 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0050 mins
[32m[0514 06:14:44 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0139 mins
[32m[0514 06:14:44 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 06:14:44 @base_main.py:47][0m 171855 total steps have happened
[32m[0514 06:14:44 @base_main.py:52][0m [avg_reward]: -1058.4513946682632
[32m[0514 06:14:44 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:44 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:44 @base_trainer.py:216][0m Mean reward: -985.3014110920124
[32m[0514 06:14:45 @base_main.py:38][0m --------------- Iteration 172 ---------------
[32m[0514 06:14:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2025 mins
[32m[0514 06:14:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0043 mins
[32m[0514 06:14:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0135 mins
[32m[0514 06:14:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:14:45 @base_main.py:47][0m 172860 total steps have happened
[32m[0514 06:14:45 @base_main.py:52][0m [avg_reward]: -985.3014110920124
[32m[0514 06:14:45 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:45 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:45 @base_trainer.py:216][0m Mean reward: -890.773219151072
[32m[0514 06:14:46 @base_main.py:38][0m --------------- Iteration 173 ---------------
[32m[0514 06:14:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2206 mins
[32m[0514 06:14:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0047 mins
[32m[0514 06:14:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0136 mins
[32m[0514 06:14:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:14:46 @base_main.py:47][0m 173865 total steps have happened
[32m[0514 06:14:46 @base_main.py:52][0m [avg_reward]: -890.773219151072
[32m[0514 06:14:46 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:46 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:46 @base_trainer.py:216][0m Mean reward: -1014.58081548424
[32m[0514 06:14:47 @base_main.py:38][0m --------------- Iteration 174 ---------------
[32m[0514 06:14:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2391 mins
[32m[0514 06:14:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0050 mins
[32m[0514 06:14:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0136 mins
[32m[0514 06:14:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:14:47 @base_main.py:47][0m 174870 total steps have happened
[32m[0514 06:14:47 @base_main.py:52][0m [avg_reward]: -1014.58081548424
[32m[0514 06:14:47 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:47 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:47 @base_trainer.py:216][0m Mean reward: -936.8504283868535
[32m[0514 06:14:48 @base_main.py:38][0m --------------- Iteration 175 ---------------
[32m[0514 06:14:48 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2579 mins
[32m[0514 06:14:48 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0049 mins
[32m[0514 06:14:48 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0137 mins
[32m[0514 06:14:48 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 06:14:48 @base_main.py:47][0m 175875 total steps have happened
[32m[0514 06:14:48 @base_main.py:52][0m [avg_reward]: -936.8504283868535
[32m[0514 06:14:48 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:48 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:48 @base_trainer.py:216][0m Mean reward: -1070.6982392559694
[32m[0514 06:14:49 @base_main.py:38][0m --------------- Iteration 176 ---------------
[32m[0514 06:14:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2767 mins
[32m[0514 06:14:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0514 06:14:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0142 mins
[32m[0514 06:14:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 06:14:49 @base_main.py:47][0m 176880 total steps have happened
[32m[0514 06:14:49 @base_main.py:52][0m [avg_reward]: -1070.6982392559694
[32m[0514 06:14:49 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:49 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:49 @base_trainer.py:216][0m Mean reward: -1051.984767632745
[32m[0514 06:14:50 @base_main.py:38][0m --------------- Iteration 177 ---------------
[32m[0514 06:14:50 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2954 mins
[32m[0514 06:14:50 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0049 mins
[32m[0514 06:14:50 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0132 mins
[32m[0514 06:14:50 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:14:50 @base_main.py:47][0m 177885 total steps have happened
[32m[0514 06:14:50 @base_main.py:52][0m [avg_reward]: -1051.984767632745
[32m[0514 06:14:51 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:51 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:51 @base_trainer.py:216][0m Mean reward: -945.5994943352418
[32m[0514 06:14:51 @base_main.py:38][0m --------------- Iteration 178 ---------------
[32m[0514 06:14:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3138 mins
[32m[0514 06:14:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0044 mins
[32m[0514 06:14:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0145 mins
[32m[0514 06:14:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:14:51 @base_main.py:47][0m 178890 total steps have happened
[32m[0514 06:14:51 @base_main.py:52][0m [avg_reward]: -945.5994943352418
[32m[0514 06:14:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:52 @base_trainer.py:216][0m Mean reward: -956.0614181729907
[32m[0514 06:14:52 @base_main.py:38][0m --------------- Iteration 179 ---------------
[32m[0514 06:14:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3327 mins
[32m[0514 06:14:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0514 06:14:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0125 mins
[32m[0514 06:14:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:14:52 @base_main.py:47][0m 179895 total steps have happened
[32m[0514 06:14:52 @base_main.py:52][0m [avg_reward]: -956.0614181729907
[32m[0514 06:14:53 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:53 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:53 @base_trainer.py:216][0m Mean reward: -1050.647078210185
[32m[0514 06:14:54 @base_main.py:38][0m --------------- Iteration 180 ---------------
[32m[0514 06:14:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3496 mins
[32m[0514 06:14:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0514 06:14:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0143 mins
[32m[0514 06:14:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:14:54 @base_main.py:47][0m 180900 total steps have happened
[32m[0514 06:14:54 @base_main.py:52][0m [avg_reward]: -1050.647078210185
[32m[0514 06:14:54 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:54 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:54 @base_trainer.py:216][0m Mean reward: -974.4396264023375
[32m[0514 06:14:55 @base_main.py:38][0m --------------- Iteration 181 ---------------
[32m[0514 06:14:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3683 mins
[32m[0514 06:14:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0046 mins
[32m[0514 06:14:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0136 mins
[32m[0514 06:14:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:14:55 @base_main.py:47][0m 181905 total steps have happened
[32m[0514 06:14:55 @base_main.py:52][0m [avg_reward]: -974.4396264023375
[32m[0514 06:14:55 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:55 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:55 @base_trainer.py:216][0m Mean reward: -945.5231174500623
[32m[0514 06:14:56 @base_main.py:38][0m --------------- Iteration 182 ---------------
[32m[0514 06:14:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3867 mins
[32m[0514 06:14:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0514 06:14:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0131 mins
[32m[0514 06:14:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:14:56 @base_main.py:47][0m 182910 total steps have happened
[32m[0514 06:14:56 @base_main.py:52][0m [avg_reward]: -945.5231174500623
[32m[0514 06:14:56 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:56 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:56 @base_trainer.py:216][0m Mean reward: -1012.8057495309458
[32m[0514 06:14:57 @base_main.py:38][0m --------------- Iteration 183 ---------------
[32m[0514 06:14:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4043 mins
[32m[0514 06:14:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0514 06:14:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0137 mins
[32m[0514 06:14:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 06:14:57 @base_main.py:47][0m 183915 total steps have happened
[32m[0514 06:14:57 @base_main.py:52][0m [avg_reward]: -1012.8057495309458
[32m[0514 06:14:57 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:57 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:57 @base_trainer.py:216][0m Mean reward: -1024.3264155987204
[32m[0514 06:14:58 @base_main.py:38][0m --------------- Iteration 184 ---------------
[32m[0514 06:14:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4225 mins
[32m[0514 06:14:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0044 mins
[32m[0514 06:14:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0138 mins
[32m[0514 06:14:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:14:58 @base_main.py:47][0m 184920 total steps have happened
[32m[0514 06:14:58 @base_main.py:52][0m [avg_reward]: -1024.3264155987204
[32m[0514 06:14:58 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:58 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:58 @base_trainer.py:216][0m Mean reward: -933.3496280603746
[32m[0514 06:14:59 @base_main.py:38][0m --------------- Iteration 185 ---------------
[32m[0514 06:14:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4409 mins
[32m[0514 06:14:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0043 mins
[32m[0514 06:14:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0139 mins
[32m[0514 06:14:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:14:59 @base_main.py:47][0m 185925 total steps have happened
[32m[0514 06:14:59 @base_main.py:52][0m [avg_reward]: -933.3496280603746
[32m[0514 06:14:59 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:59 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:59 @base_trainer.py:216][0m Mean reward: -1094.5843864548792
[32m[0514 06:15:00 @base_main.py:38][0m --------------- Iteration 186 ---------------
[32m[0514 06:15:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4594 mins
[32m[0514 06:15:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0046 mins
[32m[0514 06:15:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0137 mins
[32m[0514 06:15:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 06:15:00 @base_main.py:47][0m 186930 total steps have happened
[32m[0514 06:15:00 @base_main.py:52][0m [avg_reward]: -1094.5843864548792
[32m[0514 06:15:00 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:15:00 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:15:00 @base_trainer.py:216][0m Mean reward: -1013.4446017227292
[32m[0514 06:15:01 @base_main.py:38][0m --------------- Iteration 187 ---------------
[32m[0514 06:15:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4781 mins
[32m[0514 06:15:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0514 06:15:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0135 mins
[32m[0514 06:15:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:15:01 @base_main.py:47][0m 187935 total steps have happened
[32m[0514 06:15:01 @base_main.py:52][0m [avg_reward]: -1013.4446017227292
[32m[0514 06:15:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:15:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:15:01 @base_trainer.py:216][0m Mean reward: -1045.9398085709565
[32m[0514 06:15:02 @base_main.py:38][0m --------------- Iteration 188 ---------------
[32m[0514 06:15:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4959 mins
[32m[0514 06:15:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0045 mins
[32m[0514 06:15:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0132 mins
[32m[0514 06:15:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:15:02 @base_main.py:47][0m 188940 total steps have happened
[32m[0514 06:15:02 @base_main.py:52][0m [avg_reward]: -1045.9398085709565
[32m[0514 06:15:03 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:15:03 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:15:03 @base_trainer.py:216][0m Mean reward: -1025.6929947908743
[32m[0514 06:15:03 @base_main.py:38][0m --------------- Iteration 189 ---------------
[32m[0514 06:15:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.5138 mins
[32m[0514 06:15:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0045 mins
[32m[0514 06:15:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0143 mins
[32m[0514 06:15:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:15:03 @base_main.py:47][0m 189945 total steps have happened
[32m[0514 06:15:03 @base_main.py:52][0m [avg_reward]: -1025.6929947908743
[32m[0514 06:15:04 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:15:04 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:15:04 @base_trainer.py:216][0m Mean reward: -1020.3488039929922
[32m[0514 06:15:04 @base_main.py:38][0m --------------- Iteration 190 ---------------
[32m[0514 06:15:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.5328 mins
[32m[0514 06:15:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0043 mins
[32m[0514 06:15:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0134 mins
[32m[0514 06:15:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:15:04 @base_main.py:47][0m 190950 total steps have happened
[32m[0514 06:15:04 @base_main.py:52][0m [avg_reward]: -1020.3488039929922
[32m[0514 06:15:05 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:15:05 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:15:05 @base_trainer.py:216][0m Mean reward: -1024.3442191730974
[32m[0514 06:15:06 @base_main.py:38][0m --------------- Iteration 191 ---------------
[32m[0514 06:15:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.5507 mins
[32m[0514 06:15:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0047 mins
[32m[0514 06:15:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0142 mins
[32m[0514 06:15:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:15:06 @base_main.py:47][0m 191955 total steps have happened
[32m[0514 06:15:06 @base_main.py:52][0m [avg_reward]: -1024.3442191730974
[32m[0514 06:15:06 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:15:06 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:15:06 @base_trainer.py:216][0m Mean reward: -985.0368677257093
[32m[0514 06:15:07 @base_main.py:38][0m --------------- Iteration 192 ---------------
[32m[0514 06:15:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.5698 mins
[32m[0514 06:15:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0043 mins
[32m[0514 06:15:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0141 mins
[32m[0514 06:15:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:15:07 @base_main.py:47][0m 192960 total steps have happened
[32m[0514 06:15:07 @base_main.py:52][0m [avg_reward]: -985.0368677257093
[32m[0514 06:15:07 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:15:07 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:15:07 @base_trainer.py:216][0m Mean reward: -1018.3893558790944
[32m[0514 06:15:08 @base_main.py:38][0m --------------- Iteration 193 ---------------
[32m[0514 06:15:08 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.5884 mins
[32m[0514 06:15:08 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0038 mins
[32m[0514 06:15:08 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0137 mins
[32m[0514 06:15:08 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:15:08 @base_main.py:47][0m 193965 total steps have happened
[32m[0514 06:15:08 @base_main.py:52][0m [avg_reward]: -1018.3893558790944
[32m[0514 06:15:08 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:15:08 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:15:08 @base_trainer.py:216][0m Mean reward: -1068.7800188501149
[32m[0514 06:15:09 @base_main.py:38][0m --------------- Iteration 194 ---------------
[32m[0514 06:15:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.6061 mins
[32m[0514 06:15:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0045 mins
[32m[0514 06:15:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0142 mins
[32m[0514 06:15:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:15:09 @base_main.py:47][0m 194970 total steps have happened
[32m[0514 06:15:09 @base_main.py:52][0m [avg_reward]: -1068.7800188501149
[32m[0514 06:15:09 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:15:09 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:15:09 @base_trainer.py:216][0m Mean reward: -1010.7930889565002
[32m[0514 06:15:10 @base_main.py:38][0m --------------- Iteration 195 ---------------
[32m[0514 06:15:10 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.6250 mins
[32m[0514 06:15:10 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0044 mins
[32m[0514 06:15:10 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0154 mins
[32m[0514 06:15:10 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:15:10 @base_main.py:47][0m 195975 total steps have happened
[32m[0514 06:15:10 @base_main.py:52][0m [avg_reward]: -1010.7930889565002
[32m[0514 06:15:10 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:15:10 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:15:10 @base_trainer.py:216][0m Mean reward: -1153.3341558259774
[32m[0514 06:15:11 @base_main.py:38][0m --------------- Iteration 196 ---------------
[32m[0514 06:15:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.6451 mins
[32m[0514 06:15:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0044 mins
[32m[0514 06:15:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0136 mins
[32m[0514 06:15:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:15:11 @base_main.py:47][0m 196980 total steps have happened
[32m[0514 06:15:11 @base_main.py:52][0m [avg_reward]: -1153.3341558259774
[32m[0514 06:15:11 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:15:11 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:15:11 @base_trainer.py:216][0m Mean reward: -1031.0322707593575
[32m[0514 06:15:12 @base_main.py:38][0m --------------- Iteration 197 ---------------
[32m[0514 06:15:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.6632 mins
[32m[0514 06:15:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0044 mins
[32m[0514 06:15:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0136 mins
[32m[0514 06:15:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 06:15:12 @base_main.py:47][0m 197985 total steps have happened
[32m[0514 06:15:12 @base_main.py:52][0m [avg_reward]: -1031.0322707593575
[32m[0514 06:15:13 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:15:13 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:15:13 @base_trainer.py:216][0m Mean reward: -991.6522955197427
[32m[0514 06:15:13 @base_main.py:38][0m --------------- Iteration 198 ---------------
[32m[0514 06:15:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.6815 mins
[32m[0514 06:15:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0046 mins
[32m[0514 06:15:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0136 mins
[32m[0514 06:15:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:15:13 @base_main.py:47][0m 198990 total steps have happened
[32m[0514 06:15:13 @base_main.py:52][0m [avg_reward]: -991.6522955197427
[32m[0514 06:15:14 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:15:14 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:15:14 @base_trainer.py:216][0m Mean reward: -1046.9832365385168
[32m[0514 06:15:15 @base_main.py:38][0m --------------- Iteration 199 ---------------
[32m[0514 06:15:15 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.7000 mins
[32m[0514 06:15:15 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0046 mins
[32m[0514 06:15:15 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0135 mins
[32m[0514 06:15:15 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:15:15 @base_main.py:47][0m 199995 total steps have happened
[32m[0514 06:15:15 @base_main.py:52][0m [avg_reward]: -1046.9832365385168
[32m[0514 06:15:15 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:15:15 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:15:15 @base_trainer.py:216][0m Mean reward: -1148.6385166580424
[32m[0514 06:15:16 @base_main.py:38][0m --------------- Iteration 200 ---------------
[32m[0514 06:15:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.7184 mins
[32m[0514 06:15:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0514 06:15:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0135 mins
[32m[0514 06:15:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 06:15:16 @base_main.py:47][0m 201000 total steps have happened
[32m[0514 06:15:16 @base_main.py:52][0m [avg_reward]: -1148.6385166580424
[32m[0514 06:15:16 @base_worker.py:111][0m kill message for worker 6
[32m[0514 06:15:16 @base_worker.py:111][0m kill message for worker 1
[32m[0514 06:15:16 @base_worker.py:111][0m kill message for worker 3
[32m[0514 06:15:16 @base_worker.py:111][0m kill message for worker 12
[32m[0514 06:15:16 @base_worker.py:111][0m kill message for worker 7
[32m[0514 06:15:16 @base_worker.py:111][0m kill message for worker 15
[32m[0514 06:15:16 @base_worker.py:111][0m kill message for worker 2
[32m[0514 06:15:16 @base_worker.py:111][0m kill message for worker 19
[32m[0514 06:15:16 @base_worker.py:111][0m kill message for worker 10
[32m[0514 06:15:16 @base_worker.py:111][0m kill message for worker 0
[32m[0514 06:15:16 @base_worker.py:111][0m kill message for worker 17
[32m[0514 06:15:16 @base_worker.py:111][0m kill message for worker 9
[32m[0514 06:15:16 @base_worker.py:111][0m kill message for worker 13
[32m[0514 06:15:16 @base_worker.py:111][0m kill message for worker 16
[32m[0514 06:15:16 @base_worker.py:111][0m kill message for worker 4
[32m[0514 06:15:16 @base_worker.py:111][0m kill message for worker 5
[32m[0514 06:15:16 @base_worker.py:111][0m kill message for worker 18
[32m[0514 06:15:16 @base_worker.py:111][0m kill message for worker 14
[32m[0514 06:15:16 @base_worker.py:111][0m kill message for worker 11
[32m[0514 06:15:16 @base_worker.py:111][0m kill message for worker 8
