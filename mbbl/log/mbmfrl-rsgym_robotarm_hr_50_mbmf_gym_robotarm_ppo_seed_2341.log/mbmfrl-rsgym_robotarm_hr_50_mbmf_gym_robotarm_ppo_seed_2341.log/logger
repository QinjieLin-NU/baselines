[32m[0514 05:35:04 @logger.py:103][0m Log file set to /root/mbbl/log/mbmfrl-rsgym_robotarm_hr_50_mbmf_gym_robotarm_ppo_seed_2341.log/mbmfrl-rsgym_robotarm_hr_50_mbmf_gym_robotarm_ppo_seed_2341.log
[32m[0514 05:35:04 @mbmf_main.py:23][0m Training starts at /root/mbbl
[32m[0514 05:35:05 @base_worker.py:45][0m Worker 0 online
[32m[0514 05:35:05 @base_worker.py:45][0m Worker 1 online
[32m[0514 05:35:05 @base_worker.py:45][0m Worker 2 online
[32m[0514 05:35:05 @base_worker.py:45][0m Worker 3 online
[32m[0514 05:35:05 @base_worker.py:45][0m Worker 4 online
[32m[0514 05:35:05 @base_worker.py:45][0m Worker 5 online
[32m[0514 05:35:05 @base_worker.py:45][0m Worker 6 online
[32m[0514 05:35:05 @base_worker.py:45][0m Worker 7 online
[32m[0514 05:35:05 @base_worker.py:45][0m Worker 8 online
[32m[0514 05:35:05 @base_worker.py:45][0m Worker 9 online
[32m[0514 05:35:05 @base_worker.py:45][0m Worker 10 online
[32m[0514 05:35:05 @base_worker.py:45][0m Worker 11 online
[32m[0514 05:35:05 @base_worker.py:45][0m Worker 12 online
[32m[0514 05:35:05 @base_worker.py:45][0m Worker 13 online
[32m[0514 05:35:05 @base_worker.py:45][0m Worker 14 online
[32m[0514 05:35:05 @base_worker.py:45][0m Worker 15 online
[32m[0514 05:35:05 @base_worker.py:45][0m Worker 16 online
[32m[0514 05:35:05 @base_worker.py:45][0m Worker 17 online
[32m[0514 05:35:05 @base_worker.py:45][0m Worker 18 online
[32m[0514 05:35:05 @base_worker.py:45][0m Worker 19 online
[32m[0514 05:35:07 @base_trainer.py:152][0m Trainer maintains [1] policy network
[32m[0514 05:35:07 @base_trainer.py:152][0m Trainer maintains [1] dynamics network
[32m[0514 05:35:07 @base_trainer.py:152][0m Trainer maintains [1] reward network
[32m[0514 05:35:07 @mbmf_main.py:46][0m Generating 1000 random timesteps
[32m[0514 05:35:07 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:35:07 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:35:08 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:35:08 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:35:08 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:35:08 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:35:08 @base_trainer.py:216][0m Mean reward: -383.27955395120006
[32m[0514 05:35:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9249225854873657, Train Loss: 1.1195629835128784
[32m[0514 05:35:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9249372482299805, Train Loss: 1.1195517778396606
[32m[0514 05:35:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9249519109725952, Train Loss: 1.1195405721664429
[32m[0514 05:35:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9249668717384338, Train Loss: 1.1195296049118042
[32m[0514 05:35:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9249820709228516, Train Loss: 1.119518756866455
[32m[0514 05:35:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9249973893165588, Train Loss: 1.1195080280303955
[32m[0514 05:35:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9250125885009766, Train Loss: 1.1194977760314941
[32m[0514 05:35:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9250282049179077, Train Loss: 1.1194874048233032
[32m[0514 05:35:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9250438213348389, Train Loss: 1.1194775104522705
[32m[0514 05:35:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9250596165657043, Train Loss: 1.1194677352905273
[32m[0514 05:35:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9250755906105042, Train Loss: 1.1194580793380737
[32m[0514 05:35:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9250916242599487, Train Loss: 1.1194489002227783
[32m[0514 05:35:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9251077175140381, Train Loss: 1.119439721107483
[32m[0514 05:35:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9251238703727722, Train Loss: 1.1194305419921875
[32m[0514 05:35:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9251402616500854, Train Loss: 1.1194218397140503
[32m[0514 05:35:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9251565933227539, Train Loss: 1.1194133758544922
[32m[0514 05:35:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9251730442047119, Train Loss: 1.119404911994934
[32m[0514 05:35:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9251894354820251, Train Loss: 1.119396686553955
[32m[0514 05:35:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9252060055732727, Train Loss: 1.1193888187408447
[32m[0514 05:35:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9252225160598755, Train Loss: 1.119381070137024
[32m[0514 05:35:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9252393245697021, Train Loss: 1.1193735599517822
[32m[0514 05:35:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9252558350563049, Train Loss: 1.1193662881851196
[32m[0514 05:35:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9252723455429077, Train Loss: 1.1193591356277466
[32m[0514 05:35:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9252889156341553, Train Loss: 1.1193522214889526
[32m[0514 05:35:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9253056049346924, Train Loss: 1.1193453073501587
[32m[0514 05:35:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9253221154212952, Train Loss: 1.1193389892578125
[32m[0514 05:35:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9253386855125427, Train Loss: 1.1193325519561768
[32m[0514 05:35:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9253551363945007, Train Loss: 1.1193265914916992
[32m[0514 05:35:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.925371527671814, Train Loss: 1.1193203926086426
[32m[0514 05:35:08 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9253878593444824, Train Loss: 1.1193146705627441
[32m[0514 05:35:08 @base_main.py:38][0m --------------- Iteration 1 ---------------
[32m[0514 05:35:08 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0000 mins
[32m[0514 05:35:08 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0047 mins
[32m[0514 05:35:08 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0108 mins
[32m[0514 05:35:08 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0036 mins
[32m[0514 05:35:08 @base_main.py:47][0m 1005 total steps have happened
[32m[0514 05:35:08 @base_main.py:52][0m [avg_reward]: -383.27955395120006
[32m[0514 05:35:08 @base_main.py:52][0m [update_op]: None
[32m[0514 05:35:08 @base_main.py:52][0m [train_loss]: 1.1193146705627441
[32m[0514 05:35:08 @base_main.py:52][0m [val_loss]: 0.9253878593444824
[32m[0514 05:35:08 @base_main.py:52][0m [avg_train_loss]: 1.1193146705627441
[32m[0514 05:35:34 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:36:00 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:36:33 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:37:11 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:37:48 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:37:48 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:37:48 @base_trainer.py:216][0m Mean reward: -259.80440613878363
[32m[0514 05:37:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8071976900100708, Train Loss: 1.0705519914627075
[32m[0514 05:37:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8072178959846497, Train Loss: 1.0705569982528687
[32m[0514 05:37:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8072450757026672, Train Loss: 1.0705537796020508
[32m[0514 05:37:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8072767853736877, Train Loss: 1.0705453157424927
[32m[0514 05:37:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.807311475276947, Train Loss: 1.0705337524414062
[32m[0514 05:37:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8073480725288391, Train Loss: 1.070520281791687
[32m[0514 05:37:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8073855042457581, Train Loss: 1.0705060958862305
[32m[0514 05:37:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.80742347240448, Train Loss: 1.0704916715621948
[32m[0514 05:37:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8074618577957153, Train Loss: 1.0704774856567383
[32m[0514 05:37:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8074998259544373, Train Loss: 1.070464015007019
[32m[0514 05:37:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8075377345085144, Train Loss: 1.0704511404037476
[32m[0514 05:37:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8075748682022095, Train Loss: 1.0704388618469238
[32m[0514 05:37:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8076115846633911, Train Loss: 1.0704275369644165
[32m[0514 05:37:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8076472282409668, Train Loss: 1.070417046546936
[32m[0514 05:37:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8076823949813843, Train Loss: 1.0704073905944824
[32m[0514 05:37:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8077165484428406, Train Loss: 1.0703984498977661
[32m[0514 05:37:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.80774986743927, Train Loss: 1.070390224456787
[32m[0514 05:37:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8077822327613831, Train Loss: 1.0703827142715454
[32m[0514 05:37:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8078135848045349, Train Loss: 1.0703758001327515
[32m[0514 05:37:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8078441023826599, Train Loss: 1.0703692436218262
[32m[0514 05:37:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8078736662864685, Train Loss: 1.0703632831573486
[32m[0514 05:37:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8079023361206055, Train Loss: 1.0703577995300293
[32m[0514 05:37:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8079302906990051, Train Loss: 1.0703526735305786
[32m[0514 05:37:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8079572319984436, Train Loss: 1.0703481435775757
[32m[0514 05:37:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8079832792282104, Train Loss: 1.0703437328338623
[32m[0514 05:37:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8080085515975952, Train Loss: 1.0703397989273071
[32m[0514 05:37:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8080329895019531, Train Loss: 1.0703359842300415
[32m[0514 05:37:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8080565929412842, Train Loss: 1.070332646369934
[32m[0514 05:37:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8080794811248779, Train Loss: 1.0703295469284058
[32m[0514 05:37:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8081015944480896, Train Loss: 1.0703264474868774
[32m[0514 05:37:51 @base_main.py:38][0m --------------- Iteration 2 ---------------
[32m[0514 05:37:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0192 mins
[32m[0514 05:37:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 2.6611 mins
[32m[0514 05:37:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0318 mins
[32m[0514 05:37:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0081 mins
[32m[0514 05:37:51 @base_main.py:47][0m 2010 total steps have happened
[32m[0514 05:37:51 @base_main.py:52][0m [avg_reward]: -259.80440613878363
[32m[0514 05:37:51 @base_main.py:52][0m [update_op]: None
[32m[0514 05:37:51 @base_main.py:52][0m [train_loss]: 1.3280766010284424
[32m[0514 05:37:51 @base_main.py:52][0m [val_loss]: 0.8081015944480896
[32m[0514 05:37:51 @base_main.py:52][0m [avg_train_loss]: 1.0703264474868774
[32m[0514 05:38:28 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:39:05 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:39:42 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:40:19 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:40:56 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:40:56 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:40:56 @base_trainer.py:216][0m Mean reward: -353.4014624231174
[32m[0514 05:40:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1613327264785767, Train Loss: 0.9840218424797058
[32m[0514 05:40:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1614032983779907, Train Loss: 0.9840133786201477
[32m[0514 05:40:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1614737510681152, Train Loss: 0.9840024709701538
[32m[0514 05:40:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1615407466888428, Train Loss: 0.9839915037155151
[32m[0514 05:40:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1616029739379883, Train Loss: 0.9839812517166138
[32m[0514 05:40:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.161659836769104, Train Loss: 0.983971893787384
[32m[0514 05:40:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.16171133518219, Train Loss: 0.9839637875556946
[32m[0514 05:40:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1617575883865356, Train Loss: 0.9839568138122559
[32m[0514 05:40:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1617993116378784, Train Loss: 0.9839507937431335
[32m[0514 05:40:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1618363857269287, Train Loss: 0.9839456677436829
[32m[0514 05:40:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1618695259094238, Train Loss: 0.983941376209259
[32m[0514 05:40:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1618990898132324, Train Loss: 0.9839376211166382
[32m[0514 05:40:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1619256734848022, Train Loss: 0.9839345812797546
[32m[0514 05:40:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.161949634552002, Train Loss: 0.9839317202568054
[32m[0514 05:40:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.161970853805542, Train Loss: 0.9839296340942383
[32m[0514 05:40:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1619901657104492, Train Loss: 0.9839276075363159
[32m[0514 05:40:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1620073318481445, Train Loss: 0.9839259386062622
[32m[0514 05:40:58 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1620229482650757, Train Loss: 0.983924388885498
[32m[0514 05:40:58 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1620371341705322, Train Loss: 0.983923077583313
[32m[0514 05:40:58 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1620501279830933, Train Loss: 0.9839218854904175
[32m[0514 05:40:58 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1620615720748901, Train Loss: 0.9839209318161011
[32m[0514 05:40:58 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1620723009109497, Train Loss: 0.9839200973510742
[32m[0514 05:40:58 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1620819568634033, Train Loss: 0.9839194416999817
[32m[0514 05:40:58 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.16209077835083, Train Loss: 0.9839187860488892
[32m[0514 05:40:58 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.162099003791809, Train Loss: 0.9839181900024414
[32m[0514 05:40:58 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1621063947677612, Train Loss: 0.9839175939559937
[32m[0514 05:40:59 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.162113070487976, Train Loss: 0.9839171171188354
[32m[0514 05:40:59 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1621193885803223, Train Loss: 0.9839167594909668
[32m[0514 05:40:59 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1621251106262207, Train Loss: 0.9839164018630981
[32m[0514 05:40:59 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.16213059425354, Train Loss: 0.9839161038398743
[32m[0514 05:40:59 @base_main.py:38][0m --------------- Iteration 3 ---------------
[32m[0514 05:40:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.7204 mins
[32m[0514 05:40:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 3.0850 mins
[32m[0514 05:40:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0559 mins
[32m[0514 05:40:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0073 mins
[32m[0514 05:40:59 @base_main.py:47][0m 3015 total steps have happened
[32m[0514 05:40:59 @base_main.py:52][0m [avg_reward]: -353.4014624231174
[32m[0514 05:40:59 @base_main.py:52][0m [update_op]: None
[32m[0514 05:40:59 @base_main.py:52][0m [train_loss]: 0.9636483192443848
[32m[0514 05:40:59 @base_main.py:52][0m [val_loss]: 1.16213059425354
[32m[0514 05:40:59 @base_main.py:52][0m [avg_train_loss]: 0.9839161038398743
[32m[0514 05:41:36 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:42:13 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:42:49 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:43:26 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:44:03 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:44:03 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:44:03 @base_trainer.py:216][0m Mean reward: -330.1973649263131
[32m[0514 05:44:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4196186363697052, Train Loss: 0.9645993113517761
[32m[0514 05:44:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4196229577064514, Train Loss: 0.9645931124687195
[32m[0514 05:44:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.419627845287323, Train Loss: 0.9645857214927673
[32m[0514 05:44:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4196331202983856, Train Loss: 0.9645788073539734
[32m[0514 05:44:04 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.41963887214660645, Train Loss: 0.9645729064941406
[32m[0514 05:44:04 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.41964468359947205, Train Loss: 0.964568018913269
[32m[0514 05:44:04 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.41965052485466003, Train Loss: 0.964564323425293
[32m[0514 05:44:04 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4196561276912689, Train Loss: 0.9645613431930542
[32m[0514 05:44:04 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4196615517139435, Train Loss: 0.9645591378211975
[32m[0514 05:44:04 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.419666588306427, Train Loss: 0.9645574688911438
[32m[0514 05:44:04 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.41967126727104187, Train Loss: 0.9645562767982483
[32m[0514 05:44:05 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4196755588054657, Train Loss: 0.9645552039146423
[32m[0514 05:44:05 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4196794927120209, Train Loss: 0.964554488658905
[32m[0514 05:44:05 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4196830689907074, Train Loss: 0.9645538926124573
[32m[0514 05:44:05 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4196862578392029, Train Loss: 0.9645535349845886
[32m[0514 05:44:05 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.41968926787376404, Train Loss: 0.9645532369613647
[32m[0514 05:44:05 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.419691801071167, Train Loss: 0.9645528793334961
[32m[0514 05:44:05 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4196941554546356, Train Loss: 0.9645528197288513
[32m[0514 05:44:05 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.41969630122184753, Train Loss: 0.9645525217056274
[32m[0514 05:44:06 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.41969814896583557, Train Loss: 0.9645524024963379
[32m[0514 05:44:06 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.41969990730285645, Train Loss: 0.9645523428916931
[32m[0514 05:44:06 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.41970133781433105, Train Loss: 0.9645523428916931
[32m[0514 05:44:06 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4197026789188385, Train Loss: 0.9645523428916931
[32m[0514 05:44:06 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.419703871011734, Train Loss: 0.9645522236824036
[32m[0514 05:44:06 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.41970497369766235, Train Loss: 0.9645522832870483
[32m[0514 05:44:06 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.41970589756965637, Train Loss: 0.9645522236824036
[32m[0514 05:44:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.419706791639328, Train Loss: 0.9645522236824036
[32m[0514 05:44:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4197075068950653, Train Loss: 0.964552104473114
[32m[0514 05:44:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4197081923484802, Train Loss: 0.9645522236824036
[32m[0514 05:44:07 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.41970881819725037, Train Loss: 0.9645522236824036
[32m[0514 05:44:07 @base_main.py:38][0m --------------- Iteration 4 ---------------
[32m[0514 05:44:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 5.8688 mins
[32m[0514 05:44:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 3.0566 mins
[32m[0514 05:44:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0693 mins
[32m[0514 05:44:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0076 mins
[32m[0514 05:44:07 @base_main.py:47][0m 4020 total steps have happened
[32m[0514 05:44:07 @base_main.py:52][0m [avg_reward]: -330.1973649263131
[32m[0514 05:44:07 @base_main.py:52][0m [update_op]: None
[32m[0514 05:44:07 @base_main.py:52][0m [train_loss]: 0.5335226058959961
[32m[0514 05:44:07 @base_main.py:52][0m [val_loss]: 0.41970881819725037
[32m[0514 05:44:07 @base_main.py:52][0m [avg_train_loss]: 0.9645522236824036
[32m[0514 05:44:44 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:45:21 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:45:57 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:46:34 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:47:12 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:47:12 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:47:12 @base_trainer.py:216][0m Mean reward: -282.7445735479377
[32m[0514 05:47:12 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7657921314239502, Train Loss: 0.984517514705658
[32m[0514 05:47:12 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7658078670501709, Train Loss: 0.984515905380249
[32m[0514 05:47:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.765823483467102, Train Loss: 0.9845142364501953
[32m[0514 05:47:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.765838086605072, Train Loss: 0.984512984752655
[32m[0514 05:47:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7658507227897644, Train Loss: 0.9845119118690491
[32m[0514 05:47:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7658615112304688, Train Loss: 0.9845112562179565
[32m[0514 05:47:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7658704519271851, Train Loss: 0.9845107197761536
[32m[0514 05:47:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7658779621124268, Train Loss: 0.9845104217529297
[32m[0514 05:47:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7658841013908386, Train Loss: 0.9845101833343506
[32m[0514 05:47:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7658891677856445, Train Loss: 0.9845101237297058
[32m[0514 05:47:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7658934593200684, Train Loss: 0.9845101237297058
[32m[0514 05:47:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7658967971801758, Train Loss: 0.9845100045204163
[32m[0514 05:47:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7658997178077698, Train Loss: 0.9845098853111267
[32m[0514 05:47:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7659019827842712, Train Loss: 0.9845097661018372
[32m[0514 05:47:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.765903890132904, Train Loss: 0.9845098853111267
[32m[0514 05:47:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7659055590629578, Train Loss: 0.9845097661018372
[32m[0514 05:47:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7659067511558533, Train Loss: 0.9845098853111267
[32m[0514 05:47:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.765907883644104, Train Loss: 0.9845097661018372
[32m[0514 05:47:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7659087181091309, Train Loss: 0.9845097661018372
[32m[0514 05:47:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7659094333648682, Train Loss: 0.9845097661018372
[32m[0514 05:47:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7659101486206055, Train Loss: 0.9845097661018372
[32m[0514 05:47:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7659105658531189, Train Loss: 0.9845097661018372
[32m[0514 05:47:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7659109830856323, Train Loss: 0.9845097661018372
[32m[0514 05:47:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7659112811088562, Train Loss: 0.9845097661018372
[32m[0514 05:47:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7659115791320801, Train Loss: 0.9845097661018372
[32m[0514 05:47:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7659117579460144, Train Loss: 0.9845097661018372
[32m[0514 05:47:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7659119367599487, Train Loss: 0.9845097661018372
[32m[0514 05:47:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7659120559692383, Train Loss: 0.9845097661018372
[32m[0514 05:47:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7659122347831726, Train Loss: 0.9845097661018372
[32m[0514 05:47:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7659123539924622, Train Loss: 0.9845097661018372
[32m[0514 05:47:17 @base_main.py:38][0m --------------- Iteration 5 ---------------
[32m[0514 05:47:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 9.0024 mins
[32m[0514 05:47:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 3.0759 mins
[32m[0514 05:47:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0817 mins
[32m[0514 05:47:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0080 mins
[32m[0514 05:47:17 @base_main.py:47][0m 5025 total steps have happened
[32m[0514 05:47:17 @base_main.py:52][0m [avg_reward]: -282.7445735479377
[32m[0514 05:47:17 @base_main.py:52][0m [update_op]: None
[32m[0514 05:47:17 @base_main.py:52][0m [train_loss]: 0.4724711775779724
[32m[0514 05:47:17 @base_main.py:52][0m [val_loss]: 0.7659123539924622
[32m[0514 05:47:17 @base_main.py:52][0m [avg_train_loss]: 0.9845097661018372
[32m[0514 05:47:54 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:48:31 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:49:07 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:49:44 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:50:21 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:50:21 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:50:21 @base_trainer.py:216][0m Mean reward: -312.055657722805
[32m[0514 05:50:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9527055025100708, Train Loss: 1.0183745622634888
[32m[0514 05:50:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9527537822723389, Train Loss: 1.0183688402175903
[32m[0514 05:50:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9527974128723145, Train Loss: 1.0183637142181396
[32m[0514 05:50:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9528332948684692, Train Loss: 1.0183600187301636
[32m[0514 05:50:22 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9528619647026062, Train Loss: 1.018357276916504
[32m[0514 05:50:22 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9528847336769104, Train Loss: 1.0183558464050293
[32m[0514 05:50:22 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.95290207862854, Train Loss: 1.0183546543121338
[32m[0514 05:50:22 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.952915608882904, Train Loss: 1.018354058265686
[32m[0514 05:50:22 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9529260993003845, Train Loss: 1.0183534622192383
[32m[0514 05:50:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9529341459274292, Train Loss: 1.0183531045913696
[32m[0514 05:50:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9529402256011963, Train Loss: 1.01835298538208
[32m[0514 05:50:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9529451131820679, Train Loss: 1.0183528661727905
[32m[0514 05:50:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9529489278793335, Train Loss: 1.0183526277542114
[32m[0514 05:50:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9529516696929932, Train Loss: 1.0183526277542114
[32m[0514 05:50:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9529538750648499, Train Loss: 1.0183525085449219
[32m[0514 05:50:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9529556035995483, Train Loss: 1.0183523893356323
[32m[0514 05:50:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.952957034111023, Train Loss: 1.0183523893356323
[32m[0514 05:50:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9529580473899841, Train Loss: 1.0183523893356323
[32m[0514 05:50:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.952958881855011, Train Loss: 1.0183523893356323
[32m[0514 05:50:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9529594779014587, Train Loss: 1.0183523893356323
[32m[0514 05:50:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9529599547386169, Train Loss: 1.0183522701263428
[32m[0514 05:50:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9529602527618408, Train Loss: 1.0183522701263428
[32m[0514 05:50:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9529606103897095, Train Loss: 1.0183522701263428
[32m[0514 05:50:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9529609084129333, Train Loss: 1.0183522701263428
[32m[0514 05:50:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9529611468315125, Train Loss: 1.0183522701263428
[32m[0514 05:50:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.952961266040802, Train Loss: 1.0183522701263428
[32m[0514 05:50:26 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9529614448547363, Train Loss: 1.0183522701263428
[32m[0514 05:50:26 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9529614448547363, Train Loss: 1.0183522701263428
[32m[0514 05:50:26 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9529616236686707, Train Loss: 1.0183522701263428
[32m[0514 05:50:26 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9529616236686707, Train Loss: 1.0183522701263428
[32m[0514 05:50:27 @base_main.py:38][0m --------------- Iteration 6 ---------------
[32m[0514 05:50:27 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 12.1680 mins
[32m[0514 05:50:27 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 3.0549 mins
[32m[0514 05:50:27 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0921 mins
[32m[0514 05:50:27 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0070 mins
[32m[0514 05:50:27 @base_main.py:47][0m 6030 total steps have happened
[32m[0514 05:50:27 @base_main.py:52][0m [avg_reward]: -312.055657722805
[32m[0514 05:50:27 @base_main.py:52][0m [update_op]: None
[32m[0514 05:50:27 @base_main.py:52][0m [train_loss]: 0.918931245803833
[32m[0514 05:50:27 @base_main.py:52][0m [val_loss]: 0.9529616236686707
[32m[0514 05:50:27 @base_main.py:52][0m [avg_train_loss]: 1.0183522701263428
[32m[0514 05:51:04 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:51:41 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:52:17 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:52:54 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:53:31 @mbmf_sampler.py:39][0m done with episode
[32m[0514 05:53:31 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0514 05:53:31 @base_trainer.py:216][0m Mean reward: -276.86554804108744
[32m[0514 05:53:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7923504710197449, Train Loss: 0.9995381236076355
[32m[0514 05:53:32 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7924094796180725, Train Loss: 0.9995331168174744
[32m[0514 05:53:32 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7924644947052002, Train Loss: 0.9995288848876953
[32m[0514 05:53:32 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7925094366073608, Train Loss: 0.9995262622833252
[32m[0514 05:53:32 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7925440073013306, Train Loss: 0.9995246529579163
[32m[0514 05:53:32 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7925699949264526, Train Loss: 0.9995240569114685
[32m[0514 05:53:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7925893664360046, Train Loss: 0.9995235800743103
[32m[0514 05:53:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7926034331321716, Train Loss: 0.999523401260376
[32m[0514 05:53:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7926140427589417, Train Loss: 0.9995232224464417
[32m[0514 05:53:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7926217317581177, Train Loss: 0.9995232224464417
[32m[0514 05:53:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7926273345947266, Train Loss: 0.9995232820510864
[32m[0514 05:53:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7926315665245056, Train Loss: 0.9995232820510864
[32m[0514 05:53:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7926345467567444, Train Loss: 0.9995232224464417
[32m[0514 05:53:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7926367521286011, Train Loss: 0.9995232820510864
[32m[0514 05:53:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7926384210586548, Train Loss: 0.9995232820510864
[32m[0514 05:53:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7926396131515503, Train Loss: 0.9995232224464417
[32m[0514 05:53:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7926404476165771, Train Loss: 0.9995232820510864
[32m[0514 05:53:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7926409840583801, Train Loss: 0.9995232820510864
[32m[0514 05:53:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7926414608955383, Train Loss: 0.9995232820510864
[32m[0514 05:53:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.792641818523407, Train Loss: 0.9995232820510864
[32m[0514 05:53:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7926421165466309, Train Loss: 0.999523401260376
[32m[0514 05:53:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7926422953605652, Train Loss: 0.9995232820510864
[32m[0514 05:53:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7926424741744995, Train Loss: 0.9995232820510864
[32m[0514 05:53:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7926425337791443, Train Loss: 0.9995232820510864
[32m[0514 05:53:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7926426529884338, Train Loss: 0.9995232224464417
[32m[0514 05:53:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7926426529884338, Train Loss: 0.9995232224464417
[32m[0514 05:53:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7926426529884338, Train Loss: 0.9995232224464417
[32m[0514 05:53:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7926428318023682, Train Loss: 0.9995232224464417
[32m[0514 05:53:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7926427125930786, Train Loss: 0.9995232224464417
[32m[0514 05:53:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.7926427125930786, Train Loss: 0.9995232224464417
[32m[0514 05:53:38 @base_main.py:38][0m --------------- Iteration 7 ---------------
[32m[0514 05:53:38 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 15.3221 mins
[32m[0514 05:53:38 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 3.0730 mins
[32m[0514 05:53:38 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.1073 mins
[32m[0514 05:53:38 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0068 mins
[32m[0514 05:53:38 @base_main.py:47][0m 7035 total steps have happened
[32m[0514 05:53:38 @base_main.py:52][0m [avg_reward]: -276.86554804108744
[32m[0514 05:53:38 @base_main.py:52][0m [update_op]: None
[32m[0514 05:53:38 @base_main.py:52][0m [train_loss]: 1.2076572179794312
[32m[0514 05:53:38 @base_main.py:52][0m [val_loss]: 0.7926427125930786
[32m[0514 05:53:38 @base_main.py:52][0m [avg_train_loss]: 0.9995232224464417
[32m[0514 05:53:38 @mbmf_trainer.py:160][0m Mean reward: -314.04979525017774
[32m[0514 05:53:38 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.3208249509334564, Train Loss: 0.31197550892829895
[32m[0514 05:53:38 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.32086920738220215, Train Loss: 0.3118148148059845
[32m[0514 05:53:38 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.3209547698497772, Train Loss: 0.311731219291687
[32m[0514 05:53:38 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.32105520367622375, Train Loss: 0.31166717410087585
[32m[0514 05:53:38 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.32116004824638367, Train Loss: 0.3116113245487213
[32m[0514 05:53:38 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.32126620411872864, Train Loss: 0.31156086921691895
[32m[0514 05:53:38 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.32137295603752136, Train Loss: 0.31151509284973145
[32m[0514 05:53:38 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.32147976756095886, Train Loss: 0.3114735782146454
[32m[0514 05:53:38 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.3215857744216919, Train Loss: 0.31143614649772644
[32m[0514 05:53:39 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.32168999314308167, Train Loss: 0.31140246987342834
[32m[0514 05:53:39 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.3217915892601013, Train Loss: 0.31137213110923767
[32m[0514 05:53:39 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.3218897581100464, Train Loss: 0.3113449215888977
[32m[0514 05:53:39 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.3219839930534363, Train Loss: 0.31132039427757263
[32m[0514 05:53:39 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.3220740258693695, Train Loss: 0.3112981915473938
[32m[0514 05:53:39 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.32215961813926697, Train Loss: 0.3112780749797821
[32m[0514 05:53:39 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.3222406506538391, Train Loss: 0.31125980615615845
[32m[0514 05:53:39 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.3223171830177307, Train Loss: 0.31124308705329895
[32m[0514 05:53:39 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.3223892152309418, Train Loss: 0.3112276494503021
[32m[0514 05:53:39 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.32245689630508423, Train Loss: 0.3112134039402008
[32m[0514 05:53:39 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.32252037525177, Train Loss: 0.3112000524997711
[32m[0514 05:53:39 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.32257992029190063, Train Loss: 0.3111874759197235
[32m[0514 05:53:39 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.32263562083244324, Train Loss: 0.311175674200058
[32m[0514 05:53:39 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.32268789410591125, Train Loss: 0.31116434931755066
[32m[0514 05:53:39 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.32273685932159424, Train Loss: 0.3111535608768463
[32m[0514 05:53:39 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.3227827847003937, Train Loss: 0.3111431300640106
[32m[0514 05:53:39 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.3228258788585663, Train Loss: 0.3111330568790436
[32m[0514 05:53:39 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.32286643981933594, Train Loss: 0.31112316250801086
[32m[0514 05:53:39 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.32290470600128174, Train Loss: 0.3111135959625244
[32m[0514 05:53:39 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.32294073700904846, Train Loss: 0.3111042082309723
[32m[0514 05:53:39 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.32297489047050476, Train Loss: 0.3110949695110321
[32m[0514 05:53:39 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.3230072259902954, Train Loss: 0.3110858201980591
[32m[0514 05:53:39 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.3230380117893219, Train Loss: 0.3110768795013428
[32m[0514 05:53:39 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.3230673372745514, Train Loss: 0.31106799840927124
[32m[0514 05:53:40 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.3230953514575958, Train Loss: 0.3110591769218445
[32m[0514 05:53:40 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.3231222331523895, Train Loss: 0.31105050444602966
[32m[0514 05:53:40 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.3231479823589325, Train Loss: 0.31104183197021484
[32m[0514 05:53:40 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.32317283749580383, Train Loss: 0.3110332190990448
[32m[0514 05:53:40 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.32319676876068115, Train Loss: 0.3110246956348419
[32m[0514 05:53:40 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.32321998476982117, Train Loss: 0.31101617217063904
[32m[0514 05:53:40 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.3232424557209015, Train Loss: 0.3110077381134033
[32m[0514 05:53:40 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.32326430082321167, Train Loss: 0.31099933385849
[32m[0514 05:53:40 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.32328560948371887, Train Loss: 0.31099095940589905
[32m[0514 05:53:40 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.3233063817024231, Train Loss: 0.3109825849533081
[32m[0514 05:53:40 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.3233267068862915, Train Loss: 0.31097424030303955
[32m[0514 05:53:40 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.3233465552330017, Train Loss: 0.3109659254550934
[32m[0514 05:53:40 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.32336604595184326, Train Loss: 0.310957670211792
[32m[0514 05:53:40 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.32338523864746094, Train Loss: 0.310949444770813
[32m[0514 05:53:40 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.3234040141105652, Train Loss: 0.3109411895275116
[32m[0514 05:53:40 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.32342255115509033, Train Loss: 0.310932993888855
[32m[0514 05:53:40 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.323440819978714, Train Loss: 0.31092479825019836
[32m[0514 05:53:40 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.32345879077911377, Train Loss: 0.31091663241386414
[32m[0514 05:53:40 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.32347652316093445, Train Loss: 0.3109085261821747
[32m[0514 05:53:40 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.3234941065311432, Train Loss: 0.31090036034584045
[32m[0514 05:53:40 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.3235114514827728, Train Loss: 0.3108923137187958
[32m[0514 05:53:40 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.32352855801582336, Train Loss: 0.3108842074871063
[32m[0514 05:53:41 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.32354551553726196, Train Loss: 0.31087616086006165
[32m[0514 05:53:41 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.3235623240470886, Train Loss: 0.3108680844306946
[32m[0514 05:53:41 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.32357895374298096, Train Loss: 0.3108600378036499
[32m[0514 05:53:41 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.32359540462493896, Train Loss: 0.3108520209789276
[32m[0514 05:53:41 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.3236117362976074, Train Loss: 0.3108440339565277
[32m[0514 05:53:41 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.32362791895866394, Train Loss: 0.3108360171318054
[32m[0514 05:53:41 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.32364392280578613, Train Loss: 0.3108280599117279
[32m[0514 05:53:41 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.32365986704826355, Train Loss: 0.3108201026916504
[32m[0514 05:53:41 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.32367560267448425, Train Loss: 0.3108121454715729
[32m[0514 05:53:41 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.3236912190914154, Train Loss: 0.31080421805381775
[32m[0514 05:53:41 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.323706716299057, Train Loss: 0.3107962906360626
[32m[0514 05:53:41 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.32372209429740906, Train Loss: 0.31078842282295227
[32m[0514 05:53:41 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.32373732328414917, Train Loss: 0.31078049540519714
[32m[0514 05:53:41 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.32375243306159973, Train Loss: 0.3107726275920868
[32m[0514 05:53:41 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.32376742362976074, Train Loss: 0.31076478958129883
[32m[0514 05:53:41 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.3237822651863098, Train Loss: 0.3107569217681885
[32m[0514 05:53:41 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.32379698753356934, Train Loss: 0.3107490837574005
[32m[0514 05:53:41 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.3238115906715393, Train Loss: 0.3107413053512573
[32m[0514 05:53:41 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.3238261044025421, Train Loss: 0.31073349714279175
[32m[0514 05:53:41 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.323840469121933, Train Loss: 0.3107256591320038
[32m[0514 05:53:41 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.3238546550273895, Train Loss: 0.310717910528183
[32m[0514 05:53:41 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.3238687813282013, Train Loss: 0.3107101321220398
[32m[0514 05:53:41 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.3238827586174011, Train Loss: 0.310702383518219
[32m[0514 05:53:41 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.323896586894989, Train Loss: 0.3106946647167206
[32m[0514 05:53:41 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.32391029596328735, Train Loss: 0.31068694591522217
[32m[0514 05:53:42 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.32392385601997375, Train Loss: 0.31067919731140137
[32m[0514 05:53:42 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.323937326669693, Train Loss: 0.31067153811454773
[32m[0514 05:53:42 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.3239506781101227, Train Loss: 0.31066378951072693
[32m[0514 05:53:42 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.32396385073661804, Train Loss: 0.3106561303138733
[32m[0514 05:53:42 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.32397693395614624, Train Loss: 0.31064847111701965
[32m[0514 05:53:42 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.3239898383617401, Train Loss: 0.31064078211784363
[32m[0514 05:53:42 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.32400262355804443, Train Loss: 0.3106331527233124
[32m[0514 05:53:42 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.3240152895450592, Train Loss: 0.3106255531311035
[32m[0514 05:53:42 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.32402780652046204, Train Loss: 0.31061795353889465
[32m[0514 05:53:42 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.3240402042865753, Train Loss: 0.3106103241443634
[32m[0514 05:53:42 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.3240524232387543, Train Loss: 0.31060272455215454
[32m[0514 05:53:42 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.32406455278396606, Train Loss: 0.3105951249599457
[32m[0514 05:53:42 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.32407650351524353, Train Loss: 0.3105875551700592
[32m[0514 05:53:42 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.32408836483955383, Train Loss: 0.31057998538017273
[32m[0514 05:53:42 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.3241000771522522, Train Loss: 0.31057247519493103
[32m[0514 05:53:42 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.32411158084869385, Train Loss: 0.31056493520736694
[32m[0514 05:53:42 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.3241230249404907, Train Loss: 0.31055739521980286
[32m[0514 05:53:42 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.3241342604160309, Train Loss: 0.31054988503456116
[32m[0514 05:53:42 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.32414543628692627, Train Loss: 0.31054240465164185
[32m[0514 05:53:42 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.32415643334388733, Train Loss: 0.31053492426872253
[32m[0514 05:53:42 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.32416728138923645, Train Loss: 0.3105274438858032
[32m[0514 05:53:42 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.3241780400276184, Train Loss: 0.3105199933052063
[32m[0514 05:53:42 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.32418859004974365, Train Loss: 0.31051257252693176
[32m[0514 05:53:43 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.3241990804672241, Train Loss: 0.31050512194633484
[32m[0514 05:53:43 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.3242093622684479, Train Loss: 0.3104977011680603
[32m[0514 05:53:43 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.3242194950580597, Train Loss: 0.31049028038978577
[32m[0514 05:53:43 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.32422956824302673, Train Loss: 0.3104828894138336
[32m[0514 05:53:43 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.32423946261405945, Train Loss: 0.31047555804252625
[32m[0514 05:53:43 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.3242492377758026, Train Loss: 0.3104681670665741
[32m[0514 05:53:43 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.32425880432128906, Train Loss: 0.31046077609062195
[32m[0514 05:53:43 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.32426831126213074, Train Loss: 0.3104534149169922
[32m[0514 05:53:43 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.32427769899368286, Train Loss: 0.3104461133480072
[32m[0514 05:53:43 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.32428690791130066, Train Loss: 0.31043878197669983
[32m[0514 05:53:43 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.3242959976196289, Train Loss: 0.31043145060539246
[32m[0514 05:53:43 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.3243049383163452, Train Loss: 0.31042417883872986
[32m[0514 05:53:43 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.324313759803772, Train Loss: 0.3104168772697449
[32m[0514 05:53:43 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.3243224322795868, Train Loss: 0.31040963530540466
[32m[0514 05:53:43 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.32433098554611206, Train Loss: 0.31040239334106445
[32m[0514 05:53:43 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.3243394196033478, Train Loss: 0.31039515137672424
[32m[0514 05:53:43 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.32434770464897156, Train Loss: 0.31038787961006165
[32m[0514 05:53:43 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.3243559002876282, Train Loss: 0.3103807270526886
[32m[0514 05:53:43 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.32436391711235046, Train Loss: 0.3103735148906708
[32m[0514 05:53:43 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.3243718445301056, Train Loss: 0.31036636233329773
[32m[0514 05:53:43 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.3243796229362488, Train Loss: 0.3103591799736023
[32m[0514 05:53:43 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.3243873119354248, Train Loss: 0.31035202741622925
[32m[0514 05:53:43 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.3243948519229889, Train Loss: 0.3103448748588562
[32m[0514 05:53:43 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.32440224289894104, Train Loss: 0.31033778190612793
[32m[0514 05:53:44 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.3244095742702484, Train Loss: 0.31033065915107727
[32m[0514 05:53:44 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.32441675662994385, Train Loss: 0.310323566198349
[32m[0514 05:53:44 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.32442378997802734, Train Loss: 0.3103165030479431
[32m[0514 05:53:44 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.32443076372146606, Train Loss: 0.31030943989753723
[32m[0514 05:53:44 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.32443758845329285, Train Loss: 0.31030240654945374
[32m[0514 05:53:44 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.32444432377815247, Train Loss: 0.31029537320137024
[32m[0514 05:53:44 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.32445088028907776, Train Loss: 0.3102883994579315
[32m[0514 05:53:44 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.3244573473930359, Train Loss: 0.310281366109848
[32m[0514 05:53:44 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.32446378469467163, Train Loss: 0.3102744221687317
[32m[0514 05:53:44 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.32447004318237305, Train Loss: 0.31026744842529297
[32m[0514 05:53:44 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.3244762122631073, Train Loss: 0.310260534286499
[32m[0514 05:53:44 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.324482262134552, Train Loss: 0.3102535605430603
[32m[0514 05:53:44 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.32448819279670715, Train Loss: 0.31024667620658875
[32m[0514 05:53:44 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.32449406385421753, Train Loss: 0.3102397620677948
[32m[0514 05:53:44 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.32449981570243835, Train Loss: 0.31023287773132324
[32m[0514 05:53:44 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.324505478143692, Train Loss: 0.3102260231971741
[32m[0514 05:53:44 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.32451102137565613, Train Loss: 0.3102191984653473
[32m[0514 05:53:44 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.3245164453983307, Train Loss: 0.3102124035358429
[32m[0514 05:53:44 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.3245217502117157, Train Loss: 0.3102055490016937
[32m[0514 05:53:44 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.3245270550251007, Train Loss: 0.31019875407218933
[32m[0514 05:53:44 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.3245321810245514, Train Loss: 0.3101919889450073
[32m[0514 05:53:44 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.3245372176170349, Train Loss: 0.3101852238178253
[32m[0514 05:53:45 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.32454222440719604, Train Loss: 0.3101785182952881
[32m[0514 05:53:45 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.32454714179039, Train Loss: 0.31017178297042847
[32m[0514 05:53:45 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.32455193996429443, Train Loss: 0.31016507744789124
[32m[0514 05:53:45 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.3245565891265869, Train Loss: 0.310158371925354
[32m[0514 05:53:45 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.3245612382888794, Train Loss: 0.31015172600746155
[32m[0514 05:53:45 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.3245657682418823, Train Loss: 0.3101450502872467
[32m[0514 05:53:45 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.3245702087879181, Train Loss: 0.31013843417167664
[32m[0514 05:53:45 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.3245745897293091, Train Loss: 0.31013181805610657
[32m[0514 05:53:45 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.3245788514614105, Train Loss: 0.3101252317428589
[32m[0514 05:53:45 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.3245830833911896, Train Loss: 0.3101186454296112
[32m[0514 05:53:45 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.3245871961116791, Train Loss: 0.3101120889186859
[32m[0514 05:53:45 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.3245912492275238, Train Loss: 0.3101055324077606
[32m[0514 05:53:45 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.32459521293640137, Train Loss: 0.3100990653038025
[32m[0514 05:53:45 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.32459911704063416, Train Loss: 0.3100925385951996
[32m[0514 05:53:45 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.3246029317378998, Train Loss: 0.31008604168891907
[32m[0514 05:53:45 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.324606716632843, Train Loss: 0.3100796043872833
[32m[0514 05:53:45 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.3246103525161743, Train Loss: 0.3100731372833252
[32m[0514 05:53:45 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.3246139883995056, Train Loss: 0.31006672978401184
[32m[0514 05:53:45 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.32461753487586975, Train Loss: 0.3100602924823761
[32m[0514 05:53:45 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.3246209919452667, Train Loss: 0.31005391478538513
[32m[0514 05:53:45 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.3246243894100189, Train Loss: 0.31004753708839417
[32m[0514 05:53:45 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.32462775707244873, Train Loss: 0.3100411891937256
[32m[0514 05:53:45 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.3246310353279114, Train Loss: 0.3100348711013794
[32m[0514 05:53:46 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.32463425397872925, Train Loss: 0.3100285232067108
[32m[0514 05:53:46 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.32463741302490234, Train Loss: 0.310022234916687
[32m[0514 05:53:46 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.32464051246643066, Train Loss: 0.3100159466266632
[32m[0514 05:53:46 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.3246435523033142, Train Loss: 0.3100096583366394
[32m[0514 05:53:46 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.324646532535553, Train Loss: 0.3100034296512604
[32m[0514 05:53:46 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.324649453163147, Train Loss: 0.30999717116355896
[32m[0514 05:53:46 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.3246523439884186, Train Loss: 0.3099909722805023
[32m[0514 05:53:46 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.32465511560440063, Train Loss: 0.30998480319976807
[32m[0514 05:53:46 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.3246578574180603, Train Loss: 0.30997857451438904
[32m[0514 05:53:46 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.3246605694293976, Train Loss: 0.3099724352359772
[32m[0514 05:53:46 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.3246632516384125, Train Loss: 0.3099662959575653
[32m[0514 05:53:46 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.3246658146381378, Train Loss: 0.30996015667915344
[32m[0514 05:53:46 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.32466840744018555, Train Loss: 0.3099540174007416
[32m[0514 05:53:46 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.3246708810329437, Train Loss: 0.3099479675292969
[32m[0514 05:53:46 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.3246733546257019, Train Loss: 0.3099418878555298
[32m[0514 05:53:46 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.3246757686138153, Train Loss: 0.3099358379840851
[32m[0514 05:53:46 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.3246781527996063, Train Loss: 0.3099297881126404
[32m[0514 05:53:46 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.3246804475784302, Train Loss: 0.30992376804351807
[32m[0514 05:53:46 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.32468274235725403, Train Loss: 0.30991777777671814
[32m[0514 05:53:46 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.3246849477291107, Train Loss: 0.3099117577075958
[32m[0514 05:53:46 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.324687123298645, Train Loss: 0.3099057972431183
[32m[0514 05:53:47 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.32468926906585693, Train Loss: 0.30989983677864075
[32m[0514 05:53:47 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.32469141483306885, Train Loss: 0.3098938763141632
[32m[0514 05:53:47 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.324693500995636, Train Loss: 0.30988797545433044
[32m[0514 05:53:47 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.32469549775123596, Train Loss: 0.3098820447921753
[32m[0514 05:53:47 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.3246975243091583, Train Loss: 0.3098761737346649
[32m[0514 05:53:47 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.3246994912624359, Train Loss: 0.30987030267715454
[32m[0514 05:53:47 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.3247013986110687, Train Loss: 0.30986443161964417
[32m[0514 05:53:47 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.32470330595970154, Train Loss: 0.30985862016677856
[32m[0514 05:53:47 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.3247051537036896, Train Loss: 0.3098527491092682
[32m[0514 05:53:47 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.32470694184303284, Train Loss: 0.3098469376564026
[32m[0514 05:53:47 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.3247087597846985, Train Loss: 0.309841126203537
[32m[0514 05:53:47 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.324710488319397, Train Loss: 0.30983537435531616
[32m[0514 05:53:47 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.32471224665641785, Train Loss: 0.30982956290245056
[32m[0514 05:53:47 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.32471394538879395, Train Loss: 0.30982378125190735
[32m[0514 05:53:47 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.32471558451652527, Train Loss: 0.3098180592060089
[32m[0514 05:53:47 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.3247172236442566, Train Loss: 0.3098123073577881
[32m[0514 05:53:47 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.32471880316734314, Train Loss: 0.30980661511421204
[32m[0514 05:53:47 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.3247204124927521, Train Loss: 0.3098009526729584
[32m[0514 05:53:47 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.32472196221351624, Train Loss: 0.30979523062705994
[32m[0514 05:53:47 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.3247235417366028, Train Loss: 0.3097895681858063
[32m[0514 05:53:47 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.3247250020503998, Train Loss: 0.3097839057445526
[32m[0514 05:53:47 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.3247264623641968, Train Loss: 0.30977821350097656
[32m[0514 05:53:48 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.3247279226779938, Train Loss: 0.3097726106643677
[32m[0514 05:53:48 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.3247293531894684, Train Loss: 0.3097669780254364
[32m[0514 05:53:48 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.324730783700943, Train Loss: 0.3097613751888275
[32m[0514 05:53:48 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.3247321844100952, Train Loss: 0.309755802154541
[32m[0514 05:53:48 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.32473355531692505, Train Loss: 0.3097502291202545
[32m[0514 05:53:48 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.3247348666191101, Train Loss: 0.30974462628364563
[32m[0514 05:53:48 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.32473617792129517, Train Loss: 0.3097390830516815
[32m[0514 05:53:48 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.3247375190258026, Train Loss: 0.3097335398197174
[32m[0514 05:53:48 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.3247388005256653, Train Loss: 0.3097279965877533
[32m[0514 05:53:48 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.32474005222320557, Train Loss: 0.3097224533557892
[32m[0514 05:53:48 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.32474133372306824, Train Loss: 0.30971696972846985
[32m[0514 05:53:48 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.32474255561828613, Train Loss: 0.3097114562988281
[32m[0514 05:53:48 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.32474374771118164, Train Loss: 0.3097059726715088
[32m[0514 05:53:48 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.32474493980407715, Train Loss: 0.30970051884651184
[32m[0514 05:53:48 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.32474613189697266, Train Loss: 0.3096950352191925
[32m[0514 05:53:48 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.3247472941875458, Train Loss: 0.30968961119651794
[32m[0514 05:53:48 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.3247484564781189, Train Loss: 0.3096841275691986
[32m[0514 05:53:48 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.32474955916404724, Train Loss: 0.3096787631511688
[32m[0514 05:53:48 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.32475072145462036, Train Loss: 0.3096732795238495
[32m[0514 05:53:48 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.3247517943382263, Train Loss: 0.3096678853034973
[32m[0514 05:53:48 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.32475292682647705, Train Loss: 0.30966249108314514
[32m[0514 05:53:48 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.324753999710083, Train Loss: 0.30965709686279297
[32m[0514 05:53:48 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.3247550427913666, Train Loss: 0.3096517324447632
[32m[0514 05:53:49 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.32475611567497253, Train Loss: 0.3096463978290558
[32m[0514 05:53:49 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.3247571587562561, Train Loss: 0.3096409738063812
[32m[0514 05:53:49 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.3247581720352173, Train Loss: 0.30963560938835144
[32m[0514 05:53:49 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.32475918531417847, Train Loss: 0.30963030457496643
[32m[0514 05:53:49 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.32476022839546204, Train Loss: 0.30962494015693665
[32m[0514 05:53:49 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.3247612416744232, Train Loss: 0.30961963534355164
[32m[0514 05:53:49 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.3247621953487396, Train Loss: 0.3096143305301666
[32m[0514 05:53:49 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.3247632086277008, Train Loss: 0.30960896611213684
[32m[0514 05:53:49 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.3247641324996948, Train Loss: 0.3096037209033966
[32m[0514 05:53:49 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.324765145778656, Train Loss: 0.3095984160900116
[32m[0514 05:53:49 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.3247660994529724, Train Loss: 0.30959317088127136
[32m[0514 05:53:49 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.32476702332496643, Train Loss: 0.30958786606788635
[32m[0514 05:53:49 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.32476794719696045, Train Loss: 0.30958259105682373
[32m[0514 05:53:49 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.32476890087127686, Train Loss: 0.3095773160457611
[32m[0514 05:53:49 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.3247698247432709, Train Loss: 0.3095720708370209
[32m[0514 05:53:49 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.3247707486152649, Train Loss: 0.309566855430603
[32m[0514 05:53:49 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.3247716724872589, Train Loss: 0.3095616102218628
[32m[0514 05:53:49 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.32477256655693054, Train Loss: 0.30955636501312256
[32m[0514 05:53:49 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.3247734606266022, Train Loss: 0.3095512092113495
[32m[0514 05:53:49 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.3247743248939514, Train Loss: 0.30954596400260925
[32m[0514 05:53:49 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.32477521896362305, Train Loss: 0.3095407783985138
[32m[0514 05:53:49 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.3247760832309723, Train Loss: 0.30953556299209595
[32m[0514 05:53:50 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.3247770369052887, Train Loss: 0.3095303475856781
[32m[0514 05:53:50 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.32477784156799316, Train Loss: 0.30952516198158264
[32m[0514 05:53:50 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.3247787356376648, Train Loss: 0.30952003598213196
[32m[0514 05:53:50 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.32477959990501404, Train Loss: 0.3095148503780365
[32m[0514 05:53:50 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.32478049397468567, Train Loss: 0.30950966477394104
[32m[0514 05:53:50 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.32478129863739014, Train Loss: 0.30950450897216797
[32m[0514 05:53:50 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.3247821629047394, Train Loss: 0.3094993531703949
[32m[0514 05:53:50 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.32478299736976624, Train Loss: 0.3094941973686218
[32m[0514 05:53:50 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.3247838318347931, Train Loss: 0.30948910117149353
[32m[0514 05:53:50 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.3247847259044647, Train Loss: 0.30948391556739807
[32m[0514 05:53:50 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.3247855305671692, Train Loss: 0.3094788193702698
[32m[0514 05:53:50 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.32478636503219604, Train Loss: 0.3094736933708191
[32m[0514 05:53:50 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.3247871994972229, Train Loss: 0.3094685673713684
[32m[0514 05:53:50 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.32478803396224976, Train Loss: 0.3094634711742401
[32m[0514 05:53:50 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.3247888684272766, Train Loss: 0.3094583749771118
[32m[0514 05:53:50 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.3247896730899811, Train Loss: 0.3094532787799835
[32m[0514 05:53:50 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.3247905373573303, Train Loss: 0.30944815278053284
[32m[0514 05:53:50 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.3247913122177124, Train Loss: 0.30944305658340454
[32m[0514 05:53:50 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.32479214668273926, Train Loss: 0.30943799018859863
[32m[0514 05:53:50 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.3247929513454437, Train Loss: 0.30943289399147034
[32m[0514 05:53:50 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.3247937858104706, Train Loss: 0.30942776799201965
[32m[0514 05:53:50 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.32479462027549744, Train Loss: 0.30942273139953613
[32m[0514 05:53:50 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.3247954249382019, Train Loss: 0.30941763520240784
[32m[0514 05:53:51 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.32479625940322876, Train Loss: 0.30941256880760193
[32m[0514 05:53:51 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.3247970640659332, Train Loss: 0.3094075322151184
[32m[0514 05:53:51 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.3247978985309601, Train Loss: 0.3094024956226349
[32m[0514 05:53:51 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.3247986435890198, Train Loss: 0.30939745903015137
[32m[0514 05:53:51 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.324799507856369, Train Loss: 0.30939236283302307
[32m[0514 05:53:51 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.3248003125190735, Train Loss: 0.30938732624053955
[32m[0514 05:53:51 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.32480114698410034, Train Loss: 0.30938228964805603
[32m[0514 05:53:51 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.3248019814491272, Train Loss: 0.3093772828578949
[32m[0514 05:53:51 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.32480278611183167, Train Loss: 0.309372216463089
[32m[0514 05:53:51 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.32480359077453613, Train Loss: 0.30936720967292786
[32m[0514 05:53:51 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.324804425239563, Train Loss: 0.3093622028827667
[32m[0514 05:53:51 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.32480525970458984, Train Loss: 0.3093571364879608
[32m[0514 05:53:51 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.3248060643672943, Train Loss: 0.3093521296977997
[32m[0514 05:53:51 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.3248068690299988, Train Loss: 0.30934712290763855
[32m[0514 05:53:51 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.324807733297348, Train Loss: 0.30934208631515503
[32m[0514 05:53:51 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.3248085379600525, Train Loss: 0.3093371093273163
[32m[0514 05:53:51 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.32480937242507935, Train Loss: 0.30933207273483276
[32m[0514 05:53:52 @mbmf_sampler.py:98][0m Finished 9th episode
[32m[0514 05:53:52 @mbmf_sampler.py:102][0m 1809 timesteps from 9 episodes collected
[32m[0514 05:59:16 @mbmf_trainer.py:160][0m Mean reward: -310.0205838444602
[32m[0514 05:59:16 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.3040072023868561, Train Loss: 0.31332796812057495
[32m[0514 05:59:16 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.304506778717041, Train Loss: 0.31320682168006897
[32m[0514 05:59:16 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.30478423833847046, Train Loss: 0.31315478682518005
[32m[0514 05:59:16 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.30483952164649963, Train Loss: 0.31313392519950867
[32m[0514 05:59:16 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.30481964349746704, Train Loss: 0.31311509013175964
[32m[0514 05:59:16 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.3047963082790375, Train Loss: 0.3130960762500763
[32m[0514 05:59:16 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.30478182435035706, Train Loss: 0.3130781948566437
[32m[0514 05:59:17 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.3047731816768646, Train Loss: 0.31306180357933044
[32m[0514 05:59:17 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.3047683537006378, Train Loss: 0.31304675340652466
[32m[0514 05:59:17 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.3047664165496826, Train Loss: 0.3130328953266144
[32m[0514 05:59:17 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.30476662516593933, Train Loss: 0.31301993131637573
[32m[0514 05:59:17 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.3047683537006378, Train Loss: 0.3130077123641968
[32m[0514 05:59:17 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.3047711253166199, Train Loss: 0.3129960894584656
[32m[0514 05:59:17 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.3047747015953064, Train Loss: 0.3129850924015045
[32m[0514 05:59:17 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.3047791123390198, Train Loss: 0.3129745125770569
[32m[0514 05:59:17 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.3047841489315033, Train Loss: 0.3129643201828003
[32m[0514 05:59:17 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.30478978157043457, Train Loss: 0.31295451521873474
[32m[0514 05:59:17 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.3047959804534912, Train Loss: 0.3129449486732483
[32m[0514 05:59:17 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.3048025965690613, Train Loss: 0.3129357099533081
[32m[0514 05:59:17 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.3048095405101776, Train Loss: 0.3129267394542694
[32m[0514 05:59:17 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.3048168420791626, Train Loss: 0.3129179775714874
[32m[0514 05:59:17 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.30482447147369385, Train Loss: 0.31290942430496216
[32m[0514 05:59:17 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.3048323094844818, Train Loss: 0.31290102005004883
[32m[0514 05:59:17 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.30484044551849365, Train Loss: 0.3128928244113922
[32m[0514 05:59:17 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.30484873056411743, Train Loss: 0.31288474798202515
[32m[0514 05:59:18 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.3048572242259979, Train Loss: 0.31287679076194763
[32m[0514 05:59:18 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.3048657774925232, Train Loss: 0.31286901235580444
[32m[0514 05:59:18 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.3048745393753052, Train Loss: 0.3128613233566284
[32m[0514 05:59:18 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.3048834502696991, Train Loss: 0.31285378336906433
[32m[0514 05:59:18 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.3048924207687378, Train Loss: 0.312846302986145
[32m[0514 05:59:18 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.30490151047706604, Train Loss: 0.31283897161483765
[32m[0514 05:59:18 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.30491068959236145, Train Loss: 0.31283167004585266
[32m[0514 05:59:18 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.30491992831230164, Train Loss: 0.3128245174884796
[32m[0514 05:59:18 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.3049292266368866, Train Loss: 0.31281739473342896
[32m[0514 05:59:18 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.3049386143684387, Train Loss: 0.31281036138534546
[32m[0514 05:59:18 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.3049480617046356, Train Loss: 0.31280335783958435
[32m[0514 05:59:18 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.3049575388431549, Train Loss: 0.31279653310775757
[32m[0514 05:59:18 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.3049670457839966, Train Loss: 0.3127896189689636
[32m[0514 05:59:18 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.3049766719341278, Train Loss: 0.3127828538417816
[32m[0514 05:59:18 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.30498626828193665, Train Loss: 0.3127761781215668
[32m[0514 05:59:18 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.3049958646297455, Train Loss: 0.3127695322036743
[32m[0514 05:59:18 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.30500558018684387, Train Loss: 0.31276291608810425
[32m[0514 05:59:18 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.3050152063369751, Train Loss: 0.31275638937950134
[32m[0514 05:59:18 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.3050249218940735, Train Loss: 0.3127498924732208
[32m[0514 05:59:19 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.30503466725349426, Train Loss: 0.3127434551715851
[32m[0514 05:59:19 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.30504438281059265, Train Loss: 0.31273701786994934
[32m[0514 05:59:19 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.3050541281700134, Train Loss: 0.31273066997528076
[32m[0514 05:59:19 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.305063933134079, Train Loss: 0.31272438168525696
[32m[0514 05:59:19 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.30507367849349976, Train Loss: 0.31271809339523315
[32m[0514 05:59:19 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.30508339405059814, Train Loss: 0.31271183490753174
[32m[0514 05:59:19 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.3050931990146637, Train Loss: 0.3127056956291199
[32m[0514 05:59:19 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.30510300397872925, Train Loss: 0.3126995265483856
[32m[0514 05:59:19 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.3051127791404724, Train Loss: 0.31269341707229614
[32m[0514 05:59:19 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.3051225543022156, Train Loss: 0.31268730759620667
[32m[0514 05:59:19 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.30513235926628113, Train Loss: 0.3126812279224396
[32m[0514 05:59:19 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.3051421642303467, Train Loss: 0.31267526745796204
[32m[0514 05:59:19 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.30515193939208984, Train Loss: 0.31266921758651733
[32m[0514 05:59:19 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.3051616847515106, Train Loss: 0.3126632869243622
[32m[0514 05:59:19 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.3051714301109314, Train Loss: 0.31265735626220703
[32m[0514 05:59:19 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.30518123507499695, Train Loss: 0.31265148520469666
[32m[0514 05:59:19 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.3051909804344177, Train Loss: 0.3126455843448639
[32m[0514 05:59:20 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.3052006959915161, Train Loss: 0.3126397728919983
[32m[0514 05:59:20 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.3052104413509369, Train Loss: 0.3126339316368103
[32m[0514 05:59:20 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.30522018671035767, Train Loss: 0.3126281797885895
[32m[0514 05:59:20 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.30522990226745605, Train Loss: 0.31262242794036865
[32m[0514 05:59:20 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.30523958802223206, Train Loss: 0.3126166760921478
[32m[0514 05:59:20 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.30524927377700806, Train Loss: 0.3126109540462494
[32m[0514 05:59:20 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.30525898933410645, Train Loss: 0.3126053214073181
[32m[0514 05:59:20 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.30526864528656006, Train Loss: 0.31259965896606445
[32m[0514 05:59:20 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.3052782714366913, Train Loss: 0.3125939965248108
[32m[0514 05:59:20 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.3052878975868225, Train Loss: 0.3125883638858795
[32m[0514 05:59:20 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.30529749393463135, Train Loss: 0.3125828504562378
[32m[0514 05:59:20 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.30530714988708496, Train Loss: 0.3125772178173065
[32m[0514 05:59:20 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.3053167462348938, Train Loss: 0.3125717043876648
[32m[0514 05:59:20 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.3053262531757355, Train Loss: 0.31256619095802307
[32m[0514 05:59:20 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.3053358197212219, Train Loss: 0.31256067752838135
[32m[0514 05:59:20 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.3053453862667084, Train Loss: 0.3125552237033844
[32m[0514 05:59:20 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.30535492300987244, Train Loss: 0.3125497102737427
[32m[0514 05:59:20 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.3053644001483917, Train Loss: 0.3125443160533905
[32m[0514 05:59:21 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.305373877286911, Train Loss: 0.31253892183303833
[32m[0514 05:59:21 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.3053833246231079, Train Loss: 0.31253349781036377
[32m[0514 05:59:21 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.3053927421569824, Train Loss: 0.31252816319465637
[32m[0514 05:59:21 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.3054022192955017, Train Loss: 0.3125227689743042
[32m[0514 05:59:21 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.30541160702705383, Train Loss: 0.3125174641609192
[32m[0514 05:59:21 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.30542096495628357, Train Loss: 0.3125121295452118
[32m[0514 05:59:21 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.3054303228855133, Train Loss: 0.3125067949295044
[32m[0514 05:59:21 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.30543968081474304, Train Loss: 0.3125015199184418
[32m[0514 05:59:21 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.3054489493370056, Train Loss: 0.3124963045120239
[32m[0514 05:59:21 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.30545827746391296, Train Loss: 0.3124910295009613
[32m[0514 05:59:21 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.30546751618385315, Train Loss: 0.31248578429222107
[32m[0514 05:59:21 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.3054768145084381, Train Loss: 0.3124805688858032
[32m[0514 05:59:21 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.3054859936237335, Train Loss: 0.312475323677063
[32m[0514 05:59:21 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.3054952025413513, Train Loss: 0.3124702274799347
[32m[0514 05:59:21 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.3055044114589691, Train Loss: 0.31246504187583923
[32m[0514 05:59:21 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.30551356077194214, Train Loss: 0.3124598264694214
[32m[0514 05:59:21 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.3055226802825928, Train Loss: 0.3124547302722931
[32m[0514 05:59:21 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.3055317997932434, Train Loss: 0.3124496042728424
[32m[0514 05:59:22 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.30554088950157166, Train Loss: 0.3124445676803589
[32m[0514 05:59:22 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.3055499196052551, Train Loss: 0.3124394416809082
[32m[0514 05:59:22 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.305558979511261, Train Loss: 0.3124343752861023
[32m[0514 05:59:22 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.3055679500102997, Train Loss: 0.3124293386936188
[32m[0514 05:59:22 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.30557695031166077, Train Loss: 0.31242427229881287
[32m[0514 05:59:22 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.3055858910083771, Train Loss: 0.31241926550865173
[32m[0514 05:59:22 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.30559489130973816, Train Loss: 0.3124142587184906
[32m[0514 05:59:22 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.3056037724018097, Train Loss: 0.3124092221260071
[32m[0514 05:59:22 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.30561262369155884, Train Loss: 0.31240424513816833
[32m[0514 05:59:22 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.30562153458595276, Train Loss: 0.312399297952652
[32m[0514 05:59:22 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.3056303560733795, Train Loss: 0.31239432096481323
[32m[0514 05:59:22 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.30563920736312866, Train Loss: 0.3123893439769745
[32m[0514 05:59:22 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.30564796924591064, Train Loss: 0.3123844265937805
[32m[0514 05:59:22 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.3056567311286926, Train Loss: 0.31237950921058655
[32m[0514 05:59:22 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.30566543340682983, Train Loss: 0.3123745918273926
[32m[0514 05:59:22 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.3056742250919342, Train Loss: 0.312369704246521
[32m[0514 05:59:22 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.30568283796310425, Train Loss: 0.3123648464679718
[32m[0514 05:59:22 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.30569154024124146, Train Loss: 0.31235992908477783
[32m[0514 05:59:22 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.3057001233100891, Train Loss: 0.312355101108551
[32m[0514 05:59:23 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.30570873618125916, Train Loss: 0.3123503029346466
[32m[0514 05:59:23 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.3057173788547516, Train Loss: 0.3123454451560974
[32m[0514 05:59:23 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.30572590231895447, Train Loss: 0.312340646982193
[32m[0514 05:59:23 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.30573442578315735, Train Loss: 0.3123358190059662
[32m[0514 05:59:23 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.30574291944503784, Train Loss: 0.31233105063438416
[32m[0514 05:59:23 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.30575141310691833, Train Loss: 0.31232622265815735
[32m[0514 05:59:23 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.30575984716415405, Train Loss: 0.3123214840888977
[32m[0514 05:59:23 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.3057682514190674, Train Loss: 0.31231674551963806
[32m[0514 05:59:23 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.3057766854763031, Train Loss: 0.31231197714805603
[32m[0514 05:59:23 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.30578503012657166, Train Loss: 0.3123072385787964
[32m[0514 05:59:23 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.3057933747768402, Train Loss: 0.31230252981185913
[32m[0514 05:59:23 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.3058016896247864, Train Loss: 0.3122977912425995
[32m[0514 05:59:23 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.30581003427505493, Train Loss: 0.3122931122779846
[32m[0514 05:59:23 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.30581822991371155, Train Loss: 0.31228843331336975
[32m[0514 05:59:23 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.30582648515701294, Train Loss: 0.3122836947441101
[32m[0514 05:59:23 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.30583468079566956, Train Loss: 0.3122790455818176
[32m[0514 05:59:23 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.30584287643432617, Train Loss: 0.31227442622184753
[32m[0514 05:59:23 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.3058510422706604, Train Loss: 0.31226974725723267
[32m[0514 05:59:23 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.30585914850234985, Train Loss: 0.3122651278972626
[32m[0514 05:59:24 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.3058672547340393, Train Loss: 0.3122604787349701
[32m[0514 05:59:24 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.30587533116340637, Train Loss: 0.3122558891773224
[32m[0514 05:59:24 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.30588334798812866, Train Loss: 0.3122512400150299
[32m[0514 05:59:24 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.30589139461517334, Train Loss: 0.3122466504573822
[32m[0514 05:59:24 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.30589941143989563, Train Loss: 0.3122420310974121
[32m[0514 05:59:24 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.30590733885765076, Train Loss: 0.31223753094673157
[32m[0514 05:59:24 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.3059152662754059, Train Loss: 0.3122329115867615
[32m[0514 05:59:24 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.305923193693161, Train Loss: 0.31222835183143616
[32m[0514 05:59:24 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.30593109130859375, Train Loss: 0.3122238218784332
[32m[0514 05:59:24 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.3059389293193817, Train Loss: 0.3122192919254303
[32m[0514 05:59:24 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.30594679713249207, Train Loss: 0.31221476197242737
[32m[0514 05:59:24 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.30595460534095764, Train Loss: 0.31221023201942444
[32m[0514 05:59:24 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.30596232414245605, Train Loss: 0.3122057616710663
[32m[0514 05:59:24 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.30597007274627686, Train Loss: 0.31220120191574097
[32m[0514 05:59:24 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.30597779154777527, Train Loss: 0.3121967315673828
[32m[0514 05:59:24 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.30598554015159607, Train Loss: 0.31219226121902466
[32m[0514 05:59:24 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.3059931993484497, Train Loss: 0.3121877908706665
[32m[0514 05:59:25 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.30600082874298096, Train Loss: 0.31218332052230835
[32m[0514 05:59:25 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.3060084581375122, Train Loss: 0.3121788799762726
[32m[0514 05:59:25 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.30601605772972107, Train Loss: 0.31217440962791443
[32m[0514 05:59:25 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.30602356791496277, Train Loss: 0.31216996908187866
[32m[0514 05:59:25 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.30603113770484924, Train Loss: 0.31216558814048767
[32m[0514 05:59:25 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.30603861808776855, Train Loss: 0.3121611177921295
[32m[0514 05:59:25 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.30604609847068787, Train Loss: 0.3121567368507385
[32m[0514 05:59:25 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.3060535490512848, Train Loss: 0.31215232610702515
[32m[0514 05:59:25 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.3060609996318817, Train Loss: 0.31214791536331177
[32m[0514 05:59:25 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.30606839060783386, Train Loss: 0.3121435046195984
[32m[0514 05:59:25 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.306075781583786, Train Loss: 0.3121391236782074
[32m[0514 05:59:25 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.306083083152771, Train Loss: 0.3121348023414612
[32m[0514 05:59:25 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.30609041452407837, Train Loss: 0.3121304214000702
[32m[0514 05:59:25 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.30609768629074097, Train Loss: 0.3121260702610016
[32m[0514 05:59:25 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.30610498785972595, Train Loss: 0.312121719121933
[32m[0514 05:59:25 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.30611222982406616, Train Loss: 0.31211739778518677
[32m[0514 05:59:25 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.306119441986084, Train Loss: 0.3121130168437958
[32m[0514 05:59:25 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.3061266243457794, Train Loss: 0.31210872530937195
[32m[0514 05:59:26 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.30613380670547485, Train Loss: 0.31210437417030334
[32m[0514 05:59:26 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.3061409592628479, Train Loss: 0.3121001124382019
[32m[0514 05:59:26 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.3061480224132538, Train Loss: 0.3120958209037781
[32m[0514 05:59:26 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.30615508556365967, Train Loss: 0.31209149956703186
[32m[0514 05:59:26 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.30616214871406555, Train Loss: 0.31208720803260803
[32m[0514 05:59:26 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.30616915225982666, Train Loss: 0.3120829164981842
[32m[0514 05:59:26 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.30617618560791016, Train Loss: 0.31207865476608276
[32m[0514 05:59:26 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.3061831295490265, Train Loss: 0.3120744526386261
[32m[0514 05:59:26 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.3061901032924652, Train Loss: 0.31207016110420227
[32m[0514 05:59:26 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.30619701743125916, Train Loss: 0.3120659291744232
[32m[0514 05:59:26 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.3062039315700531, Train Loss: 0.3120616674423218
[32m[0514 05:59:26 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.3062107563018799, Train Loss: 0.3120574653148651
[32m[0514 05:59:26 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.30621767044067383, Train Loss: 0.31205323338508606
[32m[0514 05:59:26 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.3062244653701782, Train Loss: 0.312049001455307
[32m[0514 05:59:26 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.30623123049736023, Train Loss: 0.31204476952552795
[32m[0514 05:59:26 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.3062380254268646, Train Loss: 0.31204062700271606
[32m[0514 05:59:26 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.30624473094940186, Train Loss: 0.3120364248752594
[32m[0514 05:59:26 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.3062514662742615, Train Loss: 0.31203219294548035
[32m[0514 05:59:27 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.30625811219215393, Train Loss: 0.31202802062034607
[32m[0514 05:59:27 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.30626481771469116, Train Loss: 0.3120238482952118
[32m[0514 05:59:27 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.30627137422561646, Train Loss: 0.3120196759700775
[32m[0514 05:59:27 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.3062780499458313, Train Loss: 0.31201550364494324
[32m[0514 05:59:27 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.306284636259079, Train Loss: 0.31201133131980896
[32m[0514 05:59:27 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.3062911927700043, Train Loss: 0.31200721859931946
[32m[0514 05:59:27 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.3062976896762848, Train Loss: 0.3120030462741852
[32m[0514 05:59:27 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.3063042461872101, Train Loss: 0.3119988739490509
[32m[0514 05:59:27 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.3063107430934906, Train Loss: 0.3119947612285614
[32m[0514 05:59:27 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.30631715059280396, Train Loss: 0.3119906485080719
[32m[0514 05:59:27 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.3063235878944397, Train Loss: 0.31198650598526
[32m[0514 05:59:27 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.30632999539375305, Train Loss: 0.3119824230670929
[32m[0514 05:59:27 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.30633634328842163, Train Loss: 0.311978280544281
[32m[0514 05:59:27 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.3063427209854126, Train Loss: 0.3119741976261139
[32m[0514 05:59:27 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.3063490390777588, Train Loss: 0.3119700849056244
[32m[0514 05:59:27 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.3063553273677826, Train Loss: 0.31196603178977966
[32m[0514 05:59:27 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.3063616156578064, Train Loss: 0.31196197867393494
[32m[0514 05:59:27 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.3063678741455078, Train Loss: 0.3119578957557678
[32m[0514 05:59:28 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.30637407302856445, Train Loss: 0.31195375323295593
[32m[0514 05:59:28 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.30638033151626587, Train Loss: 0.3119497299194336
[32m[0514 05:59:28 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.30638647079467773, Train Loss: 0.31194570660591125
[32m[0514 05:59:28 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.3063926100730896, Train Loss: 0.31194159388542175
[32m[0514 05:59:28 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.30639880895614624, Train Loss: 0.311937540769577
[32m[0514 05:59:28 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.30640482902526855, Train Loss: 0.3119335472583771
[32m[0514 05:59:28 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.30641090869903564, Train Loss: 0.31192952394485474
[32m[0514 05:59:28 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.30641698837280273, Train Loss: 0.3119254410266876
[32m[0514 05:59:28 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.30642300844192505, Train Loss: 0.31192144751548767
[32m[0514 05:59:28 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.306428998708725, Train Loss: 0.31191742420196533
[32m[0514 05:59:28 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.3064350187778473, Train Loss: 0.311913400888443
[32m[0514 05:59:28 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.30644094944000244, Train Loss: 0.31190937757492065
[32m[0514 05:59:28 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.3064468801021576, Train Loss: 0.3119053542613983
[32m[0514 05:59:28 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.30645281076431274, Train Loss: 0.31190139055252075
[32m[0514 05:59:28 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.30645865201950073, Train Loss: 0.3118973970413208
[32m[0514 05:59:28 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.3064644932746887, Train Loss: 0.31189337372779846
[32m[0514 05:59:28 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.3064703643321991, Train Loss: 0.3118894398212433
[32m[0514 05:59:28 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.3064761757850647, Train Loss: 0.31188541650772095
[32m[0514 05:59:29 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.3064819276332855, Train Loss: 0.31188148260116577
[32m[0514 05:59:29 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.30648767948150635, Train Loss: 0.3118775188922882
[32m[0514 05:59:29 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.3064934313297272, Train Loss: 0.31187352538108826
[32m[0514 05:59:29 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.3064991533756256, Train Loss: 0.3118695914745331
[32m[0514 05:59:29 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.3065048158168793, Train Loss: 0.3118656277656555
[32m[0514 05:59:29 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.30651047825813293, Train Loss: 0.31186166405677795
[32m[0514 05:59:29 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.3065161406993866, Train Loss: 0.3118577301502228
[32m[0514 05:59:29 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.3065217435359955, Train Loss: 0.3118537664413452
[32m[0514 05:59:29 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.306527316570282, Train Loss: 0.3118498623371124
[32m[0514 05:59:29 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.30653291940689087, Train Loss: 0.31184592843055725
[32m[0514 05:59:29 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.3065384328365326, Train Loss: 0.31184202432632446
[32m[0514 05:59:29 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.3065439760684967, Train Loss: 0.3118381202220917
[32m[0514 05:59:29 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.30654942989349365, Train Loss: 0.3118341565132141
[32m[0514 05:59:29 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.3065549433231354, Train Loss: 0.3118302524089813
[32m[0514 05:59:29 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.3065603971481323, Train Loss: 0.3118263781070709
[32m[0514 05:59:29 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.3065657913684845, Train Loss: 0.31182244420051575
[32m[0514 05:59:29 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.30657121539115906, Train Loss: 0.31181856989860535
[32m[0514 05:59:29 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.30657655000686646, Train Loss: 0.31181469559669495
[32m[0514 05:59:30 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.306581974029541, Train Loss: 0.31181076169013977
[32m[0514 05:59:30 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.30658724904060364, Train Loss: 0.311806857585907
[32m[0514 05:59:30 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.30659258365631104, Train Loss: 0.31180301308631897
[32m[0514 05:59:30 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.30659788846969604, Train Loss: 0.3117991089820862
[32m[0514 05:59:30 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.3066031336784363, Train Loss: 0.31179526448249817
[32m[0514 05:59:30 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.3066083788871765, Train Loss: 0.31179139018058777
[32m[0514 05:59:30 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.306613564491272, Train Loss: 0.31178751587867737
[32m[0514 05:59:30 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.30661875009536743, Train Loss: 0.31178367137908936
[32m[0514 05:59:30 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.3066239058971405, Train Loss: 0.31177982687950134
[32m[0514 05:59:30 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.30662912130355835, Train Loss: 0.31177598237991333
[32m[0514 05:59:30 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.30663421750068665, Train Loss: 0.31177207827568054
[32m[0514 05:59:30 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.30663931369781494, Train Loss: 0.3117682635784149
[32m[0514 05:59:30 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.30664440989494324, Train Loss: 0.3117644488811493
[32m[0514 05:59:30 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.30664947628974915, Train Loss: 0.3117605745792389
[32m[0514 05:59:30 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.30665451288223267, Train Loss: 0.31175678968429565
[32m[0514 05:59:30 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.3066595196723938, Train Loss: 0.31175291538238525
[32m[0514 05:59:30 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.30666446685791016, Train Loss: 0.311749130487442
[32m[0514 05:59:31 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.3066694438457489, Train Loss: 0.311745285987854
[32m[0514 05:59:31 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.30667439103126526, Train Loss: 0.3117414712905884
[32m[0514 05:59:31 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.3066793382167816, Train Loss: 0.31173768639564514
[32m[0514 05:59:31 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.3066842257976532, Train Loss: 0.31173384189605713
[32m[0514 05:59:31 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.30668914318084717, Train Loss: 0.3117300570011139
[32m[0514 05:59:31 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.30669400095939636, Train Loss: 0.31172624230384827
[32m[0514 05:59:31 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.30669882893562317, Train Loss: 0.31172245740890503
[32m[0514 05:59:31 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.3067036271095276, Train Loss: 0.3117186427116394
[32m[0514 05:59:31 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.306708425283432, Train Loss: 0.31171485781669617
[32m[0514 05:59:31 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.30671319365501404, Train Loss: 0.3117111027240753
[32m[0514 05:59:31 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.30671796202659607, Train Loss: 0.3117072880268097
[32m[0514 05:59:31 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.30672264099121094, Train Loss: 0.31170353293418884
[32m[0514 05:59:31 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.3067273497581482, Train Loss: 0.3116997480392456
[32m[0514 05:59:31 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.30673202872276306, Train Loss: 0.31169596314430237
[32m[0514 05:59:31 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.3067367374897003, Train Loss: 0.3116922378540039
[32m[0514 05:59:31 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.306741327047348, Train Loss: 0.3116884231567383
[32m[0514 05:59:31 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.3067459464073181, Train Loss: 0.31168466806411743
[32m[0514 05:59:31 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.3067505359649658, Train Loss: 0.3116808831691742
[32m[0514 05:59:31 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.3067551553249359, Train Loss: 0.31167712807655334
[32m[0514 05:59:32 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.30675968527793884, Train Loss: 0.3116733431816101
[32m[0514 05:59:32 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.3067642152309418, Train Loss: 0.31166961789131165
[32m[0514 05:59:32 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.3067687153816223, Train Loss: 0.3116658627986908
[32m[0514 05:59:32 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.30677324533462524, Train Loss: 0.31166207790374756
[32m[0514 05:59:32 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.3067777156829834, Train Loss: 0.3116583526134491
[32m[0514 05:59:32 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.3067821264266968, Train Loss: 0.31165459752082825
[32m[0514 05:59:32 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.30678659677505493, Train Loss: 0.3116508424282074
[32m[0514 05:59:32 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.3067910075187683, Train Loss: 0.3116471469402313
[32m[0514 05:59:32 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.3067953884601593, Train Loss: 0.31164345145225525
[32m[0514 05:59:32 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.3067997395992279, Train Loss: 0.311639666557312
[32m[0514 05:59:32 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.3068041205406189, Train Loss: 0.31163594126701355
[32m[0514 05:59:32 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.3068084716796875, Train Loss: 0.3116322159767151
[32m[0514 05:59:32 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.30681276321411133, Train Loss: 0.3116284906864166
[32m[0514 05:59:32 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.30681702494621277, Train Loss: 0.31162482500076294
[32m[0514 05:59:32 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.3068213164806366, Train Loss: 0.3116210699081421
[32m[0514 05:59:32 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.30682551860809326, Train Loss: 0.31161731481552124
[32m[0514 05:59:32 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.3068297505378723, Train Loss: 0.31161361932754517
[32m[0514 05:59:32 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.306833952665329, Train Loss: 0.3116099536418915
[32m[0514 05:59:33 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.30683815479278564, Train Loss: 0.31160619854927063
[32m[0514 05:59:33 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.3068423271179199, Train Loss: 0.31160250306129456
[32m[0514 05:59:33 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.3068464696407318, Train Loss: 0.31159883737564087
[32m[0514 05:59:33 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.3068505525588989, Train Loss: 0.31159508228302
[32m[0514 05:59:33 @mbmf_sampler.py:98][0m Finished 9th episode
[32m[0514 05:59:33 @mbmf_sampler.py:102][0m 1809 timesteps from 9 episodes collected
[32m[0514 06:05:00 @mbmf_trainer.py:160][0m Mean reward: -316.0445640325858
[32m[0514 06:05:00 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.30872970819473267, Train Loss: 0.3099205493927002
[32m[0514 06:05:00 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.3088368773460388, Train Loss: 0.30980542302131653
[32m[0514 06:05:01 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.30880314111709595, Train Loss: 0.309784859418869
[32m[0514 06:05:01 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.30880048871040344, Train Loss: 0.3097530007362366
[32m[0514 06:05:01 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.3088197410106659, Train Loss: 0.3097221255302429
[32m[0514 06:05:01 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.3088368773460388, Train Loss: 0.3096970319747925
[32m[0514 06:05:01 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.308852881193161, Train Loss: 0.3096746802330017
[32m[0514 06:05:01 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.30886879563331604, Train Loss: 0.3096539080142975
[32m[0514 06:05:01 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.30888456106185913, Train Loss: 0.3096345365047455
[32m[0514 06:05:01 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.30890023708343506, Train Loss: 0.30961647629737854
[32m[0514 06:05:01 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.3089158535003662, Train Loss: 0.3095995783805847
[32m[0514 06:05:01 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.30893129110336304, Train Loss: 0.3095835745334625
[32m[0514 06:05:01 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.3089466392993927, Train Loss: 0.30956846475601196
[32m[0514 06:05:01 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.30896180868148804, Train Loss: 0.30955401062965393
[32m[0514 06:05:01 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.30897682905197144, Train Loss: 0.3095402419567108
[32m[0514 06:05:01 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.3089917004108429, Train Loss: 0.3095270097255707
[32m[0514 06:05:01 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.3090064525604248, Train Loss: 0.30951428413391113
[32m[0514 06:05:02 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.3090210556983948, Train Loss: 0.3095020651817322
[32m[0514 06:05:02 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.3090355098247528, Train Loss: 0.30949023365974426
[32m[0514 06:05:02 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.30904990434646606, Train Loss: 0.30947884917259216
[32m[0514 06:05:02 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.309064120054245, Train Loss: 0.30946776270866394
[32m[0514 06:05:02 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.3090782165527344, Train Loss: 0.30945703387260437
[32m[0514 06:05:02 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.3090921938419342, Train Loss: 0.3094465434551239
[32m[0514 06:05:02 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.3091060519218445, Train Loss: 0.3094363212585449
[32m[0514 06:05:02 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.3091197609901428, Train Loss: 0.3094264268875122
[32m[0514 06:05:02 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.30913347005844116, Train Loss: 0.3094167709350586
[32m[0514 06:05:02 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.3091469705104828, Train Loss: 0.3094072937965393
[32m[0514 06:05:02 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.30916041135787964, Train Loss: 0.30939802527427673
[32m[0514 06:05:02 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.30917370319366455, Train Loss: 0.3093889653682709
[32m[0514 06:05:02 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.3091869354248047, Train Loss: 0.30938011407852173
[32m[0514 06:05:02 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.3091999888420105, Train Loss: 0.30937138199806213
[32m[0514 06:05:02 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.30921298265457153, Train Loss: 0.30936285853385925
[32m[0514 06:05:03 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.3092258870601654, Train Loss: 0.3093544840812683
[32m[0514 06:05:03 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.3092386722564697, Train Loss: 0.3093462586402893
[32m[0514 06:05:03 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.3092513680458069, Train Loss: 0.30933815240859985
[32m[0514 06:05:03 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.3092639446258545, Train Loss: 0.3093302249908447
[32m[0514 06:05:03 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.3092764616012573, Train Loss: 0.3093223571777344
[32m[0514 06:05:03 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.3092888295650482, Train Loss: 0.30931463837623596
[32m[0514 06:05:03 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.3093011677265167, Train Loss: 0.3093070685863495
[32m[0514 06:05:03 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.3093133866786957, Train Loss: 0.3092995584011078
[32m[0514 06:05:03 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.30932554602622986, Train Loss: 0.30929216742515564
[32m[0514 06:05:03 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.3093376159667969, Train Loss: 0.30928492546081543
[32m[0514 06:05:03 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.30934959650039673, Train Loss: 0.3092777132987976
[32m[0514 06:05:03 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.3093615174293518, Train Loss: 0.30927062034606934
[32m[0514 06:05:03 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.30937331914901733, Train Loss: 0.3092636466026306
[32m[0514 06:05:03 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.3093850314617157, Train Loss: 0.3092566728591919
[32m[0514 06:05:04 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.30939674377441406, Train Loss: 0.3092498779296875
[32m[0514 06:05:04 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.3094083368778229, Train Loss: 0.3092431128025055
[32m[0514 06:05:04 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.3094198703765869, Train Loss: 0.30923640727996826
[32m[0514 06:05:04 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.3094312846660614, Train Loss: 0.3092298209667206
[32m[0514 06:05:04 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.3094426691532135, Train Loss: 0.3092232644557953
[32m[0514 06:05:04 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.3094540238380432, Train Loss: 0.30921676754951477
[32m[0514 06:05:04 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.30946528911590576, Train Loss: 0.3092103898525238
[32m[0514 06:05:04 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.30947649478912354, Train Loss: 0.30920401215553284
[32m[0514 06:05:04 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.30948761105537415, Train Loss: 0.30919772386550903
[32m[0514 06:05:04 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.30949866771698, Train Loss: 0.30919149518013
[32m[0514 06:05:04 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.3095097243785858, Train Loss: 0.30918532609939575
[32m[0514 06:05:04 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.3095206618309021, Train Loss: 0.3091791868209839
[32m[0514 06:05:04 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.3095315396785736, Train Loss: 0.3091731369495392
[32m[0514 06:05:04 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.3095424175262451, Train Loss: 0.3091670870780945
[32m[0514 06:05:04 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.30955323576927185, Train Loss: 0.30916115641593933
[32m[0514 06:05:05 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.30956393480300903, Train Loss: 0.3091551661491394
[32m[0514 06:05:05 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.3095746338367462, Train Loss: 0.3091493248939514
[32m[0514 06:05:05 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.309585303068161, Train Loss: 0.3091435134410858
[32m[0514 06:05:05 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.30959591269493103, Train Loss: 0.3091377019882202
[32m[0514 06:05:05 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.3096064329147339, Train Loss: 0.309131920337677
[32m[0514 06:05:05 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.30961692333221436, Train Loss: 0.30912625789642334
[32m[0514 06:05:05 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.3096274137496948, Train Loss: 0.3091205358505249
[32m[0514 06:05:05 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.30963778495788574, Train Loss: 0.30911490321159363
[32m[0514 06:05:05 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.30964821577072144, Train Loss: 0.30910930037498474
[32m[0514 06:05:05 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.3096585273742676, Train Loss: 0.30910372734069824
[32m[0514 06:05:05 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.3096688687801361, Train Loss: 0.30909815430641174
[32m[0514 06:05:05 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.3096791207790375, Train Loss: 0.3090927302837372
[32m[0514 06:05:05 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.30968931317329407, Train Loss: 0.30908721685409546
[32m[0514 06:05:05 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.30969947576522827, Train Loss: 0.3090817928314209
[32m[0514 06:05:06 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.3097096383571625, Train Loss: 0.3090763986110687
[32m[0514 06:05:06 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.3097197413444519, Train Loss: 0.30907100439071655
[32m[0514 06:05:06 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.30972984433174133, Train Loss: 0.30906563997268677
[32m[0514 06:05:06 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.3097398579120636, Train Loss: 0.30906030535697937
[32m[0514 06:05:06 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.30974990129470825, Train Loss: 0.30905506014823914
[32m[0514 06:05:06 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.30975982546806335, Train Loss: 0.3090497851371765
[32m[0514 06:05:06 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.30976977944374084, Train Loss: 0.3090445101261139
[32m[0514 06:05:06 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.30977970361709595, Train Loss: 0.30903932452201843
[32m[0514 06:05:06 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.3097895681858063, Train Loss: 0.3090341091156006
[32m[0514 06:05:06 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.3097993731498718, Train Loss: 0.30902889370918274
[32m[0514 06:05:06 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.30980929732322693, Train Loss: 0.30902376770973206
[32m[0514 06:05:06 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.30981898307800293, Train Loss: 0.30901864171028137
[32m[0514 06:05:06 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.30982881784439087, Train Loss: 0.3090135455131531
[32m[0514 06:05:06 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.30983856320381165, Train Loss: 0.3090084493160248
[32m[0514 06:05:07 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.30984821915626526, Train Loss: 0.30900341272354126
[32m[0514 06:05:07 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.30985790491104126, Train Loss: 0.30899837613105774
[32m[0514 06:05:07 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.3098675608634949, Train Loss: 0.3089933395385742
[32m[0514 06:05:07 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.3098771870136261, Train Loss: 0.3089883029460907
[32m[0514 06:05:07 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.30988678336143494, Train Loss: 0.30898329615592957
[32m[0514 06:05:07 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.3098963499069214, Train Loss: 0.3089783191680908
[32m[0514 06:05:07 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.30990588665008545, Train Loss: 0.30897340178489685
[32m[0514 06:05:07 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.30991536378860474, Train Loss: 0.3089684545993805
[32m[0514 06:05:07 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.3099249005317688, Train Loss: 0.3089635372161865
[32m[0514 06:05:07 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.3099343776702881, Train Loss: 0.30895861983299255
[32m[0514 06:05:07 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.3099437952041626, Train Loss: 0.3089537024497986
[32m[0514 06:05:07 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.3099532425403595, Train Loss: 0.3089488744735718
[32m[0514 06:05:07 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.3099626302719116, Train Loss: 0.3089439868927002
[32m[0514 06:05:07 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.30997201800346375, Train Loss: 0.3089390993118286
[32m[0514 06:05:07 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.3099813461303711, Train Loss: 0.3089343011379242
[32m[0514 06:05:08 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.30999070405960083, Train Loss: 0.30892953276634216
[32m[0514 06:05:08 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.3100000321865082, Train Loss: 0.30892470479011536
[32m[0514 06:05:08 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.31000933051109314, Train Loss: 0.30891990661621094
[32m[0514 06:05:08 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.3100185692310333, Train Loss: 0.30891504883766174
[32m[0514 06:05:08 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.3100278675556183, Train Loss: 0.3089103400707245
[32m[0514 06:05:08 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.3100370764732361, Train Loss: 0.30890560150146484
[32m[0514 06:05:08 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.31004631519317627, Train Loss: 0.3089008629322052
[32m[0514 06:05:08 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.3100554645061493, Train Loss: 0.30889612436294556
[32m[0514 06:05:08 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.3100646734237671, Train Loss: 0.3088913857936859
[32m[0514 06:05:08 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.3100738525390625, Train Loss: 0.30888667702674866
[32m[0514 06:05:08 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.31008294224739075, Train Loss: 0.3088819980621338
[32m[0514 06:05:08 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.3100920617580414, Train Loss: 0.3088773190975189
[32m[0514 06:05:08 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.31010112166404724, Train Loss: 0.30887264013290405
[32m[0514 06:05:08 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.3101102113723755, Train Loss: 0.3088679909706116
[32m[0514 06:05:08 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.31011927127838135, Train Loss: 0.3088632822036743
[32m[0514 06:05:09 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.3101283013820648, Train Loss: 0.3088586628437042
[32m[0514 06:05:09 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.31013739109039307, Train Loss: 0.30885401368141174
[32m[0514 06:05:09 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.31014636158943176, Train Loss: 0.30884942412376404
[32m[0514 06:05:09 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.31015536189079285, Train Loss: 0.30884477496147156
[32m[0514 06:05:09 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.31016433238983154, Train Loss: 0.30884018540382385
[32m[0514 06:05:09 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.31017327308654785, Train Loss: 0.30883562564849854
[32m[0514 06:05:09 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.3101821541786194, Train Loss: 0.30883100628852844
[32m[0514 06:05:09 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.3101911246776581, Train Loss: 0.30882641673088074
[32m[0514 06:05:09 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.310200035572052, Train Loss: 0.3088218569755554
[32m[0514 06:05:09 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.31020891666412354, Train Loss: 0.3088172674179077
[32m[0514 06:05:09 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.3102177679538727, Train Loss: 0.3088127374649048
[32m[0514 06:05:09 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.3102266490459442, Train Loss: 0.30880820751190186
[32m[0514 06:05:09 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.31023550033569336, Train Loss: 0.30880364775657654
[32m[0514 06:05:09 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.3102443218231201, Train Loss: 0.3087990880012512
[32m[0514 06:05:09 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.3102531135082245, Train Loss: 0.30879461765289307
[32m[0514 06:05:10 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.31026190519332886, Train Loss: 0.30879008769989014
[32m[0514 06:05:10 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.3102706968784332, Train Loss: 0.3087855279445648
[32m[0514 06:05:10 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.3102794289588928, Train Loss: 0.30878105759620667
[32m[0514 06:05:10 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.3102881908416748, Train Loss: 0.3087765872478485
[32m[0514 06:05:10 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.3102969229221344, Train Loss: 0.30877211689949036
[32m[0514 06:05:10 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.310305655002594, Train Loss: 0.3087676167488098
[32m[0514 06:05:10 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.3103143274784088, Train Loss: 0.3087631165981293
[32m[0514 06:05:10 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.310323029756546, Train Loss: 0.3087586462497711
[32m[0514 06:05:10 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.31033170223236084, Train Loss: 0.30875420570373535
[32m[0514 06:05:10 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.31034034490585327, Train Loss: 0.3087497353553772
[32m[0514 06:05:10 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.3103490173816681, Train Loss: 0.30874529480934143
[32m[0514 06:05:10 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.31035763025283813, Train Loss: 0.30874085426330566
[32m[0514 06:05:10 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.31036627292633057, Train Loss: 0.3087364137172699
[32m[0514 06:05:10 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.31037479639053345, Train Loss: 0.30873197317123413
[32m[0514 06:05:10 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.3103834390640259, Train Loss: 0.30872759222984314
[32m[0514 06:05:11 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.31039199233055115, Train Loss: 0.3087231516838074
[32m[0514 06:05:11 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.3104006052017212, Train Loss: 0.3087187707424164
[32m[0514 06:05:11 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.3104091286659241, Train Loss: 0.3087143301963806
[32m[0514 06:05:11 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.31041768193244934, Train Loss: 0.3087099492549896
[32m[0514 06:05:11 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.3104262053966522, Train Loss: 0.30870553851127625
[32m[0514 06:05:11 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.3104346692562103, Train Loss: 0.30870115756988525
[32m[0514 06:05:11 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.3104431927204132, Train Loss: 0.3086967468261719
[32m[0514 06:05:11 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.3104516565799713, Train Loss: 0.3086923658847809
[32m[0514 06:05:11 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.3104601502418518, Train Loss: 0.3086880147457123
[32m[0514 06:05:11 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.3104686141014099, Train Loss: 0.3086836338043213
[32m[0514 06:05:11 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.31047704815864563, Train Loss: 0.3086792826652527
[32m[0514 06:05:11 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.31048548221588135, Train Loss: 0.3086749017238617
[32m[0514 06:05:11 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.31049391627311707, Train Loss: 0.3086705505847931
[32m[0514 06:05:11 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.310502290725708, Train Loss: 0.3086662292480469
[32m[0514 06:05:11 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.31051069498062134, Train Loss: 0.3086618483066559
[32m[0514 06:05:12 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.3105190396308899, Train Loss: 0.30865752696990967
[32m[0514 06:05:12 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.3105274438858032, Train Loss: 0.30865320563316345
[32m[0514 06:05:12 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.31053581833839417, Train Loss: 0.30864885449409485
[32m[0514 06:05:12 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.3105441629886627, Train Loss: 0.30864453315734863
[32m[0514 06:05:12 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.3105524778366089, Train Loss: 0.3086402118206024
[32m[0514 06:05:12 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.31056082248687744, Train Loss: 0.3086358904838562
[32m[0514 06:05:12 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.31056907773017883, Train Loss: 0.3086315393447876
[32m[0514 06:05:12 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.3105774223804474, Train Loss: 0.30862724781036377
[32m[0514 06:05:12 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.31058570742607117, Train Loss: 0.30862295627593994
[32m[0514 06:05:12 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.31059399247169495, Train Loss: 0.3086186945438385
[32m[0514 06:05:12 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.3106023073196411, Train Loss: 0.3086143434047699
[32m[0514 06:05:12 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.3106105327606201, Train Loss: 0.30861005187034607
[32m[0514 06:05:12 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.31061872839927673, Train Loss: 0.30860579013824463
[32m[0514 06:05:12 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.31062695384025574, Train Loss: 0.3086015284061432
[32m[0514 06:05:12 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.31063517928123474, Train Loss: 0.30859723687171936
[32m[0514 06:05:13 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.31064340472221375, Train Loss: 0.3085930049419403
[32m[0514 06:05:13 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.31065163016319275, Train Loss: 0.3085886836051941
[32m[0514 06:05:13 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.3106597661972046, Train Loss: 0.30858445167541504
[32m[0514 06:05:13 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.3106679916381836, Train Loss: 0.3085801601409912
[32m[0514 06:05:13 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.31067612767219543, Train Loss: 0.30857592821121216
[32m[0514 06:05:13 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.31068429350852966, Train Loss: 0.30857163667678833
[32m[0514 06:05:13 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.3106923997402191, Train Loss: 0.30856743454933167
[32m[0514 06:05:13 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.31070056557655334, Train Loss: 0.30856314301490784
[32m[0514 06:05:13 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.3107086718082428, Train Loss: 0.3085588812828064
[32m[0514 06:05:13 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.31071680784225464, Train Loss: 0.3085547089576721
[32m[0514 06:05:13 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.3107248842716217, Train Loss: 0.3085504174232483
[32m[0514 06:05:13 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.31073302030563354, Train Loss: 0.30854618549346924
[32m[0514 06:05:13 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.3107410669326782, Train Loss: 0.30854201316833496
[32m[0514 06:05:13 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.3107491433620453, Train Loss: 0.3085377514362335
[32m[0514 06:05:14 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.31075721979141235, Train Loss: 0.30853354930877686
[32m[0514 06:05:14 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.3107653260231018, Train Loss: 0.3085292875766754
[32m[0514 06:05:14 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.3107733130455017, Train Loss: 0.30852508544921875
[32m[0514 06:05:14 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.310781329870224, Train Loss: 0.3085208833217621
[32m[0514 06:05:14 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.3107893466949463, Train Loss: 0.30851665139198303
[32m[0514 06:05:14 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.3107973635196686, Train Loss: 0.308512419462204
[32m[0514 06:05:14 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.31080541014671326, Train Loss: 0.3085082471370697
[32m[0514 06:05:14 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.31081336736679077, Train Loss: 0.30850404500961304
[32m[0514 06:05:14 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.3108213245868683, Train Loss: 0.30849984288215637
[32m[0514 06:05:14 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.3108293116092682, Train Loss: 0.3084956705570221
[32m[0514 06:05:14 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.3108372986316681, Train Loss: 0.30849146842956543
[32m[0514 06:05:14 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.3108452260494232, Train Loss: 0.30848729610443115
[32m[0514 06:05:14 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.31085318326950073, Train Loss: 0.3084830939769745
[32m[0514 06:05:14 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.31086108088493347, Train Loss: 0.3084789216518402
[32m[0514 06:05:14 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.3108690083026886, Train Loss: 0.30847474932670593
[32m[0514 06:05:15 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.3108769953250885, Train Loss: 0.30847057700157166
[32m[0514 06:05:15 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.31088483333587646, Train Loss: 0.3084664046764374
[32m[0514 06:05:15 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.3108927607536316, Train Loss: 0.3084622323513031
[32m[0514 06:05:15 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.31090065836906433, Train Loss: 0.3084580898284912
[32m[0514 06:05:15 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.3109085261821747, Train Loss: 0.30845385789871216
[32m[0514 06:05:15 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.31091639399528503, Train Loss: 0.30844974517822266
[32m[0514 06:05:15 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.3109242618083954, Train Loss: 0.3084455728530884
[32m[0514 06:05:15 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.31093209981918335, Train Loss: 0.3084414303302765
[32m[0514 06:05:15 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.3109399676322937, Train Loss: 0.3084372282028198
[32m[0514 06:05:15 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.3109477460384369, Train Loss: 0.3084331154823303
[32m[0514 06:05:15 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.31095555424690247, Train Loss: 0.30842894315719604
[32m[0514 06:05:15 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.31096339225769043, Train Loss: 0.30842483043670654
[32m[0514 06:05:15 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.3109712302684784, Train Loss: 0.30842065811157227
[32m[0514 06:05:15 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.3109790086746216, Train Loss: 0.30841654539108276
[32m[0514 06:05:16 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.31098678708076477, Train Loss: 0.30841243267059326
[32m[0514 06:05:16 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.31099459528923035, Train Loss: 0.30840831995010376
[32m[0514 06:05:16 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.31100237369537354, Train Loss: 0.3084041178226471
[32m[0514 06:05:16 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.3110101521015167, Train Loss: 0.3084000051021576
[32m[0514 06:05:16 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.31101787090301514, Train Loss: 0.3083958625793457
[32m[0514 06:05:16 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.3110256791114807, Train Loss: 0.3083917796611786
[32m[0514 06:05:16 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.31103330850601196, Train Loss: 0.3083876371383667
[32m[0514 06:05:16 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.31104111671447754, Train Loss: 0.3083834946155548
[32m[0514 06:05:16 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.31104883551597595, Train Loss: 0.3083794116973877
[32m[0514 06:05:16 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.3110564649105072, Train Loss: 0.3083752691745758
[32m[0514 06:05:16 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.311064213514328, Train Loss: 0.3083711564540863
[32m[0514 06:05:16 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.3110719323158264, Train Loss: 0.3083670735359192
[32m[0514 06:05:16 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.31107959151268005, Train Loss: 0.3083629608154297
[32m[0514 06:05:16 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.3110872805118561, Train Loss: 0.3083588480949402
[32m[0514 06:05:16 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.3110949993133545, Train Loss: 0.30835476517677307
[32m[0514 06:05:17 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.31110256910324097, Train Loss: 0.30835065245628357
[32m[0514 06:05:17 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.311110258102417, Train Loss: 0.30834653973579407
[32m[0514 06:05:17 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.311117947101593, Train Loss: 0.30834242701530457
[32m[0514 06:05:17 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.31112557649612427, Train Loss: 0.30833834409713745
[32m[0514 06:05:17 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.31113317608833313, Train Loss: 0.30833426117897034
[32m[0514 06:05:17 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.3111408054828644, Train Loss: 0.30833014845848083
[32m[0514 06:05:17 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.31114843487739563, Train Loss: 0.3083260953426361
[32m[0514 06:05:17 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.3111560642719269, Train Loss: 0.308322012424469
[32m[0514 06:05:17 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.31116360425949097, Train Loss: 0.3083178997039795
[32m[0514 06:05:17 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.31117120385169983, Train Loss: 0.30831387639045715
[32m[0514 06:05:17 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.3111788034439087, Train Loss: 0.30830979347229004
[32m[0514 06:05:17 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.31118643283843994, Train Loss: 0.30830565094947815
[32m[0514 06:05:17 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.31119397282600403, Train Loss: 0.3083016276359558
[32m[0514 06:05:17 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.3112015128135681, Train Loss: 0.3082975447177887
[32m[0514 06:05:17 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.3112090826034546, Train Loss: 0.30829349160194397
[32m[0514 06:05:18 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.3112166225910187, Train Loss: 0.30828937888145447
[32m[0514 06:05:18 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.31122416257858276, Train Loss: 0.30828532576560974
[32m[0514 06:05:18 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.31123170256614685, Train Loss: 0.3082812428474426
[32m[0514 06:05:18 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.31123924255371094, Train Loss: 0.3082772195339203
[32m[0514 06:05:18 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.31124675273895264, Train Loss: 0.30827316641807556
[32m[0514 06:05:18 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.31125423312187195, Train Loss: 0.30826911330223083
[32m[0514 06:05:18 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.31126177310943604, Train Loss: 0.3082650303840637
[32m[0514 06:05:18 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.31126922369003296, Train Loss: 0.3082610070705414
[32m[0514 06:05:18 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.31127676367759705, Train Loss: 0.3082568943500519
[32m[0514 06:05:18 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.3112841844558716, Train Loss: 0.30825290083885193
[32m[0514 06:05:18 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.3112916946411133, Train Loss: 0.3082488179206848
[32m[0514 06:05:18 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.3112991750240326, Train Loss: 0.3082447648048401
[32m[0514 06:05:18 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.31130656599998474, Train Loss: 0.30824071168899536
[32m[0514 06:05:18 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.31131404638290405, Train Loss: 0.308236688375473
[32m[0514 06:05:18 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.31132152676582336, Train Loss: 0.3082326054573059
[32m[0514 06:05:19 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.3113289177417755, Train Loss: 0.30822858214378357
[32m[0514 06:05:19 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.31133636832237244, Train Loss: 0.3082245886325836
[32m[0514 06:05:19 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.31134381890296936, Train Loss: 0.3082205057144165
[32m[0514 06:05:19 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.3113512396812439, Train Loss: 0.30821648240089417
[32m[0514 06:05:19 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.31135863065719604, Train Loss: 0.30821242928504944
[32m[0514 06:05:19 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.3113660216331482, Train Loss: 0.3082083761692047
[32m[0514 06:05:19 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.31137344241142273, Train Loss: 0.30820438265800476
[32m[0514 06:05:19 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.3113808333873749, Train Loss: 0.3082003593444824
[32m[0514 06:05:19 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.3113882541656494, Train Loss: 0.3081963360309601
[32m[0514 06:05:19 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.3113956153392792, Train Loss: 0.30819228291511536
[32m[0514 06:05:19 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.31140294671058655, Train Loss: 0.308188259601593
[32m[0514 06:05:19 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.3114103376865387, Train Loss: 0.3081842362880707
[32m[0514 06:05:19 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.31141766905784607, Train Loss: 0.30818021297454834
[32m[0514 06:05:19 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.31142503023147583, Train Loss: 0.3081762194633484
[32m[0514 06:05:19 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.3114323616027832, Train Loss: 0.3081721365451813
[32m[0514 06:05:20 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.3114396929740906, Train Loss: 0.3081681430339813
[32m[0514 06:05:20 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.31144705414772034, Train Loss: 0.308164119720459
[32m[0514 06:05:20 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.3114544153213501, Train Loss: 0.30816009640693665
[32m[0514 06:05:20 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.3114617168903351, Train Loss: 0.3081561028957367
[32m[0514 06:05:20 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.31146901845932007, Train Loss: 0.30815207958221436
[32m[0514 06:05:20 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.31147632002830505, Train Loss: 0.308148056268692
[32m[0514 06:05:20 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.31148362159729004, Train Loss: 0.3081440329551697
[32m[0514 06:05:20 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.311490923166275, Train Loss: 0.3081400394439697
[32m[0514 06:05:20 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.3114981949329376, Train Loss: 0.3081360161304474
[32m[0514 06:05:20 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.3115054965019226, Train Loss: 0.30813202261924744
[32m[0514 06:05:20 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.3115127682685852, Train Loss: 0.3081279993057251
[32m[0514 06:05:20 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.3115200698375702, Train Loss: 0.30812400579452515
[32m[0514 06:05:20 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.3115273118019104, Train Loss: 0.3081200122833252
[32m[0514 06:05:20 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.311534583568573, Train Loss: 0.30811604857444763
[32m[0514 06:05:20 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.3115418255329132, Train Loss: 0.3081120550632477
[32m[0514 06:05:21 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.3115490972995758, Train Loss: 0.30810800194740295
[32m[0514 06:05:21 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.311556339263916, Train Loss: 0.3081039786338806
[32m[0514 06:05:21 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.31156349182128906, Train Loss: 0.30810001492500305
[32m[0514 06:05:21 @mbmf_sampler.py:98][0m Finished 9th episode
[32m[0514 06:05:21 @mbmf_sampler.py:102][0m 1809 timesteps from 9 episodes collected
[32m[0514 06:10:44 @mbmf_trainer.py:160][0m Mean reward: -344.9198880712514
[32m[0514 06:10:44 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.3171693980693817, Train Loss: 0.3081866502761841
[32m[0514 06:10:44 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.3172568082809448, Train Loss: 0.3081265091896057
[32m[0514 06:10:44 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.3173074424266815, Train Loss: 0.3080935776233673
[32m[0514 06:10:44 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.3173636496067047, Train Loss: 0.30806899070739746
[32m[0514 06:10:45 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.31741341948509216, Train Loss: 0.30805012583732605
[32m[0514 06:10:45 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.3174600601196289, Train Loss: 0.30803197622299194
[32m[0514 06:10:45 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.31750261783599854, Train Loss: 0.3080160319805145
[32m[0514 06:10:45 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.3175421953201294, Train Loss: 0.30800148844718933
[32m[0514 06:10:45 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.31757912039756775, Train Loss: 0.3079879879951477
[32m[0514 06:10:45 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.3176136910915375, Train Loss: 0.3079754114151001
[32m[0514 06:10:45 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.31764617562294006, Train Loss: 0.3079635798931122
[32m[0514 06:10:45 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.3176768124103546, Train Loss: 0.3079524040222168
[32m[0514 06:10:45 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.3177059292793274, Train Loss: 0.307941734790802
[32m[0514 06:10:45 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.3177334666252136, Train Loss: 0.3079315721988678
[32m[0514 06:10:45 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.31775975227355957, Train Loss: 0.307921826839447
[32m[0514 06:10:45 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.31778484582901, Train Loss: 0.3079124987125397
[32m[0514 06:10:45 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.3178088963031769, Train Loss: 0.3079034686088562
[32m[0514 06:10:46 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.31783196330070496, Train Loss: 0.3078947365283966
[32m[0514 06:10:46 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.317854106426239, Train Loss: 0.3078862428665161
[32m[0514 06:10:46 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.3178754150867462, Train Loss: 0.3078780770301819
[32m[0514 06:10:46 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.3178960382938385, Train Loss: 0.30787011981010437
[32m[0514 06:10:46 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.3179158866405487, Train Loss: 0.30786237120628357
[32m[0514 06:10:46 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.31793519854545593, Train Loss: 0.3078548312187195
[32m[0514 06:10:46 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.31795385479927063, Train Loss: 0.3078474700450897
[32m[0514 06:10:46 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.31797194480895996, Train Loss: 0.3078403174877167
[32m[0514 06:10:46 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.3179895281791687, Train Loss: 0.3078332841396332
[32m[0514 06:10:46 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.3180066645145416, Train Loss: 0.307826429605484
[32m[0514 06:10:46 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.3180234134197235, Train Loss: 0.3078197240829468
[32m[0514 06:10:46 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.3180396258831024, Train Loss: 0.3078131377696991
[32m[0514 06:10:46 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.31805551052093506, Train Loss: 0.30780667066574097
[32m[0514 06:10:47 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.31807100772857666, Train Loss: 0.3078003525733948
[32m[0514 06:10:47 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.3180861473083496, Train Loss: 0.30779412388801575
[32m[0514 06:10:47 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.3181009888648987, Train Loss: 0.30778804421424866
[32m[0514 06:10:47 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.3181155025959015, Train Loss: 0.30778205394744873
[32m[0514 06:10:47 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.31812968850135803, Train Loss: 0.30777618288993835
[32m[0514 06:10:47 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.3181436359882355, Train Loss: 0.30777037143707275
[32m[0514 06:10:47 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.3181573152542114, Train Loss: 0.3077646791934967
[32m[0514 06:10:47 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.3181706964969635, Train Loss: 0.3077590763568878
[32m[0514 06:10:47 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.3181838393211365, Train Loss: 0.3077535629272461
[32m[0514 06:10:47 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.31819674372673035, Train Loss: 0.30774810910224915
[32m[0514 06:10:47 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.3182094991207123, Train Loss: 0.30774274468421936
[32m[0514 06:10:47 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.31822195649147034, Train Loss: 0.30773746967315674
[32m[0514 06:10:47 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.31823423504829407, Train Loss: 0.3077322244644165
[32m[0514 06:10:48 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.31824636459350586, Train Loss: 0.30772706866264343
[32m[0514 06:10:48 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.3182581961154938, Train Loss: 0.3077220022678375
[32m[0514 06:10:48 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.318269819021225, Train Loss: 0.307716965675354
[32m[0514 06:10:48 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.3182814121246338, Train Loss: 0.30771198868751526
[32m[0514 06:10:48 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.3182927668094635, Train Loss: 0.3077071011066437
[32m[0514 06:10:48 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.3183039128780365, Train Loss: 0.30770227313041687
[32m[0514 06:10:48 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.31831490993499756, Train Loss: 0.30769750475883484
[32m[0514 06:10:48 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.3183257579803467, Train Loss: 0.30769267678260803
[32m[0514 06:10:48 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.31833651661872864, Train Loss: 0.30768802762031555
[32m[0514 06:10:48 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.3183470666408539, Train Loss: 0.30768340826034546
[32m[0514 06:10:48 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.3183574974536896, Train Loss: 0.307678759098053
[32m[0514 06:10:48 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.31836774945259094, Train Loss: 0.30767422914505005
[32m[0514 06:10:49 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.31837785243988037, Train Loss: 0.30766966938972473
[32m[0514 06:10:49 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.3183879554271698, Train Loss: 0.30766522884368896
[32m[0514 06:10:49 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.3183978199958801, Train Loss: 0.3076607882976532
[32m[0514 06:10:49 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.3184075653553009, Train Loss: 0.3076564371585846
[32m[0514 06:10:49 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.3184172213077545, Train Loss: 0.3076520264148712
[32m[0514 06:10:49 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.3184267580509186, Train Loss: 0.3076477348804474
[32m[0514 06:10:49 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.3184361755847931, Train Loss: 0.30764347314834595
[32m[0514 06:10:49 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.31844544410705566, Train Loss: 0.3076392114162445
[32m[0514 06:10:49 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.31845468282699585, Train Loss: 0.30763497948646545
[32m[0514 06:10:49 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.3184637129306793, Train Loss: 0.3076308071613312
[32m[0514 06:10:49 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.3184727132320404, Train Loss: 0.3076266646385193
[32m[0514 06:10:49 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.31848159432411194, Train Loss: 0.3076224625110626
[32m[0514 06:10:49 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.3184903860092163, Train Loss: 0.3076184093952179
[32m[0514 06:10:50 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.31849905848503113, Train Loss: 0.30761435627937317
[32m[0514 06:10:50 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.3185076117515564, Train Loss: 0.30761027336120605
[32m[0514 06:10:50 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.3185160756111145, Train Loss: 0.3076062798500061
[32m[0514 06:10:50 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.3185245394706726, Train Loss: 0.30760231614112854
[32m[0514 06:10:50 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.3185328543186188, Train Loss: 0.307598352432251
[32m[0514 06:10:50 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.3185410797595978, Train Loss: 0.3075944185256958
[32m[0514 06:10:50 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.3185492157936096, Train Loss: 0.3075904846191406
[32m[0514 06:10:50 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.3185572624206543, Train Loss: 0.30758658051490784
[32m[0514 06:10:50 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.3185652196407318, Train Loss: 0.3075827360153198
[32m[0514 06:10:50 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.31857314705848694, Train Loss: 0.30757883191108704
[32m[0514 06:10:50 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.3185810446739197, Train Loss: 0.3075750172138214
[32m[0514 06:10:50 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.3185887932777405, Train Loss: 0.307571142911911
[32m[0514 06:10:50 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.3185964822769165, Train Loss: 0.30756738781929016
[32m[0514 06:10:51 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.318604052066803, Train Loss: 0.3075636327266693
[32m[0514 06:10:51 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.3186115622520447, Train Loss: 0.3075598478317261
[32m[0514 06:10:51 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.3186190128326416, Train Loss: 0.3075561225414276
[32m[0514 06:10:51 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.31862640380859375, Train Loss: 0.30755239725112915
[32m[0514 06:10:51 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.3186337947845459, Train Loss: 0.3075486719608307
[32m[0514 06:10:51 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.3186410665512085, Train Loss: 0.3075449764728546
[32m[0514 06:10:51 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.31864824891090393, Train Loss: 0.30754128098487854
[32m[0514 06:10:51 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.318655401468277, Train Loss: 0.30753767490386963
[32m[0514 06:10:51 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.31866249442100525, Train Loss: 0.30753400921821594
[32m[0514 06:10:51 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.31866949796676636, Train Loss: 0.30753040313720703
[32m[0514 06:10:51 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.3186764419078827, Train Loss: 0.30752676725387573
[32m[0514 06:10:51 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.31868332624435425, Train Loss: 0.3075231611728668
[32m[0514 06:10:51 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.3186901807785034, Train Loss: 0.3075195848941803
[32m[0514 06:10:52 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.3186970055103302, Train Loss: 0.3075160086154938
[32m[0514 06:10:52 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.3187037408351898, Train Loss: 0.30751240253448486
[32m[0514 06:10:52 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.31871041655540466, Train Loss: 0.3075089156627655
[32m[0514 06:10:52 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.31871703267097473, Train Loss: 0.307505339384079
[32m[0514 06:10:52 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.3187235891819, Train Loss: 0.30750179290771484
[32m[0514 06:10:52 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.31873011589050293, Train Loss: 0.3074982762336731
[32m[0514 06:10:52 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.31873664259910583, Train Loss: 0.30749478936195374
[32m[0514 06:10:52 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.3187430500984192, Train Loss: 0.307491272687912
[32m[0514 06:10:52 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.31874945759773254, Train Loss: 0.307487815618515
[32m[0514 06:10:52 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.31875577569007874, Train Loss: 0.30748432874679565
[32m[0514 06:10:52 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.3187620937824249, Train Loss: 0.3074808418750763
[32m[0514 06:10:52 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.31876829266548157, Train Loss: 0.3074774146080017
[32m[0514 06:10:52 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.318774551153183, Train Loss: 0.30747395753860474
[32m[0514 06:10:53 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.31878069043159485, Train Loss: 0.30747053027153015
[32m[0514 06:10:53 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.3187867999076843, Train Loss: 0.30746710300445557
[32m[0514 06:10:53 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.3187928795814514, Train Loss: 0.3074636459350586
[32m[0514 06:10:53 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.3187989294528961, Train Loss: 0.3074602782726288
[32m[0514 06:10:53 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.31880494952201843, Train Loss: 0.3074568808078766
[32m[0514 06:10:53 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.3188108801841736, Train Loss: 0.307453453540802
[32m[0514 06:10:53 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.3188168406486511, Train Loss: 0.3074500858783722
[32m[0514 06:10:53 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.3188227117061615, Train Loss: 0.30744668841362
[32m[0514 06:10:53 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.3188285529613495, Train Loss: 0.3074432909488678
[32m[0514 06:10:53 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.3188343644142151, Train Loss: 0.3074399530887604
[32m[0514 06:10:53 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.3188401162624359, Train Loss: 0.30743664503097534
[32m[0514 06:10:53 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.31884583830833435, Train Loss: 0.30743324756622314
[32m[0514 06:10:54 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.3188515603542328, Train Loss: 0.3074299395084381
[32m[0514 06:10:54 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.31885722279548645, Train Loss: 0.3074266016483307
[32m[0514 06:10:54 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.3188628852367401, Train Loss: 0.3074232339859009
[32m[0514 06:10:54 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.3188685178756714, Train Loss: 0.30741989612579346
[32m[0514 06:10:54 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.3188740313053131, Train Loss: 0.3074166476726532
[32m[0514 06:10:54 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.3188796043395996, Train Loss: 0.3074133098125458
[32m[0514 06:10:54 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.31888511776924133, Train Loss: 0.30741003155708313
[32m[0514 06:10:54 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.31889060139656067, Train Loss: 0.3074067234992981
[32m[0514 06:10:54 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.31889602541923523, Train Loss: 0.3074033856391907
[32m[0514 06:10:54 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.3189014494419098, Train Loss: 0.3074001967906952
[32m[0514 06:10:54 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.31890684366226196, Train Loss: 0.30739685893058777
[32m[0514 06:10:54 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.3189122676849365, Train Loss: 0.30739355087280273
[32m[0514 06:10:54 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.3189176023006439, Train Loss: 0.30739033222198486
[32m[0514 06:10:54 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.31892290711402893, Train Loss: 0.3073870539665222
[32m[0514 06:10:55 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.31892815232276917, Train Loss: 0.30738377571105957
[32m[0514 06:10:55 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.3189334273338318, Train Loss: 0.3073805570602417
[32m[0514 06:10:55 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.318938672542572, Train Loss: 0.30737730860710144
[32m[0514 06:10:55 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.31894388794898987, Train Loss: 0.3073740303516388
[32m[0514 06:10:55 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.31894904375076294, Train Loss: 0.3073708415031433
[32m[0514 06:10:55 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.318954199552536, Train Loss: 0.30736756324768066
[32m[0514 06:10:55 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.3189593553543091, Train Loss: 0.3073643445968628
[32m[0514 06:10:55 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.318964421749115, Train Loss: 0.3073611259460449
[32m[0514 06:10:55 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.3189695179462433, Train Loss: 0.30735790729522705
[32m[0514 06:10:55 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.3189746141433716, Train Loss: 0.30735471844673157
[32m[0514 06:10:55 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.3189796507358551, Train Loss: 0.3073514997959137
[32m[0514 06:10:55 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.31898462772369385, Train Loss: 0.3073482811450958
[32m[0514 06:10:56 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.31898966431617737, Train Loss: 0.30734509229660034
[32m[0514 06:10:56 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.3189946115016937, Train Loss: 0.3073418438434601
[32m[0514 06:10:56 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.31899958848953247, Train Loss: 0.307338684797287
[32m[0514 06:10:56 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.31900444626808167, Train Loss: 0.3073354959487915
[32m[0514 06:10:56 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.319009393453598, Train Loss: 0.30733227729797363
[32m[0514 06:10:56 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.3190143406391144, Train Loss: 0.30732911825180054
[32m[0514 06:10:56 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.3190191984176636, Train Loss: 0.3073258697986603
[32m[0514 06:10:56 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.31902408599853516, Train Loss: 0.3073227107524872
[32m[0514 06:10:56 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.3190288543701172, Train Loss: 0.3073195815086365
[32m[0514 06:10:56 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.3190337121486664, Train Loss: 0.3073163628578186
[32m[0514 06:10:56 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.3190384805202484, Train Loss: 0.3073132336139679
[32m[0514 06:10:56 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.31904327869415283, Train Loss: 0.3073101043701172
[32m[0514 06:10:56 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.3190479576587677, Train Loss: 0.3073068857192993
[32m[0514 06:10:57 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.31905272603034973, Train Loss: 0.3073037564754486
[32m[0514 06:10:57 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.3190574645996094, Train Loss: 0.3073005974292755
[32m[0514 06:10:57 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.31906217336654663, Train Loss: 0.3072974383831024
[32m[0514 06:10:57 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.3190668523311615, Train Loss: 0.3072943389415741
[32m[0514 06:10:57 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.319071501493454, Train Loss: 0.3072911500930786
[32m[0514 06:10:57 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.31907618045806885, Train Loss: 0.3072880208492279
[32m[0514 06:10:57 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.31908082962036133, Train Loss: 0.3072848916053772
[32m[0514 06:10:57 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.31908541917800903, Train Loss: 0.3072817623615265
[32m[0514 06:10:57 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.3190900385379791, Train Loss: 0.3072786033153534
[32m[0514 06:10:57 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.31909462809562683, Train Loss: 0.3072754442691803
[32m[0514 06:10:57 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.31909918785095215, Train Loss: 0.3072723150253296
[32m[0514 06:10:57 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.31910377740859985, Train Loss: 0.30726921558380127
[32m[0514 06:10:58 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.3191083073616028, Train Loss: 0.30726611614227295
[32m[0514 06:10:58 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.3191128075122833, Train Loss: 0.30726298689842224
[32m[0514 06:10:58 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.31911730766296387, Train Loss: 0.30725985765457153
[32m[0514 06:10:58 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.3191218376159668, Train Loss: 0.3072567284107208
[32m[0514 06:10:58 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.31912630796432495, Train Loss: 0.3072536587715149
[32m[0514 06:10:58 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.3191307783126831, Train Loss: 0.3072505295276642
[32m[0514 06:10:58 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.31913527846336365, Train Loss: 0.30724743008613586
[32m[0514 06:10:58 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.31913965940475464, Train Loss: 0.30724427103996277
[32m[0514 06:10:58 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.3191440999507904, Train Loss: 0.3072412610054016
[32m[0514 06:10:58 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.3191485106945038, Train Loss: 0.3072381317615509
[32m[0514 06:10:58 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.31915292143821716, Train Loss: 0.3072350323200226
[32m[0514 06:10:58 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.31915730237960815, Train Loss: 0.30723193287849426
[32m[0514 06:10:58 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.31916168332099915, Train Loss: 0.30722883343696594
[32m[0514 06:10:58 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.31916603446006775, Train Loss: 0.3072257936000824
[32m[0514 06:10:59 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.31917038559913635, Train Loss: 0.3072226643562317
[32m[0514 06:10:59 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.3191746771335602, Train Loss: 0.30721962451934814
[32m[0514 06:10:59 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.3191790282726288, Train Loss: 0.3072165250778198
[32m[0514 06:10:59 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.3191832900047302, Train Loss: 0.3072134554386139
[32m[0514 06:10:59 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.31918764114379883, Train Loss: 0.30721038579940796
[32m[0514 06:10:59 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.31919193267822266, Train Loss: 0.30720725655555725
[32m[0514 06:10:59 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.3191961944103241, Train Loss: 0.3072042167186737
[32m[0514 06:10:59 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.31920045614242554, Train Loss: 0.3072011470794678
[32m[0514 06:10:59 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.319204717874527, Train Loss: 0.30719801783561707
[32m[0514 06:10:59 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.31920892000198364, Train Loss: 0.3071949779987335
[32m[0514 06:10:59 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.3192131817340851, Train Loss: 0.3071918785572052
[32m[0514 06:10:59 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.31921738386154175, Train Loss: 0.30718886852264404
[32m[0514 06:10:59 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.3192215859889984, Train Loss: 0.3071858286857605
[32m[0514 06:11:00 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.3192257583141327, Train Loss: 0.30718275904655457
[32m[0514 06:11:00 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.31923002004623413, Train Loss: 0.30717968940734863
[32m[0514 06:11:00 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.31923413276672363, Train Loss: 0.3071766197681427
[32m[0514 06:11:00 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.3192382752895355, Train Loss: 0.30717355012893677
[32m[0514 06:11:00 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.3192424476146698, Train Loss: 0.3071705400943756
[32m[0514 06:11:00 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.3192466199398041, Train Loss: 0.30716750025749207
[32m[0514 06:11:00 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.31925076246261597, Train Loss: 0.30716443061828613
[32m[0514 06:11:00 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.3192548453807831, Train Loss: 0.307161420583725
[32m[0514 06:11:00 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.3192589581012726, Train Loss: 0.30715835094451904
[32m[0514 06:11:00 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.3192630708217621, Train Loss: 0.3071553409099579
[32m[0514 06:11:00 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.3192671537399292, Train Loss: 0.30715227127075195
[32m[0514 06:11:00 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.3192712068557739, Train Loss: 0.3071492612361908
[32m[0514 06:11:01 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.31927525997161865, Train Loss: 0.30714619159698486
[32m[0514 06:11:01 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.31927937269210815, Train Loss: 0.3071431517601013
[32m[0514 06:11:01 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.3192833960056305, Train Loss: 0.3071401119232178
[32m[0514 06:11:01 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.3192874491214752, Train Loss: 0.30713704228401184
[32m[0514 06:11:01 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.31929147243499756, Train Loss: 0.3071340322494507
[32m[0514 06:11:01 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.3192954659461975, Train Loss: 0.3071310222148895
[32m[0514 06:11:01 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.319299578666687, Train Loss: 0.307127982378006
[32m[0514 06:11:01 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.3193034827709198, Train Loss: 0.30712494254112244
[32m[0514 06:11:01 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.31930750608444214, Train Loss: 0.30712196230888367
[32m[0514 06:11:01 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.3193114995956421, Train Loss: 0.3071189224720001
[32m[0514 06:11:01 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.31931543350219727, Train Loss: 0.30711594223976135
[32m[0514 06:11:01 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.3193194568157196, Train Loss: 0.3071129024028778
[32m[0514 06:11:01 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.31932342052459717, Train Loss: 0.3071098327636719
[32m[0514 06:11:02 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.31932735443115234, Train Loss: 0.3071068525314331
[32m[0514 06:11:02 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.3193313181400299, Train Loss: 0.30710384249687195
[32m[0514 06:11:02 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.3193351924419403, Train Loss: 0.3071008026599884
[32m[0514 06:11:02 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.31933915615081787, Train Loss: 0.30709779262542725
[32m[0514 06:11:02 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.31934306025505066, Train Loss: 0.3070948123931885
[32m[0514 06:11:02 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.31934696435928345, Train Loss: 0.3070918023586273
[32m[0514 06:11:02 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.31935083866119385, Train Loss: 0.30708879232406616
[32m[0514 06:11:02 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.31935474276542664, Train Loss: 0.307085782289505
[32m[0514 06:11:02 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.31935858726501465, Train Loss: 0.30708277225494385
[32m[0514 06:11:02 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.3193625211715698, Train Loss: 0.3070797622203827
[32m[0514 06:11:02 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.3193663954734802, Train Loss: 0.3070768117904663
[32m[0514 06:11:02 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.3193702697753906, Train Loss: 0.30707380175590515
[32m[0514 06:11:02 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.31937408447265625, Train Loss: 0.307070791721344
[32m[0514 06:11:03 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.31937792897224426, Train Loss: 0.3070678114891052
[32m[0514 06:11:03 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.3193817436695099, Train Loss: 0.30706480145454407
[32m[0514 06:11:03 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.3193855583667755, Train Loss: 0.3070617914199829
[32m[0514 06:11:03 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.3193894028663635, Train Loss: 0.30705881118774414
[32m[0514 06:11:03 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.31939324736595154, Train Loss: 0.30705583095550537
[32m[0514 06:11:03 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.3193970322608948, Train Loss: 0.3070528507232666
[32m[0514 06:11:03 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.3194007873535156, Train Loss: 0.30704981088638306
[32m[0514 06:11:03 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.31940460205078125, Train Loss: 0.3070468604564667
[32m[0514 06:11:03 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.3194083869457245, Train Loss: 0.3070438504219055
[32m[0514 06:11:03 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.3194121718406677, Train Loss: 0.30704087018966675
[32m[0514 06:11:03 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.3194158971309662, Train Loss: 0.30703791975975037
[32m[0514 06:11:03 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.3194196820259094, Train Loss: 0.3070349097251892
[32m[0514 06:11:04 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.3194234073162079, Train Loss: 0.3070319890975952
[32m[0514 06:11:04 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.3194271922111511, Train Loss: 0.30702894926071167
[32m[0514 06:11:04 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.3194309175014496, Train Loss: 0.3070259988307953
[32m[0514 06:11:04 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.31943464279174805, Train Loss: 0.30702295899391174
[32m[0514 06:11:04 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.3194383680820465, Train Loss: 0.30702003836631775
[32m[0514 06:11:04 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.31944212317466736, Train Loss: 0.30701708793640137
[32m[0514 06:11:04 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.31944581866264343, Train Loss: 0.3070140779018402
[32m[0514 06:11:04 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.3194495141506195, Train Loss: 0.30701112747192383
[32m[0514 06:11:04 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.3194531798362732, Train Loss: 0.30700814723968506
[32m[0514 06:11:04 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.31945687532424927, Train Loss: 0.3070051968097687
[32m[0514 06:11:04 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.31946057081222534, Train Loss: 0.3070021867752075
[32m[0514 06:11:04 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.3194642663002014, Train Loss: 0.30699923634529114
[32m[0514 06:11:04 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.3194679021835327, Train Loss: 0.30699625611305237
[32m[0514 06:11:05 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.3194716274738312, Train Loss: 0.306993305683136
[32m[0514 06:11:05 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.3194752335548401, Train Loss: 0.3069903552532196
[32m[0514 06:11:05 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.3194788992404938, Train Loss: 0.3069874048233032
[32m[0514 06:11:05 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.3194825351238251, Train Loss: 0.30698448419570923
[32m[0514 06:11:05 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.31948617100715637, Train Loss: 0.30698150396347046
[32m[0514 06:11:05 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.31948983669281006, Train Loss: 0.30697858333587646
[32m[0514 06:11:05 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.31949344277381897, Train Loss: 0.3069756031036377
[32m[0514 06:11:05 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.3194970488548279, Train Loss: 0.3069726228713989
[32m[0514 06:11:05 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.3195006847381592, Train Loss: 0.30696964263916016
[32m[0514 06:11:05 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.3195042610168457, Train Loss: 0.3069666624069214
[32m[0514 06:11:05 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.3195078372955322, Train Loss: 0.306963711977005
[32m[0514 06:11:05 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.31951144337654114, Train Loss: 0.3069608211517334
[32m[0514 06:11:05 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.31951507925987244, Train Loss: 0.30695784091949463
[32m[0514 06:11:06 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.3195186257362366, Train Loss: 0.30695489048957825
[32m[0514 06:11:06 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.3195222020149231, Train Loss: 0.30695194005966187
[32m[0514 06:11:06 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.3195258378982544, Train Loss: 0.30694901943206787
[32m[0514 06:11:06 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.31952935457229614, Train Loss: 0.3069460690021515
[32m[0514 06:11:06 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.31953293085098267, Train Loss: 0.3069431185722351
[32m[0514 06:11:06 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.3195364773273468, Train Loss: 0.3069401681423187
[32m[0514 06:11:06 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.31954002380371094, Train Loss: 0.30693724751472473
[32m[0514 06:11:06 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.3195435702800751, Train Loss: 0.30693432688713074
[32m[0514 06:11:06 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.3195471465587616, Train Loss: 0.30693137645721436
[32m[0514 06:11:06 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.31955063343048096, Train Loss: 0.3069283664226532
[32m[0514 06:11:06 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.3195541799068451, Train Loss: 0.3069254755973816
[32m[0514 06:11:06 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.31955769658088684, Train Loss: 0.3069225251674652
[32m[0514 06:11:07 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.3195611834526062, Train Loss: 0.3069196045398712
[32m[0514 06:11:07 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.31956470012664795, Train Loss: 0.30691662430763245
[32m[0514 06:11:07 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.3195681869983673, Train Loss: 0.30691373348236084
[32m[0514 06:11:07 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.31957170367240906, Train Loss: 0.30691078305244446
[32m[0514 06:11:07 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.31957516074180603, Train Loss: 0.30690789222717285
[32m[0514 06:11:07 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.31957870721817017, Train Loss: 0.3069049119949341
[32m[0514 06:11:07 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.31958216428756714, Train Loss: 0.3069019913673401
[32m[0514 06:11:07 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.3195856511592865, Train Loss: 0.3068991005420685
[32m[0514 06:11:07 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.31958913803100586, Train Loss: 0.3068961501121521
[32m[0514 06:11:07 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.3195926249027252, Train Loss: 0.3068931996822357
[32m[0514 06:11:07 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.3195960521697998, Train Loss: 0.30689024925231934
[32m[0514 06:11:07 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.3195994794368744, Train Loss: 0.30688735842704773
[32m[0514 06:11:07 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.31960296630859375, Train Loss: 0.30688443779945374
[32m[0514 06:11:08 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.3196064233779907, Train Loss: 0.30688148736953735
[32m[0514 06:11:08 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.3196098506450653, Train Loss: 0.30687856674194336
[32m[0514 06:11:08 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 06:11:08 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 06:11:08 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 06:11:08 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 06:11:08 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 06:11:08 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 06:11:08 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 06:11:08 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 06:11:08 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 06:11:08 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 06:11:08 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 06:11:08 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 06:11:08 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 06:11:08 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 06:11:08 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 06:11:08 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 06:11:08 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 06:11:08 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 06:11:08 @mbmf_main.py:227][0m batch size for trpo is 1000
[32m[0514 06:11:08 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 06:11:08 @mbmf_worker.py:179][0m kill message for worker
[32m[0514 06:11:08 @mbmf_main.py:132][0m Training starts at /root/mbbl
[32m[0514 06:11:08 @base_worker.py:45][0m Worker 0 online
[32m[0514 06:11:08 @base_worker.py:45][0m Worker 1 online
[32m[0514 06:11:08 @base_worker.py:45][0m Worker 2 online
[32m[0514 06:11:08 @base_worker.py:45][0m Worker 3 online
[32m[0514 06:11:08 @base_worker.py:45][0m Worker 4 online
[32m[0514 06:11:08 @base_worker.py:45][0m Worker 5 online
[32m[0514 06:11:08 @base_worker.py:45][0m Worker 6 online
[32m[0514 06:11:08 @base_worker.py:45][0m Worker 7 online
[32m[0514 06:11:08 @base_worker.py:45][0m Worker 8 online
[32m[0514 06:11:08 @base_worker.py:45][0m Worker 9 online
[32m[0514 06:11:08 @base_worker.py:45][0m Worker 10 online
[32m[0514 06:11:08 @base_worker.py:45][0m Worker 11 online
[32m[0514 06:11:08 @base_worker.py:45][0m Worker 12 online
[32m[0514 06:11:08 @base_worker.py:45][0m Worker 13 online
[32m[0514 06:11:08 @base_worker.py:45][0m Worker 14 online
[32m[0514 06:11:08 @base_worker.py:45][0m Worker 15 online
[32m[0514 06:11:08 @base_worker.py:45][0m Worker 16 online
[32m[0514 06:11:08 @base_worker.py:45][0m Worker 17 online
[32m[0514 06:11:08 @base_worker.py:45][0m Worker 18 online
[32m[0514 06:11:08 @base_worker.py:45][0m Worker 19 online
[32m[0514 06:11:09 @base_trainer.py:152][0m Trainer maintains [1] policy network
[32m[0514 06:11:09 @base_trainer.py:152][0m Trainer maintains [1] dynamics network
[32m[0514 06:11:09 @base_trainer.py:152][0m Trainer maintains [1] reward network
[32m[0514 06:11:10 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:11:10 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:11:10 @base_trainer.py:216][0m Mean reward: -348.96435800195655
[32m[0514 06:11:12 @base_main.py:38][0m --------------- Iteration 1 ---------------
[32m[0514 06:11:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0000 mins
[32m[0514 06:11:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0081 mins
[32m[0514 06:11:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0243 mins
[32m[0514 06:11:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:11:12 @base_main.py:47][0m 1005 total steps have happened
[32m[0514 06:11:12 @base_main.py:52][0m [avg_reward]: -348.96435800195655
[32m[0514 06:11:12 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:11:12 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:11:12 @base_trainer.py:216][0m Mean reward: -217.24334863899716
[32m[0514 06:11:13 @base_main.py:38][0m --------------- Iteration 2 ---------------
[32m[0514 06:11:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0327 mins
[32m[0514 06:11:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0083 mins
[32m[0514 06:11:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0149 mins
[32m[0514 06:11:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 06:11:13 @base_main.py:47][0m 2010 total steps have happened
[32m[0514 06:11:13 @base_main.py:52][0m [avg_reward]: -217.24334863899716
[32m[0514 06:11:13 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:11:13 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:11:13 @base_trainer.py:216][0m Mean reward: -305.575685108579
[32m[0514 06:11:14 @base_main.py:38][0m --------------- Iteration 3 ---------------
[32m[0514 06:11:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0563 mins
[32m[0514 06:11:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0060 mins
[32m[0514 06:11:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0144 mins
[32m[0514 06:11:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:11:14 @base_main.py:47][0m 3015 total steps have happened
[32m[0514 06:11:14 @base_main.py:52][0m [avg_reward]: -305.575685108579
[32m[0514 06:11:15 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:11:15 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:11:15 @base_trainer.py:216][0m Mean reward: -396.63689941793973
[32m[0514 06:11:16 @base_main.py:38][0m --------------- Iteration 4 ---------------
[32m[0514 06:11:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0769 mins
[32m[0514 06:11:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0082 mins
[32m[0514 06:11:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0148 mins
[32m[0514 06:11:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:11:16 @base_main.py:47][0m 4020 total steps have happened
[32m[0514 06:11:16 @base_main.py:52][0m [avg_reward]: -396.63689941793973
[32m[0514 06:11:16 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:11:16 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:11:16 @base_trainer.py:216][0m Mean reward: -419.50928687684717
[32m[0514 06:11:17 @base_main.py:38][0m --------------- Iteration 5 ---------------
[32m[0514 06:11:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1001 mins
[32m[0514 06:11:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0075 mins
[32m[0514 06:11:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0142 mins
[32m[0514 06:11:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:11:17 @base_main.py:47][0m 5025 total steps have happened
[32m[0514 06:11:17 @base_main.py:52][0m [avg_reward]: -419.50928687684717
[32m[0514 06:11:17 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:11:17 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:11:17 @base_trainer.py:216][0m Mean reward: -326.5920174109329
[32m[0514 06:11:18 @base_main.py:38][0m --------------- Iteration 6 ---------------
[32m[0514 06:11:18 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1220 mins
[32m[0514 06:11:18 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0066 mins
[32m[0514 06:11:18 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0150 mins
[32m[0514 06:11:18 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:11:18 @base_main.py:47][0m 6030 total steps have happened
[32m[0514 06:11:18 @base_main.py:52][0m [avg_reward]: -326.5920174109329
[32m[0514 06:11:19 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:11:19 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:11:19 @base_trainer.py:216][0m Mean reward: -315.9599571234551
[32m[0514 06:11:19 @base_main.py:38][0m --------------- Iteration 7 ---------------
[32m[0514 06:11:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1437 mins
[32m[0514 06:11:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0058 mins
[32m[0514 06:11:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0143 mins
[32m[0514 06:11:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:11:19 @base_main.py:47][0m 7035 total steps have happened
[32m[0514 06:11:19 @base_main.py:52][0m [avg_reward]: -315.9599571234551
[32m[0514 06:11:20 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:11:20 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:11:20 @base_trainer.py:216][0m Mean reward: -300.432400707728
[32m[0514 06:11:21 @base_main.py:38][0m --------------- Iteration 8 ---------------
[32m[0514 06:11:21 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1640 mins
[32m[0514 06:11:21 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0071 mins
[32m[0514 06:11:21 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0139 mins
[32m[0514 06:11:21 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0004 mins
[32m[0514 06:11:21 @base_main.py:47][0m 8040 total steps have happened
[32m[0514 06:11:21 @base_main.py:52][0m [avg_reward]: -300.432400707728
[32m[0514 06:11:21 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:11:21 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:11:21 @base_trainer.py:216][0m Mean reward: -262.0339915334562
[32m[0514 06:11:22 @base_main.py:38][0m --------------- Iteration 9 ---------------
[32m[0514 06:11:22 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1855 mins
[32m[0514 06:11:22 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0055 mins
[32m[0514 06:11:22 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0160 mins
[32m[0514 06:11:22 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:11:22 @base_main.py:47][0m 9045 total steps have happened
[32m[0514 06:11:22 @base_main.py:52][0m [avg_reward]: -262.0339915334562
[32m[0514 06:11:22 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:11:22 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:11:22 @base_trainer.py:216][0m Mean reward: -233.49354387982126
[32m[0514 06:11:23 @base_main.py:38][0m --------------- Iteration 10 ---------------
[32m[0514 06:11:23 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2073 mins
[32m[0514 06:11:23 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0054 mins
[32m[0514 06:11:23 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0145 mins
[32m[0514 06:11:23 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:11:23 @base_main.py:47][0m 10050 total steps have happened
[32m[0514 06:11:23 @base_main.py:52][0m [avg_reward]: -233.49354387982126
[32m[0514 06:11:24 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:11:24 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:11:24 @base_trainer.py:216][0m Mean reward: -277.1466700365397
[32m[0514 06:11:24 @base_main.py:38][0m --------------- Iteration 11 ---------------
[32m[0514 06:11:24 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2274 mins
[32m[0514 06:11:24 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0056 mins
[32m[0514 06:11:24 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0139 mins
[32m[0514 06:11:24 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:11:24 @base_main.py:47][0m 11055 total steps have happened
[32m[0514 06:11:24 @base_main.py:52][0m [avg_reward]: -277.1466700365397
[32m[0514 06:11:25 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:11:25 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:11:25 @base_trainer.py:216][0m Mean reward: -306.03972171789155
[32m[0514 06:11:26 @base_main.py:38][0m --------------- Iteration 12 ---------------
[32m[0514 06:11:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2471 mins
[32m[0514 06:11:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0062 mins
[32m[0514 06:11:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0145 mins
[32m[0514 06:11:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:11:26 @base_main.py:47][0m 12060 total steps have happened
[32m[0514 06:11:26 @base_main.py:52][0m [avg_reward]: -306.03972171789155
[32m[0514 06:11:26 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:11:26 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:11:26 @base_trainer.py:216][0m Mean reward: -307.1719527095111
[32m[0514 06:11:27 @base_main.py:38][0m --------------- Iteration 13 ---------------
[32m[0514 06:11:27 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2681 mins
[32m[0514 06:11:27 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0056 mins
[32m[0514 06:11:27 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0141 mins
[32m[0514 06:11:27 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 06:11:27 @base_main.py:47][0m 13065 total steps have happened
[32m[0514 06:11:27 @base_main.py:52][0m [avg_reward]: -307.1719527095111
[32m[0514 06:11:27 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:11:27 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:11:27 @base_trainer.py:216][0m Mean reward: -253.75986454656064
[32m[0514 06:11:28 @base_main.py:38][0m --------------- Iteration 14 ---------------
[32m[0514 06:11:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2881 mins
[32m[0514 06:11:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0056 mins
[32m[0514 06:11:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0141 mins
[32m[0514 06:11:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:11:28 @base_main.py:47][0m 14070 total steps have happened
[32m[0514 06:11:28 @base_main.py:52][0m [avg_reward]: -253.75986454656064
[32m[0514 06:11:28 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:11:28 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:11:28 @base_trainer.py:216][0m Mean reward: -271.5036747469632
[32m[0514 06:11:29 @base_main.py:38][0m --------------- Iteration 15 ---------------
[32m[0514 06:11:29 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3080 mins
[32m[0514 06:11:29 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0054 mins
[32m[0514 06:11:29 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0141 mins
[32m[0514 06:11:29 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:11:29 @base_main.py:47][0m 15075 total steps have happened
[32m[0514 06:11:29 @base_main.py:52][0m [avg_reward]: -271.5036747469632
[32m[0514 06:11:30 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:11:30 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:11:30 @base_trainer.py:216][0m Mean reward: -273.86957772164476
[32m[0514 06:11:30 @base_main.py:38][0m --------------- Iteration 16 ---------------
[32m[0514 06:11:30 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3278 mins
[32m[0514 06:11:30 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0055 mins
[32m[0514 06:11:30 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0137 mins
[32m[0514 06:11:30 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:11:30 @base_main.py:47][0m 16080 total steps have happened
[32m[0514 06:11:30 @base_main.py:52][0m [avg_reward]: -273.86957772164476
[32m[0514 06:11:31 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:11:31 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:11:31 @base_trainer.py:216][0m Mean reward: -276.11968593128097
[32m[0514 06:11:32 @base_main.py:38][0m --------------- Iteration 17 ---------------
[32m[0514 06:11:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3472 mins
[32m[0514 06:11:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0050 mins
[32m[0514 06:11:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0131 mins
[32m[0514 06:11:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 06:11:32 @base_main.py:47][0m 17085 total steps have happened
[32m[0514 06:11:32 @base_main.py:52][0m [avg_reward]: -276.11968593128097
[32m[0514 06:11:32 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:11:32 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:11:32 @base_trainer.py:216][0m Mean reward: -258.45580815459675
[32m[0514 06:11:33 @base_main.py:38][0m --------------- Iteration 18 ---------------
[32m[0514 06:11:33 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3658 mins
[32m[0514 06:11:33 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0057 mins
[32m[0514 06:11:33 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0140 mins
[32m[0514 06:11:33 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:11:33 @base_main.py:47][0m 18090 total steps have happened
[32m[0514 06:11:33 @base_main.py:52][0m [avg_reward]: -258.45580815459675
[32m[0514 06:11:33 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:11:33 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:11:33 @base_trainer.py:216][0m Mean reward: -235.82788796107153
[32m[0514 06:11:34 @base_main.py:38][0m --------------- Iteration 19 ---------------
[32m[0514 06:11:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3857 mins
[32m[0514 06:11:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0053 mins
[32m[0514 06:11:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0147 mins
[32m[0514 06:11:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:11:34 @base_main.py:47][0m 19095 total steps have happened
[32m[0514 06:11:34 @base_main.py:52][0m [avg_reward]: -235.82788796107153
[32m[0514 06:11:34 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:11:34 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:11:34 @base_trainer.py:216][0m Mean reward: -282.66552819904274
[32m[0514 06:11:35 @base_main.py:38][0m --------------- Iteration 20 ---------------
[32m[0514 06:11:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4059 mins
[32m[0514 06:11:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0050 mins
[32m[0514 06:11:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0131 mins
[32m[0514 06:11:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:11:35 @base_main.py:47][0m 20100 total steps have happened
[32m[0514 06:11:35 @base_main.py:52][0m [avg_reward]: -282.66552819904274
[32m[0514 06:11:35 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:11:35 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:11:35 @base_trainer.py:216][0m Mean reward: -308.3706958723498
[32m[0514 06:11:36 @base_main.py:38][0m --------------- Iteration 21 ---------------
[32m[0514 06:11:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4243 mins
[32m[0514 06:11:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0056 mins
[32m[0514 06:11:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0137 mins
[32m[0514 06:11:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:11:36 @base_main.py:47][0m 21105 total steps have happened
[32m[0514 06:11:36 @base_main.py:52][0m [avg_reward]: -308.3706958723498
[32m[0514 06:11:37 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:11:37 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:11:37 @base_trainer.py:216][0m Mean reward: -253.16833440981728
[32m[0514 06:11:37 @base_main.py:38][0m --------------- Iteration 22 ---------------
[32m[0514 06:11:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4437 mins
[32m[0514 06:11:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0050 mins
[32m[0514 06:11:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0148 mins
[32m[0514 06:11:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:11:37 @base_main.py:47][0m 22110 total steps have happened
[32m[0514 06:11:37 @base_main.py:52][0m [avg_reward]: -253.16833440981728
[32m[0514 06:11:38 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:11:38 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:11:38 @base_trainer.py:216][0m Mean reward: -217.37304352073647
[32m[0514 06:11:39 @base_main.py:38][0m --------------- Iteration 23 ---------------
[32m[0514 06:11:39 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4638 mins
[32m[0514 06:11:39 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0053 mins
[32m[0514 06:11:39 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0145 mins
[32m[0514 06:11:39 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:11:39 @base_main.py:47][0m 23115 total steps have happened
[32m[0514 06:11:39 @base_main.py:52][0m [avg_reward]: -217.37304352073647
[32m[0514 06:11:39 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:11:39 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:11:39 @base_trainer.py:216][0m Mean reward: -235.3106450034258
[32m[0514 06:11:40 @base_main.py:38][0m --------------- Iteration 24 ---------------
[32m[0514 06:11:40 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4839 mins
[32m[0514 06:11:40 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0056 mins
[32m[0514 06:11:40 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0135 mins
[32m[0514 06:11:40 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:11:40 @base_main.py:47][0m 24120 total steps have happened
[32m[0514 06:11:40 @base_main.py:52][0m [avg_reward]: -235.3106450034258
[32m[0514 06:11:40 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:11:40 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:11:40 @base_trainer.py:216][0m Mean reward: -233.8831143257674
[32m[0514 06:11:41 @base_main.py:38][0m --------------- Iteration 25 ---------------
[32m[0514 06:11:41 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5032 mins
[32m[0514 06:11:41 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0058 mins
[32m[0514 06:11:41 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0134 mins
[32m[0514 06:11:41 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 06:11:41 @base_main.py:47][0m 25125 total steps have happened
[32m[0514 06:11:41 @base_main.py:52][0m [avg_reward]: -233.8831143257674
[32m[0514 06:11:41 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:11:41 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:11:41 @base_trainer.py:216][0m Mean reward: -245.07081057853006
[32m[0514 06:11:42 @base_main.py:38][0m --------------- Iteration 26 ---------------
[32m[0514 06:11:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5227 mins
[32m[0514 06:11:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0052 mins
[32m[0514 06:11:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0150 mins
[32m[0514 06:11:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:11:42 @base_main.py:47][0m 26130 total steps have happened
[32m[0514 06:11:42 @base_main.py:52][0m [avg_reward]: -245.07081057853006
[32m[0514 06:11:43 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:11:43 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:11:43 @base_trainer.py:216][0m Mean reward: -203.9625519901665
[32m[0514 06:11:43 @base_main.py:38][0m --------------- Iteration 27 ---------------
[32m[0514 06:11:43 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5431 mins
[32m[0514 06:11:43 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0056 mins
[32m[0514 06:11:43 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0143 mins
[32m[0514 06:11:43 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:11:43 @base_main.py:47][0m 27135 total steps have happened
[32m[0514 06:11:43 @base_main.py:52][0m [avg_reward]: -203.9625519901665
[32m[0514 06:11:44 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:11:44 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:11:44 @base_trainer.py:216][0m Mean reward: -215.00360347270552
[32m[0514 06:11:45 @base_main.py:38][0m --------------- Iteration 28 ---------------
[32m[0514 06:11:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5631 mins
[32m[0514 06:11:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0054 mins
[32m[0514 06:11:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0138 mins
[32m[0514 06:11:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:11:45 @base_main.py:47][0m 28140 total steps have happened
[32m[0514 06:11:45 @base_main.py:52][0m [avg_reward]: -215.00360347270552
[32m[0514 06:11:45 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:11:45 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:11:45 @base_trainer.py:216][0m Mean reward: -138.8064568142541
[32m[0514 06:11:46 @base_main.py:38][0m --------------- Iteration 29 ---------------
[32m[0514 06:11:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5824 mins
[32m[0514 06:11:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0052 mins
[32m[0514 06:11:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0136 mins
[32m[0514 06:11:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:11:46 @base_main.py:47][0m 29145 total steps have happened
[32m[0514 06:11:46 @base_main.py:52][0m [avg_reward]: -138.8064568142541
[32m[0514 06:11:46 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:11:46 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:11:46 @base_trainer.py:216][0m Mean reward: -207.08112840558292
[32m[0514 06:11:47 @base_main.py:38][0m --------------- Iteration 30 ---------------
[32m[0514 06:11:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6015 mins
[32m[0514 06:11:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0062 mins
[32m[0514 06:11:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0141 mins
[32m[0514 06:11:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:11:47 @base_main.py:47][0m 30150 total steps have happened
[32m[0514 06:11:47 @base_main.py:52][0m [avg_reward]: -207.08112840558292
[32m[0514 06:11:47 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:11:47 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:11:47 @base_trainer.py:216][0m Mean reward: -219.47860458456643
[32m[0514 06:11:48 @base_main.py:38][0m --------------- Iteration 31 ---------------
[32m[0514 06:11:48 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6220 mins
[32m[0514 06:11:48 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0066 mins
[32m[0514 06:11:48 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0138 mins
[32m[0514 06:11:48 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:11:48 @base_main.py:47][0m 31155 total steps have happened
[32m[0514 06:11:48 @base_main.py:52][0m [avg_reward]: -219.47860458456643
[32m[0514 06:11:48 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:11:48 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:11:48 @base_trainer.py:216][0m Mean reward: -245.09496397870976
[32m[0514 06:11:49 @base_main.py:38][0m --------------- Iteration 32 ---------------
[32m[0514 06:11:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6425 mins
[32m[0514 06:11:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0054 mins
[32m[0514 06:11:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0139 mins
[32m[0514 06:11:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:11:49 @base_main.py:47][0m 32160 total steps have happened
[32m[0514 06:11:49 @base_main.py:52][0m [avg_reward]: -245.09496397870976
[32m[0514 06:11:50 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:11:50 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:11:50 @base_trainer.py:216][0m Mean reward: -213.65773043958467
[32m[0514 06:11:51 @base_main.py:38][0m --------------- Iteration 33 ---------------
[32m[0514 06:11:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6620 mins
[32m[0514 06:11:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0062 mins
[32m[0514 06:11:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0137 mins
[32m[0514 06:11:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:11:51 @base_main.py:47][0m 33165 total steps have happened
[32m[0514 06:11:51 @base_main.py:52][0m [avg_reward]: -213.65773043958467
[32m[0514 06:11:51 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:11:51 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:11:51 @base_trainer.py:216][0m Mean reward: -155.39070078141833
[32m[0514 06:11:52 @base_main.py:38][0m --------------- Iteration 34 ---------------
[32m[0514 06:11:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6821 mins
[32m[0514 06:11:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0051 mins
[32m[0514 06:11:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0130 mins
[32m[0514 06:11:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:11:52 @base_main.py:47][0m 34170 total steps have happened
[32m[0514 06:11:52 @base_main.py:52][0m [avg_reward]: -155.39070078141833
[32m[0514 06:11:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:11:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:11:52 @base_trainer.py:216][0m Mean reward: -183.11761721799806
[32m[0514 06:11:53 @base_main.py:38][0m --------------- Iteration 35 ---------------
[32m[0514 06:11:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7004 mins
[32m[0514 06:11:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0062 mins
[32m[0514 06:11:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0130 mins
[32m[0514 06:11:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 06:11:53 @base_main.py:47][0m 35175 total steps have happened
[32m[0514 06:11:53 @base_main.py:52][0m [avg_reward]: -183.11761721799806
[32m[0514 06:11:53 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:11:53 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:11:53 @base_trainer.py:216][0m Mean reward: -167.96207700674307
[32m[0514 06:11:54 @base_main.py:38][0m --------------- Iteration 36 ---------------
[32m[0514 06:11:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7200 mins
[32m[0514 06:11:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0063 mins
[32m[0514 06:11:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0143 mins
[32m[0514 06:11:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:11:54 @base_main.py:47][0m 36180 total steps have happened
[32m[0514 06:11:54 @base_main.py:52][0m [avg_reward]: -167.96207700674307
[32m[0514 06:11:54 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:11:54 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:11:54 @base_trainer.py:216][0m Mean reward: -189.19567132753488
[32m[0514 06:11:55 @base_main.py:38][0m --------------- Iteration 37 ---------------
[32m[0514 06:11:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7409 mins
[32m[0514 06:11:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0052 mins
[32m[0514 06:11:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0142 mins
[32m[0514 06:11:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 06:11:55 @base_main.py:47][0m 37185 total steps have happened
[32m[0514 06:11:55 @base_main.py:52][0m [avg_reward]: -189.19567132753488
[32m[0514 06:11:56 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:11:56 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:11:56 @base_trainer.py:216][0m Mean reward: -162.28901337213523
[32m[0514 06:11:56 @base_main.py:38][0m --------------- Iteration 38 ---------------
[32m[0514 06:11:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7606 mins
[32m[0514 06:11:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0052 mins
[32m[0514 06:11:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0139 mins
[32m[0514 06:11:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:11:56 @base_main.py:47][0m 38190 total steps have happened
[32m[0514 06:11:56 @base_main.py:52][0m [avg_reward]: -162.28901337213523
[32m[0514 06:11:57 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:11:57 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:11:57 @base_trainer.py:216][0m Mean reward: -189.33158864868648
[32m[0514 06:11:58 @base_main.py:38][0m --------------- Iteration 39 ---------------
[32m[0514 06:11:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7799 mins
[32m[0514 06:11:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0058 mins
[32m[0514 06:11:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0132 mins
[32m[0514 06:11:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:11:58 @base_main.py:47][0m 39195 total steps have happened
[32m[0514 06:11:58 @base_main.py:52][0m [avg_reward]: -189.33158864868648
[32m[0514 06:11:58 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:11:58 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:11:58 @base_trainer.py:216][0m Mean reward: -191.59296475591003
[32m[0514 06:11:59 @base_main.py:38][0m --------------- Iteration 40 ---------------
[32m[0514 06:11:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7991 mins
[32m[0514 06:11:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0057 mins
[32m[0514 06:11:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0133 mins
[32m[0514 06:11:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:11:59 @base_main.py:47][0m 40200 total steps have happened
[32m[0514 06:11:59 @base_main.py:52][0m [avg_reward]: -191.59296475591003
[32m[0514 06:11:59 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:11:59 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:11:59 @base_trainer.py:216][0m Mean reward: -190.61084242833184
[32m[0514 06:12:00 @base_main.py:38][0m --------------- Iteration 41 ---------------
[32m[0514 06:12:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8183 mins
[32m[0514 06:12:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0053 mins
[32m[0514 06:12:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0143 mins
[32m[0514 06:12:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 06:12:00 @base_main.py:47][0m 41205 total steps have happened
[32m[0514 06:12:00 @base_main.py:52][0m [avg_reward]: -190.61084242833184
[32m[0514 06:12:00 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:00 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:00 @base_trainer.py:216][0m Mean reward: -240.1331613196311
[32m[0514 06:12:01 @base_main.py:38][0m --------------- Iteration 42 ---------------
[32m[0514 06:12:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8382 mins
[32m[0514 06:12:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0055 mins
[32m[0514 06:12:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0128 mins
[32m[0514 06:12:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:12:01 @base_main.py:47][0m 42210 total steps have happened
[32m[0514 06:12:01 @base_main.py:52][0m [avg_reward]: -240.1331613196311
[32m[0514 06:12:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:01 @base_trainer.py:216][0m Mean reward: -152.73173274749604
[32m[0514 06:12:02 @base_main.py:38][0m --------------- Iteration 43 ---------------
[32m[0514 06:12:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8568 mins
[32m[0514 06:12:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0054 mins
[32m[0514 06:12:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0134 mins
[32m[0514 06:12:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:12:02 @base_main.py:47][0m 43215 total steps have happened
[32m[0514 06:12:02 @base_main.py:52][0m [avg_reward]: -152.73173274749604
[32m[0514 06:12:02 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:02 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:02 @base_trainer.py:216][0m Mean reward: -139.74306669677847
[32m[0514 06:12:03 @base_main.py:38][0m --------------- Iteration 44 ---------------
[32m[0514 06:12:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8759 mins
[32m[0514 06:12:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0056 mins
[32m[0514 06:12:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0139 mins
[32m[0514 06:12:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:03 @base_main.py:47][0m 44220 total steps have happened
[32m[0514 06:12:03 @base_main.py:52][0m [avg_reward]: -139.74306669677847
[32m[0514 06:12:04 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:04 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:04 @base_trainer.py:216][0m Mean reward: -197.85395281417436
[32m[0514 06:12:04 @base_main.py:38][0m --------------- Iteration 45 ---------------
[32m[0514 06:12:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8955 mins
[32m[0514 06:12:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0055 mins
[32m[0514 06:12:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0137 mins
[32m[0514 06:12:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:12:04 @base_main.py:47][0m 45225 total steps have happened
[32m[0514 06:12:04 @base_main.py:52][0m [avg_reward]: -197.85395281417436
[32m[0514 06:12:05 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:05 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:05 @base_trainer.py:216][0m Mean reward: -180.0781338069492
[32m[0514 06:12:06 @base_main.py:38][0m --------------- Iteration 46 ---------------
[32m[0514 06:12:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9149 mins
[32m[0514 06:12:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0058 mins
[32m[0514 06:12:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0134 mins
[32m[0514 06:12:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:12:06 @base_main.py:47][0m 46230 total steps have happened
[32m[0514 06:12:06 @base_main.py:52][0m [avg_reward]: -180.0781338069492
[32m[0514 06:12:06 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:06 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:06 @base_trainer.py:216][0m Mean reward: -209.8594396608887
[32m[0514 06:12:07 @base_main.py:38][0m --------------- Iteration 47 ---------------
[32m[0514 06:12:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9344 mins
[32m[0514 06:12:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0058 mins
[32m[0514 06:12:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0153 mins
[32m[0514 06:12:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:12:07 @base_main.py:47][0m 47235 total steps have happened
[32m[0514 06:12:07 @base_main.py:52][0m [avg_reward]: -209.8594396608887
[32m[0514 06:12:07 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:07 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:07 @base_trainer.py:216][0m Mean reward: -183.40643050657087
[32m[0514 06:12:08 @base_main.py:38][0m --------------- Iteration 48 ---------------
[32m[0514 06:12:08 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9556 mins
[32m[0514 06:12:08 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0062 mins
[32m[0514 06:12:08 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0140 mins
[32m[0514 06:12:08 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:08 @base_main.py:47][0m 48240 total steps have happened
[32m[0514 06:12:08 @base_main.py:52][0m [avg_reward]: -183.40643050657087
[32m[0514 06:12:09 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:09 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:09 @base_trainer.py:216][0m Mean reward: -166.43496022502197
[32m[0514 06:12:09 @base_main.py:38][0m --------------- Iteration 49 ---------------
[32m[0514 06:12:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9760 mins
[32m[0514 06:12:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0062 mins
[32m[0514 06:12:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0139 mins
[32m[0514 06:12:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 06:12:09 @base_main.py:47][0m 49245 total steps have happened
[32m[0514 06:12:09 @base_main.py:52][0m [avg_reward]: -166.43496022502197
[32m[0514 06:12:10 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:10 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:10 @base_trainer.py:216][0m Mean reward: -178.51988657569663
[32m[0514 06:12:10 @base_main.py:38][0m --------------- Iteration 50 ---------------
[32m[0514 06:12:10 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9964 mins
[32m[0514 06:12:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0052 mins
[32m[0514 06:12:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0133 mins
[32m[0514 06:12:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:12:11 @base_main.py:47][0m 50250 total steps have happened
[32m[0514 06:12:11 @base_main.py:52][0m [avg_reward]: -178.51988657569663
[32m[0514 06:12:11 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:11 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:11 @base_trainer.py:216][0m Mean reward: -179.4294010948625
[32m[0514 06:12:12 @base_main.py:38][0m --------------- Iteration 51 ---------------
[32m[0514 06:12:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0151 mins
[32m[0514 06:12:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0051 mins
[32m[0514 06:12:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0133 mins
[32m[0514 06:12:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:12 @base_main.py:47][0m 51255 total steps have happened
[32m[0514 06:12:12 @base_main.py:52][0m [avg_reward]: -179.4294010948625
[32m[0514 06:12:12 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:12 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:12 @base_trainer.py:216][0m Mean reward: -180.62699450676945
[32m[0514 06:12:13 @base_main.py:38][0m --------------- Iteration 52 ---------------
[32m[0514 06:12:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0337 mins
[32m[0514 06:12:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0055 mins
[32m[0514 06:12:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0133 mins
[32m[0514 06:12:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 06:12:13 @base_main.py:47][0m 52260 total steps have happened
[32m[0514 06:12:13 @base_main.py:52][0m [avg_reward]: -180.62699450676945
[32m[0514 06:12:13 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:13 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:13 @base_trainer.py:216][0m Mean reward: -175.03761136541905
[32m[0514 06:12:14 @base_main.py:38][0m --------------- Iteration 53 ---------------
[32m[0514 06:12:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0528 mins
[32m[0514 06:12:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0055 mins
[32m[0514 06:12:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0137 mins
[32m[0514 06:12:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:14 @base_main.py:47][0m 53265 total steps have happened
[32m[0514 06:12:14 @base_main.py:52][0m [avg_reward]: -175.03761136541905
[32m[0514 06:12:14 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:14 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:14 @base_trainer.py:216][0m Mean reward: -184.52090267247695
[32m[0514 06:12:15 @base_main.py:38][0m --------------- Iteration 54 ---------------
[32m[0514 06:12:15 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0721 mins
[32m[0514 06:12:15 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0047 mins
[32m[0514 06:12:15 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0139 mins
[32m[0514 06:12:15 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 06:12:15 @base_main.py:47][0m 54270 total steps have happened
[32m[0514 06:12:15 @base_main.py:52][0m [avg_reward]: -184.52090267247695
[32m[0514 06:12:15 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:15 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:15 @base_trainer.py:216][0m Mean reward: -168.79947896468573
[32m[0514 06:12:16 @base_main.py:38][0m --------------- Iteration 55 ---------------
[32m[0514 06:12:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0910 mins
[32m[0514 06:12:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0051 mins
[32m[0514 06:12:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0135 mins
[32m[0514 06:12:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 06:12:16 @base_main.py:47][0m 55275 total steps have happened
[32m[0514 06:12:16 @base_main.py:52][0m [avg_reward]: -168.79947896468573
[32m[0514 06:12:16 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:16 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:16 @base_trainer.py:216][0m Mean reward: -199.17683487622102
[32m[0514 06:12:17 @base_main.py:38][0m --------------- Iteration 56 ---------------
[32m[0514 06:12:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1099 mins
[32m[0514 06:12:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0044 mins
[32m[0514 06:12:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0514 06:12:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:17 @base_main.py:47][0m 56280 total steps have happened
[32m[0514 06:12:17 @base_main.py:52][0m [avg_reward]: -199.17683487622102
[32m[0514 06:12:17 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:17 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:17 @base_trainer.py:216][0m Mean reward: -153.72650254761027
[32m[0514 06:12:18 @base_main.py:38][0m --------------- Iteration 57 ---------------
[32m[0514 06:12:18 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1249 mins
[32m[0514 06:12:18 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0032 mins
[32m[0514 06:12:18 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0514 06:12:18 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:18 @base_main.py:47][0m 57285 total steps have happened
[32m[0514 06:12:18 @base_main.py:52][0m [avg_reward]: -153.72650254761027
[32m[0514 06:12:18 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:18 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:18 @base_trainer.py:216][0m Mean reward: -170.91639149379185
[32m[0514 06:12:19 @base_main.py:38][0m --------------- Iteration 58 ---------------
[32m[0514 06:12:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1379 mins
[32m[0514 06:12:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0032 mins
[32m[0514 06:12:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0514 06:12:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:12:19 @base_main.py:47][0m 58290 total steps have happened
[32m[0514 06:12:19 @base_main.py:52][0m [avg_reward]: -170.91639149379185
[32m[0514 06:12:19 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:19 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:19 @base_trainer.py:216][0m Mean reward: -184.9473488355767
[32m[0514 06:12:19 @base_main.py:38][0m --------------- Iteration 59 ---------------
[32m[0514 06:12:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1508 mins
[32m[0514 06:12:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 06:12:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 06:12:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:19 @base_main.py:47][0m 59295 total steps have happened
[32m[0514 06:12:19 @base_main.py:52][0m [avg_reward]: -184.9473488355767
[32m[0514 06:12:20 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:20 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:20 @base_trainer.py:216][0m Mean reward: -203.23572915558478
[32m[0514 06:12:20 @base_main.py:38][0m --------------- Iteration 60 ---------------
[32m[0514 06:12:20 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1631 mins
[32m[0514 06:12:20 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0034 mins
[32m[0514 06:12:20 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 06:12:20 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:20 @base_main.py:47][0m 60300 total steps have happened
[32m[0514 06:12:20 @base_main.py:52][0m [avg_reward]: -203.23572915558478
[32m[0514 06:12:20 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:20 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:20 @base_trainer.py:216][0m Mean reward: -176.25100524551837
[32m[0514 06:12:21 @base_main.py:38][0m --------------- Iteration 61 ---------------
[32m[0514 06:12:21 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1755 mins
[32m[0514 06:12:21 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0032 mins
[32m[0514 06:12:21 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 06:12:21 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:21 @base_main.py:47][0m 61305 total steps have happened
[32m[0514 06:12:21 @base_main.py:52][0m [avg_reward]: -176.25100524551837
[32m[0514 06:12:21 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:21 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:21 @base_trainer.py:216][0m Mean reward: -214.81367289376976
[32m[0514 06:12:22 @base_main.py:38][0m --------------- Iteration 62 ---------------
[32m[0514 06:12:22 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1878 mins
[32m[0514 06:12:22 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 06:12:22 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0514 06:12:22 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:22 @base_main.py:47][0m 62310 total steps have happened
[32m[0514 06:12:22 @base_main.py:52][0m [avg_reward]: -214.81367289376976
[32m[0514 06:12:22 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:22 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:22 @base_trainer.py:216][0m Mean reward: -230.28748930644025
[32m[0514 06:12:22 @base_main.py:38][0m --------------- Iteration 63 ---------------
[32m[0514 06:12:22 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2000 mins
[32m[0514 06:12:22 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 06:12:22 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0514 06:12:22 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:22 @base_main.py:47][0m 63315 total steps have happened
[32m[0514 06:12:22 @base_main.py:52][0m [avg_reward]: -230.28748930644025
[32m[0514 06:12:23 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:23 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:23 @base_trainer.py:216][0m Mean reward: -222.80822523793927
[32m[0514 06:12:23 @base_main.py:38][0m --------------- Iteration 64 ---------------
[32m[0514 06:12:23 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2126 mins
[32m[0514 06:12:23 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0032 mins
[32m[0514 06:12:23 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0514 06:12:23 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:12:23 @base_main.py:47][0m 64320 total steps have happened
[32m[0514 06:12:23 @base_main.py:52][0m [avg_reward]: -222.80822523793927
[32m[0514 06:12:23 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:23 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:23 @base_trainer.py:216][0m Mean reward: -214.40813898223195
[32m[0514 06:12:24 @base_main.py:38][0m --------------- Iteration 65 ---------------
[32m[0514 06:12:24 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2253 mins
[32m[0514 06:12:24 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0514 06:12:24 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0514 06:12:24 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:24 @base_main.py:47][0m 65325 total steps have happened
[32m[0514 06:12:24 @base_main.py:52][0m [avg_reward]: -214.40813898223195
[32m[0514 06:12:24 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:24 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:24 @base_trainer.py:216][0m Mean reward: -151.55155580665922
[32m[0514 06:12:25 @base_main.py:38][0m --------------- Iteration 66 ---------------
[32m[0514 06:12:25 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2382 mins
[32m[0514 06:12:25 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 06:12:25 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0514 06:12:25 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:12:25 @base_main.py:47][0m 66330 total steps have happened
[32m[0514 06:12:25 @base_main.py:52][0m [avg_reward]: -151.55155580665922
[32m[0514 06:12:25 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:25 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:25 @base_trainer.py:216][0m Mean reward: -152.39653561499222
[32m[0514 06:12:25 @base_main.py:38][0m --------------- Iteration 67 ---------------
[32m[0514 06:12:25 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2509 mins
[32m[0514 06:12:25 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 06:12:25 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0514 06:12:25 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:25 @base_main.py:47][0m 67335 total steps have happened
[32m[0514 06:12:25 @base_main.py:52][0m [avg_reward]: -152.39653561499222
[32m[0514 06:12:26 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:26 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:26 @base_trainer.py:216][0m Mean reward: -150.48951909022168
[32m[0514 06:12:26 @base_main.py:38][0m --------------- Iteration 68 ---------------
[32m[0514 06:12:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2634 mins
[32m[0514 06:12:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 06:12:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0514 06:12:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:26 @base_main.py:47][0m 68340 total steps have happened
[32m[0514 06:12:26 @base_main.py:52][0m [avg_reward]: -150.48951909022168
[32m[0514 06:12:26 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:26 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:26 @base_trainer.py:216][0m Mean reward: -174.13706539394596
[32m[0514 06:12:27 @base_main.py:38][0m --------------- Iteration 69 ---------------
[32m[0514 06:12:27 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2759 mins
[32m[0514 06:12:27 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0514 06:12:27 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 06:12:27 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:27 @base_main.py:47][0m 69345 total steps have happened
[32m[0514 06:12:27 @base_main.py:52][0m [avg_reward]: -174.13706539394596
[32m[0514 06:12:27 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:27 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:27 @base_trainer.py:216][0m Mean reward: -162.5813964023582
[32m[0514 06:12:28 @base_main.py:38][0m --------------- Iteration 70 ---------------
[32m[0514 06:12:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2882 mins
[32m[0514 06:12:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0514 06:12:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0514 06:12:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:28 @base_main.py:47][0m 70350 total steps have happened
[32m[0514 06:12:28 @base_main.py:52][0m [avg_reward]: -162.5813964023582
[32m[0514 06:12:28 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:28 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:28 @base_trainer.py:216][0m Mean reward: -163.75234346869368
[32m[0514 06:12:28 @base_main.py:38][0m --------------- Iteration 71 ---------------
[32m[0514 06:12:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3010 mins
[32m[0514 06:12:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0032 mins
[32m[0514 06:12:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 06:12:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:28 @base_main.py:47][0m 71355 total steps have happened
[32m[0514 06:12:28 @base_main.py:52][0m [avg_reward]: -163.75234346869368
[32m[0514 06:12:29 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:29 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:29 @base_trainer.py:216][0m Mean reward: -134.09642937553988
[32m[0514 06:12:29 @base_main.py:38][0m --------------- Iteration 72 ---------------
[32m[0514 06:12:29 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3135 mins
[32m[0514 06:12:29 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0514 06:12:29 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 06:12:29 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:12:29 @base_main.py:47][0m 72360 total steps have happened
[32m[0514 06:12:29 @base_main.py:52][0m [avg_reward]: -134.09642937553988
[32m[0514 06:12:29 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:29 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:29 @base_trainer.py:216][0m Mean reward: -175.03812925441926
[32m[0514 06:12:30 @base_main.py:38][0m --------------- Iteration 73 ---------------
[32m[0514 06:12:30 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3259 mins
[32m[0514 06:12:30 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 06:12:30 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0514 06:12:30 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:30 @base_main.py:47][0m 73365 total steps have happened
[32m[0514 06:12:30 @base_main.py:52][0m [avg_reward]: -175.03812925441926
[32m[0514 06:12:30 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:30 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:30 @base_trainer.py:216][0m Mean reward: -110.40154317906836
[32m[0514 06:12:31 @base_main.py:38][0m --------------- Iteration 74 ---------------
[32m[0514 06:12:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3383 mins
[32m[0514 06:12:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 06:12:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0514 06:12:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:31 @base_main.py:47][0m 74370 total steps have happened
[32m[0514 06:12:31 @base_main.py:52][0m [avg_reward]: -110.40154317906836
[32m[0514 06:12:31 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:31 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:31 @base_trainer.py:216][0m Mean reward: -104.10920292248161
[32m[0514 06:12:31 @base_main.py:38][0m --------------- Iteration 75 ---------------
[32m[0514 06:12:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3510 mins
[32m[0514 06:12:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 06:12:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0514 06:12:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:31 @base_main.py:47][0m 75375 total steps have happened
[32m[0514 06:12:31 @base_main.py:52][0m [avg_reward]: -104.10920292248161
[32m[0514 06:12:32 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:32 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:32 @base_trainer.py:216][0m Mean reward: -76.48586852869491
[32m[0514 06:12:32 @base_main.py:38][0m --------------- Iteration 76 ---------------
[32m[0514 06:12:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3625 mins
[32m[0514 06:12:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 06:12:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 06:12:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:32 @base_main.py:47][0m 76380 total steps have happened
[32m[0514 06:12:32 @base_main.py:52][0m [avg_reward]: -76.48586852869491
[32m[0514 06:12:32 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:32 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:32 @base_trainer.py:216][0m Mean reward: -121.22431892964248
[32m[0514 06:12:33 @base_main.py:38][0m --------------- Iteration 77 ---------------
[32m[0514 06:12:33 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3746 mins
[32m[0514 06:12:33 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 06:12:33 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 06:12:33 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:33 @base_main.py:47][0m 77385 total steps have happened
[32m[0514 06:12:33 @base_main.py:52][0m [avg_reward]: -121.22431892964248
[32m[0514 06:12:33 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:33 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:33 @base_trainer.py:216][0m Mean reward: -146.14480515536843
[32m[0514 06:12:34 @base_main.py:38][0m --------------- Iteration 78 ---------------
[32m[0514 06:12:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3863 mins
[32m[0514 06:12:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0514 06:12:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 06:12:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:34 @base_main.py:47][0m 78390 total steps have happened
[32m[0514 06:12:34 @base_main.py:52][0m [avg_reward]: -146.14480515536843
[32m[0514 06:12:34 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:34 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:34 @base_trainer.py:216][0m Mean reward: -118.73107321692233
[32m[0514 06:12:34 @base_main.py:38][0m --------------- Iteration 79 ---------------
[32m[0514 06:12:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3987 mins
[32m[0514 06:12:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 06:12:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0514 06:12:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:34 @base_main.py:47][0m 79395 total steps have happened
[32m[0514 06:12:34 @base_main.py:52][0m [avg_reward]: -118.73107321692233
[32m[0514 06:12:34 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:34 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:34 @base_trainer.py:216][0m Mean reward: -110.46526902384421
[32m[0514 06:12:35 @base_main.py:38][0m --------------- Iteration 80 ---------------
[32m[0514 06:12:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4112 mins
[32m[0514 06:12:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 06:12:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 06:12:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:35 @base_main.py:47][0m 80400 total steps have happened
[32m[0514 06:12:35 @base_main.py:52][0m [avg_reward]: -110.46526902384421
[32m[0514 06:12:35 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:35 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:35 @base_trainer.py:216][0m Mean reward: -107.60675095759761
[32m[0514 06:12:36 @base_main.py:38][0m --------------- Iteration 81 ---------------
[32m[0514 06:12:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4234 mins
[32m[0514 06:12:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 06:12:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0514 06:12:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:36 @base_main.py:47][0m 81405 total steps have happened
[32m[0514 06:12:36 @base_main.py:52][0m [avg_reward]: -107.60675095759761
[32m[0514 06:12:36 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:36 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:36 @base_trainer.py:216][0m Mean reward: -82.25753416625791
[32m[0514 06:12:36 @base_main.py:38][0m --------------- Iteration 82 ---------------
[32m[0514 06:12:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4359 mins
[32m[0514 06:12:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 06:12:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 06:12:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:12:36 @base_main.py:47][0m 82410 total steps have happened
[32m[0514 06:12:36 @base_main.py:52][0m [avg_reward]: -82.25753416625791
[32m[0514 06:12:37 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:37 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:37 @base_trainer.py:216][0m Mean reward: -56.53335440506707
[32m[0514 06:12:37 @base_main.py:38][0m --------------- Iteration 83 ---------------
[32m[0514 06:12:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4480 mins
[32m[0514 06:12:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 06:12:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 06:12:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:37 @base_main.py:47][0m 83415 total steps have happened
[32m[0514 06:12:37 @base_main.py:52][0m [avg_reward]: -56.53335440506707
[32m[0514 06:12:37 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:37 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:37 @base_trainer.py:216][0m Mean reward: -84.77560528868834
[32m[0514 06:12:38 @base_main.py:38][0m --------------- Iteration 84 ---------------
[32m[0514 06:12:38 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4599 mins
[32m[0514 06:12:38 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 06:12:38 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 06:12:38 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:38 @base_main.py:47][0m 84420 total steps have happened
[32m[0514 06:12:38 @base_main.py:52][0m [avg_reward]: -84.77560528868834
[32m[0514 06:12:38 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:38 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:38 @base_trainer.py:216][0m Mean reward: -88.34830987035895
[32m[0514 06:12:39 @base_main.py:38][0m --------------- Iteration 85 ---------------
[32m[0514 06:12:39 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4716 mins
[32m[0514 06:12:39 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 06:12:39 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0514 06:12:39 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:39 @base_main.py:47][0m 85425 total steps have happened
[32m[0514 06:12:39 @base_main.py:52][0m [avg_reward]: -88.34830987035895
[32m[0514 06:12:39 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:39 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:39 @base_trainer.py:216][0m Mean reward: -65.12685746567038
[32m[0514 06:12:39 @base_main.py:38][0m --------------- Iteration 86 ---------------
[32m[0514 06:12:39 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4838 mins
[32m[0514 06:12:39 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 06:12:39 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0514 06:12:39 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:39 @base_main.py:47][0m 86430 total steps have happened
[32m[0514 06:12:39 @base_main.py:52][0m [avg_reward]: -65.12685746567038
[32m[0514 06:12:40 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:40 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:40 @base_trainer.py:216][0m Mean reward: -63.824791116779
[32m[0514 06:12:40 @base_main.py:38][0m --------------- Iteration 87 ---------------
[32m[0514 06:12:40 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4963 mins
[32m[0514 06:12:40 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 06:12:40 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 06:12:40 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:40 @base_main.py:47][0m 87435 total steps have happened
[32m[0514 06:12:40 @base_main.py:52][0m [avg_reward]: -63.824791116779
[32m[0514 06:12:40 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:40 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:40 @base_trainer.py:216][0m Mean reward: -96.54966201279129
[32m[0514 06:12:41 @base_main.py:38][0m --------------- Iteration 88 ---------------
[32m[0514 06:12:41 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5083 mins
[32m[0514 06:12:41 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 06:12:41 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 06:12:41 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:41 @base_main.py:47][0m 88440 total steps have happened
[32m[0514 06:12:41 @base_main.py:52][0m [avg_reward]: -96.54966201279129
[32m[0514 06:12:41 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:41 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:41 @base_trainer.py:216][0m Mean reward: -59.212969948323256
[32m[0514 06:12:42 @base_main.py:38][0m --------------- Iteration 89 ---------------
[32m[0514 06:12:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5201 mins
[32m[0514 06:12:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 06:12:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0514 06:12:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:42 @base_main.py:47][0m 89445 total steps have happened
[32m[0514 06:12:42 @base_main.py:52][0m [avg_reward]: -59.212969948323256
[32m[0514 06:12:42 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:42 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:42 @base_trainer.py:216][0m Mean reward: -64.25002235333618
[32m[0514 06:12:42 @base_main.py:38][0m --------------- Iteration 90 ---------------
[32m[0514 06:12:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5325 mins
[32m[0514 06:12:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 06:12:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0514 06:12:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:42 @base_main.py:47][0m 90450 total steps have happened
[32m[0514 06:12:42 @base_main.py:52][0m [avg_reward]: -64.25002235333618
[32m[0514 06:12:42 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:42 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:42 @base_trainer.py:216][0m Mean reward: -68.10703344871372
[32m[0514 06:12:43 @base_main.py:38][0m --------------- Iteration 91 ---------------
[32m[0514 06:12:43 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5446 mins
[32m[0514 06:12:43 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 06:12:43 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0514 06:12:43 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:43 @base_main.py:47][0m 91455 total steps have happened
[32m[0514 06:12:43 @base_main.py:52][0m [avg_reward]: -68.10703344871372
[32m[0514 06:12:43 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:43 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:43 @base_trainer.py:216][0m Mean reward: -62.223518321474714
[32m[0514 06:12:44 @base_main.py:38][0m --------------- Iteration 92 ---------------
[32m[0514 06:12:44 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5569 mins
[32m[0514 06:12:44 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 06:12:44 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 06:12:44 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:44 @base_main.py:47][0m 92460 total steps have happened
[32m[0514 06:12:44 @base_main.py:52][0m [avg_reward]: -62.223518321474714
[32m[0514 06:12:44 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:44 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:44 @base_trainer.py:216][0m Mean reward: -68.68321093201105
[32m[0514 06:12:44 @base_main.py:38][0m --------------- Iteration 93 ---------------
[32m[0514 06:12:44 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5684 mins
[32m[0514 06:12:44 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 06:12:44 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 06:12:44 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:12:44 @base_main.py:47][0m 93465 total steps have happened
[32m[0514 06:12:44 @base_main.py:52][0m [avg_reward]: -68.68321093201105
[32m[0514 06:12:45 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:45 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:45 @base_trainer.py:216][0m Mean reward: -73.85572212754501
[32m[0514 06:12:45 @base_main.py:38][0m --------------- Iteration 94 ---------------
[32m[0514 06:12:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5808 mins
[32m[0514 06:12:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 06:12:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 06:12:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:45 @base_main.py:47][0m 94470 total steps have happened
[32m[0514 06:12:45 @base_main.py:52][0m [avg_reward]: -73.85572212754501
[32m[0514 06:12:45 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:45 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:45 @base_trainer.py:216][0m Mean reward: -59.01980307242722
[32m[0514 06:12:46 @base_main.py:38][0m --------------- Iteration 95 ---------------
[32m[0514 06:12:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5928 mins
[32m[0514 06:12:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 06:12:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0514 06:12:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:46 @base_main.py:47][0m 95475 total steps have happened
[32m[0514 06:12:46 @base_main.py:52][0m [avg_reward]: -59.01980307242722
[32m[0514 06:12:46 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:46 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:46 @base_trainer.py:216][0m Mean reward: -59.66212540585015
[32m[0514 06:12:47 @base_main.py:38][0m --------------- Iteration 96 ---------------
[32m[0514 06:12:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6050 mins
[32m[0514 06:12:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0514 06:12:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0514 06:12:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:47 @base_main.py:47][0m 96480 total steps have happened
[32m[0514 06:12:47 @base_main.py:52][0m [avg_reward]: -59.66212540585015
[32m[0514 06:12:47 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:47 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:47 @base_trainer.py:216][0m Mean reward: -56.9594959936887
[32m[0514 06:12:47 @base_main.py:38][0m --------------- Iteration 97 ---------------
[32m[0514 06:12:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6179 mins
[32m[0514 06:12:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 06:12:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 06:12:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:47 @base_main.py:47][0m 97485 total steps have happened
[32m[0514 06:12:47 @base_main.py:52][0m [avg_reward]: -56.9594959936887
[32m[0514 06:12:48 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:48 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:48 @base_trainer.py:216][0m Mean reward: -44.889310169579055
[32m[0514 06:12:48 @base_main.py:38][0m --------------- Iteration 98 ---------------
[32m[0514 06:12:48 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6299 mins
[32m[0514 06:12:48 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 06:12:48 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 06:12:48 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:48 @base_main.py:47][0m 98490 total steps have happened
[32m[0514 06:12:48 @base_main.py:52][0m [avg_reward]: -44.889310169579055
[32m[0514 06:12:48 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:48 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:48 @base_trainer.py:216][0m Mean reward: -51.75406842673019
[32m[0514 06:12:49 @base_main.py:38][0m --------------- Iteration 99 ---------------
[32m[0514 06:12:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6419 mins
[32m[0514 06:12:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 06:12:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0514 06:12:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:49 @base_main.py:47][0m 99495 total steps have happened
[32m[0514 06:12:49 @base_main.py:52][0m [avg_reward]: -51.75406842673019
[32m[0514 06:12:49 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:49 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:49 @base_trainer.py:216][0m Mean reward: -49.71623490598699
[32m[0514 06:12:50 @base_main.py:38][0m --------------- Iteration 100 ---------------
[32m[0514 06:12:50 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6543 mins
[32m[0514 06:12:50 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 06:12:50 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0514 06:12:50 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:50 @base_main.py:47][0m 100500 total steps have happened
[32m[0514 06:12:50 @base_main.py:52][0m [avg_reward]: -49.71623490598699
[32m[0514 06:12:50 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:50 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:50 @base_trainer.py:216][0m Mean reward: -44.73537835215258
[32m[0514 06:12:50 @base_main.py:38][0m --------------- Iteration 101 ---------------
[32m[0514 06:12:50 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6666 mins
[32m[0514 06:12:50 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 06:12:50 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0514 06:12:50 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:50 @base_main.py:47][0m 101505 total steps have happened
[32m[0514 06:12:50 @base_main.py:52][0m [avg_reward]: -44.73537835215258
[32m[0514 06:12:51 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:51 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:51 @base_trainer.py:216][0m Mean reward: -59.838708215953226
[32m[0514 06:12:51 @base_main.py:38][0m --------------- Iteration 102 ---------------
[32m[0514 06:12:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6796 mins
[32m[0514 06:12:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0514 06:12:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0514 06:12:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:51 @base_main.py:47][0m 102510 total steps have happened
[32m[0514 06:12:51 @base_main.py:52][0m [avg_reward]: -59.838708215953226
[32m[0514 06:12:51 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:51 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:51 @base_trainer.py:216][0m Mean reward: -57.12727680144722
[32m[0514 06:12:52 @base_main.py:38][0m --------------- Iteration 103 ---------------
[32m[0514 06:12:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6922 mins
[32m[0514 06:12:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 06:12:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0514 06:12:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:52 @base_main.py:47][0m 103515 total steps have happened
[32m[0514 06:12:52 @base_main.py:52][0m [avg_reward]: -57.12727680144722
[32m[0514 06:12:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:52 @base_trainer.py:216][0m Mean reward: -45.328422350844384
[32m[0514 06:12:53 @base_main.py:38][0m --------------- Iteration 104 ---------------
[32m[0514 06:12:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7048 mins
[32m[0514 06:12:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 06:12:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 06:12:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:53 @base_main.py:47][0m 104520 total steps have happened
[32m[0514 06:12:53 @base_main.py:52][0m [avg_reward]: -45.328422350844384
[32m[0514 06:12:53 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:53 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:53 @base_trainer.py:216][0m Mean reward: -43.36325521538991
[32m[0514 06:12:53 @base_main.py:38][0m --------------- Iteration 105 ---------------
[32m[0514 06:12:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7169 mins
[32m[0514 06:12:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0035 mins
[32m[0514 06:12:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 06:12:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:53 @base_main.py:47][0m 105525 total steps have happened
[32m[0514 06:12:53 @base_main.py:52][0m [avg_reward]: -43.36325521538991
[32m[0514 06:12:54 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:54 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:54 @base_trainer.py:216][0m Mean reward: -40.943421309090674
[32m[0514 06:12:54 @base_main.py:38][0m --------------- Iteration 106 ---------------
[32m[0514 06:12:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7293 mins
[32m[0514 06:12:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 06:12:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 06:12:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:54 @base_main.py:47][0m 106530 total steps have happened
[32m[0514 06:12:54 @base_main.py:52][0m [avg_reward]: -40.943421309090674
[32m[0514 06:12:54 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:54 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:54 @base_trainer.py:216][0m Mean reward: -40.64094099993464
[32m[0514 06:12:55 @base_main.py:38][0m --------------- Iteration 107 ---------------
[32m[0514 06:12:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7409 mins
[32m[0514 06:12:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 06:12:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 06:12:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:55 @base_main.py:47][0m 107535 total steps have happened
[32m[0514 06:12:55 @base_main.py:52][0m [avg_reward]: -40.64094099993464
[32m[0514 06:12:55 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:55 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:55 @base_trainer.py:216][0m Mean reward: -40.78286422032453
[32m[0514 06:12:56 @base_main.py:38][0m --------------- Iteration 108 ---------------
[32m[0514 06:12:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7530 mins
[32m[0514 06:12:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 06:12:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0514 06:12:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:12:56 @base_main.py:47][0m 108540 total steps have happened
[32m[0514 06:12:56 @base_main.py:52][0m [avg_reward]: -40.78286422032453
[32m[0514 06:12:56 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:56 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:56 @base_trainer.py:216][0m Mean reward: -44.175637330495896
[32m[0514 06:12:56 @base_main.py:38][0m --------------- Iteration 109 ---------------
[32m[0514 06:12:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7653 mins
[32m[0514 06:12:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 06:12:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 06:12:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:56 @base_main.py:47][0m 109545 total steps have happened
[32m[0514 06:12:56 @base_main.py:52][0m [avg_reward]: -44.175637330495896
[32m[0514 06:12:56 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:56 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:56 @base_trainer.py:216][0m Mean reward: -43.35746726136939
[32m[0514 06:12:57 @base_main.py:38][0m --------------- Iteration 110 ---------------
[32m[0514 06:12:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7769 mins
[32m[0514 06:12:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 06:12:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0514 06:12:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:12:57 @base_main.py:47][0m 110550 total steps have happened
[32m[0514 06:12:57 @base_main.py:52][0m [avg_reward]: -43.35746726136939
[32m[0514 06:12:57 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:57 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:57 @base_trainer.py:216][0m Mean reward: -38.76758271731934
[32m[0514 06:12:58 @base_main.py:38][0m --------------- Iteration 111 ---------------
[32m[0514 06:12:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7891 mins
[32m[0514 06:12:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 06:12:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 06:12:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:58 @base_main.py:47][0m 111555 total steps have happened
[32m[0514 06:12:58 @base_main.py:52][0m [avg_reward]: -38.76758271731934
[32m[0514 06:12:58 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:58 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:58 @base_trainer.py:216][0m Mean reward: -44.92255642426865
[32m[0514 06:12:58 @base_main.py:38][0m --------------- Iteration 112 ---------------
[32m[0514 06:12:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8011 mins
[32m[0514 06:12:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 06:12:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0514 06:12:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:58 @base_main.py:47][0m 112560 total steps have happened
[32m[0514 06:12:58 @base_main.py:52][0m [avg_reward]: -44.92255642426865
[32m[0514 06:12:59 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:59 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:59 @base_trainer.py:216][0m Mean reward: -34.33956274089501
[32m[0514 06:12:59 @base_main.py:38][0m --------------- Iteration 113 ---------------
[32m[0514 06:12:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8132 mins
[32m[0514 06:12:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 06:12:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0514 06:12:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:12:59 @base_main.py:47][0m 113565 total steps have happened
[32m[0514 06:12:59 @base_main.py:52][0m [avg_reward]: -34.33956274089501
[32m[0514 06:12:59 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:12:59 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:12:59 @base_trainer.py:216][0m Mean reward: -37.44224747490597
[32m[0514 06:13:00 @base_main.py:38][0m --------------- Iteration 114 ---------------
[32m[0514 06:13:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8255 mins
[32m[0514 06:13:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 06:13:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0514 06:13:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:00 @base_main.py:47][0m 114570 total steps have happened
[32m[0514 06:13:00 @base_main.py:52][0m [avg_reward]: -37.44224747490597
[32m[0514 06:13:00 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:00 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:00 @base_trainer.py:216][0m Mean reward: -35.755511236931866
[32m[0514 06:13:01 @base_main.py:38][0m --------------- Iteration 115 ---------------
[32m[0514 06:13:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8384 mins
[32m[0514 06:13:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 06:13:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0514 06:13:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:01 @base_main.py:47][0m 115575 total steps have happened
[32m[0514 06:13:01 @base_main.py:52][0m [avg_reward]: -35.755511236931866
[32m[0514 06:13:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:01 @base_trainer.py:216][0m Mean reward: -35.794304776928314
[32m[0514 06:13:01 @base_main.py:38][0m --------------- Iteration 116 ---------------
[32m[0514 06:13:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8506 mins
[32m[0514 06:13:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 06:13:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 06:13:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:01 @base_main.py:47][0m 116580 total steps have happened
[32m[0514 06:13:01 @base_main.py:52][0m [avg_reward]: -35.794304776928314
[32m[0514 06:13:02 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:02 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:02 @base_trainer.py:216][0m Mean reward: -33.3838967926534
[32m[0514 06:13:02 @base_main.py:38][0m --------------- Iteration 117 ---------------
[32m[0514 06:13:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8628 mins
[32m[0514 06:13:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 06:13:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0514 06:13:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0003 mins
[32m[0514 06:13:02 @base_main.py:47][0m 117585 total steps have happened
[32m[0514 06:13:02 @base_main.py:52][0m [avg_reward]: -33.3838967926534
[32m[0514 06:13:02 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:02 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:02 @base_trainer.py:216][0m Mean reward: -34.00635584100144
[32m[0514 06:13:03 @base_main.py:38][0m --------------- Iteration 118 ---------------
[32m[0514 06:13:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8745 mins
[32m[0514 06:13:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 06:13:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 06:13:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:13:03 @base_main.py:47][0m 118590 total steps have happened
[32m[0514 06:13:03 @base_main.py:52][0m [avg_reward]: -34.00635584100144
[32m[0514 06:13:03 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:03 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:03 @base_trainer.py:216][0m Mean reward: -37.66760537972623
[32m[0514 06:13:04 @base_main.py:38][0m --------------- Iteration 119 ---------------
[32m[0514 06:13:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8868 mins
[32m[0514 06:13:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 06:13:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 06:13:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:04 @base_main.py:47][0m 119595 total steps have happened
[32m[0514 06:13:04 @base_main.py:52][0m [avg_reward]: -37.66760537972623
[32m[0514 06:13:04 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:04 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:04 @base_trainer.py:216][0m Mean reward: -30.308412598647283
[32m[0514 06:13:04 @base_main.py:38][0m --------------- Iteration 120 ---------------
[32m[0514 06:13:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8986 mins
[32m[0514 06:13:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 06:13:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0514 06:13:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:04 @base_main.py:47][0m 120600 total steps have happened
[32m[0514 06:13:04 @base_main.py:52][0m [avg_reward]: -30.308412598647283
[32m[0514 06:13:04 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:04 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:04 @base_trainer.py:216][0m Mean reward: -45.4819591530089
[32m[0514 06:13:05 @base_main.py:38][0m --------------- Iteration 121 ---------------
[32m[0514 06:13:05 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9116 mins
[32m[0514 06:13:05 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 06:13:05 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 06:13:05 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:13:05 @base_main.py:47][0m 121605 total steps have happened
[32m[0514 06:13:05 @base_main.py:52][0m [avg_reward]: -45.4819591530089
[32m[0514 06:13:05 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:05 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:05 @base_trainer.py:216][0m Mean reward: -60.43866308682643
[32m[0514 06:13:06 @base_main.py:38][0m --------------- Iteration 122 ---------------
[32m[0514 06:13:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9239 mins
[32m[0514 06:13:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0032 mins
[32m[0514 06:13:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 06:13:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:06 @base_main.py:47][0m 122610 total steps have happened
[32m[0514 06:13:06 @base_main.py:52][0m [avg_reward]: -60.43866308682643
[32m[0514 06:13:06 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:06 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:06 @base_trainer.py:216][0m Mean reward: -35.206517410016566
[32m[0514 06:13:06 @base_main.py:38][0m --------------- Iteration 123 ---------------
[32m[0514 06:13:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9363 mins
[32m[0514 06:13:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 06:13:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 06:13:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:06 @base_main.py:47][0m 123615 total steps have happened
[32m[0514 06:13:06 @base_main.py:52][0m [avg_reward]: -35.206517410016566
[32m[0514 06:13:07 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:07 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:07 @base_trainer.py:216][0m Mean reward: -35.39194497854954
[32m[0514 06:13:07 @base_main.py:38][0m --------------- Iteration 124 ---------------
[32m[0514 06:13:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9481 mins
[32m[0514 06:13:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 06:13:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0514 06:13:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:07 @base_main.py:47][0m 124620 total steps have happened
[32m[0514 06:13:07 @base_main.py:52][0m [avg_reward]: -35.39194497854954
[32m[0514 06:13:07 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:07 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:07 @base_trainer.py:216][0m Mean reward: -32.25747838739823
[32m[0514 06:13:08 @base_main.py:38][0m --------------- Iteration 125 ---------------
[32m[0514 06:13:08 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9606 mins
[32m[0514 06:13:08 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 06:13:08 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 06:13:08 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:08 @base_main.py:47][0m 125625 total steps have happened
[32m[0514 06:13:08 @base_main.py:52][0m [avg_reward]: -32.25747838739823
[32m[0514 06:13:08 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:08 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:08 @base_trainer.py:216][0m Mean reward: -31.5747014607488
[32m[0514 06:13:09 @base_main.py:38][0m --------------- Iteration 126 ---------------
[32m[0514 06:13:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9726 mins
[32m[0514 06:13:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 06:13:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0514 06:13:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:09 @base_main.py:47][0m 126630 total steps have happened
[32m[0514 06:13:09 @base_main.py:52][0m [avg_reward]: -31.5747014607488
[32m[0514 06:13:09 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:09 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:09 @base_trainer.py:216][0m Mean reward: -32.546024740150884
[32m[0514 06:13:09 @base_main.py:38][0m --------------- Iteration 127 ---------------
[32m[0514 06:13:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9849 mins
[32m[0514 06:13:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 06:13:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0514 06:13:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:09 @base_main.py:47][0m 127635 total steps have happened
[32m[0514 06:13:09 @base_main.py:52][0m [avg_reward]: -32.546024740150884
[32m[0514 06:13:10 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:10 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:10 @base_trainer.py:216][0m Mean reward: -31.97107262708507
[32m[0514 06:13:10 @base_main.py:38][0m --------------- Iteration 128 ---------------
[32m[0514 06:13:10 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9974 mins
[32m[0514 06:13:10 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 06:13:10 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 06:13:10 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:10 @base_main.py:47][0m 128640 total steps have happened
[32m[0514 06:13:10 @base_main.py:52][0m [avg_reward]: -31.97107262708507
[32m[0514 06:13:10 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:10 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:10 @base_trainer.py:216][0m Mean reward: -30.56872272360497
[32m[0514 06:13:11 @base_main.py:38][0m --------------- Iteration 129 ---------------
[32m[0514 06:13:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0096 mins
[32m[0514 06:13:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 06:13:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 06:13:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:11 @base_main.py:47][0m 129645 total steps have happened
[32m[0514 06:13:11 @base_main.py:52][0m [avg_reward]: -30.56872272360497
[32m[0514 06:13:11 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:11 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:11 @base_trainer.py:216][0m Mean reward: -32.113510453258534
[32m[0514 06:13:12 @base_main.py:38][0m --------------- Iteration 130 ---------------
[32m[0514 06:13:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0213 mins
[32m[0514 06:13:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0032 mins
[32m[0514 06:13:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 06:13:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:12 @base_main.py:47][0m 130650 total steps have happened
[32m[0514 06:13:12 @base_main.py:52][0m [avg_reward]: -32.113510453258534
[32m[0514 06:13:12 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:12 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:12 @base_trainer.py:216][0m Mean reward: -31.353828310542877
[32m[0514 06:13:12 @base_main.py:38][0m --------------- Iteration 131 ---------------
[32m[0514 06:13:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0339 mins
[32m[0514 06:13:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 06:13:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 06:13:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:12 @base_main.py:47][0m 131655 total steps have happened
[32m[0514 06:13:12 @base_main.py:52][0m [avg_reward]: -31.353828310542877
[32m[0514 06:13:13 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:13 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:13 @base_trainer.py:216][0m Mean reward: -32.14781149693174
[32m[0514 06:13:13 @base_main.py:38][0m --------------- Iteration 132 ---------------
[32m[0514 06:13:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0457 mins
[32m[0514 06:13:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 06:13:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 06:13:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:13:13 @base_main.py:47][0m 132660 total steps have happened
[32m[0514 06:13:13 @base_main.py:52][0m [avg_reward]: -32.14781149693174
[32m[0514 06:13:13 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:13 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:13 @base_trainer.py:216][0m Mean reward: -31.98186960161139
[32m[0514 06:13:14 @base_main.py:38][0m --------------- Iteration 133 ---------------
[32m[0514 06:13:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0577 mins
[32m[0514 06:13:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 06:13:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0514 06:13:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:14 @base_main.py:47][0m 133665 total steps have happened
[32m[0514 06:13:14 @base_main.py:52][0m [avg_reward]: -31.98186960161139
[32m[0514 06:13:14 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:14 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:14 @base_trainer.py:216][0m Mean reward: -70.8497292186045
[32m[0514 06:13:15 @base_main.py:38][0m --------------- Iteration 134 ---------------
[32m[0514 06:13:15 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0692 mins
[32m[0514 06:13:15 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 06:13:15 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0514 06:13:15 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:15 @base_main.py:47][0m 134670 total steps have happened
[32m[0514 06:13:15 @base_main.py:52][0m [avg_reward]: -70.8497292186045
[32m[0514 06:13:15 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:15 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:15 @base_trainer.py:216][0m Mean reward: -32.88894441539673
[32m[0514 06:13:15 @base_main.py:38][0m --------------- Iteration 135 ---------------
[32m[0514 06:13:15 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0819 mins
[32m[0514 06:13:15 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 06:13:15 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 06:13:15 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:15 @base_main.py:47][0m 135675 total steps have happened
[32m[0514 06:13:15 @base_main.py:52][0m [avg_reward]: -32.88894441539673
[32m[0514 06:13:15 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:15 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:15 @base_trainer.py:216][0m Mean reward: -57.21699379836114
[32m[0514 06:13:16 @base_main.py:38][0m --------------- Iteration 136 ---------------
[32m[0514 06:13:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0938 mins
[32m[0514 06:13:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0032 mins
[32m[0514 06:13:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0514 06:13:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:16 @base_main.py:47][0m 136680 total steps have happened
[32m[0514 06:13:16 @base_main.py:52][0m [avg_reward]: -57.21699379836114
[32m[0514 06:13:16 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:16 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:16 @base_trainer.py:216][0m Mean reward: -37.747046827496284
[32m[0514 06:13:17 @base_main.py:38][0m --------------- Iteration 137 ---------------
[32m[0514 06:13:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1065 mins
[32m[0514 06:13:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 06:13:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 06:13:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:17 @base_main.py:47][0m 137685 total steps have happened
[32m[0514 06:13:17 @base_main.py:52][0m [avg_reward]: -37.747046827496284
[32m[0514 06:13:17 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:17 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:17 @base_trainer.py:216][0m Mean reward: -29.484812799888893
[32m[0514 06:13:17 @base_main.py:38][0m --------------- Iteration 138 ---------------
[32m[0514 06:13:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1187 mins
[32m[0514 06:13:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 06:13:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0514 06:13:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:17 @base_main.py:47][0m 138690 total steps have happened
[32m[0514 06:13:17 @base_main.py:52][0m [avg_reward]: -29.484812799888893
[32m[0514 06:13:18 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:18 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:18 @base_trainer.py:216][0m Mean reward: -33.24388967881416
[32m[0514 06:13:18 @base_main.py:38][0m --------------- Iteration 139 ---------------
[32m[0514 06:13:18 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1303 mins
[32m[0514 06:13:18 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 06:13:18 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 06:13:18 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:18 @base_main.py:47][0m 139695 total steps have happened
[32m[0514 06:13:18 @base_main.py:52][0m [avg_reward]: -33.24388967881416
[32m[0514 06:13:18 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:18 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:18 @base_trainer.py:216][0m Mean reward: -31.69381727386456
[32m[0514 06:13:19 @base_main.py:38][0m --------------- Iteration 140 ---------------
[32m[0514 06:13:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1421 mins
[32m[0514 06:13:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 06:13:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 06:13:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:13:19 @base_main.py:47][0m 140700 total steps have happened
[32m[0514 06:13:19 @base_main.py:52][0m [avg_reward]: -31.69381727386456
[32m[0514 06:13:19 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:19 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:19 @base_trainer.py:216][0m Mean reward: -33.41654798247863
[32m[0514 06:13:20 @base_main.py:38][0m --------------- Iteration 141 ---------------
[32m[0514 06:13:20 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1539 mins
[32m[0514 06:13:20 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0034 mins
[32m[0514 06:13:20 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 06:13:20 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:20 @base_main.py:47][0m 141705 total steps have happened
[32m[0514 06:13:20 @base_main.py:52][0m [avg_reward]: -33.41654798247863
[32m[0514 06:13:20 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:20 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:20 @base_trainer.py:216][0m Mean reward: -30.308759161441884
[32m[0514 06:13:20 @base_main.py:38][0m --------------- Iteration 142 ---------------
[32m[0514 06:13:20 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1662 mins
[32m[0514 06:13:20 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 06:13:20 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 06:13:20 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:20 @base_main.py:47][0m 142710 total steps have happened
[32m[0514 06:13:20 @base_main.py:52][0m [avg_reward]: -30.308759161441884
[32m[0514 06:13:20 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:20 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:20 @base_trainer.py:216][0m Mean reward: -32.89638951483351
[32m[0514 06:13:21 @base_main.py:38][0m --------------- Iteration 143 ---------------
[32m[0514 06:13:21 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1781 mins
[32m[0514 06:13:21 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 06:13:21 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0514 06:13:21 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:21 @base_main.py:47][0m 143715 total steps have happened
[32m[0514 06:13:21 @base_main.py:52][0m [avg_reward]: -32.89638951483351
[32m[0514 06:13:21 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:21 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:21 @base_trainer.py:216][0m Mean reward: -29.262693183158735
[32m[0514 06:13:22 @base_main.py:38][0m --------------- Iteration 144 ---------------
[32m[0514 06:13:22 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1902 mins
[32m[0514 06:13:22 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 06:13:22 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 06:13:22 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:22 @base_main.py:47][0m 144720 total steps have happened
[32m[0514 06:13:22 @base_main.py:52][0m [avg_reward]: -29.262693183158735
[32m[0514 06:13:22 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:22 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:22 @base_trainer.py:216][0m Mean reward: -33.47034615808731
[32m[0514 06:13:22 @base_main.py:38][0m --------------- Iteration 145 ---------------
[32m[0514 06:13:22 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2019 mins
[32m[0514 06:13:22 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 06:13:22 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 06:13:22 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:13:22 @base_main.py:47][0m 145725 total steps have happened
[32m[0514 06:13:22 @base_main.py:52][0m [avg_reward]: -33.47034615808731
[32m[0514 06:13:23 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:23 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:23 @base_trainer.py:216][0m Mean reward: -39.566036869033326
[32m[0514 06:13:23 @base_main.py:38][0m --------------- Iteration 146 ---------------
[32m[0514 06:13:23 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2138 mins
[32m[0514 06:13:23 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0514 06:13:23 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0514 06:13:23 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:23 @base_main.py:47][0m 146730 total steps have happened
[32m[0514 06:13:23 @base_main.py:52][0m [avg_reward]: -39.566036869033326
[32m[0514 06:13:23 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:23 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:23 @base_trainer.py:216][0m Mean reward: -44.90937931778427
[32m[0514 06:13:24 @base_main.py:38][0m --------------- Iteration 147 ---------------
[32m[0514 06:13:24 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2270 mins
[32m[0514 06:13:24 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0514 06:13:24 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0514 06:13:24 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:24 @base_main.py:47][0m 147735 total steps have happened
[32m[0514 06:13:24 @base_main.py:52][0m [avg_reward]: -44.90937931778427
[32m[0514 06:13:24 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:24 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:24 @base_trainer.py:216][0m Mean reward: -43.10546324710658
[32m[0514 06:13:25 @base_main.py:38][0m --------------- Iteration 148 ---------------
[32m[0514 06:13:25 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2395 mins
[32m[0514 06:13:25 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 06:13:25 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0514 06:13:25 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:25 @base_main.py:47][0m 148740 total steps have happened
[32m[0514 06:13:25 @base_main.py:52][0m [avg_reward]: -43.10546324710658
[32m[0514 06:13:25 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:25 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:25 @base_trainer.py:216][0m Mean reward: -31.424776901124783
[32m[0514 06:13:25 @base_main.py:38][0m --------------- Iteration 149 ---------------
[32m[0514 06:13:25 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2518 mins
[32m[0514 06:13:25 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 06:13:25 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0514 06:13:25 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:13:25 @base_main.py:47][0m 149745 total steps have happened
[32m[0514 06:13:25 @base_main.py:52][0m [avg_reward]: -31.424776901124783
[32m[0514 06:13:26 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:26 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:26 @base_trainer.py:216][0m Mean reward: -30.99341083347996
[32m[0514 06:13:26 @base_main.py:38][0m --------------- Iteration 150 ---------------
[32m[0514 06:13:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2646 mins
[32m[0514 06:13:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 06:13:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 06:13:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:26 @base_main.py:47][0m 150750 total steps have happened
[32m[0514 06:13:26 @base_main.py:52][0m [avg_reward]: -30.99341083347996
[32m[0514 06:13:26 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:26 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:26 @base_trainer.py:216][0m Mean reward: -31.392915265181536
[32m[0514 06:13:27 @base_main.py:38][0m --------------- Iteration 151 ---------------
[32m[0514 06:13:27 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2765 mins
[32m[0514 06:13:27 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 06:13:27 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 06:13:27 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:27 @base_main.py:47][0m 151755 total steps have happened
[32m[0514 06:13:27 @base_main.py:52][0m [avg_reward]: -31.392915265181536
[32m[0514 06:13:27 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:27 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:27 @base_trainer.py:216][0m Mean reward: -30.987230469974634
[32m[0514 06:13:28 @base_main.py:38][0m --------------- Iteration 152 ---------------
[32m[0514 06:13:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2885 mins
[32m[0514 06:13:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 06:13:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 06:13:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:28 @base_main.py:47][0m 152760 total steps have happened
[32m[0514 06:13:28 @base_main.py:52][0m [avg_reward]: -30.987230469974634
[32m[0514 06:13:28 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:28 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:28 @base_trainer.py:216][0m Mean reward: -30.878228082107903
[32m[0514 06:13:28 @base_main.py:38][0m --------------- Iteration 153 ---------------
[32m[0514 06:13:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3004 mins
[32m[0514 06:13:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 06:13:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 06:13:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:28 @base_main.py:47][0m 153765 total steps have happened
[32m[0514 06:13:28 @base_main.py:52][0m [avg_reward]: -30.878228082107903
[32m[0514 06:13:29 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:29 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:29 @base_trainer.py:216][0m Mean reward: -32.35589369438924
[32m[0514 06:13:29 @base_main.py:38][0m --------------- Iteration 154 ---------------
[32m[0514 06:13:29 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3123 mins
[32m[0514 06:13:29 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0514 06:13:29 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0514 06:13:29 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:29 @base_main.py:47][0m 154770 total steps have happened
[32m[0514 06:13:29 @base_main.py:52][0m [avg_reward]: -32.35589369438924
[32m[0514 06:13:29 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:29 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:29 @base_trainer.py:216][0m Mean reward: -32.44491176340035
[32m[0514 06:13:30 @base_main.py:38][0m --------------- Iteration 155 ---------------
[32m[0514 06:13:30 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3248 mins
[32m[0514 06:13:30 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 06:13:30 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0514 06:13:30 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:30 @base_main.py:47][0m 155775 total steps have happened
[32m[0514 06:13:30 @base_main.py:52][0m [avg_reward]: -32.44491176340035
[32m[0514 06:13:30 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:30 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:30 @base_trainer.py:216][0m Mean reward: -31.835685794394273
[32m[0514 06:13:31 @base_main.py:38][0m --------------- Iteration 156 ---------------
[32m[0514 06:13:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3375 mins
[32m[0514 06:13:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 06:13:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 06:13:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:31 @base_main.py:47][0m 156780 total steps have happened
[32m[0514 06:13:31 @base_main.py:52][0m [avg_reward]: -31.835685794394273
[32m[0514 06:13:31 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:31 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:31 @base_trainer.py:216][0m Mean reward: -31.522797431560253
[32m[0514 06:13:31 @base_main.py:38][0m --------------- Iteration 157 ---------------
[32m[0514 06:13:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3496 mins
[32m[0514 06:13:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 06:13:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 06:13:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:31 @base_main.py:47][0m 157785 total steps have happened
[32m[0514 06:13:31 @base_main.py:52][0m [avg_reward]: -31.522797431560253
[32m[0514 06:13:31 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:31 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:31 @base_trainer.py:216][0m Mean reward: -31.388778582039315
[32m[0514 06:13:32 @base_main.py:38][0m --------------- Iteration 158 ---------------
[32m[0514 06:13:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3617 mins
[32m[0514 06:13:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 06:13:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 06:13:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:32 @base_main.py:47][0m 158790 total steps have happened
[32m[0514 06:13:32 @base_main.py:52][0m [avg_reward]: -31.388778582039315
[32m[0514 06:13:32 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:32 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:32 @base_trainer.py:216][0m Mean reward: -31.43419714681274
[32m[0514 06:13:33 @base_main.py:38][0m --------------- Iteration 159 ---------------
[32m[0514 06:13:33 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3735 mins
[32m[0514 06:13:33 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 06:13:33 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 06:13:33 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:33 @base_main.py:47][0m 159795 total steps have happened
[32m[0514 06:13:33 @base_main.py:52][0m [avg_reward]: -31.43419714681274
[32m[0514 06:13:33 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:33 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:33 @base_trainer.py:216][0m Mean reward: -33.1571501528688
[32m[0514 06:13:33 @base_main.py:38][0m --------------- Iteration 160 ---------------
[32m[0514 06:13:33 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3857 mins
[32m[0514 06:13:33 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 06:13:33 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 06:13:33 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:13:33 @base_main.py:47][0m 160800 total steps have happened
[32m[0514 06:13:33 @base_main.py:52][0m [avg_reward]: -33.1571501528688
[32m[0514 06:13:34 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:34 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:34 @base_trainer.py:216][0m Mean reward: -32.18252370925379
[32m[0514 06:13:34 @base_main.py:38][0m --------------- Iteration 161 ---------------
[32m[0514 06:13:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3975 mins
[32m[0514 06:13:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 06:13:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0514 06:13:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:34 @base_main.py:47][0m 161805 total steps have happened
[32m[0514 06:13:34 @base_main.py:52][0m [avg_reward]: -32.18252370925379
[32m[0514 06:13:34 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:34 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:34 @base_trainer.py:216][0m Mean reward: -33.744242626652785
[32m[0514 06:13:35 @base_main.py:38][0m --------------- Iteration 162 ---------------
[32m[0514 06:13:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4100 mins
[32m[0514 06:13:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 06:13:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0514 06:13:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:35 @base_main.py:47][0m 162810 total steps have happened
[32m[0514 06:13:35 @base_main.py:52][0m [avg_reward]: -33.744242626652785
[32m[0514 06:13:35 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:35 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:35 @base_trainer.py:216][0m Mean reward: -33.47912264330266
[32m[0514 06:13:36 @base_main.py:38][0m --------------- Iteration 163 ---------------
[32m[0514 06:13:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4221 mins
[32m[0514 06:13:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 06:13:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 06:13:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:36 @base_main.py:47][0m 163815 total steps have happened
[32m[0514 06:13:36 @base_main.py:52][0m [avg_reward]: -33.47912264330266
[32m[0514 06:13:36 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:36 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:36 @base_trainer.py:216][0m Mean reward: -34.74612144916026
[32m[0514 06:13:36 @base_main.py:38][0m --------------- Iteration 164 ---------------
[32m[0514 06:13:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4337 mins
[32m[0514 06:13:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0514 06:13:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 06:13:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:13:36 @base_main.py:47][0m 164820 total steps have happened
[32m[0514 06:13:36 @base_main.py:52][0m [avg_reward]: -34.74612144916026
[32m[0514 06:13:37 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:37 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:37 @base_trainer.py:216][0m Mean reward: -32.548971456038224
[32m[0514 06:13:37 @base_main.py:38][0m --------------- Iteration 165 ---------------
[32m[0514 06:13:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4461 mins
[32m[0514 06:13:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 06:13:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0514 06:13:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:37 @base_main.py:47][0m 165825 total steps have happened
[32m[0514 06:13:37 @base_main.py:52][0m [avg_reward]: -32.548971456038224
[32m[0514 06:13:37 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:37 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:37 @base_trainer.py:216][0m Mean reward: -32.52487656180271
[32m[0514 06:13:38 @base_main.py:38][0m --------------- Iteration 166 ---------------
[32m[0514 06:13:38 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4582 mins
[32m[0514 06:13:38 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 06:13:38 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0514 06:13:38 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:38 @base_main.py:47][0m 166830 total steps have happened
[32m[0514 06:13:38 @base_main.py:52][0m [avg_reward]: -32.52487656180271
[32m[0514 06:13:38 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:38 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:38 @base_trainer.py:216][0m Mean reward: -31.252940832848815
[32m[0514 06:13:39 @base_main.py:38][0m --------------- Iteration 167 ---------------
[32m[0514 06:13:39 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4709 mins
[32m[0514 06:13:39 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 06:13:39 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 06:13:39 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:13:39 @base_main.py:47][0m 167835 total steps have happened
[32m[0514 06:13:39 @base_main.py:52][0m [avg_reward]: -31.252940832848815
[32m[0514 06:13:39 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:39 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:39 @base_trainer.py:216][0m Mean reward: -31.09524398017039
[32m[0514 06:13:39 @base_main.py:38][0m --------------- Iteration 168 ---------------
[32m[0514 06:13:39 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4830 mins
[32m[0514 06:13:39 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 06:13:39 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 06:13:39 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:39 @base_main.py:47][0m 168840 total steps have happened
[32m[0514 06:13:39 @base_main.py:52][0m [avg_reward]: -31.09524398017039
[32m[0514 06:13:39 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:39 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:39 @base_trainer.py:216][0m Mean reward: -31.052688206711093
[32m[0514 06:13:40 @base_main.py:38][0m --------------- Iteration 169 ---------------
[32m[0514 06:13:40 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4948 mins
[32m[0514 06:13:40 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0032 mins
[32m[0514 06:13:40 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 06:13:40 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:13:40 @base_main.py:47][0m 169845 total steps have happened
[32m[0514 06:13:40 @base_main.py:52][0m [avg_reward]: -31.052688206711093
[32m[0514 06:13:40 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:40 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:40 @base_trainer.py:216][0m Mean reward: -31.064832901848252
[32m[0514 06:13:41 @base_main.py:38][0m --------------- Iteration 170 ---------------
[32m[0514 06:13:41 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.5069 mins
[32m[0514 06:13:41 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 06:13:41 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0514 06:13:41 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:41 @base_main.py:47][0m 170850 total steps have happened
[32m[0514 06:13:41 @base_main.py:52][0m [avg_reward]: -31.064832901848252
[32m[0514 06:13:41 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:41 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:41 @base_trainer.py:216][0m Mean reward: -29.602623329288736
[32m[0514 06:13:42 @base_main.py:38][0m --------------- Iteration 171 ---------------
[32m[0514 06:13:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.5196 mins
[32m[0514 06:13:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 06:13:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0514 06:13:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:42 @base_main.py:47][0m 171855 total steps have happened
[32m[0514 06:13:42 @base_main.py:52][0m [avg_reward]: -29.602623329288736
[32m[0514 06:13:42 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:42 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:42 @base_trainer.py:216][0m Mean reward: -29.608709208782063
[32m[0514 06:13:42 @base_main.py:38][0m --------------- Iteration 172 ---------------
[32m[0514 06:13:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.5322 mins
[32m[0514 06:13:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 06:13:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 06:13:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:42 @base_main.py:47][0m 172860 total steps have happened
[32m[0514 06:13:42 @base_main.py:52][0m [avg_reward]: -29.608709208782063
[32m[0514 06:13:42 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:42 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:42 @base_trainer.py:216][0m Mean reward: -29.118248195530345
[32m[0514 06:13:43 @base_main.py:38][0m --------------- Iteration 173 ---------------
[32m[0514 06:13:43 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.5442 mins
[32m[0514 06:13:43 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 06:13:43 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0514 06:13:43 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:43 @base_main.py:47][0m 173865 total steps have happened
[32m[0514 06:13:43 @base_main.py:52][0m [avg_reward]: -29.118248195530345
[32m[0514 06:13:43 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:43 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:43 @base_trainer.py:216][0m Mean reward: -28.926516400332325
[32m[0514 06:13:44 @base_main.py:38][0m --------------- Iteration 174 ---------------
[32m[0514 06:13:44 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.5558 mins
[32m[0514 06:13:44 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 06:13:44 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 06:13:44 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:44 @base_main.py:47][0m 174870 total steps have happened
[32m[0514 06:13:44 @base_main.py:52][0m [avg_reward]: -28.926516400332325
[32m[0514 06:13:44 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:44 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:44 @base_trainer.py:216][0m Mean reward: -36.66816033973227
[32m[0514 06:13:44 @base_main.py:38][0m --------------- Iteration 175 ---------------
[32m[0514 06:13:44 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.5677 mins
[32m[0514 06:13:44 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 06:13:44 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 06:13:44 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:44 @base_main.py:47][0m 175875 total steps have happened
[32m[0514 06:13:44 @base_main.py:52][0m [avg_reward]: -36.66816033973227
[32m[0514 06:13:45 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:45 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:45 @base_trainer.py:216][0m Mean reward: -50.30649890056567
[32m[0514 06:13:45 @base_main.py:38][0m --------------- Iteration 176 ---------------
[32m[0514 06:13:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.5796 mins
[32m[0514 06:13:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 06:13:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0514 06:13:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:45 @base_main.py:47][0m 176880 total steps have happened
[32m[0514 06:13:45 @base_main.py:52][0m [avg_reward]: -50.30649890056567
[32m[0514 06:13:45 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:45 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:45 @base_trainer.py:216][0m Mean reward: -31.26442750853078
[32m[0514 06:13:46 @base_main.py:38][0m --------------- Iteration 177 ---------------
[32m[0514 06:13:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.5919 mins
[32m[0514 06:13:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 06:13:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 06:13:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:46 @base_main.py:47][0m 177885 total steps have happened
[32m[0514 06:13:46 @base_main.py:52][0m [avg_reward]: -31.26442750853078
[32m[0514 06:13:46 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:46 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:46 @base_trainer.py:216][0m Mean reward: -28.5787930320325
[32m[0514 06:13:47 @base_main.py:38][0m --------------- Iteration 178 ---------------
[32m[0514 06:13:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.6034 mins
[32m[0514 06:13:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 06:13:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 06:13:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:47 @base_main.py:47][0m 178890 total steps have happened
[32m[0514 06:13:47 @base_main.py:52][0m [avg_reward]: -28.5787930320325
[32m[0514 06:13:47 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:47 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:47 @base_trainer.py:216][0m Mean reward: -26.763122047402625
[32m[0514 06:13:47 @base_main.py:38][0m --------------- Iteration 179 ---------------
[32m[0514 06:13:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.6152 mins
[32m[0514 06:13:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 06:13:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 06:13:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:47 @base_main.py:47][0m 179895 total steps have happened
[32m[0514 06:13:47 @base_main.py:52][0m [avg_reward]: -26.763122047402625
[32m[0514 06:13:47 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:47 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:47 @base_trainer.py:216][0m Mean reward: -24.835707406967767
[32m[0514 06:13:48 @base_main.py:38][0m --------------- Iteration 180 ---------------
[32m[0514 06:13:48 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.6273 mins
[32m[0514 06:13:48 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 06:13:48 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0514 06:13:48 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:48 @base_main.py:47][0m 180900 total steps have happened
[32m[0514 06:13:48 @base_main.py:52][0m [avg_reward]: -24.835707406967767
[32m[0514 06:13:48 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:48 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:48 @base_trainer.py:216][0m Mean reward: -28.02850963116139
[32m[0514 06:13:49 @base_main.py:38][0m --------------- Iteration 181 ---------------
[32m[0514 06:13:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.6387 mins
[32m[0514 06:13:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 06:13:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 06:13:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:49 @base_main.py:47][0m 181905 total steps have happened
[32m[0514 06:13:49 @base_main.py:52][0m [avg_reward]: -28.02850963116139
[32m[0514 06:13:49 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:49 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:49 @base_trainer.py:216][0m Mean reward: -27.25651812113395
[32m[0514 06:13:49 @base_main.py:38][0m --------------- Iteration 182 ---------------
[32m[0514 06:13:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.6503 mins
[32m[0514 06:13:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 06:13:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0514 06:13:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:13:49 @base_main.py:47][0m 182910 total steps have happened
[32m[0514 06:13:49 @base_main.py:52][0m [avg_reward]: -27.25651812113395
[32m[0514 06:13:49 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:49 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:49 @base_trainer.py:216][0m Mean reward: -26.98535739168549
[32m[0514 06:13:50 @base_main.py:38][0m --------------- Iteration 183 ---------------
[32m[0514 06:13:50 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.6617 mins
[32m[0514 06:13:50 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 06:13:50 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 06:13:50 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:50 @base_main.py:47][0m 183915 total steps have happened
[32m[0514 06:13:50 @base_main.py:52][0m [avg_reward]: -26.98535739168549
[32m[0514 06:13:50 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:50 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:50 @base_trainer.py:216][0m Mean reward: -27.37591782351628
[32m[0514 06:13:51 @base_main.py:38][0m --------------- Iteration 184 ---------------
[32m[0514 06:13:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.6739 mins
[32m[0514 06:13:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0514 06:13:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 06:13:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:51 @base_main.py:47][0m 184920 total steps have happened
[32m[0514 06:13:51 @base_main.py:52][0m [avg_reward]: -27.37591782351628
[32m[0514 06:13:51 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:51 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:51 @base_trainer.py:216][0m Mean reward: -26.519585792228668
[32m[0514 06:13:51 @base_main.py:38][0m --------------- Iteration 185 ---------------
[32m[0514 06:13:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.6862 mins
[32m[0514 06:13:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 06:13:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 06:13:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:51 @base_main.py:47][0m 185925 total steps have happened
[32m[0514 06:13:51 @base_main.py:52][0m [avg_reward]: -26.519585792228668
[32m[0514 06:13:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:52 @base_trainer.py:216][0m Mean reward: -26.238707837072695
[32m[0514 06:13:52 @base_main.py:38][0m --------------- Iteration 186 ---------------
[32m[0514 06:13:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.6981 mins
[32m[0514 06:13:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 06:13:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 06:13:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:52 @base_main.py:47][0m 186930 total steps have happened
[32m[0514 06:13:52 @base_main.py:52][0m [avg_reward]: -26.238707837072695
[32m[0514 06:13:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:52 @base_trainer.py:216][0m Mean reward: -30.76225653019181
[32m[0514 06:13:53 @base_main.py:38][0m --------------- Iteration 187 ---------------
[32m[0514 06:13:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.7101 mins
[32m[0514 06:13:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0514 06:13:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 06:13:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:53 @base_main.py:47][0m 187935 total steps have happened
[32m[0514 06:13:53 @base_main.py:52][0m [avg_reward]: -30.76225653019181
[32m[0514 06:13:53 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:53 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:53 @base_trainer.py:216][0m Mean reward: -28.94892799353421
[32m[0514 06:13:54 @base_main.py:38][0m --------------- Iteration 188 ---------------
[32m[0514 06:13:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.7224 mins
[32m[0514 06:13:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 06:13:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 06:13:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:54 @base_main.py:47][0m 188940 total steps have happened
[32m[0514 06:13:54 @base_main.py:52][0m [avg_reward]: -28.94892799353421
[32m[0514 06:13:54 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:54 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:54 @base_trainer.py:216][0m Mean reward: -26.998524874164588
[32m[0514 06:13:54 @base_main.py:38][0m --------------- Iteration 189 ---------------
[32m[0514 06:13:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.7341 mins
[32m[0514 06:13:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 06:13:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0514 06:13:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:13:54 @base_main.py:47][0m 189945 total steps have happened
[32m[0514 06:13:54 @base_main.py:52][0m [avg_reward]: -26.998524874164588
[32m[0514 06:13:55 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:55 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:55 @base_trainer.py:216][0m Mean reward: -26.271815453681683
[32m[0514 06:13:55 @base_main.py:38][0m --------------- Iteration 190 ---------------
[32m[0514 06:13:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.7461 mins
[32m[0514 06:13:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0514 06:13:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0514 06:13:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:55 @base_main.py:47][0m 190950 total steps have happened
[32m[0514 06:13:55 @base_main.py:52][0m [avg_reward]: -26.271815453681683
[32m[0514 06:13:55 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:55 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:55 @base_trainer.py:216][0m Mean reward: -26.277191279612957
[32m[0514 06:13:56 @base_main.py:38][0m --------------- Iteration 191 ---------------
[32m[0514 06:13:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.7577 mins
[32m[0514 06:13:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 06:13:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0514 06:13:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:56 @base_main.py:47][0m 191955 total steps have happened
[32m[0514 06:13:56 @base_main.py:52][0m [avg_reward]: -26.277191279612957
[32m[0514 06:13:56 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:56 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:56 @base_trainer.py:216][0m Mean reward: -29.883419784035972
[32m[0514 06:13:57 @base_main.py:38][0m --------------- Iteration 192 ---------------
[32m[0514 06:13:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.7702 mins
[32m[0514 06:13:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 06:13:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 06:13:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:57 @base_main.py:47][0m 192960 total steps have happened
[32m[0514 06:13:57 @base_main.py:52][0m [avg_reward]: -29.883419784035972
[32m[0514 06:13:57 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:57 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:57 @base_trainer.py:216][0m Mean reward: -26.342989561493187
[32m[0514 06:13:57 @base_main.py:38][0m --------------- Iteration 193 ---------------
[32m[0514 06:13:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.7819 mins
[32m[0514 06:13:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0514 06:13:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 06:13:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:57 @base_main.py:47][0m 193965 total steps have happened
[32m[0514 06:13:57 @base_main.py:52][0m [avg_reward]: -26.342989561493187
[32m[0514 06:13:57 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:57 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:57 @base_trainer.py:216][0m Mean reward: -25.035885482215207
[32m[0514 06:13:58 @base_main.py:38][0m --------------- Iteration 194 ---------------
[32m[0514 06:13:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.7937 mins
[32m[0514 06:13:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 06:13:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0514 06:13:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:58 @base_main.py:47][0m 194970 total steps have happened
[32m[0514 06:13:58 @base_main.py:52][0m [avg_reward]: -25.035885482215207
[32m[0514 06:13:58 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:58 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:58 @base_trainer.py:216][0m Mean reward: -24.958026254407862
[32m[0514 06:13:59 @base_main.py:38][0m --------------- Iteration 195 ---------------
[32m[0514 06:13:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.8062 mins
[32m[0514 06:13:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0032 mins
[32m[0514 06:13:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0514 06:13:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:13:59 @base_main.py:47][0m 195975 total steps have happened
[32m[0514 06:13:59 @base_main.py:52][0m [avg_reward]: -24.958026254407862
[32m[0514 06:13:59 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:13:59 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:13:59 @base_trainer.py:216][0m Mean reward: -24.016824078587604
[32m[0514 06:13:59 @base_main.py:38][0m --------------- Iteration 196 ---------------
[32m[0514 06:13:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.8187 mins
[32m[0514 06:13:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0033 mins
[32m[0514 06:13:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 06:13:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:13:59 @base_main.py:47][0m 196980 total steps have happened
[32m[0514 06:13:59 @base_main.py:52][0m [avg_reward]: -24.016824078587604
[32m[0514 06:14:00 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:00 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:00 @base_trainer.py:216][0m Mean reward: -24.45149869357188
[32m[0514 06:14:00 @base_main.py:38][0m --------------- Iteration 197 ---------------
[32m[0514 06:14:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.8311 mins
[32m[0514 06:14:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 06:14:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0514 06:14:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:14:00 @base_main.py:47][0m 197985 total steps have happened
[32m[0514 06:14:00 @base_main.py:52][0m [avg_reward]: -24.45149869357188
[32m[0514 06:14:00 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:00 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:00 @base_trainer.py:216][0m Mean reward: -23.711637829978123
[32m[0514 06:14:01 @base_main.py:38][0m --------------- Iteration 198 ---------------
[32m[0514 06:14:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.8438 mins
[32m[0514 06:14:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0514 06:14:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0514 06:14:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:14:01 @base_main.py:47][0m 198990 total steps have happened
[32m[0514 06:14:01 @base_main.py:52][0m [avg_reward]: -23.711637829978123
[32m[0514 06:14:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:01 @base_trainer.py:216][0m Mean reward: -24.31876633280355
[32m[0514 06:14:02 @base_main.py:38][0m --------------- Iteration 199 ---------------
[32m[0514 06:14:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.8558 mins
[32m[0514 06:14:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0514 06:14:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0514 06:14:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0514 06:14:02 @base_main.py:47][0m 199995 total steps have happened
[32m[0514 06:14:02 @base_main.py:52][0m [avg_reward]: -24.31876633280355
[32m[0514 06:14:02 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0514 06:14:02 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0514 06:14:02 @base_trainer.py:216][0m Mean reward: -26.553508449824825
[32m[0514 06:14:02 @base_main.py:38][0m --------------- Iteration 200 ---------------
[32m[0514 06:14:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.8678 mins
[32m[0514 06:14:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0514 06:14:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0514 06:14:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0514 06:14:02 @base_main.py:47][0m 201000 total steps have happened
[32m[0514 06:14:02 @base_main.py:52][0m [avg_reward]: -26.553508449824825
[32m[0514 06:14:02 @base_worker.py:111][0m kill message for worker 16
[32m[0514 06:14:02 @base_worker.py:111][0m kill message for worker 15
[32m[0514 06:14:02 @base_worker.py:111][0m kill message for worker 1
[32m[0514 06:14:02 @base_worker.py:111][0m kill message for worker 11
[32m[0514 06:14:02 @base_worker.py:111][0m kill message for worker 9
[32m[0514 06:14:02 @base_worker.py:111][0m kill message for worker 4
[32m[0514 06:14:02 @base_worker.py:111][0m kill message for worker 13
[32m[0514 06:14:02 @base_worker.py:111][0m kill message for worker 0
[32m[0514 06:14:02 @base_worker.py:111][0m kill message for worker 6
[32m[0514 06:14:02 @base_worker.py:111][0m kill message for worker 10
[32m[0514 06:14:02 @base_worker.py:111][0m kill message for worker 12
[32m[0514 06:14:02 @base_worker.py:111][0m kill message for worker 5
[32m[0514 06:14:02 @base_worker.py:111][0m kill message for worker 14
[32m[0514 06:14:02 @base_worker.py:111][0m kill message for worker 3
[32m[0514 06:14:02 @base_worker.py:111][0m kill message for worker 8
[32m[0514 06:14:02 @base_worker.py:111][0m kill message for worker 17
[32m[0514 06:14:02 @base_worker.py:111][0m kill message for worker 7
[32m[0514 06:14:02 @base_worker.py:111][0m kill message for worker 18
[32m[0514 06:14:02 @base_worker.py:111][0m kill message for worker 2
[32m[0514 06:14:02 @base_worker.py:111][0m kill message for worker 19
