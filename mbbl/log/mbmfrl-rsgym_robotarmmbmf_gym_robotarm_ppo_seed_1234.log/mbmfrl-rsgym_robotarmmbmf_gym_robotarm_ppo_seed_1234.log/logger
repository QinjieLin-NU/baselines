[32m[0511 22:17:24 @logger.py:103][0m Log file set to /root/mbbl/log/mbmfrl-rsgym_robotarmmbmf_gym_robotarm_ppo_seed_1234.log/mbmfrl-rsgym_robotarmmbmf_gym_robotarm_ppo_seed_1234.log
[32m[0511 22:17:24 @mbmf_main.py:23][0m Training starts at /root/mbbl
[32m[0511 22:17:24 @base_worker.py:45][0m Worker 0 online
[32m[0511 22:17:26 @base_worker.py:45][0m Worker 1 online
[32m[0511 22:17:26 @base_worker.py:45][0m Worker 2 online
[32m[0511 22:17:26 @base_worker.py:45][0m Worker 3 online
[32m[0511 22:17:26 @base_worker.py:45][0m Worker 4 online
[32m[0511 22:17:26 @base_worker.py:45][0m Worker 5 online
[32m[0511 22:17:26 @base_worker.py:45][0m Worker 6 online
[32m[0511 22:17:26 @base_worker.py:45][0m Worker 7 online
[32m[0511 22:17:26 @base_worker.py:45][0m Worker 8 online
[32m[0511 22:17:26 @base_worker.py:45][0m Worker 9 online
[32m[0511 22:17:26 @base_worker.py:45][0m Worker 10 online
[32m[0511 22:17:26 @base_worker.py:45][0m Worker 11 online
[32m[0511 22:17:26 @base_worker.py:45][0m Worker 12 online
[32m[0511 22:17:26 @base_worker.py:45][0m Worker 13 online
[32m[0511 22:17:26 @base_worker.py:45][0m Worker 14 online
[32m[0511 22:17:26 @base_worker.py:45][0m Worker 15 online
[32m[0511 22:17:26 @base_worker.py:45][0m Worker 16 online
[32m[0511 22:17:26 @base_worker.py:45][0m Worker 17 online
[32m[0511 22:17:26 @base_worker.py:45][0m Worker 18 online
[32m[0511 22:17:26 @base_worker.py:45][0m Worker 19 online
[32m[0511 22:17:28 @base_trainer.py:152][0m Trainer maintains [1] policy network
[32m[0511 22:17:28 @base_trainer.py:152][0m Trainer maintains [1] dynamics network
[32m[0511 22:17:28 @base_trainer.py:152][0m Trainer maintains [1] reward network
[32m[0511 22:17:29 @mbmf_main.py:46][0m Generating 1000 random timesteps
[32m[0511 22:17:29 @mbmf_sampler.py:39][0m done with episode
[32m[0511 22:17:29 @mbmf_sampler.py:39][0m done with episode
[32m[0511 22:17:29 @mbmf_sampler.py:39][0m done with episode
[32m[0511 22:17:29 @mbmf_sampler.py:39][0m done with episode
[32m[0511 22:17:30 @mbmf_sampler.py:39][0m done with episode
[32m[0511 22:17:30 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0511 22:17:30 @base_trainer.py:216][0m Mean reward: -239.97154937877696
[32m[0511 22:17:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.050061583518982, Train Loss: 1.0149692296981812
[32m[0511 22:17:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0500801801681519, Train Loss: 1.014959692955017
[32m[0511 22:17:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0500991344451904, Train Loss: 1.0149503946304321
[32m[0511 22:17:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0501182079315186, Train Loss: 1.0149412155151367
[32m[0511 22:17:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0501375198364258, Train Loss: 1.0149322748184204
[32m[0511 22:17:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.050156831741333, Train Loss: 1.0149234533309937
[32m[0511 22:17:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0501763820648193, Train Loss: 1.0149149894714355
[32m[0511 22:17:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0501958131790161, Train Loss: 1.014906644821167
[32m[0511 22:17:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0502156019210815, Train Loss: 1.014898419380188
[32m[0511 22:17:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.050235390663147, Train Loss: 1.0148905515670776
[32m[0511 22:17:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0502554178237915, Train Loss: 1.0148826837539673
[32m[0511 22:17:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0502753257751465, Train Loss: 1.0148749351501465
[32m[0511 22:17:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0502955913543701, Train Loss: 1.0148677825927734
[32m[0511 22:17:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0503156185150146, Train Loss: 1.0148606300354004
[32m[0511 22:17:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0503358840942383, Train Loss: 1.0148537158966064
[32m[0511 22:17:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.050356149673462, Train Loss: 1.0148468017578125
[32m[0511 22:17:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.050376534461975, Train Loss: 1.0148403644561768
[32m[0511 22:17:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0503969192504883, Train Loss: 1.014833927154541
[32m[0511 22:17:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0504173040390015, Train Loss: 1.014827847480774
[32m[0511 22:17:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.050437569618225, Train Loss: 1.014822006225586
[32m[0511 22:17:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0504578351974487, Train Loss: 1.014816164970398
[32m[0511 22:17:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0504778623580933, Train Loss: 1.014810562133789
[32m[0511 22:17:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0504982471466064, Train Loss: 1.0148054361343384
[32m[0511 22:17:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.050518274307251, Train Loss: 1.0148000717163086
[32m[0511 22:17:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0505385398864746, Train Loss: 1.014795184135437
[32m[0511 22:17:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0505584478378296, Train Loss: 1.0147902965545654
[32m[0511 22:17:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0505783557891846, Train Loss: 1.0147857666015625
[32m[0511 22:17:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0505982637405396, Train Loss: 1.0147812366485596
[32m[0511 22:17:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0506179332733154, Train Loss: 1.0147769451141357
[32m[0511 22:17:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0506374835968018, Train Loss: 1.0147727727890015
[32m[0511 22:17:32 @base_main.py:38][0m --------------- Iteration 1 ---------------
[32m[0511 22:17:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0000 mins
[32m[0511 22:17:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0089 mins
[32m[0511 22:17:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0284 mins
[32m[0511 22:17:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0056 mins
[32m[0511 22:17:32 @base_main.py:47][0m 1005 total steps have happened
[32m[0511 22:17:32 @base_main.py:52][0m [avg_reward]: -239.97154937877696
[32m[0511 22:17:32 @base_main.py:52][0m [update_op]: None
[32m[0511 22:17:32 @base_main.py:52][0m [train_loss]: 1.0147727727890015
[32m[0511 22:17:32 @base_main.py:52][0m [val_loss]: 1.0506374835968018
[32m[0511 22:17:32 @base_main.py:52][0m [avg_train_loss]: 1.0147727727890015
[32m[0511 22:20:07 @mbmf_sampler.py:39][0m done with episode
[32m[0511 22:22:30 @mbmf_sampler.py:39][0m done with episode
[32m[0511 22:24:52 @mbmf_sampler.py:39][0m done with episode
[32m[0511 22:27:15 @mbmf_sampler.py:39][0m done with episode
[32m[0511 22:29:37 @mbmf_sampler.py:39][0m done with episode
[32m[0511 22:29:37 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0511 22:29:37 @base_trainer.py:216][0m Mean reward: -303.31704056257985
[32m[0511 22:29:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0129362344741821, Train Loss: 1.0071886777877808
[32m[0511 22:29:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0129547119140625, Train Loss: 1.007188320159912
[32m[0511 22:29:38 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0129698514938354, Train Loss: 1.0071872472763062
[32m[0511 22:29:38 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0129822492599487, Train Loss: 1.0071858167648315
[32m[0511 22:29:38 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0129926204681396, Train Loss: 1.0071842670440674
[32m[0511 22:29:38 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.013001561164856, Train Loss: 1.0071827173233032
[32m[0511 22:29:38 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0130090713500977, Train Loss: 1.007181167602539
[32m[0511 22:29:38 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0130155086517334, Train Loss: 1.007179617881775
[32m[0511 22:29:38 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0130211114883423, Train Loss: 1.0071781873703003
[32m[0511 22:29:38 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0130257606506348, Train Loss: 1.0071767568588257
[32m[0511 22:29:38 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.013029932975769, Train Loss: 1.0071755647659302
[32m[0511 22:29:38 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0130335092544556, Train Loss: 1.0071743726730347
[32m[0511 22:29:38 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0130364894866943, Train Loss: 1.0071731805801392
[32m[0511 22:29:38 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0130391120910645, Train Loss: 1.0071722269058228
[32m[0511 22:29:38 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0130414962768555, Train Loss: 1.0071712732315063
[32m[0511 22:29:38 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0130434036254883, Train Loss: 1.00717031955719
[32m[0511 22:29:38 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0130449533462524, Train Loss: 1.0071696043014526
[32m[0511 22:29:38 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0130462646484375, Train Loss: 1.0071688890457153
[32m[0511 22:29:38 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.013047456741333, Train Loss: 1.007168173789978
[32m[0511 22:29:38 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0130482912063599, Train Loss: 1.0071674585342407
[32m[0511 22:29:38 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0130491256713867, Train Loss: 1.007166862487793
[32m[0511 22:29:38 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0130494832992554, Train Loss: 1.0071662664413452
[32m[0511 22:29:38 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0130500793457031, Train Loss: 1.007165789604187
[32m[0511 22:29:38 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0130504369735718, Train Loss: 1.0071651935577393
[32m[0511 22:29:38 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0130504369735718, Train Loss: 1.0071648359298706
[32m[0511 22:29:38 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0130506753921509, Train Loss: 1.0071643590927124
[32m[0511 22:29:39 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0130507946014404, Train Loss: 1.0071638822555542
[32m[0511 22:29:39 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0130507946014404, Train Loss: 1.007163405418396
[32m[0511 22:29:39 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0130505561828613, Train Loss: 1.007163166999817
[32m[0511 22:29:39 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0130503177642822, Train Loss: 1.0071629285812378
[32m[0511 22:29:39 @base_main.py:38][0m --------------- Iteration 2 ---------------
[32m[0511 22:29:39 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0429 mins
[32m[0511 22:29:39 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 12.0959 mins
[32m[0511 22:29:39 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0217 mins
[32m[0511 22:29:39 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0047 mins
[32m[0511 22:29:39 @base_main.py:47][0m 2010 total steps have happened
[32m[0511 22:29:39 @base_main.py:52][0m [avg_reward]: -303.31704056257985
[32m[0511 22:29:39 @base_main.py:52][0m [update_op]: None
[32m[0511 22:29:39 @base_main.py:52][0m [train_loss]: 0.7887226343154907
[32m[0511 22:29:39 @base_main.py:52][0m [val_loss]: 1.0130503177642822
[32m[0511 22:29:39 @base_main.py:52][0m [avg_train_loss]: 1.0071629285812378
[32m[0511 22:32:02 @mbmf_sampler.py:39][0m done with episode
[32m[0511 22:34:25 @mbmf_sampler.py:39][0m done with episode
[32m[0511 22:36:48 @mbmf_sampler.py:39][0m done with episode
[32m[0511 22:39:10 @mbmf_sampler.py:39][0m done with episode
[32m[0511 22:41:33 @mbmf_sampler.py:39][0m done with episode
[32m[0511 22:41:33 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0511 22:41:33 @base_trainer.py:216][0m Mean reward: -231.15262727237237
[32m[0511 22:41:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8622615337371826, Train Loss: 1.0290014743804932
[32m[0511 22:41:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8622482419013977, Train Loss: 1.028996229171753
[32m[0511 22:41:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8622310161590576, Train Loss: 1.0289888381958008
[32m[0511 22:41:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8622126579284668, Train Loss: 1.0289807319641113
[32m[0511 22:41:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8621949553489685, Train Loss: 1.0289732217788696
[32m[0511 22:41:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8621782660484314, Train Loss: 1.0289663076400757
[32m[0511 22:41:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8621633648872375, Train Loss: 1.0289604663848877
[32m[0511 22:41:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8621501922607422, Train Loss: 1.0289555788040161
[32m[0511 22:41:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8621386289596558, Train Loss: 1.0289514064788818
[32m[0511 22:41:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8621286153793335, Train Loss: 1.0289479494094849
[32m[0511 22:41:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8621200323104858, Train Loss: 1.0289452075958252
[32m[0511 22:41:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8621125221252441, Train Loss: 1.0289428234100342
[32m[0511 22:41:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8621062636375427, Train Loss: 1.0289409160614014
[32m[0511 22:41:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8621008396148682, Train Loss: 1.0289394855499268
[32m[0511 22:41:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8620960712432861, Train Loss: 1.0289380550384521
[32m[0511 22:41:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8620920777320862, Train Loss: 1.0289369821548462
[32m[0511 22:41:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.862088680267334, Train Loss: 1.0289360284805298
[32m[0511 22:41:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8620857000350952, Train Loss: 1.028935194015503
[32m[0511 22:41:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8620833158493042, Train Loss: 1.0289347171783447
[32m[0511 22:41:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.862080991268158, Train Loss: 1.0289338827133179
[32m[0511 22:41:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8620791435241699, Train Loss: 1.0289335250854492
[32m[0511 22:41:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8620777130126953, Train Loss: 1.0289329290390015
[32m[0511 22:41:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8620763421058655, Train Loss: 1.0289325714111328
[32m[0511 22:41:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8620750904083252, Train Loss: 1.0289320945739746
[32m[0511 22:41:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8620740175247192, Train Loss: 1.0289318561553955
[32m[0511 22:41:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8620732426643372, Train Loss: 1.0289316177368164
[32m[0511 22:41:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8620723485946655, Train Loss: 1.0289312601089478
[32m[0511 22:41:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8620718121528625, Train Loss: 1.0289310216903687
[32m[0511 22:41:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8620712161064148, Train Loss: 1.028930902481079
[32m[0511 22:41:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8620707988739014, Train Loss: 1.0289305448532104
[32m[0511 22:41:35 @base_main.py:38][0m --------------- Iteration 3 ---------------
[32m[0511 22:41:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 12.1653 mins
[32m[0511 22:41:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 11.8930 mins
[32m[0511 22:41:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0318 mins
[32m[0511 22:41:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0042 mins
[32m[0511 22:41:35 @base_main.py:47][0m 3015 total steps have happened
[32m[0511 22:41:35 @base_main.py:52][0m [avg_reward]: -231.15262727237237
[32m[0511 22:41:35 @base_main.py:52][0m [update_op]: None
[32m[0511 22:41:35 @base_main.py:52][0m [train_loss]: 1.130361557006836
[32m[0511 22:41:35 @base_main.py:52][0m [val_loss]: 0.8620707988739014
[32m[0511 22:41:35 @base_main.py:52][0m [avg_train_loss]: 1.0289305448532104
[32m[0511 22:43:57 @mbmf_sampler.py:39][0m done with episode
[32m[0511 22:46:18 @mbmf_sampler.py:39][0m done with episode
[32m[0511 22:48:40 @mbmf_sampler.py:39][0m done with episode
[32m[0511 22:51:02 @mbmf_sampler.py:39][0m done with episode
[32m[0511 22:53:23 @mbmf_sampler.py:39][0m done with episode
[32m[0511 22:53:23 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0511 22:53:23 @base_trainer.py:216][0m Mean reward: -276.5361811131056
[32m[0511 22:53:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.914772629737854, Train Loss: 1.0049768686294556
[32m[0511 22:53:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9147790670394897, Train Loss: 1.0049749612808228
[32m[0511 22:53:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.914786696434021, Train Loss: 1.0049728155136108
[32m[0511 22:53:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9147948026657104, Train Loss: 1.0049705505371094
[32m[0511 22:53:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9148027300834656, Train Loss: 1.0049684047698975
[32m[0511 22:53:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9148107767105103, Train Loss: 1.0049664974212646
[32m[0511 22:53:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9148184061050415, Train Loss: 1.0049649477005005
[32m[0511 22:53:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9148257374763489, Train Loss: 1.0049633979797363
[32m[0511 22:53:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9148328304290771, Train Loss: 1.0049620866775513
[32m[0511 22:53:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9148392677307129, Train Loss: 1.0049608945846558
[32m[0511 22:53:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9148457050323486, Train Loss: 1.0049599409103394
[32m[0511 22:53:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9148516058921814, Train Loss: 1.004958987236023
[32m[0511 22:53:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9148573279380798, Train Loss: 1.0049582719802856
[32m[0511 22:53:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9148626923561096, Train Loss: 1.0049574375152588
[32m[0511 22:53:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9148677587509155, Train Loss: 1.0049569606781006
[32m[0511 22:53:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9148724675178528, Train Loss: 1.0049563646316528
[32m[0511 22:53:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9148769974708557, Train Loss: 1.0049560070037842
[32m[0511 22:53:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9148811101913452, Train Loss: 1.004955530166626
[32m[0511 22:53:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9148851633071899, Train Loss: 1.0049551725387573
[32m[0511 22:53:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.914888858795166, Train Loss: 1.0049549341201782
[32m[0511 22:53:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9148923754692078, Train Loss: 1.0049546957015991
[32m[0511 22:53:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9148955941200256, Train Loss: 1.00495445728302
[32m[0511 22:53:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9148985743522644, Train Loss: 1.004954218864441
[32m[0511 22:53:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9149014353752136, Train Loss: 1.0049540996551514
[32m[0511 22:53:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9149042963981628, Train Loss: 1.0049539804458618
[32m[0511 22:53:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9149066805839539, Train Loss: 1.0049538612365723
[32m[0511 22:53:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9149090647697449, Train Loss: 1.0049537420272827
[32m[0511 22:53:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9149113893508911, Train Loss: 1.0049537420272827
[32m[0511 22:53:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9149132966995239, Train Loss: 1.0049536228179932
[32m[0511 22:53:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9149153232574463, Train Loss: 1.0049535036087036
[32m[0511 22:53:26 @base_main.py:38][0m --------------- Iteration 4 ---------------
[32m[0511 22:53:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 24.0943 mins
[32m[0511 22:53:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 11.8014 mins
[32m[0511 22:53:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0444 mins
[32m[0511 22:53:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0041 mins
[32m[0511 22:53:26 @base_main.py:47][0m 4020 total steps have happened
[32m[0511 22:53:26 @base_main.py:52][0m [avg_reward]: -276.5361811131056
[32m[0511 22:53:26 @base_main.py:52][0m [update_op]: None
[32m[0511 22:53:26 @base_main.py:52][0m [train_loss]: 0.7955857515335083
[32m[0511 22:53:26 @base_main.py:52][0m [val_loss]: 0.9149153232574463
[32m[0511 22:53:26 @base_main.py:52][0m [avg_train_loss]: 1.0049535036087036
[32m[0511 22:55:47 @mbmf_sampler.py:39][0m done with episode
[32m[0511 22:58:08 @mbmf_sampler.py:39][0m done with episode
[32m[0511 23:00:30 @mbmf_sampler.py:39][0m done with episode
[32m[0511 23:02:51 @mbmf_sampler.py:39][0m done with episode
[32m[0511 23:05:12 @mbmf_sampler.py:39][0m done with episode
[32m[0511 23:05:12 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0511 23:05:12 @base_trainer.py:216][0m Mean reward: -365.55317573603406
[32m[0511 23:05:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5010427236557007, Train Loss: 0.9489352107048035
[32m[0511 23:05:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.50106942653656, Train Loss: 0.9489336013793945
[32m[0511 23:05:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.501092791557312, Train Loss: 0.9489323496818542
[32m[0511 23:05:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5011117458343506, Train Loss: 0.9489314556121826
[32m[0511 23:05:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.501127004623413, Train Loss: 0.9489307403564453
[32m[0511 23:05:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5011388063430786, Train Loss: 0.9489303231239319
[32m[0511 23:05:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5011481046676636, Train Loss: 0.9489300847053528
[32m[0511 23:05:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.501155138015747, Train Loss: 0.9489299058914185
[32m[0511 23:05:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5011602640151978, Train Loss: 0.9489296674728394
[32m[0511 23:05:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5011643171310425, Train Loss: 0.9489295482635498
[32m[0511 23:05:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5011674165725708, Train Loss: 0.948929488658905
[32m[0511 23:05:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5011698007583618, Train Loss: 0.948929488658905
[32m[0511 23:05:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.501171588897705, Train Loss: 0.9489293694496155
[32m[0511 23:05:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5011732578277588, Train Loss: 0.9489292502403259
[32m[0511 23:05:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5011740922927856, Train Loss: 0.9489292502403259
[32m[0511 23:05:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5011751651763916, Train Loss: 0.9489292502403259
[32m[0511 23:05:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5011757612228394, Train Loss: 0.9489292502403259
[32m[0511 23:05:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5011765956878662, Train Loss: 0.9489292502403259
[32m[0511 23:05:14 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5011770725250244, Train Loss: 0.9489292502403259
[32m[0511 23:05:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.501177430152893, Train Loss: 0.9489291310310364
[32m[0511 23:05:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5011777877807617, Train Loss: 0.9489291310310364
[32m[0511 23:05:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5011781454086304, Train Loss: 0.9489291310310364
[32m[0511 23:05:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5011786222457886, Train Loss: 0.9489291310310364
[32m[0511 23:05:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5011786222457886, Train Loss: 0.9489291310310364
[32m[0511 23:05:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5011789798736572, Train Loss: 0.9489291310310364
[32m[0511 23:05:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5011789798736572, Train Loss: 0.9489291310310364
[32m[0511 23:05:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.5011794567108154, Train Loss: 0.9489291310310364
[32m[0511 23:05:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.501179575920105, Train Loss: 0.9489291310310364
[32m[0511 23:05:15 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.501179575920105, Train Loss: 0.9489291310310364
[32m[0511 23:05:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.501179814338684, Train Loss: 0.9489290714263916
[32m[0511 23:05:16 @base_main.py:38][0m --------------- Iteration 5 ---------------
[32m[0511 23:05:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 35.9443 mins
[32m[0511 23:05:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 11.7790 mins
[32m[0511 23:05:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0527 mins
[32m[0511 23:05:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0044 mins
[32m[0511 23:05:16 @base_main.py:47][0m 5025 total steps have happened
[32m[0511 23:05:16 @base_main.py:52][0m [avg_reward]: -365.55317573603406
[32m[0511 23:05:16 @base_main.py:52][0m [update_op]: None
[32m[0511 23:05:16 @base_main.py:52][0m [train_loss]: 0.8176797032356262
[32m[0511 23:05:16 @base_main.py:52][0m [val_loss]: 1.501179814338684
[32m[0511 23:05:16 @base_main.py:52][0m [avg_train_loss]: 0.9489290714263916
[32m[0511 23:07:37 @mbmf_sampler.py:39][0m done with episode
[32m[0511 23:09:58 @mbmf_sampler.py:39][0m done with episode
[32m[0511 23:12:19 @mbmf_sampler.py:39][0m done with episode
[32m[0511 23:14:39 @mbmf_sampler.py:39][0m done with episode
[32m[0511 23:17:00 @mbmf_sampler.py:39][0m done with episode
[32m[0511 23:17:00 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0511 23:17:00 @base_trainer.py:216][0m Mean reward: -307.7754151078533
[32m[0511 23:17:01 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2204513549804688, Train Loss: 0.9522937536239624
[32m[0511 23:17:01 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2204453945159912, Train Loss: 0.9522923827171326
[32m[0511 23:17:01 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2204396724700928, Train Loss: 0.9522910714149475
[32m[0511 23:17:01 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2204351425170898, Train Loss: 0.9522901177406311
[32m[0511 23:17:01 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2204324007034302, Train Loss: 0.9522895216941833
[32m[0511 23:17:01 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2204307317733765, Train Loss: 0.9522888660430908
[32m[0511 23:17:01 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2204301357269287, Train Loss: 0.9522885680198669
[32m[0511 23:17:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2204302549362183, Train Loss: 0.9522882103919983
[32m[0511 23:17:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2204307317733765, Train Loss: 0.952288031578064
[32m[0511 23:17:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2204312086105347, Train Loss: 0.9522878527641296
[32m[0511 23:17:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.220431923866272, Train Loss: 0.9522876143455505
[32m[0511 23:17:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.220432996749878, Train Loss: 0.952287495136261
[32m[0511 23:17:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2204335927963257, Train Loss: 0.952287495136261
[32m[0511 23:17:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2204344272613525, Train Loss: 0.9522873163223267
[32m[0511 23:17:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2204351425170898, Train Loss: 0.9522873163223267
[32m[0511 23:17:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2204360961914062, Train Loss: 0.9522872567176819
[32m[0511 23:17:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2204368114471436, Train Loss: 0.9522872567176819
[32m[0511 23:17:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2204376459121704, Train Loss: 0.9522871375083923
[32m[0511 23:17:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2204382419586182, Train Loss: 0.9522871375083923
[32m[0511 23:17:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2204387187957764, Train Loss: 0.9522871375083923
[32m[0511 23:17:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2204391956329346, Train Loss: 0.9522870779037476
[32m[0511 23:17:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2204396724700928, Train Loss: 0.9522871375083923
[32m[0511 23:17:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2204400300979614, Train Loss: 0.9522871375083923
[32m[0511 23:17:04 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2204406261444092, Train Loss: 0.9522871375083923
[32m[0511 23:17:04 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2204408645629883, Train Loss: 0.9522871375083923
[32m[0511 23:17:04 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2204411029815674, Train Loss: 0.9522871375083923
[32m[0511 23:17:04 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.220441460609436, Train Loss: 0.9522870779037476
[32m[0511 23:17:04 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2204415798187256, Train Loss: 0.9522871375083923
[32m[0511 23:17:04 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2204418182373047, Train Loss: 0.9522871375083923
[32m[0511 23:17:04 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2204420566558838, Train Loss: 0.9522871375083923
[32m[0511 23:17:05 @base_main.py:38][0m --------------- Iteration 6 ---------------
[32m[0511 23:17:05 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 47.7804 mins
[32m[0511 23:17:05 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 11.7432 mins
[32m[0511 23:17:05 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0646 mins
[32m[0511 23:17:05 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0042 mins
[32m[0511 23:17:05 @base_main.py:47][0m 6030 total steps have happened
[32m[0511 23:17:05 @base_main.py:52][0m [avg_reward]: -307.7754151078533
[32m[0511 23:17:05 @base_main.py:52][0m [update_op]: None
[32m[0511 23:17:05 @base_main.py:52][0m [train_loss]: 2.058445930480957
[32m[0511 23:17:05 @base_main.py:52][0m [val_loss]: 1.2204420566558838
[32m[0511 23:17:05 @base_main.py:52][0m [avg_train_loss]: 0.9522871375083923
[32m[0511 23:19:25 @mbmf_sampler.py:39][0m done with episode
[32m[0511 23:21:46 @mbmf_sampler.py:39][0m done with episode
[32m[0511 23:24:07 @mbmf_sampler.py:39][0m done with episode
[32m[0511 23:26:28 @mbmf_sampler.py:39][0m done with episode
[32m[0511 23:28:48 @mbmf_sampler.py:39][0m done with episode
[32m[0511 23:28:48 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0511 23:28:48 @base_trainer.py:216][0m Mean reward: -200.22838953954917
[32m[0511 23:28:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4684840142726898, Train Loss: 0.977291464805603
[32m[0511 23:28:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.468511700630188, Train Loss: 0.977289080619812
[32m[0511 23:28:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4685354232788086, Train Loss: 0.9772871732711792
[32m[0511 23:28:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.46855413913726807, Train Loss: 0.9772859215736389
[32m[0511 23:28:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.46856823563575745, Train Loss: 0.9772852659225464
[32m[0511 23:28:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.46857884526252747, Train Loss: 0.9772847890853882
[32m[0511 23:28:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.46858662366867065, Train Loss: 0.9772846698760986
[32m[0511 23:28:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.46859243512153625, Train Loss: 0.9772844910621643
[32m[0511 23:28:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.46859681606292725, Train Loss: 0.97728431224823
[32m[0511 23:28:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4686000347137451, Train Loss: 0.97728431224823
[32m[0511 23:28:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.46860262751579285, Train Loss: 0.97728431224823
[32m[0511 23:28:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.46860456466674805, Train Loss: 0.9772841930389404
[32m[0511 23:28:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.46860602498054504, Train Loss: 0.9772841334342957
[32m[0511 23:28:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4686072766780853, Train Loss: 0.9772840738296509
[32m[0511 23:28:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4686082601547241, Train Loss: 0.9772841930389404
[32m[0511 23:28:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4686090350151062, Train Loss: 0.9772841930389404
[32m[0511 23:28:50 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.46860966086387634, Train Loss: 0.9772841930389404
[32m[0511 23:28:51 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.46861016750335693, Train Loss: 0.9772841930389404
[32m[0511 23:28:51 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.468610554933548, Train Loss: 0.9772841930389404
[32m[0511 23:28:51 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4686110019683838, Train Loss: 0.9772841334342957
[32m[0511 23:28:51 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.46861129999160767, Train Loss: 0.9772841930389404
[32m[0511 23:28:51 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4686115086078644, Train Loss: 0.9772841334342957
[32m[0511 23:28:51 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.46861180663108826, Train Loss: 0.9772841930389404
[32m[0511 23:28:52 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4686119258403778, Train Loss: 0.9772841334342957
[32m[0511 23:28:52 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.46861207485198975, Train Loss: 0.9772840738296509
[32m[0511 23:28:52 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4686121642589569, Train Loss: 0.9772841334342957
[32m[0511 23:28:52 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4686122536659241, Train Loss: 0.9772841334342957
[32m[0511 23:28:52 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.46861231327056885, Train Loss: 0.9772841334342957
[32m[0511 23:28:52 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.468612402677536, Train Loss: 0.9772841930389404
[32m[0511 23:28:52 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.4686124324798584, Train Loss: 0.9772841930389404
[32m[0511 23:28:53 @base_main.py:38][0m --------------- Iteration 7 ---------------
[32m[0511 23:28:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 59.5925 mins
[32m[0511 23:28:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 11.7226 mins
[32m[0511 23:28:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0753 mins
[32m[0511 23:28:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0045 mins
[32m[0511 23:28:53 @base_main.py:47][0m 7035 total steps have happened
[32m[0511 23:28:53 @base_main.py:52][0m [avg_reward]: -200.22838953954917
[32m[0511 23:28:53 @base_main.py:52][0m [update_op]: None
[32m[0511 23:28:53 @base_main.py:52][0m [train_loss]: 1.0419907569885254
[32m[0511 23:28:53 @base_main.py:52][0m [val_loss]: 0.4686124324798584
[32m[0511 23:28:53 @base_main.py:52][0m [avg_train_loss]: 0.9772841930389404
[32m[0511 23:28:53 @mbmf_trainer.py:160][0m Mean reward: -274.93348267289593
[32m[0511 23:28:53 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.21550676226615906, Train Loss: 0.22659939527511597
[32m[0511 23:28:53 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.2154819667339325, Train Loss: 0.2264077514410019
[32m[0511 23:28:53 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.2154841125011444, Train Loss: 0.22635899484157562
[32m[0511 23:28:53 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.2154889553785324, Train Loss: 0.22635243833065033
[32m[0511 23:28:53 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.21548695862293243, Train Loss: 0.22634965181350708
[32m[0511 23:28:53 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.21547982096672058, Train Loss: 0.22634154558181763
[32m[0511 23:28:53 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.21547040343284607, Train Loss: 0.22633010149002075
[32m[0511 23:28:53 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.21546052396297455, Train Loss: 0.22631783783435822
[32m[0511 23:28:53 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.21545100212097168, Train Loss: 0.2263060063123703
[32m[0511 23:28:53 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.2154419720172882, Train Loss: 0.22629475593566895
[32m[0511 23:28:53 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.21543346345424652, Train Loss: 0.22628410160541534
[32m[0511 23:28:53 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.21542523801326752, Train Loss: 0.226273775100708
[32m[0511 23:28:53 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.21541716158390045, Train Loss: 0.22626371681690216
[32m[0511 23:28:53 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.21540921926498413, Train Loss: 0.22625382244586945
[32m[0511 23:28:53 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.2154012769460678, Train Loss: 0.22624410688877106
[32m[0511 23:28:53 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.21539340913295746, Train Loss: 0.226234570145607
[32m[0511 23:28:53 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.21538566052913666, Train Loss: 0.22622518241405487
[32m[0511 23:28:53 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.21537795662879944, Train Loss: 0.22621595859527588
[32m[0511 23:28:53 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.215370312333107, Train Loss: 0.2262069433927536
[32m[0511 23:28:53 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.2153628021478653, Train Loss: 0.22619803249835968
[32m[0511 23:28:53 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.21535541117191315, Train Loss: 0.22618931531906128
[32m[0511 23:28:54 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.21534810960292816, Train Loss: 0.22618071734905243
[32m[0511 23:28:54 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.21534091234207153, Train Loss: 0.22617225348949432
[32m[0511 23:28:54 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.21533380448818207, Train Loss: 0.22616390883922577
[32m[0511 23:28:54 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.21532681584358215, Train Loss: 0.22615574300289154
[32m[0511 23:28:54 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.21532000601291656, Train Loss: 0.22614766657352448
[32m[0511 23:28:54 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.21531325578689575, Train Loss: 0.22613976895809174
[32m[0511 23:28:54 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.21530668437480927, Train Loss: 0.22613197565078735
[32m[0511 23:28:54 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.21530023217201233, Train Loss: 0.22612427175045013
[32m[0511 23:28:54 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.21529389917850494, Train Loss: 0.22611673176288605
[32m[0511 23:28:54 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.2152877151966095, Train Loss: 0.22610926628112793
[32m[0511 23:28:54 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.215281680226326, Train Loss: 0.22610197961330414
[32m[0511 23:28:54 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.21527576446533203, Train Loss: 0.22609473764896393
[32m[0511 23:28:54 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.2152700126171112, Train Loss: 0.22608767449855804
[32m[0511 23:28:54 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.21526439487934113, Train Loss: 0.22608067095279694
[32m[0511 23:28:54 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.21525892615318298, Train Loss: 0.22607381641864777
[32m[0511 23:28:54 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.21525360643863678, Train Loss: 0.22606706619262695
[32m[0511 23:28:54 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.21524842083454132, Train Loss: 0.2260603904724121
[32m[0511 23:28:54 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.21524333953857422, Train Loss: 0.22605381906032562
[32m[0511 23:28:54 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.21523846685886383, Train Loss: 0.22604738175868988
[32m[0511 23:28:54 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.2152336835861206, Train Loss: 0.2260410040616989
[32m[0511 23:28:54 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.21522903442382812, Train Loss: 0.2260347157716751
[32m[0511 23:28:54 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.21522454917430878, Train Loss: 0.22602856159210205
[32m[0511 23:28:54 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.21522018313407898, Train Loss: 0.22602243721485138
[32m[0511 23:28:54 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.21521595120429993, Train Loss: 0.22601647675037384
[32m[0511 23:28:54 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.21521182358264923, Train Loss: 0.22601057589054108
[32m[0511 23:28:54 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.21520783007144928, Train Loss: 0.22600476443767548
[32m[0511 23:28:54 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.21520398557186127, Train Loss: 0.22599901258945465
[32m[0511 23:28:54 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.2152002602815628, Train Loss: 0.22599339485168457
[32m[0511 23:28:54 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.21519668400287628, Train Loss: 0.22598780691623688
[32m[0511 23:28:54 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.21519316732883453, Train Loss: 0.22598232328891754
[32m[0511 23:28:54 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.21518975496292114, Train Loss: 0.22597694396972656
[32m[0511 23:28:54 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.2151864767074585, Train Loss: 0.22597159445285797
[32m[0511 23:28:54 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.2151833325624466, Train Loss: 0.22596633434295654
[32m[0511 23:28:54 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.21518024802207947, Train Loss: 0.22596114873886108
[32m[0511 23:28:55 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.21517729759216309, Train Loss: 0.2259560376405716
[32m[0511 23:28:55 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.21517443656921387, Train Loss: 0.22595100104808807
[32m[0511 23:28:55 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.21517163515090942, Train Loss: 0.22594599425792694
[32m[0511 23:28:55 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.21516895294189453, Train Loss: 0.22594107687473297
[32m[0511 23:28:55 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.2151663601398468, Train Loss: 0.22593624889850616
[32m[0511 23:28:55 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.21516384184360504, Train Loss: 0.22593146562576294
[32m[0511 23:28:55 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.21516144275665283, Train Loss: 0.22592675685882568
[32m[0511 23:28:55 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.2151590883731842, Train Loss: 0.2259221076965332
[32m[0511 23:28:55 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.21515682339668274, Train Loss: 0.22591747343540192
[32m[0511 23:28:55 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.21515463292598724, Train Loss: 0.225912943482399
[32m[0511 23:28:55 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.21515250205993652, Train Loss: 0.22590845823287964
[32m[0511 23:28:55 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.21515044569969177, Train Loss: 0.22590403258800507
[32m[0511 23:28:55 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.21514840424060822, Train Loss: 0.2258996218442917
[32m[0511 23:28:55 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.2151464968919754, Train Loss: 0.22589528560638428
[32m[0511 23:28:55 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.21514460444450378, Train Loss: 0.22589103877544403
[32m[0511 23:28:55 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.21514280140399933, Train Loss: 0.22588680684566498
[32m[0511 23:28:55 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.21514102816581726, Train Loss: 0.22588257491588593
[32m[0511 23:28:55 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.21513931453227997, Train Loss: 0.22587847709655762
[32m[0511 23:28:55 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.21513764560222626, Train Loss: 0.22587436437606812
[32m[0511 23:28:55 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.21513603627681732, Train Loss: 0.2258703112602234
[32m[0511 23:28:55 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.21513444185256958, Train Loss: 0.22586631774902344
[32m[0511 23:28:55 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.2151329070329666, Train Loss: 0.22586233913898468
[32m[0511 23:28:55 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.21513138711452484, Train Loss: 0.2258584052324295
[32m[0511 23:28:55 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.21512992680072784, Train Loss: 0.2258545309305191
[32m[0511 23:28:55 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.21512845158576965, Train Loss: 0.2258506566286087
[32m[0511 23:28:55 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.215127095580101, Train Loss: 0.22584682703018188
[32m[0511 23:28:55 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.21512572467327118, Train Loss: 0.22584307193756104
[32m[0511 23:28:55 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.21512438356876373, Train Loss: 0.22583931684494019
[32m[0511 23:28:55 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.21512305736541748, Train Loss: 0.22583560645580292
[32m[0511 23:28:55 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.21512174606323242, Train Loss: 0.22583194077014923
[32m[0511 23:28:55 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.21512046456336975, Train Loss: 0.22582824528217316
[32m[0511 23:28:55 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.21511922776699066, Train Loss: 0.22582466900348663
[32m[0511 23:28:55 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.21511799097061157, Train Loss: 0.22582103312015533
[32m[0511 23:28:55 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.21511675417423248, Train Loss: 0.2258174866437912
[32m[0511 23:28:55 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.21511556208133698, Train Loss: 0.22581394016742706
[32m[0511 23:28:56 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.21511435508728027, Train Loss: 0.2258104532957077
[32m[0511 23:28:56 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.21511317789554596, Train Loss: 0.22580695152282715
[32m[0511 23:28:56 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.21511200070381165, Train Loss: 0.22580350935459137
[32m[0511 23:28:56 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.21511085331439972, Train Loss: 0.2258000373840332
[32m[0511 23:28:56 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.2151097059249878, Train Loss: 0.225796639919281
[32m[0511 23:28:56 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.21510860323905945, Train Loss: 0.2257932424545288
[32m[0511 23:28:56 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.21510742604732513, Train Loss: 0.2257899045944214
[32m[0511 23:28:56 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.2151062786579132, Train Loss: 0.22578652203083038
[32m[0511 23:28:56 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.21510516107082367, Train Loss: 0.22578322887420654
[32m[0511 23:28:56 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.21510399878025055, Train Loss: 0.2257799357175827
[32m[0511 23:28:56 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.21510286629199982, Train Loss: 0.22577659785747528
[32m[0511 23:28:56 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.21510176360607147, Train Loss: 0.22577333450317383
[32m[0511 23:28:56 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.21510063111782074, Train Loss: 0.22577007114887238
[32m[0511 23:28:56 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.2150994837284088, Train Loss: 0.22576682269573212
[32m[0511 23:28:56 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.21509835124015808, Train Loss: 0.22576363384723663
[32m[0511 23:28:56 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.21509721875190735, Train Loss: 0.22576041519641876
[32m[0511 23:28:56 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.21509607136249542, Train Loss: 0.22575722634792328
[32m[0511 23:28:56 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.2150948941707611, Train Loss: 0.2257540374994278
[32m[0511 23:28:56 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.21509374678134918, Train Loss: 0.2257508784532547
[32m[0511 23:28:56 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.21509259939193726, Train Loss: 0.2257477045059204
[32m[0511 23:28:56 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.21509142220020294, Train Loss: 0.2257446050643921
[32m[0511 23:28:56 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.21509023010730743, Train Loss: 0.225741446018219
[32m[0511 23:28:56 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.21508906781673431, Train Loss: 0.22573834657669067
[32m[0511 23:28:56 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.215087890625, Train Loss: 0.22573524713516235
[32m[0511 23:28:56 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.2150866687297821, Train Loss: 0.22573214769363403
[32m[0511 23:28:56 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.2150854617357254, Train Loss: 0.2257290631532669
[32m[0511 23:28:56 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.2150842249393463, Train Loss: 0.22572600841522217
[32m[0511 23:28:56 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.21508300304412842, Train Loss: 0.22572290897369385
[32m[0511 23:28:56 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.21508175134658813, Train Loss: 0.2257198691368103
[32m[0511 23:28:56 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.21508046984672546, Train Loss: 0.22571681439876556
[32m[0511 23:28:56 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.215079203248024, Train Loss: 0.22571377456188202
[32m[0511 23:28:56 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.21507792174816132, Train Loss: 0.22571073472499847
[32m[0511 23:28:56 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.21507661044597626, Train Loss: 0.22570772469043732
[32m[0511 23:28:56 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.21507528424263, Train Loss: 0.22570468485355377
[32m[0511 23:28:56 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.21507397294044495, Train Loss: 0.225701704621315
[32m[0511 23:28:56 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.2150726467370987, Train Loss: 0.22569866478443146
[32m[0511 23:28:56 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.21507130563259125, Train Loss: 0.2256956845521927
[32m[0511 23:28:57 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.21506991982460022, Train Loss: 0.22569270431995392
[32m[0511 23:28:57 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.21506854891777039, Train Loss: 0.22568969428539276
[32m[0511 23:28:57 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.21506713330745697, Train Loss: 0.225686714053154
[32m[0511 23:28:57 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.21506573259830475, Train Loss: 0.22568374872207642
[32m[0511 23:28:57 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.21506431698799133, Train Loss: 0.22568076848983765
[32m[0511 23:28:57 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.21506288647651672, Train Loss: 0.22567777335643768
[32m[0511 23:28:57 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.21506141126155853, Train Loss: 0.2256748229265213
[32m[0511 23:28:57 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.21505998075008392, Train Loss: 0.22567187249660492
[32m[0511 23:28:57 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.21505847573280334, Train Loss: 0.22566886246204376
[32m[0511 23:28:57 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.21505698561668396, Train Loss: 0.22566591203212738
[32m[0511 23:28:57 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.2150554358959198, Train Loss: 0.225662961602211
[32m[0511 23:28:57 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.21505391597747803, Train Loss: 0.2256600260734558
[32m[0511 23:28:57 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.21505238115787506, Train Loss: 0.22565704584121704
[32m[0511 23:28:57 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.2150508016347885, Train Loss: 0.22565408051013947
[32m[0511 23:28:57 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.21504923701286316, Train Loss: 0.22565113008022308
[32m[0511 23:28:57 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.21504764258861542, Train Loss: 0.22564822435379028
[32m[0511 23:28:57 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.21504604816436768, Train Loss: 0.2256452590227127
[32m[0511 23:28:57 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.21504440903663635, Train Loss: 0.22564230859279633
[32m[0511 23:28:57 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.21504278481006622, Train Loss: 0.22563935816287994
[32m[0511 23:28:57 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.2150411158800125, Train Loss: 0.22563643753528595
[32m[0511 23:28:57 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.21503946185112, Train Loss: 0.22563348710536957
[32m[0511 23:28:57 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.2150377780199051, Train Loss: 0.22563053667545319
[32m[0511 23:28:57 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.21503610908985138, Train Loss: 0.2256275862455368
[32m[0511 23:28:57 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.2150343805551529, Train Loss: 0.2256246656179428
[32m[0511 23:28:57 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.21503262221813202, Train Loss: 0.22562171518802643
[32m[0511 23:28:57 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.21503089368343353, Train Loss: 0.22561876475811005
[32m[0511 23:28:57 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.21502913534641266, Train Loss: 0.22561581432819366
[32m[0511 23:28:57 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.2150273621082306, Train Loss: 0.22561287879943848
[32m[0511 23:28:57 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.21502555906772614, Train Loss: 0.2256099432706833
[32m[0511 23:28:57 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.21502377092838287, Train Loss: 0.2256069779396057
[32m[0511 23:28:57 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.21502192318439484, Train Loss: 0.22560401260852814
[32m[0511 23:28:57 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.21502012014389038, Train Loss: 0.22560112178325653
[32m[0511 23:28:57 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.21501825749874115, Train Loss: 0.22559814155101776
[32m[0511 23:28:57 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.21501636505126953, Train Loss: 0.22559519112110138
[32m[0511 23:28:57 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.2150145024061203, Train Loss: 0.22559227049350739
[32m[0511 23:28:57 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.2150125950574875, Train Loss: 0.225589320063591
[32m[0511 23:28:58 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.21501070261001587, Train Loss: 0.22558635473251343
[32m[0511 23:28:58 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.21500878036022186, Train Loss: 0.22558338940143585
[32m[0511 23:28:58 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.21500684320926666, Train Loss: 0.22558045387268066
[32m[0511 23:28:58 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.21500489115715027, Train Loss: 0.2255774736404419
[32m[0511 23:28:58 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.21500293910503387, Train Loss: 0.2255745381116867
[32m[0511 23:28:58 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.2150009423494339, Train Loss: 0.22557158768177032
[32m[0511 23:28:58 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.21499896049499512, Train Loss: 0.22556859254837036
[32m[0511 23:28:58 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.21499696373939514, Train Loss: 0.22556567192077637
[32m[0511 23:28:58 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.21499495208263397, Train Loss: 0.2255626916885376
[32m[0511 23:28:58 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.21499288082122803, Train Loss: 0.22555971145629883
[32m[0511 23:28:58 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.21499082446098328, Train Loss: 0.22555674612522125
[32m[0511 23:28:58 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.2149888128042221, Train Loss: 0.22555376589298248
[32m[0511 23:28:58 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.21498669683933258, Train Loss: 0.2255508303642273
[32m[0511 23:28:58 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.21498461067676544, Train Loss: 0.22554780542850494
[32m[0511 23:28:58 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.2149825394153595, Train Loss: 0.22554485499858856
[32m[0511 23:28:58 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.21498042345046997, Train Loss: 0.2255418747663498
[32m[0511 23:28:58 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.21497827768325806, Train Loss: 0.22553889453411102
[32m[0511 23:28:58 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.21497614681720734, Train Loss: 0.22553588449954987
[32m[0511 23:28:58 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.21497398614883423, Train Loss: 0.2255329042673111
[32m[0511 23:28:58 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.2149718552827835, Train Loss: 0.22552992403507233
[32m[0511 23:28:58 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.2149696797132492, Train Loss: 0.22552692890167236
[32m[0511 23:28:58 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.2149674892425537, Train Loss: 0.2255239337682724
[32m[0511 23:28:58 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.21496528387069702, Train Loss: 0.22552095353603363
[32m[0511 23:28:58 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.21496306359767914, Train Loss: 0.22551792860031128
[32m[0511 23:28:58 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.21496082842350006, Train Loss: 0.2255149483680725
[32m[0511 23:28:58 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.21495859324932098, Train Loss: 0.22551192343235016
[32m[0511 23:28:58 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.2149563580751419, Train Loss: 0.2255089282989502
[32m[0511 23:28:58 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.21495409309864044, Train Loss: 0.22550590336322784
[32m[0511 23:28:58 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.21495181322097778, Train Loss: 0.2255028933286667
[32m[0511 23:28:58 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.21494954824447632, Train Loss: 0.22549986839294434
[32m[0511 23:28:58 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.21494723856449127, Train Loss: 0.22549684345722198
[32m[0511 23:28:58 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.21494494378566742, Train Loss: 0.22549386322498322
[32m[0511 23:28:58 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.21494263410568237, Train Loss: 0.22549079358577728
[32m[0511 23:28:58 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.21494030952453613, Train Loss: 0.22548778355121613
[32m[0511 23:28:58 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.2149379998445511, Train Loss: 0.22548477351665497
[32m[0511 23:28:59 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.21493567526340485, Train Loss: 0.22548170387744904
[32m[0511 23:28:59 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.21493329107761383, Train Loss: 0.22547869384288788
[32m[0511 23:28:59 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.2149309366941452, Train Loss: 0.22547565400600433
[32m[0511 23:28:59 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.2149285525083542, Train Loss: 0.2254725843667984
[32m[0511 23:28:59 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.21492616832256317, Train Loss: 0.22546954452991486
[32m[0511 23:28:59 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.21492378413677216, Train Loss: 0.2254665046930313
[32m[0511 23:28:59 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.21492137014865875, Train Loss: 0.22546343505382538
[32m[0511 23:28:59 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.21491898596286774, Train Loss: 0.22546041011810303
[32m[0511 23:28:59 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.21491654217243195, Train Loss: 0.2254573255777359
[32m[0511 23:28:59 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.21491411328315735, Train Loss: 0.22545428574085236
[32m[0511 23:28:59 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.21491166949272156, Train Loss: 0.22545121610164642
[32m[0511 23:28:59 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.21490924060344696, Train Loss: 0.2254481464624405
[32m[0511 23:28:59 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.21490678191184998, Train Loss: 0.22544507682323456
[32m[0511 23:28:59 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.214904323220253, Train Loss: 0.22544200718402863
[32m[0511 23:28:59 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.21490183472633362, Train Loss: 0.2254389077425003
[32m[0511 23:28:59 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.21489936113357544, Train Loss: 0.22543585300445557
[32m[0511 23:28:59 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.21489688754081726, Train Loss: 0.22543276846408844
[32m[0511 23:28:59 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.2148943841457367, Train Loss: 0.22542966902256012
[32m[0511 23:28:59 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.21489189565181732, Train Loss: 0.22542661428451538
[32m[0511 23:28:59 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.21488937735557556, Train Loss: 0.22542349994182587
[32m[0511 23:28:59 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.2148868590593338, Train Loss: 0.22542041540145874
[32m[0511 23:28:59 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.21488434076309204, Train Loss: 0.22541731595993042
[32m[0511 23:28:59 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.21488182246685028, Train Loss: 0.2254142314195633
[32m[0511 23:28:59 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.21487930417060852, Train Loss: 0.22541110217571259
[32m[0511 23:28:59 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.21487674117088318, Train Loss: 0.22540801763534546
[32m[0511 23:28:59 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.21487420797348022, Train Loss: 0.22540491819381714
[32m[0511 23:28:59 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.21487164497375488, Train Loss: 0.22540181875228882
[32m[0511 23:28:59 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.21486908197402954, Train Loss: 0.2253987044095993
[32m[0511 23:28:59 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.2148665338754654, Train Loss: 0.22539560496807098
[32m[0511 23:28:59 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.21486394107341766, Train Loss: 0.22539246082305908
[32m[0511 23:28:59 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.21486137807369232, Train Loss: 0.22538936138153076
[32m[0511 23:28:59 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.2148587852716446, Train Loss: 0.22538624703884125
[32m[0511 23:28:59 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.21485620737075806, Train Loss: 0.22538310289382935
[32m[0511 23:28:59 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.21485362946987152, Train Loss: 0.22537998855113983
[32m[0511 23:28:59 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.2148510366678238, Train Loss: 0.22537684440612793
[32m[0511 23:29:00 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.21484844386577606, Train Loss: 0.22537373006343842
[32m[0511 23:29:00 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.21484583616256714, Train Loss: 0.2253706306219101
[32m[0511 23:29:00 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.21484318375587463, Train Loss: 0.225367471575737
[32m[0511 23:29:00 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.2148406058549881, Train Loss: 0.2253643274307251
[32m[0511 23:29:00 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.21483799815177917, Train Loss: 0.2253611832857132
[32m[0511 23:29:00 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.21483537554740906, Train Loss: 0.2253580540418625
[32m[0511 23:29:00 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.21483272314071655, Train Loss: 0.2253548949956894
[32m[0511 23:29:00 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.21483014523983002, Train Loss: 0.2253517508506775
[32m[0511 23:29:00 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.2148274928331375, Train Loss: 0.2253486067056656
[32m[0511 23:29:00 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.2148248851299286, Train Loss: 0.22534547746181488
[32m[0511 23:29:00 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.21482223272323608, Train Loss: 0.22534233331680298
[32m[0511 23:29:00 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.21481963992118835, Train Loss: 0.2253391593694687
[32m[0511 23:29:00 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.21481697261333466, Train Loss: 0.2253360152244568
[32m[0511 23:29:00 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.21481433510780334, Train Loss: 0.2253328561782837
[32m[0511 23:29:00 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.21481171250343323, Train Loss: 0.2253297120332718
[32m[0511 23:29:00 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.21480906009674072, Train Loss: 0.2253265380859375
[32m[0511 23:29:00 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.2148064225912094, Train Loss: 0.2253233939409256
[32m[0511 23:29:00 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.2148037701845169, Train Loss: 0.2253202199935913
[32m[0511 23:29:00 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.2148011475801468, Train Loss: 0.2253170609474182
[32m[0511 23:29:00 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.21479849517345428, Train Loss: 0.22531388700008392
[32m[0511 23:29:00 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.21479587256908417, Train Loss: 0.22531072795391083
[32m[0511 23:29:00 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.21479322016239166, Train Loss: 0.22530753910541534
[32m[0511 23:29:00 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.21479056775569916, Train Loss: 0.22530436515808105
[32m[0511 23:29:00 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.21478793025016785, Train Loss: 0.22530120611190796
[32m[0511 23:29:00 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.21478524804115295, Train Loss: 0.22529804706573486
[32m[0511 23:29:00 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.21478261053562164, Train Loss: 0.22529487311840057
[32m[0511 23:29:00 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.21477997303009033, Train Loss: 0.22529171407222748
[32m[0511 23:29:00 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.21477733552455902, Train Loss: 0.2252884954214096
[32m[0511 23:29:00 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.2147747129201889, Train Loss: 0.2252853363752365
[32m[0511 23:29:00 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.214772030711174, Train Loss: 0.22528214752674103
[32m[0511 23:29:00 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.2147694081068039, Train Loss: 0.22527897357940674
[32m[0511 23:29:00 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.21476678550243378, Train Loss: 0.22527579963207245
[32m[0511 23:29:00 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.21476416289806366, Train Loss: 0.22527261078357697
[32m[0511 23:29:00 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.21476152539253235, Train Loss: 0.22526943683624268
[32m[0511 23:29:00 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.21475888788700104, Train Loss: 0.2252662628889084
[32m[0511 23:29:01 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.21475625038146973, Train Loss: 0.2252630591392517
[32m[0511 23:29:01 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.2147536277770996, Train Loss: 0.2252599000930786
[32m[0511 23:29:01 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.2147510051727295, Train Loss: 0.22525672614574432
[32m[0511 23:29:01 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.214748352766037, Train Loss: 0.22525352239608765
[32m[0511 23:29:01 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.21474574506282806, Train Loss: 0.22525031864643097
[32m[0511 23:29:01 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.21474315226078033, Train Loss: 0.22524714469909668
[32m[0511 23:29:01 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.2147405445575714, Train Loss: 0.2252439707517624
[32m[0511 23:29:01 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.2147379368543625, Train Loss: 0.2252407819032669
[32m[0511 23:29:01 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.21473532915115356, Train Loss: 0.22523759305477142
[32m[0511 23:29:01 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.21473272144794464, Train Loss: 0.22523440420627594
[32m[0511 23:29:01 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.2147301435470581, Train Loss: 0.22523121535778046
[32m[0511 23:29:01 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.21472753584384918, Train Loss: 0.22522802650928497
[32m[0511 23:29:01 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.21472495794296265, Train Loss: 0.22522486746311188
[32m[0511 23:29:01 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.2147223800420761, Train Loss: 0.2252216786146164
[32m[0511 23:29:01 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.21471981704235077, Train Loss: 0.2252184897661209
[32m[0511 23:29:01 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.21471725404262543, Train Loss: 0.22521531581878662
[32m[0511 23:29:01 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.21471469104290009, Train Loss: 0.22521211206912994
[32m[0511 23:29:01 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.21471212804317474, Train Loss: 0.22520893812179565
[32m[0511 23:29:01 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.2147095948457718, Train Loss: 0.22520577907562256
[32m[0511 23:29:01 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.21470703184604645, Train Loss: 0.2252025604248047
[32m[0511 23:29:01 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.2147044837474823, Train Loss: 0.225199356675148
[32m[0511 23:29:01 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.21470195055007935, Train Loss: 0.22519619762897491
[32m[0511 23:29:01 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.21469944715499878, Train Loss: 0.22519300878047943
[32m[0511 23:29:01 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.21469691395759583, Train Loss: 0.22518986463546753
[32m[0511 23:29:01 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.21469439566135406, Train Loss: 0.22518666088581085
[32m[0511 23:29:01 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.2146918773651123, Train Loss: 0.22518348693847656
[32m[0511 23:29:01 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.21468940377235413, Train Loss: 0.22518028318881989
[32m[0511 23:29:01 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.21468691527843475, Train Loss: 0.2251771092414856
[32m[0511 23:29:01 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.21468442678451538, Train Loss: 0.2251739352941513
[32m[0511 23:29:01 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.2146819531917572, Train Loss: 0.22517074644565582
[32m[0511 23:29:01 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.21467947959899902, Train Loss: 0.22516758739948273
[32m[0511 23:29:01 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.21467700600624084, Train Loss: 0.22516442835330963
[32m[0511 23:29:02 @mbmf_sampler.py:98][0m Finished 9th episode
[32m[0511 23:29:02 @mbmf_sampler.py:102][0m 1809 timesteps from 9 episodes collected
[32m[0511 23:50:04 @mbmf_trainer.py:160][0m Mean reward: -286.00141034145383
[32m[0511 23:50:04 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.21977241337299347, Train Loss: 0.22293400764465332
[32m[0511 23:50:04 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.21987532079219818, Train Loss: 0.22285932302474976
[32m[0511 23:50:04 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.21982131898403168, Train Loss: 0.2228267937898636
[32m[0511 23:50:04 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.21978141367435455, Train Loss: 0.22280222177505493
[32m[0511 23:50:04 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.21978454291820526, Train Loss: 0.2227822095155716
[32m[0511 23:50:04 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.21980078518390656, Train Loss: 0.22276431322097778
[32m[0511 23:50:04 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.21981310844421387, Train Loss: 0.22274824976921082
[32m[0511 23:50:04 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.21982115507125854, Train Loss: 0.22273391485214233
[32m[0511 23:50:04 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.21982823312282562, Train Loss: 0.22272109985351562
[32m[0511 23:50:04 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.21983565390110016, Train Loss: 0.22270938754081726
[32m[0511 23:50:05 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.2198433130979538, Train Loss: 0.22269867360591888
[32m[0511 23:50:05 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.21985092759132385, Train Loss: 0.2226887047290802
[32m[0511 23:50:05 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.2198583334684372, Train Loss: 0.22267937660217285
[32m[0511 23:50:05 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.219865620136261, Train Loss: 0.22267059981822968
[32m[0511 23:50:05 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.21987280249595642, Train Loss: 0.2226623147726059
[32m[0511 23:50:05 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.2198798805475235, Train Loss: 0.22265443205833435
[32m[0511 23:50:05 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.21988685429096222, Train Loss: 0.22264695167541504
[32m[0511 23:50:05 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.21989372372627258, Train Loss: 0.2226397544145584
[32m[0511 23:50:05 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.21990051865577698, Train Loss: 0.22263284027576447
[32m[0511 23:50:05 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.2199072390794754, Train Loss: 0.22262617945671082
[32m[0511 23:50:05 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.21991385519504547, Train Loss: 0.22261975705623627
[32m[0511 23:50:05 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.21992041170597076, Train Loss: 0.22261352837085724
[32m[0511 23:50:05 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.2199268937110901, Train Loss: 0.22260746359825134
[32m[0511 23:50:05 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.21993330121040344, Train Loss: 0.22260160744190216
[32m[0511 23:50:05 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.21993964910507202, Train Loss: 0.22259588539600372
[32m[0511 23:50:05 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.21994595229625702, Train Loss: 0.22259029746055603
[32m[0511 23:50:05 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.21995216608047485, Train Loss: 0.22258485853672028
[32m[0511 23:50:05 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.2199583500623703, Train Loss: 0.22257952392101288
[32m[0511 23:50:05 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.21996445953845978, Train Loss: 0.22257432341575623
[32m[0511 23:50:05 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.2199704945087433, Train Loss: 0.22256922721862793
[32m[0511 23:50:05 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.2199764996767044, Train Loss: 0.2225642055273056
[32m[0511 23:50:05 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.21998244524002075, Train Loss: 0.22255927324295044
[32m[0511 23:50:05 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.21998834609985352, Train Loss: 0.22255444526672363
[32m[0511 23:50:05 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.2199941724538803, Train Loss: 0.2225496917963028
[32m[0511 23:50:05 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.21999995410442352, Train Loss: 0.22254504263401031
[32m[0511 23:50:05 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.22000572085380554, Train Loss: 0.22254040837287903
[32m[0511 23:50:05 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.22001142799854279, Train Loss: 0.2225358635187149
[32m[0511 23:50:05 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.22001706063747406, Train Loss: 0.22253140807151794
[32m[0511 23:50:05 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.22002267837524414, Train Loss: 0.22252699732780457
[32m[0511 23:50:06 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.22002823650836945, Train Loss: 0.22252263128757477
[32m[0511 23:50:06 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.22003377974033356, Train Loss: 0.22251830995082855
[32m[0511 23:50:06 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.2200392335653305, Train Loss: 0.2225140780210495
[32m[0511 23:50:06 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.22004468739032745, Train Loss: 0.22250986099243164
[32m[0511 23:50:06 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.22005006670951843, Train Loss: 0.22250570356845856
[32m[0511 23:50:06 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.22005541622638702, Train Loss: 0.22250159084796906
[32m[0511 23:50:06 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.22006070613861084, Train Loss: 0.22249750792980194
[32m[0511 23:50:06 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.22006598114967346, Train Loss: 0.2224934846162796
[32m[0511 23:50:06 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.2200712263584137, Train Loss: 0.22248950600624084
[32m[0511 23:50:06 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.22007641196250916, Train Loss: 0.22248554229736328
[32m[0511 23:50:06 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.22008156776428223, Train Loss: 0.2224816381931305
[32m[0511 23:50:06 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.2200866937637329, Train Loss: 0.2224777489900589
[32m[0511 23:50:06 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.2200917750597, Train Loss: 0.2224739044904709
[32m[0511 23:50:06 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.22009682655334473, Train Loss: 0.22247008979320526
[32m[0511 23:50:06 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.22010184824466705, Train Loss: 0.22246627509593964
[32m[0511 23:50:06 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.2201068252325058, Train Loss: 0.2224625051021576
[32m[0511 23:50:06 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.22011180222034454, Train Loss: 0.22245879471302032
[32m[0511 23:50:06 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.22011670470237732, Train Loss: 0.22245509922504425
[32m[0511 23:50:06 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.2201215624809265, Train Loss: 0.22245141863822937
[32m[0511 23:50:06 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.2201264351606369, Train Loss: 0.22244778275489807
[32m[0511 23:50:06 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.22013123333454132, Train Loss: 0.22244414687156677
[32m[0511 23:50:06 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.22013603150844574, Train Loss: 0.22244055569171906
[32m[0511 23:50:06 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.22014077007770538, Train Loss: 0.22243694961071014
[32m[0511 23:50:06 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.22014552354812622, Train Loss: 0.2224334180355072
[32m[0511 23:50:06 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.22015021741390228, Train Loss: 0.22242988646030426
[32m[0511 23:50:06 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.22015489637851715, Train Loss: 0.22242635488510132
[32m[0511 23:50:06 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.22015951573848724, Train Loss: 0.22242285311222076
[32m[0511 23:50:06 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.22016416490077972, Train Loss: 0.22241941094398499
[32m[0511 23:50:06 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.22016875445842743, Train Loss: 0.222415953874588
[32m[0511 23:50:07 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.22017329931259155, Train Loss: 0.22241252660751343
[32m[0511 23:50:07 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.22017782926559448, Train Loss: 0.22240908443927765
[32m[0511 23:50:07 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.2201823592185974, Train Loss: 0.22240567207336426
[32m[0511 23:50:07 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.22018681466579437, Train Loss: 0.22240231931209564
[32m[0511 23:50:07 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.22019129991531372, Train Loss: 0.22239895164966583
[32m[0511 23:50:07 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.2201957255601883, Train Loss: 0.22239559888839722
[32m[0511 23:50:07 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.22020012140274048, Train Loss: 0.2223922610282898
[32m[0511 23:50:07 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.22020451724529266, Train Loss: 0.22238896787166595
[32m[0511 23:50:07 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.22020891308784485, Train Loss: 0.22238567471504211
[32m[0511 23:50:07 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.22021320462226868, Train Loss: 0.22238239645957947
[32m[0511 23:50:07 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.2202175408601761, Train Loss: 0.22237913310527802
[32m[0511 23:50:07 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.22022183239459991, Train Loss: 0.22237588465213776
[32m[0511 23:50:07 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.22022609412670135, Train Loss: 0.2223726063966751
[32m[0511 23:50:07 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.2202303409576416, Train Loss: 0.22236938774585724
[32m[0511 23:50:07 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.22023457288742065, Train Loss: 0.22236622869968414
[32m[0511 23:50:07 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.22023877501487732, Train Loss: 0.22236298024654388
[32m[0511 23:50:07 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.2202429473400116, Train Loss: 0.2223597913980484
[32m[0511 23:50:07 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.22024711966514587, Train Loss: 0.2223566174507141
[32m[0511 23:50:07 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.22025126218795776, Train Loss: 0.2223534733057022
[32m[0511 23:50:07 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.22025540471076965, Train Loss: 0.2223503142595291
[32m[0511 23:50:07 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.22025948762893677, Train Loss: 0.2223471850156784
[32m[0511 23:50:07 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.22026357054710388, Train Loss: 0.2223440557718277
[32m[0511 23:50:07 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.2202676236629486, Train Loss: 0.22234095633029938
[32m[0511 23:50:07 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.22027169167995453, Train Loss: 0.22233785688877106
[32m[0511 23:50:07 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.22027570009231567, Train Loss: 0.22233475744724274
[32m[0511 23:50:07 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.22027969360351562, Train Loss: 0.2223316729068756
[32m[0511 23:50:07 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.22028368711471558, Train Loss: 0.22232858836650848
[32m[0511 23:50:07 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.22028765082359314, Train Loss: 0.22232554852962494
[32m[0511 23:50:08 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.2202916145324707, Train Loss: 0.2223224639892578
[32m[0511 23:50:08 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.22029556334018707, Train Loss: 0.22231943905353546
[32m[0511 23:50:08 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.22029949724674225, Train Loss: 0.2223164290189743
[32m[0511 23:50:08 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.22030338644981384, Train Loss: 0.22231340408325195
[32m[0511 23:50:08 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.22030726075172424, Train Loss: 0.2223103940486908
[32m[0511 23:50:08 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.22031109035015106, Train Loss: 0.22230739891529083
[32m[0511 23:50:08 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.22031497955322266, Train Loss: 0.22230437397956848
[32m[0511 23:50:08 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.22031879425048828, Train Loss: 0.2223014235496521
[32m[0511 23:50:08 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.2203226238489151, Train Loss: 0.22229842841625214
[32m[0511 23:50:08 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.22032642364501953, Train Loss: 0.22229547798633575
[32m[0511 23:50:08 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.22033019363880157, Train Loss: 0.22229255735874176
[32m[0511 23:50:08 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.22033396363258362, Train Loss: 0.2222895622253418
[32m[0511 23:50:08 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.22033770382404327, Train Loss: 0.2222866266965866
[32m[0511 23:50:08 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.22034147381782532, Train Loss: 0.22228370606899261
[32m[0511 23:50:08 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.22034518420696259, Train Loss: 0.22228075563907623
[32m[0511 23:50:08 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.22034889459609985, Train Loss: 0.22227784991264343
[32m[0511 23:50:08 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.22035259008407593, Train Loss: 0.22227495908737183
[32m[0511 23:50:08 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.2203562706708908, Train Loss: 0.22227205336093903
[32m[0511 23:50:08 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.2203599065542221, Train Loss: 0.22226913273334503
[32m[0511 23:50:08 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.220363587141037, Train Loss: 0.22226624190807343
[32m[0511 23:50:08 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.2203672081232071, Train Loss: 0.2222633808851242
[32m[0511 23:50:08 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.220370814204216, Train Loss: 0.2222605049610138
[32m[0511 23:50:08 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.2203744351863861, Train Loss: 0.22225762903690338
[32m[0511 23:50:08 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.22037802636623383, Train Loss: 0.22225478291511536
[32m[0511 23:50:08 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.22038160264492035, Train Loss: 0.22225192189216614
[32m[0511 23:50:08 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.22038517892360687, Train Loss: 0.2222490906715393
[32m[0511 23:50:08 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.220388725399971, Train Loss: 0.2222462296485901
[32m[0511 23:50:08 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.22039230167865753, Train Loss: 0.22224339842796326
[32m[0511 23:50:08 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.2203957885503769, Train Loss: 0.22224058210849762
[32m[0511 23:50:09 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.22039933502674103, Train Loss: 0.2222377508878708
[32m[0511 23:50:09 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.2204028218984604, Train Loss: 0.22223493456840515
[32m[0511 23:50:09 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.22040630877017975, Train Loss: 0.22223210334777832
[32m[0511 23:50:09 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.22040976583957672, Train Loss: 0.22222930192947388
[32m[0511 23:50:09 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.22041328251361847, Train Loss: 0.22222651541233063
[32m[0511 23:50:09 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.22041670978069305, Train Loss: 0.222223699092865
[32m[0511 23:50:09 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.22042015194892883, Train Loss: 0.22222092747688293
[32m[0511 23:50:09 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.22042357921600342, Train Loss: 0.2222181111574173
[32m[0511 23:50:09 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.220427006483078, Train Loss: 0.22221533954143524
[32m[0511 23:50:09 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.2204304188489914, Train Loss: 0.22221256792545319
[32m[0511 23:50:09 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.2204338014125824, Train Loss: 0.22220979630947113
[32m[0511 23:50:09 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.2204371839761734, Train Loss: 0.22220703959465027
[32m[0511 23:50:09 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.2204405516386032, Train Loss: 0.2222042828798294
[32m[0511 23:50:09 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.2204439342021942, Train Loss: 0.22220151126384735
[32m[0511 23:50:09 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.22044728696346283, Train Loss: 0.22219876945018768
[32m[0511 23:50:09 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.22045059502124786, Train Loss: 0.22219602763652802
[32m[0511 23:50:09 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.22045394778251648, Train Loss: 0.22219328582286835
[32m[0511 23:50:09 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.22045724093914032, Train Loss: 0.22219052910804749
[32m[0511 23:50:09 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.22046054899692535, Train Loss: 0.22218778729438782
[32m[0511 23:50:09 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.22046388685703278, Train Loss: 0.22218509018421173
[32m[0511 23:50:09 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.22046715021133423, Train Loss: 0.22218234837055206
[32m[0511 23:50:09 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.22047042846679688, Train Loss: 0.2221796214580536
[32m[0511 23:50:09 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.22047369182109833, Train Loss: 0.22217689454555511
[32m[0511 23:50:09 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.22047695517539978, Train Loss: 0.22217419743537903
[32m[0511 23:50:09 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.22048020362854004, Train Loss: 0.22217150032520294
[32m[0511 23:50:09 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.2204834371805191, Train Loss: 0.22216878831386566
[32m[0511 23:50:09 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.22048670053482056, Train Loss: 0.22216607630252838
[32m[0511 23:50:09 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.22048987448215485, Train Loss: 0.2221633791923523
[32m[0511 23:50:10 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.22049309313297272, Train Loss: 0.22216066718101501
[32m[0511 23:50:10 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.2204962968826294, Train Loss: 0.22215797007083893
[32m[0511 23:50:10 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.22049948573112488, Train Loss: 0.22215528786182404
[32m[0511 23:50:10 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.22050268948078156, Train Loss: 0.22215257585048676
[32m[0511 23:50:10 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.22050586342811584, Train Loss: 0.22214990854263306
[32m[0511 23:50:10 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.22050900757312775, Train Loss: 0.22214721143245697
[32m[0511 23:50:10 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.22051218152046204, Train Loss: 0.22214455902576447
[32m[0511 23:50:10 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.22051531076431274, Train Loss: 0.22214189171791077
[32m[0511 23:50:10 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.22051845490932465, Train Loss: 0.22213920950889587
[32m[0511 23:50:10 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.22052158415317535, Train Loss: 0.22213652729988098
[32m[0511 23:50:10 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.22052469849586487, Train Loss: 0.22213385999202728
[32m[0511 23:50:10 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.2205277979373932, Train Loss: 0.22213119268417358
[32m[0511 23:50:10 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.2205309122800827, Train Loss: 0.22212855517864227
[32m[0511 23:50:10 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.2205340415239334, Train Loss: 0.22212587296962738
[32m[0511 23:50:10 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.22053711116313934, Train Loss: 0.22212320566177368
[32m[0511 23:50:10 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.22054018080234528, Train Loss: 0.22212055325508118
[32m[0511 23:50:10 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.2205432802438736, Train Loss: 0.22211790084838867
[32m[0511 23:50:10 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.22054632008075714, Train Loss: 0.22211526334285736
[32m[0511 23:50:10 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.22054937481880188, Train Loss: 0.22211262583732605
[32m[0511 23:50:10 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.22055241465568542, Train Loss: 0.22210995852947235
[32m[0511 23:50:10 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.22055546939373016, Train Loss: 0.22210733592510223
[32m[0511 23:50:10 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.22055849432945251, Train Loss: 0.22210465371608734
[32m[0511 23:50:10 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.22056153416633606, Train Loss: 0.22210201621055603
[32m[0511 23:50:10 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.2205645591020584, Train Loss: 0.2220993936061859
[32m[0511 23:50:10 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.22056755423545837, Train Loss: 0.2220967561006546
[32m[0511 23:50:10 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.22057056427001953, Train Loss: 0.22209413349628448
[32m[0511 23:50:10 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.2205735445022583, Train Loss: 0.22209148108959198
[32m[0511 23:50:11 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.22057656943798065, Train Loss: 0.22208884358406067
[32m[0511 23:50:11 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.22057951986789703, Train Loss: 0.22208623588085175
[32m[0511 23:50:11 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.2205825001001358, Train Loss: 0.22208361327648163
[32m[0511 23:50:11 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.22058548033237457, Train Loss: 0.2220809906721115
[32m[0511 23:50:11 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.22058844566345215, Train Loss: 0.2220783531665802
[32m[0511 23:50:11 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.22059139609336853, Train Loss: 0.22207573056221008
[32m[0511 23:50:11 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.2205943465232849, Train Loss: 0.22207309305667877
[32m[0511 23:50:11 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.2205972820520401, Train Loss: 0.22207047045230865
[32m[0511 23:50:11 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.2206002175807953, Train Loss: 0.22206789255142212
[32m[0511 23:50:11 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.22060315310955048, Train Loss: 0.2220652550458908
[32m[0511 23:50:11 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.22060605883598328, Train Loss: 0.22206264734268188
[32m[0511 23:50:11 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.22060897946357727, Train Loss: 0.22206000983715057
[32m[0511 23:50:11 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.22061191499233246, Train Loss: 0.22205740213394165
[32m[0511 23:50:11 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.22061477601528168, Train Loss: 0.22205482423305511
[32m[0511 23:50:11 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.22061768174171448, Train Loss: 0.2220521867275238
[32m[0511 23:50:11 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.22062060236930847, Train Loss: 0.22204957902431488
[32m[0511 23:50:11 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.22062347829341888, Train Loss: 0.22204700112342834
[32m[0511 23:50:11 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.2206263244152069, Train Loss: 0.22204433381557465
[32m[0511 23:50:11 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.22062921524047852, Train Loss: 0.2220418006181717
[32m[0511 23:50:11 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.22063207626342773, Train Loss: 0.22203917801380157
[32m[0511 23:50:11 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.22063493728637695, Train Loss: 0.22203655540943146
[32m[0511 23:50:11 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.22063779830932617, Train Loss: 0.22203394770622253
[32m[0511 23:50:11 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.22064067423343658, Train Loss: 0.2220313549041748
[32m[0511 23:50:11 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.22064350545406342, Train Loss: 0.2220287322998047
[32m[0511 23:50:11 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.22064632177352905, Train Loss: 0.22202613949775696
[32m[0511 23:50:11 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.22064915299415588, Train Loss: 0.22202354669570923
[32m[0511 23:50:11 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.22065198421478271, Train Loss: 0.2220209389925003
[32m[0511 23:50:11 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.22065481543540955, Train Loss: 0.22201834619045258
[32m[0511 23:50:12 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.22065763175487518, Train Loss: 0.22201578319072723
[32m[0511 23:50:12 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.22066043317317963, Train Loss: 0.22201316058635712
[32m[0511 23:50:12 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.22066323459148407, Train Loss: 0.2220105677843094
[32m[0511 23:50:12 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.2206660360097885, Train Loss: 0.22200796008110046
[32m[0511 23:50:12 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.22066880762577057, Train Loss: 0.22200536727905273
[32m[0511 23:50:12 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.220671609044075, Train Loss: 0.2220027893781662
[32m[0511 23:50:12 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.22067439556121826, Train Loss: 0.22200021147727966
[32m[0511 23:50:12 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.22067716717720032, Train Loss: 0.22199760377407074
[32m[0511 23:50:12 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.22067993879318237, Train Loss: 0.221995010972023
[32m[0511 23:50:12 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.22068271040916443, Train Loss: 0.22199241816997528
[32m[0511 23:50:12 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.2206854522228241, Train Loss: 0.22198982536792755
[32m[0511 23:50:12 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.22068820893764496, Train Loss: 0.2219872772693634
[32m[0511 23:50:12 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.22069098055362701, Train Loss: 0.22198466956615448
[32m[0511 23:50:12 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.22069373726844788, Train Loss: 0.22198209166526794
[32m[0511 23:50:12 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.22069644927978516, Train Loss: 0.22197946906089783
[32m[0511 23:50:12 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.22069919109344482, Train Loss: 0.22197690606117249
[32m[0511 23:50:12 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.2207019180059433, Train Loss: 0.22197434306144714
[32m[0511 23:50:12 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.22070464491844177, Train Loss: 0.22197173535823822
[32m[0511 23:50:12 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.22070737183094025, Train Loss: 0.22196915745735168
[32m[0511 23:50:12 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.22071008384227753, Train Loss: 0.22196654975414276
[32m[0511 23:50:12 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.2207127958536148, Train Loss: 0.22196397185325623
[32m[0511 23:50:12 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.2207154780626297, Train Loss: 0.2219613939523697
[32m[0511 23:50:12 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.22071820497512817, Train Loss: 0.22195884585380554
[32m[0511 23:50:12 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.22072090208530426, Train Loss: 0.2219562530517578
[32m[0511 23:50:12 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.22072359919548035, Train Loss: 0.2219536453485489
[32m[0511 23:50:12 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.22072629630565643, Train Loss: 0.22195105254650116
[32m[0511 23:50:12 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.22072896361351013, Train Loss: 0.22194848954677582
[32m[0511 23:50:12 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.22073161602020264, Train Loss: 0.22194591164588928
[32m[0511 23:50:13 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.22073429822921753, Train Loss: 0.22194334864616394
[32m[0511 23:50:13 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.22073695063591003, Train Loss: 0.2219407558441162
[32m[0511 23:50:13 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.22073964774608612, Train Loss: 0.22193817794322968
[32m[0511 23:50:13 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.22074231505393982, Train Loss: 0.22193560004234314
[32m[0511 23:50:13 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.22074496746063232, Train Loss: 0.2219330221414566
[32m[0511 23:50:13 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.22074761986732483, Train Loss: 0.22193045914173126
[32m[0511 23:50:13 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.22075024247169495, Train Loss: 0.22192786633968353
[32m[0511 23:50:13 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.22075290977954865, Train Loss: 0.2219252735376358
[32m[0511 23:50:13 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.22075553238391876, Train Loss: 0.22192271053791046
[32m[0511 23:50:13 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.22075818479061127, Train Loss: 0.22192011773586273
[32m[0511 23:50:13 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.220760777592659, Train Loss: 0.22191756963729858
[32m[0511 23:50:13 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.2207634150981903, Train Loss: 0.22191497683525085
[32m[0511 23:50:13 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.22076605260372162, Train Loss: 0.2219124138355255
[32m[0511 23:50:13 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.22076864540576935, Train Loss: 0.22190982103347778
[32m[0511 23:50:13 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.22077126801013947, Train Loss: 0.22190724313259125
[32m[0511 23:50:13 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.22077389061450958, Train Loss: 0.2219047099351883
[32m[0511 23:50:13 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.2207764983177185, Train Loss: 0.22190210223197937
[32m[0511 23:50:13 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.22077907621860504, Train Loss: 0.22189952433109283
[32m[0511 23:50:13 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.22078169882297516, Train Loss: 0.2218969613313675
[32m[0511 23:50:13 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.2207842469215393, Train Loss: 0.22189441323280334
[32m[0511 23:50:13 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.22078685462474823, Train Loss: 0.22189182043075562
[32m[0511 23:50:13 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.22078943252563477, Train Loss: 0.22188925743103027
[32m[0511 23:50:13 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.2207920402288437, Train Loss: 0.22188667953014374
[32m[0511 23:50:13 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.22079458832740784, Train Loss: 0.2218841016292572
[32m[0511 23:50:13 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.22079716622829437, Train Loss: 0.22188153862953186
[32m[0511 23:50:13 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.2207997590303421, Train Loss: 0.22187896072864532
[32m[0511 23:50:13 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.22080229222774506, Train Loss: 0.22187641263008118
[32m[0511 23:50:13 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.2208048552274704, Train Loss: 0.22187381982803345
[32m[0511 23:50:14 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.22080741822719574, Train Loss: 0.2218712419271469
[32m[0511 23:50:14 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.2208099514245987, Train Loss: 0.22186870872974396
[32m[0511 23:50:14 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.22081252932548523, Train Loss: 0.22186611592769623
[32m[0511 23:50:14 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.22081507742404938, Train Loss: 0.2218635529279709
[32m[0511 23:50:14 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.22081759572029114, Train Loss: 0.22186096012592316
[32m[0511 23:50:14 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.2208201140165329, Train Loss: 0.221858412027359
[32m[0511 23:50:14 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.22082267701625824, Train Loss: 0.22185583412647247
[32m[0511 23:50:14 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.2208251953125, Train Loss: 0.22185327112674713
[32m[0511 23:50:14 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.22082771360874176, Train Loss: 0.22185072302818298
[32m[0511 23:50:14 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.22083023190498352, Train Loss: 0.22184816002845764
[32m[0511 23:50:14 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.22083275020122528, Train Loss: 0.2218455821275711
[32m[0511 23:50:14 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.22083523869514465, Train Loss: 0.22184301912784576
[32m[0511 23:50:14 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.22083780169487, Train Loss: 0.22184045612812042
[32m[0511 23:50:14 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.22084027528762817, Train Loss: 0.22183789312839508
[32m[0511 23:50:14 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.22084277868270874, Train Loss: 0.22183531522750854
[32m[0511 23:50:14 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.2208452820777893, Train Loss: 0.221832737326622
[32m[0511 23:50:14 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.22084777057170868, Train Loss: 0.22183017432689667
[32m[0511 23:50:14 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.22085027396678925, Train Loss: 0.2218276411294937
[32m[0511 23:50:14 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.2208527773618698, Train Loss: 0.22182507812976837
[32m[0511 23:50:14 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.22085526585578918, Train Loss: 0.22182250022888184
[32m[0511 23:50:14 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.22085773944854736, Train Loss: 0.2218199372291565
[32m[0511 23:50:14 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.22086018323898315, Train Loss: 0.22181735932826996
[32m[0511 23:50:14 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.22086268663406372, Train Loss: 0.2218148112297058
[32m[0511 23:50:14 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.2208651602268219, Train Loss: 0.22181226313114166
[32m[0511 23:50:14 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.22086761891841888, Train Loss: 0.22180971503257751
[32m[0511 23:50:14 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.22087010741233826, Train Loss: 0.22180713713169098
[32m[0511 23:50:14 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.22087256610393524, Train Loss: 0.22180457413196564
[32m[0511 23:50:14 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.22087500989437103, Train Loss: 0.22180204093456268
[32m[0511 23:50:14 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.2208774834871292, Train Loss: 0.22179944813251495
[32m[0511 23:50:15 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.2208799123764038, Train Loss: 0.2217969000339508
[32m[0511 23:50:15 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.2208823710680008, Train Loss: 0.22179433703422546
[32m[0511 23:50:15 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.22088482975959778, Train Loss: 0.22179177403450012
[32m[0511 23:50:15 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.22088727355003357, Train Loss: 0.22178922593593597
[32m[0511 23:50:15 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.22088971734046936, Train Loss: 0.22178666293621063
[32m[0511 23:50:15 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.22089213132858276, Train Loss: 0.2217840999364853
[32m[0511 23:50:15 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.22089454531669617, Train Loss: 0.22178155183792114
[32m[0511 23:50:15 @mbmf_sampler.py:98][0m Finished 9th episode
[32m[0511 23:50:15 @mbmf_sampler.py:102][0m 1809 timesteps from 9 episodes collected
[32m[0512 00:11:19 @mbmf_trainer.py:160][0m Mean reward: -304.5778360070738
[32m[0512 00:11:19 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.20843307673931122, Train Loss: 0.22041650116443634
[32m[0512 00:11:19 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.2085222750902176, Train Loss: 0.2203359305858612
[32m[0512 00:11:19 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.20855079591274261, Train Loss: 0.22033420205116272
[32m[0512 00:11:19 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.20858857035636902, Train Loss: 0.22031369805335999
[32m[0512 00:11:19 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.20862261950969696, Train Loss: 0.2202986478805542
[32m[0512 00:11:19 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.208649143576622, Train Loss: 0.22028757631778717
[32m[0512 00:11:19 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.20867174863815308, Train Loss: 0.22027693688869476
[32m[0512 00:11:19 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.2086913138628006, Train Loss: 0.2202673703432083
[32m[0512 00:11:19 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.20870821177959442, Train Loss: 0.2202587127685547
[32m[0512 00:11:19 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.2087230235338211, Train Loss: 0.22025065124034882
[32m[0512 00:11:20 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.2087361365556717, Train Loss: 0.22024309635162354
[32m[0512 00:11:20 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.20874786376953125, Train Loss: 0.22023597359657288
[32m[0512 00:11:20 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.2087583988904953, Train Loss: 0.22022919356822968
[32m[0512 00:11:20 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.20876796543598175, Train Loss: 0.22022272646427155
[32m[0512 00:11:20 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.20877671241760254, Train Loss: 0.2202165275812149
[32m[0512 00:11:20 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.20878471434116364, Train Loss: 0.22021052241325378
[32m[0512 00:11:20 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.20879213511943817, Train Loss: 0.22020475566387177
[32m[0512 00:11:20 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.20879900455474854, Train Loss: 0.22019915282726288
[32m[0512 00:11:20 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.2088053971529007, Train Loss: 0.22019371390342712
[32m[0512 00:11:20 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.20881138741970062, Train Loss: 0.2201884239912033
[32m[0512 00:11:20 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.2088169902563095, Train Loss: 0.22018326818943024
[32m[0512 00:11:20 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.20882229506969452, Train Loss: 0.22017823159694672
[32m[0512 00:11:20 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.20882728695869446, Train Loss: 0.22017331421375275
[32m[0512 00:11:20 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.20883198082447052, Train Loss: 0.22016848623752594
[32m[0512 00:11:20 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.20883646607398987, Train Loss: 0.2201637476682663
[32m[0512 00:11:20 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.2088407576084137, Train Loss: 0.22015909850597382
[32m[0512 00:11:20 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.20884478092193604, Train Loss: 0.2201545685529709
[32m[0512 00:11:20 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.20884869992733002, Train Loss: 0.22015009820461273
[32m[0512 00:11:20 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.20885242521762848, Train Loss: 0.22014567255973816
[32m[0512 00:11:20 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.20885594189167023, Train Loss: 0.22014133632183075
[32m[0512 00:11:20 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.2088593691587448, Train Loss: 0.2201370745897293
[32m[0512 00:11:21 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.20886266231536865, Train Loss: 0.22013287246227264
[32m[0512 00:11:21 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.20886582136154175, Train Loss: 0.22012871503829956
[32m[0512 00:11:21 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.20886889100074768, Train Loss: 0.22012461721897125
[32m[0512 00:11:21 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.20887184143066406, Train Loss: 0.2201206088066101
[32m[0512 00:11:21 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.20887470245361328, Train Loss: 0.22011658549308777
[32m[0512 00:11:21 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.20887747406959534, Train Loss: 0.22011268138885498
[32m[0512 00:11:21 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.20888017117977142, Train Loss: 0.2201087325811386
[32m[0512 00:11:21 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.20888276398181915, Train Loss: 0.2201048880815506
[32m[0512 00:11:21 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.2088852971792221, Train Loss: 0.22010110318660736
[32m[0512 00:11:21 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.20888778567314148, Train Loss: 0.22009731829166412
[32m[0512 00:11:21 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.2088901847600937, Train Loss: 0.22009357810020447
[32m[0512 00:11:21 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.2088925540447235, Train Loss: 0.22008991241455078
[32m[0512 00:11:21 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.20889480412006378, Train Loss: 0.2200862467288971
[32m[0512 00:11:21 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.20889705419540405, Train Loss: 0.2200826108455658
[32m[0512 00:11:21 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.20889921486377716, Train Loss: 0.22007901966571808
[32m[0512 00:11:21 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.20890134572982788, Train Loss: 0.22007545828819275
[32m[0512 00:11:21 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.2089034467935562, Train Loss: 0.2200719118118286
[32m[0512 00:11:21 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.20890550315380096, Train Loss: 0.22006842494010925
[32m[0512 00:11:21 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.20890751481056213, Train Loss: 0.2200649380683899
[32m[0512 00:11:21 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.20890946686267853, Train Loss: 0.2200614959001541
[32m[0512 00:11:21 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.20891140401363373, Train Loss: 0.22005808353424072
[32m[0512 00:11:21 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.20891329646110535, Train Loss: 0.22005467116832733
[32m[0512 00:11:22 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.20891518890857697, Train Loss: 0.22005131840705872
[32m[0512 00:11:22 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.20891700685024261, Train Loss: 0.2200479805469513
[32m[0512 00:11:22 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.20891880989074707, Train Loss: 0.22004464268684387
[32m[0512 00:11:22 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.20892059803009033, Train Loss: 0.22004131972789764
[32m[0512 00:11:22 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.2089223563671112, Train Loss: 0.2200380563735962
[32m[0512 00:11:22 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.2089240700006485, Train Loss: 0.22003479301929474
[32m[0512 00:11:22 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.2089257687330246, Train Loss: 0.22003154456615448
[32m[0512 00:11:22 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.2089274823665619, Train Loss: 0.220028355717659
[32m[0512 00:11:22 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.2089291214942932, Train Loss: 0.22002510726451874
[32m[0512 00:11:22 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.20893077552318573, Train Loss: 0.22002191841602325
[32m[0512 00:11:22 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.20893238484859467, Train Loss: 0.22001874446868896
[32m[0512 00:11:22 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.2089339792728424, Train Loss: 0.22001560032367706
[32m[0512 00:11:22 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.20893552899360657, Train Loss: 0.22001247107982635
[32m[0512 00:11:22 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.2089371234178543, Train Loss: 0.22000935673713684
[32m[0512 00:11:22 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.20893867313861847, Train Loss: 0.22000624239444733
[32m[0512 00:11:22 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.20894019305706024, Train Loss: 0.2200031578540802
[32m[0512 00:11:22 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.20894171297550201, Train Loss: 0.22000008821487427
[32m[0512 00:11:22 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.2089432179927826, Train Loss: 0.21999700367450714
[32m[0512 00:11:22 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.2089446783065796, Train Loss: 0.2199939638376236
[32m[0512 00:11:22 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.20894615352153778, Train Loss: 0.21999092400074005
[32m[0512 00:11:22 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.20894762873649597, Train Loss: 0.2199878990650177
[32m[0512 00:11:22 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.20894907414913177, Train Loss: 0.21998488903045654
[32m[0512 00:11:22 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.20895051956176758, Train Loss: 0.2199818640947342
[32m[0512 00:11:22 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.2089518904685974, Train Loss: 0.21997888386249542
[32m[0512 00:11:23 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.20895332098007202, Train Loss: 0.21997591853141785
[32m[0512 00:11:23 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.20895470678806305, Train Loss: 0.21997293829917908
[32m[0512 00:11:23 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.20895609259605408, Train Loss: 0.2199700027704239
[32m[0512 00:11:23 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.2089574784040451, Train Loss: 0.2199670374393463
[32m[0512 00:11:23 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.20895883440971375, Train Loss: 0.21996410191059113
[32m[0512 00:11:23 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.20896020531654358, Train Loss: 0.21996119618415833
[32m[0512 00:11:23 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.20896151661872864, Train Loss: 0.21995826065540314
[32m[0512 00:11:23 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.20896288752555847, Train Loss: 0.21995536983013153
[32m[0512 00:11:23 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.20896419882774353, Train Loss: 0.21995246410369873
[32m[0512 00:11:23 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.20896552503108978, Train Loss: 0.21994957327842712
[32m[0512 00:11:23 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.20896686613559723, Train Loss: 0.2199467122554779
[32m[0512 00:11:23 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.2089681774377823, Train Loss: 0.2199438214302063
[32m[0512 00:11:23 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.20896945893764496, Train Loss: 0.21994096040725708
[32m[0512 00:11:23 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.20897074043750763, Train Loss: 0.21993809938430786
[32m[0512 00:11:23 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.2089720368385315, Train Loss: 0.21993523836135864
[32m[0512 00:11:23 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.20897331833839417, Train Loss: 0.2199324071407318
[32m[0512 00:11:23 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.20897458493709564, Train Loss: 0.21992957592010498
[32m[0512 00:11:23 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.2089758664369583, Train Loss: 0.21992675960063934
[32m[0512 00:11:23 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.2089771181344986, Train Loss: 0.2199239283800125
[32m[0512 00:11:23 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.20897836983203888, Train Loss: 0.21992111206054688
[32m[0512 00:11:23 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.20897963643074036, Train Loss: 0.21991829574108124
[32m[0512 00:11:24 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.20898088812828064, Train Loss: 0.2199154943227768
[32m[0512 00:11:24 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.20898213982582092, Train Loss: 0.21991272270679474
[32m[0512 00:11:24 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.20898336172103882, Train Loss: 0.2199099212884903
[32m[0512 00:11:24 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.2089845985174179, Train Loss: 0.21990716457366943
[32m[0512 00:11:24 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.2089858204126358, Train Loss: 0.21990437805652618
[32m[0512 00:11:24 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.2089870423078537, Train Loss: 0.21990159153938293
[32m[0512 00:11:24 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.2089882791042328, Train Loss: 0.21989881992340088
[32m[0512 00:11:24 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.20898950099945068, Train Loss: 0.21989606320858002
[32m[0512 00:11:24 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.20899072289466858, Train Loss: 0.21989330649375916
[32m[0512 00:11:24 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.20899194478988647, Train Loss: 0.2198905646800995
[32m[0512 00:11:24 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.20899315178394318, Train Loss: 0.219887837767601
[32m[0512 00:11:24 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.20899434387683868, Train Loss: 0.21988506615161896
[32m[0512 00:11:24 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.20899556577205658, Train Loss: 0.21988233923912048
[32m[0512 00:11:24 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.2089967578649521, Train Loss: 0.2198796272277832
[32m[0512 00:11:24 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.2089979648590088, Train Loss: 0.21987691521644592
[32m[0512 00:11:24 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.2089991569519043, Train Loss: 0.21987418830394745
[32m[0512 00:11:24 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.2090003490447998, Train Loss: 0.21987147629261017
[32m[0512 00:11:24 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.2090015560388565, Train Loss: 0.2198687344789505
[32m[0512 00:11:24 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.20900274813175201, Train Loss: 0.2198660522699356
[32m[0512 00:11:24 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.20900394022464752, Train Loss: 0.21986334025859833
[32m[0512 00:11:24 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.20900511741638184, Train Loss: 0.21986065804958344
[32m[0512 00:11:24 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.20900630950927734, Train Loss: 0.21985794603824615
[32m[0512 00:11:25 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.20900750160217285, Train Loss: 0.21985526382923126
[32m[0512 00:11:25 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.20900869369506836, Train Loss: 0.21985255181789398
[32m[0512 00:11:25 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.20900985598564148, Train Loss: 0.21984988451004028
[32m[0512 00:11:25 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.209011048078537, Train Loss: 0.2198472023010254
[32m[0512 00:11:25 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.2090122252702713, Train Loss: 0.2198445200920105
[32m[0512 00:11:25 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.20901340246200562, Train Loss: 0.2198418378829956
[32m[0512 00:11:25 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.20901456475257874, Train Loss: 0.2198392003774643
[32m[0512 00:11:25 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.20901577174663544, Train Loss: 0.2198365181684494
[32m[0512 00:11:25 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.20901694893836975, Train Loss: 0.2198338508605957
[32m[0512 00:11:25 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.20901811122894287, Train Loss: 0.219831183552742
[32m[0512 00:11:25 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.20901930332183838, Train Loss: 0.2198285609483719
[32m[0512 00:11:25 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.20902051031589508, Train Loss: 0.2198258638381958
[32m[0512 00:11:25 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.2090216875076294, Train Loss: 0.21982324123382568
[32m[0512 00:11:25 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.2090228646993637, Train Loss: 0.21982057392597198
[32m[0512 00:11:25 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.20902404189109802, Train Loss: 0.21981793642044067
[32m[0512 00:11:25 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.20902520418167114, Train Loss: 0.21981529891490936
[32m[0512 00:11:25 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.20902638137340546, Train Loss: 0.21981267631053925
[32m[0512 00:11:25 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.20902755856513977, Train Loss: 0.21981003880500793
[32m[0512 00:11:25 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.20902875065803528, Train Loss: 0.21980737149715424
[32m[0512 00:11:25 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.20902997255325317, Train Loss: 0.21980473399162292
[32m[0512 00:11:25 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.2090311199426651, Train Loss: 0.219802126288414
[32m[0512 00:11:25 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.2090323269367218, Train Loss: 0.21979951858520508
[32m[0512 00:11:25 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.2090335190296173, Train Loss: 0.21979685127735138
[32m[0512 00:11:26 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.20903468132019043, Train Loss: 0.21979424357414246
[32m[0512 00:11:26 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.20903587341308594, Train Loss: 0.21979163587093353
[32m[0512 00:11:26 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.20903706550598145, Train Loss: 0.2197890281677246
[32m[0512 00:11:26 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.20903825759887695, Train Loss: 0.2197863906621933
[32m[0512 00:11:26 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.20903944969177246, Train Loss: 0.21978381276130676
[32m[0512 00:11:26 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.20904062688350677, Train Loss: 0.21978117525577545
[32m[0512 00:11:26 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.20904181897640228, Train Loss: 0.21977858245372772
[32m[0512 00:11:26 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.20904304087162018, Train Loss: 0.2197759747505188
[32m[0512 00:11:26 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.2090442031621933, Train Loss: 0.21977336704730988
[32m[0512 00:11:26 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.20904541015625, Train Loss: 0.21977075934410095
[32m[0512 00:11:26 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.2090466320514679, Train Loss: 0.21976816654205322
[32m[0512 00:11:26 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.2090478241443634, Train Loss: 0.2197655886411667
[32m[0512 00:11:26 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.2090490162372589, Train Loss: 0.21976299583911896
[32m[0512 00:11:26 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.2090502381324768, Train Loss: 0.21976038813591003
[32m[0512 00:11:26 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.2090514451265335, Train Loss: 0.2197578102350235
[32m[0512 00:11:26 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.20905263721942902, Train Loss: 0.21975521743297577
[32m[0512 00:11:26 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.20905384421348572, Train Loss: 0.21975260972976685
[32m[0512 00:11:26 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.2090550661087036, Train Loss: 0.2197500318288803
[32m[0512 00:11:26 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.2090563029050827, Train Loss: 0.21974743902683258
[32m[0512 00:11:26 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.2090575098991394, Train Loss: 0.21974487602710724
[32m[0512 00:11:26 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.2090587466955185, Train Loss: 0.2197422981262207
[32m[0512 00:11:27 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.2090599536895752, Train Loss: 0.21973972022533417
[32m[0512 00:11:27 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.2090611755847931, Train Loss: 0.21973715722560883
[32m[0512 00:11:27 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.20906242728233337, Train Loss: 0.2197345644235611
[32m[0512 00:11:27 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.20906364917755127, Train Loss: 0.21973198652267456
[32m[0512 00:11:27 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.20906487107276917, Train Loss: 0.21972942352294922
[32m[0512 00:11:27 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.20906610786914825, Train Loss: 0.21972684562206268
[32m[0512 00:11:27 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.20906734466552734, Train Loss: 0.21972428262233734
[32m[0512 00:11:27 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.20906861126422882, Train Loss: 0.219721719622612
[32m[0512 00:11:27 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.20906983315944672, Train Loss: 0.21971912682056427
[32m[0512 00:11:27 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.2090710699558258, Train Loss: 0.21971657872200012
[32m[0512 00:11:27 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.2090723067522049, Train Loss: 0.21971401572227478
[32m[0512 00:11:27 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.20907357335090637, Train Loss: 0.21971145272254944
[32m[0512 00:11:27 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.20907481014728546, Train Loss: 0.2197088748216629
[32m[0512 00:11:27 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.20907610654830933, Train Loss: 0.21970631182193756
[32m[0512 00:11:27 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.2090773582458496, Train Loss: 0.21970374882221222
[32m[0512 00:11:27 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.2090786099433899, Train Loss: 0.21970121562480927
[32m[0512 00:11:27 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.20907989144325256, Train Loss: 0.21969865262508392
[32m[0512 00:11:27 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.20908115804195404, Train Loss: 0.21969608962535858
[32m[0512 00:11:27 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.2090824395418167, Train Loss: 0.21969354152679443
[32m[0512 00:11:27 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.2090837061405182, Train Loss: 0.21969099342823029
[32m[0512 00:11:27 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.20908498764038086, Train Loss: 0.21968844532966614
[32m[0512 00:11:27 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.20908623933792114, Train Loss: 0.2196858823299408
[32m[0512 00:11:28 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.2090875506401062, Train Loss: 0.21968331933021545
[32m[0512 00:11:28 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.20908886194229126, Train Loss: 0.2196807861328125
[32m[0512 00:11:28 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.20909014344215393, Train Loss: 0.21967825293540955
[32m[0512 00:11:28 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.2090914249420166, Train Loss: 0.2196756899356842
[32m[0512 00:11:28 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.20909273624420166, Train Loss: 0.21967315673828125
[32m[0512 00:11:28 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.20909403264522552, Train Loss: 0.2196706235408783
[32m[0512 00:11:28 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.2090953290462494, Train Loss: 0.21966809034347534
[32m[0512 00:11:28 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.20909665524959564, Train Loss: 0.21966552734375
[32m[0512 00:11:28 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.2090979814529419, Train Loss: 0.21966299414634705
[32m[0512 00:11:28 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.20909927785396576, Train Loss: 0.2196604609489441
[32m[0512 00:11:28 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.20910058915615082, Train Loss: 0.21965789794921875
[32m[0512 00:11:28 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.20910193026065826, Train Loss: 0.2196553647518158
[32m[0512 00:11:28 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.20910325646400452, Train Loss: 0.21965283155441284
[32m[0512 00:11:28 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.20910456776618958, Train Loss: 0.2196502983570099
[32m[0512 00:11:28 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.20910590887069702, Train Loss: 0.21964776515960693
[32m[0512 00:11:28 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.20910726487636566, Train Loss: 0.21964521706104279
[32m[0512 00:11:28 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.20910859107971191, Train Loss: 0.21964268386363983
[32m[0512 00:11:28 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.20910994708538055, Train Loss: 0.21964018046855927
[32m[0512 00:11:28 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.209111288189888, Train Loss: 0.21963761746883392
[32m[0512 00:11:28 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.20911264419555664, Train Loss: 0.21963508427143097
[32m[0512 00:11:28 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.20911403000354767, Train Loss: 0.2196325808763504
[32m[0512 00:11:28 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.20911535620689392, Train Loss: 0.21963004767894745
[32m[0512 00:11:28 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.20911674201488495, Train Loss: 0.2196275293827057
[32m[0512 00:11:29 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.20911811292171478, Train Loss: 0.21962496638298035
[32m[0512 00:11:29 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.20911946892738342, Train Loss: 0.21962246298789978
[32m[0512 00:11:29 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.20912086963653564, Train Loss: 0.21961992979049683
[32m[0512 00:11:29 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.20912225544452667, Train Loss: 0.21961739659309387
[32m[0512 00:11:29 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.2091236263513565, Train Loss: 0.21961486339569092
[32m[0512 00:11:29 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.20912501215934753, Train Loss: 0.21961234509944916
[32m[0512 00:11:29 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.20912641286849976, Train Loss: 0.2196098417043686
[32m[0512 00:11:29 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.20912781357765198, Train Loss: 0.21960730850696564
[32m[0512 00:11:29 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.2091292291879654, Train Loss: 0.21960477530956268
[32m[0512 00:11:29 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.20913061499595642, Train Loss: 0.21960225701332092
[32m[0512 00:11:29 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.20913203060626984, Train Loss: 0.21959975361824036
[32m[0512 00:11:29 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.20913343131542206, Train Loss: 0.2195972353219986
[32m[0512 00:11:29 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.20913487672805786, Train Loss: 0.21959467232227325
[32m[0512 00:11:29 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.20913629233837128, Train Loss: 0.21959219872951508
[32m[0512 00:11:29 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.2091377079486847, Train Loss: 0.21958966553211212
[32m[0512 00:11:29 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.2091391533613205, Train Loss: 0.21958714723587036
[32m[0512 00:11:29 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.2091405987739563, Train Loss: 0.2195846140384674
[32m[0512 00:11:29 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.20914201438426971, Train Loss: 0.21958211064338684
[32m[0512 00:11:29 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.20914345979690552, Train Loss: 0.2195795774459839
[32m[0512 00:11:29 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.2091449350118637, Train Loss: 0.21957705914974213
[32m[0512 00:11:29 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.2091463804244995, Train Loss: 0.21957455575466156
[32m[0512 00:11:29 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.20914782583713531, Train Loss: 0.2195720225572586
[32m[0512 00:11:29 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.2091492861509323, Train Loss: 0.21956953406333923
[32m[0512 00:11:30 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.2091507464647293, Train Loss: 0.21956700086593628
[32m[0512 00:11:30 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.2091522365808487, Train Loss: 0.21956448256969452
[32m[0512 00:11:30 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.20915371179580688, Train Loss: 0.21956197917461395
[32m[0512 00:11:30 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.20915518701076508, Train Loss: 0.2195594757795334
[32m[0512 00:11:30 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.20915666222572327, Train Loss: 0.21955692768096924
[32m[0512 00:11:30 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.20915813744068146, Train Loss: 0.21955439448356628
[32m[0512 00:11:30 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.20915964245796204, Train Loss: 0.2195519208908081
[32m[0512 00:11:30 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.20916111767292023, Train Loss: 0.21954940259456635
[32m[0512 00:11:30 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.209162637591362, Train Loss: 0.21954689919948578
[32m[0512 00:11:30 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.20916415750980377, Train Loss: 0.21954438090324402
[32m[0512 00:11:30 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.20916564762592316, Train Loss: 0.21954184770584106
[32m[0512 00:11:30 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.20916716754436493, Train Loss: 0.2195393443107605
[32m[0512 00:11:30 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.2091687023639679, Train Loss: 0.21953685581684113
[32m[0512 00:11:30 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.20917022228240967, Train Loss: 0.21953435242176056
[32m[0512 00:11:30 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.20917175710201263, Train Loss: 0.2195318341255188
[32m[0512 00:11:30 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.2091732770204544, Train Loss: 0.21952930092811584
[32m[0512 00:11:30 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.20917481184005737, Train Loss: 0.21952681243419647
[32m[0512 00:11:30 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.20917636156082153, Train Loss: 0.2195243090391159
[32m[0512 00:11:30 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.2091779261827469, Train Loss: 0.21952177584171295
[32m[0512 00:11:30 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.20917949080467224, Train Loss: 0.2195192575454712
[32m[0512 00:11:30 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.209181010723114, Train Loss: 0.219516783952713
[32m[0512 00:11:31 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.20918257534503937, Train Loss: 0.21951425075531006
[32m[0512 00:11:31 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.20918413996696472, Train Loss: 0.21951176226139069
[32m[0512 00:11:31 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.20918571949005127, Train Loss: 0.21950924396514893
[32m[0512 00:11:31 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.20918729901313782, Train Loss: 0.21950674057006836
[32m[0512 00:11:31 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.20918889343738556, Train Loss: 0.2195042371749878
[32m[0512 00:11:31 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.2091904580593109, Train Loss: 0.21950171887874603
[32m[0512 00:11:31 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.20919205248355865, Train Loss: 0.21949921548366547
[32m[0512 00:11:31 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.2091936469078064, Train Loss: 0.2194966971874237
[32m[0512 00:11:31 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.20919524133205414, Train Loss: 0.21949419379234314
[32m[0512 00:11:31 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.20919685065746307, Train Loss: 0.21949170529842377
[32m[0512 00:11:31 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.2091984748840332, Train Loss: 0.2194891721010208
[32m[0512 00:11:31 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.20920008420944214, Train Loss: 0.21948666870594025
[32m[0512 00:11:31 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.20920169353485107, Train Loss: 0.21948418021202087
[32m[0512 00:11:31 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.2092033326625824, Train Loss: 0.2194816619157791
[32m[0512 00:11:31 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.20920495688915253, Train Loss: 0.21947915852069855
[32m[0512 00:11:31 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.20920661091804504, Train Loss: 0.21947665512561798
[32m[0512 00:11:31 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.20920823514461517, Train Loss: 0.21947413682937622
[32m[0512 00:11:31 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.2092098742723465, Train Loss: 0.21947163343429565
[32m[0512 00:11:31 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.209211528301239, Train Loss: 0.21946914494037628
[32m[0512 00:11:31 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.20921316742897034, Train Loss: 0.21946664154529572
[32m[0512 00:11:31 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.20921483635902405, Train Loss: 0.21946410834789276
[32m[0512 00:11:31 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.20921649038791656, Train Loss: 0.2194616198539734
[32m[0512 00:11:32 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.20921815931797028, Train Loss: 0.21945910155773163
[32m[0512 00:11:32 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.20921984314918518, Train Loss: 0.21945659816265106
[32m[0512 00:11:32 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.2092215120792389, Train Loss: 0.2194540947675705
[32m[0512 00:11:32 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.2092231959104538, Train Loss: 0.21945157647132874
[32m[0512 00:11:32 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.2092248946428299, Train Loss: 0.21944908797740936
[32m[0512 00:11:32 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.2092265486717224, Train Loss: 0.2194465845823288
[32m[0512 00:11:32 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.2092282772064209, Train Loss: 0.21944408118724823
[32m[0512 00:11:32 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.2092299610376358, Train Loss: 0.21944156289100647
[32m[0512 00:11:32 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.2092316746711731, Train Loss: 0.2194390594959259
[32m[0512 00:11:32 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.20923340320587158, Train Loss: 0.21943654119968414
[32m[0512 00:11:32 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.2092350870370865, Train Loss: 0.21943406760692596
[32m[0512 00:11:32 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.20923681557178497, Train Loss: 0.21943151950836182
[32m[0512 00:11:32 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.20923855900764465, Train Loss: 0.21942904591560364
[32m[0512 00:11:32 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.20924028754234314, Train Loss: 0.21942652761936188
[32m[0512 00:11:32 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.209242045879364, Train Loss: 0.2194240242242813
[32m[0512 00:11:32 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.2092437893152237, Train Loss: 0.21942150592803955
[32m[0512 00:11:32 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.20924553275108337, Train Loss: 0.21941903233528137
[32m[0512 00:11:32 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.20924726128578186, Train Loss: 0.2194165140390396
[32m[0512 00:11:32 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.20924901962280273, Train Loss: 0.21941401064395905
[32m[0512 00:11:32 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.2092507779598236, Train Loss: 0.21941149234771729
[32m[0512 00:11:32 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.20925253629684448, Train Loss: 0.21940898895263672
[32m[0512 00:11:32 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.20925433933734894, Train Loss: 0.21940650045871735
[32m[0512 00:11:33 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.209256112575531, Train Loss: 0.2194039672613144
[32m[0512 00:11:33 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.20925790071487427, Train Loss: 0.21940147876739502
[32m[0512 00:11:33 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.20925967395305634, Train Loss: 0.21939897537231445
[32m[0512 00:11:33 @mbmf_sampler.py:98][0m Finished 9th episode
[32m[0512 00:11:33 @mbmf_sampler.py:102][0m 1809 timesteps from 9 episodes collected
[32m[0512 00:32:37 @mbmf_trainer.py:160][0m Mean reward: -319.7960640373119
[32m[0512 00:32:37 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.21309036016464233, Train Loss: 0.21815022826194763
[32m[0512 00:32:37 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.2130763977766037, Train Loss: 0.2181011289358139
[32m[0512 00:32:37 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.21309493482112885, Train Loss: 0.21809744834899902
[32m[0512 00:32:37 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.2131069153547287, Train Loss: 0.21807998418807983
[32m[0512 00:32:37 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.21311771869659424, Train Loss: 0.21806813776493073
[32m[0512 00:32:37 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.21312837302684784, Train Loss: 0.21805758774280548
[32m[0512 00:32:37 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.2131374180316925, Train Loss: 0.21804779767990112
[32m[0512 00:32:37 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.2131456434726715, Train Loss: 0.21803884208202362
[32m[0512 00:32:37 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.2131531536579132, Train Loss: 0.21803046762943268
[32m[0512 00:32:37 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.21316014230251312, Train Loss: 0.21802262961864471
[32m[0512 00:32:37 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.21316662430763245, Train Loss: 0.21801519393920898
[32m[0512 00:32:38 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.21317273378372192, Train Loss: 0.2180081307888031
[32m[0512 00:32:38 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.21317845582962036, Train Loss: 0.2180013805627823
[32m[0512 00:32:38 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.2131839245557785, Train Loss: 0.21799488365650177
[32m[0512 00:32:38 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.21318916976451874, Train Loss: 0.21798864006996155
[32m[0512 00:32:38 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.21319420635700226, Train Loss: 0.21798259019851685
[32m[0512 00:32:38 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.21319910883903503, Train Loss: 0.21797671914100647
[32m[0512 00:32:38 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.21320386230945587, Train Loss: 0.2179710417985916
[32m[0512 00:32:38 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.21320846676826477, Train Loss: 0.2179654985666275
[32m[0512 00:32:38 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.21321304142475128, Train Loss: 0.21796007454395294
[32m[0512 00:32:38 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.21321745216846466, Train Loss: 0.2179548144340515
[32m[0512 00:32:38 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.21322183310985565, Train Loss: 0.21794962882995605
[32m[0512 00:32:38 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.21322619915008545, Train Loss: 0.21794460713863373
[32m[0512 00:32:38 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.21323053538799286, Train Loss: 0.21793963015079498
[32m[0512 00:32:38 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.2132348120212555, Train Loss: 0.2179347574710846
[32m[0512 00:32:38 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.21323907375335693, Train Loss: 0.21792998909950256
[32m[0512 00:32:38 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.21324332058429718, Train Loss: 0.2179252654314041
[32m[0512 00:32:38 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.21324755251407623, Train Loss: 0.2179206758737564
[32m[0512 00:32:38 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.2132517695426941, Train Loss: 0.21791614592075348
[32m[0512 00:32:38 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.21325603127479553, Train Loss: 0.21791167557239532
[32m[0512 00:32:38 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.2132602334022522, Train Loss: 0.21790727972984314
[32m[0512 00:32:39 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.21326445043087006, Train Loss: 0.21790291368961334
[32m[0512 00:32:39 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.21326875686645508, Train Loss: 0.2178986519575119
[32m[0512 00:32:39 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.21327300369739532, Train Loss: 0.21789437532424927
[32m[0512 00:32:39 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.21327728033065796, Train Loss: 0.217890202999115
[32m[0512 00:32:39 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.21328160166740417, Train Loss: 0.2178860604763031
[32m[0512 00:32:39 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.2132858783006668, Train Loss: 0.21788200736045837
[32m[0512 00:32:39 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.21329021453857422, Train Loss: 0.21787796914577484
[32m[0512 00:32:39 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.21329455077648163, Train Loss: 0.2178739607334137
[32m[0512 00:32:39 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.21329891681671143, Train Loss: 0.21787001192569733
[32m[0512 00:32:39 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.2133033275604248, Train Loss: 0.21786612272262573
[32m[0512 00:32:39 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.2133077085018158, Train Loss: 0.21786221861839294
[32m[0512 00:32:39 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.21331213414669037, Train Loss: 0.2178584188222885
[32m[0512 00:32:39 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.21331657469272614, Train Loss: 0.21785463392734528
[32m[0512 00:32:39 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.21332105994224548, Train Loss: 0.21785083413124084
[32m[0512 00:32:39 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.21332551538944244, Train Loss: 0.21784710884094238
[32m[0512 00:32:39 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.21333001554012299, Train Loss: 0.21784347295761108
[32m[0512 00:32:39 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.21333453059196472, Train Loss: 0.217839777469635
[32m[0512 00:32:39 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.21333906054496765, Train Loss: 0.2178361564874649
[32m[0512 00:32:39 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.21334367990493774, Train Loss: 0.2178325653076172
[32m[0512 00:32:40 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.21334823966026306, Train Loss: 0.21782898902893066
[32m[0512 00:32:40 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.21335284411907196, Train Loss: 0.21782545745372772
[32m[0512 00:32:40 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.21335744857788086, Train Loss: 0.21782192587852478
[32m[0512 00:32:40 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.21336208283901215, Train Loss: 0.2178184539079666
[32m[0512 00:32:40 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.21336673200130463, Train Loss: 0.21781498193740845
[32m[0512 00:32:40 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.2133714109659195, Train Loss: 0.21781153976917267
[32m[0512 00:32:40 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.21337606012821198, Train Loss: 0.21780814230442047
[32m[0512 00:32:40 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.21338079869747162, Train Loss: 0.21780472993850708
[32m[0512 00:32:40 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.21338549256324768, Train Loss: 0.21780134737491608
[32m[0512 00:32:40 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.21339021623134613, Train Loss: 0.21779800951480865
[32m[0512 00:32:40 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.21339495480060577, Train Loss: 0.21779467165470123
[32m[0512 00:32:40 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.2133997231721878, Train Loss: 0.2177913784980774
[32m[0512 00:32:40 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.21340452134609222, Train Loss: 0.21778811514377594
[32m[0512 00:32:40 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.21340924501419067, Train Loss: 0.2177848368883133
[32m[0512 00:32:40 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.2134140580892563, Train Loss: 0.21778158843517303
[32m[0512 00:32:40 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.2134188711643219, Train Loss: 0.21777833998203278
[32m[0512 00:32:40 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.2134236842393875, Train Loss: 0.2177751213312149
[32m[0512 00:32:40 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.21342849731445312, Train Loss: 0.2177719622850418
[32m[0512 00:32:40 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.21343335509300232, Train Loss: 0.21776872873306274
[32m[0512 00:32:40 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.21343818306922913, Train Loss: 0.21776558458805084
[32m[0512 00:32:41 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.21344302594661713, Train Loss: 0.21776247024536133
[32m[0512 00:32:41 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.21344789862632751, Train Loss: 0.21775932610034943
[32m[0512 00:32:41 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.2134527713060379, Train Loss: 0.2177562117576599
[32m[0512 00:32:41 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.21345767378807068, Train Loss: 0.21775312721729279
[32m[0512 00:32:41 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.21346254646778107, Train Loss: 0.21775002777576447
[32m[0512 00:32:41 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.21346741914749146, Train Loss: 0.21774695813655853
[32m[0512 00:32:41 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.21347235143184662, Train Loss: 0.2177438884973526
[32m[0512 00:32:41 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.2134772390127182, Train Loss: 0.21774086356163025
[32m[0512 00:32:41 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.21348217129707336, Train Loss: 0.2177378088235855
[32m[0512 00:32:41 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.21348705887794495, Train Loss: 0.21773481369018555
[32m[0512 00:32:41 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.2134920060634613, Train Loss: 0.2177318036556244
[32m[0512 00:32:41 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.21349690854549408, Train Loss: 0.21772883832454681
[32m[0512 00:32:41 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.21350184082984924, Train Loss: 0.21772585809230804
[32m[0512 00:32:41 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.2135068029165268, Train Loss: 0.21772289276123047
[32m[0512 00:32:41 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.21351173520088196, Train Loss: 0.2177199274301529
[32m[0512 00:32:41 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.21351668238639832, Train Loss: 0.21771694719791412
[32m[0512 00:32:41 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.21352162957191467, Train Loss: 0.21771402657032013
[32m[0512 00:32:41 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.21352657675743103, Train Loss: 0.21771112084388733
[32m[0512 00:32:41 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.2135315239429474, Train Loss: 0.21770820021629333
[32m[0512 00:32:42 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.21353647112846375, Train Loss: 0.21770530939102173
[32m[0512 00:32:42 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.2135414332151413, Train Loss: 0.21770240366458893
[32m[0512 00:32:42 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.21354641020298004, Train Loss: 0.21769952774047852
[32m[0512 00:32:42 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.2135513573884964, Train Loss: 0.2176966667175293
[32m[0512 00:32:42 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.21355633437633514, Train Loss: 0.21769382059574127
[32m[0512 00:32:42 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.2135612964630127, Train Loss: 0.21769098937511444
[32m[0512 00:32:42 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.21356624364852905, Train Loss: 0.21768809854984283
[32m[0512 00:32:42 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.2135712206363678, Train Loss: 0.21768532693386078
[32m[0512 00:32:42 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.21357619762420654, Train Loss: 0.21768249571323395
[32m[0512 00:32:42 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.21358118951320648, Train Loss: 0.2176796793937683
[32m[0512 00:32:42 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.21358613669872284, Train Loss: 0.21767686307430267
[32m[0512 00:32:42 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.21359111368656158, Train Loss: 0.21767407655715942
[32m[0512 00:32:42 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.21359606087207794, Train Loss: 0.2176712602376938
[32m[0512 00:32:42 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.21360105276107788, Train Loss: 0.21766851842403412
[32m[0512 00:32:42 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.21360602974891663, Train Loss: 0.21766576170921326
[32m[0512 00:32:42 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.21361097693443298, Train Loss: 0.2176629602909088
[32m[0512 00:32:42 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.21361596882343292, Train Loss: 0.21766020357608795
[32m[0512 00:32:42 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.21362091600894928, Train Loss: 0.21765747666358948
[32m[0512 00:32:42 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.21362586319446564, Train Loss: 0.217654749751091
[32m[0512 00:32:42 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.21363084018230438, Train Loss: 0.21765199303627014
[32m[0512 00:32:42 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.21363580226898193, Train Loss: 0.21764928102493286
[32m[0512 00:32:43 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.21364080905914307, Train Loss: 0.2176465541124344
[32m[0512 00:32:43 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.21364575624465942, Train Loss: 0.2176438421010971
[32m[0512 00:32:43 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.2136506736278534, Train Loss: 0.21764113008975983
[32m[0512 00:32:43 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.21365565061569214, Train Loss: 0.21763843297958374
[32m[0512 00:32:43 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.2136605978012085, Train Loss: 0.21763576567173004
[32m[0512 00:32:43 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.21366555988788605, Train Loss: 0.21763309836387634
[32m[0512 00:32:43 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.2136705070734024, Train Loss: 0.21763038635253906
[32m[0512 00:32:43 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.21367545425891876, Train Loss: 0.21762774884700775
[32m[0512 00:32:43 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.21368040144443512, Train Loss: 0.21762505173683167
[32m[0512 00:32:43 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.2136853039264679, Train Loss: 0.21762242913246155
[32m[0512 00:32:43 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.21369028091430664, Train Loss: 0.21761976182460785
[32m[0512 00:32:43 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.2136951982975006, Train Loss: 0.21761709451675415
[32m[0512 00:32:43 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.21370014548301697, Train Loss: 0.21761445701122284
[32m[0512 00:32:43 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.21370507776737213, Train Loss: 0.21761183440685272
[32m[0512 00:32:43 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.2137099951505661, Train Loss: 0.2176092118024826
[32m[0512 00:32:43 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.21371491253376007, Train Loss: 0.2176065593957901
[32m[0512 00:32:43 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.21371984481811523, Train Loss: 0.21760396659374237
[32m[0512 00:32:43 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.2137247920036316, Train Loss: 0.21760135889053345
[32m[0512 00:32:43 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.21372967958450317, Train Loss: 0.21759876608848572
[32m[0512 00:32:43 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.21373458206653595, Train Loss: 0.2175961583852768
[32m[0512 00:32:44 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.2137395143508911, Train Loss: 0.21759353578090668
[32m[0512 00:32:44 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.21374443173408508, Train Loss: 0.21759095788002014
[32m[0512 00:32:44 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.21374930441379547, Train Loss: 0.2175883799791336
[32m[0512 00:32:44 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.21375420689582825, Train Loss: 0.21758581697940826
[32m[0512 00:32:44 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.21375910937786102, Train Loss: 0.21758322417736053
[32m[0512 00:32:44 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.2137639820575714, Train Loss: 0.2175806611776352
[32m[0512 00:32:44 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.2137688547372818, Train Loss: 0.21757808327674866
[32m[0512 00:32:44 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.2137737274169922, Train Loss: 0.2175755351781845
[32m[0512 00:32:44 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.21377862989902496, Train Loss: 0.21757297217845917
[32m[0512 00:32:44 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.21378351747989655, Train Loss: 0.21757040917873383
[32m[0512 00:32:44 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.21378834545612335, Train Loss: 0.21756787598133087
[32m[0512 00:32:44 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.21379321813583374, Train Loss: 0.21756534278392792
[32m[0512 00:32:44 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.21379809081554413, Train Loss: 0.21756280958652496
[32m[0512 00:32:44 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.21380296349525452, Train Loss: 0.217560276389122
[32m[0512 00:32:44 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.21380779147148132, Train Loss: 0.21755772829055786
[32m[0512 00:32:44 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.21381261944770813, Train Loss: 0.2175552248954773
[32m[0512 00:32:44 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.21381744742393494, Train Loss: 0.21755270659923553
[32m[0512 00:32:44 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.21382232010364532, Train Loss: 0.21755017340183258
[32m[0512 00:32:44 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.21382714807987213, Train Loss: 0.21754767000675201
[32m[0512 00:32:44 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.21383194625377655, Train Loss: 0.21754516661167145
[32m[0512 00:32:45 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.21383674442768097, Train Loss: 0.21754266321659088
[32m[0512 00:32:45 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.21384157240390778, Train Loss: 0.21754015982151031
[32m[0512 00:32:45 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.21384640038013458, Train Loss: 0.21753764152526855
[32m[0512 00:32:45 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.213851198554039, Train Loss: 0.21753516793251038
[32m[0512 00:32:45 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.21385599672794342, Train Loss: 0.217532679438591
[32m[0512 00:32:45 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.21386076509952545, Train Loss: 0.21753019094467163
[32m[0512 00:32:45 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.21386554837226868, Train Loss: 0.21752773225307465
[32m[0512 00:32:45 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.21387037634849548, Train Loss: 0.21752524375915527
[32m[0512 00:32:45 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.2138751745223999, Train Loss: 0.2175227701663971
[32m[0512 00:32:45 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.21387992799282074, Train Loss: 0.21752029657363892
[32m[0512 00:32:45 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.21388469636440277, Train Loss: 0.21751785278320312
[32m[0512 00:32:45 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.213889479637146, Train Loss: 0.21751537919044495
[32m[0512 00:32:45 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.21389420330524445, Train Loss: 0.21751293540000916
[32m[0512 00:32:45 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.21389895677566528, Train Loss: 0.21751046180725098
[32m[0512 00:32:45 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.21390372514724731, Train Loss: 0.21750801801681519
[32m[0512 00:32:45 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.21390847861766815, Train Loss: 0.2175055891275406
[32m[0512 00:32:45 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.2139132022857666, Train Loss: 0.2175031155347824
[32m[0512 00:32:45 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.21391794085502625, Train Loss: 0.21750067174434662
[32m[0512 00:32:45 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.2139226645231247, Train Loss: 0.21749824285507202
[32m[0512 00:32:45 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.21392741799354553, Train Loss: 0.21749581396579742
[32m[0512 00:32:46 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.2139321118593216, Train Loss: 0.21749338507652283
[32m[0512 00:32:46 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.21393685042858124, Train Loss: 0.21749092638492584
[32m[0512 00:32:46 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.2139415293931961, Train Loss: 0.21748851239681244
[32m[0512 00:32:46 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.21394625306129456, Train Loss: 0.21748612821102142
[32m[0512 00:32:46 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.21395094692707062, Train Loss: 0.21748366951942444
[32m[0512 00:32:46 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.21395565569400787, Train Loss: 0.21748127043247223
[32m[0512 00:32:46 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.21396033465862274, Train Loss: 0.21747884154319763
[32m[0512 00:32:46 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.21396495401859283, Train Loss: 0.21747645735740662
[32m[0512 00:32:46 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.2139696329832077, Train Loss: 0.21747402846813202
[32m[0512 00:32:46 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.21397431194782257, Train Loss: 0.217471644282341
[32m[0512 00:32:46 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.21397899091243744, Train Loss: 0.2174692302942276
[32m[0512 00:32:46 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.2139836549758911, Train Loss: 0.2174668312072754
[32m[0512 00:32:46 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.2139883041381836, Train Loss: 0.21746444702148438
[32m[0512 00:32:46 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.21399293839931488, Train Loss: 0.21746206283569336
[32m[0512 00:32:46 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.21399755775928497, Train Loss: 0.21745967864990234
[32m[0512 00:32:46 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.21400220692157745, Train Loss: 0.21745727956295013
[32m[0512 00:32:46 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.21400684118270874, Train Loss: 0.21745489537715912
[32m[0512 00:32:46 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.21401144564151764, Train Loss: 0.2174525260925293
[32m[0512 00:32:46 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.21401609480381012, Train Loss: 0.2174501270055771
[32m[0512 00:32:46 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.2140207290649414, Train Loss: 0.21744777262210846
[32m[0512 00:32:46 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.21402530372142792, Train Loss: 0.21744535863399506
[32m[0512 00:32:47 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.21402990818023682, Train Loss: 0.21744300425052643
[32m[0512 00:32:47 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.2140345424413681, Train Loss: 0.2174406200647354
[32m[0512 00:32:47 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.21403910219669342, Train Loss: 0.21743826568126678
[32m[0512 00:32:47 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.21404370665550232, Train Loss: 0.21743592619895935
[32m[0512 00:32:47 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.21404828131198883, Train Loss: 0.21743354201316833
[32m[0512 00:32:47 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.21405287086963654, Train Loss: 0.2174311727285385
[32m[0512 00:32:47 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.21405740082263947, Train Loss: 0.21742883324623108
[32m[0512 00:32:47 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.21406197547912598, Train Loss: 0.21742649376392365
[32m[0512 00:32:47 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.2140665501356125, Train Loss: 0.2174241542816162
[32m[0512 00:32:47 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.21407106518745422, Train Loss: 0.2174217849969864
[32m[0512 00:32:47 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.21407562494277954, Train Loss: 0.21741944551467896
[32m[0512 00:32:47 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.21408016979694366, Train Loss: 0.21741709113121033
[32m[0512 00:32:47 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.21408472955226898, Train Loss: 0.2174147516489029
[32m[0512 00:32:47 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.21408922970294952, Train Loss: 0.21741242706775665
[32m[0512 00:32:47 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.21409378945827484, Train Loss: 0.21741007268428802
[32m[0512 00:32:47 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.21409831941127777, Train Loss: 0.21740776300430298
[32m[0512 00:32:47 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.2141028344631195, Train Loss: 0.21740542352199554
[32m[0512 00:32:47 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.21410730481147766, Train Loss: 0.2174030840396881
[32m[0512 00:32:47 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.2141118198633194, Train Loss: 0.21740077435970306
[32m[0512 00:32:47 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.21411632001399994, Train Loss: 0.21739844977855682
[32m[0512 00:32:48 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.2141208052635193, Train Loss: 0.2173961102962494
[32m[0512 00:32:48 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.21412529051303864, Train Loss: 0.21739378571510315
[32m[0512 00:32:48 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.2141297459602356, Train Loss: 0.2173914909362793
[32m[0512 00:32:48 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.21413427591323853, Train Loss: 0.21738915145397186
[32m[0512 00:32:48 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.21413873136043549, Train Loss: 0.2173868715763092
[32m[0512 00:32:48 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.21414318680763245, Train Loss: 0.21738456189632416
[32m[0512 00:32:48 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.2141476571559906, Train Loss: 0.21738220751285553
[32m[0512 00:32:48 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.21415212750434875, Train Loss: 0.21737991273403168
[32m[0512 00:32:48 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.21415653824806213, Train Loss: 0.21737761795520782
[32m[0512 00:32:48 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.2141609936952591, Train Loss: 0.21737532317638397
[32m[0512 00:32:48 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.21416544914245605, Train Loss: 0.21737299859523773
[32m[0512 00:32:48 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.21416985988616943, Train Loss: 0.21737070381641388
[32m[0512 00:32:48 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.2141743004322052, Train Loss: 0.21736842393875122
[32m[0512 00:32:48 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.21417871117591858, Train Loss: 0.21736612915992737
[32m[0512 00:32:48 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.21418313682079315, Train Loss: 0.21736381947994232
[32m[0512 00:32:48 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.21418754756450653, Train Loss: 0.21736150979995728
[32m[0512 00:32:48 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.2141919583082199, Train Loss: 0.2173592448234558
[32m[0512 00:32:48 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.2141963690519333, Train Loss: 0.21735697984695435
[32m[0512 00:32:48 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.21420074999332428, Train Loss: 0.2173546403646469
[32m[0512 00:32:48 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.21420516073703766, Train Loss: 0.21735239028930664
[32m[0512 00:32:48 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.21420949697494507, Train Loss: 0.2173500955104828
[32m[0512 00:32:49 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.21421390771865845, Train Loss: 0.21734784543514252
[32m[0512 00:32:49 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.21421825885772705, Train Loss: 0.21734553575515747
[32m[0512 00:32:49 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.21422263979911804, Train Loss: 0.21734324097633362
[32m[0512 00:32:49 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.21422700583934784, Train Loss: 0.21734100580215454
[32m[0512 00:32:49 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.21423137187957764, Train Loss: 0.2173386961221695
[32m[0512 00:32:49 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.21423570811748505, Train Loss: 0.21733646094799042
[32m[0512 00:32:49 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.21424005925655365, Train Loss: 0.21733421087265015
[32m[0512 00:32:49 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.21424439549446106, Train Loss: 0.2173318862915039
[32m[0512 00:32:49 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.21424873173236847, Train Loss: 0.21732965111732483
[32m[0512 00:32:49 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.21425306797027588, Train Loss: 0.21732740104198456
[32m[0512 00:32:49 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.2142574042081833, Train Loss: 0.2173251062631607
[32m[0512 00:32:49 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.21426168084144592, Train Loss: 0.21732287108898163
[32m[0512 00:32:49 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.21426601707935333, Train Loss: 0.21732059121131897
[32m[0512 00:32:49 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.21427030861377716, Train Loss: 0.2173183560371399
[32m[0512 00:32:49 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.21427464485168457, Train Loss: 0.21731606125831604
[32m[0512 00:32:49 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.2142789363861084, Train Loss: 0.21731382608413696
[32m[0512 00:32:49 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.21428321301937103, Train Loss: 0.21731160581111908
[32m[0512 00:32:49 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.21428751945495605, Train Loss: 0.21730934083461761
[32m[0512 00:32:49 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.2142917662858963, Train Loss: 0.21730710566043854
[32m[0512 00:32:49 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.21429607272148132, Train Loss: 0.21730484068393707
[32m[0512 00:32:50 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.21430036425590515, Train Loss: 0.2173026204109192
[32m[0512 00:32:50 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.2143046259880066, Train Loss: 0.21730037033557892
[32m[0512 00:32:50 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.21430888772010803, Train Loss: 0.21729809045791626
[32m[0512 00:32:50 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.21431311964988708, Train Loss: 0.21729587018489838
[32m[0512 00:32:50 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.2143174111843109, Train Loss: 0.2172936350107193
[32m[0512 00:32:50 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.21432167291641235, Train Loss: 0.21729139983654022
[32m[0512 00:32:50 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.21432587504386902, Train Loss: 0.21728916466236115
[32m[0512 00:32:50 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.21433012187480927, Train Loss: 0.21728692948818207
[32m[0512 00:32:50 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.2143343836069107, Train Loss: 0.2172846794128418
[32m[0512 00:32:50 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.21433861553668976, Train Loss: 0.21728244423866272
[32m[0512 00:32:50 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.21434283256530762, Train Loss: 0.21728023886680603
[32m[0512 00:32:50 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.2143470197916031, Train Loss: 0.21727798879146576
[32m[0512 00:32:50 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.21435123682022095, Train Loss: 0.21727576851844788
[32m[0512 00:32:50 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.2143554389476776, Train Loss: 0.2172735333442688
[32m[0512 00:32:50 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.21435965597629547, Train Loss: 0.21727128326892853
[32m[0512 00:32:50 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.21436388790607452, Train Loss: 0.21726912260055542
[32m[0512 00:32:50 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.2143680602312088, Train Loss: 0.21726688742637634
[32m[0512 00:32:50 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.21437227725982666, Train Loss: 0.21726465225219727
[32m[0512 00:32:50 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.21437643468379974, Train Loss: 0.21726244688034058
[32m[0512 00:32:50 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.21438062191009521, Train Loss: 0.2172602266073227
[32m[0512 00:32:50 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.21438480913639069, Train Loss: 0.217258021235466
[32m[0512 00:32:51 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.21438895165920258, Train Loss: 0.21725578606128693
[32m[0512 00:32:51 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.21439313888549805, Train Loss: 0.21725358068943024
[32m[0512 00:32:51 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.21439732611179352, Train Loss: 0.21725139021873474
[32m[0512 00:32:51 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.2144014686346054, Train Loss: 0.21724915504455566
[32m[0512 00:32:51 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.2144055813550949, Train Loss: 0.21724694967269897
[32m[0512 00:32:51 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.214409738779068, Train Loss: 0.2172447293996811
[32m[0512 00:32:51 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.21441391110420227, Train Loss: 0.2172425389289856
[32m[0512 00:32:51 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.21441805362701416, Train Loss: 0.2172403335571289
[32m[0512 00:32:51 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.21442218124866486, Train Loss: 0.21723812818527222
[32m[0512 00:32:51 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.21442629396915436, Train Loss: 0.21723590791225433
[32m[0512 00:32:51 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.21443043649196625, Train Loss: 0.21723371744155884
[32m[0512 00:32:51 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.21443454921245575, Train Loss: 0.21723152697086334
[32m[0512 00:32:51 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.21443864703178406, Train Loss: 0.21722935140132904
[32m[0512 00:32:51 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.21444278955459595, Train Loss: 0.21722711622714996
[32m[0512 00:32:51 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.21444687247276306, Train Loss: 0.21722492575645447
[32m[0512 00:32:51 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.21445097029209137, Train Loss: 0.21722273528575897
[32m[0512 00:32:51 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.21445505321025848, Train Loss: 0.21722054481506348
[32m[0512 00:32:51 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.2144591212272644, Train Loss: 0.2172183394432068
[32m[0512 00:32:51 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.2144632339477539, Train Loss: 0.21721616387367249
[32m[0512 00:32:52 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.2144673466682434, Train Loss: 0.2172139585018158
[32m[0512 00:32:52 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.21447141468524933, Train Loss: 0.2172117829322815
[32m[0512 00:32:52 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.21447548270225525, Train Loss: 0.2172096222639084
[32m[0512 00:32:52 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.21447955071926117, Train Loss: 0.2172074168920517
[32m[0512 00:32:52 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.2144836187362671, Train Loss: 0.2172052413225174
[32m[0512 00:32:52 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.2144877016544342, Train Loss: 0.2172030508518219
[32m[0512 00:32:52 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.21449173986911774, Train Loss: 0.2172008603811264
[32m[0512 00:32:52 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.21449580788612366, Train Loss: 0.2171986699104309
[32m[0512 00:32:52 @mbmf_main.py:224][0m batch size for trpo is 1000
[32m[0512 00:32:52 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 00:32:52 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 00:32:52 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 00:32:52 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 00:32:52 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 00:32:52 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 00:32:52 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 00:32:52 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 00:32:52 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 00:32:52 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 00:32:52 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 00:32:52 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 00:32:52 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 00:32:52 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 00:32:52 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 00:32:52 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 00:32:52 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 00:32:52 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 00:32:52 @mbmf_main.py:132][0m Training starts at /root/mbbl
[32m[0512 00:32:52 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 00:32:52 @base_worker.py:45][0m Worker 0 online
[32m[0512 00:32:52 @base_worker.py:45][0m Worker 1 online
[32m[0512 00:32:52 @base_worker.py:45][0m Worker 2 online
[32m[0512 00:32:52 @base_worker.py:45][0m Worker 3 online
[32m[0512 00:32:52 @base_worker.py:45][0m Worker 4 online
[32m[0512 00:32:52 @mbmf_worker.py:179][0m kill message for worker
[32m[0512 00:32:52 @base_worker.py:45][0m Worker 5 online
[32m[0512 00:32:52 @base_worker.py:45][0m Worker 6 online
[32m[0512 00:32:52 @base_worker.py:45][0m Worker 7 online
[32m[0512 00:32:52 @base_worker.py:45][0m Worker 8 online
[32m[0512 00:32:52 @base_worker.py:45][0m Worker 9 online
[32m[0512 00:32:52 @base_worker.py:45][0m Worker 10 online
[32m[0512 00:32:52 @base_worker.py:45][0m Worker 11 online
[32m[0512 00:32:52 @base_worker.py:45][0m Worker 12 online
[32m[0512 00:32:52 @base_worker.py:45][0m Worker 13 online
[32m[0512 00:32:52 @base_worker.py:45][0m Worker 14 online
[32m[0512 00:32:52 @base_worker.py:45][0m Worker 15 online
[32m[0512 00:32:52 @base_worker.py:45][0m Worker 16 online
[32m[0512 00:32:52 @base_worker.py:45][0m Worker 17 online
[32m[0512 00:32:52 @base_worker.py:45][0m Worker 18 online
[32m[0512 00:32:52 @base_worker.py:45][0m Worker 19 online
[32m[0512 00:32:53 @base_trainer.py:152][0m Trainer maintains [1] policy network
[32m[0512 00:32:53 @base_trainer.py:152][0m Trainer maintains [1] dynamics network
[32m[0512 00:32:53 @base_trainer.py:152][0m Trainer maintains [1] reward network
[32m[0512 00:32:53 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:32:53 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:32:53 @base_trainer.py:216][0m Mean reward: -563.580705471605
[32m[0512 00:32:54 @base_main.py:38][0m --------------- Iteration 1 ---------------
[32m[0512 00:32:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0000 mins
[32m[0512 00:32:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0046 mins
[32m[0512 00:32:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0144 mins
[32m[0512 00:32:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:32:54 @base_main.py:47][0m 1005 total steps have happened
[32m[0512 00:32:54 @base_main.py:52][0m [avg_reward]: -563.580705471605
[32m[0512 00:32:54 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:32:54 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:32:54 @base_trainer.py:216][0m Mean reward: -491.21422429815937
[32m[0512 00:32:55 @base_main.py:38][0m --------------- Iteration 2 ---------------
[32m[0512 00:32:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0191 mins
[32m[0512 00:32:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0049 mins
[32m[0512 00:32:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 00:32:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:32:55 @base_main.py:47][0m 2010 total steps have happened
[32m[0512 00:32:55 @base_main.py:52][0m [avg_reward]: -491.21422429815937
[32m[0512 00:32:55 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:32:55 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:32:55 @base_trainer.py:216][0m Mean reward: -379.1733928081756
[32m[0512 00:32:56 @base_main.py:38][0m --------------- Iteration 3 ---------------
[32m[0512 00:32:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0332 mins
[32m[0512 00:32:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0048 mins
[32m[0512 00:32:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0512 00:32:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:32:56 @base_main.py:47][0m 3015 total steps have happened
[32m[0512 00:32:56 @base_main.py:52][0m [avg_reward]: -379.1733928081756
[32m[0512 00:32:56 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:32:56 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:32:56 @base_trainer.py:216][0m Mean reward: -316.19576610599444
[32m[0512 00:32:56 @base_main.py:38][0m --------------- Iteration 4 ---------------
[32m[0512 00:32:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0466 mins
[32m[0512 00:32:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0512 00:32:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 00:32:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:32:56 @base_main.py:47][0m 4020 total steps have happened
[32m[0512 00:32:56 @base_main.py:52][0m [avg_reward]: -316.19576610599444
[32m[0512 00:32:57 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:32:57 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:32:57 @base_trainer.py:216][0m Mean reward: -307.8921482564637
[32m[0512 00:32:57 @base_main.py:38][0m --------------- Iteration 5 ---------------
[32m[0512 00:32:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0594 mins
[32m[0512 00:32:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0046 mins
[32m[0512 00:32:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0084 mins
[32m[0512 00:32:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:32:57 @base_main.py:47][0m 5025 total steps have happened
[32m[0512 00:32:57 @base_main.py:52][0m [avg_reward]: -307.8921482564637
[32m[0512 00:32:57 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:32:57 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:32:57 @base_trainer.py:216][0m Mean reward: -283.4786458860296
[32m[0512 00:32:58 @base_main.py:38][0m --------------- Iteration 6 ---------------
[32m[0512 00:32:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0725 mins
[32m[0512 00:32:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0512 00:32:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 00:32:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:32:58 @base_main.py:47][0m 6030 total steps have happened
[32m[0512 00:32:58 @base_main.py:52][0m [avg_reward]: -283.4786458860296
[32m[0512 00:32:58 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:32:58 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:32:58 @base_trainer.py:216][0m Mean reward: -215.0916986945605
[32m[0512 00:32:59 @base_main.py:38][0m --------------- Iteration 7 ---------------
[32m[0512 00:32:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0856 mins
[32m[0512 00:32:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0035 mins
[32m[0512 00:32:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0081 mins
[32m[0512 00:32:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:32:59 @base_main.py:47][0m 7035 total steps have happened
[32m[0512 00:32:59 @base_main.py:52][0m [avg_reward]: -215.0916986945605
[32m[0512 00:32:59 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:32:59 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:32:59 @base_trainer.py:216][0m Mean reward: -202.5176826343834
[32m[0512 00:32:59 @base_main.py:38][0m --------------- Iteration 8 ---------------
[32m[0512 00:32:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0974 mins
[32m[0512 00:32:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0042 mins
[32m[0512 00:32:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 00:32:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:32:59 @base_main.py:47][0m 8040 total steps have happened
[32m[0512 00:32:59 @base_main.py:52][0m [avg_reward]: -202.5176826343834
[32m[0512 00:33:00 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:00 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:00 @base_trainer.py:216][0m Mean reward: -259.25001232082457
[32m[0512 00:33:00 @base_main.py:38][0m --------------- Iteration 9 ---------------
[32m[0512 00:33:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1108 mins
[32m[0512 00:33:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 00:33:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0512 00:33:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 00:33:00 @base_main.py:47][0m 9045 total steps have happened
[32m[0512 00:33:00 @base_main.py:52][0m [avg_reward]: -259.25001232082457
[32m[0512 00:33:00 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:00 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:00 @base_trainer.py:216][0m Mean reward: -161.6533980532879
[32m[0512 00:33:01 @base_main.py:38][0m --------------- Iteration 10 ---------------
[32m[0512 00:33:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1224 mins
[32m[0512 00:33:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 00:33:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 00:33:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:01 @base_main.py:47][0m 10050 total steps have happened
[32m[0512 00:33:01 @base_main.py:52][0m [avg_reward]: -161.6533980532879
[32m[0512 00:33:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:01 @base_trainer.py:216][0m Mean reward: -152.2558977300808
[32m[0512 00:33:01 @base_main.py:38][0m --------------- Iteration 11 ---------------
[32m[0512 00:33:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1342 mins
[32m[0512 00:33:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 00:33:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0079 mins
[32m[0512 00:33:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:01 @base_main.py:47][0m 11055 total steps have happened
[32m[0512 00:33:01 @base_main.py:52][0m [avg_reward]: -152.2558977300808
[32m[0512 00:33:02 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:02 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:02 @base_trainer.py:216][0m Mean reward: -188.97391274474418
[32m[0512 00:33:02 @base_main.py:38][0m --------------- Iteration 12 ---------------
[32m[0512 00:33:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1453 mins
[32m[0512 00:33:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 00:33:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 00:33:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 00:33:02 @base_main.py:47][0m 12060 total steps have happened
[32m[0512 00:33:02 @base_main.py:52][0m [avg_reward]: -188.97391274474418
[32m[0512 00:33:02 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:02 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:02 @base_trainer.py:216][0m Mean reward: -195.57052465267483
[32m[0512 00:33:03 @base_main.py:38][0m --------------- Iteration 13 ---------------
[32m[0512 00:33:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1571 mins
[32m[0512 00:33:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 00:33:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 00:33:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:03 @base_main.py:47][0m 13065 total steps have happened
[32m[0512 00:33:03 @base_main.py:52][0m [avg_reward]: -195.57052465267483
[32m[0512 00:33:03 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:03 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:03 @base_trainer.py:216][0m Mean reward: -231.35153112795834
[32m[0512 00:33:04 @base_main.py:38][0m --------------- Iteration 14 ---------------
[32m[0512 00:33:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1689 mins
[32m[0512 00:33:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0512 00:33:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0512 00:33:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 00:33:04 @base_main.py:47][0m 14070 total steps have happened
[32m[0512 00:33:04 @base_main.py:52][0m [avg_reward]: -231.35153112795834
[32m[0512 00:33:04 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:04 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:04 @base_trainer.py:216][0m Mean reward: -131.9365366065851
[32m[0512 00:33:04 @base_main.py:38][0m --------------- Iteration 15 ---------------
[32m[0512 00:33:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1818 mins
[32m[0512 00:33:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:33:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 00:33:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:04 @base_main.py:47][0m 15075 total steps have happened
[32m[0512 00:33:04 @base_main.py:52][0m [avg_reward]: -131.9365366065851
[32m[0512 00:33:05 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:05 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:05 @base_trainer.py:216][0m Mean reward: -115.94976462981852
[32m[0512 00:33:05 @base_main.py:38][0m --------------- Iteration 16 ---------------
[32m[0512 00:33:05 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1936 mins
[32m[0512 00:33:05 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 00:33:05 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 00:33:05 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:05 @base_main.py:47][0m 16080 total steps have happened
[32m[0512 00:33:05 @base_main.py:52][0m [avg_reward]: -115.94976462981852
[32m[0512 00:33:05 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:05 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:05 @base_trainer.py:216][0m Mean reward: -161.68366844834878
[32m[0512 00:33:06 @base_main.py:38][0m --------------- Iteration 17 ---------------
[32m[0512 00:33:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2054 mins
[32m[0512 00:33:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:33:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0512 00:33:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:06 @base_main.py:47][0m 17085 total steps have happened
[32m[0512 00:33:06 @base_main.py:52][0m [avg_reward]: -161.68366844834878
[32m[0512 00:33:06 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:06 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:06 @base_trainer.py:216][0m Mean reward: -211.02441948414275
[32m[0512 00:33:07 @base_main.py:38][0m --------------- Iteration 18 ---------------
[32m[0512 00:33:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2176 mins
[32m[0512 00:33:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 00:33:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0512 00:33:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:07 @base_main.py:47][0m 18090 total steps have happened
[32m[0512 00:33:07 @base_main.py:52][0m [avg_reward]: -211.02441948414275
[32m[0512 00:33:07 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:07 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:07 @base_trainer.py:216][0m Mean reward: -183.02649944968098
[32m[0512 00:33:07 @base_main.py:38][0m --------------- Iteration 19 ---------------
[32m[0512 00:33:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2297 mins
[32m[0512 00:33:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0512 00:33:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 00:33:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 00:33:07 @base_main.py:47][0m 19095 total steps have happened
[32m[0512 00:33:07 @base_main.py:52][0m [avg_reward]: -183.02649944968098
[32m[0512 00:33:07 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:07 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:07 @base_trainer.py:216][0m Mean reward: -178.60019640454234
[32m[0512 00:33:08 @base_main.py:38][0m --------------- Iteration 20 ---------------
[32m[0512 00:33:08 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2418 mins
[32m[0512 00:33:08 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:33:08 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0512 00:33:08 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 00:33:08 @base_main.py:47][0m 20100 total steps have happened
[32m[0512 00:33:08 @base_main.py:52][0m [avg_reward]: -178.60019640454234
[32m[0512 00:33:08 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:08 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:08 @base_trainer.py:216][0m Mean reward: -186.27918318471944
[32m[0512 00:33:09 @base_main.py:38][0m --------------- Iteration 21 ---------------
[32m[0512 00:33:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2536 mins
[32m[0512 00:33:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 00:33:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0512 00:33:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:09 @base_main.py:47][0m 21105 total steps have happened
[32m[0512 00:33:09 @base_main.py:52][0m [avg_reward]: -186.27918318471944
[32m[0512 00:33:09 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:09 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:09 @base_trainer.py:216][0m Mean reward: -142.98838232466102
[32m[0512 00:33:09 @base_main.py:38][0m --------------- Iteration 22 ---------------
[32m[0512 00:33:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2654 mins
[32m[0512 00:33:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:33:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 00:33:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:09 @base_main.py:47][0m 22110 total steps have happened
[32m[0512 00:33:09 @base_main.py:52][0m [avg_reward]: -142.98838232466102
[32m[0512 00:33:10 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:10 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:10 @base_trainer.py:216][0m Mean reward: -167.9280412226398
[32m[0512 00:33:10 @base_main.py:38][0m --------------- Iteration 23 ---------------
[32m[0512 00:33:10 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2773 mins
[32m[0512 00:33:10 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 00:33:10 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 00:33:10 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 00:33:10 @base_main.py:47][0m 23115 total steps have happened
[32m[0512 00:33:10 @base_main.py:52][0m [avg_reward]: -167.9280412226398
[32m[0512 00:33:10 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:10 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:10 @base_trainer.py:216][0m Mean reward: -155.46876524410595
[32m[0512 00:33:11 @base_main.py:38][0m --------------- Iteration 24 ---------------
[32m[0512 00:33:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2894 mins
[32m[0512 00:33:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0512 00:33:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0512 00:33:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:11 @base_main.py:47][0m 24120 total steps have happened
[32m[0512 00:33:11 @base_main.py:52][0m [avg_reward]: -155.46876524410595
[32m[0512 00:33:11 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:11 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:11 @base_trainer.py:216][0m Mean reward: -176.47421124353286
[32m[0512 00:33:12 @base_main.py:38][0m --------------- Iteration 25 ---------------
[32m[0512 00:33:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3021 mins
[32m[0512 00:33:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:33:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0512 00:33:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:12 @base_main.py:47][0m 25125 total steps have happened
[32m[0512 00:33:12 @base_main.py:52][0m [avg_reward]: -176.47421124353286
[32m[0512 00:33:12 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:12 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:12 @base_trainer.py:216][0m Mean reward: -202.24553991099938
[32m[0512 00:33:12 @base_main.py:38][0m --------------- Iteration 26 ---------------
[32m[0512 00:33:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3142 mins
[32m[0512 00:33:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:33:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0512 00:33:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:12 @base_main.py:47][0m 26130 total steps have happened
[32m[0512 00:33:12 @base_main.py:52][0m [avg_reward]: -202.24553991099938
[32m[0512 00:33:13 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:13 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:13 @base_trainer.py:216][0m Mean reward: -194.76807866974406
[32m[0512 00:33:13 @base_main.py:38][0m --------------- Iteration 27 ---------------
[32m[0512 00:33:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3259 mins
[32m[0512 00:33:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:33:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0512 00:33:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:13 @base_main.py:47][0m 27135 total steps have happened
[32m[0512 00:33:13 @base_main.py:52][0m [avg_reward]: -194.76807866974406
[32m[0512 00:33:13 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:13 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:13 @base_trainer.py:216][0m Mean reward: -127.04047935257249
[32m[0512 00:33:14 @base_main.py:38][0m --------------- Iteration 28 ---------------
[32m[0512 00:33:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3377 mins
[32m[0512 00:33:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 00:33:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0512 00:33:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:14 @base_main.py:47][0m 28140 total steps have happened
[32m[0512 00:33:14 @base_main.py:52][0m [avg_reward]: -127.04047935257249
[32m[0512 00:33:14 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:14 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:14 @base_trainer.py:216][0m Mean reward: -173.42667653197205
[32m[0512 00:33:14 @base_main.py:38][0m --------------- Iteration 29 ---------------
[32m[0512 00:33:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3496 mins
[32m[0512 00:33:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:33:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 00:33:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:14 @base_main.py:47][0m 29145 total steps have happened
[32m[0512 00:33:14 @base_main.py:52][0m [avg_reward]: -173.42667653197205
[32m[0512 00:33:15 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:15 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:15 @base_trainer.py:216][0m Mean reward: -149.62816981091677
[32m[0512 00:33:15 @base_main.py:38][0m --------------- Iteration 30 ---------------
[32m[0512 00:33:15 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3612 mins
[32m[0512 00:33:15 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 00:33:15 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0512 00:33:15 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:15 @base_main.py:47][0m 30150 total steps have happened
[32m[0512 00:33:15 @base_main.py:52][0m [avg_reward]: -149.62816981091677
[32m[0512 00:33:15 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:15 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:15 @base_trainer.py:216][0m Mean reward: -116.62482117663255
[32m[0512 00:33:16 @base_main.py:38][0m --------------- Iteration 31 ---------------
[32m[0512 00:33:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3727 mins
[32m[0512 00:33:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:33:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0512 00:33:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:16 @base_main.py:47][0m 31155 total steps have happened
[32m[0512 00:33:16 @base_main.py:52][0m [avg_reward]: -116.62482117663255
[32m[0512 00:33:16 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:16 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:16 @base_trainer.py:216][0m Mean reward: -119.37870488362103
[32m[0512 00:33:17 @base_main.py:38][0m --------------- Iteration 32 ---------------
[32m[0512 00:33:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3843 mins
[32m[0512 00:33:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:33:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 00:33:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:17 @base_main.py:47][0m 32160 total steps have happened
[32m[0512 00:33:17 @base_main.py:52][0m [avg_reward]: -119.37870488362103
[32m[0512 00:33:17 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:17 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:17 @base_trainer.py:216][0m Mean reward: -126.7937276222397
[32m[0512 00:33:17 @base_main.py:38][0m --------------- Iteration 33 ---------------
[32m[0512 00:33:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3963 mins
[32m[0512 00:33:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:33:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0512 00:33:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:17 @base_main.py:47][0m 33165 total steps have happened
[32m[0512 00:33:17 @base_main.py:52][0m [avg_reward]: -126.7937276222397
[32m[0512 00:33:17 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:17 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:17 @base_trainer.py:216][0m Mean reward: -107.45709550973581
[32m[0512 00:33:18 @base_main.py:38][0m --------------- Iteration 34 ---------------
[32m[0512 00:33:18 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4079 mins
[32m[0512 00:33:18 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:33:18 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 00:33:18 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:18 @base_main.py:47][0m 34170 total steps have happened
[32m[0512 00:33:18 @base_main.py:52][0m [avg_reward]: -107.45709550973581
[32m[0512 00:33:18 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:18 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:18 @base_trainer.py:216][0m Mean reward: -157.10014090160396
[32m[0512 00:33:19 @base_main.py:38][0m --------------- Iteration 35 ---------------
[32m[0512 00:33:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4196 mins
[32m[0512 00:33:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 00:33:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0512 00:33:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:19 @base_main.py:47][0m 35175 total steps have happened
[32m[0512 00:33:19 @base_main.py:52][0m [avg_reward]: -157.10014090160396
[32m[0512 00:33:19 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:19 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:19 @base_trainer.py:216][0m Mean reward: -117.65867037859582
[32m[0512 00:33:19 @base_main.py:38][0m --------------- Iteration 36 ---------------
[32m[0512 00:33:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4321 mins
[32m[0512 00:33:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 00:33:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0512 00:33:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:19 @base_main.py:47][0m 36180 total steps have happened
[32m[0512 00:33:19 @base_main.py:52][0m [avg_reward]: -117.65867037859582
[32m[0512 00:33:20 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:20 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:20 @base_trainer.py:216][0m Mean reward: -123.7134451599459
[32m[0512 00:33:20 @base_main.py:38][0m --------------- Iteration 37 ---------------
[32m[0512 00:33:20 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4450 mins
[32m[0512 00:33:20 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:33:20 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0512 00:33:20 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 00:33:20 @base_main.py:47][0m 37185 total steps have happened
[32m[0512 00:33:20 @base_main.py:52][0m [avg_reward]: -123.7134451599459
[32m[0512 00:33:20 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:20 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:20 @base_trainer.py:216][0m Mean reward: -108.55207888308549
[32m[0512 00:33:21 @base_main.py:38][0m --------------- Iteration 38 ---------------
[32m[0512 00:33:21 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4575 mins
[32m[0512 00:33:21 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:33:21 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0512 00:33:21 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:21 @base_main.py:47][0m 38190 total steps have happened
[32m[0512 00:33:21 @base_main.py:52][0m [avg_reward]: -108.55207888308549
[32m[0512 00:33:21 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:21 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:21 @base_trainer.py:216][0m Mean reward: -114.18206135171404
[32m[0512 00:33:22 @base_main.py:38][0m --------------- Iteration 39 ---------------
[32m[0512 00:33:22 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4698 mins
[32m[0512 00:33:22 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:33:22 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0512 00:33:22 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:22 @base_main.py:47][0m 39195 total steps have happened
[32m[0512 00:33:22 @base_main.py:52][0m [avg_reward]: -114.18206135171404
[32m[0512 00:33:22 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:22 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:22 @base_trainer.py:216][0m Mean reward: -130.0774475562877
[32m[0512 00:33:22 @base_main.py:38][0m --------------- Iteration 40 ---------------
[32m[0512 00:33:22 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4811 mins
[32m[0512 00:33:22 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:33:22 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0083 mins
[32m[0512 00:33:22 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:22 @base_main.py:47][0m 40200 total steps have happened
[32m[0512 00:33:22 @base_main.py:52][0m [avg_reward]: -130.0774475562877
[32m[0512 00:33:23 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:23 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:23 @base_trainer.py:216][0m Mean reward: -108.18647821264517
[32m[0512 00:33:23 @base_main.py:38][0m --------------- Iteration 41 ---------------
[32m[0512 00:33:23 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4924 mins
[32m[0512 00:33:23 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0032 mins
[32m[0512 00:33:23 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 00:33:23 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:23 @base_main.py:47][0m 41205 total steps have happened
[32m[0512 00:33:23 @base_main.py:52][0m [avg_reward]: -108.18647821264517
[32m[0512 00:33:23 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:23 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:23 @base_trainer.py:216][0m Mean reward: -122.0905715404668
[32m[0512 00:33:24 @base_main.py:38][0m --------------- Iteration 42 ---------------
[32m[0512 00:33:24 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5045 mins
[32m[0512 00:33:24 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 00:33:24 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0512 00:33:24 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:24 @base_main.py:47][0m 42210 total steps have happened
[32m[0512 00:33:24 @base_main.py:52][0m [avg_reward]: -122.0905715404668
[32m[0512 00:33:24 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:24 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:24 @base_trainer.py:216][0m Mean reward: -138.19745040828667
[32m[0512 00:33:24 @base_main.py:38][0m --------------- Iteration 43 ---------------
[32m[0512 00:33:24 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5161 mins
[32m[0512 00:33:24 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0512 00:33:24 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 00:33:24 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:24 @base_main.py:47][0m 43215 total steps have happened
[32m[0512 00:33:24 @base_main.py:52][0m [avg_reward]: -138.19745040828667
[32m[0512 00:33:25 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:25 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:25 @base_trainer.py:216][0m Mean reward: -164.30520024506487
[32m[0512 00:33:25 @base_main.py:38][0m --------------- Iteration 44 ---------------
[32m[0512 00:33:25 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5276 mins
[32m[0512 00:33:25 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:33:25 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0512 00:33:25 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:25 @base_main.py:47][0m 44220 total steps have happened
[32m[0512 00:33:25 @base_main.py:52][0m [avg_reward]: -164.30520024506487
[32m[0512 00:33:25 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:25 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:25 @base_trainer.py:216][0m Mean reward: -109.20024474690385
[32m[0512 00:33:26 @base_main.py:38][0m --------------- Iteration 45 ---------------
[32m[0512 00:33:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5390 mins
[32m[0512 00:33:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 00:33:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0081 mins
[32m[0512 00:33:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:26 @base_main.py:47][0m 45225 total steps have happened
[32m[0512 00:33:26 @base_main.py:52][0m [avg_reward]: -109.20024474690385
[32m[0512 00:33:26 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:26 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:26 @base_trainer.py:216][0m Mean reward: -107.82638255482121
[32m[0512 00:33:27 @base_main.py:38][0m --------------- Iteration 46 ---------------
[32m[0512 00:33:27 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5502 mins
[32m[0512 00:33:27 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:33:27 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0512 00:33:27 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:27 @base_main.py:47][0m 46230 total steps have happened
[32m[0512 00:33:27 @base_main.py:52][0m [avg_reward]: -107.82638255482121
[32m[0512 00:33:27 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:27 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:27 @base_trainer.py:216][0m Mean reward: -106.96457554370491
[32m[0512 00:33:27 @base_main.py:38][0m --------------- Iteration 47 ---------------
[32m[0512 00:33:27 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5625 mins
[32m[0512 00:33:27 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:33:27 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0512 00:33:27 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:27 @base_main.py:47][0m 47235 total steps have happened
[32m[0512 00:33:27 @base_main.py:52][0m [avg_reward]: -106.96457554370491
[32m[0512 00:33:27 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:27 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:27 @base_trainer.py:216][0m Mean reward: -106.49828359348115
[32m[0512 00:33:28 @base_main.py:38][0m --------------- Iteration 48 ---------------
[32m[0512 00:33:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5749 mins
[32m[0512 00:33:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 00:33:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0512 00:33:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 00:33:28 @base_main.py:47][0m 48240 total steps have happened
[32m[0512 00:33:28 @base_main.py:52][0m [avg_reward]: -106.49828359348115
[32m[0512 00:33:28 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:28 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:28 @base_trainer.py:216][0m Mean reward: -100.54669086270955
[32m[0512 00:33:29 @base_main.py:38][0m --------------- Iteration 49 ---------------
[32m[0512 00:33:29 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5868 mins
[32m[0512 00:33:29 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:33:29 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0512 00:33:29 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 00:33:29 @base_main.py:47][0m 49245 total steps have happened
[32m[0512 00:33:29 @base_main.py:52][0m [avg_reward]: -100.54669086270955
[32m[0512 00:33:29 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:29 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:29 @base_trainer.py:216][0m Mean reward: -107.6506295302427
[32m[0512 00:33:29 @base_main.py:38][0m --------------- Iteration 50 ---------------
[32m[0512 00:33:29 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5985 mins
[32m[0512 00:33:29 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0032 mins
[32m[0512 00:33:29 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 00:33:29 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:29 @base_main.py:47][0m 50250 total steps have happened
[32m[0512 00:33:29 @base_main.py:52][0m [avg_reward]: -107.6506295302427
[32m[0512 00:33:30 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:30 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:30 @base_trainer.py:216][0m Mean reward: -106.96613825591585
[32m[0512 00:33:30 @base_main.py:38][0m --------------- Iteration 51 ---------------
[32m[0512 00:33:30 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6108 mins
[32m[0512 00:33:30 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 00:33:30 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0512 00:33:30 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:30 @base_main.py:47][0m 51255 total steps have happened
[32m[0512 00:33:30 @base_main.py:52][0m [avg_reward]: -106.96613825591585
[32m[0512 00:33:30 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:30 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:30 @base_trainer.py:216][0m Mean reward: -103.02004323057369
[32m[0512 00:33:31 @base_main.py:38][0m --------------- Iteration 52 ---------------
[32m[0512 00:33:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6226 mins
[32m[0512 00:33:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:33:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 00:33:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:31 @base_main.py:47][0m 52260 total steps have happened
[32m[0512 00:33:31 @base_main.py:52][0m [avg_reward]: -103.02004323057369
[32m[0512 00:33:31 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:31 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:31 @base_trainer.py:216][0m Mean reward: -100.9179529884821
[32m[0512 00:33:32 @base_main.py:38][0m --------------- Iteration 53 ---------------
[32m[0512 00:33:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6342 mins
[32m[0512 00:33:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:33:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0512 00:33:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:32 @base_main.py:47][0m 53265 total steps have happened
[32m[0512 00:33:32 @base_main.py:52][0m [avg_reward]: -100.9179529884821
[32m[0512 00:33:32 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:32 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:32 @base_trainer.py:216][0m Mean reward: -103.56467085926411
[32m[0512 00:33:32 @base_main.py:38][0m --------------- Iteration 54 ---------------
[32m[0512 00:33:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6458 mins
[32m[0512 00:33:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:33:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0083 mins
[32m[0512 00:33:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:32 @base_main.py:47][0m 54270 total steps have happened
[32m[0512 00:33:32 @base_main.py:52][0m [avg_reward]: -103.56467085926411
[32m[0512 00:33:32 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:32 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:32 @base_trainer.py:216][0m Mean reward: -96.97575309970576
[32m[0512 00:33:33 @base_main.py:38][0m --------------- Iteration 55 ---------------
[32m[0512 00:33:33 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6569 mins
[32m[0512 00:33:33 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:33:33 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 00:33:33 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:33 @base_main.py:47][0m 55275 total steps have happened
[32m[0512 00:33:33 @base_main.py:52][0m [avg_reward]: -96.97575309970576
[32m[0512 00:33:33 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:33 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:33 @base_trainer.py:216][0m Mean reward: -100.14599956925909
[32m[0512 00:33:34 @base_main.py:38][0m --------------- Iteration 56 ---------------
[32m[0512 00:33:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6687 mins
[32m[0512 00:33:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 00:33:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 00:33:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:34 @base_main.py:47][0m 56280 total steps have happened
[32m[0512 00:33:34 @base_main.py:52][0m [avg_reward]: -100.14599956925909
[32m[0512 00:33:34 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:34 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:34 @base_trainer.py:216][0m Mean reward: -99.9533807685169
[32m[0512 00:33:34 @base_main.py:38][0m --------------- Iteration 57 ---------------
[32m[0512 00:33:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6802 mins
[32m[0512 00:33:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 00:33:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 00:33:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:34 @base_main.py:47][0m 57285 total steps have happened
[32m[0512 00:33:34 @base_main.py:52][0m [avg_reward]: -99.9533807685169
[32m[0512 00:33:34 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:34 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:34 @base_trainer.py:216][0m Mean reward: -97.50366003506883
[32m[0512 00:33:35 @base_main.py:38][0m --------------- Iteration 58 ---------------
[32m[0512 00:33:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6917 mins
[32m[0512 00:33:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:33:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0512 00:33:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:35 @base_main.py:47][0m 58290 total steps have happened
[32m[0512 00:33:35 @base_main.py:52][0m [avg_reward]: -97.50366003506883
[32m[0512 00:33:35 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:35 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:35 @base_trainer.py:216][0m Mean reward: -93.78749030493923
[32m[0512 00:33:36 @base_main.py:38][0m --------------- Iteration 59 ---------------
[32m[0512 00:33:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7041 mins
[32m[0512 00:33:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:33:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0512 00:33:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:36 @base_main.py:47][0m 59295 total steps have happened
[32m[0512 00:33:36 @base_main.py:52][0m [avg_reward]: -93.78749030493923
[32m[0512 00:33:36 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:36 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:36 @base_trainer.py:216][0m Mean reward: -96.79796062503588
[32m[0512 00:33:36 @base_main.py:38][0m --------------- Iteration 60 ---------------
[32m[0512 00:33:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7161 mins
[32m[0512 00:33:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:33:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0512 00:33:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 00:33:36 @base_main.py:47][0m 60300 total steps have happened
[32m[0512 00:33:36 @base_main.py:52][0m [avg_reward]: -96.79796062503588
[32m[0512 00:33:37 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:37 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:37 @base_trainer.py:216][0m Mean reward: -93.44091785154407
[32m[0512 00:33:37 @base_main.py:38][0m --------------- Iteration 61 ---------------
[32m[0512 00:33:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7283 mins
[32m[0512 00:33:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:33:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 00:33:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:37 @base_main.py:47][0m 61305 total steps have happened
[32m[0512 00:33:37 @base_main.py:52][0m [avg_reward]: -93.44091785154407
[32m[0512 00:33:37 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:37 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:37 @base_trainer.py:216][0m Mean reward: -93.41201339950258
[32m[0512 00:33:38 @base_main.py:38][0m --------------- Iteration 62 ---------------
[32m[0512 00:33:38 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7400 mins
[32m[0512 00:33:38 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:33:38 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 00:33:38 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:38 @base_main.py:47][0m 62310 total steps have happened
[32m[0512 00:33:38 @base_main.py:52][0m [avg_reward]: -93.41201339950258
[32m[0512 00:33:38 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:38 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:38 @base_trainer.py:216][0m Mean reward: -101.14642970252933
[32m[0512 00:33:39 @base_main.py:38][0m --------------- Iteration 63 ---------------
[32m[0512 00:33:39 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7517 mins
[32m[0512 00:33:39 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 00:33:39 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 00:33:39 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:39 @base_main.py:47][0m 63315 total steps have happened
[32m[0512 00:33:39 @base_main.py:52][0m [avg_reward]: -101.14642970252933
[32m[0512 00:33:39 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:39 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:39 @base_trainer.py:216][0m Mean reward: -97.09046638316458
[32m[0512 00:33:39 @base_main.py:38][0m --------------- Iteration 64 ---------------
[32m[0512 00:33:39 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7638 mins
[32m[0512 00:33:39 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0512 00:33:39 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0512 00:33:39 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:39 @base_main.py:47][0m 64320 total steps have happened
[32m[0512 00:33:39 @base_main.py:52][0m [avg_reward]: -97.09046638316458
[32m[0512 00:33:39 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:39 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:39 @base_trainer.py:216][0m Mean reward: -105.46332136797214
[32m[0512 00:33:40 @base_main.py:38][0m --------------- Iteration 65 ---------------
[32m[0512 00:33:40 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7756 mins
[32m[0512 00:33:40 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 00:33:40 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0512 00:33:40 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 00:33:40 @base_main.py:47][0m 65325 total steps have happened
[32m[0512 00:33:40 @base_main.py:52][0m [avg_reward]: -105.46332136797214
[32m[0512 00:33:40 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:40 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:40 @base_trainer.py:216][0m Mean reward: -98.28461331599593
[32m[0512 00:33:41 @base_main.py:38][0m --------------- Iteration 66 ---------------
[32m[0512 00:33:41 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7880 mins
[32m[0512 00:33:41 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0512 00:33:41 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 00:33:41 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:41 @base_main.py:47][0m 66330 total steps have happened
[32m[0512 00:33:41 @base_main.py:52][0m [avg_reward]: -98.28461331599593
[32m[0512 00:33:41 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:41 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:41 @base_trainer.py:216][0m Mean reward: -117.52740927784312
[32m[0512 00:33:42 @base_main.py:38][0m --------------- Iteration 67 ---------------
[32m[0512 00:33:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8003 mins
[32m[0512 00:33:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 00:33:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0512 00:33:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:42 @base_main.py:47][0m 67335 total steps have happened
[32m[0512 00:33:42 @base_main.py:52][0m [avg_reward]: -117.52740927784312
[32m[0512 00:33:42 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:42 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:42 @base_trainer.py:216][0m Mean reward: -93.62618118615345
[32m[0512 00:33:42 @base_main.py:38][0m --------------- Iteration 68 ---------------
[32m[0512 00:33:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8124 mins
[32m[0512 00:33:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:33:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 00:33:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:42 @base_main.py:47][0m 68340 total steps have happened
[32m[0512 00:33:42 @base_main.py:52][0m [avg_reward]: -93.62618118615345
[32m[0512 00:33:42 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:42 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:42 @base_trainer.py:216][0m Mean reward: -107.19315483524724
[32m[0512 00:33:43 @base_main.py:38][0m --------------- Iteration 69 ---------------
[32m[0512 00:33:43 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8244 mins
[32m[0512 00:33:43 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 00:33:43 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0512 00:33:43 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:43 @base_main.py:47][0m 69345 total steps have happened
[32m[0512 00:33:43 @base_main.py:52][0m [avg_reward]: -107.19315483524724
[32m[0512 00:33:43 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:43 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:43 @base_trainer.py:216][0m Mean reward: -91.03473705780782
[32m[0512 00:33:44 @base_main.py:38][0m --------------- Iteration 70 ---------------
[32m[0512 00:33:44 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8360 mins
[32m[0512 00:33:44 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:33:44 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 00:33:44 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 00:33:44 @base_main.py:47][0m 70350 total steps have happened
[32m[0512 00:33:44 @base_main.py:52][0m [avg_reward]: -91.03473705780782
[32m[0512 00:33:44 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:44 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:44 @base_trainer.py:216][0m Mean reward: -90.88983899877903
[32m[0512 00:33:44 @base_main.py:38][0m --------------- Iteration 71 ---------------
[32m[0512 00:33:44 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8478 mins
[32m[0512 00:33:44 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 00:33:44 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0512 00:33:44 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:44 @base_main.py:47][0m 71355 total steps have happened
[32m[0512 00:33:44 @base_main.py:52][0m [avg_reward]: -90.88983899877903
[32m[0512 00:33:45 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:45 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:45 @base_trainer.py:216][0m Mean reward: -90.50209375863926
[32m[0512 00:33:45 @base_main.py:38][0m --------------- Iteration 72 ---------------
[32m[0512 00:33:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8594 mins
[32m[0512 00:33:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 00:33:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0512 00:33:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:45 @base_main.py:47][0m 72360 total steps have happened
[32m[0512 00:33:45 @base_main.py:52][0m [avg_reward]: -90.50209375863926
[32m[0512 00:33:45 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:45 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:45 @base_trainer.py:216][0m Mean reward: -89.17822104340082
[32m[0512 00:33:46 @base_main.py:38][0m --------------- Iteration 73 ---------------
[32m[0512 00:33:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8717 mins
[32m[0512 00:33:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:33:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0512 00:33:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:46 @base_main.py:47][0m 73365 total steps have happened
[32m[0512 00:33:46 @base_main.py:52][0m [avg_reward]: -89.17822104340082
[32m[0512 00:33:46 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:46 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:46 @base_trainer.py:216][0m Mean reward: -90.88535168376234
[32m[0512 00:33:47 @base_main.py:38][0m --------------- Iteration 74 ---------------
[32m[0512 00:33:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8838 mins
[32m[0512 00:33:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:33:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0512 00:33:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:47 @base_main.py:47][0m 74370 total steps have happened
[32m[0512 00:33:47 @base_main.py:52][0m [avg_reward]: -90.88535168376234
[32m[0512 00:33:47 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:47 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:47 @base_trainer.py:216][0m Mean reward: -95.93724531901374
[32m[0512 00:33:47 @base_main.py:38][0m --------------- Iteration 75 ---------------
[32m[0512 00:33:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8960 mins
[32m[0512 00:33:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:33:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0512 00:33:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:47 @base_main.py:47][0m 75375 total steps have happened
[32m[0512 00:33:47 @base_main.py:52][0m [avg_reward]: -95.93724531901374
[32m[0512 00:33:47 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:47 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:47 @base_trainer.py:216][0m Mean reward: -102.19067061995332
[32m[0512 00:33:48 @base_main.py:38][0m --------------- Iteration 76 ---------------
[32m[0512 00:33:48 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9083 mins
[32m[0512 00:33:48 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:33:48 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0512 00:33:48 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:48 @base_main.py:47][0m 76380 total steps have happened
[32m[0512 00:33:48 @base_main.py:52][0m [avg_reward]: -102.19067061995332
[32m[0512 00:33:48 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:48 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:48 @base_trainer.py:216][0m Mean reward: -90.12648309733271
[32m[0512 00:33:49 @base_main.py:38][0m --------------- Iteration 77 ---------------
[32m[0512 00:33:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9197 mins
[32m[0512 00:33:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 00:33:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 00:33:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:49 @base_main.py:47][0m 77385 total steps have happened
[32m[0512 00:33:49 @base_main.py:52][0m [avg_reward]: -90.12648309733271
[32m[0512 00:33:49 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:49 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:49 @base_trainer.py:216][0m Mean reward: -86.83807554232438
[32m[0512 00:33:49 @base_main.py:38][0m --------------- Iteration 78 ---------------
[32m[0512 00:33:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9316 mins
[32m[0512 00:33:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:33:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0512 00:33:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:49 @base_main.py:47][0m 78390 total steps have happened
[32m[0512 00:33:49 @base_main.py:52][0m [avg_reward]: -86.83807554232438
[32m[0512 00:33:50 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:50 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:50 @base_trainer.py:216][0m Mean reward: -90.20504156655596
[32m[0512 00:33:50 @base_main.py:38][0m --------------- Iteration 79 ---------------
[32m[0512 00:33:50 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9442 mins
[32m[0512 00:33:50 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:33:50 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0512 00:33:50 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 00:33:50 @base_main.py:47][0m 79395 total steps have happened
[32m[0512 00:33:50 @base_main.py:52][0m [avg_reward]: -90.20504156655596
[32m[0512 00:33:50 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:50 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:50 @base_trainer.py:216][0m Mean reward: -85.89320663016957
[32m[0512 00:33:51 @base_main.py:38][0m --------------- Iteration 80 ---------------
[32m[0512 00:33:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9564 mins
[32m[0512 00:33:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 00:33:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0512 00:33:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:51 @base_main.py:47][0m 80400 total steps have happened
[32m[0512 00:33:51 @base_main.py:52][0m [avg_reward]: -85.89320663016957
[32m[0512 00:33:51 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:51 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:51 @base_trainer.py:216][0m Mean reward: -80.57243637206011
[32m[0512 00:33:52 @base_main.py:38][0m --------------- Iteration 81 ---------------
[32m[0512 00:33:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9680 mins
[32m[0512 00:33:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:33:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 00:33:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:52 @base_main.py:47][0m 81405 total steps have happened
[32m[0512 00:33:52 @base_main.py:52][0m [avg_reward]: -80.57243637206011
[32m[0512 00:33:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:52 @base_trainer.py:216][0m Mean reward: -81.85298836854238
[32m[0512 00:33:52 @base_main.py:38][0m --------------- Iteration 82 ---------------
[32m[0512 00:33:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9799 mins
[32m[0512 00:33:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:33:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0512 00:33:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:52 @base_main.py:47][0m 82410 total steps have happened
[32m[0512 00:33:52 @base_main.py:52][0m [avg_reward]: -81.85298836854238
[32m[0512 00:33:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:52 @base_trainer.py:216][0m Mean reward: -99.105778683516
[32m[0512 00:33:53 @base_main.py:38][0m --------------- Iteration 83 ---------------
[32m[0512 00:33:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9919 mins
[32m[0512 00:33:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:33:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0512 00:33:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:53 @base_main.py:47][0m 83415 total steps have happened
[32m[0512 00:33:53 @base_main.py:52][0m [avg_reward]: -99.105778683516
[32m[0512 00:33:53 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:53 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:53 @base_trainer.py:216][0m Mean reward: -91.09218278152709
[32m[0512 00:33:54 @base_main.py:38][0m --------------- Iteration 84 ---------------
[32m[0512 00:33:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0042 mins
[32m[0512 00:33:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:33:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0512 00:33:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 00:33:54 @base_main.py:47][0m 84420 total steps have happened
[32m[0512 00:33:54 @base_main.py:52][0m [avg_reward]: -91.09218278152709
[32m[0512 00:33:54 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:54 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:54 @base_trainer.py:216][0m Mean reward: -79.34178127502962
[32m[0512 00:33:54 @base_main.py:38][0m --------------- Iteration 85 ---------------
[32m[0512 00:33:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0158 mins
[32m[0512 00:33:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:33:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 00:33:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:54 @base_main.py:47][0m 85425 total steps have happened
[32m[0512 00:33:54 @base_main.py:52][0m [avg_reward]: -79.34178127502962
[32m[0512 00:33:55 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:55 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:55 @base_trainer.py:216][0m Mean reward: -91.41142645030487
[32m[0512 00:33:55 @base_main.py:38][0m --------------- Iteration 86 ---------------
[32m[0512 00:33:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0278 mins
[32m[0512 00:33:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 00:33:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0512 00:33:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:55 @base_main.py:47][0m 86430 total steps have happened
[32m[0512 00:33:55 @base_main.py:52][0m [avg_reward]: -91.41142645030487
[32m[0512 00:33:55 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:55 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:55 @base_trainer.py:216][0m Mean reward: -79.09390861998611
[32m[0512 00:33:56 @base_main.py:38][0m --------------- Iteration 87 ---------------
[32m[0512 00:33:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0401 mins
[32m[0512 00:33:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:33:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0082 mins
[32m[0512 00:33:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:56 @base_main.py:47][0m 87435 total steps have happened
[32m[0512 00:33:56 @base_main.py:52][0m [avg_reward]: -79.09390861998611
[32m[0512 00:33:56 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:56 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:56 @base_trainer.py:216][0m Mean reward: -76.2976285094974
[32m[0512 00:33:57 @base_main.py:38][0m --------------- Iteration 88 ---------------
[32m[0512 00:33:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0512 mins
[32m[0512 00:33:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 00:33:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 00:33:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:57 @base_main.py:47][0m 88440 total steps have happened
[32m[0512 00:33:57 @base_main.py:52][0m [avg_reward]: -76.2976285094974
[32m[0512 00:33:57 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:57 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:57 @base_trainer.py:216][0m Mean reward: -85.45689395006193
[32m[0512 00:33:57 @base_main.py:38][0m --------------- Iteration 89 ---------------
[32m[0512 00:33:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0628 mins
[32m[0512 00:33:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 00:33:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0512 00:33:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:57 @base_main.py:47][0m 89445 total steps have happened
[32m[0512 00:33:57 @base_main.py:52][0m [avg_reward]: -85.45689395006193
[32m[0512 00:33:57 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:57 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:57 @base_trainer.py:216][0m Mean reward: -87.55942419671197
[32m[0512 00:33:58 @base_main.py:38][0m --------------- Iteration 90 ---------------
[32m[0512 00:33:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0744 mins
[32m[0512 00:33:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 00:33:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 00:33:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:58 @base_main.py:47][0m 90450 total steps have happened
[32m[0512 00:33:58 @base_main.py:52][0m [avg_reward]: -87.55942419671197
[32m[0512 00:33:58 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:58 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:58 @base_trainer.py:216][0m Mean reward: -103.26368044115277
[32m[0512 00:33:59 @base_main.py:38][0m --------------- Iteration 91 ---------------
[32m[0512 00:33:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0862 mins
[32m[0512 00:33:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:33:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0512 00:33:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:59 @base_main.py:47][0m 91455 total steps have happened
[32m[0512 00:33:59 @base_main.py:52][0m [avg_reward]: -103.26368044115277
[32m[0512 00:33:59 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:33:59 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:33:59 @base_trainer.py:216][0m Mean reward: -84.34365024895615
[32m[0512 00:33:59 @base_main.py:38][0m --------------- Iteration 92 ---------------
[32m[0512 00:33:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0986 mins
[32m[0512 00:33:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:33:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0512 00:33:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:33:59 @base_main.py:47][0m 92460 total steps have happened
[32m[0512 00:33:59 @base_main.py:52][0m [avg_reward]: -84.34365024895615
[32m[0512 00:34:00 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:00 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:00 @base_trainer.py:216][0m Mean reward: -104.82957397003517
[32m[0512 00:34:00 @base_main.py:38][0m --------------- Iteration 93 ---------------
[32m[0512 00:34:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1114 mins
[32m[0512 00:34:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:34:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0512 00:34:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 00:34:00 @base_main.py:47][0m 93465 total steps have happened
[32m[0512 00:34:00 @base_main.py:52][0m [avg_reward]: -104.82957397003517
[32m[0512 00:34:00 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:00 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:00 @base_trainer.py:216][0m Mean reward: -76.10412245896174
[32m[0512 00:34:01 @base_main.py:38][0m --------------- Iteration 94 ---------------
[32m[0512 00:34:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1239 mins
[32m[0512 00:34:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 00:34:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0512 00:34:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:01 @base_main.py:47][0m 94470 total steps have happened
[32m[0512 00:34:01 @base_main.py:52][0m [avg_reward]: -76.10412245896174
[32m[0512 00:34:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:01 @base_trainer.py:216][0m Mean reward: -86.29667911992917
[32m[0512 00:34:02 @base_main.py:38][0m --------------- Iteration 95 ---------------
[32m[0512 00:34:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1362 mins
[32m[0512 00:34:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 00:34:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 00:34:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:02 @base_main.py:47][0m 95475 total steps have happened
[32m[0512 00:34:02 @base_main.py:52][0m [avg_reward]: -86.29667911992917
[32m[0512 00:34:02 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:02 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:02 @base_trainer.py:216][0m Mean reward: -71.67618873156775
[32m[0512 00:34:02 @base_main.py:38][0m --------------- Iteration 96 ---------------
[32m[0512 00:34:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1480 mins
[32m[0512 00:34:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0512 00:34:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0512 00:34:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:02 @base_main.py:47][0m 96480 total steps have happened
[32m[0512 00:34:02 @base_main.py:52][0m [avg_reward]: -71.67618873156775
[32m[0512 00:34:03 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:03 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:03 @base_trainer.py:216][0m Mean reward: -84.65734660389555
[32m[0512 00:34:03 @base_main.py:38][0m --------------- Iteration 97 ---------------
[32m[0512 00:34:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1605 mins
[32m[0512 00:34:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:34:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0084 mins
[32m[0512 00:34:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:03 @base_main.py:47][0m 97485 total steps have happened
[32m[0512 00:34:03 @base_main.py:52][0m [avg_reward]: -84.65734660389555
[32m[0512 00:34:03 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:03 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:03 @base_trainer.py:216][0m Mean reward: -82.11876600406181
[32m[0512 00:34:04 @base_main.py:38][0m --------------- Iteration 98 ---------------
[32m[0512 00:34:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1718 mins
[32m[0512 00:34:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:34:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0080 mins
[32m[0512 00:34:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:04 @base_main.py:47][0m 98490 total steps have happened
[32m[0512 00:34:04 @base_main.py:52][0m [avg_reward]: -82.11876600406181
[32m[0512 00:34:04 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:04 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:04 @base_trainer.py:216][0m Mean reward: -73.284076681463
[32m[0512 00:34:04 @base_main.py:38][0m --------------- Iteration 99 ---------------
[32m[0512 00:34:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1828 mins
[32m[0512 00:34:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 00:34:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 00:34:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 00:34:04 @base_main.py:47][0m 99495 total steps have happened
[32m[0512 00:34:04 @base_main.py:52][0m [avg_reward]: -73.284076681463
[32m[0512 00:34:05 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:05 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:05 @base_trainer.py:216][0m Mean reward: -70.90176707453824
[32m[0512 00:34:05 @base_main.py:38][0m --------------- Iteration 100 ---------------
[32m[0512 00:34:05 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1947 mins
[32m[0512 00:34:05 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:34:05 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0512 00:34:05 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 00:34:05 @base_main.py:47][0m 100500 total steps have happened
[32m[0512 00:34:05 @base_main.py:52][0m [avg_reward]: -70.90176707453824
[32m[0512 00:34:05 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:05 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:05 @base_trainer.py:216][0m Mean reward: -75.08363380245689
[32m[0512 00:34:06 @base_main.py:38][0m --------------- Iteration 101 ---------------
[32m[0512 00:34:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2062 mins
[32m[0512 00:34:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 00:34:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0082 mins
[32m[0512 00:34:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:06 @base_main.py:47][0m 101505 total steps have happened
[32m[0512 00:34:06 @base_main.py:52][0m [avg_reward]: -75.08363380245689
[32m[0512 00:34:06 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:06 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:06 @base_trainer.py:216][0m Mean reward: -73.10636200965656
[32m[0512 00:34:07 @base_main.py:38][0m --------------- Iteration 102 ---------------
[32m[0512 00:34:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2176 mins
[32m[0512 00:34:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:34:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 00:34:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:07 @base_main.py:47][0m 102510 total steps have happened
[32m[0512 00:34:07 @base_main.py:52][0m [avg_reward]: -73.10636200965656
[32m[0512 00:34:07 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:07 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:07 @base_trainer.py:216][0m Mean reward: -71.49650956269487
[32m[0512 00:34:07 @base_main.py:38][0m --------------- Iteration 103 ---------------
[32m[0512 00:34:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2291 mins
[32m[0512 00:34:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:34:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0512 00:34:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:07 @base_main.py:47][0m 103515 total steps have happened
[32m[0512 00:34:07 @base_main.py:52][0m [avg_reward]: -71.49650956269487
[32m[0512 00:34:07 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:07 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:07 @base_trainer.py:216][0m Mean reward: -71.70973176723955
[32m[0512 00:34:08 @base_main.py:38][0m --------------- Iteration 104 ---------------
[32m[0512 00:34:08 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2408 mins
[32m[0512 00:34:08 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 00:34:08 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0512 00:34:08 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:08 @base_main.py:47][0m 104520 total steps have happened
[32m[0512 00:34:08 @base_main.py:52][0m [avg_reward]: -71.70973176723955
[32m[0512 00:34:08 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:08 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:08 @base_trainer.py:216][0m Mean reward: -69.47162915232406
[32m[0512 00:34:09 @base_main.py:38][0m --------------- Iteration 105 ---------------
[32m[0512 00:34:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2529 mins
[32m[0512 00:34:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 00:34:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0512 00:34:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:09 @base_main.py:47][0m 105525 total steps have happened
[32m[0512 00:34:09 @base_main.py:52][0m [avg_reward]: -69.47162915232406
[32m[0512 00:34:09 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:09 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:09 @base_trainer.py:216][0m Mean reward: -70.15985643778103
[32m[0512 00:34:09 @base_main.py:38][0m --------------- Iteration 106 ---------------
[32m[0512 00:34:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2649 mins
[32m[0512 00:34:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:34:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0512 00:34:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:09 @base_main.py:47][0m 106530 total steps have happened
[32m[0512 00:34:09 @base_main.py:52][0m [avg_reward]: -70.15985643778103
[32m[0512 00:34:10 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:10 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:10 @base_trainer.py:216][0m Mean reward: -68.41797950836869
[32m[0512 00:34:10 @base_main.py:38][0m --------------- Iteration 107 ---------------
[32m[0512 00:34:10 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2767 mins
[32m[0512 00:34:10 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:34:10 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0512 00:34:10 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:10 @base_main.py:47][0m 107535 total steps have happened
[32m[0512 00:34:10 @base_main.py:52][0m [avg_reward]: -68.41797950836869
[32m[0512 00:34:10 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:10 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:10 @base_trainer.py:216][0m Mean reward: -68.89645447431361
[32m[0512 00:34:11 @base_main.py:38][0m --------------- Iteration 108 ---------------
[32m[0512 00:34:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2881 mins
[32m[0512 00:34:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 00:34:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0512 00:34:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:11 @base_main.py:47][0m 108540 total steps have happened
[32m[0512 00:34:11 @base_main.py:52][0m [avg_reward]: -68.89645447431361
[32m[0512 00:34:11 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:11 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:11 @base_trainer.py:216][0m Mean reward: -77.37445687478173
[32m[0512 00:34:12 @base_main.py:38][0m --------------- Iteration 109 ---------------
[32m[0512 00:34:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3002 mins
[32m[0512 00:34:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:34:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0512 00:34:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 00:34:12 @base_main.py:47][0m 109545 total steps have happened
[32m[0512 00:34:12 @base_main.py:52][0m [avg_reward]: -77.37445687478173
[32m[0512 00:34:12 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:12 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:12 @base_trainer.py:216][0m Mean reward: -63.657776153120494
[32m[0512 00:34:12 @base_main.py:38][0m --------------- Iteration 110 ---------------
[32m[0512 00:34:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3127 mins
[32m[0512 00:34:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 00:34:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0083 mins
[32m[0512 00:34:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:12 @base_main.py:47][0m 110550 total steps have happened
[32m[0512 00:34:12 @base_main.py:52][0m [avg_reward]: -63.657776153120494
[32m[0512 00:34:12 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:12 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:12 @base_trainer.py:216][0m Mean reward: -64.33923774124614
[32m[0512 00:34:13 @base_main.py:38][0m --------------- Iteration 111 ---------------
[32m[0512 00:34:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3241 mins
[32m[0512 00:34:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 00:34:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 00:34:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:13 @base_main.py:47][0m 111555 total steps have happened
[32m[0512 00:34:13 @base_main.py:52][0m [avg_reward]: -64.33923774124614
[32m[0512 00:34:13 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:13 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:13 @base_trainer.py:216][0m Mean reward: -62.21013003436843
[32m[0512 00:34:14 @base_main.py:38][0m --------------- Iteration 112 ---------------
[32m[0512 00:34:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3355 mins
[32m[0512 00:34:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 00:34:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 00:34:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:14 @base_main.py:47][0m 112560 total steps have happened
[32m[0512 00:34:14 @base_main.py:52][0m [avg_reward]: -62.21013003436843
[32m[0512 00:34:14 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:14 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:14 @base_trainer.py:216][0m Mean reward: -59.808117684012224
[32m[0512 00:34:14 @base_main.py:38][0m --------------- Iteration 113 ---------------
[32m[0512 00:34:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3473 mins
[32m[0512 00:34:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:34:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0512 00:34:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:14 @base_main.py:47][0m 113565 total steps have happened
[32m[0512 00:34:14 @base_main.py:52][0m [avg_reward]: -59.808117684012224
[32m[0512 00:34:14 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:14 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:14 @base_trainer.py:216][0m Mean reward: -59.996907463517665
[32m[0512 00:34:15 @base_main.py:38][0m --------------- Iteration 114 ---------------
[32m[0512 00:34:15 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3587 mins
[32m[0512 00:34:15 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 00:34:15 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0512 00:34:15 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:15 @base_main.py:47][0m 114570 total steps have happened
[32m[0512 00:34:15 @base_main.py:52][0m [avg_reward]: -59.996907463517665
[32m[0512 00:34:15 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:15 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:15 @base_trainer.py:216][0m Mean reward: -55.855317257472976
[32m[0512 00:34:16 @base_main.py:38][0m --------------- Iteration 115 ---------------
[32m[0512 00:34:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3710 mins
[32m[0512 00:34:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 00:34:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0512 00:34:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:16 @base_main.py:47][0m 115575 total steps have happened
[32m[0512 00:34:16 @base_main.py:52][0m [avg_reward]: -55.855317257472976
[32m[0512 00:34:16 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:16 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:16 @base_trainer.py:216][0m Mean reward: -55.51059359947673
[32m[0512 00:34:16 @base_main.py:38][0m --------------- Iteration 116 ---------------
[32m[0512 00:34:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3828 mins
[32m[0512 00:34:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0512 00:34:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 00:34:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:16 @base_main.py:47][0m 116580 total steps have happened
[32m[0512 00:34:16 @base_main.py:52][0m [avg_reward]: -55.51059359947673
[32m[0512 00:34:17 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:17 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:17 @base_trainer.py:216][0m Mean reward: -52.26339341320229
[32m[0512 00:34:17 @base_main.py:38][0m --------------- Iteration 117 ---------------
[32m[0512 00:34:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3947 mins
[32m[0512 00:34:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 00:34:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0512 00:34:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:17 @base_main.py:47][0m 117585 total steps have happened
[32m[0512 00:34:17 @base_main.py:52][0m [avg_reward]: -52.26339341320229
[32m[0512 00:34:17 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:17 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:17 @base_trainer.py:216][0m Mean reward: -56.86768481553183
[32m[0512 00:34:18 @base_main.py:38][0m --------------- Iteration 118 ---------------
[32m[0512 00:34:18 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4064 mins
[32m[0512 00:34:18 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:34:18 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0512 00:34:18 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:18 @base_main.py:47][0m 118590 total steps have happened
[32m[0512 00:34:18 @base_main.py:52][0m [avg_reward]: -56.86768481553183
[32m[0512 00:34:18 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:18 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:18 @base_trainer.py:216][0m Mean reward: -59.63147671301374
[32m[0512 00:34:19 @base_main.py:38][0m --------------- Iteration 119 ---------------
[32m[0512 00:34:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4183 mins
[32m[0512 00:34:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:34:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0084 mins
[32m[0512 00:34:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 00:34:19 @base_main.py:47][0m 119595 total steps have happened
[32m[0512 00:34:19 @base_main.py:52][0m [avg_reward]: -59.63147671301374
[32m[0512 00:34:19 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:19 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:19 @base_trainer.py:216][0m Mean reward: -54.09187469644854
[32m[0512 00:34:19 @base_main.py:38][0m --------------- Iteration 120 ---------------
[32m[0512 00:34:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4296 mins
[32m[0512 00:34:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 00:34:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 00:34:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:19 @base_main.py:47][0m 120600 total steps have happened
[32m[0512 00:34:19 @base_main.py:52][0m [avg_reward]: -54.09187469644854
[32m[0512 00:34:19 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:19 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:19 @base_trainer.py:216][0m Mean reward: -50.22760793343411
[32m[0512 00:34:20 @base_main.py:38][0m --------------- Iteration 121 ---------------
[32m[0512 00:34:20 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4417 mins
[32m[0512 00:34:20 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:34:20 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0080 mins
[32m[0512 00:34:20 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:20 @base_main.py:47][0m 121605 total steps have happened
[32m[0512 00:34:20 @base_main.py:52][0m [avg_reward]: -50.22760793343411
[32m[0512 00:34:20 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:20 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:20 @base_trainer.py:216][0m Mean reward: -47.02869013025811
[32m[0512 00:34:21 @base_main.py:38][0m --------------- Iteration 122 ---------------
[32m[0512 00:34:21 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4525 mins
[32m[0512 00:34:21 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 00:34:21 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0512 00:34:21 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 00:34:21 @base_main.py:47][0m 122610 total steps have happened
[32m[0512 00:34:21 @base_main.py:52][0m [avg_reward]: -47.02869013025811
[32m[0512 00:34:21 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:21 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:21 @base_trainer.py:216][0m Mean reward: -50.27610098727475
[32m[0512 00:34:21 @base_main.py:38][0m --------------- Iteration 123 ---------------
[32m[0512 00:34:21 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4655 mins
[32m[0512 00:34:21 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 00:34:21 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 00:34:21 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:21 @base_main.py:47][0m 123615 total steps have happened
[32m[0512 00:34:21 @base_main.py:52][0m [avg_reward]: -50.27610098727475
[32m[0512 00:34:22 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:22 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:22 @base_trainer.py:216][0m Mean reward: -55.80221584563552
[32m[0512 00:34:22 @base_main.py:38][0m --------------- Iteration 124 ---------------
[32m[0512 00:34:22 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4777 mins
[32m[0512 00:34:22 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:34:22 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0512 00:34:22 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 00:34:22 @base_main.py:47][0m 124620 total steps have happened
[32m[0512 00:34:22 @base_main.py:52][0m [avg_reward]: -55.80221584563552
[32m[0512 00:34:22 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:22 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:22 @base_trainer.py:216][0m Mean reward: -49.69428419736116
[32m[0512 00:34:23 @base_main.py:38][0m --------------- Iteration 125 ---------------
[32m[0512 00:34:23 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4904 mins
[32m[0512 00:34:23 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 00:34:23 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0512 00:34:23 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:23 @base_main.py:47][0m 125625 total steps have happened
[32m[0512 00:34:23 @base_main.py:52][0m [avg_reward]: -49.69428419736116
[32m[0512 00:34:23 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:23 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:23 @base_trainer.py:216][0m Mean reward: -59.23541720506431
[32m[0512 00:34:24 @base_main.py:38][0m --------------- Iteration 126 ---------------
[32m[0512 00:34:24 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5023 mins
[32m[0512 00:34:24 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:34:24 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 00:34:24 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:24 @base_main.py:47][0m 126630 total steps have happened
[32m[0512 00:34:24 @base_main.py:52][0m [avg_reward]: -59.23541720506431
[32m[0512 00:34:24 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:24 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:24 @base_trainer.py:216][0m Mean reward: -46.77269703783772
[32m[0512 00:34:24 @base_main.py:38][0m --------------- Iteration 127 ---------------
[32m[0512 00:34:24 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5142 mins
[32m[0512 00:34:24 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 00:34:24 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 00:34:24 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:24 @base_main.py:47][0m 127635 total steps have happened
[32m[0512 00:34:24 @base_main.py:52][0m [avg_reward]: -46.77269703783772
[32m[0512 00:34:25 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:25 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:25 @base_trainer.py:216][0m Mean reward: -46.38557636508828
[32m[0512 00:34:25 @base_main.py:38][0m --------------- Iteration 128 ---------------
[32m[0512 00:34:25 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5263 mins
[32m[0512 00:34:25 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:34:25 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0512 00:34:25 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 00:34:25 @base_main.py:47][0m 128640 total steps have happened
[32m[0512 00:34:25 @base_main.py:52][0m [avg_reward]: -46.38557636508828
[32m[0512 00:34:25 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:25 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:25 @base_trainer.py:216][0m Mean reward: -45.76447846983248
[32m[0512 00:34:26 @base_main.py:38][0m --------------- Iteration 129 ---------------
[32m[0512 00:34:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5385 mins
[32m[0512 00:34:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 00:34:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0512 00:34:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:26 @base_main.py:47][0m 129645 total steps have happened
[32m[0512 00:34:26 @base_main.py:52][0m [avg_reward]: -45.76447846983248
[32m[0512 00:34:26 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:26 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:26 @base_trainer.py:216][0m Mean reward: -48.246862877202865
[32m[0512 00:34:26 @base_main.py:38][0m --------------- Iteration 130 ---------------
[32m[0512 00:34:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5504 mins
[32m[0512 00:34:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:34:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0512 00:34:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:26 @base_main.py:47][0m 130650 total steps have happened
[32m[0512 00:34:26 @base_main.py:52][0m [avg_reward]: -48.246862877202865
[32m[0512 00:34:27 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:27 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:27 @base_trainer.py:216][0m Mean reward: -47.8682240078479
[32m[0512 00:34:27 @base_main.py:38][0m --------------- Iteration 131 ---------------
[32m[0512 00:34:27 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5619 mins
[32m[0512 00:34:27 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:34:27 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0512 00:34:27 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:27 @base_main.py:47][0m 131655 total steps have happened
[32m[0512 00:34:27 @base_main.py:52][0m [avg_reward]: -47.8682240078479
[32m[0512 00:34:27 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:27 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:27 @base_trainer.py:216][0m Mean reward: -45.37267765006531
[32m[0512 00:34:28 @base_main.py:38][0m --------------- Iteration 132 ---------------
[32m[0512 00:34:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5733 mins
[32m[0512 00:34:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 00:34:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0512 00:34:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 00:34:28 @base_main.py:47][0m 132660 total steps have happened
[32m[0512 00:34:28 @base_main.py:52][0m [avg_reward]: -45.37267765006531
[32m[0512 00:34:28 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:28 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:28 @base_trainer.py:216][0m Mean reward: -45.89977502394324
[32m[0512 00:34:29 @base_main.py:38][0m --------------- Iteration 133 ---------------
[32m[0512 00:34:29 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5857 mins
[32m[0512 00:34:29 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0032 mins
[32m[0512 00:34:29 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 00:34:29 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:29 @base_main.py:47][0m 133665 total steps have happened
[32m[0512 00:34:29 @base_main.py:52][0m [avg_reward]: -45.89977502394324
[32m[0512 00:34:29 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:29 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:29 @base_trainer.py:216][0m Mean reward: -49.93262401294906
[32m[0512 00:34:29 @base_main.py:38][0m --------------- Iteration 134 ---------------
[32m[0512 00:34:29 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5981 mins
[32m[0512 00:34:29 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 00:34:29 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0512 00:34:29 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:29 @base_main.py:47][0m 134670 total steps have happened
[32m[0512 00:34:29 @base_main.py:52][0m [avg_reward]: -49.93262401294906
[32m[0512 00:34:30 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:30 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:30 @base_trainer.py:216][0m Mean reward: -44.290726373878314
[32m[0512 00:34:30 @base_main.py:38][0m --------------- Iteration 135 ---------------
[32m[0512 00:34:30 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6108 mins
[32m[0512 00:34:30 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:34:30 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0512 00:34:30 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:30 @base_main.py:47][0m 135675 total steps have happened
[32m[0512 00:34:30 @base_main.py:52][0m [avg_reward]: -44.290726373878314
[32m[0512 00:34:30 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:30 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:30 @base_trainer.py:216][0m Mean reward: -44.60343948219455
[32m[0512 00:34:31 @base_main.py:38][0m --------------- Iteration 136 ---------------
[32m[0512 00:34:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6238 mins
[32m[0512 00:34:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 00:34:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 00:34:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:31 @base_main.py:47][0m 136680 total steps have happened
[32m[0512 00:34:31 @base_main.py:52][0m [avg_reward]: -44.60343948219455
[32m[0512 00:34:31 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:31 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:31 @base_trainer.py:216][0m Mean reward: -43.60364309372757
[32m[0512 00:34:32 @base_main.py:38][0m --------------- Iteration 137 ---------------
[32m[0512 00:34:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6355 mins
[32m[0512 00:34:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:34:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0512 00:34:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:32 @base_main.py:47][0m 137685 total steps have happened
[32m[0512 00:34:32 @base_main.py:52][0m [avg_reward]: -43.60364309372757
[32m[0512 00:34:32 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:32 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:32 @base_trainer.py:216][0m Mean reward: -44.384805453545454
[32m[0512 00:34:32 @base_main.py:38][0m --------------- Iteration 138 ---------------
[32m[0512 00:34:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6477 mins
[32m[0512 00:34:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 00:34:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0512 00:34:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:32 @base_main.py:47][0m 138690 total steps have happened
[32m[0512 00:34:32 @base_main.py:52][0m [avg_reward]: -44.384805453545454
[32m[0512 00:34:33 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:33 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:33 @base_trainer.py:216][0m Mean reward: -43.031104687329105
[32m[0512 00:34:33 @base_main.py:38][0m --------------- Iteration 139 ---------------
[32m[0512 00:34:33 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6595 mins
[32m[0512 00:34:33 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:34:33 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0512 00:34:33 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:33 @base_main.py:47][0m 139695 total steps have happened
[32m[0512 00:34:33 @base_main.py:52][0m [avg_reward]: -43.031104687329105
[32m[0512 00:34:33 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:33 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:33 @base_trainer.py:216][0m Mean reward: -41.015735018488265
[32m[0512 00:34:34 @base_main.py:38][0m --------------- Iteration 140 ---------------
[32m[0512 00:34:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6718 mins
[32m[0512 00:34:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 00:34:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 00:34:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:34 @base_main.py:47][0m 140700 total steps have happened
[32m[0512 00:34:34 @base_main.py:52][0m [avg_reward]: -41.015735018488265
[32m[0512 00:34:34 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:34 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:34 @base_trainer.py:216][0m Mean reward: -41.31993718753162
[32m[0512 00:34:35 @base_main.py:38][0m --------------- Iteration 141 ---------------
[32m[0512 00:34:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6836 mins
[32m[0512 00:34:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:34:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 00:34:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:35 @base_main.py:47][0m 141705 total steps have happened
[32m[0512 00:34:35 @base_main.py:52][0m [avg_reward]: -41.31993718753162
[32m[0512 00:34:35 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:35 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:35 @base_trainer.py:216][0m Mean reward: -41.58774495191656
[32m[0512 00:34:35 @base_main.py:38][0m --------------- Iteration 142 ---------------
[32m[0512 00:34:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6956 mins
[32m[0512 00:34:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:34:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 00:34:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:35 @base_main.py:47][0m 142710 total steps have happened
[32m[0512 00:34:35 @base_main.py:52][0m [avg_reward]: -41.58774495191656
[32m[0512 00:34:35 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:35 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:35 @base_trainer.py:216][0m Mean reward: -39.49470801342486
[32m[0512 00:34:36 @base_main.py:38][0m --------------- Iteration 143 ---------------
[32m[0512 00:34:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7075 mins
[32m[0512 00:34:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:34:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0512 00:34:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:36 @base_main.py:47][0m 143715 total steps have happened
[32m[0512 00:34:36 @base_main.py:52][0m [avg_reward]: -39.49470801342486
[32m[0512 00:34:36 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:36 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:36 @base_trainer.py:216][0m Mean reward: -44.80007417217358
[32m[0512 00:34:37 @base_main.py:38][0m --------------- Iteration 144 ---------------
[32m[0512 00:34:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7199 mins
[32m[0512 00:34:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0512 00:34:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0512 00:34:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:37 @base_main.py:47][0m 144720 total steps have happened
[32m[0512 00:34:37 @base_main.py:52][0m [avg_reward]: -44.80007417217358
[32m[0512 00:34:37 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:37 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:37 @base_trainer.py:216][0m Mean reward: -39.524633729091974
[32m[0512 00:34:37 @base_main.py:38][0m --------------- Iteration 145 ---------------
[32m[0512 00:34:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7320 mins
[32m[0512 00:34:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:34:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0512 00:34:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:37 @base_main.py:47][0m 145725 total steps have happened
[32m[0512 00:34:37 @base_main.py:52][0m [avg_reward]: -39.524633729091974
[32m[0512 00:34:38 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:38 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:38 @base_trainer.py:216][0m Mean reward: -40.242499061369756
[32m[0512 00:34:38 @base_main.py:38][0m --------------- Iteration 146 ---------------
[32m[0512 00:34:38 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7437 mins
[32m[0512 00:34:38 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 00:34:38 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 00:34:38 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:38 @base_main.py:47][0m 146730 total steps have happened
[32m[0512 00:34:38 @base_main.py:52][0m [avg_reward]: -40.242499061369756
[32m[0512 00:34:38 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:38 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:38 @base_trainer.py:216][0m Mean reward: -39.27274696107402
[32m[0512 00:34:39 @base_main.py:38][0m --------------- Iteration 147 ---------------
[32m[0512 00:34:39 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7558 mins
[32m[0512 00:34:39 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0512 00:34:39 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0084 mins
[32m[0512 00:34:39 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:39 @base_main.py:47][0m 147735 total steps have happened
[32m[0512 00:34:39 @base_main.py:52][0m [avg_reward]: -39.27274696107402
[32m[0512 00:34:39 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:39 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:39 @base_trainer.py:216][0m Mean reward: -40.089292108015286
[32m[0512 00:34:40 @base_main.py:38][0m --------------- Iteration 148 ---------------
[32m[0512 00:34:40 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7675 mins
[32m[0512 00:34:40 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:34:40 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0512 00:34:40 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:40 @base_main.py:47][0m 148740 total steps have happened
[32m[0512 00:34:40 @base_main.py:52][0m [avg_reward]: -40.089292108015286
[32m[0512 00:34:40 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:40 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:40 @base_trainer.py:216][0m Mean reward: -49.87600825174371
[32m[0512 00:34:40 @base_main.py:38][0m --------------- Iteration 149 ---------------
[32m[0512 00:34:40 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7803 mins
[32m[0512 00:34:40 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 00:34:40 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0512 00:34:40 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:40 @base_main.py:47][0m 149745 total steps have happened
[32m[0512 00:34:40 @base_main.py:52][0m [avg_reward]: -49.87600825174371
[32m[0512 00:34:40 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:40 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:40 @base_trainer.py:216][0m Mean reward: -42.412996054823395
[32m[0512 00:34:41 @base_main.py:38][0m --------------- Iteration 150 ---------------
[32m[0512 00:34:41 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7923 mins
[32m[0512 00:34:41 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:34:41 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0081 mins
[32m[0512 00:34:41 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:41 @base_main.py:47][0m 150750 total steps have happened
[32m[0512 00:34:41 @base_main.py:52][0m [avg_reward]: -42.412996054823395
[32m[0512 00:34:41 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:41 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:41 @base_trainer.py:216][0m Mean reward: -41.111715917534156
[32m[0512 00:34:42 @base_main.py:38][0m --------------- Iteration 151 ---------------
[32m[0512 00:34:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8032 mins
[32m[0512 00:34:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0512 00:34:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0085 mins
[32m[0512 00:34:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:42 @base_main.py:47][0m 151755 total steps have happened
[32m[0512 00:34:42 @base_main.py:52][0m [avg_reward]: -41.111715917534156
[32m[0512 00:34:42 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:42 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:42 @base_trainer.py:216][0m Mean reward: -41.92157505247573
[32m[0512 00:34:42 @base_main.py:38][0m --------------- Iteration 152 ---------------
[32m[0512 00:34:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8142 mins
[32m[0512 00:34:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 00:34:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 00:34:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:42 @base_main.py:47][0m 152760 total steps have happened
[32m[0512 00:34:42 @base_main.py:52][0m [avg_reward]: -41.92157505247573
[32m[0512 00:34:43 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:43 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:43 @base_trainer.py:216][0m Mean reward: -41.22252103354392
[32m[0512 00:34:43 @base_main.py:38][0m --------------- Iteration 153 ---------------
[32m[0512 00:34:43 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8260 mins
[32m[0512 00:34:43 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 00:34:43 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 00:34:43 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:43 @base_main.py:47][0m 153765 total steps have happened
[32m[0512 00:34:43 @base_main.py:52][0m [avg_reward]: -41.22252103354392
[32m[0512 00:34:43 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:43 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:43 @base_trainer.py:216][0m Mean reward: -41.365182182895516
[32m[0512 00:34:44 @base_main.py:38][0m --------------- Iteration 154 ---------------
[32m[0512 00:34:44 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8381 mins
[32m[0512 00:34:44 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:34:44 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0512 00:34:44 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:44 @base_main.py:47][0m 154770 total steps have happened
[32m[0512 00:34:44 @base_main.py:52][0m [avg_reward]: -41.365182182895516
[32m[0512 00:34:44 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:44 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:44 @base_trainer.py:216][0m Mean reward: -41.987645149321494
[32m[0512 00:34:45 @base_main.py:38][0m --------------- Iteration 155 ---------------
[32m[0512 00:34:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8509 mins
[32m[0512 00:34:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 00:34:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0512 00:34:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:45 @base_main.py:47][0m 155775 total steps have happened
[32m[0512 00:34:45 @base_main.py:52][0m [avg_reward]: -41.987645149321494
[32m[0512 00:34:45 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:45 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:45 @base_trainer.py:216][0m Mean reward: -40.42463792990691
[32m[0512 00:34:45 @base_main.py:38][0m --------------- Iteration 156 ---------------
[32m[0512 00:34:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8628 mins
[32m[0512 00:34:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:34:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 00:34:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:45 @base_main.py:47][0m 156780 total steps have happened
[32m[0512 00:34:45 @base_main.py:52][0m [avg_reward]: -40.42463792990691
[32m[0512 00:34:45 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:45 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:45 @base_trainer.py:216][0m Mean reward: -53.14172697522743
[32m[0512 00:34:46 @base_main.py:38][0m --------------- Iteration 157 ---------------
[32m[0512 00:34:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8746 mins
[32m[0512 00:34:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:34:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0087 mins
[32m[0512 00:34:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:46 @base_main.py:47][0m 157785 total steps have happened
[32m[0512 00:34:46 @base_main.py:52][0m [avg_reward]: -53.14172697522743
[32m[0512 00:34:46 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:46 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:46 @base_trainer.py:216][0m Mean reward: -41.21238062149014
[32m[0512 00:34:47 @base_main.py:38][0m --------------- Iteration 158 ---------------
[32m[0512 00:34:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8862 mins
[32m[0512 00:34:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 00:34:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0512 00:34:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:47 @base_main.py:47][0m 158790 total steps have happened
[32m[0512 00:34:47 @base_main.py:52][0m [avg_reward]: -41.21238062149014
[32m[0512 00:34:47 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:47 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:47 @base_trainer.py:216][0m Mean reward: -55.29058507874531
[32m[0512 00:34:47 @base_main.py:38][0m --------------- Iteration 159 ---------------
[32m[0512 00:34:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8980 mins
[32m[0512 00:34:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:34:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0512 00:34:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:47 @base_main.py:47][0m 159795 total steps have happened
[32m[0512 00:34:47 @base_main.py:52][0m [avg_reward]: -55.29058507874531
[32m[0512 00:34:48 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:48 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:48 @base_trainer.py:216][0m Mean reward: -58.94324040494486
[32m[0512 00:34:48 @base_main.py:38][0m --------------- Iteration 160 ---------------
[32m[0512 00:34:48 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9097 mins
[32m[0512 00:34:48 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:34:48 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0082 mins
[32m[0512 00:34:48 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:48 @base_main.py:47][0m 160800 total steps have happened
[32m[0512 00:34:48 @base_main.py:52][0m [avg_reward]: -58.94324040494486
[32m[0512 00:34:48 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:48 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:48 @base_trainer.py:216][0m Mean reward: -45.12870867783799
[32m[0512 00:34:49 @base_main.py:38][0m --------------- Iteration 161 ---------------
[32m[0512 00:34:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9208 mins
[32m[0512 00:34:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 00:34:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 00:34:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:49 @base_main.py:47][0m 161805 total steps have happened
[32m[0512 00:34:49 @base_main.py:52][0m [avg_reward]: -45.12870867783799
[32m[0512 00:34:49 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:49 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:49 @base_trainer.py:216][0m Mean reward: -40.74961031388225
[32m[0512 00:34:49 @base_main.py:38][0m --------------- Iteration 162 ---------------
[32m[0512 00:34:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9325 mins
[32m[0512 00:34:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 00:34:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 00:34:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:49 @base_main.py:47][0m 162810 total steps have happened
[32m[0512 00:34:49 @base_main.py:52][0m [avg_reward]: -40.74961031388225
[32m[0512 00:34:50 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:50 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:50 @base_trainer.py:216][0m Mean reward: -41.30770910643999
[32m[0512 00:34:50 @base_main.py:38][0m --------------- Iteration 163 ---------------
[32m[0512 00:34:50 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9448 mins
[32m[0512 00:34:50 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:34:50 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0512 00:34:50 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:50 @base_main.py:47][0m 163815 total steps have happened
[32m[0512 00:34:50 @base_main.py:52][0m [avg_reward]: -41.30770910643999
[32m[0512 00:34:50 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:50 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:50 @base_trainer.py:216][0m Mean reward: -36.3598934397898
[32m[0512 00:34:51 @base_main.py:38][0m --------------- Iteration 164 ---------------
[32m[0512 00:34:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9563 mins
[32m[0512 00:34:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:34:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0512 00:34:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:51 @base_main.py:47][0m 164820 total steps have happened
[32m[0512 00:34:51 @base_main.py:52][0m [avg_reward]: -36.3598934397898
[32m[0512 00:34:51 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:51 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:51 @base_trainer.py:216][0m Mean reward: -41.15935405292835
[32m[0512 00:34:52 @base_main.py:38][0m --------------- Iteration 165 ---------------
[32m[0512 00:34:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9680 mins
[32m[0512 00:34:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0033 mins
[32m[0512 00:34:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0080 mins
[32m[0512 00:34:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:52 @base_main.py:47][0m 165825 total steps have happened
[32m[0512 00:34:52 @base_main.py:52][0m [avg_reward]: -41.15935405292835
[32m[0512 00:34:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:52 @base_trainer.py:216][0m Mean reward: -40.1029784260267
[32m[0512 00:34:52 @base_main.py:38][0m --------------- Iteration 166 ---------------
[32m[0512 00:34:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9794 mins
[32m[0512 00:34:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0037 mins
[32m[0512 00:34:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0512 00:34:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:52 @base_main.py:47][0m 166830 total steps have happened
[32m[0512 00:34:52 @base_main.py:52][0m [avg_reward]: -40.1029784260267
[32m[0512 00:34:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:52 @base_trainer.py:216][0m Mean reward: -40.36911063642774
[32m[0512 00:34:53 @base_main.py:38][0m --------------- Iteration 167 ---------------
[32m[0512 00:34:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9921 mins
[32m[0512 00:34:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:34:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0512 00:34:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:53 @base_main.py:47][0m 167835 total steps have happened
[32m[0512 00:34:53 @base_main.py:52][0m [avg_reward]: -40.36911063642774
[32m[0512 00:34:53 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:53 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:53 @base_trainer.py:216][0m Mean reward: -45.24609930321678
[32m[0512 00:34:54 @base_main.py:38][0m --------------- Iteration 168 ---------------
[32m[0512 00:34:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0035 mins
[32m[0512 00:34:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:34:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0512 00:34:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:54 @base_main.py:47][0m 168840 total steps have happened
[32m[0512 00:34:54 @base_main.py:52][0m [avg_reward]: -45.24609930321678
[32m[0512 00:34:54 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:54 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:54 @base_trainer.py:216][0m Mean reward: -39.131403066552934
[32m[0512 00:34:54 @base_main.py:38][0m --------------- Iteration 169 ---------------
[32m[0512 00:34:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0150 mins
[32m[0512 00:34:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:34:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0512 00:34:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:54 @base_main.py:47][0m 169845 total steps have happened
[32m[0512 00:34:54 @base_main.py:52][0m [avg_reward]: -39.131403066552934
[32m[0512 00:34:55 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:55 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:55 @base_trainer.py:216][0m Mean reward: -39.98976686923494
[32m[0512 00:34:55 @base_main.py:38][0m --------------- Iteration 170 ---------------
[32m[0512 00:34:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0273 mins
[32m[0512 00:34:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 00:34:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0081 mins
[32m[0512 00:34:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:55 @base_main.py:47][0m 170850 total steps have happened
[32m[0512 00:34:55 @base_main.py:52][0m [avg_reward]: -39.98976686923494
[32m[0512 00:34:55 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:55 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:55 @base_trainer.py:216][0m Mean reward: -59.36246265637557
[32m[0512 00:34:56 @base_main.py:38][0m --------------- Iteration 171 ---------------
[32m[0512 00:34:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0380 mins
[32m[0512 00:34:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 00:34:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 00:34:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:56 @base_main.py:47][0m 171855 total steps have happened
[32m[0512 00:34:56 @base_main.py:52][0m [avg_reward]: -59.36246265637557
[32m[0512 00:34:56 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:56 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:56 @base_trainer.py:216][0m Mean reward: -40.57386493019833
[32m[0512 00:34:56 @base_main.py:38][0m --------------- Iteration 172 ---------------
[32m[0512 00:34:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0497 mins
[32m[0512 00:34:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:34:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0512 00:34:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:56 @base_main.py:47][0m 172860 total steps have happened
[32m[0512 00:34:56 @base_main.py:52][0m [avg_reward]: -40.57386493019833
[32m[0512 00:34:57 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:57 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:57 @base_trainer.py:216][0m Mean reward: -39.79020873490077
[32m[0512 00:34:57 @base_main.py:38][0m --------------- Iteration 173 ---------------
[32m[0512 00:34:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0613 mins
[32m[0512 00:34:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 00:34:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0078 mins
[32m[0512 00:34:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:57 @base_main.py:47][0m 173865 total steps have happened
[32m[0512 00:34:57 @base_main.py:52][0m [avg_reward]: -39.79020873490077
[32m[0512 00:34:57 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:57 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:57 @base_trainer.py:216][0m Mean reward: -40.22788027522721
[32m[0512 00:34:58 @base_main.py:38][0m --------------- Iteration 174 ---------------
[32m[0512 00:34:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0723 mins
[32m[0512 00:34:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:34:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 00:34:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 00:34:58 @base_main.py:47][0m 174870 total steps have happened
[32m[0512 00:34:58 @base_main.py:52][0m [avg_reward]: -40.22788027522721
[32m[0512 00:34:58 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:58 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:58 @base_trainer.py:216][0m Mean reward: -36.75802002219357
[32m[0512 00:34:59 @base_main.py:38][0m --------------- Iteration 175 ---------------
[32m[0512 00:34:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0843 mins
[32m[0512 00:34:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:34:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0512 00:34:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:34:59 @base_main.py:47][0m 175875 total steps have happened
[32m[0512 00:34:59 @base_main.py:52][0m [avg_reward]: -36.75802002219357
[32m[0512 00:34:59 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:59 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:59 @base_trainer.py:216][0m Mean reward: -37.8110792643658
[32m[0512 00:34:59 @base_main.py:38][0m --------------- Iteration 176 ---------------
[32m[0512 00:34:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0962 mins
[32m[0512 00:34:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 00:34:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0512 00:34:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 00:34:59 @base_main.py:47][0m 176880 total steps have happened
[32m[0512 00:34:59 @base_main.py:52][0m [avg_reward]: -37.8110792643658
[32m[0512 00:34:59 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:34:59 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:34:59 @base_trainer.py:216][0m Mean reward: -40.215832057546734
[32m[0512 00:35:00 @base_main.py:38][0m --------------- Iteration 177 ---------------
[32m[0512 00:35:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1088 mins
[32m[0512 00:35:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:35:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0088 mins
[32m[0512 00:35:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 00:35:00 @base_main.py:47][0m 177885 total steps have happened
[32m[0512 00:35:00 @base_main.py:52][0m [avg_reward]: -40.215832057546734
[32m[0512 00:35:00 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:35:00 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:35:00 @base_trainer.py:216][0m Mean reward: -38.23605791134149
[32m[0512 00:35:01 @base_main.py:38][0m --------------- Iteration 178 ---------------
[32m[0512 00:35:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1205 mins
[32m[0512 00:35:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:35:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0512 00:35:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:35:01 @base_main.py:47][0m 178890 total steps have happened
[32m[0512 00:35:01 @base_main.py:52][0m [avg_reward]: -38.23605791134149
[32m[0512 00:35:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:35:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:35:01 @base_trainer.py:216][0m Mean reward: -42.309789880983374
[32m[0512 00:35:01 @base_main.py:38][0m --------------- Iteration 179 ---------------
[32m[0512 00:35:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1323 mins
[32m[0512 00:35:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0512 00:35:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0512 00:35:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0512 00:35:01 @base_main.py:47][0m 179895 total steps have happened
[32m[0512 00:35:01 @base_main.py:52][0m [avg_reward]: -42.309789880983374
[32m[0512 00:35:02 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:35:02 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:35:02 @base_trainer.py:216][0m Mean reward: -37.416062280685196
[32m[0512 00:35:02 @base_main.py:38][0m --------------- Iteration 180 ---------------
[32m[0512 00:35:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1452 mins
[32m[0512 00:35:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0512 00:35:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 00:35:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:35:02 @base_main.py:47][0m 180900 total steps have happened
[32m[0512 00:35:02 @base_main.py:52][0m [avg_reward]: -37.416062280685196
[32m[0512 00:35:02 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:35:02 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:35:02 @base_trainer.py:216][0m Mean reward: -40.45980824456539
[32m[0512 00:35:03 @base_main.py:38][0m --------------- Iteration 181 ---------------
[32m[0512 00:35:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1573 mins
[32m[0512 00:35:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:35:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0512 00:35:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:35:03 @base_main.py:47][0m 181905 total steps have happened
[32m[0512 00:35:03 @base_main.py:52][0m [avg_reward]: -40.45980824456539
[32m[0512 00:35:03 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:35:03 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:35:03 @base_trainer.py:216][0m Mean reward: -42.52319439663355
[32m[0512 00:35:04 @base_main.py:38][0m --------------- Iteration 182 ---------------
[32m[0512 00:35:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1688 mins
[32m[0512 00:35:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 00:35:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0512 00:35:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:35:04 @base_main.py:47][0m 182910 total steps have happened
[32m[0512 00:35:04 @base_main.py:52][0m [avg_reward]: -42.52319439663355
[32m[0512 00:35:04 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:35:04 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:35:04 @base_trainer.py:216][0m Mean reward: -37.47078206329995
[32m[0512 00:35:04 @base_main.py:38][0m --------------- Iteration 183 ---------------
[32m[0512 00:35:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1812 mins
[32m[0512 00:35:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:35:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0512 00:35:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:35:04 @base_main.py:47][0m 183915 total steps have happened
[32m[0512 00:35:04 @base_main.py:52][0m [avg_reward]: -37.47078206329995
[32m[0512 00:35:05 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:35:05 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:35:05 @base_trainer.py:216][0m Mean reward: -39.091811848447904
[32m[0512 00:35:05 @base_main.py:38][0m --------------- Iteration 184 ---------------
[32m[0512 00:35:05 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1933 mins
[32m[0512 00:35:05 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:35:05 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0512 00:35:05 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:35:05 @base_main.py:47][0m 184920 total steps have happened
[32m[0512 00:35:05 @base_main.py:52][0m [avg_reward]: -39.091811848447904
[32m[0512 00:35:05 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:35:05 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:35:05 @base_trainer.py:216][0m Mean reward: -43.04465525297682
[32m[0512 00:35:06 @base_main.py:38][0m --------------- Iteration 185 ---------------
[32m[0512 00:35:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2050 mins
[32m[0512 00:35:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 00:35:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 00:35:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:35:06 @base_main.py:47][0m 185925 total steps have happened
[32m[0512 00:35:06 @base_main.py:52][0m [avg_reward]: -43.04465525297682
[32m[0512 00:35:06 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:35:06 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:35:06 @base_trainer.py:216][0m Mean reward: -39.222586336684266
[32m[0512 00:35:07 @base_main.py:38][0m --------------- Iteration 186 ---------------
[32m[0512 00:35:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2169 mins
[32m[0512 00:35:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:35:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 00:35:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:35:07 @base_main.py:47][0m 186930 total steps have happened
[32m[0512 00:35:07 @base_main.py:52][0m [avg_reward]: -39.222586336684266
[32m[0512 00:35:07 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:35:07 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:35:07 @base_trainer.py:216][0m Mean reward: -39.67253462602302
[32m[0512 00:35:07 @base_main.py:38][0m --------------- Iteration 187 ---------------
[32m[0512 00:35:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2289 mins
[32m[0512 00:35:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:35:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0082 mins
[32m[0512 00:35:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:35:07 @base_main.py:47][0m 187935 total steps have happened
[32m[0512 00:35:07 @base_main.py:52][0m [avg_reward]: -39.67253462602302
[32m[0512 00:35:07 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:35:07 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:35:07 @base_trainer.py:216][0m Mean reward: -39.398243650015466
[32m[0512 00:35:08 @base_main.py:38][0m --------------- Iteration 188 ---------------
[32m[0512 00:35:08 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2400 mins
[32m[0512 00:35:08 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 00:35:08 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0512 00:35:08 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:35:08 @base_main.py:47][0m 188940 total steps have happened
[32m[0512 00:35:08 @base_main.py:52][0m [avg_reward]: -39.398243650015466
[32m[0512 00:35:08 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:35:08 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:35:08 @base_trainer.py:216][0m Mean reward: -41.31211274056561
[32m[0512 00:35:09 @base_main.py:38][0m --------------- Iteration 189 ---------------
[32m[0512 00:35:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2512 mins
[32m[0512 00:35:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 00:35:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0512 00:35:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:35:09 @base_main.py:47][0m 189945 total steps have happened
[32m[0512 00:35:09 @base_main.py:52][0m [avg_reward]: -41.31211274056561
[32m[0512 00:35:09 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:35:09 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:35:09 @base_trainer.py:216][0m Mean reward: -46.4488613587401
[32m[0512 00:35:09 @base_main.py:38][0m --------------- Iteration 190 ---------------
[32m[0512 00:35:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2636 mins
[32m[0512 00:35:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0512 00:35:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0512 00:35:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:35:09 @base_main.py:47][0m 190950 total steps have happened
[32m[0512 00:35:09 @base_main.py:52][0m [avg_reward]: -46.4488613587401
[32m[0512 00:35:09 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:35:09 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:35:09 @base_trainer.py:216][0m Mean reward: -37.252409436555354
[32m[0512 00:35:10 @base_main.py:38][0m --------------- Iteration 191 ---------------
[32m[0512 00:35:10 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2754 mins
[32m[0512 00:35:10 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0512 00:35:10 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0089 mins
[32m[0512 00:35:10 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:35:10 @base_main.py:47][0m 191955 total steps have happened
[32m[0512 00:35:10 @base_main.py:52][0m [avg_reward]: -37.252409436555354
[32m[0512 00:35:10 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:35:10 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:35:10 @base_trainer.py:216][0m Mean reward: -42.87738475462899
[32m[0512 00:35:11 @base_main.py:38][0m --------------- Iteration 192 ---------------
[32m[0512 00:35:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2876 mins
[32m[0512 00:35:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 00:35:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0512 00:35:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:35:11 @base_main.py:47][0m 192960 total steps have happened
[32m[0512 00:35:11 @base_main.py:52][0m [avg_reward]: -42.87738475462899
[32m[0512 00:35:11 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:35:11 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:35:11 @base_trainer.py:216][0m Mean reward: -38.54043473329718
[32m[0512 00:35:12 @base_main.py:38][0m --------------- Iteration 193 ---------------
[32m[0512 00:35:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3006 mins
[32m[0512 00:35:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 00:35:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 00:35:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:35:12 @base_main.py:47][0m 193965 total steps have happened
[32m[0512 00:35:12 @base_main.py:52][0m [avg_reward]: -38.54043473329718
[32m[0512 00:35:12 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:35:12 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:35:12 @base_trainer.py:216][0m Mean reward: -38.099283556829924
[32m[0512 00:35:12 @base_main.py:38][0m --------------- Iteration 194 ---------------
[32m[0512 00:35:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3123 mins
[32m[0512 00:35:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0512 00:35:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0512 00:35:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:35:12 @base_main.py:47][0m 194970 total steps have happened
[32m[0512 00:35:12 @base_main.py:52][0m [avg_reward]: -38.099283556829924
[32m[0512 00:35:12 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:35:12 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:35:12 @base_trainer.py:216][0m Mean reward: -40.10085328880342
[32m[0512 00:35:13 @base_main.py:38][0m --------------- Iteration 195 ---------------
[32m[0512 00:35:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3244 mins
[32m[0512 00:35:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0033 mins
[32m[0512 00:35:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 00:35:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:35:13 @base_main.py:47][0m 195975 total steps have happened
[32m[0512 00:35:13 @base_main.py:52][0m [avg_reward]: -40.10085328880342
[32m[0512 00:35:13 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:35:13 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:35:13 @base_trainer.py:216][0m Mean reward: -49.773367848011816
[32m[0512 00:35:14 @base_main.py:38][0m --------------- Iteration 196 ---------------
[32m[0512 00:35:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3369 mins
[32m[0512 00:35:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0512 00:35:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0512 00:35:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:35:14 @base_main.py:47][0m 196980 total steps have happened
[32m[0512 00:35:14 @base_main.py:52][0m [avg_reward]: -49.773367848011816
[32m[0512 00:35:14 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:35:14 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:35:14 @base_trainer.py:216][0m Mean reward: -37.70007323958113
[32m[0512 00:35:14 @base_main.py:38][0m --------------- Iteration 197 ---------------
[32m[0512 00:35:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3496 mins
[32m[0512 00:35:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:35:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0512 00:35:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:35:14 @base_main.py:47][0m 197985 total steps have happened
[32m[0512 00:35:14 @base_main.py:52][0m [avg_reward]: -37.70007323958113
[32m[0512 00:35:15 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:35:15 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:35:15 @base_trainer.py:216][0m Mean reward: -37.805842339090916
[32m[0512 00:35:15 @base_main.py:38][0m --------------- Iteration 198 ---------------
[32m[0512 00:35:15 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3616 mins
[32m[0512 00:35:15 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:35:15 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0082 mins
[32m[0512 00:35:15 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:35:15 @base_main.py:47][0m 198990 total steps have happened
[32m[0512 00:35:15 @base_main.py:52][0m [avg_reward]: -37.805842339090916
[32m[0512 00:35:15 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:35:15 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:35:15 @base_trainer.py:216][0m Mean reward: -36.720783576332295
[32m[0512 00:35:16 @base_main.py:38][0m --------------- Iteration 199 ---------------
[32m[0512 00:35:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3727 mins
[32m[0512 00:35:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0512 00:35:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0086 mins
[32m[0512 00:35:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:35:16 @base_main.py:47][0m 199995 total steps have happened
[32m[0512 00:35:16 @base_main.py:52][0m [avg_reward]: -36.720783576332295
[32m[0512 00:35:16 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0512 00:35:16 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0512 00:35:16 @base_trainer.py:216][0m Mean reward: -38.07789281473398
[32m[0512 00:35:17 @base_main.py:38][0m --------------- Iteration 200 ---------------
[32m[0512 00:35:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3840 mins
[32m[0512 00:35:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0512 00:35:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0512 00:35:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0512 00:35:17 @base_main.py:47][0m 201000 total steps have happened
[32m[0512 00:35:17 @base_main.py:52][0m [avg_reward]: -38.07789281473398
[32m[0512 00:35:17 @base_worker.py:111][0m kill message for worker 15
[32m[0512 00:35:17 @base_worker.py:111][0m kill message for worker 10
[32m[0512 00:35:17 @base_worker.py:111][0m kill message for worker 12
[32m[0512 00:35:17 @base_worker.py:111][0m kill message for worker 8
[32m[0512 00:35:17 @base_worker.py:111][0m kill message for worker 3
[32m[0512 00:35:17 @base_worker.py:111][0m kill message for worker 2
[32m[0512 00:35:17 @base_worker.py:111][0m kill message for worker 0
[32m[0512 00:35:17 @base_worker.py:111][0m kill message for worker 11
[32m[0512 00:35:17 @base_worker.py:111][0m kill message for worker 5
[32m[0512 00:35:17 @base_worker.py:111][0m kill message for worker 13
[32m[0512 00:35:17 @base_worker.py:111][0m kill message for worker 18
[32m[0512 00:35:17 @base_worker.py:111][0m kill message for worker 14
[32m[0512 00:35:17 @base_worker.py:111][0m kill message for worker 4
[32m[0512 00:35:17 @base_worker.py:111][0m kill message for worker 9
[32m[0512 00:35:17 @base_worker.py:111][0m kill message for worker 16
[32m[0512 00:35:17 @base_worker.py:111][0m kill message for worker 17
[32m[0512 00:35:17 @base_worker.py:111][0m kill message for worker 6
[32m[0512 00:35:17 @base_worker.py:111][0m kill message for worker 7
[32m[0512 00:35:17 @base_worker.py:111][0m kill message for worker 1
[32m[0512 00:35:17 @base_worker.py:111][0m kill message for worker 19
