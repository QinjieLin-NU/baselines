[32m[0511 07:37:15 @logger.py:103][0m Log file set to /root/mbbl/log/mbmfrl-rsgym_pendulummbmf_gym_pendulum_ppo_seed_3412.log/mbmfrl-rsgym_pendulummbmf_gym_pendulum_ppo_seed_3412.log
[32m[0511 07:37:15 @mbmf_main.py:23][0m Training starts at /root/mbbl
[32m[0511 07:37:15 @base_worker.py:45][0m Worker 0 online
[32m[0511 07:37:15 @base_worker.py:45][0m Worker 1 online
[32m[0511 07:37:15 @base_worker.py:45][0m Worker 2 online
[32m[0511 07:37:15 @base_worker.py:45][0m Worker 3 online
[32m[0511 07:37:15 @base_worker.py:45][0m Worker 4 online
[32m[0511 07:37:15 @base_worker.py:45][0m Worker 5 online
[32m[0511 07:37:15 @base_worker.py:45][0m Worker 6 online
[32m[0511 07:37:15 @base_worker.py:45][0m Worker 7 online
[32m[0511 07:37:15 @base_worker.py:45][0m Worker 8 online
[32m[0511 07:37:15 @base_worker.py:45][0m Worker 9 online
[32m[0511 07:37:15 @base_worker.py:45][0m Worker 10 online
[32m[0511 07:37:15 @base_worker.py:45][0m Worker 11 online
[32m[0511 07:37:15 @base_worker.py:45][0m Worker 12 online
[32m[0511 07:37:15 @base_worker.py:45][0m Worker 13 online
[32m[0511 07:37:15 @base_worker.py:45][0m Worker 14 online
[32m[0511 07:37:15 @base_worker.py:45][0m Worker 15 online
[32m[0511 07:37:15 @base_worker.py:45][0m Worker 16 online
[32m[0511 07:37:15 @base_worker.py:45][0m Worker 17 online
[32m[0511 07:37:15 @base_worker.py:45][0m Worker 18 online
[32m[0511 07:37:15 @base_worker.py:45][0m Worker 19 online
[32m[0511 07:37:16 @base_trainer.py:152][0m Trainer maintains [1] policy network
[32m[0511 07:37:16 @base_trainer.py:152][0m Trainer maintains [1] dynamics network
[32m[0511 07:37:16 @base_trainer.py:152][0m Trainer maintains [1] reward network
[32m[0511 07:37:17 @mbmf_main.py:46][0m Generating 1000 random timesteps
[32m[0511 07:37:17 @mbmf_sampler.py:39][0m done with episode
[32m[0511 07:37:17 @mbmf_sampler.py:39][0m done with episode
[32m[0511 07:37:17 @mbmf_sampler.py:39][0m done with episode
[32m[0511 07:37:17 @mbmf_sampler.py:39][0m done with episode
[32m[0511 07:37:17 @mbmf_sampler.py:39][0m done with episode
[32m[0511 07:37:17 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:37:17 @base_trainer.py:216][0m Mean reward: -1294.3992244635283
[32m[0511 07:37:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9885371923446655, Train Loss: 0.9941521883010864
[32m[0511 07:37:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9885523915290833, Train Loss: 0.9941415786743164
[32m[0511 07:37:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9885678291320801, Train Loss: 0.9941309690475464
[32m[0511 07:37:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9885833859443665, Train Loss: 0.9941206574440002
[32m[0511 07:37:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9885990619659424, Train Loss: 0.9941105842590332
[32m[0511 07:37:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9886150360107422, Train Loss: 0.9941007494926453
[32m[0511 07:37:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.988631010055542, Train Loss: 0.9940909147262573
[32m[0511 07:37:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9886472821235657, Train Loss: 0.994081437587738
[32m[0511 07:37:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9886635541915894, Train Loss: 0.9940720796585083
[32m[0511 07:37:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9886798858642578, Train Loss: 0.9940629005432129
[32m[0511 07:37:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9886965155601501, Train Loss: 0.9940540194511414
[32m[0511 07:37:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9887131452560425, Train Loss: 0.9940454363822937
[32m[0511 07:37:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9887300133705139, Train Loss: 0.994036853313446
[32m[0511 07:37:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9887470006942749, Train Loss: 0.994028627872467
[32m[0511 07:37:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9887639880180359, Train Loss: 0.994020402431488
[32m[0511 07:37:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9887811541557312, Train Loss: 0.994012713432312
[32m[0511 07:37:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9887982606887817, Train Loss: 0.994005024433136
[32m[0511 07:37:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9888154864311218, Train Loss: 0.9939975738525391
[32m[0511 07:37:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9888328313827515, Train Loss: 0.9939902424812317
[32m[0511 07:37:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9888502359390259, Train Loss: 0.9939831495285034
[32m[0511 07:37:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9888675808906555, Train Loss: 0.9939764142036438
[32m[0511 07:37:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9888851642608643, Train Loss: 0.9939696192741394
[32m[0511 07:37:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9889026880264282, Train Loss: 0.9939633011817932
[32m[0511 07:37:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9889200925827026, Train Loss: 0.9939570426940918
[32m[0511 07:37:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9889376163482666, Train Loss: 0.9939510822296143
[32m[0511 07:37:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9889552593231201, Train Loss: 0.9939452409744263
[32m[0511 07:37:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9889728426933289, Train Loss: 0.9939395189285278
[32m[0511 07:37:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9889903664588928, Train Loss: 0.9939339756965637
[32m[0511 07:37:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9890078902244568, Train Loss: 0.9939289689064026
[32m[0511 07:37:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9890252947807312, Train Loss: 0.9939237236976624
[32m[0511 07:37:18 @base_main.py:38][0m --------------- Iteration 1 ---------------
[32m[0511 07:37:18 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0000 mins
[32m[0511 07:37:18 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 07:37:18 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0110 mins
[32m[0511 07:37:18 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0042 mins
[32m[0511 07:37:18 @base_main.py:47][0m 1005 total steps have happened
[32m[0511 07:37:18 @base_main.py:52][0m [avg_reward]: -1294.3992244635283
[32m[0511 07:37:18 @base_main.py:52][0m [update_op]: None
[32m[0511 07:37:18 @base_main.py:52][0m [train_loss]: 0.9939237236976624
[32m[0511 07:37:18 @base_main.py:52][0m [val_loss]: 0.9890252947807312
[32m[0511 07:37:18 @base_main.py:52][0m [avg_train_loss]: 0.9939237236976624
[32m[0511 07:39:26 @mbmf_sampler.py:39][0m done with episode
[32m[0511 07:41:33 @mbmf_sampler.py:39][0m done with episode
[32m[0511 07:43:40 @mbmf_sampler.py:39][0m done with episode
[32m[0511 07:45:46 @mbmf_sampler.py:39][0m done with episode
[32m[0511 07:47:53 @mbmf_sampler.py:39][0m done with episode
[32m[0511 07:47:53 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:47:53 @base_trainer.py:216][0m Mean reward: -1331.4315754320928
[32m[0511 07:47:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9332776665687561, Train Loss: 0.9093512892723083
[32m[0511 07:47:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9333044290542603, Train Loss: 0.9093512892723083
[32m[0511 07:47:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.933326780796051, Train Loss: 0.9093487858772278
[32m[0511 07:47:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9333460330963135, Train Loss: 0.9093449115753174
[32m[0511 07:47:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9333626627922058, Train Loss: 0.9093402028083801
[32m[0511 07:47:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9333772659301758, Train Loss: 0.9093351364135742
[32m[0511 07:47:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9333905577659607, Train Loss: 0.9093299508094788
[32m[0511 07:47:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9334024786949158, Train Loss: 0.9093249440193176
[32m[0511 07:47:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9334133863449097, Train Loss: 0.9093201756477356
[32m[0511 07:47:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9334236979484558, Train Loss: 0.9093155264854431
[32m[0511 07:47:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9334330558776855, Train Loss: 0.9093111157417297
[32m[0511 07:47:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9334419965744019, Train Loss: 0.9093070030212402
[32m[0511 07:47:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9334502220153809, Train Loss: 0.9093031883239746
[32m[0511 07:47:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9334580898284912, Train Loss: 0.9092996716499329
[32m[0511 07:47:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9334656596183777, Train Loss: 0.9092963337898254
[32m[0511 07:47:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.933472752571106, Train Loss: 0.9092933535575867
[32m[0511 07:47:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9334794878959656, Train Loss: 0.9092904925346375
[32m[0511 07:47:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9334858059883118, Train Loss: 0.9092879295349121
[32m[0511 07:47:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9334918856620789, Train Loss: 0.9092855453491211
[32m[0511 07:47:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9334977269172668, Train Loss: 0.9092831611633301
[32m[0511 07:47:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9335033893585205, Train Loss: 0.9092810750007629
[32m[0511 07:47:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.933508574962616, Train Loss: 0.9092791676521301
[32m[0511 07:47:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9335137009620667, Train Loss: 0.9092772006988525
[32m[0511 07:47:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9335185885429382, Train Loss: 0.9092755317687988
[32m[0511 07:47:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9335231184959412, Train Loss: 0.9092739224433899
[32m[0511 07:47:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9335275888442993, Train Loss: 0.9092724919319153
[32m[0511 07:47:53 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9335318803787231, Train Loss: 0.9092710614204407
[32m[0511 07:47:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9335358738899231, Train Loss: 0.9092698097229004
[32m[0511 07:47:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9335397481918335, Train Loss: 0.9092686176300049
[32m[0511 07:47:54 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9335434436798096, Train Loss: 0.9092673659324646
[32m[0511 07:47:54 @base_main.py:38][0m --------------- Iteration 2 ---------------
[32m[0511 07:47:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0173 mins
[32m[0511 07:47:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 10.5815 mins
[32m[0511 07:47:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0179 mins
[32m[0511 07:47:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0051 mins
[32m[0511 07:47:54 @base_main.py:47][0m 2010 total steps have happened
[32m[0511 07:47:54 @base_main.py:52][0m [avg_reward]: -1331.4315754320928
[32m[0511 07:47:54 @base_main.py:52][0m [update_op]: None
[32m[0511 07:47:54 @base_main.py:52][0m [train_loss]: 0.5916021466255188
[32m[0511 07:47:54 @base_main.py:52][0m [val_loss]: 0.9335434436798096
[32m[0511 07:47:54 @base_main.py:52][0m [avg_train_loss]: 0.9092673659324646
[32m[0511 07:50:00 @mbmf_sampler.py:39][0m done with episode
[32m[0511 07:52:07 @mbmf_sampler.py:39][0m done with episode
[32m[0511 07:54:13 @mbmf_sampler.py:39][0m done with episode
[32m[0511 07:56:19 @mbmf_sampler.py:39][0m done with episode
[32m[0511 07:58:24 @mbmf_sampler.py:39][0m done with episode
[32m[0511 07:58:24 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0511 07:58:24 @base_trainer.py:216][0m Mean reward: -1216.6740931641232
[32m[0511 07:58:24 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.038082480430603, Train Loss: 1.064121961593628
[32m[0511 07:58:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.038111925125122, Train Loss: 1.064112901687622
[32m[0511 07:58:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0381443500518799, Train Loss: 1.0641014575958252
[32m[0511 07:58:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0381783246994019, Train Loss: 1.064089059829712
[32m[0511 07:58:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.038212776184082, Train Loss: 1.0640769004821777
[32m[0511 07:58:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0382468700408936, Train Loss: 1.0640653371810913
[32m[0511 07:58:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0382804870605469, Train Loss: 1.0640547275543213
[32m[0511 07:58:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0383127927780151, Train Loss: 1.0640451908111572
[32m[0511 07:58:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0383437871932983, Train Loss: 1.06403648853302
[32m[0511 07:58:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0383738279342651, Train Loss: 1.0640285015106201
[32m[0511 07:58:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0384024381637573, Train Loss: 1.0640215873718262
[32m[0511 07:58:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.038429856300354, Train Loss: 1.0640153884887695
[32m[0511 07:58:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0384559631347656, Train Loss: 1.0640097856521606
[32m[0511 07:58:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0384808778762817, Train Loss: 1.0640050172805786
[32m[0511 07:58:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0385046005249023, Train Loss: 1.0640004873275757
[32m[0511 07:58:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0385271310806274, Train Loss: 1.0639965534210205
[32m[0511 07:58:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.038548469543457, Train Loss: 1.063993215560913
[32m[0511 07:58:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0385688543319702, Train Loss: 1.0639898777008057
[32m[0511 07:58:25 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.038588285446167, Train Loss: 1.0639872550964355
[32m[0511 07:58:26 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0386065244674683, Train Loss: 1.063984751701355
[32m[0511 07:58:26 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0386239290237427, Train Loss: 1.063982605934143
[32m[0511 07:58:26 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0386402606964111, Train Loss: 1.0639804601669312
[32m[0511 07:58:26 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0386559963226318, Train Loss: 1.0639787912368774
[32m[0511 07:58:26 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0386708974838257, Train Loss: 1.0639771223068237
[32m[0511 07:58:26 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0386848449707031, Train Loss: 1.0639756917953491
[32m[0511 07:58:26 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0386980772018433, Train Loss: 1.0639744997024536
[32m[0511 07:58:26 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0387107133865356, Train Loss: 1.0639731884002686
[32m[0511 07:58:26 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0387226343154907, Train Loss: 1.0639722347259521
[32m[0511 07:58:26 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.038733959197998, Train Loss: 1.0639712810516357
[32m[0511 07:58:26 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0387444496154785, Train Loss: 1.0639704465866089
[32m[0511 07:58:26 @base_main.py:38][0m --------------- Iteration 3 ---------------
[32m[0511 07:58:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 10.6219 mins
[32m[0511 07:58:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 10.5085 mins
[32m[0511 07:58:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0271 mins
[32m[0511 07:58:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0052 mins
[32m[0511 07:58:26 @base_main.py:47][0m 3015 total steps have happened
[32m[0511 07:58:26 @base_main.py:52][0m [avg_reward]: -1216.6740931641232
[32m[0511 07:58:26 @base_main.py:52][0m [update_op]: None
[32m[0511 07:58:26 @base_main.py:52][0m [train_loss]: 0.972560465335846
[32m[0511 07:58:26 @base_main.py:52][0m [val_loss]: 1.0387444496154785
[32m[0511 07:58:26 @base_main.py:52][0m [avg_train_loss]: 1.0639704465866089
[32m[0511 08:00:33 @mbmf_sampler.py:39][0m done with episode
[32m[0511 08:02:39 @mbmf_sampler.py:39][0m done with episode
[32m[0511 08:04:45 @mbmf_sampler.py:39][0m done with episode
[32m[0511 08:06:50 @mbmf_sampler.py:39][0m done with episode
[32m[0511 08:08:56 @mbmf_sampler.py:39][0m done with episode
[32m[0511 08:08:56 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0511 08:08:56 @base_trainer.py:216][0m Mean reward: -1349.6505501988624
[32m[0511 08:08:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.968417227268219, Train Loss: 0.9756527543067932
[32m[0511 08:08:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9684248566627502, Train Loss: 0.9756521582603455
[32m[0511 08:08:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9684330224990845, Train Loss: 0.9756513833999634
[32m[0511 08:08:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9684410095214844, Train Loss: 0.9756506681442261
[32m[0511 08:08:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9684487581253052, Train Loss: 0.975649893283844
[32m[0511 08:08:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9684561491012573, Train Loss: 0.9756492972373962
[32m[0511 08:08:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9684630632400513, Train Loss: 0.9756487607955933
[32m[0511 08:08:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9684695601463318, Train Loss: 0.9756482839584351
[32m[0511 08:08:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9684755802154541, Train Loss: 0.9756478667259216
[32m[0511 08:08:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9684810042381287, Train Loss: 0.9756474494934082
[32m[0511 08:08:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9684863090515137, Train Loss: 0.9756471514701843
[32m[0511 08:08:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9684910178184509, Train Loss: 0.9756470322608948
[32m[0511 08:08:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9684954881668091, Train Loss: 0.9756468534469604
[32m[0511 08:08:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9684996008872986, Train Loss: 0.9756464958190918
[32m[0511 08:08:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9685034155845642, Train Loss: 0.9756463766098022
[32m[0511 08:08:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.968506932258606, Train Loss: 0.9756461977958679
[32m[0511 08:08:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9685103297233582, Train Loss: 0.9756461381912231
[32m[0511 08:08:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9685132503509521, Train Loss: 0.9756459593772888
[32m[0511 08:08:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9685159921646118, Train Loss: 0.975645899772644
[32m[0511 08:08:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9685187339782715, Train Loss: 0.9756458401679993
[32m[0511 08:08:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9685210585594177, Train Loss: 0.9756457209587097
[32m[0511 08:08:57 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9685232639312744, Train Loss: 0.9756456613540649
[32m[0511 08:08:58 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9685253500938416, Train Loss: 0.9756456017494202
[32m[0511 08:08:58 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9685273766517639, Train Loss: 0.9756455421447754
[32m[0511 08:08:58 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9685290455818176, Train Loss: 0.9756454825401306
[32m[0511 08:08:58 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9685307741165161, Train Loss: 0.9756454825401306
[32m[0511 08:08:58 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9685322642326355, Train Loss: 0.9756454229354858
[32m[0511 08:08:58 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9685336947441101, Train Loss: 0.9756454229354858
[32m[0511 08:08:58 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9685350060462952, Train Loss: 0.9756454229354858
[32m[0511 08:08:58 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9685362577438354, Train Loss: 0.9756453633308411
[32m[0511 08:08:58 @base_main.py:38][0m --------------- Iteration 4 ---------------
[32m[0511 08:08:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 21.1628 mins
[32m[0511 08:08:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 10.4913 mins
[32m[0511 08:08:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0368 mins
[32m[0511 08:08:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0051 mins
[32m[0511 08:08:58 @base_main.py:47][0m 4020 total steps have happened
[32m[0511 08:08:58 @base_main.py:52][0m [avg_reward]: -1349.6505501988624
[32m[0511 08:08:58 @base_main.py:52][0m [update_op]: None
[32m[0511 08:08:58 @base_main.py:52][0m [train_loss]: 0.7634912729263306
[32m[0511 08:08:58 @base_main.py:52][0m [val_loss]: 0.9685362577438354
[32m[0511 08:08:58 @base_main.py:52][0m [avg_train_loss]: 0.9756453633308411
[32m[0511 08:11:04 @mbmf_sampler.py:39][0m done with episode
[32m[0511 08:13:11 @mbmf_sampler.py:39][0m done with episode
[32m[0511 08:15:17 @mbmf_sampler.py:39][0m done with episode
[32m[0511 08:17:22 @mbmf_sampler.py:39][0m done with episode
[32m[0511 08:19:28 @mbmf_sampler.py:39][0m done with episode
[32m[0511 08:19:28 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0511 08:19:28 @base_trainer.py:216][0m Mean reward: -1026.2990982584047
[32m[0511 08:19:28 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.275638222694397, Train Loss: 0.9638707041740417
[32m[0511 08:19:29 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2757041454315186, Train Loss: 0.9638634920120239
[32m[0511 08:19:29 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2757794857025146, Train Loss: 0.9638539552688599
[32m[0511 08:19:29 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2758543491363525, Train Loss: 0.9638447165489197
[32m[0511 08:19:29 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2759244441986084, Train Loss: 0.9638367891311646
[32m[0511 08:19:29 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2759886980056763, Train Loss: 0.963830292224884
[32m[0511 08:19:29 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2760469913482666, Train Loss: 0.963824987411499
[32m[0511 08:19:29 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2760993242263794, Train Loss: 0.9638208746910095
[32m[0511 08:19:29 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2761465311050415, Train Loss: 0.9638174772262573
[32m[0511 08:19:29 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2761887311935425, Train Loss: 0.9638149738311768
[32m[0511 08:19:29 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.27622652053833, Train Loss: 0.9638127088546753
[32m[0511 08:19:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.276260256767273, Train Loss: 0.9638110399246216
[32m[0511 08:19:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.276290774345398, Train Loss: 0.9638097286224365
[32m[0511 08:19:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2763177156448364, Train Loss: 0.9638087153434753
[32m[0511 08:19:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2763419151306152, Train Loss: 0.9638077616691589
[32m[0511 08:19:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.276363492012024, Train Loss: 0.9638071060180664
[32m[0511 08:19:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2763829231262207, Train Loss: 0.9638065695762634
[32m[0511 08:19:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2764003276824951, Train Loss: 0.96380615234375
[32m[0511 08:19:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2764158248901367, Train Loss: 0.9638057351112366
[32m[0511 08:19:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2764296531677246, Train Loss: 0.9638054966926575
[32m[0511 08:19:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2764419317245483, Train Loss: 0.9638053178787231
[32m[0511 08:19:30 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2764532566070557, Train Loss: 0.9638051986694336
[32m[0511 08:19:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2764629125595093, Train Loss: 0.963805079460144
[32m[0511 08:19:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2764719724655151, Train Loss: 0.9638049006462097
[32m[0511 08:19:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2764798402786255, Train Loss: 0.9638049006462097
[32m[0511 08:19:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2764867544174194, Train Loss: 0.9638046622276306
[32m[0511 08:19:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2764933109283447, Train Loss: 0.9638046622276306
[32m[0511 08:19:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.276498794555664, Train Loss: 0.9638046622276306
[32m[0511 08:19:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2765041589736938, Train Loss: 0.9638044834136963
[32m[0511 08:19:31 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2765084505081177, Train Loss: 0.9638045430183411
[32m[0511 08:19:32 @base_main.py:38][0m --------------- Iteration 5 ---------------
[32m[0511 08:19:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 31.6960 mins
[32m[0511 08:19:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 10.5000 mins
[32m[0511 08:19:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0475 mins
[32m[0511 08:19:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0051 mins
[32m[0511 08:19:32 @base_main.py:47][0m 5025 total steps have happened
[32m[0511 08:19:32 @base_main.py:52][0m [avg_reward]: -1026.2990982584047
[32m[0511 08:19:32 @base_main.py:52][0m [update_op]: None
[32m[0511 08:19:32 @base_main.py:52][0m [train_loss]: 0.5951374769210815
[32m[0511 08:19:32 @base_main.py:52][0m [val_loss]: 1.2765084505081177
[32m[0511 08:19:32 @base_main.py:52][0m [avg_train_loss]: 0.9638045430183411
[32m[0511 08:21:38 @mbmf_sampler.py:39][0m done with episode
[32m[0511 08:23:43 @mbmf_sampler.py:39][0m done with episode
[32m[0511 08:25:49 @mbmf_sampler.py:39][0m done with episode
[32m[0511 08:27:54 @mbmf_sampler.py:39][0m done with episode
[32m[0511 08:30:00 @mbmf_sampler.py:39][0m done with episode
[32m[0511 08:30:00 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0511 08:30:00 @base_trainer.py:216][0m Mean reward: -1108.4152411751295
[32m[0511 08:30:00 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1781387329101562, Train Loss: 0.9873847365379333
[32m[0511 08:30:00 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1781854629516602, Train Loss: 0.9873777627944946
[32m[0511 08:30:00 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1782338619232178, Train Loss: 0.987369954586029
[32m[0511 08:30:00 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.178279161453247, Train Loss: 0.9873630404472351
[32m[0511 08:30:01 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1783204078674316, Train Loss: 0.9873573184013367
[32m[0511 08:30:01 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1783572435379028, Train Loss: 0.9873529076576233
[32m[0511 08:30:01 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1783897876739502, Train Loss: 0.9873495101928711
[32m[0511 08:30:01 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.178418755531311, Train Loss: 0.987346887588501
[32m[0511 08:30:01 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.178444266319275, Train Loss: 0.9873449206352234
[32m[0511 08:30:01 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1784666776657104, Train Loss: 0.9873433709144592
[32m[0511 08:30:01 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1784864664077759, Train Loss: 0.987342119216919
[32m[0511 08:30:01 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1785039901733398, Train Loss: 0.9873412847518921
[32m[0511 08:30:01 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1785192489624023, Train Loss: 0.9873403906822205
[32m[0511 08:30:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1785327196121216, Train Loss: 0.9873399138450623
[32m[0511 08:30:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.178544521331787, Train Loss: 0.987339437007904
[32m[0511 08:30:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.178554892539978, Train Loss: 0.9873390197753906
[32m[0511 08:30:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.178564190864563, Train Loss: 0.9873388409614563
[32m[0511 08:30:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1785720586776733, Train Loss: 0.9873386025428772
[32m[0511 08:30:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1785788536071777, Train Loss: 0.9873384833335876
[32m[0511 08:30:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1785850524902344, Train Loss: 0.9873383045196533
[32m[0511 08:30:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1785905361175537, Train Loss: 0.987338125705719
[32m[0511 08:30:02 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1785951852798462, Train Loss: 0.987338125705719
[32m[0511 08:30:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.17859947681427, Train Loss: 0.9873380661010742
[32m[0511 08:30:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1786032915115356, Train Loss: 0.9873380064964294
[32m[0511 08:30:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1786062717437744, Train Loss: 0.9873380064964294
[32m[0511 08:30:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1786091327667236, Train Loss: 0.9873378872871399
[32m[0511 08:30:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.178611397743225, Train Loss: 0.9873378872871399
[32m[0511 08:30:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.178613543510437, Train Loss: 0.9873378872871399
[32m[0511 08:30:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1786155700683594, Train Loss: 0.9873378872871399
[32m[0511 08:30:03 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1786171197891235, Train Loss: 0.9873378872871399
[32m[0511 08:30:04 @base_main.py:38][0m --------------- Iteration 6 ---------------
[32m[0511 08:30:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 42.2486 mins
[32m[0511 08:30:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 10.4747 mins
[32m[0511 08:30:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0548 mins
[32m[0511 08:30:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0051 mins
[32m[0511 08:30:04 @base_main.py:47][0m 6030 total steps have happened
[32m[0511 08:30:04 @base_main.py:52][0m [avg_reward]: -1108.4152411751295
[32m[0511 08:30:04 @base_main.py:52][0m [update_op]: None
[32m[0511 08:30:04 @base_main.py:52][0m [train_loss]: 1.384397268295288
[32m[0511 08:30:04 @base_main.py:52][0m [val_loss]: 1.1786171197891235
[32m[0511 08:30:04 @base_main.py:52][0m [avg_train_loss]: 0.9873378872871399
[32m[0511 08:32:09 @mbmf_sampler.py:39][0m done with episode
[32m[0511 08:34:15 @mbmf_sampler.py:39][0m done with episode
[32m[0511 08:36:21 @mbmf_sampler.py:39][0m done with episode
[32m[0511 08:38:27 @mbmf_sampler.py:39][0m done with episode
[32m[0511 08:40:33 @mbmf_sampler.py:39][0m done with episode
[32m[0511 08:40:33 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0511 08:40:33 @base_trainer.py:216][0m Mean reward: -1151.4508786947822
[32m[0511 08:40:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0843346118927002, Train Loss: 0.9867125153541565
[32m[0511 08:40:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0843563079833984, Train Loss: 0.9867101907730103
[32m[0511 08:40:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0843772888183594, Train Loss: 0.9867085814476013
[32m[0511 08:40:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0843957662582397, Train Loss: 0.9867070913314819
[32m[0511 08:40:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0844120979309082, Train Loss: 0.9867063164710999
[32m[0511 08:40:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0844260454177856, Train Loss: 0.986705482006073
[32m[0511 08:40:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0844379663467407, Train Loss: 0.9867048859596252
[32m[0511 08:40:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.084448218345642, Train Loss: 0.9867047071456909
[32m[0511 08:40:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0844571590423584, Train Loss: 0.9867042899131775
[32m[0511 08:40:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0844646692276, Train Loss: 0.9867041707038879
[32m[0511 08:40:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0844711065292358, Train Loss: 0.9867039918899536
[32m[0511 08:40:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0844765901565552, Train Loss: 0.9867038726806641
[32m[0511 08:40:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0844813585281372, Train Loss: 0.9867038130760193
[32m[0511 08:40:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0844855308532715, Train Loss: 0.9867037534713745
[32m[0511 08:40:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0844889879226685, Train Loss: 0.9867037534713745
[32m[0511 08:40:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0844920873641968, Train Loss: 0.9867037534713745
[32m[0511 08:40:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0844948291778564, Train Loss: 0.986703634262085
[32m[0511 08:40:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0844969749450684, Train Loss: 0.9867035746574402
[32m[0511 08:40:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0844987630844116, Train Loss: 0.9867037534713745
[32m[0511 08:40:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0845005512237549, Train Loss: 0.986703634262085
[32m[0511 08:40:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0845017433166504, Train Loss: 0.986703634262085
[32m[0511 08:40:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.084502935409546, Train Loss: 0.9867035746574402
[32m[0511 08:40:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0845040082931519, Train Loss: 0.9867035746574402
[32m[0511 08:40:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0845047235488892, Train Loss: 0.9867035746574402
[32m[0511 08:40:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0845054388046265, Train Loss: 0.9867035746574402
[32m[0511 08:40:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0845063924789429, Train Loss: 0.986703634262085
[32m[0511 08:40:36 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.084506869316101, Train Loss: 0.986703634262085
[32m[0511 08:40:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0845073461532593, Train Loss: 0.9867035746574402
[32m[0511 08:40:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0845075845718384, Train Loss: 0.9867037534713745
[32m[0511 08:40:37 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.0845081806182861, Train Loss: 0.9867037534713745
[32m[0511 08:40:37 @base_main.py:38][0m --------------- Iteration 7 ---------------
[32m[0511 08:40:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 52.7833 mins
[32m[0511 08:40:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 10.4888 mins
[32m[0511 08:40:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0648 mins
[32m[0511 08:40:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0048 mins
[32m[0511 08:40:37 @base_main.py:47][0m 7035 total steps have happened
[32m[0511 08:40:37 @base_main.py:52][0m [avg_reward]: -1151.4508786947822
[32m[0511 08:40:37 @base_main.py:52][0m [update_op]: None
[32m[0511 08:40:37 @base_main.py:52][0m [train_loss]: 0.8831120729446411
[32m[0511 08:40:37 @base_main.py:52][0m [val_loss]: 1.0845081806182861
[32m[0511 08:40:37 @base_main.py:52][0m [avg_train_loss]: 0.9867037534713745
[32m[0511 08:40:37 @mbmf_trainer.py:160][0m Mean reward: -1211.1886659124175
[32m[0511 08:40:37 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.19144465029239655, Train Loss: 0.18281199038028717
[32m[0511 08:40:37 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.1914171725511551, Train Loss: 0.18272335827350616
[32m[0511 08:40:37 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.1914358139038086, Train Loss: 0.1827087551355362
[32m[0511 08:40:37 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.1914530247449875, Train Loss: 0.18268828094005585
[32m[0511 08:40:37 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.19145864248275757, Train Loss: 0.18267256021499634
[32m[0511 08:40:37 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.19146595895290375, Train Loss: 0.18266268074512482
[32m[0511 08:40:37 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.19147664308547974, Train Loss: 0.18265525996685028
[32m[0511 08:40:37 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.19148719310760498, Train Loss: 0.18264766037464142
[32m[0511 08:40:37 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.19149646162986755, Train Loss: 0.1826401799917221
[32m[0511 08:40:38 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.19150537252426147, Train Loss: 0.18263328075408936
[32m[0511 08:40:38 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.1915144920349121, Train Loss: 0.1826268434524536
[32m[0511 08:40:38 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.19152358174324036, Train Loss: 0.18262071907520294
[32m[0511 08:40:38 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.19153255224227905, Train Loss: 0.18261481821537018
[32m[0511 08:40:38 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.19154143333435059, Train Loss: 0.1826092153787613
[32m[0511 08:40:38 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.1915503293275833, Train Loss: 0.1826038509607315
[32m[0511 08:40:38 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.19155921041965485, Train Loss: 0.1825987547636032
[32m[0511 08:40:38 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.19156809151172638, Train Loss: 0.18259382247924805
[32m[0511 08:40:38 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.19157694280147552, Train Loss: 0.1825890988111496
[32m[0511 08:40:38 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.19158577919006348, Train Loss: 0.18258453905582428
[32m[0511 08:40:38 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.19159461557865143, Train Loss: 0.1825801581144333
[32m[0511 08:40:38 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.1916033923625946, Train Loss: 0.18257592618465424
[32m[0511 08:40:38 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.1916121393442154, Train Loss: 0.18257184326648712
[32m[0511 08:40:38 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.19162091612815857, Train Loss: 0.18256793916225433
[32m[0511 08:40:38 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.19162966310977936, Train Loss: 0.1825641393661499
[32m[0511 08:40:38 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.19163832068443298, Train Loss: 0.18256044387817383
[32m[0511 08:40:38 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.19164696335792542, Train Loss: 0.18255692720413208
[32m[0511 08:40:38 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.19165557622909546, Train Loss: 0.1825534701347351
[32m[0511 08:40:38 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.19166412949562073, Train Loss: 0.18255013227462769
[32m[0511 08:40:38 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.19167263805866241, Train Loss: 0.18254691362380981
[32m[0511 08:40:38 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.19168110191822052, Train Loss: 0.1825437992811203
[32m[0511 08:40:38 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.19168950617313385, Train Loss: 0.18254075944423676
[32m[0511 08:40:38 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.1916978359222412, Train Loss: 0.18253779411315918
[32m[0511 08:40:38 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.1917061060667038, Train Loss: 0.18253491818904877
[32m[0511 08:40:38 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.1917143315076828, Train Loss: 0.18253211677074432
[32m[0511 08:40:38 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.19172246754169464, Train Loss: 0.18252937495708466
[32m[0511 08:40:38 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.1917305439710617, Train Loss: 0.18252670764923096
[32m[0511 08:40:38 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.191738560795784, Train Loss: 0.18252409994602203
[32m[0511 08:40:38 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.19174650311470032, Train Loss: 0.18252156674861908
[32m[0511 08:40:38 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.19175435602664948, Train Loss: 0.1825190782546997
[32m[0511 08:40:38 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.19176214933395386, Train Loss: 0.1825166493654251
[32m[0511 08:40:38 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.19176983833312988, Train Loss: 0.1825142502784729
[32m[0511 08:40:38 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.19177743792533875, Train Loss: 0.18251192569732666
[32m[0511 08:40:38 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.1917850226163864, Train Loss: 0.1825096160173416
[32m[0511 08:40:38 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.19179247319698334, Train Loss: 0.18250735104084015
[32m[0511 08:40:39 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.1917998492717743, Train Loss: 0.18250513076782227
[32m[0511 08:40:39 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.19180716574192047, Train Loss: 0.18250294029712677
[32m[0511 08:40:39 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.1918143928050995, Train Loss: 0.18250082433223724
[32m[0511 08:40:39 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.19182151556015015, Train Loss: 0.18249869346618652
[32m[0511 08:40:39 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.19182859361171722, Train Loss: 0.1824965924024582
[32m[0511 08:40:39 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.19183558225631714, Train Loss: 0.18249453604221344
[32m[0511 08:40:39 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.19184249639511108, Train Loss: 0.18249249458312988
[32m[0511 08:40:39 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.19184932112693787, Train Loss: 0.18249046802520752
[32m[0511 08:40:39 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.19185607135295868, Train Loss: 0.18248848617076874
[32m[0511 08:40:39 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.19186273217201233, Train Loss: 0.18248651921749115
[32m[0511 08:40:39 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.1918693482875824, Train Loss: 0.18248456716537476
[32m[0511 08:40:39 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.1918758898973465, Train Loss: 0.18248264491558075
[32m[0511 08:40:39 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.19188232719898224, Train Loss: 0.18248073756694794
[32m[0511 08:40:39 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.1918887346982956, Train Loss: 0.18247883021831512
[32m[0511 08:40:39 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.1918950378894806, Train Loss: 0.1824769377708435
[32m[0511 08:40:39 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.19190126657485962, Train Loss: 0.18247507512569427
[32m[0511 08:40:39 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.19190745055675507, Train Loss: 0.18247322738170624
[32m[0511 08:40:39 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.19191353023052216, Train Loss: 0.1824713796377182
[32m[0511 08:40:39 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.19191958010196686, Train Loss: 0.18246956169605255
[32m[0511 08:40:39 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.19192557036876678, Train Loss: 0.1824677586555481
[32m[0511 08:40:39 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.19193147122859955, Train Loss: 0.18246595561504364
[32m[0511 08:40:39 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.19193735718727112, Train Loss: 0.182464137673378
[32m[0511 08:40:39 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.19194315373897552, Train Loss: 0.18246237933635712
[32m[0511 08:40:39 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.19194887578487396, Train Loss: 0.18246059119701385
[32m[0511 08:40:39 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.19195456802845, Train Loss: 0.1824588179588318
[32m[0511 08:40:39 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.19196021556854248, Train Loss: 0.18245704472064972
[32m[0511 08:40:39 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.1919657438993454, Train Loss: 0.18245531618595123
[32m[0511 08:40:39 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.1919713020324707, Train Loss: 0.18245357275009155
[32m[0511 08:40:39 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.19197677075862885, Train Loss: 0.18245184421539307
[32m[0511 08:40:39 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.1919821947813034, Train Loss: 0.18245011568069458
[32m[0511 08:40:39 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.1919875591993332, Train Loss: 0.1824484020471573
[32m[0511 08:40:39 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.1919928938150406, Train Loss: 0.1824467033147812
[32m[0511 08:40:39 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.1919981986284256, Train Loss: 0.1824449896812439
[32m[0511 08:40:39 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.19200342893600464, Train Loss: 0.182443305850029
[32m[0511 08:40:39 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.1920086294412613, Train Loss: 0.1824416071176529
[32m[0511 08:40:39 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.19201380014419556, Train Loss: 0.182439923286438
[32m[0511 08:40:39 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.19201892614364624, Train Loss: 0.18243825435638428
[32m[0511 08:40:40 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.19202400743961334, Train Loss: 0.18243657052516937
[32m[0511 08:40:40 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.19202904403209686, Train Loss: 0.18243490159511566
[32m[0511 08:40:40 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.192034050822258, Train Loss: 0.18243324756622314
[32m[0511 08:40:40 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.19203904271125793, Train Loss: 0.18243159353733063
[32m[0511 08:40:40 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.1920439451932907, Train Loss: 0.1824299544095993
[32m[0511 08:40:40 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.19204886257648468, Train Loss: 0.1824283003807068
[32m[0511 08:40:40 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.19205372035503387, Train Loss: 0.18242667615413666
[32m[0511 08:40:40 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.19205857813358307, Train Loss: 0.18242503702640533
[32m[0511 08:40:40 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.1920633614063263, Train Loss: 0.182423397898674
[32m[0511 08:40:40 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.19206812977790833, Train Loss: 0.18242178857326508
[32m[0511 08:40:40 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.19207288324832916, Train Loss: 0.18242017924785614
[32m[0511 08:40:40 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.19207759201526642, Train Loss: 0.18241854012012482
[32m[0511 08:40:40 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.19208228588104248, Train Loss: 0.18241696059703827
[32m[0511 08:40:40 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.19208692014217377, Train Loss: 0.18241536617279053
[32m[0511 08:40:40 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.19209159910678864, Train Loss: 0.1824137568473816
[32m[0511 08:40:40 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.19209618866443634, Train Loss: 0.18241216242313385
[32m[0511 08:40:40 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.19210077822208405, Train Loss: 0.1824105978012085
[32m[0511 08:40:40 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.19210530817508698, Train Loss: 0.18240900337696075
[32m[0511 08:40:40 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.1921098232269287, Train Loss: 0.1824074536561966
[32m[0511 08:40:40 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.19211436808109283, Train Loss: 0.18240587413311005
[32m[0511 08:40:40 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.192118838429451, Train Loss: 0.1824043244123459
[32m[0511 08:40:40 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.19212330877780914, Train Loss: 0.18240274488925934
[32m[0511 08:40:40 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.19212773442268372, Train Loss: 0.18240122497081757
[32m[0511 08:40:40 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.19213217496871948, Train Loss: 0.1823996901512146
[32m[0511 08:40:40 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.19213658571243286, Train Loss: 0.18239812552928925
[32m[0511 08:40:40 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.19214092195034027, Train Loss: 0.18239659070968628
[32m[0511 08:40:40 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.19214528799057007, Train Loss: 0.1823950856924057
[32m[0511 08:40:40 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.19214960932731628, Train Loss: 0.18239353597164154
[32m[0511 08:40:40 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.1921539306640625, Train Loss: 0.18239204585552216
[32m[0511 08:40:40 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.19215822219848633, Train Loss: 0.1823905110359192
[32m[0511 08:40:40 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.19216249883174896, Train Loss: 0.1823890209197998
[32m[0511 08:40:40 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.19216673076152802, Train Loss: 0.18238751590251923
[32m[0511 08:40:40 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.19217099249362946, Train Loss: 0.18238602578639984
[32m[0511 08:40:40 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.19217517971992493, Train Loss: 0.18238453567028046
[32m[0511 08:40:40 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.19217939674854279, Train Loss: 0.18238304555416107
[32m[0511 08:40:40 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.19218358397483826, Train Loss: 0.1823815554380417
[32m[0511 08:40:40 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.19218774139881134, Train Loss: 0.1823800951242447
[32m[0511 08:40:41 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.19219189882278442, Train Loss: 0.1823786050081253
[32m[0511 08:40:41 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.19219601154327393, Train Loss: 0.1823771446943283
[32m[0511 08:40:41 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.19220013916492462, Train Loss: 0.1823756843805313
[32m[0511 08:40:41 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.19220422208309174, Train Loss: 0.1823742389678955
[32m[0511 08:40:41 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.19220827519893646, Train Loss: 0.1823727935552597
[32m[0511 08:40:41 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.19221234321594238, Train Loss: 0.1823713630437851
[32m[0511 08:40:41 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.19221638143062592, Train Loss: 0.18236993253231049
[32m[0511 08:40:41 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.19222037494182587, Train Loss: 0.1823684722185135
[32m[0511 08:40:41 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.1922244131565094, Train Loss: 0.18236707150936127
[32m[0511 08:40:41 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.19222840666770935, Train Loss: 0.18236564099788666
[32m[0511 08:40:41 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.19223235547542572, Train Loss: 0.18236422538757324
[32m[0511 08:40:41 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.1922363042831421, Train Loss: 0.18236280977725983
[32m[0511 08:40:41 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.19224026799201965, Train Loss: 0.1823614090681076
[32m[0511 08:40:41 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.19224418699741364, Train Loss: 0.1823599934577942
[32m[0511 08:40:41 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.19224809110164642, Train Loss: 0.18235860764980316
[32m[0511 08:40:41 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.1922519952058792, Train Loss: 0.18235720694065094
[32m[0511 08:40:41 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.19225583970546722, Train Loss: 0.1823558360338211
[32m[0511 08:40:41 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.19225969910621643, Train Loss: 0.18235445022583008
[32m[0511 08:40:41 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.19226354360580444, Train Loss: 0.18235307931900024
[32m[0511 08:40:41 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.19226738810539246, Train Loss: 0.1823517084121704
[32m[0511 08:40:41 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.1922711580991745, Train Loss: 0.18235033750534058
[32m[0511 08:40:41 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.19227495789527893, Train Loss: 0.18234896659851074
[32m[0511 08:40:41 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.19227871298789978, Train Loss: 0.1823476105928421
[32m[0511 08:40:41 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.19228246808052063, Train Loss: 0.18234628438949585
[32m[0511 08:40:41 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.19228622317314148, Train Loss: 0.18234491348266602
[32m[0511 08:40:41 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.19228993356227875, Train Loss: 0.18234358727931976
[32m[0511 08:40:41 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.19229364395141602, Train Loss: 0.18234224617481232
[32m[0511 08:40:41 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.1922973394393921, Train Loss: 0.18234091997146606
[32m[0511 08:40:41 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.19230102002620697, Train Loss: 0.1823395937681198
[32m[0511 08:40:41 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.19230467081069946, Train Loss: 0.18233825266361237
[32m[0511 08:40:41 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.19230833649635315, Train Loss: 0.1823369413614273
[32m[0511 08:40:41 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.19231197237968445, Train Loss: 0.18233561515808105
[32m[0511 08:40:41 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.19231556355953217, Train Loss: 0.1823343187570572
[32m[0511 08:40:41 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.19231916964054108, Train Loss: 0.18233299255371094
[32m[0511 08:40:41 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.1923227608203888, Train Loss: 0.18233172595500946
[32m[0511 08:40:41 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.19232630729675293, Train Loss: 0.1823304146528244
[32m[0511 08:40:42 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.19232985377311707, Train Loss: 0.18232913315296173
[32m[0511 08:40:42 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.19233338534832, Train Loss: 0.18232785165309906
[32m[0511 08:40:42 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.19233690202236176, Train Loss: 0.182326540350914
[32m[0511 08:40:42 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.1923404186964035, Train Loss: 0.18232524394989014
[32m[0511 08:40:42 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.19234389066696167, Train Loss: 0.18232399225234985
[32m[0511 08:40:42 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.19234736263751984, Train Loss: 0.18232272565364838
[32m[0511 08:40:42 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.19235078990459442, Train Loss: 0.1823214441537857
[32m[0511 08:40:42 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.1923542320728302, Train Loss: 0.18232019245624542
[32m[0511 08:40:42 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.19235765933990479, Train Loss: 0.18231894075870514
[32m[0511 08:40:42 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.19236105680465698, Train Loss: 0.18231767416000366
[32m[0511 08:40:42 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.19236445426940918, Train Loss: 0.18231642246246338
[32m[0511 08:40:42 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.1923678070306778, Train Loss: 0.1823151856660843
[32m[0511 08:40:42 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.1923711746931076, Train Loss: 0.182313933968544
[32m[0511 08:40:42 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.19237452745437622, Train Loss: 0.18231268227100372
[32m[0511 08:40:42 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.19237786531448364, Train Loss: 0.18231146037578583
[32m[0511 08:40:42 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.1923811435699463, Train Loss: 0.18231022357940674
[32m[0511 08:40:42 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.19238443672657013, Train Loss: 0.18230898678302765
[32m[0511 08:40:42 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.19238770008087158, Train Loss: 0.18230776488780975
[32m[0511 08:40:42 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.19239097833633423, Train Loss: 0.18230654299259186
[32m[0511 08:40:42 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.1923942118883133, Train Loss: 0.18230533599853516
[32m[0511 08:40:42 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.19239744544029236, Train Loss: 0.18230409920215607
[32m[0511 08:40:42 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.19240063428878784, Train Loss: 0.18230290710926056
[32m[0511 08:40:42 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.19240383803844452, Train Loss: 0.18230170011520386
[32m[0511 08:40:42 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.1924070119857788, Train Loss: 0.18230049312114716
[32m[0511 08:40:42 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.1924101561307907, Train Loss: 0.18229927122592926
[32m[0511 08:40:42 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.192413330078125, Train Loss: 0.18229807913303375
[32m[0511 08:40:42 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.1924164593219757, Train Loss: 0.18229688704013824
[32m[0511 08:40:42 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.19241955876350403, Train Loss: 0.18229569494724274
[32m[0511 08:40:42 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.19242264330387115, Train Loss: 0.18229450285434723
[32m[0511 08:40:42 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.19242574274539948, Train Loss: 0.1822933405637741
[32m[0511 08:40:42 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.1924288123846054, Train Loss: 0.1822921484708786
[32m[0511 08:40:42 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.19243186712265015, Train Loss: 0.1822909712791443
[32m[0511 08:40:42 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.1924348622560501, Train Loss: 0.18228977918624878
[32m[0511 08:40:42 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.19243790209293365, Train Loss: 0.18228863179683685
[32m[0511 08:40:42 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.1924409419298172, Train Loss: 0.18228745460510254
[32m[0511 08:40:42 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.19244390726089478, Train Loss: 0.18228627741336823
[32m[0511 08:40:43 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.19244688749313354, Train Loss: 0.1822851300239563
[32m[0511 08:40:43 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.19244983792304993, Train Loss: 0.18228398263454437
[32m[0511 08:40:43 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.1924527883529663, Train Loss: 0.18228282034397125
[32m[0511 08:40:43 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.19245567917823792, Train Loss: 0.18228165805339813
[32m[0511 08:40:43 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.1924585998058319, Train Loss: 0.182280495762825
[32m[0511 08:40:43 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.19246149063110352, Train Loss: 0.18227934837341309
[32m[0511 08:40:43 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.19246436655521393, Train Loss: 0.18227821588516235
[32m[0511 08:40:43 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.19246724247932434, Train Loss: 0.18227706849575043
[32m[0511 08:40:43 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.19247008860111237, Train Loss: 0.1822759360074997
[32m[0511 08:40:43 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.192472904920578, Train Loss: 0.18227477371692657
[32m[0511 08:40:43 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.19247573614120483, Train Loss: 0.18227367103099823
[32m[0511 08:40:43 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.19247853755950928, Train Loss: 0.1822725385427475
[32m[0511 08:40:43 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.19248133897781372, Train Loss: 0.18227140605449677
[32m[0511 08:40:43 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.19248409569263458, Train Loss: 0.18227027356624603
[32m[0511 08:40:43 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.19248685240745544, Train Loss: 0.1822691410779953
[32m[0511 08:40:43 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.19248957931995392, Train Loss: 0.18226802349090576
[32m[0511 08:40:43 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.1924923211336136, Train Loss: 0.18226690590381622
[32m[0511 08:40:43 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.19249500334262848, Train Loss: 0.18226580321788788
[32m[0511 08:40:43 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.19249776005744934, Train Loss: 0.18226468563079834
[32m[0511 08:40:43 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.19250042736530304, Train Loss: 0.1822635680437088
[32m[0511 08:40:43 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.19250310957431793, Train Loss: 0.18226246535778046
[32m[0511 08:40:43 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.19250577688217163, Train Loss: 0.1822613626718521
[32m[0511 08:40:43 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.19250838458538055, Train Loss: 0.18226025998592377
[32m[0511 08:40:43 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.19251100718975067, Train Loss: 0.18225914239883423
[32m[0511 08:40:43 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.1925136148929596, Train Loss: 0.18225805461406708
[32m[0511 08:40:43 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.1925162374973297, Train Loss: 0.18225695192813873
[32m[0511 08:40:43 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.19251880049705505, Train Loss: 0.18225586414337158
[32m[0511 08:40:43 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.1925213634967804, Train Loss: 0.18225477635860443
[32m[0511 08:40:43 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.19252391159534454, Train Loss: 0.1822536736726761
[32m[0511 08:40:43 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.1925264596939087, Train Loss: 0.18225258588790894
[32m[0511 08:40:43 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.19252902269363403, Train Loss: 0.18225151300430298
[32m[0511 08:40:43 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.1925314962863922, Train Loss: 0.18225042521953583
[32m[0511 08:40:43 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.19253401458263397, Train Loss: 0.18224932253360748
[32m[0511 08:40:43 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.19253648817539215, Train Loss: 0.1822482794523239
[32m[0511 08:40:43 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.19253897666931152, Train Loss: 0.18224720656871796
[32m[0511 08:40:43 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.19254140555858612, Train Loss: 0.1822461038827896
[32m[0511 08:40:44 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.1925438642501831, Train Loss: 0.18224506080150604
[32m[0511 08:40:44 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.1925463229417801, Train Loss: 0.1822439581155777
[32m[0511 08:40:44 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.1925487220287323, Train Loss: 0.18224291503429413
[32m[0511 08:40:44 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.1925511211156845, Train Loss: 0.18224184215068817
[32m[0511 08:40:44 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.19255350530147552, Train Loss: 0.18224076926708221
[32m[0511 08:40:44 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.19255588948726654, Train Loss: 0.18223971128463745
[32m[0511 08:40:44 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.19255825877189636, Train Loss: 0.1822386533021927
[32m[0511 08:40:44 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.19256062805652618, Train Loss: 0.18223758041858673
[32m[0511 08:40:44 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.19256296753883362, Train Loss: 0.18223655223846436
[32m[0511 08:40:44 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.19256524741649628, Train Loss: 0.1822354793548584
[32m[0511 08:40:44 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.1925676167011261, Train Loss: 0.18223445117473602
[32m[0511 08:40:44 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.19256989657878876, Train Loss: 0.18223339319229126
[32m[0511 08:40:44 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.1925722062587738, Train Loss: 0.1822323352098465
[32m[0511 08:40:44 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.19257447123527527, Train Loss: 0.18223130702972412
[32m[0511 08:40:44 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.19257675111293793, Train Loss: 0.18223024904727936
[32m[0511 08:40:44 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.192578986287117, Train Loss: 0.18222922086715698
[32m[0511 08:40:44 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.19258122146129608, Train Loss: 0.1822281926870346
[32m[0511 08:40:44 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.19258345663547516, Train Loss: 0.18222711980342865
[32m[0511 08:40:44 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.19258567690849304, Train Loss: 0.18222610652446747
[32m[0511 08:40:44 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.19258788228034973, Train Loss: 0.1822250634431839
[32m[0511 08:40:44 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.19259007275104523, Train Loss: 0.18222403526306152
[32m[0511 08:40:44 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.19259224832057953, Train Loss: 0.18222300708293915
[32m[0511 08:40:44 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.19259443879127502, Train Loss: 0.18222196400165558
[32m[0511 08:40:44 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.19259658455848694, Train Loss: 0.1822209358215332
[32m[0511 08:40:44 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.19259876012802124, Train Loss: 0.18221992254257202
[32m[0511 08:40:44 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.19260086119174957, Train Loss: 0.18221889436244965
[32m[0511 08:40:44 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.1926030069589615, Train Loss: 0.18221788108348846
[32m[0511 08:40:44 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.19260509312152863, Train Loss: 0.1822168380022049
[32m[0511 08:40:44 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.19260722398757935, Train Loss: 0.1822158247232437
[32m[0511 08:40:44 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.1926092803478241, Train Loss: 0.18221481144428253
[32m[0511 08:40:44 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.19261139631271362, Train Loss: 0.18221379816532135
[32m[0511 08:40:44 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.19261345267295837, Train Loss: 0.18221278488636017
[32m[0511 08:40:44 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.19261549413204193, Train Loss: 0.18221180140972137
[32m[0511 08:40:44 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.19261755049228668, Train Loss: 0.1822107583284378
[32m[0511 08:40:44 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.19261962175369263, Train Loss: 0.182209774851799
[32m[0511 08:40:44 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.1926216185092926, Train Loss: 0.18220877647399902
[32m[0511 08:40:44 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.19262365996837616, Train Loss: 0.18220774829387665
[32m[0511 08:40:45 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.19262562692165375, Train Loss: 0.18220674991607666
[32m[0511 08:40:45 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.1926276534795761, Train Loss: 0.18220575153827667
[32m[0511 08:40:45 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.1926296204328537, Train Loss: 0.1822047382593155
[32m[0511 08:40:45 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.19263164699077606, Train Loss: 0.1822037547826767
[32m[0511 08:40:45 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.19263359904289246, Train Loss: 0.18220274150371552
[32m[0511 08:40:45 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.19263552129268646, Train Loss: 0.18220175802707672
[32m[0511 08:40:45 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.19263747334480286, Train Loss: 0.18220077455043793
[32m[0511 08:40:45 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.19263941049575806, Train Loss: 0.18219977617263794
[32m[0511 08:40:45 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.19264134764671326, Train Loss: 0.18219880759716034
[32m[0511 08:40:45 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.19264326989650726, Train Loss: 0.18219780921936035
[32m[0511 08:40:45 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.19264520704746246, Train Loss: 0.18219679594039917
[32m[0511 08:40:45 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.1926470547914505, Train Loss: 0.18219582736492157
[32m[0511 08:40:45 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.1926489621400833, Train Loss: 0.18219484388828278
[32m[0511 08:40:45 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.19265085458755493, Train Loss: 0.18219386041164398
[32m[0511 08:40:45 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.19265270233154297, Train Loss: 0.1821928769350052
[32m[0511 08:40:45 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.1926545649766922, Train Loss: 0.1821918934583664
[32m[0511 08:40:45 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.19265642762184143, Train Loss: 0.1821909099817276
[32m[0511 08:40:45 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.19265827536582947, Train Loss: 0.1821899265050888
[32m[0511 08:40:45 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.19266009330749512, Train Loss: 0.1821889877319336
[32m[0511 08:40:45 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.19266192615032196, Train Loss: 0.1821879893541336
[32m[0511 08:40:45 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.1926637440919876, Train Loss: 0.182187020778656
[32m[0511 08:40:45 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.19266556203365326, Train Loss: 0.1821860671043396
[32m[0511 08:40:45 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.19266736507415771, Train Loss: 0.182185098528862
[32m[0511 08:40:45 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.19266916811466217, Train Loss: 0.1821841448545456
[32m[0511 08:40:45 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.19267092645168304, Train Loss: 0.1821831613779068
[32m[0511 08:40:45 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.1926727145910263, Train Loss: 0.1821821928024292
[32m[0511 08:40:45 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.19267447292804718, Train Loss: 0.182181254029274
[32m[0511 08:40:45 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.19267624616622925, Train Loss: 0.1821802854537964
[32m[0511 08:40:45 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.19267798960208893, Train Loss: 0.18217933177947998
[32m[0511 08:40:45 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.19267971813678741, Train Loss: 0.18217836320400238
[32m[0511 08:40:45 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.1926814615726471, Train Loss: 0.18217740952968597
[32m[0511 08:40:45 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.19268319010734558, Train Loss: 0.18217645585536957
[32m[0511 08:40:45 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.19268488883972168, Train Loss: 0.18217551708221436
[32m[0511 08:40:45 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.19268660247325897, Train Loss: 0.18217457830905914
[32m[0511 08:40:45 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.19268833100795746, Train Loss: 0.18217360973358154
[32m[0511 08:40:45 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.19268998503684998, Train Loss: 0.18217267096042633
[32m[0511 08:40:45 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.19269169867038727, Train Loss: 0.18217171728610992
[32m[0511 08:40:46 @mbmf_sampler.py:98][0m Finished 9th episode
[32m[0511 08:40:46 @mbmf_sampler.py:102][0m 1809 timesteps from 9 episodes collected
[32m[0511 08:59:39 @mbmf_trainer.py:160][0m Mean reward: -1245.0463799265992
[32m[0511 08:59:39 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.18828041851520538, Train Loss: 0.17874905467033386
[32m[0511 08:59:39 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.1882537454366684, Train Loss: 0.17872285842895508
[32m[0511 08:59:39 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.1882568746805191, Train Loss: 0.17870669066905975
[32m[0511 08:59:39 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.18826711177825928, Train Loss: 0.17869681119918823
[32m[0511 08:59:39 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.18828102946281433, Train Loss: 0.17868882417678833
[32m[0511 08:59:39 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.18829433619976044, Train Loss: 0.17868170142173767
[32m[0511 08:59:39 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.18830560147762299, Train Loss: 0.1786753386259079
[32m[0511 08:59:39 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.18831588327884674, Train Loss: 0.17866961658000946
[32m[0511 08:59:39 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.18832534551620483, Train Loss: 0.17866449058055878
[32m[0511 08:59:39 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.188334122300148, Train Loss: 0.1786598563194275
[32m[0511 08:59:39 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.1883423775434494, Train Loss: 0.1786556839942932
[32m[0511 08:59:39 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.1883501410484314, Train Loss: 0.17865188419818878
[32m[0511 08:59:39 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.1883573681116104, Train Loss: 0.1786484271287918
[32m[0511 08:59:39 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.1883641481399536, Train Loss: 0.17864522337913513
[32m[0511 08:59:39 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.188370481133461, Train Loss: 0.17864228785037994
[32m[0511 08:59:39 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.18837642669677734, Train Loss: 0.17863954603672028
[32m[0511 08:59:39 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.18838199973106384, Train Loss: 0.17863701283931732
[32m[0511 08:59:39 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.18838723003864288, Train Loss: 0.1786346286535263
[32m[0511 08:59:40 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.18839211761951447, Train Loss: 0.17863239347934723
[32m[0511 08:59:40 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.18839676678180695, Train Loss: 0.1786302775144577
[32m[0511 08:59:40 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.18840114772319794, Train Loss: 0.17862828075885773
[32m[0511 08:59:40 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.18840526044368744, Train Loss: 0.1786263883113861
[32m[0511 08:59:40 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.18840911984443665, Train Loss: 0.17862457036972046
[32m[0511 08:59:40 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.1884128451347351, Train Loss: 0.17862285673618317
[32m[0511 08:59:40 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.18841631710529327, Train Loss: 0.17862123250961304
[32m[0511 08:59:40 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.1884196400642395, Train Loss: 0.1786196082830429
[32m[0511 08:59:40 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.18842282891273499, Train Loss: 0.17861808836460114
[32m[0511 08:59:40 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.18842580914497375, Train Loss: 0.17861661314964294
[32m[0511 08:59:40 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.18842871487140656, Train Loss: 0.17861515283584595
[32m[0511 08:59:40 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.1884314864873886, Train Loss: 0.17861376702785492
[32m[0511 08:59:40 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.18843412399291992, Train Loss: 0.17861242592334747
[32m[0511 08:59:40 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.18843665719032288, Train Loss: 0.17861111462116241
[32m[0511 08:59:40 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.18843908607959747, Train Loss: 0.17860981822013855
[32m[0511 08:59:40 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.1884414553642273, Train Loss: 0.17860858142375946
[32m[0511 08:59:40 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.18844373524188995, Train Loss: 0.17860735952854156
[32m[0511 08:59:40 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.18844592571258545, Train Loss: 0.17860616743564606
[32m[0511 08:59:40 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.18844804167747498, Train Loss: 0.17860499024391174
[32m[0511 08:59:40 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.1884501427412033, Train Loss: 0.17860384285449982
[32m[0511 08:59:40 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.1884521245956421, Train Loss: 0.17860271036624908
[32m[0511 08:59:40 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.18845407664775848, Train Loss: 0.17860157787799835
[32m[0511 08:59:40 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.1884559690952301, Train Loss: 0.1786005049943924
[32m[0511 08:59:40 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.18845781683921814, Train Loss: 0.17859940230846405
[32m[0511 08:59:40 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.1884596347808838, Train Loss: 0.17859835922718048
[32m[0511 08:59:40 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.18846142292022705, Train Loss: 0.17859727144241333
[32m[0511 08:59:40 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.18846315145492554, Train Loss: 0.17859625816345215
[32m[0511 08:59:40 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.18846486508846283, Train Loss: 0.17859524488449097
[32m[0511 08:59:40 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.18846653401851654, Train Loss: 0.1785942018032074
[32m[0511 08:59:41 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.18846818804740906, Train Loss: 0.1785932183265686
[32m[0511 08:59:41 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.188469797372818, Train Loss: 0.17859221994876862
[32m[0511 08:59:41 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.18847140669822693, Train Loss: 0.17859120666980743
[32m[0511 08:59:41 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.1884729415178299, Train Loss: 0.17859025299549103
[32m[0511 08:59:41 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.18847450613975525, Train Loss: 0.17858929932117462
[32m[0511 08:59:41 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.18847602605819702, Train Loss: 0.17858834564685822
[32m[0511 08:59:41 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.1884775310754776, Train Loss: 0.178587406873703
[32m[0511 08:59:41 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.18847903609275818, Train Loss: 0.1785864681005478
[32m[0511 08:59:41 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.18848049640655518, Train Loss: 0.17858552932739258
[32m[0511 08:59:41 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.18848194181919098, Train Loss: 0.17858460545539856
[32m[0511 08:59:41 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.1884833574295044, Train Loss: 0.17858369648456573
[32m[0511 08:59:41 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.1884848177433014, Train Loss: 0.1785828024148941
[32m[0511 08:59:41 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.188486248254776, Train Loss: 0.17858187854290009
[32m[0511 08:59:41 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.18848760426044464, Train Loss: 0.17858098447322845
[32m[0511 08:59:41 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.18848900496959686, Train Loss: 0.17858009040355682
[32m[0511 08:59:41 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.1884903907775879, Train Loss: 0.1785791963338852
[32m[0511 08:59:41 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.18849174678325653, Train Loss: 0.17857833206653595
[32m[0511 08:59:41 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.18849310278892517, Train Loss: 0.1785774528980255
[32m[0511 08:59:41 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.18849444389343262, Train Loss: 0.17857655882835388
[32m[0511 08:59:41 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.18849578499794006, Train Loss: 0.17857569456100464
[32m[0511 08:59:41 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.1884971261024475, Train Loss: 0.1785748451948166
[32m[0511 08:59:41 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.18849843740463257, Train Loss: 0.17857399582862854
[32m[0511 08:59:41 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.18849974870681763, Train Loss: 0.1785731315612793
[32m[0511 08:59:41 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.1885010451078415, Train Loss: 0.17857231199741364
[32m[0511 08:59:41 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.18850235641002655, Train Loss: 0.1785714477300644
[32m[0511 08:59:41 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.18850360810756683, Train Loss: 0.17857059836387634
[32m[0511 08:59:41 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.1885049194097519, Train Loss: 0.17856979370117188
[32m[0511 08:59:41 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.18850618600845337, Train Loss: 0.17856892943382263
[32m[0511 08:59:41 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.18850745260715485, Train Loss: 0.17856812477111816
[32m[0511 08:59:42 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.18850871920585632, Train Loss: 0.1785673052072525
[32m[0511 08:59:42 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.1885099560022354, Train Loss: 0.17856648564338684
[32m[0511 08:59:42 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.18851123750209808, Train Loss: 0.17856566607952118
[32m[0511 08:59:42 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.18851245939731598, Train Loss: 0.17856483161449432
[32m[0511 08:59:42 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.18851371109485626, Train Loss: 0.17856402695178986
[32m[0511 08:59:42 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.18851494789123535, Train Loss: 0.1785632073879242
[32m[0511 08:59:42 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.18851616978645325, Train Loss: 0.17856241762638092
[32m[0511 08:59:42 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.18851739168167114, Train Loss: 0.17856159806251526
[32m[0511 08:59:42 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.18851861357688904, Train Loss: 0.17856080830097198
[32m[0511 08:59:42 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.18851982057094574, Train Loss: 0.1785600185394287
[32m[0511 08:59:42 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.18852102756500244, Train Loss: 0.17855921387672424
[32m[0511 08:59:42 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.18852221965789795, Train Loss: 0.17855842411518097
[32m[0511 08:59:42 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.18852342665195465, Train Loss: 0.1785576343536377
[32m[0511 08:59:42 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.18852461874485016, Train Loss: 0.17855684459209442
[32m[0511 08:59:42 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.18852581083774567, Train Loss: 0.17855605483055115
[32m[0511 08:59:42 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.18852700293064117, Train Loss: 0.17855527997016907
[32m[0511 08:59:42 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.18852819502353668, Train Loss: 0.178554505109787
[32m[0511 08:59:42 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.1885293573141098, Train Loss: 0.1785537302494049
[32m[0511 08:59:42 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.18853051960468292, Train Loss: 0.17855295538902283
[32m[0511 08:59:42 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.18853171169757843, Train Loss: 0.17855218052864075
[32m[0511 08:59:42 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.18853288888931274, Train Loss: 0.17855140566825867
[32m[0511 08:59:42 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.18853406608104706, Train Loss: 0.17855064570903778
[32m[0511 08:59:42 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.1885351985692978, Train Loss: 0.1785499006509781
[32m[0511 08:59:42 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.1885363608598709, Train Loss: 0.17854909598827362
[32m[0511 08:59:42 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.18853749334812164, Train Loss: 0.17854833602905273
[32m[0511 08:59:42 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.18853865563869476, Train Loss: 0.17854756116867065
[32m[0511 08:59:42 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.1885397881269455, Train Loss: 0.17854681611061096
[32m[0511 08:59:42 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.18854093551635742, Train Loss: 0.17854605615139008
[32m[0511 08:59:43 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.18854208290576935, Train Loss: 0.17854531109333038
[32m[0511 08:59:43 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.18854323029518127, Train Loss: 0.1785445511341095
[32m[0511 08:59:43 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.1885443776845932, Train Loss: 0.1785437911748886
[32m[0511 08:59:43 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.18854551017284393, Train Loss: 0.17854303121566772
[32m[0511 08:59:43 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.18854662775993347, Train Loss: 0.17854228615760803
[32m[0511 08:59:43 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.188547745347023, Train Loss: 0.17854152619838715
[32m[0511 08:59:43 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.18854886293411255, Train Loss: 0.17854078114032745
[32m[0511 08:59:43 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.18854999542236328, Train Loss: 0.17854003608226776
[32m[0511 08:59:43 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.18855109810829163, Train Loss: 0.17853929102420807
[32m[0511 08:59:43 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.18855221569538116, Train Loss: 0.17853856086730957
[32m[0511 08:59:43 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.1885533332824707, Train Loss: 0.17853781580924988
[32m[0511 08:59:43 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.18855445086956024, Train Loss: 0.17853710055351257
[32m[0511 08:59:43 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.1885555535554886, Train Loss: 0.17853635549545288
[32m[0511 08:59:43 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.18855665624141693, Train Loss: 0.1785356104373932
[32m[0511 08:59:43 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.18855774402618408, Train Loss: 0.1785348504781723
[32m[0511 08:59:43 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.18855884671211243, Train Loss: 0.178534135222435
[32m[0511 08:59:43 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.18855996429920197, Train Loss: 0.1785334050655365
[32m[0511 08:59:43 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.18856105208396912, Train Loss: 0.1785326600074768
[32m[0511 08:59:43 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.18856212496757507, Train Loss: 0.1785319298505783
[32m[0511 08:59:43 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.1885632425546646, Train Loss: 0.1785311996936798
[32m[0511 08:59:43 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.18856431543827057, Train Loss: 0.1785304695367813
[32m[0511 08:59:43 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.1885654181241989, Train Loss: 0.17852972447872162
[32m[0511 08:59:43 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.18856649100780487, Train Loss: 0.1785290241241455
[32m[0511 08:59:43 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.18856757879257202, Train Loss: 0.178528293967247
[32m[0511 08:59:43 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.18856865167617798, Train Loss: 0.1785275638103485
[32m[0511 08:59:43 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.18856972455978394, Train Loss: 0.17852683365345
[32m[0511 08:59:43 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.1885708123445511, Train Loss: 0.1785261332988739
[32m[0511 08:59:43 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.18857188522815704, Train Loss: 0.1785254180431366
[32m[0511 08:59:44 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.1885729879140854, Train Loss: 0.1785246878862381
[32m[0511 08:59:44 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.18857403099536896, Train Loss: 0.1785239577293396
[32m[0511 08:59:44 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.18857510387897491, Train Loss: 0.1785232573747635
[32m[0511 08:59:44 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.18857617676258087, Train Loss: 0.17852254211902618
[32m[0511 08:59:44 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.18857724964618683, Train Loss: 0.17852181196212769
[32m[0511 08:59:44 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.1885782927274704, Train Loss: 0.17852109670639038
[32m[0511 08:59:44 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.18857935070991516, Train Loss: 0.17852038145065308
[32m[0511 08:59:44 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.18858042359352112, Train Loss: 0.17851966619491577
[32m[0511 08:59:44 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.18858149647712708, Train Loss: 0.17851896584033966
[32m[0511 08:59:44 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.18858252465724945, Train Loss: 0.17851823568344116
[32m[0511 08:59:44 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.1885836124420166, Train Loss: 0.17851752042770386
[32m[0511 08:59:44 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.18858467042446136, Train Loss: 0.17851682007312775
[32m[0511 08:59:44 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.18858572840690613, Train Loss: 0.17851610481739044
[32m[0511 08:59:44 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.1885867565870285, Train Loss: 0.17851538956165314
[32m[0511 08:59:44 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.18858784437179565, Train Loss: 0.17851470410823822
[32m[0511 08:59:44 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.18858885765075684, Train Loss: 0.17851398885250092
[32m[0511 08:59:44 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.1885899156332016, Train Loss: 0.1785132735967636
[32m[0511 08:59:44 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.18859097361564636, Train Loss: 0.1785125732421875
[32m[0511 08:59:44 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.18859201669692993, Train Loss: 0.17851188778877258
[32m[0511 08:59:44 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.1885930448770523, Train Loss: 0.17851117253303528
[32m[0511 08:59:44 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.18859408795833588, Train Loss: 0.17851047217845917
[32m[0511 08:59:44 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.18859514594078064, Train Loss: 0.17850977182388306
[32m[0511 08:59:44 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.18859615921974182, Train Loss: 0.17850907146930695
[32m[0511 08:59:44 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.1885972023010254, Train Loss: 0.17850837111473083
[32m[0511 08:59:44 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.18859826028347015, Train Loss: 0.17850765585899353
[32m[0511 08:59:44 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.18859925866127014, Train Loss: 0.178507000207901
[32m[0511 08:59:44 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.1886003017425537, Train Loss: 0.1785062700510025
[32m[0511 08:59:44 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.18860135972499847, Train Loss: 0.17850559949874878
[32m[0511 08:59:44 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.18860235810279846, Train Loss: 0.17850489914417267
[32m[0511 08:59:45 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.18860341608524323, Train Loss: 0.17850418388843536
[32m[0511 08:59:45 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.1886044144630432, Train Loss: 0.17850349843502045
[32m[0511 08:59:45 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.18860545754432678, Train Loss: 0.17850278317928314
[32m[0511 08:59:45 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.18860648572444916, Train Loss: 0.17850211262702942
[32m[0511 08:59:45 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.18860749900341034, Train Loss: 0.17850139737129211
[32m[0511 08:59:45 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.1886085420846939, Train Loss: 0.1785007119178772
[32m[0511 08:59:45 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.1886095404624939, Train Loss: 0.1785000115633011
[32m[0511 08:59:45 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.18861058354377747, Train Loss: 0.17849935591220856
[32m[0511 08:59:45 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.18861161172389984, Train Loss: 0.17849865555763245
[32m[0511 08:59:45 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.18861261010169983, Train Loss: 0.17849794030189514
[32m[0511 08:59:45 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.1886136382818222, Train Loss: 0.1784972846508026
[32m[0511 08:59:45 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.1886146515607834, Train Loss: 0.1784965842962265
[32m[0511 08:59:45 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.18861564993858337, Train Loss: 0.1784958839416504
[32m[0511 08:59:45 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.18861666321754456, Train Loss: 0.17849519848823547
[32m[0511 08:59:45 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.18861770629882812, Train Loss: 0.17849449813365936
[32m[0511 08:59:45 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.18861868977546692, Train Loss: 0.17849382758140564
[32m[0511 08:59:45 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.1886197030544281, Train Loss: 0.17849315702915192
[32m[0511 08:59:45 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.18862073123455048, Train Loss: 0.1784924566745758
[32m[0511 08:59:45 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.18862172961235046, Train Loss: 0.17849178612232208
[32m[0511 08:59:45 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.18862272799015045, Train Loss: 0.17849110066890717
[32m[0511 08:59:45 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.18862374126911163, Train Loss: 0.17849041521549225
[32m[0511 08:59:45 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.18862475454807281, Train Loss: 0.17848971486091614
[32m[0511 08:59:45 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.1886257380247116, Train Loss: 0.17848902940750122
[32m[0511 08:59:45 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.1886267364025116, Train Loss: 0.1784883439540863
[32m[0511 08:59:45 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.18862774968147278, Train Loss: 0.17848767340183258
[32m[0511 08:59:45 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.18862874805927277, Train Loss: 0.17848697304725647
[32m[0511 08:59:45 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.18862973153591156, Train Loss: 0.17848630249500275
[32m[0511 08:59:45 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.18863075971603394, Train Loss: 0.17848560214042664
[32m[0511 08:59:45 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.18863174319267273, Train Loss: 0.1784849315881729
[32m[0511 08:59:45 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.18863274157047272, Train Loss: 0.17848427593708038
[32m[0511 08:59:46 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.1886337250471115, Train Loss: 0.17848357558250427
[32m[0511 08:59:46 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.1886347085237503, Train Loss: 0.17848290503025055
[32m[0511 08:59:46 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.1886357218027115, Train Loss: 0.17848223447799683
[32m[0511 08:59:46 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.18863670527935028, Train Loss: 0.1784815490245819
[32m[0511 08:59:46 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.18863767385482788, Train Loss: 0.178480863571167
[32m[0511 08:59:46 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.18863870203495026, Train Loss: 0.17848019301891327
[32m[0511 08:59:46 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.18863968551158905, Train Loss: 0.17847952246665955
[32m[0511 08:59:46 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.18864063918590546, Train Loss: 0.17847882211208344
[32m[0511 08:59:46 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.18864163756370544, Train Loss: 0.1784781664609909
[32m[0511 08:59:46 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.18864262104034424, Train Loss: 0.178477481007576
[32m[0511 08:59:46 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.18864360451698303, Train Loss: 0.17847681045532227
[32m[0511 08:59:46 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.18864455819129944, Train Loss: 0.17847612500190735
[32m[0511 08:59:46 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.18864557147026062, Train Loss: 0.17847545444965363
[32m[0511 08:59:46 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.18864652514457703, Train Loss: 0.1784747987985611
[32m[0511 08:59:46 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.18864752352237701, Train Loss: 0.17847411334514618
[32m[0511 08:59:46 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.1886485069990158, Train Loss: 0.17847344279289246
[32m[0511 08:59:46 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.18864946067333221, Train Loss: 0.17847275733947754
[32m[0511 08:59:46 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.18865042924880981, Train Loss: 0.17847207188606262
[32m[0511 08:59:46 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.1886514127254486, Train Loss: 0.1784713864326477
[32m[0511 08:59:46 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.1886523813009262, Train Loss: 0.17847076058387756
[32m[0511 08:59:46 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.1886533498764038, Train Loss: 0.17847006022930145
[32m[0511 08:59:46 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.1886543184518814, Train Loss: 0.17846940457820892
[32m[0511 08:59:46 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.18865527212619781, Train Loss: 0.178468719124794
[32m[0511 08:59:46 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.18865622580051422, Train Loss: 0.1784680336713791
[32m[0511 08:59:46 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.18865719437599182, Train Loss: 0.17846736311912537
[32m[0511 08:59:46 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.18865816295146942, Train Loss: 0.17846670746803284
[32m[0511 08:59:46 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.18865913152694702, Train Loss: 0.17846602201461792
[32m[0511 08:59:46 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.18866008520126343, Train Loss: 0.1784653514623642
[32m[0511 08:59:46 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.18866103887557983, Train Loss: 0.17846466600894928
[32m[0511 08:59:46 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.18866202235221863, Train Loss: 0.17846401035785675
[32m[0511 08:59:47 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.18866294622421265, Train Loss: 0.17846332490444183
[32m[0511 08:59:47 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.18866389989852905, Train Loss: 0.1784626692533493
[32m[0511 08:59:47 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.18866486847400665, Train Loss: 0.17846201360225677
[32m[0511 08:59:47 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.18866579234600067, Train Loss: 0.17846132814884186
[32m[0511 08:59:47 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.18866674602031708, Train Loss: 0.17846067249774933
[32m[0511 08:59:47 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.18866769969463348, Train Loss: 0.1784599870443344
[32m[0511 08:59:47 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.1886686384677887, Train Loss: 0.17845933139324188
[32m[0511 08:59:47 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.1886695921421051, Train Loss: 0.17845866084098816
[32m[0511 08:59:47 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.18867053091526031, Train Loss: 0.17845799028873444
[32m[0511 08:59:47 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.18867145478725433, Train Loss: 0.17845730483531952
[32m[0511 08:59:47 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.18867239356040955, Train Loss: 0.1784566193819046
[32m[0511 08:59:47 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.18867333233356476, Train Loss: 0.17845597863197327
[32m[0511 08:59:47 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.18867425620555878, Train Loss: 0.17845530807971954
[32m[0511 08:59:47 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.18867520987987518, Train Loss: 0.17845462262630463
[32m[0511 08:59:47 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.1886761337518692, Train Loss: 0.1784539669752121
[32m[0511 08:59:47 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.18867707252502441, Train Loss: 0.17845328152179718
[32m[0511 08:59:47 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.18867799639701843, Train Loss: 0.17845259606838226
[32m[0511 08:59:47 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.18867892026901245, Train Loss: 0.17845195531845093
[32m[0511 08:59:47 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.18867984414100647, Train Loss: 0.1784512847661972
[32m[0511 08:59:47 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.1886807382106781, Train Loss: 0.17845061421394348
[32m[0511 08:59:47 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.1886816918849945, Train Loss: 0.17844994366168976
[32m[0511 08:59:47 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.18868258595466614, Train Loss: 0.17844928801059723
[32m[0511 08:59:47 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.18868352472782135, Train Loss: 0.1784486025571823
[32m[0511 08:59:47 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.18868443369865417, Train Loss: 0.17844794690608978
[32m[0511 08:59:47 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.1886853575706482, Train Loss: 0.17844726145267487
[32m[0511 08:59:47 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.18868625164031982, Train Loss: 0.17844659090042114
[32m[0511 08:59:47 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.18868716061115265, Train Loss: 0.17844592034816742
[32m[0511 08:59:47 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.18868808448314667, Train Loss: 0.1784452497959137
[32m[0511 08:59:48 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.1886889934539795, Train Loss: 0.17844457924365997
[32m[0511 08:59:48 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.18868988752365112, Train Loss: 0.17844392359256744
[32m[0511 08:59:48 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.18869079649448395, Train Loss: 0.17844326794147491
[32m[0511 08:59:48 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.18869170546531677, Train Loss: 0.17844258248806
[32m[0511 08:59:48 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.1886925846338272, Train Loss: 0.17844192683696747
[32m[0511 08:59:48 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.18869347870349884, Train Loss: 0.17844125628471375
[32m[0511 08:59:48 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.18869435787200928, Train Loss: 0.17844058573246002
[32m[0511 08:59:48 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.18869523704051971, Train Loss: 0.1784399151802063
[32m[0511 08:59:48 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.18869616091251373, Train Loss: 0.1784392148256302
[32m[0511 08:59:48 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.18869704008102417, Train Loss: 0.17843857407569885
[32m[0511 08:59:48 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.1886979192495346, Train Loss: 0.17843790352344513
[32m[0511 08:59:48 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.18869879841804504, Train Loss: 0.1784372329711914
[32m[0511 08:59:48 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.18869967758655548, Train Loss: 0.17843656241893768
[32m[0511 08:59:48 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.18870055675506592, Train Loss: 0.17843587696552277
[32m[0511 08:59:48 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.18870143592357635, Train Loss: 0.17843522131443024
[32m[0511 08:59:48 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.1887023150920868, Train Loss: 0.1784345656633377
[32m[0511 08:59:48 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.18870314955711365, Train Loss: 0.1784338802099228
[32m[0511 08:59:48 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.18870402872562408, Train Loss: 0.17843320965766907
[32m[0511 08:59:48 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.18870489299297333, Train Loss: 0.17843255400657654
[32m[0511 08:59:48 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.18870577216148376, Train Loss: 0.17843188345432281
[32m[0511 08:59:48 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.188706636428833, Train Loss: 0.17843122780323029
[32m[0511 08:59:48 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.18870748579502106, Train Loss: 0.17843054234981537
[32m[0511 08:59:48 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.1887083649635315, Train Loss: 0.17842988669872284
[32m[0511 08:59:48 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.18870921432971954, Train Loss: 0.17842918634414673
[32m[0511 08:59:48 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.1887100487947464, Train Loss: 0.178428515791893
[32m[0511 08:59:48 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.18871089816093445, Train Loss: 0.17842787504196167
[32m[0511 08:59:48 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.1887117475271225, Train Loss: 0.17842717468738556
[32m[0511 08:59:48 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.18871259689331055, Train Loss: 0.17842650413513184
[32m[0511 08:59:48 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.1887134313583374, Train Loss: 0.17842581868171692
[32m[0511 08:59:48 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.18871426582336426, Train Loss: 0.17842517793178558
[32m[0511 08:59:49 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.1887151002883911, Train Loss: 0.17842450737953186
[32m[0511 08:59:49 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.18871591985225677, Train Loss: 0.17842382192611694
[32m[0511 08:59:49 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.18871678411960602, Train Loss: 0.17842316627502441
[32m[0511 08:59:49 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.18871761858463287, Train Loss: 0.1784224808216095
[32m[0511 08:59:49 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.18871842324733734, Train Loss: 0.17842182517051697
[32m[0511 08:59:49 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.1887192577123642, Train Loss: 0.17842115461826324
[32m[0511 08:59:49 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.18872007727622986, Train Loss: 0.17842046916484833
[32m[0511 08:59:49 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.18872089684009552, Train Loss: 0.1784197986125946
[32m[0511 08:59:49 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.1887217015028, Train Loss: 0.1784191131591797
[32m[0511 08:59:49 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.18872252106666565, Train Loss: 0.17841845750808716
[32m[0511 08:59:49 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.1887233406305313, Train Loss: 0.17841778695583344
[32m[0511 08:59:49 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.18872414529323578, Train Loss: 0.17841710150241852
[32m[0511 08:59:49 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.18872494995594025, Train Loss: 0.178416445851326
[32m[0511 08:59:49 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.18872572481632233, Train Loss: 0.17841574549674988
[32m[0511 08:59:49 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.1887265145778656, Train Loss: 0.17841506004333496
[32m[0511 08:59:49 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.18872733414173126, Train Loss: 0.17841438949108124
[32m[0511 08:59:49 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.18872813880443573, Train Loss: 0.1784137338399887
[32m[0511 08:59:49 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.1887289136648178, Train Loss: 0.17841306328773499
[32m[0511 08:59:49 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.18872970342636108, Train Loss: 0.17841239273548126
[32m[0511 08:59:49 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.18873049318790436, Train Loss: 0.17841169238090515
[32m[0511 08:59:49 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.18873126804828644, Train Loss: 0.17841102182865143
[32m[0511 08:59:49 @mbmf_sampler.py:98][0m Finished 9th episode
[32m[0511 08:59:49 @mbmf_sampler.py:102][0m 1809 timesteps from 9 episodes collected
[32m[0511 09:18:39 @mbmf_trainer.py:160][0m Mean reward: -1245.432937742478
[32m[0511 09:18:39 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.17262394726276398, Train Loss: 0.17786020040512085
[32m[0511 09:18:39 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.17277221381664276, Train Loss: 0.1778295636177063
[32m[0511 09:18:39 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.17275600135326385, Train Loss: 0.17782741785049438
[32m[0511 09:18:39 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.1727716624736786, Train Loss: 0.1778138130903244
[32m[0511 09:18:39 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.1727619767189026, Train Loss: 0.17781151831150055
[32m[0511 09:18:39 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.17276673018932343, Train Loss: 0.1778041422367096
[32m[0511 09:18:39 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.17276887595653534, Train Loss: 0.17779941856861115
[32m[0511 09:18:39 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.17277219891548157, Train Loss: 0.17779412865638733
[32m[0511 09:18:39 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.17277511954307556, Train Loss: 0.1777893602848053
[32m[0511 09:18:39 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.17277804017066956, Train Loss: 0.1777847409248352
[32m[0511 09:18:39 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.17278099060058594, Train Loss: 0.17778031527996063
[32m[0511 09:18:39 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.1727839559316635, Train Loss: 0.17777609825134277
[32m[0511 09:18:39 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.17278695106506348, Train Loss: 0.17777198553085327
[32m[0511 09:18:40 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.17278997600078583, Train Loss: 0.17776808142662048
[32m[0511 09:18:40 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.17279298603534698, Train Loss: 0.17776426672935486
[32m[0511 09:18:40 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.17279604077339172, Train Loss: 0.17776058614253998
[32m[0511 09:18:40 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.17279912531375885, Train Loss: 0.17775703966617584
[32m[0511 09:18:40 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.17280220985412598, Train Loss: 0.17775359749794006
[32m[0511 09:18:40 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.1728053092956543, Train Loss: 0.17775025963783264
[32m[0511 09:18:40 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.1728084236383438, Train Loss: 0.17774702608585358
[32m[0511 09:18:40 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.17281155288219452, Train Loss: 0.17774386703968048
[32m[0511 09:18:40 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.17281466722488403, Train Loss: 0.17774081230163574
[32m[0511 09:18:40 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.17281778156757355, Train Loss: 0.17773783206939697
[32m[0511 09:18:40 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.17282089591026306, Train Loss: 0.17773492634296417
[32m[0511 09:18:40 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.17282404005527496, Train Loss: 0.17773208022117615
[32m[0511 09:18:40 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.17282713949680328, Train Loss: 0.17772932350635529
[32m[0511 09:18:40 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.17283028364181519, Train Loss: 0.1777266263961792
[32m[0511 09:18:40 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.1728333979845047, Train Loss: 0.1777239888906479
[32m[0511 09:18:40 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.17283649742603302, Train Loss: 0.17772142589092255
[32m[0511 09:18:40 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.17283962666988373, Train Loss: 0.1777188926935196
[32m[0511 09:18:40 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.17284272611141205, Train Loss: 0.17771640419960022
[32m[0511 09:18:40 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.17284579575061798, Train Loss: 0.17771399021148682
[32m[0511 09:18:40 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.1728488653898239, Train Loss: 0.1777116060256958
[32m[0511 09:18:40 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.17285194993019104, Train Loss: 0.17770928144454956
[32m[0511 09:18:40 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.17285501956939697, Train Loss: 0.1777070015668869
[32m[0511 09:18:40 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.17285804450511932, Train Loss: 0.17770475149154663
[32m[0511 09:18:41 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.17286106944084167, Train Loss: 0.17770254611968994
[32m[0511 09:18:41 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.17286407947540283, Train Loss: 0.17770038545131683
[32m[0511 09:18:41 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.17286713421344757, Train Loss: 0.17769823968410492
[32m[0511 09:18:41 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.17287012934684753, Train Loss: 0.17769615352153778
[32m[0511 09:18:41 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.1728730946779251, Train Loss: 0.17769406735897064
[32m[0511 09:18:41 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.17287607491016388, Train Loss: 0.17769205570220947
[32m[0511 09:18:41 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.17287902534008026, Train Loss: 0.1776900440454483
[32m[0511 09:18:41 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.17288194596767426, Train Loss: 0.17768804728984833
[32m[0511 09:18:41 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.17288488149642944, Train Loss: 0.17768609523773193
[32m[0511 09:18:41 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.17288780212402344, Train Loss: 0.17768415808677673
[32m[0511 09:18:41 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.17289072275161743, Train Loss: 0.17768226563930511
[32m[0511 09:18:41 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.17289362847805023, Train Loss: 0.1776803880929947
[32m[0511 09:18:41 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.17289647459983826, Train Loss: 0.17767851054668427
[32m[0511 09:18:41 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.17289933562278748, Train Loss: 0.17767669260501862
[32m[0511 09:18:41 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.1729021966457367, Train Loss: 0.17767487466335297
[32m[0511 09:18:41 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.17290499806404114, Train Loss: 0.1776731014251709
[32m[0511 09:18:41 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.17290782928466797, Train Loss: 0.17767131328582764
[32m[0511 09:18:41 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.17291061580181122, Train Loss: 0.17766955494880676
[32m[0511 09:18:41 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.17291340231895447, Train Loss: 0.17766781151294708
[32m[0511 09:18:41 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.1729162037372589, Train Loss: 0.1776660680770874
[32m[0511 09:18:41 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.17291896045207977, Train Loss: 0.1776643693447113
[32m[0511 09:18:41 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.17292171716690063, Train Loss: 0.177662655711174
[32m[0511 09:18:41 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.1729244440793991, Train Loss: 0.1776609867811203
[32m[0511 09:18:42 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.17292718589305878, Train Loss: 0.1776593178510666
[32m[0511 09:18:42 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.17292989790439606, Train Loss: 0.17765764892101288
[32m[0511 09:18:42 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.17293260991573334, Train Loss: 0.17765599489212036
[32m[0511 09:18:42 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.17293527722358704, Train Loss: 0.17765438556671143
[32m[0511 09:18:42 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.17293795943260193, Train Loss: 0.1776527613401413
[32m[0511 09:18:42 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.17294064164161682, Train Loss: 0.17765115201473236
[32m[0511 09:18:42 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.17294327914714813, Train Loss: 0.17764955759048462
[32m[0511 09:18:42 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.17294593155384064, Train Loss: 0.17764797806739807
[32m[0511 09:18:42 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.17294855415821075, Train Loss: 0.17764639854431152
[32m[0511 09:18:42 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.17295119166374207, Train Loss: 0.17764484882354736
[32m[0511 09:18:42 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.17295382916927338, Train Loss: 0.17764326930046082
[32m[0511 09:18:42 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.1729564368724823, Train Loss: 0.17764171957969666
[32m[0511 09:18:42 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.17295901477336884, Train Loss: 0.1776401847600937
[32m[0511 09:18:42 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.17296159267425537, Train Loss: 0.17763864994049072
[32m[0511 09:18:42 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.1729641854763031, Train Loss: 0.17763713002204895
[32m[0511 09:18:42 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.17296674847602844, Train Loss: 0.17763562500476837
[32m[0511 09:18:42 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.17296931147575378, Train Loss: 0.1776341050863266
[32m[0511 09:18:42 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.1729719042778015, Train Loss: 0.17763260006904602
[32m[0511 09:18:42 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.17297442257404327, Train Loss: 0.17763110995292664
[32m[0511 09:18:42 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.17297695577144623, Train Loss: 0.17762964963912964
[32m[0511 09:18:42 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.17297948896884918, Train Loss: 0.17762814462184906
[32m[0511 09:18:42 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.17298200726509094, Train Loss: 0.17762668430805206
[32m[0511 09:18:42 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.1729845404624939, Train Loss: 0.17762522399425507
[32m[0511 09:18:43 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.17298704385757446, Train Loss: 0.17762376368045807
[32m[0511 09:18:43 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.17298954725265503, Train Loss: 0.17762230336666107
[32m[0511 09:18:43 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.1729920506477356, Train Loss: 0.17762085795402527
[32m[0511 09:18:43 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.17299455404281616, Train Loss: 0.17761941254138947
[32m[0511 09:18:43 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.17299702763557434, Train Loss: 0.17761798202991486
[32m[0511 09:18:43 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.1729995161294937, Train Loss: 0.17761655151844025
[32m[0511 09:18:43 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.17300200462341309, Train Loss: 0.17761512100696564
[32m[0511 09:18:43 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.17300444841384888, Train Loss: 0.17761370539665222
[32m[0511 09:18:43 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.17300693690776825, Train Loss: 0.1776122897863388
[32m[0511 09:18:43 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.17300939559936523, Train Loss: 0.17761090397834778
[32m[0511 09:18:43 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.17301185429096222, Train Loss: 0.17760947346687317
[32m[0511 09:18:43 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.1730143278837204, Train Loss: 0.17760807275772095
[32m[0511 09:18:43 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.1730167418718338, Train Loss: 0.17760668694972992
[32m[0511 09:18:43 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.17301923036575317, Train Loss: 0.1776053011417389
[32m[0511 09:18:43 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.17302164435386658, Train Loss: 0.17760390043258667
[32m[0511 09:18:43 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.17302407324314117, Train Loss: 0.17760254442691803
[32m[0511 09:18:43 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.17302651703357697, Train Loss: 0.1776011735200882
[32m[0511 09:18:43 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.17302896082401276, Train Loss: 0.17759978771209717
[32m[0511 09:18:43 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.17303140461444855, Train Loss: 0.17759843170642853
[32m[0511 09:18:43 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.17303380370140076, Train Loss: 0.17759709060192108
[32m[0511 09:18:43 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.17303623259067535, Train Loss: 0.17759571969509125
[32m[0511 09:18:43 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.17303864657878876, Train Loss: 0.1775943487882614
[32m[0511 09:18:43 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.17304107546806335, Train Loss: 0.17759302258491516
[32m[0511 09:18:43 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.17304348945617676, Train Loss: 0.17759166657924652
[32m[0511 09:18:44 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.17304590344429016, Train Loss: 0.17759034037590027
[32m[0511 09:18:44 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.17304830253124237, Train Loss: 0.17758898437023163
[32m[0511 09:18:44 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.17305073142051697, Train Loss: 0.17758765816688538
[32m[0511 09:18:44 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.17305313050746918, Train Loss: 0.1775863617658615
[32m[0511 09:18:44 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.17305554449558258, Train Loss: 0.17758502066135406
[32m[0511 09:18:44 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.1730579286813736, Train Loss: 0.177583709359169
[32m[0511 09:18:44 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.173060342669487, Train Loss: 0.17758238315582275
[32m[0511 09:18:44 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.1730627566576004, Train Loss: 0.1775810718536377
[32m[0511 09:18:44 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.17306514084339142, Train Loss: 0.17757976055145264
[32m[0511 09:18:44 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.17306753993034363, Train Loss: 0.17757846415042877
[32m[0511 09:18:44 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.17306995391845703, Train Loss: 0.1775771677494049
[32m[0511 09:18:44 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.17307233810424805, Train Loss: 0.17757587134838104
[32m[0511 09:18:44 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.17307472229003906, Train Loss: 0.17757457494735718
[32m[0511 09:18:44 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.17307713627815247, Train Loss: 0.1775732785463333
[32m[0511 09:18:44 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.17307952046394348, Train Loss: 0.17757201194763184
[32m[0511 09:18:44 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.1730819046497345, Train Loss: 0.17757071554660797
[32m[0511 09:18:44 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.1730843037366867, Train Loss: 0.1775694340467453
[32m[0511 09:18:44 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.17308667302131653, Train Loss: 0.17756816744804382
[32m[0511 09:18:44 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.17308910191059113, Train Loss: 0.17756688594818115
[32m[0511 09:18:44 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.17309147119522095, Train Loss: 0.17756564915180206
[32m[0511 09:18:44 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.17309387028217316, Train Loss: 0.17756438255310059
[32m[0511 09:18:44 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.17309625446796417, Train Loss: 0.1775631159543991
[32m[0511 09:18:44 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.1730986386537552, Train Loss: 0.17756186425685883
[32m[0511 09:18:45 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.1731010377407074, Train Loss: 0.17756061255931854
[32m[0511 09:18:45 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.17310340702533722, Train Loss: 0.17755936086177826
[32m[0511 09:18:45 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.17310580611228943, Train Loss: 0.17755809426307678
[32m[0511 09:18:45 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.17310817539691925, Train Loss: 0.1775568723678589
[32m[0511 09:18:45 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.17311057448387146, Train Loss: 0.1775556206703186
[32m[0511 09:18:45 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.17311295866966248, Train Loss: 0.1775543987751007
[32m[0511 09:18:45 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.17311535775661469, Train Loss: 0.17755314707756042
[32m[0511 09:18:45 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.1731177419424057, Train Loss: 0.17755194008350372
[32m[0511 09:18:45 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.17312012612819672, Train Loss: 0.17755073308944702
[32m[0511 09:18:45 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.17312251031398773, Train Loss: 0.17754949629306793
[32m[0511 09:18:45 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.17312490940093994, Train Loss: 0.17754828929901123
[32m[0511 09:18:45 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.17312727868556976, Train Loss: 0.17754709720611572
[32m[0511 09:18:45 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.17312967777252197, Train Loss: 0.17754586040973663
[32m[0511 09:18:45 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.1731320321559906, Train Loss: 0.17754463851451874
[32m[0511 09:18:45 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.173134446144104, Train Loss: 0.17754344642162323
[32m[0511 09:18:45 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.17313683032989502, Train Loss: 0.17754223942756653
[32m[0511 09:18:45 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.17313919961452484, Train Loss: 0.17754106223583221
[32m[0511 09:18:45 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.17314159870147705, Train Loss: 0.1775398552417755
[32m[0511 09:18:45 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.17314396798610687, Train Loss: 0.17753866314888
[32m[0511 09:18:45 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.1731463521718979, Train Loss: 0.1775374710559845
[32m[0511 09:18:45 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.1731487512588501, Train Loss: 0.17753629386425018
[32m[0511 09:18:45 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.1731511354446411, Train Loss: 0.17753510177135468
[32m[0511 09:18:45 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.17315353453159332, Train Loss: 0.17753392457962036
[32m[0511 09:18:45 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.17315588891506195, Train Loss: 0.17753273248672485
[32m[0511 09:18:45 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.17315830290317535, Train Loss: 0.17753157019615173
[32m[0511 09:18:46 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.17316067218780518, Train Loss: 0.1775304079055786
[32m[0511 09:18:46 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.17316307127475739, Train Loss: 0.1775292307138443
[32m[0511 09:18:46 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.1731654554605484, Train Loss: 0.17752806842327118
[32m[0511 09:18:46 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.17316783964633942, Train Loss: 0.17752690613269806
[32m[0511 09:18:46 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.17317022383213043, Train Loss: 0.17752575874328613
[32m[0511 09:18:46 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.17317262291908264, Train Loss: 0.177524596452713
[32m[0511 09:18:46 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.17317500710487366, Train Loss: 0.1775234490633011
[32m[0511 09:18:46 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.17317739129066467, Train Loss: 0.17752233147621155
[32m[0511 09:18:46 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.1731797754764557, Train Loss: 0.17752115428447723
[32m[0511 09:18:46 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.1731821596622467, Train Loss: 0.1775200217962265
[32m[0511 09:18:46 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.1731845587491989, Train Loss: 0.17751888930797577
[32m[0511 09:18:46 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.17318695783615112, Train Loss: 0.17751774191856384
[32m[0511 09:18:46 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.17318934202194214, Train Loss: 0.1775166094303131
[32m[0511 09:18:46 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.17319172620773315, Train Loss: 0.17751549184322357
[32m[0511 09:18:46 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.17319411039352417, Train Loss: 0.17751435935497284
[32m[0511 09:18:46 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.17319649457931519, Train Loss: 0.1775132268667221
[32m[0511 09:18:46 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.1731988936662674, Train Loss: 0.17751210927963257
[32m[0511 09:18:46 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.1732012778520584, Train Loss: 0.17751099169254303
[32m[0511 09:18:46 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.17320366203784943, Train Loss: 0.1775098741054535
[32m[0511 09:18:46 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.17320604622364044, Train Loss: 0.17750877141952515
[32m[0511 09:18:46 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.17320843040943146, Train Loss: 0.1775076687335968
[32m[0511 09:18:46 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.17321082949638367, Train Loss: 0.17750655114650726
[32m[0511 09:18:46 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.17321321368217468, Train Loss: 0.17750544846057892
[32m[0511 09:18:46 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.1732156127691269, Train Loss: 0.17750434577465057
[32m[0511 09:18:47 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.1732179969549179, Train Loss: 0.17750325798988342
[32m[0511 09:18:47 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.17322039604187012, Train Loss: 0.17750217020511627
[32m[0511 09:18:47 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.17322279512882233, Train Loss: 0.17750106751918793
[32m[0511 09:18:47 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.17322517931461334, Train Loss: 0.17749996483325958
[32m[0511 09:18:47 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.17322756350040436, Train Loss: 0.17749889194965363
[32m[0511 09:18:47 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.17322994768619537, Train Loss: 0.17749780416488647
[32m[0511 09:18:47 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.1732323318719864, Train Loss: 0.17749673128128052
[32m[0511 09:18:47 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.1732347458600998, Train Loss: 0.17749565839767456
[32m[0511 09:18:47 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.17323711514472961, Train Loss: 0.1774945706129074
[32m[0511 09:18:47 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.17323951423168182, Train Loss: 0.17749351263046265
[32m[0511 09:18:47 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.17324191331863403, Train Loss: 0.1774924248456955
[32m[0511 09:18:47 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.17324429750442505, Train Loss: 0.17749136686325073
[32m[0511 09:18:47 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.17324668169021606, Train Loss: 0.17749030888080597
[32m[0511 09:18:47 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.17324911057949066, Train Loss: 0.1774892359972
[32m[0511 09:18:47 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.1732514649629593, Train Loss: 0.17748820781707764
[32m[0511 09:18:47 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.1732538789510727, Train Loss: 0.17748713493347168
[32m[0511 09:18:47 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.1732562780380249, Train Loss: 0.1774860918521881
[32m[0511 09:18:47 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.17325864732265472, Train Loss: 0.17748503386974335
[32m[0511 09:18:47 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.17326103150844574, Train Loss: 0.17748399078845978
[32m[0511 09:18:47 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.17326341569423676, Train Loss: 0.1774829477071762
[32m[0511 09:18:47 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.17326581478118896, Train Loss: 0.17748190462589264
[32m[0511 09:18:47 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.17326819896697998, Train Loss: 0.17748086154460907
[32m[0511 09:18:47 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.1732705980539322, Train Loss: 0.1774798482656479
[32m[0511 09:18:47 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.1732729822397232, Train Loss: 0.17747880518436432
[32m[0511 09:18:48 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.17327536642551422, Train Loss: 0.17747776210308075
[32m[0511 09:18:48 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.17327775061130524, Train Loss: 0.17747674882411957
[32m[0511 09:18:48 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.17328016459941864, Train Loss: 0.1774757355451584
[32m[0511 09:18:48 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.17328251898288727, Train Loss: 0.17747469246387482
[32m[0511 09:18:48 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.17328493297100067, Train Loss: 0.17747366428375244
[32m[0511 09:18:48 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.1732873022556305, Train Loss: 0.17747265100479126
[32m[0511 09:18:48 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.1732896864414215, Train Loss: 0.17747166752815247
[32m[0511 09:18:48 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.17329207062721252, Train Loss: 0.1774706244468689
[32m[0511 09:18:48 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.17329446971416473, Train Loss: 0.17746961116790771
[32m[0511 09:18:48 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.17329685389995575, Train Loss: 0.17746859788894653
[32m[0511 09:18:48 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.17329923808574677, Train Loss: 0.17746762931346893
[32m[0511 09:18:48 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.17330162227153778, Train Loss: 0.17746661603450775
[32m[0511 09:18:48 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.1733040064573288, Train Loss: 0.17746560275554657
[32m[0511 09:18:48 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.173306405544281, Train Loss: 0.17746460437774658
[32m[0511 09:18:48 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.17330877482891083, Train Loss: 0.17746363580226898
[32m[0511 09:18:48 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.17331115901470184, Train Loss: 0.1774626225233078
[32m[0511 09:18:48 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.17331357300281525, Train Loss: 0.1774616539478302
[32m[0511 09:18:48 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.17331592738628387, Train Loss: 0.1774606555700302
[32m[0511 09:18:48 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.1733182966709137, Train Loss: 0.17745967209339142
[32m[0511 09:18:48 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.1733206957578659, Train Loss: 0.17745870351791382
[32m[0511 09:18:48 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.17332306504249573, Train Loss: 0.17745773494243622
[32m[0511 09:18:48 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.17332544922828674, Train Loss: 0.17745673656463623
[32m[0511 09:18:48 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.17332783341407776, Train Loss: 0.17745578289031982
[32m[0511 09:18:49 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.17333020269870758, Train Loss: 0.17745481431484222
[32m[0511 09:18:49 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.1733325868844986, Train Loss: 0.17745381593704224
[32m[0511 09:18:49 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.17333495616912842, Train Loss: 0.17745287716388702
[32m[0511 09:18:49 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.17333734035491943, Train Loss: 0.17745192348957062
[32m[0511 09:18:49 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.17333970963954926, Train Loss: 0.17745095491409302
[32m[0511 09:18:49 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.17334209382534027, Train Loss: 0.1774500012397766
[32m[0511 09:18:49 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.1733444780111313, Train Loss: 0.1774490624666214
[32m[0511 09:18:49 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.17334683239459991, Train Loss: 0.1774480789899826
[32m[0511 09:18:49 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.17334920167922974, Train Loss: 0.1774471402168274
[32m[0511 09:18:49 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.17335157096385956, Train Loss: 0.177446186542511
[32m[0511 09:18:49 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.17335394024848938, Train Loss: 0.17744526267051697
[32m[0511 09:18:49 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.1733563095331192, Train Loss: 0.17744430899620056
[32m[0511 09:18:49 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.17335867881774902, Train Loss: 0.17744337022304535
[32m[0511 09:18:49 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.17336106300354004, Train Loss: 0.17744241654872894
[32m[0511 09:18:49 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.17336341738700867, Train Loss: 0.17744147777557373
[32m[0511 09:18:49 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.1733657866716385, Train Loss: 0.1774405539035797
[32m[0511 09:18:49 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.17336814105510712, Train Loss: 0.1774396300315857
[32m[0511 09:18:49 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.17337051033973694, Train Loss: 0.17743869125843048
[32m[0511 09:18:49 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.17337287962436676, Train Loss: 0.17743776738643646
[32m[0511 09:18:49 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.17337524890899658, Train Loss: 0.17743685841560364
[32m[0511 09:18:49 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.1733776032924652, Train Loss: 0.17743593454360962
[32m[0511 09:18:49 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.17337995767593384, Train Loss: 0.1774350106716156
[32m[0511 09:18:49 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.17338232696056366, Train Loss: 0.17743410170078278
[32m[0511 09:18:49 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.1733846813440323, Train Loss: 0.17743320763111115
[32m[0511 09:18:50 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.17338703572750092, Train Loss: 0.17743228375911713
[32m[0511 09:18:50 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.17338937520980835, Train Loss: 0.1774313598871231
[32m[0511 09:18:50 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.17339172959327698, Train Loss: 0.17743045091629028
[32m[0511 09:18:50 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.1733940839767456, Train Loss: 0.17742955684661865
[32m[0511 09:18:50 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.17339643836021423, Train Loss: 0.17742867767810822
[32m[0511 09:18:50 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.17339880764484406, Train Loss: 0.177427738904953
[32m[0511 09:18:50 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.1734011322259903, Train Loss: 0.17742685973644257
[32m[0511 09:18:50 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.17340348660945892, Train Loss: 0.17742598056793213
[32m[0511 09:18:50 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.17340582609176636, Train Loss: 0.1774250864982605
[32m[0511 09:18:50 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.17340818047523499, Train Loss: 0.17742419242858887
[32m[0511 09:18:50 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.17341050505638123, Train Loss: 0.17742329835891724
[32m[0511 09:18:50 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.17341284453868866, Train Loss: 0.1774224191904068
[32m[0511 09:18:50 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.17341521382331848, Train Loss: 0.17742154002189636
[32m[0511 09:18:50 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.17341752350330353, Train Loss: 0.17742066085338593
[32m[0511 09:18:50 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.17341986298561096, Train Loss: 0.1774197816848755
[32m[0511 09:18:50 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.1734222173690796, Train Loss: 0.17741890251636505
[32m[0511 09:18:50 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.17342454195022583, Train Loss: 0.17741802334785461
[32m[0511 09:18:50 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.17342688143253326, Train Loss: 0.17741715908050537
[32m[0511 09:18:50 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.1734292060136795, Train Loss: 0.17741627991199493
[32m[0511 09:18:50 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.17343153059482574, Train Loss: 0.1774154156446457
[32m[0511 09:18:50 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.17343385517597198, Train Loss: 0.17741455137729645
[32m[0511 09:18:50 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.1734362095594406, Train Loss: 0.1774137020111084
[32m[0511 09:18:50 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.17343850433826447, Train Loss: 0.17741280794143677
[32m[0511 09:18:50 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.1734408587217331, Train Loss: 0.1774119734764099
[32m[0511 09:18:51 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.17344315350055695, Train Loss: 0.17741112411022186
[32m[0511 09:18:51 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.17344547808170319, Train Loss: 0.17741024494171143
[32m[0511 09:18:51 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.17344780266284943, Train Loss: 0.17740941047668457
[32m[0511 09:18:51 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.17345014214515686, Train Loss: 0.17740857601165771
[32m[0511 09:18:51 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.17345242202281952, Train Loss: 0.17740771174430847
[32m[0511 09:18:51 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.17345476150512695, Train Loss: 0.17740686237812042
[32m[0511 09:18:51 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.173457071185112, Train Loss: 0.17740601301193237
[32m[0511 09:18:51 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.17345936596393585, Train Loss: 0.17740517854690552
[32m[0511 09:18:51 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.1734617054462433, Train Loss: 0.17740434408187866
[32m[0511 09:18:51 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.17346400022506714, Train Loss: 0.1774034947156906
[32m[0511 09:18:51 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.173466295003891, Train Loss: 0.17740267515182495
[32m[0511 09:18:51 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.17346858978271484, Train Loss: 0.1774018406867981
[32m[0511 09:18:51 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.17347091436386108, Train Loss: 0.17740102112293243
[32m[0511 09:18:51 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.17347320914268494, Train Loss: 0.17740020155906677
[32m[0511 09:18:51 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.1734755039215088, Train Loss: 0.17739936709403992
[32m[0511 09:18:51 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.17347778379917145, Train Loss: 0.17739854753017426
[32m[0511 09:18:51 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.1734800785779953, Train Loss: 0.1773977130651474
[32m[0511 09:18:51 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.17348238825798035, Train Loss: 0.17739690840244293
[32m[0511 09:18:51 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.173484668135643, Train Loss: 0.17739608883857727
[32m[0511 09:18:51 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.17348697781562805, Train Loss: 0.17739525437355042
[32m[0511 09:18:51 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.1734892725944519, Train Loss: 0.17739446461200714
[32m[0511 09:18:51 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.17349152266979218, Train Loss: 0.17739363014698029
[32m[0511 09:18:51 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.17349383234977722, Train Loss: 0.177392840385437
[32m[0511 09:18:52 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.17349612712860107, Train Loss: 0.17739205062389374
[32m[0511 09:18:52 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.17349837720394135, Train Loss: 0.17739124596118927
[32m[0511 09:18:52 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.173500657081604, Train Loss: 0.1773904263973236
[32m[0511 09:18:52 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.17350295186042786, Train Loss: 0.17738963663578033
[32m[0511 09:18:52 @mbmf_sampler.py:98][0m Finished 9th episode
[32m[0511 09:18:52 @mbmf_sampler.py:102][0m 1809 timesteps from 9 episodes collected
[32m[0511 09:37:43 @mbmf_trainer.py:160][0m Mean reward: -1226.5573227011066
[32m[0511 09:37:43 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.1845891922712326, Train Loss: 0.17393368482589722
[32m[0511 09:37:44 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.18470971286296844, Train Loss: 0.17389577627182007
[32m[0511 09:37:44 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.1847720444202423, Train Loss: 0.17388096451759338
[32m[0511 09:37:44 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.18481066823005676, Train Loss: 0.1738707721233368
[32m[0511 09:37:44 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.1848457157611847, Train Loss: 0.17386247217655182
[32m[0511 09:37:44 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.18487779796123505, Train Loss: 0.17385552823543549
[32m[0511 09:37:44 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.18490584194660187, Train Loss: 0.17384964227676392
[32m[0511 09:37:44 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.18493013083934784, Train Loss: 0.17384439706802368
[32m[0511 09:37:44 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.18495133519172668, Train Loss: 0.17383970320224762
[32m[0511 09:37:44 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.18497003614902496, Train Loss: 0.17383535206317902
[32m[0511 09:37:44 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.1849866658449173, Train Loss: 0.17383134365081787
[32m[0511 09:37:44 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.18500158190727234, Train Loss: 0.17382755875587463
[32m[0511 09:37:44 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.18501506745815277, Train Loss: 0.1738240122795105
[32m[0511 09:37:44 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.18502742052078247, Train Loss: 0.1738206148147583
[32m[0511 09:37:44 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.185038760304451, Train Loss: 0.17381738126277924
[32m[0511 09:37:44 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.18504931032657623, Train Loss: 0.17381425201892853
[32m[0511 09:37:44 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.18505914509296417, Train Loss: 0.17381125688552856
[32m[0511 09:37:44 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.18506838381290436, Train Loss: 0.17380839586257935
[32m[0511 09:37:44 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.18507713079452515, Train Loss: 0.1738056242465973
[32m[0511 09:37:44 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.18508543074131012, Train Loss: 0.1738029271364212
[32m[0511 09:37:44 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.18509337306022644, Train Loss: 0.17380033433437347
[32m[0511 09:37:45 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.1851009577512741, Train Loss: 0.1737978458404541
[32m[0511 09:37:45 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.1851082593202591, Train Loss: 0.1737954020500183
[32m[0511 09:37:45 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.18511530756950378, Train Loss: 0.17379306256771088
[32m[0511 09:37:45 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.18512211740016937, Train Loss: 0.17379075288772583
[32m[0511 09:37:45 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.18512868881225586, Train Loss: 0.17378853261470795
[32m[0511 09:37:45 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.1851350963115692, Train Loss: 0.17378637194633484
[32m[0511 09:37:45 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.18514132499694824, Train Loss: 0.1737842708826065
[32m[0511 09:37:45 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.18514738976955414, Train Loss: 0.17378224432468414
[32m[0511 09:37:45 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.1851533055305481, Train Loss: 0.17378023266792297
[32m[0511 09:37:45 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.1851590871810913, Train Loss: 0.17377828061580658
[32m[0511 09:37:45 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.18516471982002258, Train Loss: 0.17377640306949615
[32m[0511 09:37:45 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.1851702481508255, Train Loss: 0.1737745702266693
[32m[0511 09:37:45 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.18517562747001648, Train Loss: 0.17377275228500366
[32m[0511 09:37:45 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.18518094718456268, Train Loss: 0.1737709939479828
[32m[0511 09:37:45 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.18518611788749695, Train Loss: 0.1737692952156067
[32m[0511 09:37:45 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.18519116938114166, Train Loss: 0.1737675815820694
[32m[0511 09:37:45 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.1851961463689804, Train Loss: 0.17376597225666046
[32m[0511 09:37:45 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.18520104885101318, Train Loss: 0.17376436293125153
[32m[0511 09:37:45 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.1852058470249176, Train Loss: 0.17376278340816498
[32m[0511 09:37:45 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.18521054089069366, Train Loss: 0.17376123368740082
[32m[0511 09:37:46 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.18521519005298615, Train Loss: 0.17375974357128143
[32m[0511 09:37:46 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.18521973490715027, Train Loss: 0.17375823855400085
[32m[0511 09:37:46 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.18522417545318604, Train Loss: 0.17375679314136505
[32m[0511 09:37:46 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.18522855639457703, Train Loss: 0.17375536262989044
[32m[0511 09:37:46 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.18523286283016205, Train Loss: 0.17375397682189941
[32m[0511 09:37:46 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.1852371245622635, Train Loss: 0.17375260591506958
[32m[0511 09:37:46 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.18524126708507538, Train Loss: 0.17375127971172333
[32m[0511 09:37:46 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.1852453500032425, Train Loss: 0.17374993860721588
[32m[0511 09:37:46 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.1852494180202484, Train Loss: 0.17374864220619202
[32m[0511 09:37:46 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.1852533519268036, Train Loss: 0.17374739050865173
[32m[0511 09:37:46 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.18525724112987518, Train Loss: 0.17374612390995026
[32m[0511 09:37:46 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.1852611005306244, Train Loss: 0.17374490201473236
[32m[0511 09:37:46 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.18526485562324524, Train Loss: 0.17374368011951447
[32m[0511 09:37:46 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.1852685660123825, Train Loss: 0.17374247312545776
[32m[0511 09:37:46 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.1852722465991974, Train Loss: 0.17374132573604584
[32m[0511 09:37:46 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.1852758228778839, Train Loss: 0.17374016344547272
[32m[0511 09:37:46 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.18527936935424805, Train Loss: 0.1737390160560608
[32m[0511 09:37:46 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.1852828711271286, Train Loss: 0.17373789846897125
[32m[0511 09:37:46 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.18528629839420319, Train Loss: 0.17373676598072052
[32m[0511 09:37:46 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.1852896809577942, Train Loss: 0.17373567819595337
[32m[0511 09:37:46 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.18529300391674042, Train Loss: 0.1737346053123474
[32m[0511 09:37:47 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.18529629707336426, Train Loss: 0.17373354732990265
[32m[0511 09:37:47 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.18529953062534332, Train Loss: 0.17373250424861908
[32m[0511 09:37:47 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.1853027045726776, Train Loss: 0.1737314611673355
[32m[0511 09:37:47 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.18530584871768951, Train Loss: 0.17373043298721313
[32m[0511 09:37:47 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.18530894815921783, Train Loss: 0.17372943460941315
[32m[0511 09:37:47 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.18531198799610138, Train Loss: 0.17372845113277435
[32m[0511 09:37:47 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.18531499803066254, Train Loss: 0.17372745275497437
[32m[0511 09:37:47 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.1853179633617401, Train Loss: 0.17372649908065796
[32m[0511 09:37:47 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.1853208839893341, Train Loss: 0.17372553050518036
[32m[0511 09:37:47 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.18532373011112213, Train Loss: 0.17372456192970276
[32m[0511 09:37:47 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.18532659113407135, Train Loss: 0.17372363805770874
[32m[0511 09:37:47 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.1853293627500534, Train Loss: 0.17372269928455353
[32m[0511 09:37:47 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.18533211946487427, Train Loss: 0.1737217754125595
[32m[0511 09:37:47 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.18533484637737274, Train Loss: 0.17372088134288788
[32m[0511 09:37:47 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.18533752858638763, Train Loss: 0.17371997237205505
[32m[0511 09:37:47 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.18534016609191895, Train Loss: 0.17371906340122223
[32m[0511 09:37:47 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.18534275889396667, Train Loss: 0.17371819913387299
[32m[0511 09:37:47 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.1853453367948532, Train Loss: 0.17371731996536255
[32m[0511 09:37:47 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.18534788489341736, Train Loss: 0.1737164407968521
[32m[0511 09:37:47 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.18535038828849792, Train Loss: 0.17371559143066406
[32m[0511 09:37:48 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.1853528618812561, Train Loss: 0.1737147718667984
[32m[0511 09:37:48 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.1853552758693695, Train Loss: 0.17371392250061035
[32m[0511 09:37:48 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.1853576898574829, Train Loss: 0.1737131029367447
[32m[0511 09:37:48 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.18536007404327393, Train Loss: 0.17371226847171783
[32m[0511 09:37:48 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.18536239862442017, Train Loss: 0.17371146380901337
[32m[0511 09:37:48 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.1853647083044052, Train Loss: 0.1737106293439865
[32m[0511 09:37:48 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.18536698818206787, Train Loss: 0.17370983958244324
[32m[0511 09:37:48 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.18536923825740814, Train Loss: 0.17370903491973877
[32m[0511 09:37:48 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.1853714883327484, Train Loss: 0.1737082451581955
[32m[0511 09:37:48 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.18537366390228271, Train Loss: 0.17370745539665222
[32m[0511 09:37:48 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.18537583947181702, Train Loss: 0.17370668053627014
[32m[0511 09:37:48 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.18537797033786774, Train Loss: 0.17370590567588806
[32m[0511 09:37:48 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.18538008630275726, Train Loss: 0.17370514571666718
[32m[0511 09:37:48 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.1853821724653244, Train Loss: 0.1737043708562851
[32m[0511 09:37:48 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.18538424372673035, Train Loss: 0.1737036257982254
[32m[0511 09:37:48 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.18538625538349152, Train Loss: 0.1737028807401657
[32m[0511 09:37:48 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.18538828194141388, Train Loss: 0.17370213568210602
[32m[0511 09:37:48 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.18539026379585266, Train Loss: 0.17370139062404633
[32m[0511 09:37:48 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.18539220094680786, Train Loss: 0.17370067536830902
[32m[0511 09:37:48 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.18539415299892426, Train Loss: 0.17369994521141052
[32m[0511 09:37:49 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.18539604544639587, Train Loss: 0.17369921505451202
[32m[0511 09:37:49 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.1853979527950287, Train Loss: 0.17369848489761353
[32m[0511 09:37:49 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.18539981544017792, Train Loss: 0.17369778454303741
[32m[0511 09:37:49 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.18540167808532715, Train Loss: 0.1736970692873001
[32m[0511 09:37:49 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.1854034960269928, Train Loss: 0.173696368932724
[32m[0511 09:37:49 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.18540529906749725, Train Loss: 0.1736956685781479
[32m[0511 09:37:49 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.18540705740451813, Train Loss: 0.17369498312473297
[32m[0511 09:37:49 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.1854088455438614, Train Loss: 0.17369426786899567
[32m[0511 09:37:49 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.18541057407855988, Train Loss: 0.17369358241558075
[32m[0511 09:37:49 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.18541231751441956, Train Loss: 0.17369291186332703
[32m[0511 09:37:49 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.18541398644447327, Train Loss: 0.17369221150875092
[32m[0511 09:37:49 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.18541567027568817, Train Loss: 0.17369157075881958
[32m[0511 09:37:49 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.18541735410690308, Train Loss: 0.17369087040424347
[32m[0511 09:37:49 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.1854189932346344, Train Loss: 0.17369021475315094
[32m[0511 09:37:49 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.18542060256004333, Train Loss: 0.17368954420089722
[32m[0511 09:37:49 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.18542221188545227, Train Loss: 0.1736888736486435
[32m[0511 09:37:49 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.1854238063097, Train Loss: 0.17368823289871216
[32m[0511 09:37:49 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.18542535603046417, Train Loss: 0.17368759214878082
[32m[0511 09:37:49 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.18542690575122833, Train Loss: 0.1736869215965271
[32m[0511 09:37:49 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.1854284405708313, Train Loss: 0.17368628084659576
[32m[0511 09:37:50 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.18542996048927307, Train Loss: 0.17368564009666443
[32m[0511 09:37:50 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.18543148040771484, Train Loss: 0.1736849844455719
[32m[0511 09:37:50 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.18543295562267303, Train Loss: 0.17368435859680176
[32m[0511 09:37:50 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.18543443083763123, Train Loss: 0.17368371784687042
[32m[0511 09:37:50 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.18543587625026703, Train Loss: 0.17368309199810028
[32m[0511 09:37:50 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.18543732166290283, Train Loss: 0.17368246614933014
[32m[0511 09:37:50 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.18543873727321625, Train Loss: 0.17368184030056
[32m[0511 09:37:50 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.18544016778469086, Train Loss: 0.17368119955062866
[32m[0511 09:37:50 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.1854415386915207, Train Loss: 0.17368057370185852
[32m[0511 09:37:50 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.18544290959835052, Train Loss: 0.17367996275424957
[32m[0511 09:37:50 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.18544428050518036, Train Loss: 0.17367936670780182
[32m[0511 09:37:50 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.1854456216096878, Train Loss: 0.17367874085903168
[32m[0511 09:37:50 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.18544697761535645, Train Loss: 0.17367814481258392
[32m[0511 09:37:50 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.1854482889175415, Train Loss: 0.17367753386497498
[32m[0511 09:37:50 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.18544961512088776, Train Loss: 0.17367690801620483
[32m[0511 09:37:50 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.18545086681842804, Train Loss: 0.17367632687091827
[32m[0511 09:37:50 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.1854521781206131, Train Loss: 0.17367571592330933
[32m[0511 09:37:50 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.18545342981815338, Train Loss: 0.17367511987686157
[32m[0511 09:37:50 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.18545469641685486, Train Loss: 0.17367452383041382
[32m[0511 09:37:50 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.18545594811439514, Train Loss: 0.17367391288280487
[32m[0511 09:37:50 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.18545715510845184, Train Loss: 0.1736733317375183
[32m[0511 09:37:51 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.18545837700366974, Train Loss: 0.17367273569107056
[32m[0511 09:37:51 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.18545959889888763, Train Loss: 0.17367218434810638
[32m[0511 09:37:51 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.18546079099178314, Train Loss: 0.17367158830165863
[32m[0511 09:37:51 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.18546195328235626, Train Loss: 0.17367099225521088
[32m[0511 09:37:51 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.18546314537525177, Train Loss: 0.1736704260110855
[32m[0511 09:37:51 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.1854643076658249, Train Loss: 0.17366984486579895
[32m[0511 09:37:51 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.18546545505523682, Train Loss: 0.1736692637205124
[32m[0511 09:37:51 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.18546658754348755, Train Loss: 0.17366866767406464
[32m[0511 09:37:51 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.18546773493289948, Train Loss: 0.17366813123226166
[32m[0511 09:37:51 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.185468852519989, Train Loss: 0.1736675649881363
[32m[0511 09:37:51 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.18546992540359497, Train Loss: 0.17366698384284973
[32m[0511 09:37:51 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.1854710429906845, Train Loss: 0.17366640269756317
[32m[0511 09:37:51 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.18547216057777405, Train Loss: 0.1736658662557602
[32m[0511 09:37:51 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.1854732185602188, Train Loss: 0.17366528511047363
[32m[0511 09:37:51 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.18547427654266357, Train Loss: 0.17366471886634827
[32m[0511 09:37:51 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.18547534942626953, Train Loss: 0.1736641675233841
[32m[0511 09:37:51 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.1854763925075531, Train Loss: 0.17366360127925873
[32m[0511 09:37:51 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.18547743558883667, Train Loss: 0.17366303503513336
[32m[0511 09:37:51 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.18547844886779785, Train Loss: 0.17366249859333038
[32m[0511 09:37:51 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.18547947704792023, Train Loss: 0.17366193234920502
[32m[0511 09:37:51 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.1854804903268814, Train Loss: 0.17366139590740204
[32m[0511 09:37:52 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.1854814887046814, Train Loss: 0.17366084456443787
[32m[0511 09:37:52 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.18548248708248138, Train Loss: 0.1736602932214737
[32m[0511 09:37:52 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.18548347055912018, Train Loss: 0.17365974187850952
[32m[0511 09:37:52 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.18548445403575897, Train Loss: 0.17365922033786774
[32m[0511 09:37:52 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.18548542261123657, Train Loss: 0.17365866899490356
[32m[0511 09:37:52 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.18548637628555298, Train Loss: 0.17365813255310059
[32m[0511 09:37:52 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.18548732995986938, Train Loss: 0.1736575812101364
[32m[0511 09:37:52 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.1854882836341858, Train Loss: 0.17365704476833344
[32m[0511 09:37:52 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.1854892075061798, Train Loss: 0.17365650832653046
[32m[0511 09:37:52 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.18549013137817383, Train Loss: 0.17365598678588867
[32m[0511 09:37:52 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.18549104034900665, Train Loss: 0.1736554354429245
[32m[0511 09:37:52 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.18549197912216187, Train Loss: 0.17365489900112152
[32m[0511 09:37:52 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.1854928880929947, Train Loss: 0.17365436255931854
[32m[0511 09:37:52 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.18549378216266632, Train Loss: 0.17365382611751556
[32m[0511 09:37:52 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.18549467623233795, Train Loss: 0.17365331947803497
[32m[0511 09:37:52 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.18549557030200958, Train Loss: 0.173652783036232
[32m[0511 09:37:52 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.18549641966819763, Train Loss: 0.17365224659442902
[32m[0511 09:37:52 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.18549728393554688, Train Loss: 0.17365172505378723
[32m[0511 09:37:52 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.1854981780052185, Train Loss: 0.17365123331546783
[32m[0511 09:37:52 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.18549902737140656, Train Loss: 0.17365069687366486
[32m[0511 09:37:53 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.1854998618364334, Train Loss: 0.17365017533302307
[32m[0511 09:37:53 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.18550072610378265, Train Loss: 0.1736496537923813
[32m[0511 09:37:53 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.18550154566764832, Train Loss: 0.1736491322517395
[32m[0511 09:37:53 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.18550238013267517, Train Loss: 0.17364861071109772
[32m[0511 09:37:53 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.18550319969654083, Train Loss: 0.17364808917045593
[32m[0511 09:37:53 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.1855040192604065, Train Loss: 0.17364756762981415
[32m[0511 09:37:53 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.18550483882427216, Train Loss: 0.17364704608917236
[32m[0511 09:37:53 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.18550564348697662, Train Loss: 0.17364653944969177
[32m[0511 09:37:53 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.1855064332485199, Train Loss: 0.17364603281021118
[32m[0511 09:37:53 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.18550723791122437, Train Loss: 0.1736455112695694
[32m[0511 09:37:53 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.18550801277160645, Train Loss: 0.1736450046300888
[32m[0511 09:37:53 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.18550880253314972, Train Loss: 0.1736445128917694
[32m[0511 09:37:53 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.1855095773935318, Train Loss: 0.17364397644996643
[32m[0511 09:37:53 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.18551033735275269, Train Loss: 0.17364351451396942
[32m[0511 09:37:53 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.18551111221313477, Train Loss: 0.17364299297332764
[32m[0511 09:37:53 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.18551187217235565, Train Loss: 0.17364250123500824
[32m[0511 09:37:53 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.18551261723041534, Train Loss: 0.17364197969436646
[32m[0511 09:37:53 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.18551337718963623, Train Loss: 0.17364147305488586
[32m[0511 09:37:53 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.18551412224769592, Train Loss: 0.17364098131656647
[32m[0511 09:37:53 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.18551486730575562, Train Loss: 0.17364047467708588
[32m[0511 09:37:54 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.18551558256149292, Train Loss: 0.17363998293876648
[32m[0511 09:37:54 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.18551631271839142, Train Loss: 0.1736394762992859
[32m[0511 09:37:54 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.18551702797412872, Train Loss: 0.1736389696598053
[32m[0511 09:37:54 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.18551775813102722, Train Loss: 0.1736385077238083
[32m[0511 09:37:54 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.18551847338676453, Train Loss: 0.1736380010843277
[32m[0511 09:37:54 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.18551914393901825, Train Loss: 0.1736374944448471
[32m[0511 09:37:54 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.18551985919475555, Train Loss: 0.1736370176076889
[32m[0511 09:37:54 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.18552055954933167, Train Loss: 0.1736365258693695
[32m[0511 09:37:54 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.18552125990390778, Train Loss: 0.17363600432872772
[32m[0511 09:37:54 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.1855219602584839, Train Loss: 0.17363552749156952
[32m[0511 09:37:54 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.1855226308107376, Train Loss: 0.17363503575325012
[32m[0511 09:37:54 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.18552330136299133, Train Loss: 0.17363455891609192
[32m[0511 09:37:54 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.18552398681640625, Train Loss: 0.17363406717777252
[32m[0511 09:37:54 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.18552464246749878, Train Loss: 0.17363359034061432
[32m[0511 09:37:54 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.1855253279209137, Train Loss: 0.17363309860229492
[32m[0511 09:37:54 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.18552596867084503, Train Loss: 0.17363260686397552
[32m[0511 09:37:54 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.18552663922309875, Train Loss: 0.17363213002681732
[32m[0511 09:37:54 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.1855272650718689, Train Loss: 0.17363163828849792
[32m[0511 09:37:54 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.18552793562412262, Train Loss: 0.17363113164901733
[32m[0511 09:37:54 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.18552856147289276, Train Loss: 0.1736306995153427
[32m[0511 09:37:54 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.1855292171239853, Train Loss: 0.17363019287586212
[32m[0511 09:37:55 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.18552985787391663, Train Loss: 0.17362970113754272
[32m[0511 09:37:55 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.18553046882152557, Train Loss: 0.17362922430038452
[32m[0511 09:37:55 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.1855311244726181, Train Loss: 0.17362874746322632
[32m[0511 09:37:55 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.18553172051906586, Train Loss: 0.17362827062606812
[32m[0511 09:37:55 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.185532346367836, Train Loss: 0.17362777888774872
[32m[0511 09:37:55 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.18553295731544495, Train Loss: 0.1736273169517517
[32m[0511 09:37:55 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.1855335831642151, Train Loss: 0.1736268401145935
[32m[0511 09:37:55 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.18553416430950165, Train Loss: 0.1736263632774353
[32m[0511 09:37:55 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.1855347752571106, Train Loss: 0.1736258864402771
[32m[0511 09:37:55 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.18553537130355835, Train Loss: 0.1736254096031189
[32m[0511 09:37:55 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.1855359673500061, Train Loss: 0.1736249327659607
[32m[0511 09:37:55 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.18553654849529266, Train Loss: 0.17362448573112488
[32m[0511 09:37:55 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.18553714454174042, Train Loss: 0.1736239790916443
[32m[0511 09:37:55 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.18553772568702698, Train Loss: 0.17362351715564728
[32m[0511 09:37:55 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.18553832173347473, Train Loss: 0.17362307012081146
[32m[0511 09:37:55 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.1855388730764389, Train Loss: 0.17362259328365326
[32m[0511 09:37:55 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.18553946912288666, Train Loss: 0.17362211644649506
[32m[0511 09:37:55 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.18554003536701202, Train Loss: 0.17362163960933685
[32m[0511 09:37:55 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.1855406016111374, Train Loss: 0.17362116277217865
[32m[0511 09:37:55 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.18554116785526276, Train Loss: 0.17362071573734283
[32m[0511 09:37:56 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.18554171919822693, Train Loss: 0.17362023890018463
[32m[0511 09:37:56 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.1855422854423523, Train Loss: 0.17361977696418762
[32m[0511 09:37:56 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.18554285168647766, Train Loss: 0.1736193299293518
[32m[0511 09:37:56 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.18554337322711945, Train Loss: 0.1736188530921936
[32m[0511 09:37:56 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.18554392457008362, Train Loss: 0.1736183762550354
[32m[0511 09:37:56 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.1855444610118866, Train Loss: 0.17361792922019958
[32m[0511 09:37:56 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.18554501235485077, Train Loss: 0.17361745238304138
[32m[0511 09:37:56 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.18554554879665375, Train Loss: 0.17361699044704437
[32m[0511 09:37:56 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.18554607033729553, Train Loss: 0.17361652851104736
[32m[0511 09:37:56 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.1855466216802597, Train Loss: 0.17361606657505035
[32m[0511 09:37:56 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.1855471134185791, Train Loss: 0.17361560463905334
[32m[0511 09:37:56 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.1855476349592209, Train Loss: 0.17361514270305634
[32m[0511 09:37:56 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.18554817140102386, Train Loss: 0.17361468076705933
[32m[0511 09:37:56 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.18554869294166565, Train Loss: 0.17361421883106232
[32m[0511 09:37:56 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.18554919958114624, Train Loss: 0.1736137568950653
[32m[0511 09:37:56 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.18554972112178802, Train Loss: 0.1736132949590683
[32m[0511 09:37:56 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.1855502426624298, Train Loss: 0.17361284792423248
[32m[0511 09:37:56 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.1855507344007492, Train Loss: 0.17361237108707428
[32m[0511 09:37:56 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.185551255941391, Train Loss: 0.17361193895339966
[32m[0511 09:37:56 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.18555176258087158, Train Loss: 0.17361147701740265
[32m[0511 09:37:57 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.18555223941802979, Train Loss: 0.17361102998256683
[32m[0511 09:37:57 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.18555273115634918, Train Loss: 0.17361056804656982
[32m[0511 09:37:57 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.18555323779582977, Train Loss: 0.17361010611057281
[32m[0511 09:37:57 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.18555371463298798, Train Loss: 0.1736096441745758
[32m[0511 09:37:57 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.18555420637130737, Train Loss: 0.17360919713974
[32m[0511 09:37:57 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.18555468320846558, Train Loss: 0.17360876500606537
[32m[0511 09:37:57 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.18555516004562378, Train Loss: 0.17360830307006836
[32m[0511 09:37:57 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.18555565178394318, Train Loss: 0.17360784113407135
[32m[0511 09:37:57 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.18555611371994019, Train Loss: 0.17360739409923553
[32m[0511 09:37:57 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.1855565905570984, Train Loss: 0.1736069619655609
[32m[0511 09:37:57 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.18555708229541779, Train Loss: 0.1736065000295639
[32m[0511 09:37:57 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.1855575293302536, Train Loss: 0.1736060529947281
[32m[0511 09:37:57 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.1855579912662506, Train Loss: 0.17360559105873108
[32m[0511 09:37:57 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.1855584681034088, Train Loss: 0.17360514402389526
[32m[0511 09:37:57 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.18555894494056702, Train Loss: 0.17360471189022064
[32m[0511 09:37:57 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.18555940687656403, Train Loss: 0.17360424995422363
[32m[0511 09:37:57 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.18555983901023865, Train Loss: 0.17360378801822662
[32m[0511 09:37:57 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.18556030094623566, Train Loss: 0.1736033707857132
[32m[0511 09:37:57 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.18556071817874908, Train Loss: 0.17360292375087738
[32m[0511 09:37:57 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.1855611801147461, Train Loss: 0.17360247671604156
[32m[0511 09:37:58 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.1855616420507431, Train Loss: 0.17360202968120575
[32m[0511 09:37:58 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.1855621039867401, Train Loss: 0.17360158264636993
[32m[0511 09:37:58 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.18556252121925354, Train Loss: 0.17360113561153412
[32m[0511 09:37:58 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.18556295335292816, Train Loss: 0.1736006885766983
[32m[0511 09:37:58 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.18556340038776398, Train Loss: 0.17360025644302368
[32m[0511 09:37:58 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.1855638474225998, Train Loss: 0.17359977960586548
[32m[0511 09:37:58 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.18556426465511322, Train Loss: 0.17359934747219086
[32m[0511 09:37:58 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.18556471168994904, Train Loss: 0.17359890043735504
[32m[0511 09:37:58 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.18556512892246246, Train Loss: 0.1735984832048416
[32m[0511 09:37:58 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.1855655461549759, Train Loss: 0.1735980361700058
[32m[0511 09:37:58 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.1855659782886505, Train Loss: 0.17359758913516998
[32m[0511 09:37:58 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.18556641042232513, Train Loss: 0.17359714210033417
[32m[0511 09:37:58 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.18556682765483856, Train Loss: 0.17359668016433716
[32m[0511 09:37:58 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.185567244887352, Train Loss: 0.17359626293182373
[32m[0511 09:37:58 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.18556766211986542, Train Loss: 0.1735958307981491
[32m[0511 09:37:58 @mbmf_main.py:224][0m batch size for trpo is 1000
[32m[0511 09:37:58 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 09:37:58 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 09:37:58 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 09:37:58 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 09:37:58 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 09:37:58 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 09:37:58 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 09:37:58 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 09:37:58 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 09:37:58 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 09:37:58 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 09:37:58 @mbmf_main.py:132][0m Training starts at /root/mbbl
[32m[0511 09:37:58 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 09:37:58 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 09:37:58 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 09:37:58 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 09:37:58 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 09:37:58 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 09:37:58 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 09:37:58 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 09:37:58 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 09:37:58 @base_worker.py:45][0m Worker 0 online
[32m[0511 09:37:58 @base_worker.py:45][0m Worker 1 online
[32m[0511 09:37:58 @base_worker.py:45][0m Worker 2 online
[32m[0511 09:37:58 @base_worker.py:45][0m Worker 3 online
[32m[0511 09:37:58 @base_worker.py:45][0m Worker 4 online
[32m[0511 09:37:58 @base_worker.py:45][0m Worker 5 online
[32m[0511 09:37:58 @base_worker.py:45][0m Worker 6 online
[32m[0511 09:37:58 @base_worker.py:45][0m Worker 7 online
[32m[0511 09:37:58 @base_worker.py:45][0m Worker 8 online
[32m[0511 09:37:58 @base_worker.py:45][0m Worker 9 online
[32m[0511 09:37:58 @base_worker.py:45][0m Worker 10 online
[32m[0511 09:37:58 @base_worker.py:45][0m Worker 11 online
[32m[0511 09:37:58 @base_worker.py:45][0m Worker 12 online
[32m[0511 09:37:58 @base_worker.py:45][0m Worker 13 online
[32m[0511 09:37:58 @base_worker.py:45][0m Worker 14 online
[32m[0511 09:37:58 @base_worker.py:45][0m Worker 15 online
[32m[0511 09:37:58 @base_worker.py:45][0m Worker 16 online
[32m[0511 09:37:58 @base_worker.py:45][0m Worker 17 online
[32m[0511 09:37:58 @base_worker.py:45][0m Worker 18 online
[32m[0511 09:37:58 @base_worker.py:45][0m Worker 19 online
[32m[0511 09:37:59 @base_trainer.py:152][0m Trainer maintains [1] policy network
[32m[0511 09:37:59 @base_trainer.py:152][0m Trainer maintains [1] dynamics network
[32m[0511 09:37:59 @base_trainer.py:152][0m Trainer maintains [1] reward network
[32m[0511 09:37:59 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:37:59 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:37:59 @base_trainer.py:216][0m Mean reward: -1157.8225227812554
[32m[0511 09:38:00 @base_main.py:38][0m --------------- Iteration 1 ---------------
[32m[0511 09:38:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0000 mins
[32m[0511 09:38:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0029 mins
[32m[0511 09:38:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0148 mins
[32m[0511 09:38:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:00 @base_main.py:47][0m 1005 total steps have happened
[32m[0511 09:38:00 @base_main.py:52][0m [avg_reward]: -1157.8225227812554
[32m[0511 09:38:00 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:00 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:00 @base_trainer.py:216][0m Mean reward: -1121.3223440016168
[32m[0511 09:38:01 @base_main.py:38][0m --------------- Iteration 2 ---------------
[32m[0511 09:38:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0178 mins
[32m[0511 09:38:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0511 09:38:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 09:38:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:01 @base_main.py:47][0m 2010 total steps have happened
[32m[0511 09:38:01 @base_main.py:52][0m [avg_reward]: -1121.3223440016168
[32m[0511 09:38:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:01 @base_trainer.py:216][0m Mean reward: -1131.3977285907256
[32m[0511 09:38:02 @base_main.py:38][0m --------------- Iteration 3 ---------------
[32m[0511 09:38:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0308 mins
[32m[0511 09:38:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0511 09:38:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 09:38:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0511 09:38:02 @base_main.py:47][0m 3015 total steps have happened
[32m[0511 09:38:02 @base_main.py:52][0m [avg_reward]: -1131.3977285907256
[32m[0511 09:38:02 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:02 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:02 @base_trainer.py:216][0m Mean reward: -1104.6932153671264
[32m[0511 09:38:03 @base_main.py:38][0m --------------- Iteration 4 ---------------
[32m[0511 09:38:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0439 mins
[32m[0511 09:38:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0511 09:38:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 09:38:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:03 @base_main.py:47][0m 4020 total steps have happened
[32m[0511 09:38:03 @base_main.py:52][0m [avg_reward]: -1104.6932153671264
[32m[0511 09:38:03 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:03 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:03 @base_trainer.py:216][0m Mean reward: -1090.9797208908612
[32m[0511 09:38:03 @base_main.py:38][0m --------------- Iteration 5 ---------------
[32m[0511 09:38:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0568 mins
[32m[0511 09:38:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 09:38:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 09:38:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:03 @base_main.py:47][0m 5025 total steps have happened
[32m[0511 09:38:03 @base_main.py:52][0m [avg_reward]: -1090.9797208908612
[32m[0511 09:38:03 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:03 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:03 @base_trainer.py:216][0m Mean reward: -1167.144176552193
[32m[0511 09:38:04 @base_main.py:38][0m --------------- Iteration 6 ---------------
[32m[0511 09:38:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0696 mins
[32m[0511 09:38:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 09:38:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 09:38:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:04 @base_main.py:47][0m 6030 total steps have happened
[32m[0511 09:38:04 @base_main.py:52][0m [avg_reward]: -1167.144176552193
[32m[0511 09:38:04 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:04 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:04 @base_trainer.py:216][0m Mean reward: -1433.5624541453788
[32m[0511 09:38:05 @base_main.py:38][0m --------------- Iteration 7 ---------------
[32m[0511 09:38:05 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0817 mins
[32m[0511 09:38:05 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 09:38:05 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 09:38:05 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:05 @base_main.py:47][0m 7035 total steps have happened
[32m[0511 09:38:05 @base_main.py:52][0m [avg_reward]: -1433.5624541453788
[32m[0511 09:38:05 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:05 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:05 @base_trainer.py:216][0m Mean reward: -1180.956191862245
[32m[0511 09:38:06 @base_main.py:38][0m --------------- Iteration 8 ---------------
[32m[0511 09:38:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0940 mins
[32m[0511 09:38:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 09:38:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 09:38:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:06 @base_main.py:47][0m 8040 total steps have happened
[32m[0511 09:38:06 @base_main.py:52][0m [avg_reward]: -1180.956191862245
[32m[0511 09:38:06 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:06 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:06 @base_trainer.py:216][0m Mean reward: -1196.8235866972566
[32m[0511 09:38:06 @base_main.py:38][0m --------------- Iteration 9 ---------------
[32m[0511 09:38:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1070 mins
[32m[0511 09:38:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 09:38:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 09:38:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:06 @base_main.py:47][0m 9045 total steps have happened
[32m[0511 09:38:06 @base_main.py:52][0m [avg_reward]: -1196.8235866972566
[32m[0511 09:38:06 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:06 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:06 @base_trainer.py:216][0m Mean reward: -1044.1678008477525
[32m[0511 09:38:07 @base_main.py:38][0m --------------- Iteration 10 ---------------
[32m[0511 09:38:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1188 mins
[32m[0511 09:38:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 09:38:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0511 09:38:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:07 @base_main.py:47][0m 10050 total steps have happened
[32m[0511 09:38:07 @base_main.py:52][0m [avg_reward]: -1044.1678008477525
[32m[0511 09:38:07 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:07 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:07 @base_trainer.py:216][0m Mean reward: -1084.7251715896502
[32m[0511 09:38:08 @base_main.py:38][0m --------------- Iteration 11 ---------------
[32m[0511 09:38:08 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1304 mins
[32m[0511 09:38:08 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 09:38:08 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 09:38:08 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:08 @base_main.py:47][0m 11055 total steps have happened
[32m[0511 09:38:08 @base_main.py:52][0m [avg_reward]: -1084.7251715896502
[32m[0511 09:38:08 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:08 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:08 @base_trainer.py:216][0m Mean reward: -1252.511224433059
[32m[0511 09:38:08 @base_main.py:38][0m --------------- Iteration 12 ---------------
[32m[0511 09:38:08 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1434 mins
[32m[0511 09:38:08 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 09:38:08 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 09:38:08 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:08 @base_main.py:47][0m 12060 total steps have happened
[32m[0511 09:38:08 @base_main.py:52][0m [avg_reward]: -1252.511224433059
[32m[0511 09:38:09 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:09 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:09 @base_trainer.py:216][0m Mean reward: -1144.993952953521
[32m[0511 09:38:09 @base_main.py:38][0m --------------- Iteration 13 ---------------
[32m[0511 09:38:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1557 mins
[32m[0511 09:38:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 09:38:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 09:38:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:09 @base_main.py:47][0m 13065 total steps have happened
[32m[0511 09:38:09 @base_main.py:52][0m [avg_reward]: -1144.993952953521
[32m[0511 09:38:09 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:09 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:09 @base_trainer.py:216][0m Mean reward: -1139.5820037000797
[32m[0511 09:38:10 @base_main.py:38][0m --------------- Iteration 14 ---------------
[32m[0511 09:38:10 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1684 mins
[32m[0511 09:38:10 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 09:38:10 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 09:38:10 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:10 @base_main.py:47][0m 14070 total steps have happened
[32m[0511 09:38:10 @base_main.py:52][0m [avg_reward]: -1139.5820037000797
[32m[0511 09:38:10 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:10 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:10 @base_trainer.py:216][0m Mean reward: -1279.2217989122032
[32m[0511 09:38:11 @base_main.py:38][0m --------------- Iteration 15 ---------------
[32m[0511 09:38:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1811 mins
[32m[0511 09:38:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 09:38:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 09:38:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:11 @base_main.py:47][0m 15075 total steps have happened
[32m[0511 09:38:11 @base_main.py:52][0m [avg_reward]: -1279.2217989122032
[32m[0511 09:38:11 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:11 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:11 @base_trainer.py:216][0m Mean reward: -1235.4685877240013
[32m[0511 09:38:11 @base_main.py:38][0m --------------- Iteration 16 ---------------
[32m[0511 09:38:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1934 mins
[32m[0511 09:38:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0511 09:38:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 09:38:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:11 @base_main.py:47][0m 16080 total steps have happened
[32m[0511 09:38:11 @base_main.py:52][0m [avg_reward]: -1235.4685877240013
[32m[0511 09:38:12 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:12 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:12 @base_trainer.py:216][0m Mean reward: -1055.0525325204662
[32m[0511 09:38:12 @base_main.py:38][0m --------------- Iteration 17 ---------------
[32m[0511 09:38:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2060 mins
[32m[0511 09:38:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 09:38:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 09:38:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:12 @base_main.py:47][0m 17085 total steps have happened
[32m[0511 09:38:12 @base_main.py:52][0m [avg_reward]: -1055.0525325204662
[32m[0511 09:38:12 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:12 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:12 @base_trainer.py:216][0m Mean reward: -1325.3234638339734
[32m[0511 09:38:13 @base_main.py:38][0m --------------- Iteration 18 ---------------
[32m[0511 09:38:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2189 mins
[32m[0511 09:38:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 09:38:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 09:38:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:13 @base_main.py:47][0m 18090 total steps have happened
[32m[0511 09:38:13 @base_main.py:52][0m [avg_reward]: -1325.3234638339734
[32m[0511 09:38:13 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:13 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:13 @base_trainer.py:216][0m Mean reward: -1124.0627787063327
[32m[0511 09:38:14 @base_main.py:38][0m --------------- Iteration 19 ---------------
[32m[0511 09:38:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2314 mins
[32m[0511 09:38:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0018 mins
[32m[0511 09:38:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 09:38:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:14 @base_main.py:47][0m 19095 total steps have happened
[32m[0511 09:38:14 @base_main.py:52][0m [avg_reward]: -1124.0627787063327
[32m[0511 09:38:14 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:14 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:14 @base_trainer.py:216][0m Mean reward: -1154.7509898504375
[32m[0511 09:38:14 @base_main.py:38][0m --------------- Iteration 20 ---------------
[32m[0511 09:38:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2434 mins
[32m[0511 09:38:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 09:38:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 09:38:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:14 @base_main.py:47][0m 20100 total steps have happened
[32m[0511 09:38:14 @base_main.py:52][0m [avg_reward]: -1154.7509898504375
[32m[0511 09:38:15 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:15 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:15 @base_trainer.py:216][0m Mean reward: -1126.5563142058347
[32m[0511 09:38:15 @base_main.py:38][0m --------------- Iteration 21 ---------------
[32m[0511 09:38:15 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2559 mins
[32m[0511 09:38:15 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 09:38:15 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 09:38:15 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:15 @base_main.py:47][0m 21105 total steps have happened
[32m[0511 09:38:15 @base_main.py:52][0m [avg_reward]: -1126.5563142058347
[32m[0511 09:38:15 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:15 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:15 @base_trainer.py:216][0m Mean reward: -1057.0852444815455
[32m[0511 09:38:16 @base_main.py:38][0m --------------- Iteration 22 ---------------
[32m[0511 09:38:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2679 mins
[32m[0511 09:38:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 09:38:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 09:38:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:16 @base_main.py:47][0m 22110 total steps have happened
[32m[0511 09:38:16 @base_main.py:52][0m [avg_reward]: -1057.0852444815455
[32m[0511 09:38:16 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:16 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:16 @base_trainer.py:216][0m Mean reward: -950.3624659538407
[32m[0511 09:38:17 @base_main.py:38][0m --------------- Iteration 23 ---------------
[32m[0511 09:38:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2800 mins
[32m[0511 09:38:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 09:38:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0511 09:38:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:17 @base_main.py:47][0m 23115 total steps have happened
[32m[0511 09:38:17 @base_main.py:52][0m [avg_reward]: -950.3624659538407
[32m[0511 09:38:17 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:17 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:17 @base_trainer.py:216][0m Mean reward: -1052.3777473289763
[32m[0511 09:38:17 @base_main.py:38][0m --------------- Iteration 24 ---------------
[32m[0511 09:38:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2916 mins
[32m[0511 09:38:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 09:38:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 09:38:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:17 @base_main.py:47][0m 24120 total steps have happened
[32m[0511 09:38:17 @base_main.py:52][0m [avg_reward]: -1052.3777473289763
[32m[0511 09:38:18 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:18 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:18 @base_trainer.py:216][0m Mean reward: -1168.886327360948
[32m[0511 09:38:18 @base_main.py:38][0m --------------- Iteration 25 ---------------
[32m[0511 09:38:18 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3041 mins
[32m[0511 09:38:18 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 09:38:18 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 09:38:18 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:18 @base_main.py:47][0m 25125 total steps have happened
[32m[0511 09:38:18 @base_main.py:52][0m [avg_reward]: -1168.886327360948
[32m[0511 09:38:18 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:18 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:18 @base_trainer.py:216][0m Mean reward: -911.0979398913116
[32m[0511 09:38:19 @base_main.py:38][0m --------------- Iteration 26 ---------------
[32m[0511 09:38:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3169 mins
[32m[0511 09:38:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 09:38:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 09:38:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:19 @base_main.py:47][0m 26130 total steps have happened
[32m[0511 09:38:19 @base_main.py:52][0m [avg_reward]: -911.0979398913116
[32m[0511 09:38:19 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:19 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:19 @base_trainer.py:216][0m Mean reward: -1246.2498031466898
[32m[0511 09:38:20 @base_main.py:38][0m --------------- Iteration 27 ---------------
[32m[0511 09:38:20 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3290 mins
[32m[0511 09:38:20 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 09:38:20 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 09:38:20 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:20 @base_main.py:47][0m 27135 total steps have happened
[32m[0511 09:38:20 @base_main.py:52][0m [avg_reward]: -1246.2498031466898
[32m[0511 09:38:20 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:20 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:20 @base_trainer.py:216][0m Mean reward: -1151.5734873665865
[32m[0511 09:38:20 @base_main.py:38][0m --------------- Iteration 28 ---------------
[32m[0511 09:38:20 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3414 mins
[32m[0511 09:38:20 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 09:38:20 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 09:38:20 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0511 09:38:20 @base_main.py:47][0m 28140 total steps have happened
[32m[0511 09:38:20 @base_main.py:52][0m [avg_reward]: -1151.5734873665865
[32m[0511 09:38:20 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:20 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:20 @base_trainer.py:216][0m Mean reward: -1043.2975598052883
[32m[0511 09:38:21 @base_main.py:38][0m --------------- Iteration 29 ---------------
[32m[0511 09:38:21 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3537 mins
[32m[0511 09:38:21 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0018 mins
[32m[0511 09:38:21 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 09:38:21 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:21 @base_main.py:47][0m 29145 total steps have happened
[32m[0511 09:38:21 @base_main.py:52][0m [avg_reward]: -1043.2975598052883
[32m[0511 09:38:21 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:21 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:21 @base_trainer.py:216][0m Mean reward: -1041.9098867222406
[32m[0511 09:38:22 @base_main.py:38][0m --------------- Iteration 30 ---------------
[32m[0511 09:38:22 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3659 mins
[32m[0511 09:38:22 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 09:38:22 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 09:38:22 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:22 @base_main.py:47][0m 30150 total steps have happened
[32m[0511 09:38:22 @base_main.py:52][0m [avg_reward]: -1041.9098867222406
[32m[0511 09:38:22 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:22 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:22 @base_trainer.py:216][0m Mean reward: -1102.6392613493415
[32m[0511 09:38:23 @base_main.py:38][0m --------------- Iteration 31 ---------------
[32m[0511 09:38:23 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3784 mins
[32m[0511 09:38:23 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0511 09:38:23 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 09:38:23 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:23 @base_main.py:47][0m 31155 total steps have happened
[32m[0511 09:38:23 @base_main.py:52][0m [avg_reward]: -1102.6392613493415
[32m[0511 09:38:23 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:23 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:23 @base_trainer.py:216][0m Mean reward: -947.4246000408702
[32m[0511 09:38:23 @base_main.py:38][0m --------------- Iteration 32 ---------------
[32m[0511 09:38:23 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3915 mins
[32m[0511 09:38:23 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 09:38:23 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 09:38:23 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:23 @base_main.py:47][0m 32160 total steps have happened
[32m[0511 09:38:23 @base_main.py:52][0m [avg_reward]: -947.4246000408702
[32m[0511 09:38:23 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:23 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:23 @base_trainer.py:216][0m Mean reward: -1041.9611761989959
[32m[0511 09:38:24 @base_main.py:38][0m --------------- Iteration 33 ---------------
[32m[0511 09:38:24 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4035 mins
[32m[0511 09:38:24 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 09:38:24 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 09:38:24 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0511 09:38:24 @base_main.py:47][0m 33165 total steps have happened
[32m[0511 09:38:24 @base_main.py:52][0m [avg_reward]: -1041.9611761989959
[32m[0511 09:38:24 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:24 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:24 @base_trainer.py:216][0m Mean reward: -1140.8798065539402
[32m[0511 09:38:25 @base_main.py:38][0m --------------- Iteration 34 ---------------
[32m[0511 09:38:25 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4155 mins
[32m[0511 09:38:25 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 09:38:25 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 09:38:25 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:25 @base_main.py:47][0m 34170 total steps have happened
[32m[0511 09:38:25 @base_main.py:52][0m [avg_reward]: -1140.8798065539402
[32m[0511 09:38:25 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:25 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:25 @base_trainer.py:216][0m Mean reward: -979.6311778227049
[32m[0511 09:38:26 @base_main.py:38][0m --------------- Iteration 35 ---------------
[32m[0511 09:38:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4283 mins
[32m[0511 09:38:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 09:38:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 09:38:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:26 @base_main.py:47][0m 35175 total steps have happened
[32m[0511 09:38:26 @base_main.py:52][0m [avg_reward]: -979.6311778227049
[32m[0511 09:38:26 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:26 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:26 @base_trainer.py:216][0m Mean reward: -883.8772716138781
[32m[0511 09:38:26 @base_main.py:38][0m --------------- Iteration 36 ---------------
[32m[0511 09:38:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4407 mins
[32m[0511 09:38:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 09:38:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 09:38:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:26 @base_main.py:47][0m 36180 total steps have happened
[32m[0511 09:38:26 @base_main.py:52][0m [avg_reward]: -883.8772716138781
[32m[0511 09:38:26 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:26 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:26 @base_trainer.py:216][0m Mean reward: -1081.4407783002334
[32m[0511 09:38:27 @base_main.py:38][0m --------------- Iteration 37 ---------------
[32m[0511 09:38:27 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4533 mins
[32m[0511 09:38:27 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 09:38:27 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 09:38:27 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:27 @base_main.py:47][0m 37185 total steps have happened
[32m[0511 09:38:27 @base_main.py:52][0m [avg_reward]: -1081.4407783002334
[32m[0511 09:38:27 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:27 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:27 @base_trainer.py:216][0m Mean reward: -1029.7045116051718
[32m[0511 09:38:28 @base_main.py:38][0m --------------- Iteration 38 ---------------
[32m[0511 09:38:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4659 mins
[32m[0511 09:38:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 09:38:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 09:38:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:28 @base_main.py:47][0m 38190 total steps have happened
[32m[0511 09:38:28 @base_main.py:52][0m [avg_reward]: -1029.7045116051718
[32m[0511 09:38:28 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:28 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:28 @base_trainer.py:216][0m Mean reward: -1072.0156205951357
[32m[0511 09:38:29 @base_main.py:38][0m --------------- Iteration 39 ---------------
[32m[0511 09:38:29 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4782 mins
[32m[0511 09:38:29 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0018 mins
[32m[0511 09:38:29 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 09:38:29 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:29 @base_main.py:47][0m 39195 total steps have happened
[32m[0511 09:38:29 @base_main.py:52][0m [avg_reward]: -1072.0156205951357
[32m[0511 09:38:29 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:29 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:29 @base_trainer.py:216][0m Mean reward: -1089.8673469030475
[32m[0511 09:38:29 @base_main.py:38][0m --------------- Iteration 40 ---------------
[32m[0511 09:38:29 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4906 mins
[32m[0511 09:38:29 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 09:38:29 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 09:38:29 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:29 @base_main.py:47][0m 40200 total steps have happened
[32m[0511 09:38:29 @base_main.py:52][0m [avg_reward]: -1089.8673469030475
[32m[0511 09:38:29 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:29 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:29 @base_trainer.py:216][0m Mean reward: -1030.8198190738474
[32m[0511 09:38:30 @base_main.py:38][0m --------------- Iteration 41 ---------------
[32m[0511 09:38:30 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5030 mins
[32m[0511 09:38:30 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 09:38:30 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 09:38:30 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:30 @base_main.py:47][0m 41205 total steps have happened
[32m[0511 09:38:30 @base_main.py:52][0m [avg_reward]: -1030.8198190738474
[32m[0511 09:38:30 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:30 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:30 @base_trainer.py:216][0m Mean reward: -1187.429947322235
[32m[0511 09:38:31 @base_main.py:38][0m --------------- Iteration 42 ---------------
[32m[0511 09:38:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5156 mins
[32m[0511 09:38:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 09:38:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 09:38:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:31 @base_main.py:47][0m 42210 total steps have happened
[32m[0511 09:38:31 @base_main.py:52][0m [avg_reward]: -1187.429947322235
[32m[0511 09:38:31 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:31 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:31 @base_trainer.py:216][0m Mean reward: -988.8980095150498
[32m[0511 09:38:32 @base_main.py:38][0m --------------- Iteration 43 ---------------
[32m[0511 09:38:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5277 mins
[32m[0511 09:38:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 09:38:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 09:38:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:32 @base_main.py:47][0m 43215 total steps have happened
[32m[0511 09:38:32 @base_main.py:52][0m [avg_reward]: -988.8980095150498
[32m[0511 09:38:32 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:32 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:32 @base_trainer.py:216][0m Mean reward: -1163.4525105131193
[32m[0511 09:38:32 @base_main.py:38][0m --------------- Iteration 44 ---------------
[32m[0511 09:38:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5402 mins
[32m[0511 09:38:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 09:38:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 09:38:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:32 @base_main.py:47][0m 44220 total steps have happened
[32m[0511 09:38:32 @base_main.py:52][0m [avg_reward]: -1163.4525105131193
[32m[0511 09:38:32 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:32 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:32 @base_trainer.py:216][0m Mean reward: -1315.9377487113713
[32m[0511 09:38:33 @base_main.py:38][0m --------------- Iteration 45 ---------------
[32m[0511 09:38:33 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5523 mins
[32m[0511 09:38:33 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 09:38:33 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 09:38:33 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:33 @base_main.py:47][0m 45225 total steps have happened
[32m[0511 09:38:33 @base_main.py:52][0m [avg_reward]: -1315.9377487113713
[32m[0511 09:38:33 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:33 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:33 @base_trainer.py:216][0m Mean reward: -934.2089570502867
[32m[0511 09:38:34 @base_main.py:38][0m --------------- Iteration 46 ---------------
[32m[0511 09:38:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5652 mins
[32m[0511 09:38:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0511 09:38:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 09:38:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:34 @base_main.py:47][0m 46230 total steps have happened
[32m[0511 09:38:34 @base_main.py:52][0m [avg_reward]: -934.2089570502867
[32m[0511 09:38:34 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:34 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:34 @base_trainer.py:216][0m Mean reward: -1090.6540633905165
[32m[0511 09:38:35 @base_main.py:38][0m --------------- Iteration 47 ---------------
[32m[0511 09:38:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5785 mins
[32m[0511 09:38:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 09:38:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 09:38:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:35 @base_main.py:47][0m 47235 total steps have happened
[32m[0511 09:38:35 @base_main.py:52][0m [avg_reward]: -1090.6540633905165
[32m[0511 09:38:35 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:35 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:35 @base_trainer.py:216][0m Mean reward: -1012.8714695222055
[32m[0511 09:38:35 @base_main.py:38][0m --------------- Iteration 48 ---------------
[32m[0511 09:38:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5913 mins
[32m[0511 09:38:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 09:38:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 09:38:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:35 @base_main.py:47][0m 48240 total steps have happened
[32m[0511 09:38:35 @base_main.py:52][0m [avg_reward]: -1012.8714695222055
[32m[0511 09:38:35 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:35 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:35 @base_trainer.py:216][0m Mean reward: -1000.611273398889
[32m[0511 09:38:36 @base_main.py:38][0m --------------- Iteration 49 ---------------
[32m[0511 09:38:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6040 mins
[32m[0511 09:38:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 09:38:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 09:38:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:36 @base_main.py:47][0m 49245 total steps have happened
[32m[0511 09:38:36 @base_main.py:52][0m [avg_reward]: -1000.611273398889
[32m[0511 09:38:36 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:36 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:36 @base_trainer.py:216][0m Mean reward: -1069.2654093042331
[32m[0511 09:38:37 @base_main.py:38][0m --------------- Iteration 50 ---------------
[32m[0511 09:38:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6161 mins
[32m[0511 09:38:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 09:38:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 09:38:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:37 @base_main.py:47][0m 50250 total steps have happened
[32m[0511 09:38:37 @base_main.py:52][0m [avg_reward]: -1069.2654093042331
[32m[0511 09:38:37 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:37 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:37 @base_trainer.py:216][0m Mean reward: -1235.7865718036076
[32m[0511 09:38:38 @base_main.py:38][0m --------------- Iteration 51 ---------------
[32m[0511 09:38:38 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6281 mins
[32m[0511 09:38:38 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 09:38:38 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 09:38:38 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:38 @base_main.py:47][0m 51255 total steps have happened
[32m[0511 09:38:38 @base_main.py:52][0m [avg_reward]: -1235.7865718036076
[32m[0511 09:38:38 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:38 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:38 @base_trainer.py:216][0m Mean reward: -1185.4927949533194
[32m[0511 09:38:38 @base_main.py:38][0m --------------- Iteration 52 ---------------
[32m[0511 09:38:38 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6403 mins
[32m[0511 09:38:38 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 09:38:38 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 09:38:38 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:38 @base_main.py:47][0m 52260 total steps have happened
[32m[0511 09:38:38 @base_main.py:52][0m [avg_reward]: -1185.4927949533194
[32m[0511 09:38:38 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:38 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:38 @base_trainer.py:216][0m Mean reward: -1071.5200352088518
[32m[0511 09:38:39 @base_main.py:38][0m --------------- Iteration 53 ---------------
[32m[0511 09:38:39 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6530 mins
[32m[0511 09:38:39 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 09:38:39 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 09:38:39 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0511 09:38:39 @base_main.py:47][0m 53265 total steps have happened
[32m[0511 09:38:39 @base_main.py:52][0m [avg_reward]: -1071.5200352088518
[32m[0511 09:38:39 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:39 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:39 @base_trainer.py:216][0m Mean reward: -1086.1733363596409
[32m[0511 09:38:40 @base_main.py:38][0m --------------- Iteration 54 ---------------
[32m[0511 09:38:40 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6656 mins
[32m[0511 09:38:40 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 09:38:40 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 09:38:40 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:40 @base_main.py:47][0m 54270 total steps have happened
[32m[0511 09:38:40 @base_main.py:52][0m [avg_reward]: -1086.1733363596409
[32m[0511 09:38:40 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:40 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:40 @base_trainer.py:216][0m Mean reward: -1133.9286319644757
[32m[0511 09:38:41 @base_main.py:38][0m --------------- Iteration 55 ---------------
[32m[0511 09:38:41 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6778 mins
[32m[0511 09:38:41 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 09:38:41 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 09:38:41 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:41 @base_main.py:47][0m 55275 total steps have happened
[32m[0511 09:38:41 @base_main.py:52][0m [avg_reward]: -1133.9286319644757
[32m[0511 09:38:41 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:41 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:41 @base_trainer.py:216][0m Mean reward: -925.687839252238
[32m[0511 09:38:41 @base_main.py:38][0m --------------- Iteration 56 ---------------
[32m[0511 09:38:41 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6907 mins
[32m[0511 09:38:41 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0511 09:38:41 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 09:38:41 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:41 @base_main.py:47][0m 56280 total steps have happened
[32m[0511 09:38:41 @base_main.py:52][0m [avg_reward]: -925.687839252238
[32m[0511 09:38:41 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:41 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:42 @base_trainer.py:216][0m Mean reward: -1286.4190369363512
[32m[0511 09:38:42 @base_main.py:38][0m --------------- Iteration 57 ---------------
[32m[0511 09:38:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7040 mins
[32m[0511 09:38:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 09:38:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 09:38:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:42 @base_main.py:47][0m 57285 total steps have happened
[32m[0511 09:38:42 @base_main.py:52][0m [avg_reward]: -1286.4190369363512
[32m[0511 09:38:42 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:42 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:42 @base_trainer.py:216][0m Mean reward: -1089.335802690842
[32m[0511 09:38:43 @base_main.py:38][0m --------------- Iteration 58 ---------------
[32m[0511 09:38:43 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7159 mins
[32m[0511 09:38:43 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 09:38:43 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0093 mins
[32m[0511 09:38:43 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:43 @base_main.py:47][0m 58290 total steps have happened
[32m[0511 09:38:43 @base_main.py:52][0m [avg_reward]: -1089.335802690842
[32m[0511 09:38:43 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:43 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:43 @base_trainer.py:216][0m Mean reward: -1248.1158103584569
[32m[0511 09:38:44 @base_main.py:38][0m --------------- Iteration 59 ---------------
[32m[0511 09:38:44 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7279 mins
[32m[0511 09:38:44 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 09:38:44 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 09:38:44 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:44 @base_main.py:47][0m 59295 total steps have happened
[32m[0511 09:38:44 @base_main.py:52][0m [avg_reward]: -1248.1158103584569
[32m[0511 09:38:44 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:44 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:44 @base_trainer.py:216][0m Mean reward: -1072.719240422819
[32m[0511 09:38:44 @base_main.py:38][0m --------------- Iteration 60 ---------------
[32m[0511 09:38:44 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7403 mins
[32m[0511 09:38:44 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 09:38:44 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 09:38:44 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:44 @base_main.py:47][0m 60300 total steps have happened
[32m[0511 09:38:44 @base_main.py:52][0m [avg_reward]: -1072.719240422819
[32m[0511 09:38:44 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:44 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:44 @base_trainer.py:216][0m Mean reward: -1018.2476741231767
[32m[0511 09:38:45 @base_main.py:38][0m --------------- Iteration 61 ---------------
[32m[0511 09:38:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7525 mins
[32m[0511 09:38:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0511 09:38:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 09:38:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:45 @base_main.py:47][0m 61305 total steps have happened
[32m[0511 09:38:45 @base_main.py:52][0m [avg_reward]: -1018.2476741231767
[32m[0511 09:38:45 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:45 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:45 @base_trainer.py:216][0m Mean reward: -1101.1525803013506
[32m[0511 09:38:46 @base_main.py:38][0m --------------- Iteration 62 ---------------
[32m[0511 09:38:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7657 mins
[32m[0511 09:38:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 09:38:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 09:38:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:46 @base_main.py:47][0m 62310 total steps have happened
[32m[0511 09:38:46 @base_main.py:52][0m [avg_reward]: -1101.1525803013506
[32m[0511 09:38:46 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:46 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:46 @base_trainer.py:216][0m Mean reward: -831.4234059382692
[32m[0511 09:38:47 @base_main.py:38][0m --------------- Iteration 63 ---------------
[32m[0511 09:38:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7780 mins
[32m[0511 09:38:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 09:38:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 09:38:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:47 @base_main.py:47][0m 63315 total steps have happened
[32m[0511 09:38:47 @base_main.py:52][0m [avg_reward]: -831.4234059382692
[32m[0511 09:38:47 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:47 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:47 @base_trainer.py:216][0m Mean reward: -946.6813686326057
[32m[0511 09:38:47 @base_main.py:38][0m --------------- Iteration 64 ---------------
[32m[0511 09:38:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7903 mins
[32m[0511 09:38:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 09:38:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 09:38:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:47 @base_main.py:47][0m 64320 total steps have happened
[32m[0511 09:38:47 @base_main.py:52][0m [avg_reward]: -946.6813686326057
[32m[0511 09:38:47 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:47 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:47 @base_trainer.py:216][0m Mean reward: -1195.8445981294171
[32m[0511 09:38:48 @base_main.py:38][0m --------------- Iteration 65 ---------------
[32m[0511 09:38:48 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8030 mins
[32m[0511 09:38:48 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 09:38:48 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 09:38:48 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:48 @base_main.py:47][0m 65325 total steps have happened
[32m[0511 09:38:48 @base_main.py:52][0m [avg_reward]: -1195.8445981294171
[32m[0511 09:38:48 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:48 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:48 @base_trainer.py:216][0m Mean reward: -989.7514858042271
[32m[0511 09:38:49 @base_main.py:38][0m --------------- Iteration 66 ---------------
[32m[0511 09:38:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8153 mins
[32m[0511 09:38:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 09:38:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 09:38:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:49 @base_main.py:47][0m 66330 total steps have happened
[32m[0511 09:38:49 @base_main.py:52][0m [avg_reward]: -989.7514858042271
[32m[0511 09:38:49 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:49 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:49 @base_trainer.py:216][0m Mean reward: -977.7260448526677
[32m[0511 09:38:50 @base_main.py:38][0m --------------- Iteration 67 ---------------
[32m[0511 09:38:50 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8278 mins
[32m[0511 09:38:50 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 09:38:50 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 09:38:50 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:50 @base_main.py:47][0m 67335 total steps have happened
[32m[0511 09:38:50 @base_main.py:52][0m [avg_reward]: -977.7260448526677
[32m[0511 09:38:50 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:50 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:50 @base_trainer.py:216][0m Mean reward: -1062.5250928420242
[32m[0511 09:38:50 @base_main.py:38][0m --------------- Iteration 68 ---------------
[32m[0511 09:38:50 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8400 mins
[32m[0511 09:38:50 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 09:38:50 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 09:38:50 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:50 @base_main.py:47][0m 68340 total steps have happened
[32m[0511 09:38:50 @base_main.py:52][0m [avg_reward]: -1062.5250928420242
[32m[0511 09:38:50 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:50 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:50 @base_trainer.py:216][0m Mean reward: -946.3135067418501
[32m[0511 09:38:51 @base_main.py:38][0m --------------- Iteration 69 ---------------
[32m[0511 09:38:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8520 mins
[32m[0511 09:38:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 09:38:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 09:38:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:51 @base_main.py:47][0m 69345 total steps have happened
[32m[0511 09:38:51 @base_main.py:52][0m [avg_reward]: -946.3135067418501
[32m[0511 09:38:51 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:51 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:51 @base_trainer.py:216][0m Mean reward: -1054.0665418978276
[32m[0511 09:38:52 @base_main.py:38][0m --------------- Iteration 70 ---------------
[32m[0511 09:38:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8644 mins
[32m[0511 09:38:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 09:38:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 09:38:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:52 @base_main.py:47][0m 70350 total steps have happened
[32m[0511 09:38:52 @base_main.py:52][0m [avg_reward]: -1054.0665418978276
[32m[0511 09:38:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:52 @base_trainer.py:216][0m Mean reward: -1090.0693537189068
[32m[0511 09:38:52 @base_main.py:38][0m --------------- Iteration 71 ---------------
[32m[0511 09:38:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8765 mins
[32m[0511 09:38:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 09:38:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 09:38:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:52 @base_main.py:47][0m 71355 total steps have happened
[32m[0511 09:38:52 @base_main.py:52][0m [avg_reward]: -1090.0693537189068
[32m[0511 09:38:53 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:53 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:53 @base_trainer.py:216][0m Mean reward: -1091.196082429799
[32m[0511 09:38:53 @base_main.py:38][0m --------------- Iteration 72 ---------------
[32m[0511 09:38:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8894 mins
[32m[0511 09:38:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 09:38:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 09:38:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:53 @base_main.py:47][0m 72360 total steps have happened
[32m[0511 09:38:53 @base_main.py:52][0m [avg_reward]: -1091.196082429799
[32m[0511 09:38:53 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:53 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:53 @base_trainer.py:216][0m Mean reward: -1267.8828258098358
[32m[0511 09:38:54 @base_main.py:38][0m --------------- Iteration 73 ---------------
[32m[0511 09:38:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9017 mins
[32m[0511 09:38:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 09:38:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0511 09:38:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:54 @base_main.py:47][0m 73365 total steps have happened
[32m[0511 09:38:54 @base_main.py:52][0m [avg_reward]: -1267.8828258098358
[32m[0511 09:38:54 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:54 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:54 @base_trainer.py:216][0m Mean reward: -1205.5261095329038
[32m[0511 09:38:55 @base_main.py:38][0m --------------- Iteration 74 ---------------
[32m[0511 09:38:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9135 mins
[32m[0511 09:38:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 09:38:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0511 09:38:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:55 @base_main.py:47][0m 74370 total steps have happened
[32m[0511 09:38:55 @base_main.py:52][0m [avg_reward]: -1205.5261095329038
[32m[0511 09:38:55 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:55 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:55 @base_trainer.py:216][0m Mean reward: -1161.497482583516
[32m[0511 09:38:55 @base_main.py:38][0m --------------- Iteration 75 ---------------
[32m[0511 09:38:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9250 mins
[32m[0511 09:38:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0511 09:38:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 09:38:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:55 @base_main.py:47][0m 75375 total steps have happened
[32m[0511 09:38:55 @base_main.py:52][0m [avg_reward]: -1161.497482583516
[32m[0511 09:38:55 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:55 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:55 @base_trainer.py:216][0m Mean reward: -935.2152577391444
[32m[0511 09:38:56 @base_main.py:38][0m --------------- Iteration 76 ---------------
[32m[0511 09:38:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9375 mins
[32m[0511 09:38:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 09:38:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 09:38:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:56 @base_main.py:47][0m 76380 total steps have happened
[32m[0511 09:38:56 @base_main.py:52][0m [avg_reward]: -935.2152577391444
[32m[0511 09:38:56 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:56 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:56 @base_trainer.py:216][0m Mean reward: -1033.4778304800825
[32m[0511 09:38:57 @base_main.py:38][0m --------------- Iteration 77 ---------------
[32m[0511 09:38:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9496 mins
[32m[0511 09:38:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 09:38:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 09:38:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:57 @base_main.py:47][0m 77385 total steps have happened
[32m[0511 09:38:57 @base_main.py:52][0m [avg_reward]: -1033.4778304800825
[32m[0511 09:38:57 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:57 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:57 @base_trainer.py:216][0m Mean reward: -975.5576585019556
[32m[0511 09:38:58 @base_main.py:38][0m --------------- Iteration 78 ---------------
[32m[0511 09:38:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9615 mins
[32m[0511 09:38:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 09:38:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 09:38:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:58 @base_main.py:47][0m 78390 total steps have happened
[32m[0511 09:38:58 @base_main.py:52][0m [avg_reward]: -975.5576585019556
[32m[0511 09:38:58 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:58 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:58 @base_trainer.py:216][0m Mean reward: -1229.0087014853275
[32m[0511 09:38:58 @base_main.py:38][0m --------------- Iteration 79 ---------------
[32m[0511 09:38:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9740 mins
[32m[0511 09:38:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0511 09:38:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 09:38:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:58 @base_main.py:47][0m 79395 total steps have happened
[32m[0511 09:38:58 @base_main.py:52][0m [avg_reward]: -1229.0087014853275
[32m[0511 09:38:58 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:58 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:58 @base_trainer.py:216][0m Mean reward: -1096.8479384426178
[32m[0511 09:38:59 @base_main.py:38][0m --------------- Iteration 80 ---------------
[32m[0511 09:38:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9872 mins
[32m[0511 09:38:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0018 mins
[32m[0511 09:38:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 09:38:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:38:59 @base_main.py:47][0m 80400 total steps have happened
[32m[0511 09:38:59 @base_main.py:52][0m [avg_reward]: -1096.8479384426178
[32m[0511 09:38:59 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:38:59 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:38:59 @base_trainer.py:216][0m Mean reward: -1104.029761316236
[32m[0511 09:39:00 @base_main.py:38][0m --------------- Iteration 81 ---------------
[32m[0511 09:39:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9993 mins
[32m[0511 09:39:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 09:39:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 09:39:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:00 @base_main.py:47][0m 81405 total steps have happened
[32m[0511 09:39:00 @base_main.py:52][0m [avg_reward]: -1104.029761316236
[32m[0511 09:39:00 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:00 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:00 @base_trainer.py:216][0m Mean reward: -1096.4141103026802
[32m[0511 09:39:01 @base_main.py:38][0m --------------- Iteration 82 ---------------
[32m[0511 09:39:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0116 mins
[32m[0511 09:39:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 09:39:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 09:39:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:01 @base_main.py:47][0m 82410 total steps have happened
[32m[0511 09:39:01 @base_main.py:52][0m [avg_reward]: -1096.4141103026802
[32m[0511 09:39:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:01 @base_trainer.py:216][0m Mean reward: -1088.75336552101
[32m[0511 09:39:01 @base_main.py:38][0m --------------- Iteration 83 ---------------
[32m[0511 09:39:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0246 mins
[32m[0511 09:39:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 09:39:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 09:39:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:01 @base_main.py:47][0m 83415 total steps have happened
[32m[0511 09:39:01 @base_main.py:52][0m [avg_reward]: -1088.75336552101
[32m[0511 09:39:02 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:02 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:02 @base_trainer.py:216][0m Mean reward: -947.1971511093722
[32m[0511 09:39:02 @base_main.py:38][0m --------------- Iteration 84 ---------------
[32m[0511 09:39:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0369 mins
[32m[0511 09:39:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0511 09:39:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 09:39:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:02 @base_main.py:47][0m 84420 total steps have happened
[32m[0511 09:39:02 @base_main.py:52][0m [avg_reward]: -947.1971511093722
[32m[0511 09:39:02 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:02 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:02 @base_trainer.py:216][0m Mean reward: -1028.755783169839
[32m[0511 09:39:03 @base_main.py:38][0m --------------- Iteration 85 ---------------
[32m[0511 09:39:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0495 mins
[32m[0511 09:39:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 09:39:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 09:39:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:03 @base_main.py:47][0m 85425 total steps have happened
[32m[0511 09:39:03 @base_main.py:52][0m [avg_reward]: -1028.755783169839
[32m[0511 09:39:03 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:03 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:03 @base_trainer.py:216][0m Mean reward: -1254.935658613755
[32m[0511 09:39:04 @base_main.py:38][0m --------------- Iteration 86 ---------------
[32m[0511 09:39:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0624 mins
[32m[0511 09:39:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 09:39:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 09:39:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:04 @base_main.py:47][0m 86430 total steps have happened
[32m[0511 09:39:04 @base_main.py:52][0m [avg_reward]: -1254.935658613755
[32m[0511 09:39:04 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:04 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:04 @base_trainer.py:216][0m Mean reward: -1070.9175105672234
[32m[0511 09:39:04 @base_main.py:38][0m --------------- Iteration 87 ---------------
[32m[0511 09:39:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0752 mins
[32m[0511 09:39:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 09:39:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 09:39:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:04 @base_main.py:47][0m 87435 total steps have happened
[32m[0511 09:39:04 @base_main.py:52][0m [avg_reward]: -1070.9175105672234
[32m[0511 09:39:05 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:05 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:05 @base_trainer.py:216][0m Mean reward: -1106.7405275338438
[32m[0511 09:39:05 @base_main.py:38][0m --------------- Iteration 88 ---------------
[32m[0511 09:39:05 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0881 mins
[32m[0511 09:39:05 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 09:39:05 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 09:39:05 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:05 @base_main.py:47][0m 88440 total steps have happened
[32m[0511 09:39:05 @base_main.py:52][0m [avg_reward]: -1106.7405275338438
[32m[0511 09:39:05 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:05 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:05 @base_trainer.py:216][0m Mean reward: -948.7410915464961
[32m[0511 09:39:06 @base_main.py:38][0m --------------- Iteration 89 ---------------
[32m[0511 09:39:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1009 mins
[32m[0511 09:39:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0511 09:39:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 09:39:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:06 @base_main.py:47][0m 89445 total steps have happened
[32m[0511 09:39:06 @base_main.py:52][0m [avg_reward]: -948.7410915464961
[32m[0511 09:39:06 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:06 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:06 @base_trainer.py:216][0m Mean reward: -1039.030882667766
[32m[0511 09:39:07 @base_main.py:38][0m --------------- Iteration 90 ---------------
[32m[0511 09:39:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1141 mins
[32m[0511 09:39:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0018 mins
[32m[0511 09:39:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 09:39:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:07 @base_main.py:47][0m 90450 total steps have happened
[32m[0511 09:39:07 @base_main.py:52][0m [avg_reward]: -1039.030882667766
[32m[0511 09:39:07 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:07 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:07 @base_trainer.py:216][0m Mean reward: -1033.0912508167414
[32m[0511 09:39:07 @base_main.py:38][0m --------------- Iteration 91 ---------------
[32m[0511 09:39:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1261 mins
[32m[0511 09:39:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 09:39:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 09:39:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:07 @base_main.py:47][0m 91455 total steps have happened
[32m[0511 09:39:07 @base_main.py:52][0m [avg_reward]: -1033.0912508167414
[32m[0511 09:39:08 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:08 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:08 @base_trainer.py:216][0m Mean reward: -1001.4242985980032
[32m[0511 09:39:08 @base_main.py:38][0m --------------- Iteration 92 ---------------
[32m[0511 09:39:08 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1380 mins
[32m[0511 09:39:08 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 09:39:08 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 09:39:08 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:08 @base_main.py:47][0m 92460 total steps have happened
[32m[0511 09:39:08 @base_main.py:52][0m [avg_reward]: -1001.4242985980032
[32m[0511 09:39:08 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:08 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:08 @base_trainer.py:216][0m Mean reward: -1039.6413664643173
[32m[0511 09:39:09 @base_main.py:38][0m --------------- Iteration 93 ---------------
[32m[0511 09:39:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1506 mins
[32m[0511 09:39:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 09:39:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 09:39:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:09 @base_main.py:47][0m 93465 total steps have happened
[32m[0511 09:39:09 @base_main.py:52][0m [avg_reward]: -1039.6413664643173
[32m[0511 09:39:09 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:09 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:09 @base_trainer.py:216][0m Mean reward: -1205.0129563528087
[32m[0511 09:39:10 @base_main.py:38][0m --------------- Iteration 94 ---------------
[32m[0511 09:39:10 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1625 mins
[32m[0511 09:39:10 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0511 09:39:10 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 09:39:10 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:10 @base_main.py:47][0m 94470 total steps have happened
[32m[0511 09:39:10 @base_main.py:52][0m [avg_reward]: -1205.0129563528087
[32m[0511 09:39:10 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:10 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:10 @base_trainer.py:216][0m Mean reward: -925.2011196866406
[32m[0511 09:39:10 @base_main.py:38][0m --------------- Iteration 95 ---------------
[32m[0511 09:39:10 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1756 mins
[32m[0511 09:39:10 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 09:39:10 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 09:39:10 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:10 @base_main.py:47][0m 95475 total steps have happened
[32m[0511 09:39:10 @base_main.py:52][0m [avg_reward]: -925.2011196866406
[32m[0511 09:39:11 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:11 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:11 @base_trainer.py:216][0m Mean reward: -960.8146817810418
[32m[0511 09:39:11 @base_main.py:38][0m --------------- Iteration 96 ---------------
[32m[0511 09:39:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1887 mins
[32m[0511 09:39:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 09:39:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 09:39:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:11 @base_main.py:47][0m 96480 total steps have happened
[32m[0511 09:39:11 @base_main.py:52][0m [avg_reward]: -960.8146817810418
[32m[0511 09:39:11 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:11 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:11 @base_trainer.py:216][0m Mean reward: -936.4746836900595
[32m[0511 09:39:12 @base_main.py:38][0m --------------- Iteration 97 ---------------
[32m[0511 09:39:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2010 mins
[32m[0511 09:39:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 09:39:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0511 09:39:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:12 @base_main.py:47][0m 97485 total steps have happened
[32m[0511 09:39:12 @base_main.py:52][0m [avg_reward]: -936.4746836900595
[32m[0511 09:39:12 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:12 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:12 @base_trainer.py:216][0m Mean reward: -1041.5378278964497
[32m[0511 09:39:13 @base_main.py:38][0m --------------- Iteration 98 ---------------
[32m[0511 09:39:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2127 mins
[32m[0511 09:39:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0511 09:39:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 09:39:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:13 @base_main.py:47][0m 98490 total steps have happened
[32m[0511 09:39:13 @base_main.py:52][0m [avg_reward]: -1041.5378278964497
[32m[0511 09:39:13 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:13 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:13 @base_trainer.py:216][0m Mean reward: -948.2458087926134
[32m[0511 09:39:13 @base_main.py:38][0m --------------- Iteration 99 ---------------
[32m[0511 09:39:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2259 mins
[32m[0511 09:39:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 09:39:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 09:39:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:13 @base_main.py:47][0m 99495 total steps have happened
[32m[0511 09:39:13 @base_main.py:52][0m [avg_reward]: -948.2458087926134
[32m[0511 09:39:14 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:14 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:14 @base_trainer.py:216][0m Mean reward: -982.3744948634343
[32m[0511 09:39:14 @base_main.py:38][0m --------------- Iteration 100 ---------------
[32m[0511 09:39:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2383 mins
[32m[0511 09:39:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 09:39:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 09:39:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:14 @base_main.py:47][0m 100500 total steps have happened
[32m[0511 09:39:14 @base_main.py:52][0m [avg_reward]: -982.3744948634343
[32m[0511 09:39:14 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:14 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:14 @base_trainer.py:216][0m Mean reward: -1067.4398746557665
[32m[0511 09:39:15 @base_main.py:38][0m --------------- Iteration 101 ---------------
[32m[0511 09:39:15 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2511 mins
[32m[0511 09:39:15 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 09:39:15 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 09:39:15 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:15 @base_main.py:47][0m 101505 total steps have happened
[32m[0511 09:39:15 @base_main.py:52][0m [avg_reward]: -1067.4398746557665
[32m[0511 09:39:15 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:15 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:15 @base_trainer.py:216][0m Mean reward: -926.7826300538733
[32m[0511 09:39:16 @base_main.py:38][0m --------------- Iteration 102 ---------------
[32m[0511 09:39:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2633 mins
[32m[0511 09:39:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 09:39:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 09:39:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:16 @base_main.py:47][0m 102510 total steps have happened
[32m[0511 09:39:16 @base_main.py:52][0m [avg_reward]: -926.7826300538733
[32m[0511 09:39:16 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:16 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:16 @base_trainer.py:216][0m Mean reward: -1025.9219485055708
[32m[0511 09:39:16 @base_main.py:38][0m --------------- Iteration 103 ---------------
[32m[0511 09:39:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2757 mins
[32m[0511 09:39:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 09:39:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 09:39:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:16 @base_main.py:47][0m 103515 total steps have happened
[32m[0511 09:39:16 @base_main.py:52][0m [avg_reward]: -1025.9219485055708
[32m[0511 09:39:17 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:17 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:17 @base_trainer.py:216][0m Mean reward: -1082.6030756059158
[32m[0511 09:39:17 @base_main.py:38][0m --------------- Iteration 104 ---------------
[32m[0511 09:39:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2881 mins
[32m[0511 09:39:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 09:39:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 09:39:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:17 @base_main.py:47][0m 104520 total steps have happened
[32m[0511 09:39:17 @base_main.py:52][0m [avg_reward]: -1082.6030756059158
[32m[0511 09:39:17 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:17 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:17 @base_trainer.py:216][0m Mean reward: -1207.8020603740847
[32m[0511 09:39:18 @base_main.py:38][0m --------------- Iteration 105 ---------------
[32m[0511 09:39:18 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3005 mins
[32m[0511 09:39:18 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 09:39:18 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 09:39:18 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:18 @base_main.py:47][0m 105525 total steps have happened
[32m[0511 09:39:18 @base_main.py:52][0m [avg_reward]: -1207.8020603740847
[32m[0511 09:39:18 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:18 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:18 @base_trainer.py:216][0m Mean reward: -1326.1684565960609
[32m[0511 09:39:19 @base_main.py:38][0m --------------- Iteration 106 ---------------
[32m[0511 09:39:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3129 mins
[32m[0511 09:39:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 09:39:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 09:39:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:19 @base_main.py:47][0m 106530 total steps have happened
[32m[0511 09:39:19 @base_main.py:52][0m [avg_reward]: -1326.1684565960609
[32m[0511 09:39:19 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:19 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:19 @base_trainer.py:216][0m Mean reward: -1098.4001258815867
[32m[0511 09:39:19 @base_main.py:38][0m --------------- Iteration 107 ---------------
[32m[0511 09:39:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3247 mins
[32m[0511 09:39:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 09:39:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 09:39:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:19 @base_main.py:47][0m 107535 total steps have happened
[32m[0511 09:39:19 @base_main.py:52][0m [avg_reward]: -1098.4001258815867
[32m[0511 09:39:20 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:20 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:20 @base_trainer.py:216][0m Mean reward: -1010.558281889282
[32m[0511 09:39:20 @base_main.py:38][0m --------------- Iteration 108 ---------------
[32m[0511 09:39:20 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3370 mins
[32m[0511 09:39:20 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 09:39:20 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 09:39:20 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:20 @base_main.py:47][0m 108540 total steps have happened
[32m[0511 09:39:20 @base_main.py:52][0m [avg_reward]: -1010.558281889282
[32m[0511 09:39:20 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:20 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:20 @base_trainer.py:216][0m Mean reward: -1130.657215540557
[32m[0511 09:39:21 @base_main.py:38][0m --------------- Iteration 109 ---------------
[32m[0511 09:39:21 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3500 mins
[32m[0511 09:39:21 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 09:39:21 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0511 09:39:21 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:21 @base_main.py:47][0m 109545 total steps have happened
[32m[0511 09:39:21 @base_main.py:52][0m [avg_reward]: -1130.657215540557
[32m[0511 09:39:21 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:21 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:21 @base_trainer.py:216][0m Mean reward: -994.5775696154706
[32m[0511 09:39:22 @base_main.py:38][0m --------------- Iteration 110 ---------------
[32m[0511 09:39:22 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3616 mins
[32m[0511 09:39:22 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 09:39:22 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 09:39:22 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:22 @base_main.py:47][0m 110550 total steps have happened
[32m[0511 09:39:22 @base_main.py:52][0m [avg_reward]: -994.5775696154706
[32m[0511 09:39:22 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:22 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:22 @base_trainer.py:216][0m Mean reward: -891.9624623980162
[32m[0511 09:39:22 @base_main.py:38][0m --------------- Iteration 111 ---------------
[32m[0511 09:39:22 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3742 mins
[32m[0511 09:39:22 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 09:39:22 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 09:39:22 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:22 @base_main.py:47][0m 111555 total steps have happened
[32m[0511 09:39:22 @base_main.py:52][0m [avg_reward]: -891.9624623980162
[32m[0511 09:39:23 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:23 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:23 @base_trainer.py:216][0m Mean reward: -893.0195700105796
[32m[0511 09:39:23 @base_main.py:38][0m --------------- Iteration 112 ---------------
[32m[0511 09:39:23 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3871 mins
[32m[0511 09:39:23 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0511 09:39:23 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 09:39:23 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:23 @base_main.py:47][0m 112560 total steps have happened
[32m[0511 09:39:23 @base_main.py:52][0m [avg_reward]: -893.0195700105796
[32m[0511 09:39:23 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:23 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:23 @base_trainer.py:216][0m Mean reward: -1147.968857545884
[32m[0511 09:39:24 @base_main.py:38][0m --------------- Iteration 113 ---------------
[32m[0511 09:39:24 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3999 mins
[32m[0511 09:39:24 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 09:39:24 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 09:39:24 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:24 @base_main.py:47][0m 113565 total steps have happened
[32m[0511 09:39:24 @base_main.py:52][0m [avg_reward]: -1147.968857545884
[32m[0511 09:39:24 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:24 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:24 @base_trainer.py:216][0m Mean reward: -930.281953218225
[32m[0511 09:39:25 @base_main.py:38][0m --------------- Iteration 114 ---------------
[32m[0511 09:39:25 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4131 mins
[32m[0511 09:39:25 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 09:39:25 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 09:39:25 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:25 @base_main.py:47][0m 114570 total steps have happened
[32m[0511 09:39:25 @base_main.py:52][0m [avg_reward]: -930.281953218225
[32m[0511 09:39:25 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:25 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:25 @base_trainer.py:216][0m Mean reward: -1240.716031610556
[32m[0511 09:39:25 @base_main.py:38][0m --------------- Iteration 115 ---------------
[32m[0511 09:39:25 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4258 mins
[32m[0511 09:39:25 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 09:39:25 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 09:39:25 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:25 @base_main.py:47][0m 115575 total steps have happened
[32m[0511 09:39:25 @base_main.py:52][0m [avg_reward]: -1240.716031610556
[32m[0511 09:39:26 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:26 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:26 @base_trainer.py:216][0m Mean reward: -1324.5780067553283
[32m[0511 09:39:26 @base_main.py:38][0m --------------- Iteration 116 ---------------
[32m[0511 09:39:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4381 mins
[32m[0511 09:39:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 09:39:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 09:39:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:26 @base_main.py:47][0m 116580 total steps have happened
[32m[0511 09:39:26 @base_main.py:52][0m [avg_reward]: -1324.5780067553283
[32m[0511 09:39:26 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:26 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:26 @base_trainer.py:216][0m Mean reward: -1087.973105912678
[32m[0511 09:39:27 @base_main.py:38][0m --------------- Iteration 117 ---------------
[32m[0511 09:39:27 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4504 mins
[32m[0511 09:39:27 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 09:39:27 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 09:39:27 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:27 @base_main.py:47][0m 117585 total steps have happened
[32m[0511 09:39:27 @base_main.py:52][0m [avg_reward]: -1087.973105912678
[32m[0511 09:39:27 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:27 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:27 @base_trainer.py:216][0m Mean reward: -1094.6128705369201
[32m[0511 09:39:28 @base_main.py:38][0m --------------- Iteration 118 ---------------
[32m[0511 09:39:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4634 mins
[32m[0511 09:39:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 09:39:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 09:39:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:28 @base_main.py:47][0m 118590 total steps have happened
[32m[0511 09:39:28 @base_main.py:52][0m [avg_reward]: -1094.6128705369201
[32m[0511 09:39:28 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:28 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:28 @base_trainer.py:216][0m Mean reward: -891.8634365382165
[32m[0511 09:39:28 @base_main.py:38][0m --------------- Iteration 119 ---------------
[32m[0511 09:39:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4757 mins
[32m[0511 09:39:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 09:39:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0511 09:39:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:28 @base_main.py:47][0m 119595 total steps have happened
[32m[0511 09:39:28 @base_main.py:52][0m [avg_reward]: -891.8634365382165
[32m[0511 09:39:29 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:29 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:29 @base_trainer.py:216][0m Mean reward: -904.0173105530594
[32m[0511 09:39:29 @base_main.py:38][0m --------------- Iteration 120 ---------------
[32m[0511 09:39:29 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4875 mins
[32m[0511 09:39:29 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 09:39:29 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0107 mins
[32m[0511 09:39:29 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:29 @base_main.py:47][0m 120600 total steps have happened
[32m[0511 09:39:29 @base_main.py:52][0m [avg_reward]: -904.0173105530594
[32m[0511 09:39:29 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:29 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:29 @base_trainer.py:216][0m Mean reward: -1102.2996184312099
[32m[0511 09:39:30 @base_main.py:38][0m --------------- Iteration 121 ---------------
[32m[0511 09:39:30 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5005 mins
[32m[0511 09:39:30 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 09:39:30 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 09:39:30 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:30 @base_main.py:47][0m 121605 total steps have happened
[32m[0511 09:39:30 @base_main.py:52][0m [avg_reward]: -1102.2996184312099
[32m[0511 09:39:30 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:30 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:30 @base_trainer.py:216][0m Mean reward: -1019.2541920623675
[32m[0511 09:39:31 @base_main.py:38][0m --------------- Iteration 122 ---------------
[32m[0511 09:39:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5131 mins
[32m[0511 09:39:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 09:39:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 09:39:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:31 @base_main.py:47][0m 122610 total steps have happened
[32m[0511 09:39:31 @base_main.py:52][0m [avg_reward]: -1019.2541920623675
[32m[0511 09:39:31 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:31 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:31 @base_trainer.py:216][0m Mean reward: -1131.5307685338255
[32m[0511 09:39:31 @base_main.py:38][0m --------------- Iteration 123 ---------------
[32m[0511 09:39:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5252 mins
[32m[0511 09:39:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 09:39:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 09:39:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:31 @base_main.py:47][0m 123615 total steps have happened
[32m[0511 09:39:31 @base_main.py:52][0m [avg_reward]: -1131.5307685338255
[32m[0511 09:39:32 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:32 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:32 @base_trainer.py:216][0m Mean reward: -1143.5918054822166
[32m[0511 09:39:32 @base_main.py:38][0m --------------- Iteration 124 ---------------
[32m[0511 09:39:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5376 mins
[32m[0511 09:39:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 09:39:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0511 09:39:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:32 @base_main.py:47][0m 124620 total steps have happened
[32m[0511 09:39:32 @base_main.py:52][0m [avg_reward]: -1143.5918054822166
[32m[0511 09:39:32 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:32 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:32 @base_trainer.py:216][0m Mean reward: -1039.4648100676907
[32m[0511 09:39:33 @base_main.py:38][0m --------------- Iteration 125 ---------------
[32m[0511 09:39:33 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5494 mins
[32m[0511 09:39:33 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 09:39:33 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 09:39:33 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:33 @base_main.py:47][0m 125625 total steps have happened
[32m[0511 09:39:33 @base_main.py:52][0m [avg_reward]: -1039.4648100676907
[32m[0511 09:39:33 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:33 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:33 @base_trainer.py:216][0m Mean reward: -977.5619229611224
[32m[0511 09:39:34 @base_main.py:38][0m --------------- Iteration 126 ---------------
[32m[0511 09:39:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5623 mins
[32m[0511 09:39:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 09:39:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0511 09:39:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:34 @base_main.py:47][0m 126630 total steps have happened
[32m[0511 09:39:34 @base_main.py:52][0m [avg_reward]: -977.5619229611224
[32m[0511 09:39:34 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:34 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:34 @base_trainer.py:216][0m Mean reward: -1025.4952654129888
[32m[0511 09:39:34 @base_main.py:38][0m --------------- Iteration 127 ---------------
[32m[0511 09:39:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5741 mins
[32m[0511 09:39:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 09:39:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 09:39:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:34 @base_main.py:47][0m 127635 total steps have happened
[32m[0511 09:39:34 @base_main.py:52][0m [avg_reward]: -1025.4952654129888
[32m[0511 09:39:34 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:34 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:34 @base_trainer.py:216][0m Mean reward: -809.6103352861713
[32m[0511 09:39:35 @base_main.py:38][0m --------------- Iteration 128 ---------------
[32m[0511 09:39:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5863 mins
[32m[0511 09:39:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 09:39:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 09:39:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:35 @base_main.py:47][0m 128640 total steps have happened
[32m[0511 09:39:35 @base_main.py:52][0m [avg_reward]: -809.6103352861713
[32m[0511 09:39:35 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:35 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:35 @base_trainer.py:216][0m Mean reward: -817.7041589627918
[32m[0511 09:39:36 @base_main.py:38][0m --------------- Iteration 129 ---------------
[32m[0511 09:39:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5992 mins
[32m[0511 09:39:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 09:39:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 09:39:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:36 @base_main.py:47][0m 129645 total steps have happened
[32m[0511 09:39:36 @base_main.py:52][0m [avg_reward]: -817.7041589627918
[32m[0511 09:39:36 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:36 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:36 @base_trainer.py:216][0m Mean reward: -1160.7662601150364
[32m[0511 09:39:37 @base_main.py:38][0m --------------- Iteration 130 ---------------
[32m[0511 09:39:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6118 mins
[32m[0511 09:39:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 09:39:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 09:39:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:37 @base_main.py:47][0m 130650 total steps have happened
[32m[0511 09:39:37 @base_main.py:52][0m [avg_reward]: -1160.7662601150364
[32m[0511 09:39:37 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:37 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:37 @base_trainer.py:216][0m Mean reward: -934.7964868895242
[32m[0511 09:39:37 @base_main.py:38][0m --------------- Iteration 131 ---------------
[32m[0511 09:39:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6245 mins
[32m[0511 09:39:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 09:39:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 09:39:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:37 @base_main.py:47][0m 131655 total steps have happened
[32m[0511 09:39:37 @base_main.py:52][0m [avg_reward]: -934.7964868895242
[32m[0511 09:39:37 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:37 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:37 @base_trainer.py:216][0m Mean reward: -1061.9355395760447
[32m[0511 09:39:38 @base_main.py:38][0m --------------- Iteration 132 ---------------
[32m[0511 09:39:38 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6371 mins
[32m[0511 09:39:38 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 09:39:38 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 09:39:38 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:38 @base_main.py:47][0m 132660 total steps have happened
[32m[0511 09:39:38 @base_main.py:52][0m [avg_reward]: -1061.9355395760447
[32m[0511 09:39:38 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:38 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:38 @base_trainer.py:216][0m Mean reward: -937.6040473406392
[32m[0511 09:39:39 @base_main.py:38][0m --------------- Iteration 133 ---------------
[32m[0511 09:39:39 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6488 mins
[32m[0511 09:39:39 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 09:39:39 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 09:39:39 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:39 @base_main.py:47][0m 133665 total steps have happened
[32m[0511 09:39:39 @base_main.py:52][0m [avg_reward]: -937.6040473406392
[32m[0511 09:39:39 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:39 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:39 @base_trainer.py:216][0m Mean reward: -983.4082592170183
[32m[0511 09:39:40 @base_main.py:38][0m --------------- Iteration 134 ---------------
[32m[0511 09:39:40 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6614 mins
[32m[0511 09:39:40 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 09:39:40 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 09:39:40 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:40 @base_main.py:47][0m 134670 total steps have happened
[32m[0511 09:39:40 @base_main.py:52][0m [avg_reward]: -983.4082592170183
[32m[0511 09:39:40 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:40 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:40 @base_trainer.py:216][0m Mean reward: -992.4057218883754
[32m[0511 09:39:40 @base_main.py:38][0m --------------- Iteration 135 ---------------
[32m[0511 09:39:40 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6735 mins
[32m[0511 09:39:40 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 09:39:40 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 09:39:40 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:40 @base_main.py:47][0m 135675 total steps have happened
[32m[0511 09:39:40 @base_main.py:52][0m [avg_reward]: -992.4057218883754
[32m[0511 09:39:40 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:40 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:40 @base_trainer.py:216][0m Mean reward: -981.0889296086764
[32m[0511 09:39:41 @base_main.py:38][0m --------------- Iteration 136 ---------------
[32m[0511 09:39:41 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6865 mins
[32m[0511 09:39:41 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 09:39:41 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0511 09:39:41 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0511 09:39:41 @base_main.py:47][0m 136680 total steps have happened
[32m[0511 09:39:41 @base_main.py:52][0m [avg_reward]: -981.0889296086764
[32m[0511 09:39:41 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:41 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:41 @base_trainer.py:216][0m Mean reward: -1000.9006961045465
[32m[0511 09:39:42 @base_main.py:38][0m --------------- Iteration 137 ---------------
[32m[0511 09:39:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6981 mins
[32m[0511 09:39:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 09:39:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 09:39:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:42 @base_main.py:47][0m 137685 total steps have happened
[32m[0511 09:39:42 @base_main.py:52][0m [avg_reward]: -1000.9006961045465
[32m[0511 09:39:42 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:42 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:42 @base_trainer.py:216][0m Mean reward: -932.3954180422854
[32m[0511 09:39:42 @base_main.py:38][0m --------------- Iteration 138 ---------------
[32m[0511 09:39:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7101 mins
[32m[0511 09:39:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 09:39:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 09:39:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:42 @base_main.py:47][0m 138690 total steps have happened
[32m[0511 09:39:42 @base_main.py:52][0m [avg_reward]: -932.3954180422854
[32m[0511 09:39:43 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:43 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:43 @base_trainer.py:216][0m Mean reward: -966.0392809187491
[32m[0511 09:39:43 @base_main.py:38][0m --------------- Iteration 139 ---------------
[32m[0511 09:39:43 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7229 mins
[32m[0511 09:39:43 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 09:39:43 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 09:39:43 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:43 @base_main.py:47][0m 139695 total steps have happened
[32m[0511 09:39:43 @base_main.py:52][0m [avg_reward]: -966.0392809187491
[32m[0511 09:39:43 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:43 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:43 @base_trainer.py:216][0m Mean reward: -857.5080526943932
[32m[0511 09:39:44 @base_main.py:38][0m --------------- Iteration 140 ---------------
[32m[0511 09:39:44 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7351 mins
[32m[0511 09:39:44 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0511 09:39:44 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 09:39:44 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:44 @base_main.py:47][0m 140700 total steps have happened
[32m[0511 09:39:44 @base_main.py:52][0m [avg_reward]: -857.5080526943932
[32m[0511 09:39:44 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:44 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:44 @base_trainer.py:216][0m Mean reward: -1102.4947744001224
[32m[0511 09:39:45 @base_main.py:38][0m --------------- Iteration 141 ---------------
[32m[0511 09:39:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7477 mins
[32m[0511 09:39:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 09:39:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 09:39:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:45 @base_main.py:47][0m 141705 total steps have happened
[32m[0511 09:39:45 @base_main.py:52][0m [avg_reward]: -1102.4947744001224
[32m[0511 09:39:45 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:45 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:45 @base_trainer.py:216][0m Mean reward: -1052.3467236248225
[32m[0511 09:39:45 @base_main.py:38][0m --------------- Iteration 142 ---------------
[32m[0511 09:39:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7603 mins
[32m[0511 09:39:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 09:39:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 09:39:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:45 @base_main.py:47][0m 142710 total steps have happened
[32m[0511 09:39:45 @base_main.py:52][0m [avg_reward]: -1052.3467236248225
[32m[0511 09:39:46 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:46 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:46 @base_trainer.py:216][0m Mean reward: -922.0825922170291
[32m[0511 09:39:46 @base_main.py:38][0m --------------- Iteration 143 ---------------
[32m[0511 09:39:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7724 mins
[32m[0511 09:39:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 09:39:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 09:39:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:46 @base_main.py:47][0m 143715 total steps have happened
[32m[0511 09:39:46 @base_main.py:52][0m [avg_reward]: -922.0825922170291
[32m[0511 09:39:46 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:46 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:46 @base_trainer.py:216][0m Mean reward: -1051.3152082969416
[32m[0511 09:39:47 @base_main.py:38][0m --------------- Iteration 144 ---------------
[32m[0511 09:39:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7846 mins
[32m[0511 09:39:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 09:39:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 09:39:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:47 @base_main.py:47][0m 144720 total steps have happened
[32m[0511 09:39:47 @base_main.py:52][0m [avg_reward]: -1051.3152082969416
[32m[0511 09:39:47 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:47 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:47 @base_trainer.py:216][0m Mean reward: -1019.0850716364532
[32m[0511 09:39:48 @base_main.py:38][0m --------------- Iteration 145 ---------------
[32m[0511 09:39:48 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7976 mins
[32m[0511 09:39:48 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 09:39:48 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 09:39:48 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:48 @base_main.py:47][0m 145725 total steps have happened
[32m[0511 09:39:48 @base_main.py:52][0m [avg_reward]: -1019.0850716364532
[32m[0511 09:39:48 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:48 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:48 @base_trainer.py:216][0m Mean reward: -797.022042830612
[32m[0511 09:39:49 @base_main.py:38][0m --------------- Iteration 146 ---------------
[32m[0511 09:39:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8105 mins
[32m[0511 09:39:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 09:39:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 09:39:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:49 @base_main.py:47][0m 146730 total steps have happened
[32m[0511 09:39:49 @base_main.py:52][0m [avg_reward]: -797.022042830612
[32m[0511 09:39:49 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:49 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:49 @base_trainer.py:216][0m Mean reward: -973.0985998081385
[32m[0511 09:39:49 @base_main.py:38][0m --------------- Iteration 147 ---------------
[32m[0511 09:39:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8231 mins
[32m[0511 09:39:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 09:39:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 09:39:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:49 @base_main.py:47][0m 147735 total steps have happened
[32m[0511 09:39:49 @base_main.py:52][0m [avg_reward]: -973.0985998081385
[32m[0511 09:39:49 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:49 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:49 @base_trainer.py:216][0m Mean reward: -1133.5242058105387
[32m[0511 09:39:50 @base_main.py:38][0m --------------- Iteration 148 ---------------
[32m[0511 09:39:50 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8359 mins
[32m[0511 09:39:50 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0511 09:39:50 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 09:39:50 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:50 @base_main.py:47][0m 148740 total steps have happened
[32m[0511 09:39:50 @base_main.py:52][0m [avg_reward]: -1133.5242058105387
[32m[0511 09:39:50 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:50 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:50 @base_trainer.py:216][0m Mean reward: -978.1082677974695
[32m[0511 09:39:51 @base_main.py:38][0m --------------- Iteration 149 ---------------
[32m[0511 09:39:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8487 mins
[32m[0511 09:39:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 09:39:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 09:39:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:51 @base_main.py:47][0m 149745 total steps have happened
[32m[0511 09:39:51 @base_main.py:52][0m [avg_reward]: -978.1082677974695
[32m[0511 09:39:51 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:51 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:51 @base_trainer.py:216][0m Mean reward: -964.9901920301345
[32m[0511 09:39:52 @base_main.py:38][0m --------------- Iteration 150 ---------------
[32m[0511 09:39:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8615 mins
[32m[0511 09:39:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0511 09:39:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 09:39:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:52 @base_main.py:47][0m 150750 total steps have happened
[32m[0511 09:39:52 @base_main.py:52][0m [avg_reward]: -964.9901920301345
[32m[0511 09:39:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:52 @base_trainer.py:216][0m Mean reward: -1099.8602614148056
[32m[0511 09:39:52 @base_main.py:38][0m --------------- Iteration 151 ---------------
[32m[0511 09:39:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8745 mins
[32m[0511 09:39:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 09:39:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 09:39:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:52 @base_main.py:47][0m 151755 total steps have happened
[32m[0511 09:39:52 @base_main.py:52][0m [avg_reward]: -1099.8602614148056
[32m[0511 09:39:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:53 @base_trainer.py:216][0m Mean reward: -1138.773967598393
[32m[0511 09:39:53 @base_main.py:38][0m --------------- Iteration 152 ---------------
[32m[0511 09:39:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8873 mins
[32m[0511 09:39:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 09:39:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 09:39:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:53 @base_main.py:47][0m 152760 total steps have happened
[32m[0511 09:39:53 @base_main.py:52][0m [avg_reward]: -1138.773967598393
[32m[0511 09:39:53 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:53 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:53 @base_trainer.py:216][0m Mean reward: -1001.705424545789
[32m[0511 09:39:54 @base_main.py:38][0m --------------- Iteration 153 ---------------
[32m[0511 09:39:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8995 mins
[32m[0511 09:39:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 09:39:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 09:39:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:54 @base_main.py:47][0m 153765 total steps have happened
[32m[0511 09:39:54 @base_main.py:52][0m [avg_reward]: -1001.705424545789
[32m[0511 09:39:54 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:54 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:54 @base_trainer.py:216][0m Mean reward: -1084.69723918904
[32m[0511 09:39:55 @base_main.py:38][0m --------------- Iteration 154 ---------------
[32m[0511 09:39:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9117 mins
[32m[0511 09:39:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 09:39:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 09:39:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:55 @base_main.py:47][0m 154770 total steps have happened
[32m[0511 09:39:55 @base_main.py:52][0m [avg_reward]: -1084.69723918904
[32m[0511 09:39:55 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:55 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:55 @base_trainer.py:216][0m Mean reward: -1068.90173518323
[32m[0511 09:39:55 @base_main.py:38][0m --------------- Iteration 155 ---------------
[32m[0511 09:39:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9241 mins
[32m[0511 09:39:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 09:39:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 09:39:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:55 @base_main.py:47][0m 155775 total steps have happened
[32m[0511 09:39:55 @base_main.py:52][0m [avg_reward]: -1068.90173518323
[32m[0511 09:39:55 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:55 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:55 @base_trainer.py:216][0m Mean reward: -1005.3901842525174
[32m[0511 09:39:56 @base_main.py:38][0m --------------- Iteration 156 ---------------
[32m[0511 09:39:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9363 mins
[32m[0511 09:39:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 09:39:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 09:39:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:56 @base_main.py:47][0m 156780 total steps have happened
[32m[0511 09:39:56 @base_main.py:52][0m [avg_reward]: -1005.3901842525174
[32m[0511 09:39:56 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:56 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:56 @base_trainer.py:216][0m Mean reward: -1157.6230911973823
[32m[0511 09:39:57 @base_main.py:38][0m --------------- Iteration 157 ---------------
[32m[0511 09:39:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9491 mins
[32m[0511 09:39:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 09:39:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 09:39:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:57 @base_main.py:47][0m 157785 total steps have happened
[32m[0511 09:39:57 @base_main.py:52][0m [avg_reward]: -1157.6230911973823
[32m[0511 09:39:57 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:57 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:57 @base_trainer.py:216][0m Mean reward: -1138.5426880959774
[32m[0511 09:39:58 @base_main.py:38][0m --------------- Iteration 158 ---------------
[32m[0511 09:39:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9611 mins
[32m[0511 09:39:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 09:39:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 09:39:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:58 @base_main.py:47][0m 158790 total steps have happened
[32m[0511 09:39:58 @base_main.py:52][0m [avg_reward]: -1138.5426880959774
[32m[0511 09:39:58 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:58 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:58 @base_trainer.py:216][0m Mean reward: -1043.9442265193475
[32m[0511 09:39:58 @base_main.py:38][0m --------------- Iteration 159 ---------------
[32m[0511 09:39:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9735 mins
[32m[0511 09:39:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0018 mins
[32m[0511 09:39:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 09:39:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:58 @base_main.py:47][0m 159795 total steps have happened
[32m[0511 09:39:58 @base_main.py:52][0m [avg_reward]: -1043.9442265193475
[32m[0511 09:39:58 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:58 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:58 @base_trainer.py:216][0m Mean reward: -975.667624064536
[32m[0511 09:39:59 @base_main.py:38][0m --------------- Iteration 160 ---------------
[32m[0511 09:39:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9856 mins
[32m[0511 09:39:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 09:39:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 09:39:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:39:59 @base_main.py:47][0m 160800 total steps have happened
[32m[0511 09:39:59 @base_main.py:52][0m [avg_reward]: -975.667624064536
[32m[0511 09:39:59 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:39:59 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:39:59 @base_trainer.py:216][0m Mean reward: -1083.0652330978457
[32m[0511 09:40:00 @base_main.py:38][0m --------------- Iteration 161 ---------------
[32m[0511 09:40:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9981 mins
[32m[0511 09:40:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 09:40:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0511 09:40:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:40:00 @base_main.py:47][0m 161805 total steps have happened
[32m[0511 09:40:00 @base_main.py:52][0m [avg_reward]: -1083.0652330978457
[32m[0511 09:40:00 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:40:00 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:40:00 @base_trainer.py:216][0m Mean reward: -1163.5466745760275
[32m[0511 09:40:00 @base_main.py:38][0m --------------- Iteration 162 ---------------
[32m[0511 09:40:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0094 mins
[32m[0511 09:40:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 09:40:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 09:40:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:40:00 @base_main.py:47][0m 162810 total steps have happened
[32m[0511 09:40:00 @base_main.py:52][0m [avg_reward]: -1163.5466745760275
[32m[0511 09:40:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:40:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:40:01 @base_trainer.py:216][0m Mean reward: -1113.6489291330731
[32m[0511 09:40:01 @base_main.py:38][0m --------------- Iteration 163 ---------------
[32m[0511 09:40:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0217 mins
[32m[0511 09:40:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 09:40:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 09:40:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:40:01 @base_main.py:47][0m 163815 total steps have happened
[32m[0511 09:40:01 @base_main.py:52][0m [avg_reward]: -1113.6489291330731
[32m[0511 09:40:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:40:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:40:01 @base_trainer.py:216][0m Mean reward: -905.9952677843557
[32m[0511 09:40:02 @base_main.py:38][0m --------------- Iteration 164 ---------------
[32m[0511 09:40:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0339 mins
[32m[0511 09:40:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 09:40:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 09:40:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:40:02 @base_main.py:47][0m 164820 total steps have happened
[32m[0511 09:40:02 @base_main.py:52][0m [avg_reward]: -905.9952677843557
[32m[0511 09:40:02 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:40:02 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:40:02 @base_trainer.py:216][0m Mean reward: -850.392681389672
[32m[0511 09:40:03 @base_main.py:38][0m --------------- Iteration 165 ---------------
[32m[0511 09:40:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0465 mins
[32m[0511 09:40:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 09:40:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 09:40:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:40:03 @base_main.py:47][0m 165825 total steps have happened
[32m[0511 09:40:03 @base_main.py:52][0m [avg_reward]: -850.392681389672
[32m[0511 09:40:03 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:40:03 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:40:03 @base_trainer.py:216][0m Mean reward: -969.0196320538214
[32m[0511 09:40:03 @base_main.py:38][0m --------------- Iteration 166 ---------------
[32m[0511 09:40:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0594 mins
[32m[0511 09:40:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 09:40:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 09:40:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:40:03 @base_main.py:47][0m 166830 total steps have happened
[32m[0511 09:40:03 @base_main.py:52][0m [avg_reward]: -969.0196320538214
[32m[0511 09:40:04 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:40:04 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:40:04 @base_trainer.py:216][0m Mean reward: -934.2244251949166
[32m[0511 09:40:04 @base_main.py:38][0m --------------- Iteration 167 ---------------
[32m[0511 09:40:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0720 mins
[32m[0511 09:40:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 09:40:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 09:40:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:40:04 @base_main.py:47][0m 167835 total steps have happened
[32m[0511 09:40:04 @base_main.py:52][0m [avg_reward]: -934.2244251949166
[32m[0511 09:40:04 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:40:04 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:40:04 @base_trainer.py:216][0m Mean reward: -1052.6186988793245
[32m[0511 09:40:05 @base_main.py:38][0m --------------- Iteration 168 ---------------
[32m[0511 09:40:05 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0840 mins
[32m[0511 09:40:05 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 09:40:05 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 09:40:05 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:40:05 @base_main.py:47][0m 168840 total steps have happened
[32m[0511 09:40:05 @base_main.py:52][0m [avg_reward]: -1052.6186988793245
[32m[0511 09:40:05 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:40:05 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:40:05 @base_trainer.py:216][0m Mean reward: -993.5674334019444
[32m[0511 09:40:06 @base_main.py:38][0m --------------- Iteration 169 ---------------
[32m[0511 09:40:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0961 mins
[32m[0511 09:40:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 09:40:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 09:40:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:40:06 @base_main.py:47][0m 169845 total steps have happened
[32m[0511 09:40:06 @base_main.py:52][0m [avg_reward]: -993.5674334019444
[32m[0511 09:40:06 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:40:06 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:40:06 @base_trainer.py:216][0m Mean reward: -968.7143886285161
[32m[0511 09:40:06 @base_main.py:38][0m --------------- Iteration 170 ---------------
[32m[0511 09:40:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1090 mins
[32m[0511 09:40:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 09:40:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 09:40:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:40:06 @base_main.py:47][0m 170850 total steps have happened
[32m[0511 09:40:06 @base_main.py:52][0m [avg_reward]: -968.7143886285161
[32m[0511 09:40:07 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:40:07 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:40:07 @base_trainer.py:216][0m Mean reward: -1075.1449316206263
[32m[0511 09:40:07 @base_main.py:38][0m --------------- Iteration 171 ---------------
[32m[0511 09:40:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1210 mins
[32m[0511 09:40:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 09:40:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 09:40:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:40:07 @base_main.py:47][0m 171855 total steps have happened
[32m[0511 09:40:07 @base_main.py:52][0m [avg_reward]: -1075.1449316206263
[32m[0511 09:40:07 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:40:07 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:40:07 @base_trainer.py:216][0m Mean reward: -1042.4107210476134
[32m[0511 09:40:08 @base_main.py:38][0m --------------- Iteration 172 ---------------
[32m[0511 09:40:08 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1336 mins
[32m[0511 09:40:08 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 09:40:08 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 09:40:08 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:40:08 @base_main.py:47][0m 172860 total steps have happened
[32m[0511 09:40:08 @base_main.py:52][0m [avg_reward]: -1042.4107210476134
[32m[0511 09:40:08 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:40:08 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:40:08 @base_trainer.py:216][0m Mean reward: -1022.1839287265273
[32m[0511 09:40:09 @base_main.py:38][0m --------------- Iteration 173 ---------------
[32m[0511 09:40:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1463 mins
[32m[0511 09:40:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 09:40:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 09:40:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:40:09 @base_main.py:47][0m 173865 total steps have happened
[32m[0511 09:40:09 @base_main.py:52][0m [avg_reward]: -1022.1839287265273
[32m[0511 09:40:09 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:40:09 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:40:09 @base_trainer.py:216][0m Mean reward: -971.4721687543863
[32m[0511 09:40:09 @base_main.py:38][0m --------------- Iteration 174 ---------------
[32m[0511 09:40:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1589 mins
[32m[0511 09:40:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 09:40:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 09:40:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:40:09 @base_main.py:47][0m 174870 total steps have happened
[32m[0511 09:40:09 @base_main.py:52][0m [avg_reward]: -971.4721687543863
[32m[0511 09:40:10 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:40:10 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:40:10 @base_trainer.py:216][0m Mean reward: -891.3023346036559
[32m[0511 09:40:10 @base_main.py:38][0m --------------- Iteration 175 ---------------
[32m[0511 09:40:10 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1715 mins
[32m[0511 09:40:10 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0511 09:40:10 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 09:40:10 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:40:10 @base_main.py:47][0m 175875 total steps have happened
[32m[0511 09:40:10 @base_main.py:52][0m [avg_reward]: -891.3023346036559
[32m[0511 09:40:10 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:40:10 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:40:10 @base_trainer.py:216][0m Mean reward: -994.8012196528932
[32m[0511 09:40:11 @base_main.py:38][0m --------------- Iteration 176 ---------------
[32m[0511 09:40:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1845 mins
[32m[0511 09:40:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 09:40:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 09:40:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:40:11 @base_main.py:47][0m 176880 total steps have happened
[32m[0511 09:40:11 @base_main.py:52][0m [avg_reward]: -994.8012196528932
[32m[0511 09:40:11 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:40:11 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:40:11 @base_trainer.py:216][0m Mean reward: -1001.4807158555726
[32m[0511 09:40:12 @base_main.py:38][0m --------------- Iteration 177 ---------------
[32m[0511 09:40:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1971 mins
[32m[0511 09:40:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 09:40:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 09:40:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:40:12 @base_main.py:47][0m 177885 total steps have happened
[32m[0511 09:40:12 @base_main.py:52][0m [avg_reward]: -1001.4807158555726
[32m[0511 09:40:12 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:40:12 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:40:12 @base_trainer.py:216][0m Mean reward: -985.8965336109013
[32m[0511 09:40:12 @base_main.py:38][0m --------------- Iteration 178 ---------------
[32m[0511 09:40:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2098 mins
[32m[0511 09:40:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 09:40:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 09:40:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0511 09:40:12 @base_main.py:47][0m 178890 total steps have happened
[32m[0511 09:40:12 @base_main.py:52][0m [avg_reward]: -985.8965336109013
[32m[0511 09:40:13 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:40:13 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:40:13 @base_trainer.py:216][0m Mean reward: -979.4211802844411
[32m[0511 09:40:13 @base_main.py:38][0m --------------- Iteration 179 ---------------
[32m[0511 09:40:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2223 mins
[32m[0511 09:40:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 09:40:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 09:40:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:40:13 @base_main.py:47][0m 179895 total steps have happened
[32m[0511 09:40:13 @base_main.py:52][0m [avg_reward]: -979.4211802844411
[32m[0511 09:40:13 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:40:13 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:40:13 @base_trainer.py:216][0m Mean reward: -867.5641663808686
[32m[0511 09:40:14 @base_main.py:38][0m --------------- Iteration 180 ---------------
[32m[0511 09:40:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2343 mins
[32m[0511 09:40:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 09:40:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 09:40:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:40:14 @base_main.py:47][0m 180900 total steps have happened
[32m[0511 09:40:14 @base_main.py:52][0m [avg_reward]: -867.5641663808686
[32m[0511 09:40:14 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:40:14 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:40:14 @base_trainer.py:216][0m Mean reward: -847.506301617814
[32m[0511 09:40:15 @base_main.py:38][0m --------------- Iteration 181 ---------------
[32m[0511 09:40:15 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2465 mins
[32m[0511 09:40:15 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 09:40:15 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 09:40:15 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:40:15 @base_main.py:47][0m 181905 total steps have happened
[32m[0511 09:40:15 @base_main.py:52][0m [avg_reward]: -847.506301617814
[32m[0511 09:40:15 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:40:15 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:40:15 @base_trainer.py:216][0m Mean reward: -847.611108360438
[32m[0511 09:40:15 @base_main.py:38][0m --------------- Iteration 182 ---------------
[32m[0511 09:40:15 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2590 mins
[32m[0511 09:40:15 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 09:40:15 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 09:40:15 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:40:15 @base_main.py:47][0m 182910 total steps have happened
[32m[0511 09:40:15 @base_main.py:52][0m [avg_reward]: -847.611108360438
[32m[0511 09:40:16 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:40:16 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:40:16 @base_trainer.py:216][0m Mean reward: -820.9897953193451
[32m[0511 09:40:16 @base_main.py:38][0m --------------- Iteration 183 ---------------
[32m[0511 09:40:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2713 mins
[32m[0511 09:40:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 09:40:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 09:40:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:40:16 @base_main.py:47][0m 183915 total steps have happened
[32m[0511 09:40:16 @base_main.py:52][0m [avg_reward]: -820.9897953193451
[32m[0511 09:40:16 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:40:16 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:40:16 @base_trainer.py:216][0m Mean reward: -914.0375061899152
[32m[0511 09:40:17 @base_main.py:38][0m --------------- Iteration 184 ---------------
[32m[0511 09:40:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2839 mins
[32m[0511 09:40:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 09:40:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 09:40:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0511 09:40:17 @base_main.py:47][0m 184920 total steps have happened
[32m[0511 09:40:17 @base_main.py:52][0m [avg_reward]: -914.0375061899152
[32m[0511 09:40:17 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:40:17 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:40:17 @base_trainer.py:216][0m Mean reward: -861.1525875366067
[32m[0511 09:40:18 @base_main.py:38][0m --------------- Iteration 185 ---------------
[32m[0511 09:40:18 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2961 mins
[32m[0511 09:40:18 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 09:40:18 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0511 09:40:18 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:40:18 @base_main.py:47][0m 185925 total steps have happened
[32m[0511 09:40:18 @base_main.py:52][0m [avg_reward]: -861.1525875366067
[32m[0511 09:40:18 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:40:18 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:40:18 @base_trainer.py:216][0m Mean reward: -706.9361434385585
[32m[0511 09:40:18 @base_main.py:38][0m --------------- Iteration 186 ---------------
[32m[0511 09:40:18 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3082 mins
[32m[0511 09:40:18 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 09:40:18 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 09:40:18 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0511 09:40:18 @base_main.py:47][0m 186930 total steps have happened
[32m[0511 09:40:18 @base_main.py:52][0m [avg_reward]: -706.9361434385585
[32m[0511 09:40:18 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:40:18 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:40:18 @base_trainer.py:216][0m Mean reward: -906.1915938657388
[32m[0511 09:40:19 @base_main.py:38][0m --------------- Iteration 187 ---------------
[32m[0511 09:40:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3200 mins
[32m[0511 09:40:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 09:40:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 09:40:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:40:19 @base_main.py:47][0m 187935 total steps have happened
[32m[0511 09:40:19 @base_main.py:52][0m [avg_reward]: -906.1915938657388
[32m[0511 09:40:19 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:40:19 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:40:19 @base_trainer.py:216][0m Mean reward: -816.6939308705159
[32m[0511 09:40:20 @base_main.py:38][0m --------------- Iteration 188 ---------------
[32m[0511 09:40:20 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3320 mins
[32m[0511 09:40:20 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 09:40:20 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 09:40:20 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:40:20 @base_main.py:47][0m 188940 total steps have happened
[32m[0511 09:40:20 @base_main.py:52][0m [avg_reward]: -816.6939308705159
[32m[0511 09:40:20 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:40:20 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:40:20 @base_trainer.py:216][0m Mean reward: -830.0141629678004
[32m[0511 09:40:21 @base_main.py:38][0m --------------- Iteration 189 ---------------
[32m[0511 09:40:21 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3449 mins
[32m[0511 09:40:21 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 09:40:21 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 09:40:21 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:40:21 @base_main.py:47][0m 189945 total steps have happened
[32m[0511 09:40:21 @base_main.py:52][0m [avg_reward]: -830.0141629678004
[32m[0511 09:40:21 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:40:21 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:40:21 @base_trainer.py:216][0m Mean reward: -863.7164629212155
[32m[0511 09:40:21 @base_main.py:38][0m --------------- Iteration 190 ---------------
[32m[0511 09:40:21 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3575 mins
[32m[0511 09:40:21 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 09:40:21 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 09:40:21 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:40:21 @base_main.py:47][0m 190950 total steps have happened
[32m[0511 09:40:21 @base_main.py:52][0m [avg_reward]: -863.7164629212155
[32m[0511 09:40:21 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:40:21 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:40:21 @base_trainer.py:216][0m Mean reward: -749.5435344710592
[32m[0511 09:40:22 @base_main.py:38][0m --------------- Iteration 191 ---------------
[32m[0511 09:40:22 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3702 mins
[32m[0511 09:40:22 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 09:40:22 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0511 09:40:22 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:40:22 @base_main.py:47][0m 191955 total steps have happened
[32m[0511 09:40:22 @base_main.py:52][0m [avg_reward]: -749.5435344710592
[32m[0511 09:40:22 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:40:22 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:40:22 @base_trainer.py:216][0m Mean reward: -1016.841139598912
[32m[0511 09:40:23 @base_main.py:38][0m --------------- Iteration 192 ---------------
[32m[0511 09:40:23 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3820 mins
[32m[0511 09:40:23 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 09:40:23 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 09:40:23 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:40:23 @base_main.py:47][0m 192960 total steps have happened
[32m[0511 09:40:23 @base_main.py:52][0m [avg_reward]: -1016.841139598912
[32m[0511 09:40:23 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:40:23 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:40:23 @base_trainer.py:216][0m Mean reward: -930.2986491820109
[32m[0511 09:40:24 @base_main.py:38][0m --------------- Iteration 193 ---------------
[32m[0511 09:40:24 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3942 mins
[32m[0511 09:40:24 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0511 09:40:24 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 09:40:24 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:40:24 @base_main.py:47][0m 193965 total steps have happened
[32m[0511 09:40:24 @base_main.py:52][0m [avg_reward]: -930.2986491820109
[32m[0511 09:40:24 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:40:24 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:40:24 @base_trainer.py:216][0m Mean reward: -686.5223962947563
[32m[0511 09:40:24 @base_main.py:38][0m --------------- Iteration 194 ---------------
[32m[0511 09:40:24 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4070 mins
[32m[0511 09:40:24 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0018 mins
[32m[0511 09:40:24 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0511 09:40:24 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:40:24 @base_main.py:47][0m 194970 total steps have happened
[32m[0511 09:40:24 @base_main.py:52][0m [avg_reward]: -686.5223962947563
[32m[0511 09:40:24 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:40:24 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:40:24 @base_trainer.py:216][0m Mean reward: -882.7478575468524
[32m[0511 09:40:25 @base_main.py:38][0m --------------- Iteration 195 ---------------
[32m[0511 09:40:25 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4184 mins
[32m[0511 09:40:25 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 09:40:25 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 09:40:25 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:40:25 @base_main.py:47][0m 195975 total steps have happened
[32m[0511 09:40:25 @base_main.py:52][0m [avg_reward]: -882.7478575468524
[32m[0511 09:40:25 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:40:25 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:40:25 @base_trainer.py:216][0m Mean reward: -1098.5035055909834
[32m[0511 09:40:26 @base_main.py:38][0m --------------- Iteration 196 ---------------
[32m[0511 09:40:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4307 mins
[32m[0511 09:40:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 09:40:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 09:40:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:40:26 @base_main.py:47][0m 196980 total steps have happened
[32m[0511 09:40:26 @base_main.py:52][0m [avg_reward]: -1098.5035055909834
[32m[0511 09:40:26 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:40:26 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:40:26 @base_trainer.py:216][0m Mean reward: -894.8543240364181
[32m[0511 09:40:26 @base_main.py:38][0m --------------- Iteration 197 ---------------
[32m[0511 09:40:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4427 mins
[32m[0511 09:40:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 09:40:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 09:40:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:40:26 @base_main.py:47][0m 197985 total steps have happened
[32m[0511 09:40:26 @base_main.py:52][0m [avg_reward]: -894.8543240364181
[32m[0511 09:40:27 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:40:27 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:40:27 @base_trainer.py:216][0m Mean reward: -772.3137831989632
[32m[0511 09:40:27 @base_main.py:38][0m --------------- Iteration 198 ---------------
[32m[0511 09:40:27 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4555 mins
[32m[0511 09:40:27 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0511 09:40:27 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 09:40:27 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:40:27 @base_main.py:47][0m 198990 total steps have happened
[32m[0511 09:40:27 @base_main.py:52][0m [avg_reward]: -772.3137831989632
[32m[0511 09:40:27 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:40:27 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:40:27 @base_trainer.py:216][0m Mean reward: -966.3195493561337
[32m[0511 09:40:28 @base_main.py:38][0m --------------- Iteration 199 ---------------
[32m[0511 09:40:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4680 mins
[32m[0511 09:40:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 09:40:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 09:40:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:40:28 @base_main.py:47][0m 199995 total steps have happened
[32m[0511 09:40:28 @base_main.py:52][0m [avg_reward]: -966.3195493561337
[32m[0511 09:40:28 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 09:40:28 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:40:28 @base_trainer.py:216][0m Mean reward: -892.2213737568381
[32m[0511 09:40:29 @base_main.py:38][0m --------------- Iteration 200 ---------------
[32m[0511 09:40:29 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4802 mins
[32m[0511 09:40:29 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 09:40:29 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 09:40:29 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 09:40:29 @base_main.py:47][0m 201000 total steps have happened
[32m[0511 09:40:29 @base_main.py:52][0m [avg_reward]: -892.2213737568381
[32m[0511 09:40:29 @base_worker.py:111][0m kill message for worker 5
[32m[0511 09:40:29 @base_worker.py:111][0m kill message for worker 6
[32m[0511 09:40:29 @base_worker.py:111][0m kill message for worker 3
[32m[0511 09:40:29 @base_worker.py:111][0m kill message for worker 0
[32m[0511 09:40:29 @base_worker.py:111][0m kill message for worker 19
[32m[0511 09:40:29 @base_worker.py:111][0m kill message for worker 18
[32m[0511 09:40:29 @base_worker.py:111][0m kill message for worker 12
[32m[0511 09:40:29 @base_worker.py:111][0m kill message for worker 13
[32m[0511 09:40:29 @base_worker.py:111][0m kill message for worker 8
[32m[0511 09:40:29 @base_worker.py:111][0m kill message for worker 2
[32m[0511 09:40:29 @base_worker.py:111][0m kill message for worker 15
[32m[0511 09:40:29 @base_worker.py:111][0m kill message for worker 9
[32m[0511 09:40:29 @base_worker.py:111][0m kill message for worker 11
[32m[0511 09:40:29 @base_worker.py:111][0m kill message for worker 10
[32m[0511 09:40:29 @base_worker.py:111][0m kill message for worker 1
[32m[0511 09:40:29 @base_worker.py:111][0m kill message for worker 17
[32m[0511 09:40:29 @base_worker.py:111][0m kill message for worker 14
[32m[0511 09:40:29 @base_worker.py:111][0m kill message for worker 7
[32m[0511 09:40:29 @base_worker.py:111][0m kill message for worker 16
[32m[0511 09:40:29 @base_worker.py:111][0m kill message for worker 4
