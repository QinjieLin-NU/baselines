[32m[0513 17:32:27 @logger.py:103][0m Log file set to /root/mbbl/log/mbmfrl-rsgym_swingup_hr_80_mbmf_gym_swingup_ppo_seed_2341.log/mbmfrl-rsgym_swingup_hr_80_mbmf_gym_swingup_ppo_seed_2341.log
[32m[0513 17:32:27 @mbmf_main.py:23][0m Training starts at /root/mbbl
[32m[0513 17:32:27 @base_worker.py:45][0m Worker 0 online
[32m[0513 17:32:29 @base_worker.py:45][0m Worker 1 online
[32m[0513 17:32:29 @base_worker.py:45][0m Worker 2 online
[32m[0513 17:32:29 @base_worker.py:45][0m Worker 3 online
[32m[0513 17:32:29 @base_worker.py:45][0m Worker 4 online
[32m[0513 17:32:29 @base_worker.py:45][0m Worker 5 online
[32m[0513 17:32:29 @base_worker.py:45][0m Worker 6 online
[32m[0513 17:32:29 @base_worker.py:45][0m Worker 7 online
[32m[0513 17:32:29 @base_worker.py:45][0m Worker 8 online
[32m[0513 17:32:29 @base_worker.py:45][0m Worker 9 online
[32m[0513 17:32:29 @base_worker.py:45][0m Worker 10 online
[32m[0513 17:32:29 @base_worker.py:45][0m Worker 11 online
[32m[0513 17:32:29 @base_worker.py:45][0m Worker 12 online
[32m[0513 17:32:29 @base_worker.py:45][0m Worker 13 online
[32m[0513 17:32:29 @base_worker.py:45][0m Worker 14 online
[32m[0513 17:32:29 @base_worker.py:45][0m Worker 15 online
[32m[0513 17:32:29 @base_worker.py:45][0m Worker 16 online
[32m[0513 17:32:29 @base_worker.py:45][0m Worker 17 online
[32m[0513 17:32:29 @base_worker.py:45][0m Worker 18 online
[32m[0513 17:32:29 @base_worker.py:45][0m Worker 19 online
[32m[0513 17:32:31 @base_trainer.py:152][0m Trainer maintains [1] policy network
[32m[0513 17:32:31 @base_trainer.py:152][0m Trainer maintains [1] dynamics network
[32m[0513 17:32:31 @base_trainer.py:152][0m Trainer maintains [1] reward network
[32m[0513 17:32:32 @mbmf_main.py:46][0m Generating 1000 random timesteps
[32m[0513 17:32:32 @mbmf_sampler.py:39][0m done with episode
[32m[0513 17:32:32 @mbmf_sampler.py:39][0m done with episode
[32m[0513 17:32:32 @mbmf_sampler.py:50][0m 1002 timesteps from 2 episodes collected
[32m[0513 17:32:32 @base_trainer.py:216][0m Mean reward: -282.19164990005675
[32m[0513 17:32:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5009628534317017, Train Loss: 0.5107177495956421
[32m[0513 17:32:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5009865760803223, Train Loss: 0.5107112526893616
[32m[0513 17:32:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5010101199150085, Train Loss: 0.5107049942016602
[32m[0513 17:32:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5010334253311157, Train Loss: 0.5106988549232483
[32m[0513 17:32:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5010561347007751, Train Loss: 0.5106929540634155
[32m[0513 17:32:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5010785460472107, Train Loss: 0.5106870532035828
[32m[0513 17:32:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5011006593704224, Train Loss: 0.5106813311576843
[32m[0513 17:32:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5011226534843445, Train Loss: 0.5106756687164307
[32m[0513 17:32:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5011445879936218, Train Loss: 0.5106700658798218
[32m[0513 17:32:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5011666417121887, Train Loss: 0.5106645822525024
[32m[0513 17:32:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5011888742446899, Train Loss: 0.5106592178344727
[32m[0513 17:32:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5012111067771912, Train Loss: 0.5106539130210876
[32m[0513 17:32:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5012336373329163, Train Loss: 0.510648787021637
[32m[0513 17:32:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5012562870979309, Train Loss: 0.5106436610221863
[32m[0513 17:32:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5012791752815247, Train Loss: 0.5106387734413147
[32m[0513 17:32:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5013020634651184, Train Loss: 0.5106339454650879
[32m[0513 17:32:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5013250112533569, Train Loss: 0.5106292366981506
[32m[0513 17:32:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5013478398323059, Train Loss: 0.5106245875358582
[32m[0513 17:32:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5013705492019653, Train Loss: 0.5106200575828552
[32m[0513 17:32:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.50139319896698, Train Loss: 0.5106156468391418
[32m[0513 17:32:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5014156699180603, Train Loss: 0.5106112957000732
[32m[0513 17:32:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5014379620552063, Train Loss: 0.510607123374939
[32m[0513 17:32:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5014600157737732, Train Loss: 0.5106030106544495
[32m[0513 17:32:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5014818906784058, Train Loss: 0.5105989575386047
[32m[0513 17:32:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5015037655830383, Train Loss: 0.5105951428413391
[32m[0513 17:32:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5015255808830261, Train Loss: 0.5105913281440735
[32m[0513 17:32:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5015472173690796, Train Loss: 0.5105875730514526
[32m[0513 17:32:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5015688538551331, Train Loss: 0.5105840563774109
[32m[0513 17:32:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5015904903411865, Train Loss: 0.5105805397033691
[32m[0513 17:32:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.5016120672225952, Train Loss: 0.5105771422386169
[32m[0513 17:32:35 @base_main.py:38][0m --------------- Iteration 1 ---------------
[32m[0513 17:32:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0000 mins
[32m[0513 17:32:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0039 mins
[32m[0513 17:32:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0291 mins
[32m[0513 17:32:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0083 mins
[32m[0513 17:32:35 @base_main.py:47][0m 1002 total steps have happened
[32m[0513 17:32:35 @base_main.py:52][0m [avg_reward]: -282.19164990005675
[32m[0513 17:32:35 @base_main.py:52][0m [update_op]: None
[32m[0513 17:32:35 @base_main.py:52][0m [train_loss]: 0.5105771422386169
[32m[0513 17:32:35 @base_main.py:52][0m [val_loss]: 0.5016120672225952
[32m[0513 17:32:35 @base_main.py:52][0m [avg_train_loss]: 0.5105771422386169
