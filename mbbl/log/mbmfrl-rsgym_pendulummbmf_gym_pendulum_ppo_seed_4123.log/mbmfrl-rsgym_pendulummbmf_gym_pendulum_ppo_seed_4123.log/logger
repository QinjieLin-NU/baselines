[32m[0511 09:40:31 @logger.py:103][0m Log file set to /root/mbbl/log/mbmfrl-rsgym_pendulummbmf_gym_pendulum_ppo_seed_4123.log/mbmfrl-rsgym_pendulummbmf_gym_pendulum_ppo_seed_4123.log
[32m[0511 09:40:31 @mbmf_main.py:23][0m Training starts at /root/mbbl
[32m[0511 09:40:31 @base_worker.py:45][0m Worker 0 online
[32m[0511 09:40:31 @base_worker.py:45][0m Worker 1 online
[32m[0511 09:40:31 @base_worker.py:45][0m Worker 2 online
[32m[0511 09:40:31 @base_worker.py:45][0m Worker 3 online
[32m[0511 09:40:31 @base_worker.py:45][0m Worker 4 online
[32m[0511 09:40:31 @base_worker.py:45][0m Worker 5 online
[32m[0511 09:40:31 @base_worker.py:45][0m Worker 6 online
[32m[0511 09:40:31 @base_worker.py:45][0m Worker 7 online
[32m[0511 09:40:31 @base_worker.py:45][0m Worker 8 online
[32m[0511 09:40:31 @base_worker.py:45][0m Worker 9 online
[32m[0511 09:40:31 @base_worker.py:45][0m Worker 10 online
[32m[0511 09:40:31 @base_worker.py:45][0m Worker 11 online
[32m[0511 09:40:31 @base_worker.py:45][0m Worker 12 online
[32m[0511 09:40:31 @base_worker.py:45][0m Worker 13 online
[32m[0511 09:40:31 @base_worker.py:45][0m Worker 14 online
[32m[0511 09:40:31 @base_worker.py:45][0m Worker 15 online
[32m[0511 09:40:31 @base_worker.py:45][0m Worker 16 online
[32m[0511 09:40:31 @base_worker.py:45][0m Worker 17 online
[32m[0511 09:40:31 @base_worker.py:45][0m Worker 18 online
[32m[0511 09:40:31 @base_worker.py:45][0m Worker 19 online
[32m[0511 09:40:32 @base_trainer.py:152][0m Trainer maintains [1] policy network
[32m[0511 09:40:32 @base_trainer.py:152][0m Trainer maintains [1] dynamics network
[32m[0511 09:40:32 @base_trainer.py:152][0m Trainer maintains [1] reward network
[32m[0511 09:40:33 @mbmf_main.py:46][0m Generating 1000 random timesteps
[32m[0511 09:40:33 @mbmf_sampler.py:39][0m done with episode
[32m[0511 09:40:33 @mbmf_sampler.py:39][0m done with episode
[32m[0511 09:40:33 @mbmf_sampler.py:39][0m done with episode
[32m[0511 09:40:33 @mbmf_sampler.py:39][0m done with episode
[32m[0511 09:40:33 @mbmf_sampler.py:39][0m done with episode
[32m[0511 09:40:33 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:40:33 @base_trainer.py:216][0m Mean reward: -1364.2336563612255
[32m[0511 09:40:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9974661469459534, Train Loss: 0.9811155796051025
[32m[0511 09:40:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9974634647369385, Train Loss: 0.9811004996299744
[32m[0511 09:40:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9974609017372131, Train Loss: 0.9810855388641357
[32m[0511 09:40:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9974585175514221, Train Loss: 0.9810708165168762
[32m[0511 09:40:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9974563121795654, Train Loss: 0.9810563325881958
[32m[0511 09:40:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9974543452262878, Train Loss: 0.9810419678688049
[32m[0511 09:40:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.997452437877655, Train Loss: 0.9810278415679932
[32m[0511 09:40:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9974508881568909, Train Loss: 0.98101407289505
[32m[0511 09:40:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9974492788314819, Train Loss: 0.9810001850128174
[32m[0511 09:40:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9974479675292969, Train Loss: 0.9809865951538086
[32m[0511 09:40:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9974467754364014, Train Loss: 0.9809733033180237
[32m[0511 09:40:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9974459409713745, Train Loss: 0.9809601306915283
[32m[0511 09:40:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9974449872970581, Train Loss: 0.9809472560882568
[32m[0511 09:40:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9974443912506104, Train Loss: 0.9809346795082092
[32m[0511 09:40:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9974439740180969, Train Loss: 0.9809221029281616
[32m[0511 09:40:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9974437355995178, Train Loss: 0.9809098243713379
[32m[0511 09:40:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9974435567855835, Train Loss: 0.9808977246284485
[32m[0511 09:40:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9974435567855835, Train Loss: 0.980885922908783
[32m[0511 09:40:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.997443675994873, Train Loss: 0.980874240398407
[32m[0511 09:40:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9974440336227417, Train Loss: 0.9808628559112549
[32m[0511 09:40:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9974443912506104, Train Loss: 0.9808516502380371
[32m[0511 09:40:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9974449276924133, Train Loss: 0.9808406829833984
[32m[0511 09:40:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.997445821762085, Train Loss: 0.9808298945426941
[32m[0511 09:40:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.997446596622467, Train Loss: 0.9808193445205688
[32m[0511 09:40:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9974477887153625, Train Loss: 0.9808090925216675
[32m[0511 09:40:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9974488019943237, Train Loss: 0.9807989001274109
[32m[0511 09:40:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9974501132965088, Train Loss: 0.9807890057563782
[32m[0511 09:40:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9974514842033386, Train Loss: 0.9807792901992798
[32m[0511 09:40:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9974530935287476, Train Loss: 0.9807697534561157
[32m[0511 09:40:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9974547624588013, Train Loss: 0.9807605147361755
[32m[0511 09:40:34 @base_main.py:38][0m --------------- Iteration 1 ---------------
[32m[0511 09:40:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0000 mins
[32m[0511 09:40:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 09:40:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0110 mins
[32m[0511 09:40:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0043 mins
[32m[0511 09:40:34 @base_main.py:47][0m 1005 total steps have happened
[32m[0511 09:40:34 @base_main.py:52][0m [avg_reward]: -1364.2336563612255
[32m[0511 09:40:34 @base_main.py:52][0m [update_op]: None
[32m[0511 09:40:34 @base_main.py:52][0m [train_loss]: 0.9807605147361755
[32m[0511 09:40:34 @base_main.py:52][0m [val_loss]: 0.9974547624588013
[32m[0511 09:40:34 @base_main.py:52][0m [avg_train_loss]: 0.9807605147361755
[32m[0511 09:42:44 @mbmf_sampler.py:39][0m done with episode
[32m[0511 09:44:53 @mbmf_sampler.py:39][0m done with episode
[32m[0511 09:47:00 @mbmf_sampler.py:39][0m done with episode
[32m[0511 09:49:08 @mbmf_sampler.py:39][0m done with episode
[32m[0511 09:51:16 @mbmf_sampler.py:39][0m done with episode
[32m[0511 09:51:16 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0511 09:51:16 @base_trainer.py:216][0m Mean reward: -1388.516640762186
[32m[0511 09:51:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8344576358795166, Train Loss: 0.998767077922821
[32m[0511 09:51:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8344636559486389, Train Loss: 0.998776376247406
[32m[0511 09:51:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8344686031341553, Train Loss: 0.9987779259681702
[32m[0511 09:51:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8344724774360657, Train Loss: 0.998773992061615
[32m[0511 09:51:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8344755172729492, Train Loss: 0.9987664222717285
[32m[0511 09:51:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8344780802726746, Train Loss: 0.9987564086914062
[32m[0511 09:51:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8344802260398865, Train Loss: 0.9987451434135437
[32m[0511 09:51:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8344823718070984, Train Loss: 0.99873286485672
[32m[0511 09:51:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8344844579696655, Train Loss: 0.998720645904541
[32m[0511 09:51:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8344867825508118, Train Loss: 0.9987084269523621
[32m[0511 09:51:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8344892263412476, Train Loss: 0.9986966252326965
[32m[0511 09:51:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8344919681549072, Train Loss: 0.998685359954834
[32m[0511 09:51:16 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8344948887825012, Train Loss: 0.9986745715141296
[32m[0511 09:51:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8344981074333191, Train Loss: 0.9986646771430969
[32m[0511 09:51:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8345015645027161, Train Loss: 0.9986553192138672
[32m[0511 09:51:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8345053195953369, Train Loss: 0.9986466765403748
[32m[0511 09:51:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8345092535018921, Train Loss: 0.9986386299133301
[32m[0511 09:51:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8345131874084473, Train Loss: 0.9986311793327332
[32m[0511 09:51:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8345174193382263, Train Loss: 0.9986245036125183
[32m[0511 09:51:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8345218300819397, Train Loss: 0.9986181855201721
[32m[0511 09:51:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8345261216163635, Train Loss: 0.9986124634742737
[32m[0511 09:51:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8345306515693665, Train Loss: 0.998607337474823
[32m[0511 09:51:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8345352411270142, Train Loss: 0.9986023902893066
[32m[0511 09:51:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8345397710800171, Train Loss: 0.9985980987548828
[32m[0511 09:51:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.83454430103302, Train Loss: 0.9985940456390381
[32m[0511 09:51:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8345488905906677, Train Loss: 0.9985902905464172
[32m[0511 09:51:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8345534801483154, Train Loss: 0.9985869526863098
[32m[0511 09:51:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8345578908920288, Train Loss: 0.998583972454071
[32m[0511 09:51:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8345624208450317, Train Loss: 0.9985811114311218
[32m[0511 09:51:17 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.8345668315887451, Train Loss: 0.9985784888267517
[32m[0511 09:51:17 @base_main.py:38][0m --------------- Iteration 2 ---------------
[32m[0511 09:51:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0174 mins
[32m[0511 09:51:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 10.7072 mins
[32m[0511 09:51:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0180 mins
[32m[0511 09:51:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0051 mins
[32m[0511 09:51:17 @base_main.py:47][0m 2010 total steps have happened
[32m[0511 09:51:17 @base_main.py:52][0m [avg_reward]: -1388.516640762186
[32m[0511 09:51:17 @base_main.py:52][0m [update_op]: None
[32m[0511 09:51:17 @base_main.py:52][0m [train_loss]: 1.4162113666534424
[32m[0511 09:51:17 @base_main.py:52][0m [val_loss]: 0.8345668315887451
[32m[0511 09:51:17 @base_main.py:52][0m [avg_train_loss]: 0.9985784888267517
[32m[0511 09:53:25 @mbmf_sampler.py:39][0m done with episode
[32m[0511 09:55:33 @mbmf_sampler.py:39][0m done with episode
[32m[0511 09:57:40 @mbmf_sampler.py:39][0m done with episode
[32m[0511 09:59:48 @mbmf_sampler.py:39][0m done with episode
[32m[0511 10:01:55 @mbmf_sampler.py:39][0m done with episode
[32m[0511 10:01:55 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0511 10:01:55 @base_trainer.py:216][0m Mean reward: -1253.1416922111061
[32m[0511 10:01:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2416160106658936, Train Loss: 1.0244386196136475
[32m[0511 10:01:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2416316270828247, Train Loss: 1.024436354637146
[32m[0511 10:01:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2416445016860962, Train Loss: 1.0244340896606445
[32m[0511 10:01:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2416552305221558, Train Loss: 1.024431586265564
[32m[0511 10:01:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2416646480560303, Train Loss: 1.024429440498352
[32m[0511 10:01:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2416728734970093, Train Loss: 1.0244274139404297
[32m[0511 10:01:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.241680383682251, Train Loss: 1.024425745010376
[32m[0511 10:01:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2416871786117554, Train Loss: 1.0244243144989014
[32m[0511 10:01:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.241693377494812, Train Loss: 1.0244231224060059
[32m[0511 10:01:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2416988611221313, Train Loss: 1.0244221687316895
[32m[0511 10:01:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2417038679122925, Train Loss: 1.0244214534759521
[32m[0511 10:01:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.241708517074585, Train Loss: 1.0244208574295044
[32m[0511 10:01:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2417126893997192, Train Loss: 1.0244203805923462
[32m[0511 10:01:55 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2417163848876953, Train Loss: 1.0244200229644775
[32m[0511 10:01:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2417197227478027, Train Loss: 1.0244196653366089
[32m[0511 10:01:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2417229413986206, Train Loss: 1.0244195461273193
[32m[0511 10:01:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2417255640029907, Train Loss: 1.0244194269180298
[32m[0511 10:01:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2417279481887817, Train Loss: 1.0244190692901611
[32m[0511 10:01:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2417303323745728, Train Loss: 1.0244190692901611
[32m[0511 10:01:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.241732120513916, Train Loss: 1.0244190692901611
[32m[0511 10:01:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2417341470718384, Train Loss: 1.0244190692901611
[32m[0511 10:01:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.241735816001892, Train Loss: 1.0244187116622925
[32m[0511 10:01:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2417374849319458, Train Loss: 1.024418830871582
[32m[0511 10:01:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2417385578155518, Train Loss: 1.0244187116622925
[32m[0511 10:01:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2417399883270264, Train Loss: 1.0244187116622925
[32m[0511 10:01:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2417410612106323, Train Loss: 1.024418592453003
[32m[0511 10:01:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2417422533035278, Train Loss: 1.024418592453003
[32m[0511 10:01:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2417430877685547, Train Loss: 1.024418592453003
[32m[0511 10:01:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2417439222335815, Train Loss: 1.024418592453003
[32m[0511 10:01:56 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2417447566986084, Train Loss: 1.024418592453003
[32m[0511 10:01:57 @base_main.py:38][0m --------------- Iteration 3 ---------------
[32m[0511 10:01:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 10.7476 mins
[32m[0511 10:01:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 10.6209 mins
[32m[0511 10:01:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0277 mins
[32m[0511 10:01:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0050 mins
[32m[0511 10:01:57 @base_main.py:47][0m 3015 total steps have happened
[32m[0511 10:01:57 @base_main.py:52][0m [avg_reward]: -1253.1416922111061
[32m[0511 10:01:57 @base_main.py:52][0m [update_op]: None
[32m[0511 10:01:57 @base_main.py:52][0m [train_loss]: 1.1580760478973389
[32m[0511 10:01:57 @base_main.py:52][0m [val_loss]: 1.2417447566986084
[32m[0511 10:01:57 @base_main.py:52][0m [avg_train_loss]: 1.024418592453003
[32m[0511 10:04:04 @mbmf_sampler.py:39][0m done with episode
[32m[0511 10:06:11 @mbmf_sampler.py:39][0m done with episode
[32m[0511 10:08:19 @mbmf_sampler.py:39][0m done with episode
[32m[0511 10:10:26 @mbmf_sampler.py:39][0m done with episode
[32m[0511 10:12:33 @mbmf_sampler.py:39][0m done with episode
[32m[0511 10:12:33 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0511 10:12:33 @base_trainer.py:216][0m Mean reward: -1186.4915111503806
[32m[0511 10:12:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.249999761581421, Train Loss: 0.9570125937461853
[32m[0511 10:12:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2500683069229126, Train Loss: 0.9570057988166809
[32m[0511 10:12:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2501530647277832, Train Loss: 0.9569973349571228
[32m[0511 10:12:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2502378225326538, Train Loss: 0.9569894671440125
[32m[0511 10:12:33 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2503153085708618, Train Loss: 0.956983208656311
[32m[0511 10:12:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.250382661819458, Train Loss: 0.9569787979125977
[32m[0511 10:12:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2504394054412842, Train Loss: 0.9569754600524902
[32m[0511 10:12:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2504855394363403, Train Loss: 0.9569731950759888
[32m[0511 10:12:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.250522494316101, Train Loss: 0.9569717049598694
[32m[0511 10:12:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2505518198013306, Train Loss: 0.9569706320762634
[32m[0511 10:12:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2505748271942139, Train Loss: 0.9569699168205261
[32m[0511 10:12:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2505923509597778, Train Loss: 0.9569693207740784
[32m[0511 10:12:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.250605821609497, Train Loss: 0.9569689035415649
[32m[0511 10:12:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2506155967712402, Train Loss: 0.9569686651229858
[32m[0511 10:12:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2506229877471924, Train Loss: 0.9569684863090515
[32m[0511 10:12:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2506284713745117, Train Loss: 0.9569683074951172
[32m[0511 10:12:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2506319284439087, Train Loss: 0.9569681882858276
[32m[0511 10:12:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2506344318389893, Train Loss: 0.9569680094718933
[32m[0511 10:12:34 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2506358623504639, Train Loss: 0.9569679498672485
[32m[0511 10:12:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2506368160247803, Train Loss: 0.9569678902626038
[32m[0511 10:12:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2506369352340698, Train Loss: 0.9569678902626038
[32m[0511 10:12:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2506369352340698, Train Loss: 0.9569677710533142
[32m[0511 10:12:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2506365776062012, Train Loss: 0.9569677710533142
[32m[0511 10:12:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2506358623504639, Train Loss: 0.9569677114486694
[32m[0511 10:12:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.250635027885437, Train Loss: 0.9569677114486694
[32m[0511 10:12:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2506343126296997, Train Loss: 0.9569677710533142
[32m[0511 10:12:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2506334781646729, Train Loss: 0.9569676518440247
[32m[0511 10:12:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2506325244903564, Train Loss: 0.9569676518440247
[32m[0511 10:12:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.25063157081604, Train Loss: 0.9569675326347351
[32m[0511 10:12:35 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.2506307363510132, Train Loss: 0.9569675326347351
[32m[0511 10:12:36 @base_main.py:38][0m --------------- Iteration 4 ---------------
[32m[0511 10:12:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 21.4014 mins
[32m[0511 10:12:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 10.6072 mins
[32m[0511 10:12:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0363 mins
[32m[0511 10:12:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0051 mins
[32m[0511 10:12:36 @base_main.py:47][0m 4020 total steps have happened
[32m[0511 10:12:36 @base_main.py:52][0m [avg_reward]: -1186.4915111503806
[32m[0511 10:12:36 @base_main.py:52][0m [update_op]: None
[32m[0511 10:12:36 @base_main.py:52][0m [train_loss]: 1.1344690322875977
[32m[0511 10:12:36 @base_main.py:52][0m [val_loss]: 1.2506307363510132
[32m[0511 10:12:36 @base_main.py:52][0m [avg_train_loss]: 0.9569675326347351
[32m[0511 10:14:43 @mbmf_sampler.py:39][0m done with episode
[32m[0511 10:16:50 @mbmf_sampler.py:39][0m done with episode
[32m[0511 10:18:57 @mbmf_sampler.py:39][0m done with episode
[32m[0511 10:21:04 @mbmf_sampler.py:39][0m done with episode
[32m[0511 10:23:10 @mbmf_sampler.py:39][0m done with episode
[32m[0511 10:23:10 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0511 10:23:10 @base_trainer.py:216][0m Mean reward: -1309.6189601278377
[32m[0511 10:23:10 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9590456485748291, Train Loss: 0.9744307398796082
[32m[0511 10:23:10 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9590713381767273, Train Loss: 0.9744217991828918
[32m[0511 10:23:10 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9590976238250732, Train Loss: 0.9744122624397278
[32m[0511 10:23:10 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.959122359752655, Train Loss: 0.9744047522544861
[32m[0511 10:23:11 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9591445326805115, Train Loss: 0.9743995666503906
[32m[0511 10:23:11 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.959164023399353, Train Loss: 0.974396288394928
[32m[0511 10:23:11 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9591807126998901, Train Loss: 0.9743942618370056
[32m[0511 10:23:11 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9591948986053467, Train Loss: 0.9743930101394653
[32m[0511 10:23:11 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9592069983482361, Train Loss: 0.9743922352790833
[32m[0511 10:23:11 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9592171907424927, Train Loss: 0.9743919372558594
[32m[0511 10:23:11 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9592260718345642, Train Loss: 0.974391520023346
[32m[0511 10:23:11 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9592335224151611, Train Loss: 0.9743912816047668
[32m[0511 10:23:11 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9592401385307312, Train Loss: 0.9743912220001221
[32m[0511 10:23:11 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9592458009719849, Train Loss: 0.9743911027908325
[32m[0511 10:23:11 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9592506885528564, Train Loss: 0.974390983581543
[32m[0511 10:23:12 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.959255039691925, Train Loss: 0.9743908643722534
[32m[0511 10:23:12 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9592588543891907, Train Loss: 0.9743908643722534
[32m[0511 10:23:12 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9592623114585876, Train Loss: 0.9743907451629639
[32m[0511 10:23:12 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9592654705047607, Train Loss: 0.9743907451629639
[32m[0511 10:23:12 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9592681527137756, Train Loss: 0.9743906855583191
[32m[0511 10:23:12 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9592706561088562, Train Loss: 0.9743906855583191
[32m[0511 10:23:12 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9592729806900024, Train Loss: 0.9743906855583191
[32m[0511 10:23:12 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.95927494764328, Train Loss: 0.9743906855583191
[32m[0511 10:23:12 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9592767953872681, Train Loss: 0.9743905663490295
[32m[0511 10:23:12 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9592784643173218, Train Loss: 0.9743905663490295
[32m[0511 10:23:12 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9592799544334412, Train Loss: 0.9743905663490295
[32m[0511 10:23:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9592814445495605, Train Loss: 0.9743905663490295
[32m[0511 10:23:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9592826962471008, Train Loss: 0.9743905663490295
[32m[0511 10:23:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9592838287353516, Train Loss: 0.9743905663490295
[32m[0511 10:23:13 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 0.9592849612236023, Train Loss: 0.9743905663490295
[32m[0511 10:23:13 @base_main.py:38][0m --------------- Iteration 5 ---------------
[32m[0511 10:23:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 32.0501 mins
[32m[0511 10:23:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 10.5754 mins
[32m[0511 10:23:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0467 mins
[32m[0511 10:23:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0053 mins
[32m[0511 10:23:13 @base_main.py:47][0m 5025 total steps have happened
[32m[0511 10:23:13 @base_main.py:52][0m [avg_reward]: -1309.6189601278377
[32m[0511 10:23:13 @base_main.py:52][0m [update_op]: None
[32m[0511 10:23:13 @base_main.py:52][0m [train_loss]: 1.3149958848953247
[32m[0511 10:23:13 @base_main.py:52][0m [val_loss]: 0.9592849612236023
[32m[0511 10:23:13 @base_main.py:52][0m [avg_train_loss]: 0.9743905663490295
[32m[0511 10:25:20 @mbmf_sampler.py:39][0m done with episode
[32m[0511 10:27:26 @mbmf_sampler.py:39][0m done with episode
[32m[0511 10:29:33 @mbmf_sampler.py:39][0m done with episode
[32m[0511 10:31:39 @mbmf_sampler.py:39][0m done with episode
[32m[0511 10:33:45 @mbmf_sampler.py:39][0m done with episode
[32m[0511 10:33:45 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0511 10:33:45 @base_trainer.py:216][0m Mean reward: -1180.9579975457732
[32m[0511 10:33:45 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1393330097198486, Train Loss: 1.0172778367996216
[32m[0511 10:33:45 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1393401622772217, Train Loss: 1.017274260520935
[32m[0511 10:33:46 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1393487453460693, Train Loss: 1.0172717571258545
[32m[0511 10:33:46 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1393574476242065, Train Loss: 1.0172699689865112
[32m[0511 10:33:46 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1393656730651855, Train Loss: 1.0172688961029053
[32m[0511 10:33:46 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1393736600875854, Train Loss: 1.0172679424285889
[32m[0511 10:33:46 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1393808126449585, Train Loss: 1.0172673463821411
[32m[0511 10:33:46 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1393873691558838, Train Loss: 1.0172667503356934
[32m[0511 10:33:46 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1393932104110718, Train Loss: 1.0172663927078247
[32m[0511 10:33:46 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1393990516662598, Train Loss: 1.017266035079956
[32m[0511 10:33:46 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1394039392471313, Train Loss: 1.0172656774520874
[32m[0511 10:33:47 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1394084692001343, Train Loss: 1.0172654390335083
[32m[0511 10:33:47 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1394124031066895, Train Loss: 1.0172654390335083
[32m[0511 10:33:47 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1394164562225342, Train Loss: 1.0172652006149292
[32m[0511 10:33:47 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.139419674873352, Train Loss: 1.0172650814056396
[32m[0511 10:33:47 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.13942289352417, Train Loss: 1.0172648429870605
[32m[0511 10:33:47 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1394256353378296, Train Loss: 1.0172648429870605
[32m[0511 10:33:47 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1394282579421997, Train Loss: 1.0172648429870605
[32m[0511 10:33:47 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1394306421279907, Train Loss: 1.0172648429870605
[32m[0511 10:33:47 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.139432668685913, Train Loss: 1.0172646045684814
[32m[0511 10:33:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1394346952438354, Train Loss: 1.0172646045684814
[32m[0511 10:33:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1394363641738892, Train Loss: 1.0172646045684814
[32m[0511 10:33:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1394380331039429, Train Loss: 1.017264485359192
[32m[0511 10:33:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.139439344406128, Train Loss: 1.017264485359192
[32m[0511 10:33:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.139440655708313, Train Loss: 1.017264485359192
[32m[0511 10:33:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1394418478012085, Train Loss: 1.017264485359192
[32m[0511 10:33:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.139442801475525, Train Loss: 1.017264485359192
[32m[0511 10:33:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1394437551498413, Train Loss: 1.017264485359192
[32m[0511 10:33:48 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1394445896148682, Train Loss: 1.017264485359192
[32m[0511 10:33:49 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1394453048706055, Train Loss: 1.017264485359192
[32m[0511 10:33:49 @base_main.py:38][0m --------------- Iteration 6 ---------------
[32m[0511 10:33:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 42.6775 mins
[32m[0511 10:33:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 10.5326 mins
[32m[0511 10:33:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0575 mins
[32m[0511 10:33:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0047 mins
[32m[0511 10:33:49 @base_main.py:47][0m 6030 total steps have happened
[32m[0511 10:33:49 @base_main.py:52][0m [avg_reward]: -1180.9579975457732
[32m[0511 10:33:49 @base_main.py:52][0m [update_op]: None
[32m[0511 10:33:49 @base_main.py:52][0m [train_loss]: 0.9956876039505005
[32m[0511 10:33:49 @base_main.py:52][0m [val_loss]: 1.1394453048706055
[32m[0511 10:33:49 @base_main.py:52][0m [avg_train_loss]: 1.017264485359192
[32m[0511 10:35:55 @mbmf_sampler.py:39][0m done with episode
[32m[0511 10:38:01 @mbmf_sampler.py:39][0m done with episode
[32m[0511 10:40:07 @mbmf_sampler.py:39][0m done with episode
[32m[0511 10:42:13 @mbmf_sampler.py:39][0m done with episode
[32m[0511 10:44:19 @mbmf_sampler.py:39][0m done with episode
[32m[0511 10:44:19 @mbmf_sampler.py:50][0m 1005 timesteps from 5 episodes collected
[32m[0511 10:44:19 @base_trainer.py:216][0m Mean reward: -1163.1862797606327
[32m[0511 10:44:19 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1292787790298462, Train Loss: 0.9777266383171082
[32m[0511 10:44:20 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1292834281921387, Train Loss: 0.9777269959449768
[32m[0511 10:44:20 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1292858123779297, Train Loss: 0.9777270555496216
[32m[0511 10:44:20 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1292874813079834, Train Loss: 0.9777269959449768
[32m[0511 10:44:20 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.129288911819458, Train Loss: 0.9777269959449768
[32m[0511 10:44:20 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1292901039123535, Train Loss: 0.977726936340332
[32m[0511 10:44:20 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.129291296005249, Train Loss: 0.9777270555496216
[32m[0511 10:44:20 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1292921304702759, Train Loss: 0.9777269959449768
[32m[0511 10:44:20 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1292929649353027, Train Loss: 0.977726936340332
[32m[0511 10:44:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.12929368019104, Train Loss: 0.9777269959449768
[32m[0511 10:44:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1292942762374878, Train Loss: 0.9777268171310425
[32m[0511 10:44:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1292948722839355, Train Loss: 0.9777268767356873
[32m[0511 10:44:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1292952299118042, Train Loss: 0.9777268767356873
[32m[0511 10:44:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1292957067489624, Train Loss: 0.9777268171310425
[32m[0511 10:44:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.129296064376831, Train Loss: 0.9777268767356873
[32m[0511 10:44:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1292964220046997, Train Loss: 0.9777268767356873
[32m[0511 10:44:21 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1292967796325684, Train Loss: 0.9777268767356873
[32m[0511 10:44:22 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1292970180511475, Train Loss: 0.9777268171310425
[32m[0511 10:44:22 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1292972564697266, Train Loss: 0.9777268171310425
[32m[0511 10:44:22 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1292973756790161, Train Loss: 0.9777268171310425
[32m[0511 10:44:22 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1292976140975952, Train Loss: 0.9777266979217529
[32m[0511 10:44:22 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1292978525161743, Train Loss: 0.9777268171310425
[32m[0511 10:44:22 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1292978525161743, Train Loss: 0.9777268171310425
[32m[0511 10:44:22 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1292978525161743, Train Loss: 0.9777268171310425
[32m[0511 10:44:22 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.129298210144043, Train Loss: 0.9777268171310425
[32m[0511 10:44:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.129298448562622, Train Loss: 0.9777268767356873
[32m[0511 10:44:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.129298210144043, Train Loss: 0.9777268767356873
[32m[0511 10:44:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.129298448562622, Train Loss: 0.9777268171310425
[32m[0511 10:44:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.129298448562622, Train Loss: 0.9777268171310425
[32m[0511 10:44:23 @deterministic_forward_dynamics.py:166][0m [dynamics]: Val Loss: 1.1292986869812012, Train Loss: 0.9777268171310425
[32m[0511 10:44:23 @base_main.py:38][0m --------------- Iteration 7 ---------------
[32m[0511 10:44:23 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 53.2725 mins
[32m[0511 10:44:23 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 10.5069 mins
[32m[0511 10:44:23 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0642 mins
[32m[0511 10:44:23 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0052 mins
[32m[0511 10:44:23 @base_main.py:47][0m 7035 total steps have happened
[32m[0511 10:44:23 @base_main.py:52][0m [avg_reward]: -1163.1862797606327
[32m[0511 10:44:23 @base_main.py:52][0m [update_op]: None
[32m[0511 10:44:23 @base_main.py:52][0m [train_loss]: 1.0247563123703003
[32m[0511 10:44:23 @base_main.py:52][0m [val_loss]: 1.1292986869812012
[32m[0511 10:44:23 @base_main.py:52][0m [avg_train_loss]: 0.9777268171310425
[32m[0511 10:44:24 @mbmf_trainer.py:160][0m Mean reward: -1263.7352482741633
[32m[0511 10:44:24 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.19007502496242523, Train Loss: 0.1877763271331787
[32m[0511 10:44:24 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.18984705209732056, Train Loss: 0.18764342367649078
[32m[0511 10:44:24 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.1899634152650833, Train Loss: 0.1876436471939087
[32m[0511 10:44:24 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.19012531638145447, Train Loss: 0.18762773275375366
[32m[0511 10:44:24 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.19020193815231323, Train Loss: 0.18760590255260468
[32m[0511 10:44:24 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.1902374029159546, Train Loss: 0.18758948147296906
[32m[0511 10:44:24 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.1902802288532257, Train Loss: 0.18757855892181396
[32m[0511 10:44:24 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.190329447388649, Train Loss: 0.18756872415542603
[32m[0511 10:44:24 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.19037294387817383, Train Loss: 0.1875585913658142
[32m[0511 10:44:24 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.19041010737419128, Train Loss: 0.18754906952381134
[32m[0511 10:44:24 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.19044524431228638, Train Loss: 0.18754057586193085
[32m[0511 10:44:24 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.19047991931438446, Train Loss: 0.18753282725811005
[32m[0511 10:44:24 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.19051343202590942, Train Loss: 0.18752558529376984
[32m[0511 10:44:24 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.19054554402828217, Train Loss: 0.1875188797712326
[32m[0511 10:44:24 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.1905764639377594, Train Loss: 0.18751263618469238
[32m[0511 10:44:24 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.19060641527175903, Train Loss: 0.18750683963298798
[32m[0511 10:44:24 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.19063527882099152, Train Loss: 0.18750141561031342
[32m[0511 10:44:24 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.1906631737947464, Train Loss: 0.1874963492155075
[32m[0511 10:44:24 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.1906900256872177, Train Loss: 0.18749158084392548
[32m[0511 10:44:24 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.19071589410305023, Train Loss: 0.18748711049556732
[32m[0511 10:44:24 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.19074079394340515, Train Loss: 0.18748289346694946
[32m[0511 10:44:24 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.19076472520828247, Train Loss: 0.1874788999557495
[32m[0511 10:44:24 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.190787672996521, Train Loss: 0.1874750703573227
[32m[0511 10:44:24 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.19080974161624908, Train Loss: 0.1874714493751526
[32m[0511 10:44:24 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.19083093106746674, Train Loss: 0.1874680072069168
[32m[0511 10:44:24 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.19085119664669037, Train Loss: 0.18746469914913177
[32m[0511 10:44:24 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.19087062776088715, Train Loss: 0.1874615103006363
[32m[0511 10:44:24 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.19088925421237946, Train Loss: 0.18745845556259155
[32m[0511 10:44:24 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.19090712070465088, Train Loss: 0.18745549023151398
[32m[0511 10:44:24 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.19092415273189545, Train Loss: 0.18745262920856476
[32m[0511 10:44:24 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.1909404844045639, Train Loss: 0.1874498575925827
[32m[0511 10:44:24 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.19095610082149506, Train Loss: 0.18744713068008423
[32m[0511 10:44:24 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.19097106158733368, Train Loss: 0.1874445080757141
[32m[0511 10:44:25 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.19098533689975739, Train Loss: 0.1874419003725052
[32m[0511 10:44:25 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.19099900126457214, Train Loss: 0.18743939697742462
[32m[0511 10:44:25 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.19101208448410034, Train Loss: 0.18743692338466644
[32m[0511 10:44:25 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.1910245567560196, Train Loss: 0.18743447959423065
[32m[0511 10:44:25 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.19103652238845825, Train Loss: 0.18743206560611725
[32m[0511 10:44:25 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.19104798138141632, Train Loss: 0.187429741024971
[32m[0511 10:44:25 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.1910589188337326, Train Loss: 0.18742738664150238
[32m[0511 10:44:25 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.19106940925121307, Train Loss: 0.18742509186267853
[32m[0511 10:44:25 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.19107940793037415, Train Loss: 0.18742281198501587
[32m[0511 10:44:25 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.1910889893770218, Train Loss: 0.1874205619096756
[32m[0511 10:44:25 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.19109821319580078, Train Loss: 0.18741834163665771
[32m[0511 10:44:25 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.19110697507858276, Train Loss: 0.18741612136363983
[32m[0511 10:44:25 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.19111542403697968, Train Loss: 0.18741391599178314
[32m[0511 10:44:25 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.19112350046634674, Train Loss: 0.18741177022457123
[32m[0511 10:44:25 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.19113121926784515, Train Loss: 0.18740959465503693
[32m[0511 10:44:25 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.1911386400461197, Train Loss: 0.18740743398666382
[32m[0511 10:44:25 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.19114579260349274, Train Loss: 0.1874052882194519
[32m[0511 10:44:25 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.19115260243415833, Train Loss: 0.18740315735340118
[32m[0511 10:44:25 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.19115915894508362, Train Loss: 0.18740104138851166
[32m[0511 10:44:25 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.19116543233394623, Train Loss: 0.18739895522594452
[32m[0511 10:44:25 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.19117151200771332, Train Loss: 0.187396839261055
[32m[0511 10:44:25 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.19117730855941772, Train Loss: 0.18739473819732666
[32m[0511 10:44:25 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.19118286669254303, Train Loss: 0.18739263713359833
[32m[0511 10:44:25 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.19118821620941162, Train Loss: 0.18739056587219238
[32m[0511 10:44:25 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.1911933869123459, Train Loss: 0.18738847970962524
[32m[0511 10:44:25 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.19119833409786224, Train Loss: 0.1873864084482193
[32m[0511 10:44:25 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.19120311737060547, Train Loss: 0.18738432228565216
[32m[0511 10:44:25 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.1912076622247696, Train Loss: 0.1873822957277298
[32m[0511 10:44:25 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.19121211767196655, Train Loss: 0.18738023936748505
[32m[0511 10:44:25 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.191216379404068, Train Loss: 0.1873781681060791
[32m[0511 10:44:25 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.19122043251991272, Train Loss: 0.18737609684467316
[32m[0511 10:44:25 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.1912243813276291, Train Loss: 0.1873740553855896
[32m[0511 10:44:25 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.19122818112373352, Train Loss: 0.18737201392650604
[32m[0511 10:44:25 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.191231831908226, Train Loss: 0.1873699426651001
[32m[0511 10:44:25 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.19123534858226776, Train Loss: 0.18736791610717773
[32m[0511 10:44:25 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.19123870134353638, Train Loss: 0.1873658448457718
[32m[0511 10:44:26 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.19124197959899902, Train Loss: 0.18736381828784943
[32m[0511 10:44:26 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.19124513864517212, Train Loss: 0.18736177682876587
[32m[0511 10:44:26 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.19124816358089447, Train Loss: 0.1873597353696823
[32m[0511 10:44:26 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.19125105440616608, Train Loss: 0.18735767900943756
[32m[0511 10:44:26 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.1912538856267929, Train Loss: 0.187355637550354
[32m[0511 10:44:26 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.1912565976381302, Train Loss: 0.18735361099243164
[32m[0511 10:44:26 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.19125917553901672, Train Loss: 0.18735158443450928
[32m[0511 10:44:26 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.19126169383525848, Train Loss: 0.18734954297542572
[32m[0511 10:44:26 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.1912640780210495, Train Loss: 0.18734748661518097
[32m[0511 10:44:26 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.19126640260219574, Train Loss: 0.1873454600572586
[32m[0511 10:44:26 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.19126862287521362, Train Loss: 0.18734343349933624
[32m[0511 10:44:26 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.19127078354358673, Train Loss: 0.18734139204025269
[32m[0511 10:44:26 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.1912728250026703, Train Loss: 0.18733936548233032
[32m[0511 10:44:26 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.19127482175827026, Train Loss: 0.18733733892440796
[32m[0511 10:44:26 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.19127671420574188, Train Loss: 0.1873353123664856
[32m[0511 10:44:26 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.1912785768508911, Train Loss: 0.18733327090740204
[32m[0511 10:44:26 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.1912803202867508, Train Loss: 0.1873312145471573
[32m[0511 10:44:26 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.19128203392028809, Train Loss: 0.1873292177915573
[32m[0511 10:44:26 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.19128361344337463, Train Loss: 0.18732716143131256
[32m[0511 10:44:26 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.19128519296646118, Train Loss: 0.1873251348733902
[32m[0511 10:44:26 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.19128665328025818, Train Loss: 0.18732309341430664
[32m[0511 10:44:26 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.1912880837917328, Train Loss: 0.18732105195522308
[32m[0511 10:44:26 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.19128945469856262, Train Loss: 0.18731904029846191
[32m[0511 10:44:26 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.19129078090190887, Train Loss: 0.18731701374053955
[32m[0511 10:44:26 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.19129201769828796, Train Loss: 0.1873149424791336
[32m[0511 10:44:26 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.19129320979118347, Train Loss: 0.18731294572353363
[32m[0511 10:44:26 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.1912943422794342, Train Loss: 0.18731091916561127
[32m[0511 10:44:26 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.19129544496536255, Train Loss: 0.18730886280536652
[32m[0511 10:44:26 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.1912965029478073, Train Loss: 0.18730683624744415
[32m[0511 10:44:26 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.1912974864244461, Train Loss: 0.1873048096895218
[32m[0511 10:44:26 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.19129842519760132, Train Loss: 0.18730281293392181
[32m[0511 10:44:26 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.19129933416843414, Train Loss: 0.18730075657367706
[32m[0511 10:44:26 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.1913001835346222, Train Loss: 0.1872987300157547
[32m[0511 10:44:26 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.19130100309848785, Train Loss: 0.18729668855667114
[32m[0511 10:44:26 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.19130176305770874, Train Loss: 0.18729467689990997
[32m[0511 10:44:26 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.19130249321460724, Train Loss: 0.1872926503419876
[32m[0511 10:44:26 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.19130319356918335, Train Loss: 0.18729065358638763
[32m[0511 10:44:27 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.19130386412143707, Train Loss: 0.18728859722614288
[32m[0511 10:44:27 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.19130448997020721, Train Loss: 0.18728657066822052
[32m[0511 10:44:27 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.19130508601665497, Train Loss: 0.18728457391262054
[32m[0511 10:44:27 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.19130565226078033, Train Loss: 0.1872825175523758
[32m[0511 10:44:27 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.1913061887025833, Train Loss: 0.18728052079677582
[32m[0511 10:44:27 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.1913066953420639, Train Loss: 0.18727850914001465
[32m[0511 10:44:27 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.19130714237689972, Train Loss: 0.18727648258209229
[32m[0511 10:44:27 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.19130760431289673, Train Loss: 0.18727447092533112
[32m[0511 10:44:27 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.19130800664424896, Train Loss: 0.18727247416973114
[32m[0511 10:44:27 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.1913084089756012, Train Loss: 0.18727046251296997
[32m[0511 10:44:27 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.19130876660346985, Train Loss: 0.1872684508562088
[32m[0511 10:44:27 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.1913091391324997, Train Loss: 0.18726645410060883
[32m[0511 10:44:27 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.19130943715572357, Train Loss: 0.18726444244384766
[32m[0511 10:44:27 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.19130972027778625, Train Loss: 0.1872624307870865
[32m[0511 10:44:27 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.19131000339984894, Train Loss: 0.1872604638338089
[32m[0511 10:44:27 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.19131028652191162, Train Loss: 0.18725843727588654
[32m[0511 10:44:27 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.19131051003932953, Train Loss: 0.18725645542144775
[32m[0511 10:44:27 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.19131074845790863, Train Loss: 0.18725447356700897
[32m[0511 10:44:27 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.19131094217300415, Train Loss: 0.187252476811409
[32m[0511 10:44:27 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.19131113588809967, Train Loss: 0.18725049495697021
[32m[0511 10:44:27 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.191311314702034, Train Loss: 0.18724852800369263
[32m[0511 10:44:27 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.19131146371364594, Train Loss: 0.18724654614925385
[32m[0511 10:44:27 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.19131159782409668, Train Loss: 0.18724457919597626
[32m[0511 10:44:27 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.19131171703338623, Train Loss: 0.18724261224269867
[32m[0511 10:44:27 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.19131185114383698, Train Loss: 0.18724064528942108
[32m[0511 10:44:27 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.19131194055080414, Train Loss: 0.1872386783361435
[32m[0511 10:44:27 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.1913120299577713, Train Loss: 0.1872367113828659
[32m[0511 10:44:27 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.19131211936473846, Train Loss: 0.1872347593307495
[32m[0511 10:44:27 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.19131217896938324, Train Loss: 0.18723280727863312
[32m[0511 10:44:27 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.19131222367286682, Train Loss: 0.18723084032535553
[32m[0511 10:44:27 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.1913122683763504, Train Loss: 0.18722891807556152
[32m[0511 10:44:27 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.19131231307983398, Train Loss: 0.18722699582576752
[32m[0511 10:44:27 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.19131232798099518, Train Loss: 0.18722504377365112
[32m[0511 10:44:27 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.19131235778331757, Train Loss: 0.1872231364250183
[32m[0511 10:44:27 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.19131237268447876, Train Loss: 0.18722118437290192
[32m[0511 10:44:27 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.19131237268447876, Train Loss: 0.1872192770242691
[32m[0511 10:44:28 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.19131235778331757, Train Loss: 0.1872173547744751
[32m[0511 10:44:28 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.19131235778331757, Train Loss: 0.18721546232700348
[32m[0511 10:44:28 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.19131232798099518, Train Loss: 0.18721354007720947
[32m[0511 10:44:28 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.19131231307983398, Train Loss: 0.18721163272857666
[32m[0511 10:44:28 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.1913122683763504, Train Loss: 0.18720977008342743
[32m[0511 10:44:28 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.19131223857402802, Train Loss: 0.18720786273479462
[32m[0511 10:44:28 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.19131222367286682, Train Loss: 0.187205970287323
[32m[0511 10:44:28 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.19131216406822205, Train Loss: 0.18720410764217377
[32m[0511 10:44:28 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.19131211936473846, Train Loss: 0.18720223009586334
[32m[0511 10:44:28 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.19131207466125488, Train Loss: 0.18720035254955292
[32m[0511 10:44:28 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.1913120001554489, Train Loss: 0.18719850480556488
[32m[0511 10:44:28 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.19131194055080414, Train Loss: 0.18719665706157684
[32m[0511 10:44:28 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.19131189584732056, Train Loss: 0.18719477951526642
[32m[0511 10:44:28 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.19131183624267578, Train Loss: 0.18719293177127838
[32m[0511 10:44:28 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.19131174683570862, Train Loss: 0.18719108402729034
[32m[0511 10:44:28 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.19131168723106384, Train Loss: 0.1871892809867859
[32m[0511 10:44:28 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.19131164252758026, Train Loss: 0.18718744814395905
[32m[0511 10:44:28 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.1913115531206131, Train Loss: 0.187185600399971
[32m[0511 10:44:28 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.19131147861480713, Train Loss: 0.18718379735946655
[32m[0511 10:44:28 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.19131141901016235, Train Loss: 0.1871819943189621
[32m[0511 10:44:28 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.19131135940551758, Train Loss: 0.18718020617961884
[32m[0511 10:44:28 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.1913112848997116, Train Loss: 0.187178373336792
[32m[0511 10:44:28 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.19131122529506683, Train Loss: 0.18717658519744873
[32m[0511 10:44:28 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.19131113588809967, Train Loss: 0.18717479705810547
[32m[0511 10:44:28 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.1913110762834549, Train Loss: 0.1871730238199234
[32m[0511 10:44:28 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.19131098687648773, Train Loss: 0.18717123568058014
[32m[0511 10:44:28 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.19131094217300415, Train Loss: 0.18716947734355927
[32m[0511 10:44:28 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.19131088256835938, Train Loss: 0.1871677190065384
[32m[0511 10:44:28 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.1913108378648758, Train Loss: 0.1871659755706787
[32m[0511 10:44:28 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.19131076335906982, Train Loss: 0.18716423213481903
[32m[0511 10:44:28 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.19131068885326385, Train Loss: 0.18716247379779816
[32m[0511 10:44:28 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.19131065905094147, Train Loss: 0.18716073036193848
[32m[0511 10:44:28 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.1913105994462967, Train Loss: 0.1871589869260788
[32m[0511 10:44:28 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.19131052494049072, Train Loss: 0.1871572732925415
[32m[0511 10:44:28 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.19131051003932953, Train Loss: 0.18715554475784302
[32m[0511 10:44:28 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.19131045043468475, Train Loss: 0.18715383112430573
[32m[0511 10:44:28 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.19131042063236237, Train Loss: 0.18715214729309082
[32m[0511 10:44:29 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.1913103610277176, Train Loss: 0.18715043365955353
[32m[0511 10:44:29 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.1913103312253952, Train Loss: 0.18714873492717743
[32m[0511 10:44:29 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.1913103312253952, Train Loss: 0.18714706599712372
[32m[0511 10:44:29 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.19131027162075043, Train Loss: 0.18714536726474762
[32m[0511 10:44:29 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.19131027162075043, Train Loss: 0.1871436983346939
[32m[0511 10:44:29 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.19131022691726685, Train Loss: 0.1871420294046402
[32m[0511 10:44:29 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.19131022691726685, Train Loss: 0.1871403604745865
[32m[0511 10:44:29 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.19131019711494446, Train Loss: 0.18713872134685516
[32m[0511 10:44:29 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.19131019711494446, Train Loss: 0.18713706731796265
[32m[0511 10:44:29 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.19131019711494446, Train Loss: 0.18713541328907013
[32m[0511 10:44:29 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.19131019711494446, Train Loss: 0.1871337741613388
[32m[0511 10:44:29 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.19131019711494446, Train Loss: 0.18713216483592987
[32m[0511 10:44:29 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.19131022691726685, Train Loss: 0.18713055551052094
[32m[0511 10:44:29 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.19131024181842804, Train Loss: 0.187128946185112
[32m[0511 10:44:29 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.19131028652191162, Train Loss: 0.18712730705738068
[32m[0511 10:44:29 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.19131028652191162, Train Loss: 0.18712569773197174
[32m[0511 10:44:29 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.1913103312253952, Train Loss: 0.1871240884065628
[32m[0511 10:44:29 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.1913103610277176, Train Loss: 0.18712250888347626
[32m[0511 10:44:29 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.19131042063236237, Train Loss: 0.1871209293603897
[32m[0511 10:44:29 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.19131045043468475, Train Loss: 0.18711936473846436
[32m[0511 10:44:29 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.19131048023700714, Train Loss: 0.1871177703142166
[32m[0511 10:44:29 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.1913105696439743, Train Loss: 0.18711620569229126
[32m[0511 10:44:29 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.19131061434745789, Train Loss: 0.1871146559715271
[32m[0511 10:44:29 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.19131070375442505, Train Loss: 0.18711310625076294
[32m[0511 10:44:29 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.1913107931613922, Train Loss: 0.18711155652999878
[32m[0511 10:44:29 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.191310852766037, Train Loss: 0.18711000680923462
[32m[0511 10:44:29 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.19131092727184296, Train Loss: 0.18710850179195404
[32m[0511 10:44:29 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.19131100177764893, Train Loss: 0.18710695207118988
[32m[0511 10:44:29 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.19131112098693848, Train Loss: 0.18710541725158691
[32m[0511 10:44:29 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.19131122529506683, Train Loss: 0.18710391223430634
[32m[0511 10:44:29 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.191311314702034, Train Loss: 0.18710239231586456
[32m[0511 10:44:29 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.19131141901016235, Train Loss: 0.18710090219974518
[32m[0511 10:44:29 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.1913115531206131, Train Loss: 0.1870994120836258
[32m[0511 10:44:29 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.19131164252758026, Train Loss: 0.18709790706634521
[32m[0511 10:44:29 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.1913117617368698, Train Loss: 0.18709643185138702
[32m[0511 10:44:29 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.19131192564964294, Train Loss: 0.18709494173526764
[32m[0511 10:44:30 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.1913120448589325, Train Loss: 0.18709345161914825
[32m[0511 10:44:30 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.19131219387054443, Train Loss: 0.18709200620651245
[32m[0511 10:44:30 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.19131232798099518, Train Loss: 0.18709056079387665
[32m[0511 10:44:30 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.19131247699260712, Train Loss: 0.18708908557891846
[32m[0511 10:44:30 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.19131264090538025, Train Loss: 0.18708764016628265
[32m[0511 10:44:30 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.19131280481815338, Train Loss: 0.18708620965480804
[32m[0511 10:44:30 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.19131295382976532, Train Loss: 0.18708477914333344
[32m[0511 10:44:30 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.19131311774253845, Train Loss: 0.18708334863185883
[32m[0511 10:44:30 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.19131332635879517, Train Loss: 0.18708191812038422
[32m[0511 10:44:30 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.1913134753704071, Train Loss: 0.1870805025100708
[32m[0511 10:44:30 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.19131368398666382, Train Loss: 0.1870790719985962
[32m[0511 10:44:30 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.19131387770175934, Train Loss: 0.18707770109176636
[32m[0511 10:44:30 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.19131407141685486, Train Loss: 0.18707627058029175
[32m[0511 10:44:30 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.19131428003311157, Train Loss: 0.18707488477230072
[32m[0511 10:44:30 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.1913144737482071, Train Loss: 0.1870734840631485
[32m[0511 10:44:30 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.1913146823644638, Train Loss: 0.18707211315631866
[32m[0511 10:44:30 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.1913149207830429, Train Loss: 0.18707074224948883
[32m[0511 10:44:30 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.19131512939929962, Train Loss: 0.1870693415403366
[32m[0511 10:44:30 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.19131535291671753, Train Loss: 0.18706800043582916
[32m[0511 10:44:30 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.19131556153297424, Train Loss: 0.18706665933132172
[32m[0511 10:44:30 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.19131579995155334, Train Loss: 0.18706528842449188
[32m[0511 10:44:30 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.19131603837013245, Train Loss: 0.18706394731998444
[32m[0511 10:44:30 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.19131626188755035, Train Loss: 0.187062606215477
[32m[0511 10:44:30 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.19131654500961304, Train Loss: 0.18706125020980835
[32m[0511 10:44:30 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.19131675362586975, Train Loss: 0.1870599240064621
[32m[0511 10:44:30 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.19131703674793243, Train Loss: 0.18705861270427704
[32m[0511 10:44:30 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.19131727516651154, Train Loss: 0.18705730140209198
[32m[0511 10:44:30 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.19131755828857422, Train Loss: 0.18705596029758453
[32m[0511 10:44:30 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.1913178414106369, Train Loss: 0.18705464899539948
[32m[0511 10:44:30 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.1913181096315384, Train Loss: 0.1870533674955368
[32m[0511 10:44:30 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.19131839275360107, Train Loss: 0.18705207109451294
[32m[0511 10:44:30 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.19131867587566376, Train Loss: 0.18705077469348907
[32m[0511 10:44:30 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.19131894409656525, Train Loss: 0.1870495080947876
[32m[0511 10:44:30 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.19131925702095032, Train Loss: 0.18704821169376373
[32m[0511 10:44:30 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.191319540143013, Train Loss: 0.18704693019390106
[32m[0511 10:44:30 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.19131983816623688, Train Loss: 0.18704567849636078
[32m[0511 10:44:30 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.19132015109062195, Train Loss: 0.1870443969964981
[32m[0511 10:44:31 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.19132044911384583, Train Loss: 0.18704314529895782
[32m[0511 10:44:31 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.1913207471370697, Train Loss: 0.18704189360141754
[32m[0511 10:44:31 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.19132106006145477, Train Loss: 0.18704064190387726
[32m[0511 10:44:31 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.19132140278816223, Train Loss: 0.18703939020633698
[32m[0511 10:44:31 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.1913217008113861, Train Loss: 0.18703818321228027
[32m[0511 10:44:31 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.19132202863693237, Train Loss: 0.18703693151474
[32m[0511 10:44:31 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.19132238626480103, Train Loss: 0.1870357245206833
[32m[0511 10:44:31 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.1913226991891861, Train Loss: 0.1870345026254654
[32m[0511 10:44:31 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.19132302701473236, Train Loss: 0.1870332956314087
[32m[0511 10:44:31 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.191323384642601, Train Loss: 0.1870320588350296
[32m[0511 10:44:31 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.19132372736930847, Train Loss: 0.1870308667421341
[32m[0511 10:44:31 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.19132407009601593, Train Loss: 0.1870296597480774
[32m[0511 10:44:31 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.19132442772388458, Train Loss: 0.18702848255634308
[32m[0511 10:44:31 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.19132477045059204, Train Loss: 0.18702729046344757
[32m[0511 10:44:31 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.1913251429796219, Train Loss: 0.18702609837055206
[32m[0511 10:44:31 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.19132548570632935, Train Loss: 0.18702495098114014
[32m[0511 10:44:31 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.1913258582353592, Train Loss: 0.18702374398708344
[32m[0511 10:44:31 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.19132624566555023, Train Loss: 0.18702258169651031
[32m[0511 10:44:31 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.1913265734910965, Train Loss: 0.1870214194059372
[32m[0511 10:44:31 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.19132697582244873, Train Loss: 0.18702025711536407
[32m[0511 10:44:31 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.19132737815380096, Train Loss: 0.18701910972595215
[32m[0511 10:44:31 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.19132772088050842, Train Loss: 0.18701796233654022
[32m[0511 10:44:31 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.19132813811302185, Train Loss: 0.1870168298482895
[32m[0511 10:44:31 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.1913284957408905, Train Loss: 0.18701569736003876
[32m[0511 10:44:31 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.19132891297340393, Train Loss: 0.18701456487178802
[32m[0511 10:44:31 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.19132930040359497, Train Loss: 0.1870134025812149
[32m[0511 10:44:31 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.19132967293262482, Train Loss: 0.18701229989528656
[32m[0511 10:44:31 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.19133006036281586, Train Loss: 0.18701118230819702
[32m[0511 10:44:31 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.19133049249649048, Train Loss: 0.18701006472110748
[32m[0511 10:44:31 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.1913309097290039, Train Loss: 0.18700893223285675
[32m[0511 10:44:31 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.19133132696151733, Train Loss: 0.1870078593492508
[32m[0511 10:44:31 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.19133172929286957, Train Loss: 0.18700675666332245
[32m[0511 10:44:31 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.191332146525383, Train Loss: 0.1870056539773941
[32m[0511 10:44:31 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.19133256375789642, Train Loss: 0.18700456619262695
[32m[0511 10:44:31 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.19133299589157104, Train Loss: 0.1870034784078598
[32m[0511 10:44:31 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.19133342802524567, Train Loss: 0.18700240552425385
[32m[0511 10:44:32 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.1913338452577591, Train Loss: 0.1870013028383255
[32m[0511 10:44:32 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.19133424758911133, Train Loss: 0.18700025975704193
[32m[0511 10:44:32 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.19133469462394714, Train Loss: 0.18699920177459717
[32m[0511 10:44:32 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.19133514165878296, Train Loss: 0.1869981437921524
[32m[0511 10:44:32 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.19133557379245758, Train Loss: 0.18699707090854645
[32m[0511 10:44:32 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.1913360357284546, Train Loss: 0.18699602782726288
[32m[0511 10:44:32 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.1913364678621292, Train Loss: 0.18699496984481812
[32m[0511 10:44:32 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.19133692979812622, Train Loss: 0.18699394166469574
[32m[0511 10:44:32 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.19133736193180084, Train Loss: 0.18699288368225098
[32m[0511 10:44:32 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.19133780896663666, Train Loss: 0.1869918704032898
[32m[0511 10:44:32 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.19133827090263367, Train Loss: 0.1869908571243286
[32m[0511 10:44:32 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.19133871793746948, Train Loss: 0.18698979914188385
[32m[0511 10:44:32 @mbmf_sampler.py:98][0m Finished 9th episode
[32m[0511 10:44:32 @mbmf_sampler.py:102][0m 1809 timesteps from 9 episodes collected
[32m[0511 11:03:25 @mbmf_trainer.py:160][0m Mean reward: -1227.8810308668744
[32m[0511 11:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.17416977882385254, Train Loss: 0.18393410742282867
[32m[0511 11:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.174188494682312, Train Loss: 0.18389511108398438
[32m[0511 11:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.174188494682312, Train Loss: 0.18387965857982635
[32m[0511 11:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.17418770492076874, Train Loss: 0.1838632971048355
[32m[0511 11:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.17418314516544342, Train Loss: 0.18385228514671326
[32m[0511 11:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.1741764396429062, Train Loss: 0.18384400010108948
[32m[0511 11:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.1741715371608734, Train Loss: 0.1838361620903015
[32m[0511 11:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.17416808009147644, Train Loss: 0.18382969498634338
[32m[0511 11:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.1741659939289093, Train Loss: 0.1838240772485733
[32m[0511 11:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.17416508495807648, Train Loss: 0.18381905555725098
[32m[0511 11:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.17416499555110931, Train Loss: 0.1838146150112152
[32m[0511 11:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.1741655468940735, Train Loss: 0.18381063640117645
[32m[0511 11:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.17416658997535706, Train Loss: 0.18380695581436157
[32m[0511 11:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.17416800558567047, Train Loss: 0.18380360305309296
[32m[0511 11:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.17416974902153015, Train Loss: 0.18380050361156464
[32m[0511 11:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.17417174577713013, Train Loss: 0.18379755318164825
[32m[0511 11:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.17417387664318085, Train Loss: 0.1837948113679886
[32m[0511 11:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.1741761714220047, Train Loss: 0.18379218876361847
[32m[0511 11:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.1741786003112793, Train Loss: 0.18378974497318268
[32m[0511 11:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.17418110370635986, Train Loss: 0.18378734588623047
[32m[0511 11:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.17418363690376282, Train Loss: 0.18378505110740662
[32m[0511 11:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.17418624460697174, Train Loss: 0.18378284573554993
[32m[0511 11:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.17418885231018066, Train Loss: 0.1837807148694992
[32m[0511 11:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.17419148981571198, Train Loss: 0.18377865850925446
[32m[0511 11:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.17419414222240448, Train Loss: 0.1837766170501709
[32m[0511 11:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.17419680953025818, Train Loss: 0.1837746500968933
[32m[0511 11:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.17419946193695068, Train Loss: 0.1837727278470993
[32m[0511 11:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.1742021143436432, Train Loss: 0.18377085030078888
[32m[0511 11:03:26 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.1742047816514969, Train Loss: 0.18376900255680084
[32m[0511 11:03:27 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.1742073893547058, Train Loss: 0.1837671846151352
[32m[0511 11:03:27 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.17420999705791473, Train Loss: 0.18376539647579193
[32m[0511 11:03:27 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.17421261966228485, Train Loss: 0.18376365303993225
[32m[0511 11:03:27 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.1742151826620102, Train Loss: 0.18376192450523376
[32m[0511 11:03:27 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.17421776056289673, Train Loss: 0.18376022577285767
[32m[0511 11:03:27 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.17422030866146088, Train Loss: 0.18375854194164276
[32m[0511 11:03:27 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.17422285676002502, Train Loss: 0.18375688791275024
[32m[0511 11:03:27 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.17422538995742798, Train Loss: 0.1837552934885025
[32m[0511 11:03:27 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.17422787845134735, Train Loss: 0.18375363945960999
[32m[0511 11:03:27 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.17423033714294434, Train Loss: 0.18375205993652344
[32m[0511 11:03:27 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.1742328405380249, Train Loss: 0.18375049531459808
[32m[0511 11:03:27 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.1742352843284607, Train Loss: 0.18374894559383392
[32m[0511 11:03:27 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.17423772811889648, Train Loss: 0.18374739587306976
[32m[0511 11:03:27 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.1742401421070099, Train Loss: 0.1837458610534668
[32m[0511 11:03:27 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.1742425411939621, Train Loss: 0.18374435603618622
[32m[0511 11:03:27 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.1742449402809143, Train Loss: 0.18374286592006683
[32m[0511 11:03:27 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.17424733936786652, Train Loss: 0.18374137580394745
[32m[0511 11:03:27 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.17424970865249634, Train Loss: 0.18373991549015045
[32m[0511 11:03:27 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.17425206303596497, Train Loss: 0.18373847007751465
[32m[0511 11:03:27 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.1742543876171112, Train Loss: 0.18373702466487885
[32m[0511 11:03:27 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.17425675690174103, Train Loss: 0.18373562395572662
[32m[0511 11:03:27 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.17425906658172607, Train Loss: 0.18373417854309082
[32m[0511 11:03:27 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.17426136136054993, Train Loss: 0.1837327629327774
[32m[0511 11:03:27 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.17426365613937378, Train Loss: 0.1837313324213028
[32m[0511 11:03:27 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.17426595091819763, Train Loss: 0.18372997641563416
[32m[0511 11:03:27 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.1742682009935379, Train Loss: 0.18372862040996552
[32m[0511 11:03:27 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.17427045106887817, Train Loss: 0.1837272346019745
[32m[0511 11:03:27 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.17427271604537964, Train Loss: 0.18372586369514465
[32m[0511 11:03:28 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.1742749661207199, Train Loss: 0.1837245374917984
[32m[0511 11:03:28 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.1742771863937378, Train Loss: 0.18372316658496857
[32m[0511 11:03:28 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.17427942156791687, Train Loss: 0.18372184038162231
[32m[0511 11:03:28 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.17428161203861237, Train Loss: 0.18372052907943726
[32m[0511 11:03:28 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.17428381741046906, Train Loss: 0.183719202876091
[32m[0511 11:03:28 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.17428600788116455, Train Loss: 0.18371789157390594
[32m[0511 11:03:28 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.17428818345069885, Train Loss: 0.1837165802717209
[32m[0511 11:03:28 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.17429035902023315, Train Loss: 0.1837153136730194
[32m[0511 11:03:28 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.17429250478744507, Train Loss: 0.18371398746967316
[32m[0511 11:03:28 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.17429465055465698, Train Loss: 0.18371272087097168
[32m[0511 11:03:28 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.17429685592651367, Train Loss: 0.1837114542722702
[32m[0511 11:03:28 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.174298956990242, Train Loss: 0.18371015787124634
[32m[0511 11:03:28 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.17430105805397034, Train Loss: 0.18370892107486725
[32m[0511 11:03:28 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.17430321872234344, Train Loss: 0.18370766937732697
[32m[0511 11:03:28 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.17430530488491058, Train Loss: 0.18370641767978668
[32m[0511 11:03:28 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.17430740594863892, Train Loss: 0.1837051510810852
[32m[0511 11:03:28 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.17430952191352844, Train Loss: 0.18370391428470612
[32m[0511 11:03:28 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.17431160807609558, Train Loss: 0.18370267748832703
[32m[0511 11:03:28 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.17431369423866272, Train Loss: 0.18370145559310913
[32m[0511 11:03:28 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.17431575059890747, Train Loss: 0.18370023369789124
[32m[0511 11:03:28 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.17431782186031342, Train Loss: 0.18369898200035095
[32m[0511 11:03:28 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.17431987822055817, Train Loss: 0.18369780480861664
[32m[0511 11:03:28 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.17432193458080292, Train Loss: 0.18369656801223755
[32m[0511 11:03:28 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.17432399094104767, Train Loss: 0.18369536101818085
[32m[0511 11:03:28 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.17432601749897003, Train Loss: 0.18369416892528534
[32m[0511 11:03:28 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.1743280589580536, Train Loss: 0.18369294703006744
[32m[0511 11:03:28 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.17433010041713715, Train Loss: 0.18369178473949432
[32m[0511 11:03:28 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.17433208227157593, Train Loss: 0.18369059264659882
[32m[0511 11:03:29 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.1743340939283371, Train Loss: 0.1836894005537033
[32m[0511 11:03:29 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.17433612048625946, Train Loss: 0.183688223361969
[32m[0511 11:03:29 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.17433808743953705, Train Loss: 0.18368704617023468
[32m[0511 11:03:29 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.17434008419513702, Train Loss: 0.18368591368198395
[32m[0511 11:03:29 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.1743420511484146, Train Loss: 0.18368472158908844
[32m[0511 11:03:29 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.1743440479040146, Train Loss: 0.18368352949619293
[32m[0511 11:03:29 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.17434601485729218, Train Loss: 0.1836823672056198
[32m[0511 11:03:29 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.17434798181056976, Train Loss: 0.18368121981620789
[32m[0511 11:03:29 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.17434994876384735, Train Loss: 0.18368005752563477
[32m[0511 11:03:29 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.17435190081596375, Train Loss: 0.18367889523506165
[32m[0511 11:03:29 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.17435385286808014, Train Loss: 0.18367774784564972
[32m[0511 11:03:29 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.17435577511787415, Train Loss: 0.1836765706539154
[32m[0511 11:03:29 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.17435769736766815, Train Loss: 0.18367545306682587
[32m[0511 11:03:29 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.17435963451862335, Train Loss: 0.18367430567741394
[32m[0511 11:03:29 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.17436155676841736, Train Loss: 0.1836731731891632
[32m[0511 11:03:29 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.17436347901821136, Train Loss: 0.18367204070091248
[32m[0511 11:03:29 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.17436538636684418, Train Loss: 0.18367092311382294
[32m[0511 11:03:29 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.1743672788143158, Train Loss: 0.18366976082324982
[32m[0511 11:03:29 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.1743691861629486, Train Loss: 0.18366862833499908
[32m[0511 11:03:29 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.17437107861042023, Train Loss: 0.18366751074790955
[32m[0511 11:03:29 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.17437295615673065, Train Loss: 0.18366639316082
[32m[0511 11:03:29 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.17437484860420227, Train Loss: 0.18366527557373047
[32m[0511 11:03:29 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.1743767112493515, Train Loss: 0.18366414308547974
[32m[0511 11:03:29 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.17437860369682312, Train Loss: 0.18366305530071259
[32m[0511 11:03:29 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.17438048124313354, Train Loss: 0.18366190791130066
[32m[0511 11:03:29 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.17438232898712158, Train Loss: 0.18366079032421112
[32m[0511 11:03:29 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.17438416182994843, Train Loss: 0.18365970253944397
[32m[0511 11:03:29 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.17438602447509766, Train Loss: 0.18365857005119324
[32m[0511 11:03:29 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.1743878424167633, Train Loss: 0.1836574673652649
[32m[0511 11:03:30 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.17438971996307373, Train Loss: 0.18365637958049774
[32m[0511 11:03:30 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.174391508102417, Train Loss: 0.183655247092247
[32m[0511 11:03:30 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.17439334094524384, Train Loss: 0.18365415930747986
[32m[0511 11:03:30 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.17439518868923187, Train Loss: 0.1836530566215515
[32m[0511 11:03:30 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.17439699172973633, Train Loss: 0.18365196883678436
[32m[0511 11:03:30 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.17439879477024078, Train Loss: 0.1836508810520172
[32m[0511 11:03:30 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.17440061271190643, Train Loss: 0.18364979326725006
[32m[0511 11:03:30 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.1744024008512497, Train Loss: 0.18364867568016052
[32m[0511 11:03:30 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.17440421879291534, Train Loss: 0.18364760279655457
[32m[0511 11:03:30 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.1744060218334198, Train Loss: 0.18364648520946503
[32m[0511 11:03:30 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.17440776526927948, Train Loss: 0.18364542722702026
[32m[0511 11:03:30 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.17440956830978394, Train Loss: 0.1836443394422531
[32m[0511 11:03:30 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.1744113266468048, Train Loss: 0.18364326655864716
[32m[0511 11:03:30 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.17441309988498688, Train Loss: 0.1836421638727188
[32m[0511 11:03:30 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.17441485822200775, Train Loss: 0.18364109098911285
[32m[0511 11:03:30 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.174416646361351, Train Loss: 0.1836400032043457
[32m[0511 11:03:30 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.1744183599948883, Train Loss: 0.18363894522190094
[32m[0511 11:03:30 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.17442013323307037, Train Loss: 0.18363787233829498
[32m[0511 11:03:30 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.17442187666893005, Train Loss: 0.18363679945468903
[32m[0511 11:03:30 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.17442362010478973, Train Loss: 0.18363571166992188
[32m[0511 11:03:30 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.1744253784418106, Train Loss: 0.1836346536874771
[32m[0511 11:03:30 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.1744270771741867, Train Loss: 0.18363358080387115
[32m[0511 11:03:30 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.1744288206100464, Train Loss: 0.1836325228214264
[32m[0511 11:03:30 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.17443053424358368, Train Loss: 0.18363143503665924
[32m[0511 11:03:30 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.17443223297595978, Train Loss: 0.18363036215305328
[32m[0511 11:03:30 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.17443397641181946, Train Loss: 0.18362927436828613
[32m[0511 11:03:30 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.17443567514419556, Train Loss: 0.18362824618816376
[32m[0511 11:03:30 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.17443737387657166, Train Loss: 0.1836271733045578
[32m[0511 11:03:30 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.17443908751010895, Train Loss: 0.18362613022327423
[32m[0511 11:03:31 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.17444075644016266, Train Loss: 0.18362505733966827
[32m[0511 11:03:31 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.17444244027137756, Train Loss: 0.1836240142583847
[32m[0511 11:03:31 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.17444413900375366, Train Loss: 0.18362292647361755
[32m[0511 11:03:31 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.17444585263729095, Train Loss: 0.18362188339233398
[32m[0511 11:03:31 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.17444749176502228, Train Loss: 0.18362084031105042
[32m[0511 11:03:31 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.174449160695076, Train Loss: 0.18361976742744446
[32m[0511 11:03:31 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.1744508147239685, Train Loss: 0.1836187243461609
[32m[0511 11:03:31 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.17445246875286102, Train Loss: 0.18361766636371613
[32m[0511 11:03:31 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.17445413768291473, Train Loss: 0.18361660838127136
[32m[0511 11:03:31 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.17445579171180725, Train Loss: 0.1836155503988266
[32m[0511 11:03:31 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.17445743083953857, Train Loss: 0.18361450731754303
[32m[0511 11:03:31 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.1744590699672699, Train Loss: 0.18361347913742065
[32m[0511 11:03:31 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.17446070909500122, Train Loss: 0.1836124062538147
[32m[0511 11:03:31 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.17446234822273254, Train Loss: 0.18361136317253113
[32m[0511 11:03:31 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.17446400225162506, Train Loss: 0.18361030519008636
[32m[0511 11:03:31 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.174465611577034, Train Loss: 0.1836092621088028
[32m[0511 11:03:31 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.17446722090244293, Train Loss: 0.1836082488298416
[32m[0511 11:03:31 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.17446886003017426, Train Loss: 0.18360716104507446
[32m[0511 11:03:31 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.17447048425674438, Train Loss: 0.1836061328649521
[32m[0511 11:03:31 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.17447206377983093, Train Loss: 0.1836051046848297
[32m[0511 11:03:31 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.17447367310523987, Train Loss: 0.18360404670238495
[32m[0511 11:03:31 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.17447525262832642, Train Loss: 0.18360301852226257
[32m[0511 11:03:31 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.17447686195373535, Train Loss: 0.1836019903421402
[32m[0511 11:03:31 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.1744784563779831, Train Loss: 0.18360091745853424
[32m[0511 11:03:31 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.17448006570339203, Train Loss: 0.18359988927841187
[32m[0511 11:03:31 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.17448163032531738, Train Loss: 0.1835988461971283
[32m[0511 11:03:31 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.17448319494724274, Train Loss: 0.18359781801700592
[32m[0511 11:03:31 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.17448478937149048, Train Loss: 0.18359678983688354
[32m[0511 11:03:31 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.17448636889457703, Train Loss: 0.18359574675559998
[32m[0511 11:03:32 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.17448793351650238, Train Loss: 0.1835947185754776
[32m[0511 11:03:32 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.17448948323726654, Train Loss: 0.18359369039535522
[32m[0511 11:03:32 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.1744910478591919, Train Loss: 0.18359263241291046
[32m[0511 11:03:32 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.17449262738227844, Train Loss: 0.18359160423278809
[32m[0511 11:03:32 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.1744941622018814, Train Loss: 0.1835905909538269
[32m[0511 11:03:32 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.17449571192264557, Train Loss: 0.18358951807022095
[32m[0511 11:03:32 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.17449724674224854, Train Loss: 0.18358850479125977
[32m[0511 11:03:32 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.1744988113641739, Train Loss: 0.1835874766111374
[32m[0511 11:03:32 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.17450030148029327, Train Loss: 0.18358644843101501
[32m[0511 11:03:32 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.17450186610221863, Train Loss: 0.18358542025089264
[32m[0511 11:03:32 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.1745033711194992, Train Loss: 0.18358437716960907
[32m[0511 11:03:32 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.17450495064258575, Train Loss: 0.1835833489894867
[32m[0511 11:03:32 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.17450645565986633, Train Loss: 0.18358232080936432
[32m[0511 11:03:32 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.17450794577598572, Train Loss: 0.18358129262924194
[32m[0511 11:03:32 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.1745094656944275, Train Loss: 0.18358026444911957
[32m[0511 11:03:32 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.17451098561286926, Train Loss: 0.183579221367836
[32m[0511 11:03:32 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.17451250553131104, Train Loss: 0.18357820808887482
[32m[0511 11:03:32 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.1745140105485916, Train Loss: 0.18357719480991364
[32m[0511 11:03:32 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.1745155155658722, Train Loss: 0.18357616662979126
[32m[0511 11:03:32 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.1745169758796692, Train Loss: 0.18357513844966888
[32m[0511 11:03:32 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.17451849579811096, Train Loss: 0.1835741102695465
[32m[0511 11:03:32 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.17451998591423035, Train Loss: 0.18357308208942413
[32m[0511 11:03:32 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.17452146112918854, Train Loss: 0.18357206881046295
[32m[0511 11:03:32 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.17452295124530792, Train Loss: 0.18357104063034058
[32m[0511 11:03:32 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.1745244413614273, Train Loss: 0.1835699826478958
[32m[0511 11:03:32 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.1745259016752243, Train Loss: 0.18356898427009583
[32m[0511 11:03:32 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.1745273917913437, Train Loss: 0.18356797099113464
[32m[0511 11:03:32 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.17452885210514069, Train Loss: 0.18356694281101227
[32m[0511 11:03:32 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.17453031241893768, Train Loss: 0.1835659146308899
[32m[0511 11:03:33 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.17453180253505707, Train Loss: 0.18356488645076752
[32m[0511 11:03:33 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.17453326284885406, Train Loss: 0.18356387317180634
[32m[0511 11:03:33 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.17453470826148987, Train Loss: 0.18356284499168396
[32m[0511 11:03:33 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.17453615367412567, Train Loss: 0.18356184661388397
[32m[0511 11:03:33 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.17453761398792267, Train Loss: 0.1835607886314392
[32m[0511 11:03:33 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.17453905940055847, Train Loss: 0.18355979025363922
[32m[0511 11:03:33 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.17454050481319427, Train Loss: 0.18355876207351685
[32m[0511 11:03:33 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.17454193532466888, Train Loss: 0.18355773389339447
[32m[0511 11:03:33 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.17454339563846588, Train Loss: 0.18355673551559448
[32m[0511 11:03:33 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.1745448261499405, Train Loss: 0.1835556924343109
[32m[0511 11:03:33 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.1745462566614151, Train Loss: 0.18355467915534973
[32m[0511 11:03:33 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.1745476871728897, Train Loss: 0.18355365097522736
[32m[0511 11:03:33 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.17454911768436432, Train Loss: 0.18355266749858856
[32m[0511 11:03:33 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.17455053329467773, Train Loss: 0.1835516095161438
[32m[0511 11:03:33 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.17455194890499115, Train Loss: 0.1835506111383438
[32m[0511 11:03:33 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.17455337941646576, Train Loss: 0.18354958295822144
[32m[0511 11:03:33 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.17455479502677917, Train Loss: 0.18354858458042145
[32m[0511 11:03:33 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.1745562106370926, Train Loss: 0.18354754149913788
[32m[0511 11:03:33 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.174557626247406, Train Loss: 0.1835465133190155
[32m[0511 11:03:33 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.17455904185771942, Train Loss: 0.18354551494121552
[32m[0511 11:03:33 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.17456044256687164, Train Loss: 0.18354447185993195
[32m[0511 11:03:33 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.17456185817718506, Train Loss: 0.18354348838329315
[32m[0511 11:03:33 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.17456325888633728, Train Loss: 0.18354246020317078
[32m[0511 11:03:33 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.1745646595954895, Train Loss: 0.1835414469242096
[32m[0511 11:03:33 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.17456603050231934, Train Loss: 0.18354041874408722
[32m[0511 11:03:33 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.17456743121147156, Train Loss: 0.18353940546512604
[32m[0511 11:03:33 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.17456881701946259, Train Loss: 0.18353840708732605
[32m[0511 11:03:33 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.174570232629776, Train Loss: 0.18353737890720367
[32m[0511 11:03:33 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.17457161843776703, Train Loss: 0.1835363507270813
[32m[0511 11:03:34 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.17457298934459686, Train Loss: 0.1835353523492813
[32m[0511 11:03:34 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.1745743751525879, Train Loss: 0.18353435397148132
[32m[0511 11:03:34 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.17457576096057892, Train Loss: 0.18353328108787537
[32m[0511 11:03:34 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.17457714676856995, Train Loss: 0.18353229761123657
[32m[0511 11:03:34 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.1745785027742386, Train Loss: 0.1835312694311142
[32m[0511 11:03:34 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.17457987368106842, Train Loss: 0.1835302859544754
[32m[0511 11:03:34 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.17458124458789825, Train Loss: 0.18352922797203064
[32m[0511 11:03:34 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.1745826005935669, Train Loss: 0.18352822959423065
[32m[0511 11:03:34 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.17458398640155792, Train Loss: 0.18352720141410828
[32m[0511 11:03:34 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.17458535730838776, Train Loss: 0.18352621793746948
[32m[0511 11:03:34 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.1745867133140564, Train Loss: 0.1835251748561859
[32m[0511 11:03:34 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.17458805441856384, Train Loss: 0.18352414667606354
[32m[0511 11:03:34 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.17458942532539368, Train Loss: 0.18352316319942474
[32m[0511 11:03:34 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.17459078133106232, Train Loss: 0.18352213501930237
[32m[0511 11:03:34 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.17459213733673096, Train Loss: 0.1835211217403412
[32m[0511 11:03:34 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.1745934933423996, Train Loss: 0.1835200935602188
[32m[0511 11:03:34 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.17459484934806824, Train Loss: 0.18351906538009644
[32m[0511 11:03:34 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.17459619045257568, Train Loss: 0.18351808190345764
[32m[0511 11:03:34 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.17459753155708313, Train Loss: 0.18351703882217407
[32m[0511 11:03:34 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.17459888756275177, Train Loss: 0.18351605534553528
[32m[0511 11:03:34 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.17460022866725922, Train Loss: 0.1835150271654129
[32m[0511 11:03:34 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.17460155487060547, Train Loss: 0.18351398408412933
[32m[0511 11:03:34 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.1746029108762741, Train Loss: 0.18351300060749054
[32m[0511 11:03:34 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.17460425198078156, Train Loss: 0.18351198732852936
[32m[0511 11:03:34 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.1746055632829666, Train Loss: 0.1835109442472458
[32m[0511 11:03:34 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.17460694909095764, Train Loss: 0.1835099309682846
[32m[0511 11:03:34 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.1746082454919815, Train Loss: 0.18350893259048462
[32m[0511 11:03:34 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.17460958659648895, Train Loss: 0.18350791931152344
[32m[0511 11:03:34 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.1746109127998352, Train Loss: 0.18350690603256226
[32m[0511 11:03:35 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.17461222410202026, Train Loss: 0.1835058629512787
[32m[0511 11:03:35 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.17461355030536652, Train Loss: 0.1835048645734787
[32m[0511 11:03:35 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.17461489140987396, Train Loss: 0.18350385129451752
[32m[0511 11:03:35 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.17461620271205902, Train Loss: 0.18350283801555634
[32m[0511 11:03:35 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.17461752891540527, Train Loss: 0.18350182473659515
[32m[0511 11:03:35 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.17461887001991272, Train Loss: 0.18350079655647278
[32m[0511 11:03:35 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.17462016642093658, Train Loss: 0.1834997832775116
[32m[0511 11:03:35 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.17462149262428284, Train Loss: 0.18349876999855042
[32m[0511 11:03:35 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.1746228188276291, Train Loss: 0.18349774181842804
[32m[0511 11:03:35 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.17462413012981415, Train Loss: 0.18349674344062805
[32m[0511 11:03:35 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.1746254414319992, Train Loss: 0.18349570035934448
[32m[0511 11:03:35 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.17462678253650665, Train Loss: 0.1834947019815445
[32m[0511 11:03:35 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.17462807893753052, Train Loss: 0.18349367380142212
[32m[0511 11:03:35 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.17462939023971558, Train Loss: 0.18349266052246094
[32m[0511 11:03:35 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.17463070154190063, Train Loss: 0.18349166214466095
[32m[0511 11:03:35 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.1746320128440857, Train Loss: 0.1834906041622162
[32m[0511 11:03:35 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.17463332414627075, Train Loss: 0.1834896057844162
[32m[0511 11:03:35 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.1746346354484558, Train Loss: 0.18348859250545502
[32m[0511 11:03:35 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.17463593184947968, Train Loss: 0.18348757922649384
[32m[0511 11:03:35 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.17463721334934235, Train Loss: 0.18348656594753265
[32m[0511 11:03:35 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.1746385097503662, Train Loss: 0.18348555266857147
[32m[0511 11:03:35 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.17463982105255127, Train Loss: 0.1834845244884491
[32m[0511 11:03:35 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.17464111745357513, Train Loss: 0.1834835261106491
[32m[0511 11:03:35 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.1746424287557602, Train Loss: 0.18348248302936554
[32m[0511 11:03:35 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.17464372515678406, Train Loss: 0.18348146975040436
[32m[0511 11:03:35 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.17464503645896912, Train Loss: 0.18348045647144318
[32m[0511 11:03:35 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.1746463179588318, Train Loss: 0.1834794580936432
[32m[0511 11:03:35 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.17464764416217804, Train Loss: 0.18347841501235962
[32m[0511 11:03:35 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.1746489256620407, Train Loss: 0.18347738683223724
[32m[0511 11:03:36 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.17465020716190338, Train Loss: 0.18347638845443726
[32m[0511 11:03:36 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.17465153336524963, Train Loss: 0.18347536027431488
[32m[0511 11:03:36 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.1746527999639511, Train Loss: 0.1834743618965149
[32m[0511 11:03:36 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.17465409636497498, Train Loss: 0.1834733486175537
[32m[0511 11:03:36 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.17465539276599884, Train Loss: 0.18347232043743134
[32m[0511 11:03:36 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.1746566891670227, Train Loss: 0.18347127735614777
[32m[0511 11:03:36 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.17465798556804657, Train Loss: 0.18347026407718658
[32m[0511 11:03:36 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.17465926706790924, Train Loss: 0.1834692507982254
[32m[0511 11:03:36 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.1746605783700943, Train Loss: 0.18346823751926422
[32m[0511 11:03:36 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.17466184496879578, Train Loss: 0.18346720933914185
[32m[0511 11:03:36 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.17466314136981964, Train Loss: 0.18346621096134186
[32m[0511 11:03:36 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.1746644228696823, Train Loss: 0.18346518278121948
[32m[0511 11:03:36 @mbmf_sampler.py:98][0m Finished 9th episode
[32m[0511 11:03:36 @mbmf_sampler.py:102][0m 1809 timesteps from 9 episodes collected
[32m[0511 11:22:27 @mbmf_trainer.py:160][0m Mean reward: -1217.8598686063565
[32m[0511 11:22:27 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.17911846935749054, Train Loss: 0.17981308698654175
[32m[0511 11:22:27 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.1792270839214325, Train Loss: 0.17976656556129456
[32m[0511 11:22:27 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.1793041229248047, Train Loss: 0.17974738776683807
[32m[0511 11:22:27 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.17934457957744598, Train Loss: 0.179737851023674
[32m[0511 11:22:28 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.17937150597572327, Train Loss: 0.17972822487354279
[32m[0511 11:22:28 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.17939594388008118, Train Loss: 0.17972047626972198
[32m[0511 11:22:28 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.17941811680793762, Train Loss: 0.179713636636734
[32m[0511 11:22:28 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.1794385313987732, Train Loss: 0.17970791459083557
[32m[0511 11:22:28 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.1794569045305252, Train Loss: 0.1797029674053192
[32m[0511 11:22:28 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.17947345972061157, Train Loss: 0.17969858646392822
[32m[0511 11:22:28 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.179488405585289, Train Loss: 0.17969465255737305
[32m[0511 11:22:28 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.17950204014778137, Train Loss: 0.17969103157520294
[32m[0511 11:22:28 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.17951452732086182, Train Loss: 0.17968764901161194
[32m[0511 11:22:28 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.17952601611614227, Train Loss: 0.17968450486660004
[32m[0511 11:22:28 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.17953667044639587, Train Loss: 0.17968147993087769
[32m[0511 11:22:28 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.17954657971858978, Train Loss: 0.1796785593032837
[32m[0511 11:22:28 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.17955586314201355, Train Loss: 0.17967581748962402
[32m[0511 11:22:28 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.17956461012363434, Train Loss: 0.17967313528060913
[32m[0511 11:22:28 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.1795729100704193, Train Loss: 0.1796705275774002
[32m[0511 11:22:28 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.17958077788352966, Train Loss: 0.17966802418231964
[32m[0511 11:22:28 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.17958830296993256, Train Loss: 0.17966558039188385
[32m[0511 11:22:28 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.179595485329628, Train Loss: 0.17966322600841522
[32m[0511 11:22:28 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.1796024590730667, Train Loss: 0.17966090142726898
[32m[0511 11:22:28 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.17960913479328156, Train Loss: 0.17965862154960632
[32m[0511 11:22:28 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.1796155869960785, Train Loss: 0.17965640127658844
[32m[0511 11:22:28 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.1796218454837799, Train Loss: 0.17965422570705414
[32m[0511 11:22:28 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.17962795495986938, Train Loss: 0.17965209484100342
[32m[0511 11:22:29 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.17963388562202454, Train Loss: 0.17965000867843628
[32m[0511 11:22:29 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.17963969707489014, Train Loss: 0.17964796721935272
[32m[0511 11:22:29 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.1796453595161438, Train Loss: 0.17964597046375275
[32m[0511 11:22:29 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.1796509176492691, Train Loss: 0.17964398860931396
[32m[0511 11:22:29 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.17965635657310486, Train Loss: 0.17964205145835876
[32m[0511 11:22:29 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.17966169118881226, Train Loss: 0.17964015901088715
[32m[0511 11:22:29 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.1796668916940689, Train Loss: 0.17963828146457672
[32m[0511 11:22:29 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.17967206239700317, Train Loss: 0.17963643372058868
[32m[0511 11:22:29 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.17967712879180908, Train Loss: 0.17963463068008423
[32m[0511 11:22:29 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.17968213558197021, Train Loss: 0.17963285744190216
[32m[0511 11:22:29 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.17968705296516418, Train Loss: 0.1796310693025589
[32m[0511 11:22:29 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.17969189584255219, Train Loss: 0.1796293705701828
[32m[0511 11:22:29 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.1796966940164566, Train Loss: 0.1796276569366455
[32m[0511 11:22:29 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.17970140278339386, Train Loss: 0.1796259880065918
[32m[0511 11:22:29 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.17970609664916992, Train Loss: 0.17962433397769928
[32m[0511 11:22:29 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.17971068620681763, Train Loss: 0.17962269484996796
[32m[0511 11:22:29 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.17971523106098175, Train Loss: 0.17962110042572021
[32m[0511 11:22:29 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.1797197312116623, Train Loss: 0.17961950600147247
[32m[0511 11:22:29 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.17972420156002045, Train Loss: 0.17961794137954712
[32m[0511 11:22:29 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.17972861230373383, Train Loss: 0.17961640655994415
[32m[0511 11:22:29 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.17973297834396362, Train Loss: 0.17961490154266357
[32m[0511 11:22:29 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.17973726987838745, Train Loss: 0.1796133667230606
[32m[0511 11:22:29 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.1797415316104889, Train Loss: 0.17961189150810242
[32m[0511 11:22:30 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.17974576354026794, Train Loss: 0.17961041629314423
[32m[0511 11:22:30 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.17974995076656342, Train Loss: 0.17960898578166962
[32m[0511 11:22:30 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.1797541081905365, Train Loss: 0.17960752546787262
[32m[0511 11:22:30 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.1797582060098648, Train Loss: 0.1796061247587204
[32m[0511 11:22:30 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.17976227402687073, Train Loss: 0.17960475385189056
[32m[0511 11:22:30 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.17976631224155426, Train Loss: 0.17960335314273834
[32m[0511 11:22:30 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.1797703206539154, Train Loss: 0.1796019971370697
[32m[0511 11:22:30 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.17977429926395416, Train Loss: 0.17960065603256226
[32m[0511 11:22:30 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.17977823317050934, Train Loss: 0.1795993149280548
[32m[0511 11:22:30 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.17978212237358093, Train Loss: 0.17959798872470856
[32m[0511 11:22:30 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.17978598177433014, Train Loss: 0.1795966923236847
[32m[0511 11:22:30 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.17978984117507935, Train Loss: 0.17959539592266083
[32m[0511 11:22:30 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.17979364097118378, Train Loss: 0.17959409952163696
[32m[0511 11:22:30 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.17979741096496582, Train Loss: 0.17959283292293549
[32m[0511 11:22:30 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.17980116605758667, Train Loss: 0.17959155142307281
[32m[0511 11:22:30 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.17980486154556274, Train Loss: 0.17959032952785492
[32m[0511 11:22:30 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.17980854213237762, Train Loss: 0.17958910763263702
[32m[0511 11:22:30 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.1798122227191925, Train Loss: 0.17958788573741913
[32m[0511 11:22:30 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.1798158586025238, Train Loss: 0.17958667874336243
[32m[0511 11:22:30 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.17981944978237152, Train Loss: 0.17958548665046692
[32m[0511 11:22:30 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.17982305586338043, Train Loss: 0.1795842945575714
[32m[0511 11:22:30 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.17982658743858337, Train Loss: 0.1795831024646759
[32m[0511 11:22:30 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.17983010411262512, Train Loss: 0.1795819252729416
[32m[0511 11:22:31 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.17983360588550568, Train Loss: 0.17958076298236847
[32m[0511 11:22:31 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.17983709275722504, Train Loss: 0.17957961559295654
[32m[0511 11:22:31 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.179840549826622, Train Loss: 0.1795784831047058
[32m[0511 11:22:31 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.1798439621925354, Train Loss: 0.17957736551761627
[32m[0511 11:22:31 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.1798473596572876, Train Loss: 0.17957620322704315
[32m[0511 11:22:31 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.1798507273197174, Train Loss: 0.1795751005411148
[32m[0511 11:22:31 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.17985409498214722, Train Loss: 0.17957399785518646
[32m[0511 11:22:31 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.17985743284225464, Train Loss: 0.17957288026809692
[32m[0511 11:22:31 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.17986074090003967, Train Loss: 0.17957180738449097
[32m[0511 11:22:31 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.1798640340566635, Train Loss: 0.17957071959972382
[32m[0511 11:22:31 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.17986728250980377, Train Loss: 0.17956963181495667
[32m[0511 11:22:31 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.17987053096294403, Train Loss: 0.1795685738325119
[32m[0511 11:22:31 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.1798737645149231, Train Loss: 0.17956751585006714
[32m[0511 11:22:31 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.17987695336341858, Train Loss: 0.1795664280653
[32m[0511 11:22:31 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.17988012731075287, Train Loss: 0.17956538498401642
[32m[0511 11:22:31 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.17988330125808716, Train Loss: 0.17956434190273285
[32m[0511 11:22:31 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.17988643050193787, Train Loss: 0.17956329882144928
[32m[0511 11:22:31 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.1798895299434662, Train Loss: 0.1795622706413269
[32m[0511 11:22:31 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.1798926442861557, Train Loss: 0.17956125736236572
[32m[0511 11:22:31 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.17989572882652283, Train Loss: 0.17956022918224335
[32m[0511 11:22:31 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.17989876866340637, Train Loss: 0.17955918610095978
[32m[0511 11:22:31 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.1799018234014511, Train Loss: 0.17955820262432098
[32m[0511 11:22:31 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.17990483343601227, Train Loss: 0.179557204246521
[32m[0511 11:22:31 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.17990784347057343, Train Loss: 0.17955619096755981
[32m[0511 11:22:32 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.1799108386039734, Train Loss: 0.17955519258975983
[32m[0511 11:22:32 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.17991378903388977, Train Loss: 0.17955419421195984
[32m[0511 11:22:32 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.17991673946380615, Train Loss: 0.17955321073532104
[32m[0511 11:22:32 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.17991967499256134, Train Loss: 0.17955222725868225
[32m[0511 11:22:32 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.17992258071899414, Train Loss: 0.17955125868320465
[32m[0511 11:22:32 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.17992547154426575, Train Loss: 0.17955027520656586
[32m[0511 11:22:32 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.17992834746837616, Train Loss: 0.17954930663108826
[32m[0511 11:22:32 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.17993120849132538, Train Loss: 0.17954835295677185
[32m[0511 11:22:32 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.1799340397119522, Train Loss: 0.17954736948013306
[32m[0511 11:22:32 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.17993685603141785, Train Loss: 0.17954644560813904
[32m[0511 11:22:32 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.17993967235088348, Train Loss: 0.17954547703266144
[32m[0511 11:22:32 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.17994247376918793, Train Loss: 0.17954452335834503
[32m[0511 11:22:32 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.1799452304840088, Train Loss: 0.179543599486351
[32m[0511 11:22:32 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.17994798719882965, Train Loss: 0.1795426458120346
[32m[0511 11:22:32 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.1799507439136505, Train Loss: 0.1795417070388794
[32m[0511 11:22:32 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.1799534559249878, Train Loss: 0.179540753364563
[32m[0511 11:22:32 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.17995616793632507, Train Loss: 0.17953984439373016
[32m[0511 11:22:32 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.17995886504650116, Train Loss: 0.17953890562057495
[32m[0511 11:22:32 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.17996153235435486, Train Loss: 0.17953796684741974
[32m[0511 11:22:32 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.17996421456336975, Train Loss: 0.17953704297542572
[32m[0511 11:22:32 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.17996685206890106, Train Loss: 0.1795361489057541
[32m[0511 11:22:32 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.17996948957443237, Train Loss: 0.17953521013259888
[32m[0511 11:22:32 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.1799721121788025, Train Loss: 0.17953431606292725
[32m[0511 11:22:33 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.17997470498085022, Train Loss: 0.17953342199325562
[32m[0511 11:22:33 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.17997731268405914, Train Loss: 0.1795324832201004
[32m[0511 11:22:33 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.1799798607826233, Train Loss: 0.17953158915042877
[32m[0511 11:22:33 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.17998242378234863, Train Loss: 0.17953068017959595
[32m[0511 11:22:33 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.17998497188091278, Train Loss: 0.17952978610992432
[32m[0511 11:22:33 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.17998749017715454, Train Loss: 0.1795288771390915
[32m[0511 11:22:33 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.1799900233745575, Train Loss: 0.17952801287174225
[32m[0511 11:22:33 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.17999249696731567, Train Loss: 0.17952710390090942
[32m[0511 11:22:33 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.17999501526355743, Train Loss: 0.179526224732399
[32m[0511 11:22:33 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.1799974888563156, Train Loss: 0.17952533066272736
[32m[0511 11:22:33 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.1799999475479126, Train Loss: 0.17952445149421692
[32m[0511 11:22:33 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.18000240623950958, Train Loss: 0.1795235574245453
[32m[0511 11:22:33 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.18000482022762299, Train Loss: 0.17952269315719604
[32m[0511 11:22:33 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.18000724911689758, Train Loss: 0.1795218139886856
[32m[0511 11:22:33 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.180009663105011, Train Loss: 0.17952091991901398
[32m[0511 11:22:33 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.1800120621919632, Train Loss: 0.17952005565166473
[32m[0511 11:22:33 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.1800144463777542, Train Loss: 0.1795191764831543
[32m[0511 11:22:33 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.18001681566238403, Train Loss: 0.17951831221580505
[32m[0511 11:22:33 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.18001918494701385, Train Loss: 0.1795174479484558
[32m[0511 11:22:33 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.1800215244293213, Train Loss: 0.17951659858226776
[32m[0511 11:22:33 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.18002383410930634, Train Loss: 0.17951571941375732
[32m[0511 11:22:33 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.18002617359161377, Train Loss: 0.1795148402452469
[32m[0511 11:22:33 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.18002848327159882, Train Loss: 0.17951399087905884
[32m[0511 11:22:34 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.18003076314926147, Train Loss: 0.17951315641403198
[32m[0511 11:22:34 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.18003305792808533, Train Loss: 0.17951230704784393
[32m[0511 11:22:34 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.1800353080034256, Train Loss: 0.1795114278793335
[32m[0511 11:22:34 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.18003755807876587, Train Loss: 0.17951059341430664
[32m[0511 11:22:34 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.18003982305526733, Train Loss: 0.1795097440481186
[32m[0511 11:22:34 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.1800420582294464, Train Loss: 0.17950889468193054
[32m[0511 11:22:34 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.1800442785024643, Train Loss: 0.1795080453157425
[32m[0511 11:22:34 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.18004649877548218, Train Loss: 0.17950719594955444
[32m[0511 11:22:34 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.18004868924617767, Train Loss: 0.1795063465833664
[32m[0511 11:22:34 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.18005087971687317, Train Loss: 0.17950552701950073
[32m[0511 11:22:34 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.18005307018756866, Train Loss: 0.17950467765331268
[32m[0511 11:22:34 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.18005521595478058, Train Loss: 0.17950382828712463
[32m[0511 11:22:34 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.1800573766231537, Train Loss: 0.17950300872325897
[32m[0511 11:22:34 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.1800595074892044, Train Loss: 0.17950215935707092
[32m[0511 11:22:34 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.18006166815757751, Train Loss: 0.17950132489204407
[32m[0511 11:22:34 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.18006376922130585, Train Loss: 0.1795004904270172
[32m[0511 11:22:34 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.18006588518619537, Train Loss: 0.17949967086315155
[32m[0511 11:22:34 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.1800679713487625, Train Loss: 0.1794988214969635
[32m[0511 11:22:34 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.18007007241249084, Train Loss: 0.17949800193309784
[32m[0511 11:22:34 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.1800721287727356, Train Loss: 0.17949718236923218
[32m[0511 11:22:34 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.18007420003414154, Train Loss: 0.17949636280536652
[32m[0511 11:22:34 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.1800762563943863, Train Loss: 0.17949552834033966
[32m[0511 11:22:34 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.18007831275463104, Train Loss: 0.1794946789741516
[32m[0511 11:22:35 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.1800803393125534, Train Loss: 0.17949387431144714
[32m[0511 11:22:35 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.18008236587047577, Train Loss: 0.17949305474758148
[32m[0511 11:22:35 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.18008439242839813, Train Loss: 0.17949223518371582
[32m[0511 11:22:35 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.18008635938167572, Train Loss: 0.17949141561985016
[32m[0511 11:22:35 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.1800883561372757, Train Loss: 0.1794906109571457
[32m[0511 11:22:35 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.18009036779403687, Train Loss: 0.17948979139328003
[32m[0511 11:22:35 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.18009230494499207, Train Loss: 0.17948897182941437
[32m[0511 11:22:35 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.18009425699710846, Train Loss: 0.1794881522655487
[32m[0511 11:22:35 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.18009622395038605, Train Loss: 0.17948734760284424
[32m[0511 11:22:35 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.18009819090366364, Train Loss: 0.17948651313781738
[32m[0511 11:22:35 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.18010011315345764, Train Loss: 0.1794857233762741
[32m[0511 11:22:35 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.18010203540325165, Train Loss: 0.17948490381240845
[32m[0511 11:22:35 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.18010394275188446, Train Loss: 0.17948409914970398
[32m[0511 11:22:35 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.18010585010051727, Train Loss: 0.17948327958583832
[32m[0511 11:22:35 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.1801077276468277, Train Loss: 0.17948248982429504
[32m[0511 11:22:35 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.18010962009429932, Train Loss: 0.17948167026042938
[32m[0511 11:22:35 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.18011151254177094, Train Loss: 0.1794808804988861
[32m[0511 11:22:35 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.18011336028575897, Train Loss: 0.17948006093502045
[32m[0511 11:22:35 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.18011519312858582, Train Loss: 0.17947927117347717
[32m[0511 11:22:35 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.18011707067489624, Train Loss: 0.1794784516096115
[32m[0511 11:22:35 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.18011891841888428, Train Loss: 0.17947766184806824
[32m[0511 11:22:35 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.18012073636054993, Train Loss: 0.17947685718536377
[32m[0511 11:22:35 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.1801225244998932, Train Loss: 0.1794760525226593
[32m[0511 11:22:36 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.18012434244155884, Train Loss: 0.17947524785995483
[32m[0511 11:22:36 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.1801261007785797, Train Loss: 0.17947447299957275
[32m[0511 11:22:36 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.18012790381908417, Train Loss: 0.17947368323802948
[32m[0511 11:22:36 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.18012970685958862, Train Loss: 0.17947286367416382
[32m[0511 11:22:36 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.18013149499893188, Train Loss: 0.17947207391262054
[32m[0511 11:22:36 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.18013325333595276, Train Loss: 0.17947129905223846
[32m[0511 11:22:36 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.18013499677181244, Train Loss: 0.1794704794883728
[32m[0511 11:22:36 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.18013674020767212, Train Loss: 0.17946970462799072
[32m[0511 11:22:36 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.1801384538412094, Train Loss: 0.17946888506412506
[32m[0511 11:22:36 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.1801401972770691, Train Loss: 0.17946811020374298
[32m[0511 11:22:36 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.1801418960094452, Train Loss: 0.1794673204421997
[32m[0511 11:22:36 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.18014363944530487, Train Loss: 0.17946653068065643
[32m[0511 11:22:36 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.18014532327651978, Train Loss: 0.17946572601795197
[32m[0511 11:22:36 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.18014700710773468, Train Loss: 0.1794649362564087
[32m[0511 11:22:36 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.18014869093894958, Train Loss: 0.17946414649486542
[32m[0511 11:22:36 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.1801503598690033, Train Loss: 0.17946337163448334
[32m[0511 11:22:36 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.180152028799057, Train Loss: 0.17946259677410126
[32m[0511 11:22:36 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.18015368282794952, Train Loss: 0.17946180701255798
[32m[0511 11:22:36 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.18015533685684204, Train Loss: 0.1794610172510147
[32m[0511 11:22:36 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.18015696108341217, Train Loss: 0.17946022748947144
[32m[0511 11:22:36 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.1801586002111435, Train Loss: 0.17945945262908936
[32m[0511 11:22:36 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.18016022443771362, Train Loss: 0.17945866286754608
[32m[0511 11:22:36 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.18016183376312256, Train Loss: 0.179457888007164
[32m[0511 11:22:37 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.1801634281873703, Train Loss: 0.17945711314678192
[32m[0511 11:22:37 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.18016503751277924, Train Loss: 0.17945632338523865
[32m[0511 11:22:37 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.18016661703586578, Train Loss: 0.17945554852485657
[32m[0511 11:22:37 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.18016819655895233, Train Loss: 0.1794547587633133
[32m[0511 11:22:37 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.18016979098320007, Train Loss: 0.17945396900177002
[32m[0511 11:22:37 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.18017135560512543, Train Loss: 0.17945320904254913
[32m[0511 11:22:37 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.1801728904247284, Train Loss: 0.17945244908332825
[32m[0511 11:22:37 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.18017445504665375, Train Loss: 0.17945164442062378
[32m[0511 11:22:37 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.18017597496509552, Train Loss: 0.1794508695602417
[32m[0511 11:22:37 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.18017752468585968, Train Loss: 0.17945009469985962
[32m[0511 11:22:37 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.18017902970314026, Train Loss: 0.17944930493831635
[32m[0511 11:22:37 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.18018056452274323, Train Loss: 0.17944854497909546
[32m[0511 11:22:37 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.18018203973770142, Train Loss: 0.17944777011871338
[32m[0511 11:22:37 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.1801835596561432, Train Loss: 0.1794469803571701
[32m[0511 11:22:37 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.18018504977226257, Train Loss: 0.17944622039794922
[32m[0511 11:22:37 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.18018653988838196, Train Loss: 0.17944546043872833
[32m[0511 11:22:37 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.18018798530101776, Train Loss: 0.17944467067718506
[32m[0511 11:22:37 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.18018947541713715, Train Loss: 0.17944391071796417
[32m[0511 11:22:37 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.18019093573093414, Train Loss: 0.1794431209564209
[32m[0511 11:22:37 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.18019239604473114, Train Loss: 0.1794423609972
[32m[0511 11:22:37 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.18019382655620575, Train Loss: 0.17944160103797913
[32m[0511 11:22:37 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.18019528687000275, Train Loss: 0.17944082617759705
[32m[0511 11:22:37 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.18019670248031616, Train Loss: 0.17944006621837616
[32m[0511 11:22:38 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.18019811809062958, Train Loss: 0.17943927645683289
[32m[0511 11:22:38 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.180199533700943, Train Loss: 0.1794385313987732
[32m[0511 11:22:38 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.1802009493112564, Train Loss: 0.1794377565383911
[32m[0511 11:22:38 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.18020236492156982, Train Loss: 0.17943698167800903
[32m[0511 11:22:38 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.18020372092723846, Train Loss: 0.17943620681762695
[32m[0511 11:22:38 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.18020513653755188, Train Loss: 0.17943544685840607
[32m[0511 11:22:38 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.18020649254322052, Train Loss: 0.17943468689918518
[32m[0511 11:22:38 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.18020787835121155, Train Loss: 0.1794339269399643
[32m[0511 11:22:38 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.180209219455719, Train Loss: 0.1794331669807434
[32m[0511 11:22:38 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.18021057546138763, Train Loss: 0.17943237721920013
[32m[0511 11:22:38 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.18021193146705627, Train Loss: 0.17943163216114044
[32m[0511 11:22:38 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.18021327257156372, Train Loss: 0.17943085730075836
[32m[0511 11:22:38 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.18021459877490997, Train Loss: 0.17943011224269867
[32m[0511 11:22:38 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.18021592497825623, Train Loss: 0.17942935228347778
[32m[0511 11:22:38 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.18021723628044128, Train Loss: 0.1794285923242569
[32m[0511 11:22:38 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.18021857738494873, Train Loss: 0.17942781746387482
[32m[0511 11:22:38 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.1802198588848114, Train Loss: 0.17942705750465393
[32m[0511 11:22:38 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.18022115528583527, Train Loss: 0.17942629754543304
[32m[0511 11:22:38 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.18022246658802032, Train Loss: 0.17942552268505096
[32m[0511 11:22:38 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.180223748087883, Train Loss: 0.17942477762699127
[32m[0511 11:22:38 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.18022499978542328, Train Loss: 0.1794240027666092
[32m[0511 11:22:38 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.18022628128528595, Train Loss: 0.1794232726097107
[32m[0511 11:22:38 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.18022754788398743, Train Loss: 0.1794224977493286
[32m[0511 11:22:39 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.1802288144826889, Train Loss: 0.17942173779010773
[32m[0511 11:22:39 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.180230051279068, Train Loss: 0.17942099273204803
[32m[0511 11:22:39 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.18023130297660828, Train Loss: 0.17942021787166595
[32m[0511 11:22:39 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.18023253977298737, Train Loss: 0.17941947281360626
[32m[0511 11:22:39 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.18023374676704407, Train Loss: 0.17941872775554657
[32m[0511 11:22:39 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.18023498356342316, Train Loss: 0.1794179528951645
[32m[0511 11:22:39 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.18023617565631866, Train Loss: 0.1794171929359436
[32m[0511 11:22:39 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.18023738265037537, Train Loss: 0.1794164627790451
[32m[0511 11:22:39 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.18023861944675446, Train Loss: 0.17941570281982422
[32m[0511 11:22:39 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.18023981153964996, Train Loss: 0.17941494286060333
[32m[0511 11:22:39 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.18024097383022308, Train Loss: 0.17941419780254364
[32m[0511 11:22:39 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.18024218082427979, Train Loss: 0.17941342294216156
[32m[0511 11:22:39 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.1802433282136917, Train Loss: 0.17941267788410187
[32m[0511 11:22:39 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.18024452030658722, Train Loss: 0.17941193282604218
[32m[0511 11:22:39 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.18024568259716034, Train Loss: 0.1794111579656601
[32m[0511 11:22:39 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.18024682998657227, Train Loss: 0.1794104129076004
[32m[0511 11:22:39 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.18024799227714539, Train Loss: 0.1794096827507019
[32m[0511 11:22:39 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.18024912476539612, Train Loss: 0.17940892279148102
[32m[0511 11:22:39 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.18025027215480804, Train Loss: 0.17940819263458252
[32m[0511 11:22:39 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.18025140464305878, Train Loss: 0.17940741777420044
[32m[0511 11:22:39 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.18025252223014832, Train Loss: 0.17940667271614075
[32m[0511 11:22:39 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.18025363981723785, Train Loss: 0.17940591275691986
[32m[0511 11:22:39 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.1802547425031662, Train Loss: 0.17940516769886017
[32m[0511 11:22:39 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.18025584518909454, Train Loss: 0.17940443754196167
[32m[0511 11:22:40 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.18025696277618408, Train Loss: 0.17940367758274078
[32m[0511 11:22:40 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.18025805056095123, Train Loss: 0.1794029325246811
[32m[0511 11:22:40 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.18025913834571838, Train Loss: 0.1794021725654602
[32m[0511 11:22:40 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.18026024103164673, Train Loss: 0.1794014275074005
[32m[0511 11:22:40 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.1802612990140915, Train Loss: 0.17940068244934082
[32m[0511 11:22:40 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.18026238679885864, Train Loss: 0.17939992249011993
[32m[0511 11:22:40 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.1802634298801422, Train Loss: 0.17939919233322144
[32m[0511 11:22:40 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.18026448786258698, Train Loss: 0.17939843237400055
[32m[0511 11:22:40 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.18026554584503174, Train Loss: 0.17939770221710205
[32m[0511 11:22:40 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.1802666187286377, Train Loss: 0.17939695715904236
[32m[0511 11:22:40 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.18026764690876007, Train Loss: 0.17939619719982147
[32m[0511 11:22:40 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.18026867508888245, Train Loss: 0.17939545214176178
[32m[0511 11:22:40 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.18026968836784363, Train Loss: 0.1793947070837021
[32m[0511 11:22:40 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.180270716547966, Train Loss: 0.1793939769268036
[32m[0511 11:22:40 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.18027172982692719, Train Loss: 0.1793932318687439
[32m[0511 11:22:40 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.18027275800704956, Train Loss: 0.1793924868106842
[32m[0511 11:22:40 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.18027375638484955, Train Loss: 0.1793917417526245
[32m[0511 11:22:40 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.18027473986148834, Train Loss: 0.179391011595726
[32m[0511 11:22:40 @mbmf_sampler.py:98][0m Finished 9th episode
[32m[0511 11:22:40 @mbmf_sampler.py:102][0m 1809 timesteps from 9 episodes collected
[32m[0511 11:41:31 @mbmf_trainer.py:160][0m Mean reward: -1247.4393773273741
[32m[0511 11:41:31 @mbmf_policy.py:81][0m [dynamics at epoch 0]: Val Loss: 0.16813084483146667, Train Loss: 0.1777425855398178
[32m[0511 11:41:31 @mbmf_policy.py:81][0m [dynamics at epoch 1]: Val Loss: 0.1683688759803772, Train Loss: 0.17770278453826904
[32m[0511 11:41:31 @mbmf_policy.py:81][0m [dynamics at epoch 2]: Val Loss: 0.16842709481716156, Train Loss: 0.17768655717372894
[32m[0511 11:41:31 @mbmf_policy.py:81][0m [dynamics at epoch 3]: Val Loss: 0.16842418909072876, Train Loss: 0.1776803880929947
[32m[0511 11:41:31 @mbmf_policy.py:81][0m [dynamics at epoch 4]: Val Loss: 0.16843648254871368, Train Loss: 0.17767253518104553
[32m[0511 11:41:31 @mbmf_policy.py:81][0m [dynamics at epoch 5]: Val Loss: 0.16844958066940308, Train Loss: 0.17766478657722473
[32m[0511 11:41:31 @mbmf_policy.py:81][0m [dynamics at epoch 6]: Val Loss: 0.16846159100532532, Train Loss: 0.17765839397907257
[32m[0511 11:41:31 @mbmf_policy.py:81][0m [dynamics at epoch 7]: Val Loss: 0.16847123205661774, Train Loss: 0.17765261232852936
[32m[0511 11:41:31 @mbmf_policy.py:81][0m [dynamics at epoch 8]: Val Loss: 0.16847960650920868, Train Loss: 0.17764747142791748
[32m[0511 11:41:31 @mbmf_policy.py:81][0m [dynamics at epoch 9]: Val Loss: 0.16848696768283844, Train Loss: 0.17764270305633545
[32m[0511 11:41:31 @mbmf_policy.py:81][0m [dynamics at epoch 10]: Val Loss: 0.16849350929260254, Train Loss: 0.17763830721378326
[32m[0511 11:41:31 @mbmf_policy.py:81][0m [dynamics at epoch 11]: Val Loss: 0.1684993952512741, Train Loss: 0.17763420939445496
[32m[0511 11:41:31 @mbmf_policy.py:81][0m [dynamics at epoch 12]: Val Loss: 0.16850478947162628, Train Loss: 0.17763036489486694
[32m[0511 11:41:31 @mbmf_policy.py:81][0m [dynamics at epoch 13]: Val Loss: 0.16850973665714264, Train Loss: 0.17762671411037445
[32m[0511 11:41:32 @mbmf_policy.py:81][0m [dynamics at epoch 14]: Val Loss: 0.16851435601711273, Train Loss: 0.1776232272386551
[32m[0511 11:41:32 @mbmf_policy.py:81][0m [dynamics at epoch 15]: Val Loss: 0.16851870715618134, Train Loss: 0.17761993408203125
[32m[0511 11:41:32 @mbmf_policy.py:81][0m [dynamics at epoch 16]: Val Loss: 0.16852284967899323, Train Loss: 0.17761678993701935
[32m[0511 11:41:32 @mbmf_policy.py:81][0m [dynamics at epoch 17]: Val Loss: 0.1685267835855484, Train Loss: 0.177613765001297
[32m[0511 11:41:32 @mbmf_policy.py:81][0m [dynamics at epoch 18]: Val Loss: 0.1685306280851364, Train Loss: 0.1776108592748642
[32m[0511 11:41:32 @mbmf_policy.py:81][0m [dynamics at epoch 19]: Val Loss: 0.1685343235731125, Train Loss: 0.17760802805423737
[32m[0511 11:41:32 @mbmf_policy.py:81][0m [dynamics at epoch 20]: Val Loss: 0.1685379296541214, Train Loss: 0.17760533094406128
[32m[0511 11:41:32 @mbmf_policy.py:81][0m [dynamics at epoch 21]: Val Loss: 0.16854144632816315, Train Loss: 0.17760270833969116
[32m[0511 11:41:32 @mbmf_policy.py:81][0m [dynamics at epoch 22]: Val Loss: 0.16854490339756012, Train Loss: 0.1776001751422882
[32m[0511 11:41:32 @mbmf_policy.py:81][0m [dynamics at epoch 23]: Val Loss: 0.16854830086231232, Train Loss: 0.17759771645069122
[32m[0511 11:41:32 @mbmf_policy.py:81][0m [dynamics at epoch 24]: Val Loss: 0.16855166852474213, Train Loss: 0.17759530246257782
[32m[0511 11:41:32 @mbmf_policy.py:81][0m [dynamics at epoch 25]: Val Loss: 0.16855496168136597, Train Loss: 0.17759299278259277
[32m[0511 11:41:32 @mbmf_policy.py:81][0m [dynamics at epoch 26]: Val Loss: 0.1685582399368286, Train Loss: 0.17759071290493011
[32m[0511 11:41:32 @mbmf_policy.py:81][0m [dynamics at epoch 27]: Val Loss: 0.16856148838996887, Train Loss: 0.17758852243423462
[32m[0511 11:41:32 @mbmf_policy.py:81][0m [dynamics at epoch 28]: Val Loss: 0.16856470704078674, Train Loss: 0.1775863617658615
[32m[0511 11:41:32 @mbmf_policy.py:81][0m [dynamics at epoch 29]: Val Loss: 0.16856788098812103, Train Loss: 0.17758426070213318
[32m[0511 11:41:32 @mbmf_policy.py:81][0m [dynamics at epoch 30]: Val Loss: 0.16857105493545532, Train Loss: 0.17758217453956604
[32m[0511 11:41:32 @mbmf_policy.py:81][0m [dynamics at epoch 31]: Val Loss: 0.16857418417930603, Train Loss: 0.17758019268512726
[32m[0511 11:41:32 @mbmf_policy.py:81][0m [dynamics at epoch 32]: Val Loss: 0.16857728362083435, Train Loss: 0.17757821083068848
[32m[0511 11:41:32 @mbmf_policy.py:81][0m [dynamics at epoch 33]: Val Loss: 0.16858038306236267, Train Loss: 0.17757630348205566
[32m[0511 11:41:33 @mbmf_policy.py:81][0m [dynamics at epoch 34]: Val Loss: 0.1685834527015686, Train Loss: 0.17757441103458405
[32m[0511 11:41:33 @mbmf_policy.py:81][0m [dynamics at epoch 35]: Val Loss: 0.16858649253845215, Train Loss: 0.17757254838943481
[32m[0511 11:41:33 @mbmf_policy.py:81][0m [dynamics at epoch 36]: Val Loss: 0.1685895323753357, Train Loss: 0.17757074534893036
[32m[0511 11:41:33 @mbmf_policy.py:81][0m [dynamics at epoch 37]: Val Loss: 0.16859254240989685, Train Loss: 0.1775689572095871
[32m[0511 11:41:33 @mbmf_policy.py:81][0m [dynamics at epoch 38]: Val Loss: 0.16859552264213562, Train Loss: 0.17756719887256622
[32m[0511 11:41:33 @mbmf_policy.py:81][0m [dynamics at epoch 39]: Val Loss: 0.1685984879732132, Train Loss: 0.17756547033786774
[32m[0511 11:41:33 @mbmf_policy.py:81][0m [dynamics at epoch 40]: Val Loss: 0.16860143840312958, Train Loss: 0.17756378650665283
[32m[0511 11:41:33 @mbmf_policy.py:81][0m [dynamics at epoch 41]: Val Loss: 0.16860437393188477, Train Loss: 0.17756213247776031
[32m[0511 11:41:33 @mbmf_policy.py:81][0m [dynamics at epoch 42]: Val Loss: 0.16860729455947876, Train Loss: 0.1775604784488678
[32m[0511 11:41:33 @mbmf_policy.py:81][0m [dynamics at epoch 43]: Val Loss: 0.16861020028591156, Train Loss: 0.17755888402462006
[32m[0511 11:41:33 @mbmf_policy.py:81][0m [dynamics at epoch 44]: Val Loss: 0.16861306130886078, Train Loss: 0.17755728960037231
[32m[0511 11:41:33 @mbmf_policy.py:81][0m [dynamics at epoch 45]: Val Loss: 0.1686159074306488, Train Loss: 0.17755572497844696
[32m[0511 11:41:33 @mbmf_policy.py:81][0m [dynamics at epoch 46]: Val Loss: 0.16861875355243683, Train Loss: 0.177554190158844
[32m[0511 11:41:33 @mbmf_policy.py:81][0m [dynamics at epoch 47]: Val Loss: 0.16862159967422485, Train Loss: 0.17755267024040222
[32m[0511 11:41:33 @mbmf_policy.py:81][0m [dynamics at epoch 48]: Val Loss: 0.16862435638904572, Train Loss: 0.17755115032196045
[32m[0511 11:41:33 @mbmf_policy.py:81][0m [dynamics at epoch 49]: Val Loss: 0.16862715780735016, Train Loss: 0.17754967510700226
[32m[0511 11:41:33 @mbmf_policy.py:81][0m [dynamics at epoch 50]: Val Loss: 0.16862991452217102, Train Loss: 0.17754822969436646
[32m[0511 11:41:33 @mbmf_policy.py:81][0m [dynamics at epoch 51]: Val Loss: 0.1686326563358307, Train Loss: 0.17754678428173065
[32m[0511 11:41:33 @mbmf_policy.py:81][0m [dynamics at epoch 52]: Val Loss: 0.16863538324832916, Train Loss: 0.17754533886909485
[32m[0511 11:41:33 @mbmf_policy.py:81][0m [dynamics at epoch 53]: Val Loss: 0.16863808035850525, Train Loss: 0.17754393815994263
[32m[0511 11:41:34 @mbmf_policy.py:81][0m [dynamics at epoch 54]: Val Loss: 0.16864076256752014, Train Loss: 0.1775425523519516
[32m[0511 11:41:34 @mbmf_policy.py:81][0m [dynamics at epoch 55]: Val Loss: 0.16864342987537384, Train Loss: 0.17754116654396057
[32m[0511 11:41:34 @mbmf_policy.py:81][0m [dynamics at epoch 56]: Val Loss: 0.16864608228206635, Train Loss: 0.17753981053829193
[32m[0511 11:41:34 @mbmf_policy.py:81][0m [dynamics at epoch 57]: Val Loss: 0.16864873468875885, Train Loss: 0.1775384545326233
[32m[0511 11:41:34 @mbmf_policy.py:81][0m [dynamics at epoch 58]: Val Loss: 0.16865134239196777, Train Loss: 0.17753714323043823
[32m[0511 11:41:34 @mbmf_policy.py:81][0m [dynamics at epoch 59]: Val Loss: 0.1686539351940155, Train Loss: 0.17753583192825317
[32m[0511 11:41:34 @mbmf_policy.py:81][0m [dynamics at epoch 60]: Val Loss: 0.16865651309490204, Train Loss: 0.17753452062606812
[32m[0511 11:41:34 @mbmf_policy.py:81][0m [dynamics at epoch 61]: Val Loss: 0.16865907609462738, Train Loss: 0.17753322422504425
[32m[0511 11:41:34 @mbmf_policy.py:81][0m [dynamics at epoch 62]: Val Loss: 0.16866160929203033, Train Loss: 0.17753194272518158
[32m[0511 11:41:34 @mbmf_policy.py:81][0m [dynamics at epoch 63]: Val Loss: 0.1686641275882721, Train Loss: 0.17753072082996368
[32m[0511 11:41:34 @mbmf_policy.py:81][0m [dynamics at epoch 64]: Val Loss: 0.16866663098335266, Train Loss: 0.1775294542312622
[32m[0511 11:41:34 @mbmf_policy.py:81][0m [dynamics at epoch 65]: Val Loss: 0.16866913437843323, Train Loss: 0.17752820253372192
[32m[0511 11:41:34 @mbmf_policy.py:81][0m [dynamics at epoch 66]: Val Loss: 0.1686716079711914, Train Loss: 0.17752698063850403
[32m[0511 11:41:34 @mbmf_policy.py:81][0m [dynamics at epoch 67]: Val Loss: 0.1686740517616272, Train Loss: 0.17752577364444733
[32m[0511 11:41:34 @mbmf_policy.py:81][0m [dynamics at epoch 68]: Val Loss: 0.1686764806509018, Train Loss: 0.17752458155155182
[32m[0511 11:41:34 @mbmf_policy.py:81][0m [dynamics at epoch 69]: Val Loss: 0.1686789095401764, Train Loss: 0.17752335965633392
[32m[0511 11:41:34 @mbmf_policy.py:81][0m [dynamics at epoch 70]: Val Loss: 0.1686812937259674, Train Loss: 0.1775221973657608
[32m[0511 11:41:34 @mbmf_policy.py:81][0m [dynamics at epoch 71]: Val Loss: 0.16868367791175842, Train Loss: 0.1775210052728653
[32m[0511 11:41:34 @mbmf_policy.py:81][0m [dynamics at epoch 72]: Val Loss: 0.16868603229522705, Train Loss: 0.17751985788345337
[32m[0511 11:41:34 @mbmf_policy.py:81][0m [dynamics at epoch 73]: Val Loss: 0.16868838667869568, Train Loss: 0.17751868069171906
[32m[0511 11:41:35 @mbmf_policy.py:81][0m [dynamics at epoch 74]: Val Loss: 0.1686907261610031, Train Loss: 0.17751753330230713
[32m[0511 11:41:35 @mbmf_policy.py:81][0m [dynamics at epoch 75]: Val Loss: 0.16869302093982697, Train Loss: 0.1775164008140564
[32m[0511 11:41:35 @mbmf_policy.py:81][0m [dynamics at epoch 76]: Val Loss: 0.1686953455209732, Train Loss: 0.17751526832580566
[32m[0511 11:41:35 @mbmf_policy.py:81][0m [dynamics at epoch 77]: Val Loss: 0.16869762539863586, Train Loss: 0.17751416563987732
[32m[0511 11:41:35 @mbmf_policy.py:81][0m [dynamics at epoch 78]: Val Loss: 0.16869989037513733, Train Loss: 0.17751304805278778
[32m[0511 11:41:35 @mbmf_policy.py:81][0m [dynamics at epoch 79]: Val Loss: 0.1687021106481552, Train Loss: 0.17751194536685944
[32m[0511 11:41:35 @mbmf_policy.py:81][0m [dynamics at epoch 80]: Val Loss: 0.16870436072349548, Train Loss: 0.17751085758209229
[32m[0511 11:41:35 @mbmf_policy.py:81][0m [dynamics at epoch 81]: Val Loss: 0.16870658099651337, Train Loss: 0.17750976979732513
[32m[0511 11:41:35 @mbmf_policy.py:81][0m [dynamics at epoch 82]: Val Loss: 0.16870877146720886, Train Loss: 0.17750869691371918
[32m[0511 11:41:35 @mbmf_policy.py:81][0m [dynamics at epoch 83]: Val Loss: 0.16871096193790436, Train Loss: 0.17750760912895203
[32m[0511 11:41:35 @mbmf_policy.py:81][0m [dynamics at epoch 84]: Val Loss: 0.16871312260627747, Train Loss: 0.17750655114650726
[32m[0511 11:41:35 @mbmf_policy.py:81][0m [dynamics at epoch 85]: Val Loss: 0.16871529817581177, Train Loss: 0.1775054782629013
[32m[0511 11:41:35 @mbmf_policy.py:81][0m [dynamics at epoch 86]: Val Loss: 0.1687174290418625, Train Loss: 0.17750445008277893
[32m[0511 11:41:35 @mbmf_policy.py:81][0m [dynamics at epoch 87]: Val Loss: 0.1687195599079132, Train Loss: 0.17750337719917297
[32m[0511 11:41:35 @mbmf_policy.py:81][0m [dynamics at epoch 88]: Val Loss: 0.16872164607048035, Train Loss: 0.17750237882137299
[32m[0511 11:41:35 @mbmf_policy.py:81][0m [dynamics at epoch 89]: Val Loss: 0.16872374713420868, Train Loss: 0.17750133574008942
[32m[0511 11:41:35 @mbmf_policy.py:81][0m [dynamics at epoch 90]: Val Loss: 0.16872581839561462, Train Loss: 0.17750030755996704
[32m[0511 11:41:35 @mbmf_policy.py:81][0m [dynamics at epoch 91]: Val Loss: 0.16872787475585938, Train Loss: 0.17749927937984467
[32m[0511 11:41:35 @mbmf_policy.py:81][0m [dynamics at epoch 92]: Val Loss: 0.16872993111610413, Train Loss: 0.1774982511997223
[32m[0511 11:41:35 @mbmf_policy.py:81][0m [dynamics at epoch 93]: Val Loss: 0.1687319576740265, Train Loss: 0.1774972677230835
[32m[0511 11:41:36 @mbmf_policy.py:81][0m [dynamics at epoch 94]: Val Loss: 0.16873396933078766, Train Loss: 0.1774962693452835
[32m[0511 11:41:36 @mbmf_policy.py:81][0m [dynamics at epoch 95]: Val Loss: 0.16873599588871002, Train Loss: 0.17749525606632233
[32m[0511 11:41:36 @mbmf_policy.py:81][0m [dynamics at epoch 96]: Val Loss: 0.1687379777431488, Train Loss: 0.17749428749084473
[32m[0511 11:41:36 @mbmf_policy.py:81][0m [dynamics at epoch 97]: Val Loss: 0.16873997449874878, Train Loss: 0.17749330401420593
[32m[0511 11:41:36 @mbmf_policy.py:81][0m [dynamics at epoch 98]: Val Loss: 0.16874194145202637, Train Loss: 0.17749232053756714
[32m[0511 11:41:36 @mbmf_policy.py:81][0m [dynamics at epoch 99]: Val Loss: 0.16874389350414276, Train Loss: 0.17749135196208954
[32m[0511 11:41:36 @mbmf_policy.py:81][0m [dynamics at epoch 100]: Val Loss: 0.16874580085277557, Train Loss: 0.17749038338661194
[32m[0511 11:41:36 @mbmf_policy.py:81][0m [dynamics at epoch 101]: Val Loss: 0.16874773800373077, Train Loss: 0.17748939990997314
[32m[0511 11:41:36 @mbmf_policy.py:81][0m [dynamics at epoch 102]: Val Loss: 0.1687496453523636, Train Loss: 0.17748846113681793
[32m[0511 11:41:36 @mbmf_policy.py:81][0m [dynamics at epoch 103]: Val Loss: 0.1687515377998352, Train Loss: 0.17748749256134033
[32m[0511 11:41:36 @mbmf_policy.py:81][0m [dynamics at epoch 104]: Val Loss: 0.16875344514846802, Train Loss: 0.17748655378818512
[32m[0511 11:41:36 @mbmf_policy.py:81][0m [dynamics at epoch 105]: Val Loss: 0.16875530779361725, Train Loss: 0.1774856150150299
[32m[0511 11:41:36 @mbmf_policy.py:81][0m [dynamics at epoch 106]: Val Loss: 0.16875715553760529, Train Loss: 0.1774846762418747
[32m[0511 11:41:36 @mbmf_policy.py:81][0m [dynamics at epoch 107]: Val Loss: 0.16875901818275452, Train Loss: 0.17748373746871948
[32m[0511 11:41:36 @mbmf_policy.py:81][0m [dynamics at epoch 108]: Val Loss: 0.16876085102558136, Train Loss: 0.17748281359672546
[32m[0511 11:41:36 @mbmf_policy.py:81][0m [dynamics at epoch 109]: Val Loss: 0.168762668967247, Train Loss: 0.17748187482357025
[32m[0511 11:41:36 @mbmf_policy.py:81][0m [dynamics at epoch 110]: Val Loss: 0.16876445710659027, Train Loss: 0.17748095095157623
[32m[0511 11:41:36 @mbmf_policy.py:81][0m [dynamics at epoch 111]: Val Loss: 0.16876627504825592, Train Loss: 0.1774800419807434
[32m[0511 11:41:36 @mbmf_policy.py:81][0m [dynamics at epoch 112]: Val Loss: 0.16876807808876038, Train Loss: 0.17747913300991058
[32m[0511 11:41:36 @mbmf_policy.py:81][0m [dynamics at epoch 113]: Val Loss: 0.16876985132694244, Train Loss: 0.17747822403907776
[32m[0511 11:41:37 @mbmf_policy.py:81][0m [dynamics at epoch 114]: Val Loss: 0.16877159476280212, Train Loss: 0.17747732996940613
[32m[0511 11:41:37 @mbmf_policy.py:81][0m [dynamics at epoch 115]: Val Loss: 0.1687733232975006, Train Loss: 0.1774764060974121
[32m[0511 11:41:37 @mbmf_policy.py:81][0m [dynamics at epoch 116]: Val Loss: 0.16877508163452148, Train Loss: 0.17747551202774048
[32m[0511 11:41:37 @mbmf_policy.py:81][0m [dynamics at epoch 117]: Val Loss: 0.16877681016921997, Train Loss: 0.17747460305690765
[32m[0511 11:41:37 @mbmf_policy.py:81][0m [dynamics at epoch 118]: Val Loss: 0.16877852380275726, Train Loss: 0.17747372388839722
[32m[0511 11:41:37 @mbmf_policy.py:81][0m [dynamics at epoch 119]: Val Loss: 0.16878020763397217, Train Loss: 0.17747284471988678
[32m[0511 11:41:37 @mbmf_policy.py:81][0m [dynamics at epoch 120]: Val Loss: 0.16878190636634827, Train Loss: 0.17747193574905396
[32m[0511 11:41:37 @mbmf_policy.py:81][0m [dynamics at epoch 121]: Val Loss: 0.16878360509872437, Train Loss: 0.1774710714817047
[32m[0511 11:41:37 @mbmf_policy.py:81][0m [dynamics at epoch 122]: Val Loss: 0.16878525912761688, Train Loss: 0.17747019231319427
[32m[0511 11:41:37 @mbmf_policy.py:81][0m [dynamics at epoch 123]: Val Loss: 0.1687869280576706, Train Loss: 0.17746932804584503
[32m[0511 11:41:37 @mbmf_policy.py:81][0m [dynamics at epoch 124]: Val Loss: 0.16878856718540192, Train Loss: 0.1774684488773346
[32m[0511 11:41:37 @mbmf_policy.py:81][0m [dynamics at epoch 125]: Val Loss: 0.16879019141197205, Train Loss: 0.17746758460998535
[32m[0511 11:41:37 @mbmf_policy.py:81][0m [dynamics at epoch 126]: Val Loss: 0.16879183053970337, Train Loss: 0.1774667203426361
[32m[0511 11:41:37 @mbmf_policy.py:81][0m [dynamics at epoch 127]: Val Loss: 0.1687934398651123, Train Loss: 0.17746587097644806
[32m[0511 11:41:37 @mbmf_policy.py:81][0m [dynamics at epoch 128]: Val Loss: 0.16879504919052124, Train Loss: 0.17746499180793762
[32m[0511 11:41:37 @mbmf_policy.py:81][0m [dynamics at epoch 129]: Val Loss: 0.16879665851593018, Train Loss: 0.17746414244174957
[32m[0511 11:41:37 @mbmf_policy.py:81][0m [dynamics at epoch 130]: Val Loss: 0.16879825294017792, Train Loss: 0.17746330797672272
[32m[0511 11:41:37 @mbmf_policy.py:81][0m [dynamics at epoch 131]: Val Loss: 0.16879981756210327, Train Loss: 0.17746244370937347
[32m[0511 11:41:37 @mbmf_policy.py:81][0m [dynamics at epoch 132]: Val Loss: 0.16880136728286743, Train Loss: 0.17746157944202423
[32m[0511 11:41:37 @mbmf_policy.py:81][0m [dynamics at epoch 133]: Val Loss: 0.16880293190479279, Train Loss: 0.17746075987815857
[32m[0511 11:41:38 @mbmf_policy.py:81][0m [dynamics at epoch 134]: Val Loss: 0.16880446672439575, Train Loss: 0.17745991051197052
[32m[0511 11:41:38 @mbmf_policy.py:81][0m [dynamics at epoch 135]: Val Loss: 0.16880600154399872, Train Loss: 0.17745907604694366
[32m[0511 11:41:38 @mbmf_policy.py:81][0m [dynamics at epoch 136]: Val Loss: 0.16880753636360168, Train Loss: 0.17745822668075562
[32m[0511 11:41:38 @mbmf_policy.py:81][0m [dynamics at epoch 137]: Val Loss: 0.16880904138088226, Train Loss: 0.17745739221572876
[32m[0511 11:41:38 @mbmf_policy.py:81][0m [dynamics at epoch 138]: Val Loss: 0.16881054639816284, Train Loss: 0.1774565726518631
[32m[0511 11:41:38 @mbmf_policy.py:81][0m [dynamics at epoch 139]: Val Loss: 0.16881205141544342, Train Loss: 0.17745575308799744
[32m[0511 11:41:38 @mbmf_policy.py:81][0m [dynamics at epoch 140]: Val Loss: 0.1688135266304016, Train Loss: 0.17745493352413177
[32m[0511 11:41:38 @mbmf_policy.py:81][0m [dynamics at epoch 141]: Val Loss: 0.1688150018453598, Train Loss: 0.17745409905910492
[32m[0511 11:41:38 @mbmf_policy.py:81][0m [dynamics at epoch 142]: Val Loss: 0.168816477060318, Train Loss: 0.17745327949523926
[32m[0511 11:41:38 @mbmf_policy.py:81][0m [dynamics at epoch 143]: Val Loss: 0.1688179075717926, Train Loss: 0.1774524599313736
[32m[0511 11:41:38 @mbmf_policy.py:81][0m [dynamics at epoch 144]: Val Loss: 0.1688193678855896, Train Loss: 0.17745162546634674
[32m[0511 11:41:38 @mbmf_policy.py:81][0m [dynamics at epoch 145]: Val Loss: 0.1688207983970642, Train Loss: 0.17745083570480347
[32m[0511 11:41:38 @mbmf_policy.py:81][0m [dynamics at epoch 146]: Val Loss: 0.1688222438097, Train Loss: 0.1774500161409378
[32m[0511 11:41:38 @mbmf_policy.py:81][0m [dynamics at epoch 147]: Val Loss: 0.16882365942001343, Train Loss: 0.17744921147823334
[32m[0511 11:41:38 @mbmf_policy.py:81][0m [dynamics at epoch 148]: Val Loss: 0.16882507503032684, Train Loss: 0.17744839191436768
[32m[0511 11:41:38 @mbmf_policy.py:81][0m [dynamics at epoch 149]: Val Loss: 0.16882650554180145, Train Loss: 0.1774476021528244
[32m[0511 11:41:38 @mbmf_policy.py:81][0m [dynamics at epoch 150]: Val Loss: 0.1688278764486313, Train Loss: 0.17744681239128113
[32m[0511 11:41:38 @mbmf_policy.py:81][0m [dynamics at epoch 151]: Val Loss: 0.16882926225662231, Train Loss: 0.17744600772857666
[32m[0511 11:41:38 @mbmf_policy.py:81][0m [dynamics at epoch 152]: Val Loss: 0.16883063316345215, Train Loss: 0.1774452030658722
[32m[0511 11:41:38 @mbmf_policy.py:81][0m [dynamics at epoch 153]: Val Loss: 0.16883200407028198, Train Loss: 0.17744439840316772
[32m[0511 11:41:39 @mbmf_policy.py:81][0m [dynamics at epoch 154]: Val Loss: 0.16883336007595062, Train Loss: 0.17744362354278564
[32m[0511 11:41:39 @mbmf_policy.py:81][0m [dynamics at epoch 155]: Val Loss: 0.16883470118045807, Train Loss: 0.17744281888008118
[32m[0511 11:41:39 @mbmf_policy.py:81][0m [dynamics at epoch 156]: Val Loss: 0.1688360571861267, Train Loss: 0.1774420440196991
[32m[0511 11:41:39 @mbmf_policy.py:81][0m [dynamics at epoch 157]: Val Loss: 0.16883739829063416, Train Loss: 0.17744123935699463
[32m[0511 11:41:39 @mbmf_policy.py:81][0m [dynamics at epoch 158]: Val Loss: 0.1688387244939804, Train Loss: 0.17744044959545135
[32m[0511 11:41:39 @mbmf_policy.py:81][0m [dynamics at epoch 159]: Val Loss: 0.16884002089500427, Train Loss: 0.1774396449327469
[32m[0511 11:41:39 @mbmf_policy.py:81][0m [dynamics at epoch 160]: Val Loss: 0.16884134709835052, Train Loss: 0.1774388700723648
[32m[0511 11:41:39 @mbmf_policy.py:81][0m [dynamics at epoch 161]: Val Loss: 0.16884265840053558, Train Loss: 0.17743811011314392
[32m[0511 11:41:39 @mbmf_policy.py:81][0m [dynamics at epoch 162]: Val Loss: 0.16884393990039825, Train Loss: 0.17743730545043945
[32m[0511 11:41:39 @mbmf_policy.py:81][0m [dynamics at epoch 163]: Val Loss: 0.16884522140026093, Train Loss: 0.17743653059005737
[32m[0511 11:41:39 @mbmf_policy.py:81][0m [dynamics at epoch 164]: Val Loss: 0.1688465029001236, Train Loss: 0.1774357706308365
[32m[0511 11:41:39 @mbmf_policy.py:81][0m [dynamics at epoch 165]: Val Loss: 0.16884776949882507, Train Loss: 0.1774349957704544
[32m[0511 11:41:39 @mbmf_policy.py:81][0m [dynamics at epoch 166]: Val Loss: 0.16884905099868774, Train Loss: 0.17743422091007233
[32m[0511 11:41:39 @mbmf_policy.py:81][0m [dynamics at epoch 167]: Val Loss: 0.16885028779506683, Train Loss: 0.17743346095085144
[32m[0511 11:41:39 @mbmf_policy.py:81][0m [dynamics at epoch 168]: Val Loss: 0.16885152459144592, Train Loss: 0.17743268609046936
[32m[0511 11:41:39 @mbmf_policy.py:81][0m [dynamics at epoch 169]: Val Loss: 0.1688527762889862, Train Loss: 0.17743194103240967
[32m[0511 11:41:39 @mbmf_policy.py:81][0m [dynamics at epoch 170]: Val Loss: 0.1688540130853653, Train Loss: 0.1774311661720276
[32m[0511 11:41:39 @mbmf_policy.py:81][0m [dynamics at epoch 171]: Val Loss: 0.16885524988174438, Train Loss: 0.17743037641048431
[32m[0511 11:41:39 @mbmf_policy.py:81][0m [dynamics at epoch 172]: Val Loss: 0.1688564568758011, Train Loss: 0.17742963135242462
[32m[0511 11:41:39 @mbmf_policy.py:81][0m [dynamics at epoch 173]: Val Loss: 0.1688576489686966, Train Loss: 0.17742885649204254
[32m[0511 11:41:40 @mbmf_policy.py:81][0m [dynamics at epoch 174]: Val Loss: 0.16885888576507568, Train Loss: 0.17742811143398285
[32m[0511 11:41:40 @mbmf_policy.py:81][0m [dynamics at epoch 175]: Val Loss: 0.16886006295681, Train Loss: 0.17742735147476196
[32m[0511 11:41:40 @mbmf_policy.py:81][0m [dynamics at epoch 176]: Val Loss: 0.1688612401485443, Train Loss: 0.17742659151554108
[32m[0511 11:41:40 @mbmf_policy.py:81][0m [dynamics at epoch 177]: Val Loss: 0.168862447142601, Train Loss: 0.17742584645748138
[32m[0511 11:41:40 @mbmf_policy.py:81][0m [dynamics at epoch 178]: Val Loss: 0.16886360943317413, Train Loss: 0.1774250715970993
[32m[0511 11:41:40 @mbmf_policy.py:81][0m [dynamics at epoch 179]: Val Loss: 0.16886475682258606, Train Loss: 0.1774243414402008
[32m[0511 11:41:40 @mbmf_policy.py:81][0m [dynamics at epoch 180]: Val Loss: 0.16886594891548157, Train Loss: 0.17742358148097992
[32m[0511 11:41:40 @mbmf_policy.py:81][0m [dynamics at epoch 181]: Val Loss: 0.1688670963048935, Train Loss: 0.17742282152175903
[32m[0511 11:41:40 @mbmf_policy.py:81][0m [dynamics at epoch 182]: Val Loss: 0.16886822879314423, Train Loss: 0.17742206156253815
[32m[0511 11:41:40 @mbmf_policy.py:81][0m [dynamics at epoch 183]: Val Loss: 0.16886937618255615, Train Loss: 0.17742133140563965
[32m[0511 11:41:40 @mbmf_policy.py:81][0m [dynamics at epoch 184]: Val Loss: 0.1688704937696457, Train Loss: 0.17742061614990234
[32m[0511 11:41:40 @mbmf_policy.py:81][0m [dynamics at epoch 185]: Val Loss: 0.16887162625789642, Train Loss: 0.17741984128952026
[32m[0511 11:41:40 @mbmf_policy.py:81][0m [dynamics at epoch 186]: Val Loss: 0.16887272894382477, Train Loss: 0.17741911113262177
[32m[0511 11:41:40 @mbmf_policy.py:81][0m [dynamics at epoch 187]: Val Loss: 0.1688738614320755, Train Loss: 0.17741836607456207
[32m[0511 11:41:40 @mbmf_policy.py:81][0m [dynamics at epoch 188]: Val Loss: 0.16887496411800385, Train Loss: 0.17741763591766357
[32m[0511 11:41:40 @mbmf_policy.py:81][0m [dynamics at epoch 189]: Val Loss: 0.1688760668039322, Train Loss: 0.17741689085960388
[32m[0511 11:41:40 @mbmf_policy.py:81][0m [dynamics at epoch 190]: Val Loss: 0.16887713968753815, Train Loss: 0.17741617560386658
[32m[0511 11:41:40 @mbmf_policy.py:81][0m [dynamics at epoch 191]: Val Loss: 0.1688782274723053, Train Loss: 0.17741543054580688
[32m[0511 11:41:40 @mbmf_policy.py:81][0m [dynamics at epoch 192]: Val Loss: 0.16887931525707245, Train Loss: 0.177414670586586
[32m[0511 11:41:40 @mbmf_policy.py:81][0m [dynamics at epoch 193]: Val Loss: 0.1688803881406784, Train Loss: 0.1774139553308487
[32m[0511 11:41:41 @mbmf_policy.py:81][0m [dynamics at epoch 194]: Val Loss: 0.16888144612312317, Train Loss: 0.1774132251739502
[32m[0511 11:41:41 @mbmf_policy.py:81][0m [dynamics at epoch 195]: Val Loss: 0.16888250410556793, Train Loss: 0.1774124950170517
[32m[0511 11:41:41 @mbmf_policy.py:81][0m [dynamics at epoch 196]: Val Loss: 0.1688835620880127, Train Loss: 0.1774117648601532
[32m[0511 11:41:41 @mbmf_policy.py:81][0m [dynamics at epoch 197]: Val Loss: 0.16888463497161865, Train Loss: 0.1774110347032547
[32m[0511 11:41:41 @mbmf_policy.py:81][0m [dynamics at epoch 198]: Val Loss: 0.16888564825057983, Train Loss: 0.1774103045463562
[32m[0511 11:41:41 @mbmf_policy.py:81][0m [dynamics at epoch 199]: Val Loss: 0.1688866913318634, Train Loss: 0.1774095743894577
[32m[0511 11:41:41 @mbmf_policy.py:81][0m [dynamics at epoch 200]: Val Loss: 0.16888771951198578, Train Loss: 0.1774088442325592
[32m[0511 11:41:41 @mbmf_policy.py:81][0m [dynamics at epoch 201]: Val Loss: 0.16888874769210815, Train Loss: 0.1774081140756607
[32m[0511 11:41:41 @mbmf_policy.py:81][0m [dynamics at epoch 202]: Val Loss: 0.16888976097106934, Train Loss: 0.1774073988199234
[32m[0511 11:41:41 @mbmf_policy.py:81][0m [dynamics at epoch 203]: Val Loss: 0.16889077425003052, Train Loss: 0.1774066835641861
[32m[0511 11:41:41 @mbmf_policy.py:81][0m [dynamics at epoch 204]: Val Loss: 0.1688917726278305, Train Loss: 0.1774059683084488
[32m[0511 11:41:41 @mbmf_policy.py:81][0m [dynamics at epoch 205]: Val Loss: 0.1688927859067917, Train Loss: 0.1774052381515503
[32m[0511 11:41:41 @mbmf_policy.py:81][0m [dynamics at epoch 206]: Val Loss: 0.16889376938343048, Train Loss: 0.17740453779697418
[32m[0511 11:41:41 @mbmf_policy.py:81][0m [dynamics at epoch 207]: Val Loss: 0.16889475286006927, Train Loss: 0.1774037927389145
[32m[0511 11:41:41 @mbmf_policy.py:81][0m [dynamics at epoch 208]: Val Loss: 0.16889573633670807, Train Loss: 0.17740310728549957
[32m[0511 11:41:41 @mbmf_policy.py:81][0m [dynamics at epoch 209]: Val Loss: 0.16889670491218567, Train Loss: 0.17740237712860107
[32m[0511 11:41:41 @mbmf_policy.py:81][0m [dynamics at epoch 210]: Val Loss: 0.16889767348766327, Train Loss: 0.17740167677402496
[32m[0511 11:41:41 @mbmf_policy.py:81][0m [dynamics at epoch 211]: Val Loss: 0.16889864206314087, Train Loss: 0.17740096151828766
[32m[0511 11:41:41 @mbmf_policy.py:81][0m [dynamics at epoch 212]: Val Loss: 0.16889961063861847, Train Loss: 0.17740024626255035
[32m[0511 11:41:41 @mbmf_policy.py:81][0m [dynamics at epoch 213]: Val Loss: 0.16890054941177368, Train Loss: 0.17739953100681305
[32m[0511 11:41:42 @mbmf_policy.py:81][0m [dynamics at epoch 214]: Val Loss: 0.1689015030860901, Train Loss: 0.17739881575107574
[32m[0511 11:41:42 @mbmf_policy.py:81][0m [dynamics at epoch 215]: Val Loss: 0.1689024567604065, Train Loss: 0.17739813029766083
[32m[0511 11:41:42 @mbmf_policy.py:81][0m [dynamics at epoch 216]: Val Loss: 0.1689033806324005, Train Loss: 0.17739740014076233
[32m[0511 11:41:42 @mbmf_policy.py:81][0m [dynamics at epoch 217]: Val Loss: 0.16890430450439453, Train Loss: 0.17739669978618622
[32m[0511 11:41:42 @mbmf_policy.py:81][0m [dynamics at epoch 218]: Val Loss: 0.16890524327754974, Train Loss: 0.1773960143327713
[32m[0511 11:41:42 @mbmf_policy.py:81][0m [dynamics at epoch 219]: Val Loss: 0.16890616714954376, Train Loss: 0.1773952841758728
[32m[0511 11:41:42 @mbmf_policy.py:81][0m [dynamics at epoch 220]: Val Loss: 0.1689070761203766, Train Loss: 0.17739459872245789
[32m[0511 11:41:42 @mbmf_policy.py:81][0m [dynamics at epoch 221]: Val Loss: 0.16890797019004822, Train Loss: 0.17739389836788177
[32m[0511 11:41:42 @mbmf_policy.py:81][0m [dynamics at epoch 222]: Val Loss: 0.16890887916088104, Train Loss: 0.17739318311214447
[32m[0511 11:41:42 @mbmf_policy.py:81][0m [dynamics at epoch 223]: Val Loss: 0.16890980303287506, Train Loss: 0.17739246785640717
[32m[0511 11:41:42 @mbmf_policy.py:81][0m [dynamics at epoch 224]: Val Loss: 0.1689106822013855, Train Loss: 0.17739178240299225
[32m[0511 11:41:42 @mbmf_policy.py:81][0m [dynamics at epoch 225]: Val Loss: 0.16891156136989594, Train Loss: 0.17739111185073853
[32m[0511 11:41:42 @mbmf_policy.py:81][0m [dynamics at epoch 226]: Val Loss: 0.16891244053840637, Train Loss: 0.17739041149616241
[32m[0511 11:41:42 @mbmf_policy.py:81][0m [dynamics at epoch 227]: Val Loss: 0.1689133197069168, Train Loss: 0.1773897111415863
[32m[0511 11:41:42 @mbmf_policy.py:81][0m [dynamics at epoch 228]: Val Loss: 0.16891419887542725, Train Loss: 0.177388995885849
[32m[0511 11:41:42 @mbmf_policy.py:81][0m [dynamics at epoch 229]: Val Loss: 0.1689150482416153, Train Loss: 0.17738832533359528
[32m[0511 11:41:42 @mbmf_policy.py:81][0m [dynamics at epoch 230]: Val Loss: 0.16891592741012573, Train Loss: 0.17738761007785797
[32m[0511 11:41:42 @mbmf_policy.py:81][0m [dynamics at epoch 231]: Val Loss: 0.16891679167747498, Train Loss: 0.17738692462444305
[32m[0511 11:41:42 @mbmf_policy.py:81][0m [dynamics at epoch 232]: Val Loss: 0.16891764104366302, Train Loss: 0.17738622426986694
[32m[0511 11:41:42 @mbmf_policy.py:81][0m [dynamics at epoch 233]: Val Loss: 0.16891847550868988, Train Loss: 0.17738553881645203
[32m[0511 11:41:43 @mbmf_policy.py:81][0m [dynamics at epoch 234]: Val Loss: 0.16891929507255554, Train Loss: 0.1773848533630371
[32m[0511 11:41:43 @mbmf_policy.py:81][0m [dynamics at epoch 235]: Val Loss: 0.16892015933990479, Train Loss: 0.177384153008461
[32m[0511 11:41:43 @mbmf_policy.py:81][0m [dynamics at epoch 236]: Val Loss: 0.16892097890377045, Train Loss: 0.17738346755504608
[32m[0511 11:41:43 @mbmf_policy.py:81][0m [dynamics at epoch 237]: Val Loss: 0.1689218133687973, Train Loss: 0.17738278210163116
[32m[0511 11:41:43 @mbmf_policy.py:81][0m [dynamics at epoch 238]: Val Loss: 0.16892263293266296, Train Loss: 0.17738208174705505
[32m[0511 11:41:43 @mbmf_policy.py:81][0m [dynamics at epoch 239]: Val Loss: 0.16892345249652863, Train Loss: 0.17738141119480133
[32m[0511 11:41:43 @mbmf_policy.py:81][0m [dynamics at epoch 240]: Val Loss: 0.1689242571592331, Train Loss: 0.17738069593906403
[32m[0511 11:41:43 @mbmf_policy.py:81][0m [dynamics at epoch 241]: Val Loss: 0.16892506182193756, Train Loss: 0.1773800253868103
[32m[0511 11:41:43 @mbmf_policy.py:81][0m [dynamics at epoch 242]: Val Loss: 0.16892586648464203, Train Loss: 0.17737933993339539
[32m[0511 11:41:43 @mbmf_policy.py:81][0m [dynamics at epoch 243]: Val Loss: 0.1689266562461853, Train Loss: 0.17737866938114166
[32m[0511 11:41:43 @mbmf_policy.py:81][0m [dynamics at epoch 244]: Val Loss: 0.16892744600772858, Train Loss: 0.17737798392772675
[32m[0511 11:41:43 @mbmf_policy.py:81][0m [dynamics at epoch 245]: Val Loss: 0.16892823576927185, Train Loss: 0.17737729847431183
[32m[0511 11:41:43 @mbmf_policy.py:81][0m [dynamics at epoch 246]: Val Loss: 0.16892901062965393, Train Loss: 0.1773766130208969
[32m[0511 11:41:43 @mbmf_policy.py:81][0m [dynamics at epoch 247]: Val Loss: 0.1689298152923584, Train Loss: 0.1773759424686432
[32m[0511 11:41:43 @mbmf_policy.py:81][0m [dynamics at epoch 248]: Val Loss: 0.16893057525157928, Train Loss: 0.17737525701522827
[32m[0511 11:41:43 @mbmf_policy.py:81][0m [dynamics at epoch 249]: Val Loss: 0.16893133521080017, Train Loss: 0.17737458646297455
[32m[0511 11:41:43 @mbmf_policy.py:81][0m [dynamics at epoch 250]: Val Loss: 0.16893209517002106, Train Loss: 0.17737390100955963
[32m[0511 11:41:43 @mbmf_policy.py:81][0m [dynamics at epoch 251]: Val Loss: 0.16893284022808075, Train Loss: 0.17737321555614471
[32m[0511 11:41:43 @mbmf_policy.py:81][0m [dynamics at epoch 252]: Val Loss: 0.16893360018730164, Train Loss: 0.177372545003891
[32m[0511 11:41:43 @mbmf_policy.py:81][0m [dynamics at epoch 253]: Val Loss: 0.16893434524536133, Train Loss: 0.17737188935279846
[32m[0511 11:41:44 @mbmf_policy.py:81][0m [dynamics at epoch 254]: Val Loss: 0.16893510520458221, Train Loss: 0.17737120389938354
[32m[0511 11:41:44 @mbmf_policy.py:81][0m [dynamics at epoch 255]: Val Loss: 0.1689358502626419, Train Loss: 0.17737050354480743
[32m[0511 11:41:44 @mbmf_policy.py:81][0m [dynamics at epoch 256]: Val Loss: 0.1689365655183792, Train Loss: 0.1773698627948761
[32m[0511 11:41:44 @mbmf_policy.py:81][0m [dynamics at epoch 257]: Val Loss: 0.1689373105764389, Train Loss: 0.17736917734146118
[32m[0511 11:41:44 @mbmf_policy.py:81][0m [dynamics at epoch 258]: Val Loss: 0.1689380258321762, Train Loss: 0.17736849188804626
[32m[0511 11:41:44 @mbmf_policy.py:81][0m [dynamics at epoch 259]: Val Loss: 0.1689387410879135, Train Loss: 0.17736782133579254
[32m[0511 11:41:44 @mbmf_policy.py:81][0m [dynamics at epoch 260]: Val Loss: 0.16893944144248962, Train Loss: 0.1773671656847
[32m[0511 11:41:44 @mbmf_policy.py:81][0m [dynamics at epoch 261]: Val Loss: 0.16894017159938812, Train Loss: 0.1773664951324463
[32m[0511 11:41:44 @mbmf_policy.py:81][0m [dynamics at epoch 262]: Val Loss: 0.16894087195396423, Train Loss: 0.17736582458019257
[32m[0511 11:41:44 @mbmf_policy.py:81][0m [dynamics at epoch 263]: Val Loss: 0.16894157230854034, Train Loss: 0.17736516892910004
[32m[0511 11:41:44 @mbmf_policy.py:81][0m [dynamics at epoch 264]: Val Loss: 0.16894225776195526, Train Loss: 0.17736448347568512
[32m[0511 11:41:44 @mbmf_policy.py:81][0m [dynamics at epoch 265]: Val Loss: 0.16894297301769257, Train Loss: 0.1773638129234314
[32m[0511 11:41:44 @mbmf_policy.py:81][0m [dynamics at epoch 266]: Val Loss: 0.16894365847110748, Train Loss: 0.17736312747001648
[32m[0511 11:41:44 @mbmf_policy.py:81][0m [dynamics at epoch 267]: Val Loss: 0.1689443439245224, Train Loss: 0.17736248672008514
[32m[0511 11:41:44 @mbmf_policy.py:81][0m [dynamics at epoch 268]: Val Loss: 0.16894502937793732, Train Loss: 0.17736178636550903
[32m[0511 11:41:44 @mbmf_policy.py:81][0m [dynamics at epoch 269]: Val Loss: 0.16894569993019104, Train Loss: 0.1773611605167389
[32m[0511 11:41:44 @mbmf_policy.py:81][0m [dynamics at epoch 270]: Val Loss: 0.16894637048244476, Train Loss: 0.17736047506332397
[32m[0511 11:41:44 @mbmf_policy.py:81][0m [dynamics at epoch 271]: Val Loss: 0.1689470410346985, Train Loss: 0.17735981941223145
[32m[0511 11:41:44 @mbmf_policy.py:81][0m [dynamics at epoch 272]: Val Loss: 0.16894768178462982, Train Loss: 0.17735914885997772
[32m[0511 11:41:44 @mbmf_policy.py:81][0m [dynamics at epoch 273]: Val Loss: 0.16894833743572235, Train Loss: 0.1773584932088852
[32m[0511 11:41:45 @mbmf_policy.py:81][0m [dynamics at epoch 274]: Val Loss: 0.16894899308681488, Train Loss: 0.17735785245895386
[32m[0511 11:41:45 @mbmf_policy.py:81][0m [dynamics at epoch 275]: Val Loss: 0.1689496487379074, Train Loss: 0.17735716700553894
[32m[0511 11:41:45 @mbmf_policy.py:81][0m [dynamics at epoch 276]: Val Loss: 0.16895030438899994, Train Loss: 0.17735649645328522
[32m[0511 11:41:45 @mbmf_policy.py:81][0m [dynamics at epoch 277]: Val Loss: 0.16895094513893127, Train Loss: 0.1773558259010315
[32m[0511 11:41:45 @mbmf_policy.py:81][0m [dynamics at epoch 278]: Val Loss: 0.1689516007900238, Train Loss: 0.17735518515110016
[32m[0511 11:41:45 @mbmf_policy.py:81][0m [dynamics at epoch 279]: Val Loss: 0.16895222663879395, Train Loss: 0.17735452950000763
[32m[0511 11:41:45 @mbmf_policy.py:81][0m [dynamics at epoch 280]: Val Loss: 0.1689528375864029, Train Loss: 0.1773538440465927
[32m[0511 11:41:45 @mbmf_policy.py:81][0m [dynamics at epoch 281]: Val Loss: 0.16895347833633423, Train Loss: 0.17735320329666138
[32m[0511 11:41:45 @mbmf_policy.py:81][0m [dynamics at epoch 282]: Val Loss: 0.16895408928394318, Train Loss: 0.17735253274440765
[32m[0511 11:41:45 @mbmf_policy.py:81][0m [dynamics at epoch 283]: Val Loss: 0.16895471513271332, Train Loss: 0.17735186219215393
[32m[0511 11:41:45 @mbmf_policy.py:81][0m [dynamics at epoch 284]: Val Loss: 0.16895532608032227, Train Loss: 0.1773512363433838
[32m[0511 11:41:45 @mbmf_policy.py:81][0m [dynamics at epoch 285]: Val Loss: 0.1689559370279312, Train Loss: 0.17735056579113007
[32m[0511 11:41:45 @mbmf_policy.py:81][0m [dynamics at epoch 286]: Val Loss: 0.16895654797554016, Train Loss: 0.17734991014003754
[32m[0511 11:41:45 @mbmf_policy.py:81][0m [dynamics at epoch 287]: Val Loss: 0.1689571589231491, Train Loss: 0.1773492395877838
[32m[0511 11:41:45 @mbmf_policy.py:81][0m [dynamics at epoch 288]: Val Loss: 0.16895774006843567, Train Loss: 0.17734861373901367
[32m[0511 11:41:45 @mbmf_policy.py:81][0m [dynamics at epoch 289]: Val Loss: 0.16895833611488342, Train Loss: 0.17734794318675995
[32m[0511 11:41:45 @mbmf_policy.py:81][0m [dynamics at epoch 290]: Val Loss: 0.16895891726016998, Train Loss: 0.17734728753566742
[32m[0511 11:41:45 @mbmf_policy.py:81][0m [dynamics at epoch 291]: Val Loss: 0.16895952820777893, Train Loss: 0.1773466169834137
[32m[0511 11:41:45 @mbmf_policy.py:81][0m [dynamics at epoch 292]: Val Loss: 0.1689601093530655, Train Loss: 0.17734599113464355
[32m[0511 11:41:45 @mbmf_policy.py:81][0m [dynamics at epoch 293]: Val Loss: 0.16896069049835205, Train Loss: 0.17734533548355103
[32m[0511 11:41:46 @mbmf_policy.py:81][0m [dynamics at epoch 294]: Val Loss: 0.16896125674247742, Train Loss: 0.1773446649312973
[32m[0511 11:41:46 @mbmf_policy.py:81][0m [dynamics at epoch 295]: Val Loss: 0.16896183788776398, Train Loss: 0.17734402418136597
[32m[0511 11:41:46 @mbmf_policy.py:81][0m [dynamics at epoch 296]: Val Loss: 0.16896241903305054, Train Loss: 0.17734338343143463
[32m[0511 11:41:46 @mbmf_policy.py:81][0m [dynamics at epoch 297]: Val Loss: 0.1689629852771759, Train Loss: 0.1773427128791809
[32m[0511 11:41:46 @mbmf_policy.py:81][0m [dynamics at epoch 298]: Val Loss: 0.16896355152130127, Train Loss: 0.17734208703041077
[32m[0511 11:41:46 @mbmf_policy.py:81][0m [dynamics at epoch 299]: Val Loss: 0.16896411776542664, Train Loss: 0.17734143137931824
[32m[0511 11:41:46 @mbmf_main.py:224][0m batch size for trpo is 1000
[32m[0511 11:41:46 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 11:41:46 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 11:41:46 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 11:41:46 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 11:41:46 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 11:41:46 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 11:41:46 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 11:41:46 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 11:41:46 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 11:41:46 @mbmf_main.py:132][0m Training starts at /root/mbbl
[32m[0511 11:41:46 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 11:41:46 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 11:41:46 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 11:41:46 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 11:41:46 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 11:41:46 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 11:41:46 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 11:41:46 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 11:41:46 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 11:41:46 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 11:41:46 @base_worker.py:45][0m Worker 0 online
[32m[0511 11:41:46 @mbmf_worker.py:179][0m kill message for worker
[32m[0511 11:41:46 @base_worker.py:45][0m Worker 1 online
[32m[0511 11:41:46 @base_worker.py:45][0m Worker 2 online
[32m[0511 11:41:46 @base_worker.py:45][0m Worker 3 online
[32m[0511 11:41:46 @base_worker.py:45][0m Worker 4 online
[32m[0511 11:41:46 @base_worker.py:45][0m Worker 5 online
[32m[0511 11:41:46 @base_worker.py:45][0m Worker 6 online
[32m[0511 11:41:46 @base_worker.py:45][0m Worker 7 online
[32m[0511 11:41:46 @base_worker.py:45][0m Worker 8 online
[32m[0511 11:41:46 @base_worker.py:45][0m Worker 9 online
[32m[0511 11:41:46 @base_worker.py:45][0m Worker 10 online
[32m[0511 11:41:46 @base_worker.py:45][0m Worker 11 online
[32m[0511 11:41:46 @base_worker.py:45][0m Worker 12 online
[32m[0511 11:41:46 @base_worker.py:45][0m Worker 13 online
[32m[0511 11:41:46 @base_worker.py:45][0m Worker 14 online
[32m[0511 11:41:46 @base_worker.py:45][0m Worker 15 online
[32m[0511 11:41:46 @base_worker.py:45][0m Worker 16 online
[32m[0511 11:41:46 @base_worker.py:45][0m Worker 17 online
[32m[0511 11:41:46 @base_worker.py:45][0m Worker 18 online
[32m[0511 11:41:46 @base_worker.py:45][0m Worker 19 online
[32m[0511 11:41:47 @base_trainer.py:152][0m Trainer maintains [1] policy network
[32m[0511 11:41:47 @base_trainer.py:152][0m Trainer maintains [1] dynamics network
[32m[0511 11:41:47 @base_trainer.py:152][0m Trainer maintains [1] reward network
[32m[0511 11:41:47 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:41:47 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:41:47 @base_trainer.py:216][0m Mean reward: -1169.0211244114105
[32m[0511 11:41:48 @base_main.py:38][0m --------------- Iteration 1 ---------------
[32m[0511 11:41:48 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0000 mins
[32m[0511 11:41:48 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0511 11:41:48 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0147 mins
[32m[0511 11:41:48 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:41:48 @base_main.py:47][0m 1005 total steps have happened
[32m[0511 11:41:48 @base_main.py:52][0m [avg_reward]: -1169.0211244114105
[32m[0511 11:41:48 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:41:48 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:41:48 @base_trainer.py:216][0m Mean reward: -1229.2376940635456
[32m[0511 11:41:48 @base_main.py:38][0m --------------- Iteration 2 ---------------
[32m[0511 11:41:48 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0175 mins
[32m[0511 11:41:48 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0031 mins
[32m[0511 11:41:48 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 11:41:48 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:41:48 @base_main.py:47][0m 2010 total steps have happened
[32m[0511 11:41:48 @base_main.py:52][0m [avg_reward]: -1229.2376940635456
[32m[0511 11:41:49 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:41:49 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:41:49 @base_trainer.py:216][0m Mean reward: -1145.9037128770783
[32m[0511 11:41:49 @base_main.py:38][0m --------------- Iteration 3 ---------------
[32m[0511 11:41:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0310 mins
[32m[0511 11:41:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 11:41:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 11:41:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:41:49 @base_main.py:47][0m 3015 total steps have happened
[32m[0511 11:41:49 @base_main.py:52][0m [avg_reward]: -1145.9037128770783
[32m[0511 11:41:49 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:41:49 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:41:49 @base_trainer.py:216][0m Mean reward: -970.5734379725025
[32m[0511 11:41:50 @base_main.py:38][0m --------------- Iteration 4 ---------------
[32m[0511 11:41:50 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0440 mins
[32m[0511 11:41:50 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 11:41:50 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 11:41:50 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:41:50 @base_main.py:47][0m 4020 total steps have happened
[32m[0511 11:41:50 @base_main.py:52][0m [avg_reward]: -970.5734379725025
[32m[0511 11:41:50 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:41:50 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:41:50 @base_trainer.py:216][0m Mean reward: -1176.0238237141725
[32m[0511 11:41:51 @base_main.py:38][0m --------------- Iteration 5 ---------------
[32m[0511 11:41:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0570 mins
[32m[0511 11:41:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0511 11:41:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 11:41:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:41:51 @base_main.py:47][0m 5025 total steps have happened
[32m[0511 11:41:51 @base_main.py:52][0m [avg_reward]: -1176.0238237141725
[32m[0511 11:41:51 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:41:51 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:41:51 @base_trainer.py:216][0m Mean reward: -1373.3696216748367
[32m[0511 11:41:52 @base_main.py:38][0m --------------- Iteration 6 ---------------
[32m[0511 11:41:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0700 mins
[32m[0511 11:41:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0030 mins
[32m[0511 11:41:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0511 11:41:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:41:52 @base_main.py:47][0m 6030 total steps have happened
[32m[0511 11:41:52 @base_main.py:52][0m [avg_reward]: -1373.3696216748367
[32m[0511 11:41:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:41:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:41:52 @base_trainer.py:216][0m Mean reward: -1006.8896146791783
[32m[0511 11:41:52 @base_main.py:38][0m --------------- Iteration 7 ---------------
[32m[0511 11:41:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0822 mins
[32m[0511 11:41:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 11:41:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 11:41:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:41:52 @base_main.py:47][0m 7035 total steps have happened
[32m[0511 11:41:52 @base_main.py:52][0m [avg_reward]: -1006.8896146791783
[32m[0511 11:41:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:41:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:41:52 @base_trainer.py:216][0m Mean reward: -1052.1223765335817
[32m[0511 11:41:53 @base_main.py:38][0m --------------- Iteration 8 ---------------
[32m[0511 11:41:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.0951 mins
[32m[0511 11:41:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 11:41:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 11:41:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:41:53 @base_main.py:47][0m 8040 total steps have happened
[32m[0511 11:41:53 @base_main.py:52][0m [avg_reward]: -1052.1223765335817
[32m[0511 11:41:53 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:41:53 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:41:53 @base_trainer.py:216][0m Mean reward: -988.1721996189117
[32m[0511 11:41:54 @base_main.py:38][0m --------------- Iteration 9 ---------------
[32m[0511 11:41:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1082 mins
[32m[0511 11:41:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0511 11:41:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 11:41:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:41:54 @base_main.py:47][0m 9045 total steps have happened
[32m[0511 11:41:54 @base_main.py:52][0m [avg_reward]: -988.1721996189117
[32m[0511 11:41:54 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:41:54 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:41:54 @base_trainer.py:216][0m Mean reward: -1186.1344091968786
[32m[0511 11:41:55 @base_main.py:38][0m --------------- Iteration 10 ---------------
[32m[0511 11:41:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1211 mins
[32m[0511 11:41:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 11:41:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 11:41:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:41:55 @base_main.py:47][0m 10050 total steps have happened
[32m[0511 11:41:55 @base_main.py:52][0m [avg_reward]: -1186.1344091968786
[32m[0511 11:41:55 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:41:55 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:41:55 @base_trainer.py:216][0m Mean reward: -1249.3536598662838
[32m[0511 11:41:55 @base_main.py:38][0m --------------- Iteration 11 ---------------
[32m[0511 11:41:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1334 mins
[32m[0511 11:41:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 11:41:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 11:41:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:41:55 @base_main.py:47][0m 11055 total steps have happened
[32m[0511 11:41:55 @base_main.py:52][0m [avg_reward]: -1249.3536598662838
[32m[0511 11:41:56 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:41:56 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:41:56 @base_trainer.py:216][0m Mean reward: -1356.7303724180215
[32m[0511 11:41:56 @base_main.py:38][0m --------------- Iteration 12 ---------------
[32m[0511 11:41:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1462 mins
[32m[0511 11:41:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 11:41:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 11:41:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:41:56 @base_main.py:47][0m 12060 total steps have happened
[32m[0511 11:41:56 @base_main.py:52][0m [avg_reward]: -1356.7303724180215
[32m[0511 11:41:56 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:41:56 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:41:56 @base_trainer.py:216][0m Mean reward: -1197.1518269550988
[32m[0511 11:41:57 @base_main.py:38][0m --------------- Iteration 13 ---------------
[32m[0511 11:41:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1583 mins
[32m[0511 11:41:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 11:41:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 11:41:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:41:57 @base_main.py:47][0m 13065 total steps have happened
[32m[0511 11:41:57 @base_main.py:52][0m [avg_reward]: -1197.1518269550988
[32m[0511 11:41:57 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:41:57 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:41:57 @base_trainer.py:216][0m Mean reward: -1172.9197718179857
[32m[0511 11:41:58 @base_main.py:38][0m --------------- Iteration 14 ---------------
[32m[0511 11:41:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1709 mins
[32m[0511 11:41:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 11:41:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 11:41:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:41:58 @base_main.py:47][0m 14070 total steps have happened
[32m[0511 11:41:58 @base_main.py:52][0m [avg_reward]: -1172.9197718179857
[32m[0511 11:41:58 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:41:58 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:41:58 @base_trainer.py:216][0m Mean reward: -1114.4339820065275
[32m[0511 11:41:58 @base_main.py:38][0m --------------- Iteration 15 ---------------
[32m[0511 11:41:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1836 mins
[32m[0511 11:41:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 11:41:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 11:41:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:41:58 @base_main.py:47][0m 15075 total steps have happened
[32m[0511 11:41:58 @base_main.py:52][0m [avg_reward]: -1114.4339820065275
[32m[0511 11:41:59 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:41:59 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:41:59 @base_trainer.py:216][0m Mean reward: -1135.5214470354094
[32m[0511 11:41:59 @base_main.py:38][0m --------------- Iteration 16 ---------------
[32m[0511 11:41:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.1964 mins
[32m[0511 11:41:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 11:41:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 11:41:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:41:59 @base_main.py:47][0m 16080 total steps have happened
[32m[0511 11:41:59 @base_main.py:52][0m [avg_reward]: -1135.5214470354094
[32m[0511 11:41:59 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:41:59 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:41:59 @base_trainer.py:216][0m Mean reward: -946.3957921887102
[32m[0511 11:42:00 @base_main.py:38][0m --------------- Iteration 17 ---------------
[32m[0511 11:42:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2084 mins
[32m[0511 11:42:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 11:42:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 11:42:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:00 @base_main.py:47][0m 17085 total steps have happened
[32m[0511 11:42:00 @base_main.py:52][0m [avg_reward]: -946.3957921887102
[32m[0511 11:42:00 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:00 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:00 @base_trainer.py:216][0m Mean reward: -996.6238886396002
[32m[0511 11:42:01 @base_main.py:38][0m --------------- Iteration 18 ---------------
[32m[0511 11:42:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2204 mins
[32m[0511 11:42:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 11:42:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0511 11:42:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:01 @base_main.py:47][0m 18090 total steps have happened
[32m[0511 11:42:01 @base_main.py:52][0m [avg_reward]: -996.6238886396002
[32m[0511 11:42:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:01 @base_trainer.py:216][0m Mean reward: -1086.4816748166352
[32m[0511 11:42:01 @base_main.py:38][0m --------------- Iteration 19 ---------------
[32m[0511 11:42:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2321 mins
[32m[0511 11:42:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 11:42:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 11:42:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:01 @base_main.py:47][0m 19095 total steps have happened
[32m[0511 11:42:01 @base_main.py:52][0m [avg_reward]: -1086.4816748166352
[32m[0511 11:42:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:01 @base_trainer.py:216][0m Mean reward: -1093.7848255914128
[32m[0511 11:42:02 @base_main.py:38][0m --------------- Iteration 20 ---------------
[32m[0511 11:42:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2443 mins
[32m[0511 11:42:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 11:42:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 11:42:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:02 @base_main.py:47][0m 20100 total steps have happened
[32m[0511 11:42:02 @base_main.py:52][0m [avg_reward]: -1093.7848255914128
[32m[0511 11:42:02 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:02 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:02 @base_trainer.py:216][0m Mean reward: -1166.9957164529394
[32m[0511 11:42:03 @base_main.py:38][0m --------------- Iteration 21 ---------------
[32m[0511 11:42:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2573 mins
[32m[0511 11:42:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 11:42:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 11:42:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:03 @base_main.py:47][0m 21105 total steps have happened
[32m[0511 11:42:03 @base_main.py:52][0m [avg_reward]: -1166.9957164529394
[32m[0511 11:42:03 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:03 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:03 @base_trainer.py:216][0m Mean reward: -1229.9445139732732
[32m[0511 11:42:04 @base_main.py:38][0m --------------- Iteration 22 ---------------
[32m[0511 11:42:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2697 mins
[32m[0511 11:42:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 11:42:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0107 mins
[32m[0511 11:42:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:04 @base_main.py:47][0m 22110 total steps have happened
[32m[0511 11:42:04 @base_main.py:52][0m [avg_reward]: -1229.9445139732732
[32m[0511 11:42:04 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:04 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:04 @base_trainer.py:216][0m Mean reward: -1086.3153893406757
[32m[0511 11:42:04 @base_main.py:38][0m --------------- Iteration 23 ---------------
[32m[0511 11:42:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2828 mins
[32m[0511 11:42:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 11:42:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 11:42:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:04 @base_main.py:47][0m 23115 total steps have happened
[32m[0511 11:42:04 @base_main.py:52][0m [avg_reward]: -1086.3153893406757
[32m[0511 11:42:04 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:04 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:04 @base_trainer.py:216][0m Mean reward: -1087.0886086001867
[32m[0511 11:42:05 @base_main.py:38][0m --------------- Iteration 24 ---------------
[32m[0511 11:42:05 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.2956 mins
[32m[0511 11:42:05 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 11:42:05 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 11:42:05 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:05 @base_main.py:47][0m 24120 total steps have happened
[32m[0511 11:42:05 @base_main.py:52][0m [avg_reward]: -1087.0886086001867
[32m[0511 11:42:05 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:05 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:05 @base_trainer.py:216][0m Mean reward: -979.0530781335443
[32m[0511 11:42:06 @base_main.py:38][0m --------------- Iteration 25 ---------------
[32m[0511 11:42:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3078 mins
[32m[0511 11:42:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 11:42:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 11:42:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:06 @base_main.py:47][0m 25125 total steps have happened
[32m[0511 11:42:06 @base_main.py:52][0m [avg_reward]: -979.0530781335443
[32m[0511 11:42:06 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:06 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:06 @base_trainer.py:216][0m Mean reward: -939.8713098713936
[32m[0511 11:42:06 @base_main.py:38][0m --------------- Iteration 26 ---------------
[32m[0511 11:42:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3200 mins
[32m[0511 11:42:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 11:42:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0511 11:42:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:06 @base_main.py:47][0m 26130 total steps have happened
[32m[0511 11:42:06 @base_main.py:52][0m [avg_reward]: -939.8713098713936
[32m[0511 11:42:07 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:07 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:07 @base_trainer.py:216][0m Mean reward: -1047.9253465411402
[32m[0511 11:42:07 @base_main.py:38][0m --------------- Iteration 27 ---------------
[32m[0511 11:42:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3314 mins
[32m[0511 11:42:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 11:42:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 11:42:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0511 11:42:07 @base_main.py:47][0m 27135 total steps have happened
[32m[0511 11:42:07 @base_main.py:52][0m [avg_reward]: -1047.9253465411402
[32m[0511 11:42:07 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:07 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:07 @base_trainer.py:216][0m Mean reward: -963.2186521705844
[32m[0511 11:42:08 @base_main.py:38][0m --------------- Iteration 28 ---------------
[32m[0511 11:42:08 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3438 mins
[32m[0511 11:42:08 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 11:42:08 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 11:42:08 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:08 @base_main.py:47][0m 28140 total steps have happened
[32m[0511 11:42:08 @base_main.py:52][0m [avg_reward]: -963.2186521705844
[32m[0511 11:42:08 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:08 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:08 @base_trainer.py:216][0m Mean reward: -985.1169118778695
[32m[0511 11:42:09 @base_main.py:38][0m --------------- Iteration 29 ---------------
[32m[0511 11:42:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3566 mins
[32m[0511 11:42:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 11:42:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 11:42:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:09 @base_main.py:47][0m 29145 total steps have happened
[32m[0511 11:42:09 @base_main.py:52][0m [avg_reward]: -985.1169118778695
[32m[0511 11:42:09 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:09 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:09 @base_trainer.py:216][0m Mean reward: -1107.566478916325
[32m[0511 11:42:09 @base_main.py:38][0m --------------- Iteration 30 ---------------
[32m[0511 11:42:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3689 mins
[32m[0511 11:42:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 11:42:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0094 mins
[32m[0511 11:42:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:09 @base_main.py:47][0m 30150 total steps have happened
[32m[0511 11:42:09 @base_main.py:52][0m [avg_reward]: -1107.566478916325
[32m[0511 11:42:10 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:10 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:10 @base_trainer.py:216][0m Mean reward: -1024.5803956900736
[32m[0511 11:42:10 @base_main.py:38][0m --------------- Iteration 31 ---------------
[32m[0511 11:42:10 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3807 mins
[32m[0511 11:42:10 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 11:42:10 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0511 11:42:10 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:10 @base_main.py:47][0m 31155 total steps have happened
[32m[0511 11:42:10 @base_main.py:52][0m [avg_reward]: -1024.5803956900736
[32m[0511 11:42:10 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:10 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:10 @base_trainer.py:216][0m Mean reward: -1191.592201999406
[32m[0511 11:42:11 @base_main.py:38][0m --------------- Iteration 32 ---------------
[32m[0511 11:42:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.3922 mins
[32m[0511 11:42:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 11:42:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 11:42:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:11 @base_main.py:47][0m 32160 total steps have happened
[32m[0511 11:42:11 @base_main.py:52][0m [avg_reward]: -1191.592201999406
[32m[0511 11:42:11 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:11 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:11 @base_trainer.py:216][0m Mean reward: -1072.5426619934963
[32m[0511 11:42:12 @base_main.py:38][0m --------------- Iteration 33 ---------------
[32m[0511 11:42:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4049 mins
[32m[0511 11:42:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 11:42:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 11:42:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:12 @base_main.py:47][0m 33165 total steps have happened
[32m[0511 11:42:12 @base_main.py:52][0m [avg_reward]: -1072.5426619934963
[32m[0511 11:42:12 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:12 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:12 @base_trainer.py:216][0m Mean reward: -902.3327495028825
[32m[0511 11:42:12 @base_main.py:38][0m --------------- Iteration 34 ---------------
[32m[0511 11:42:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4170 mins
[32m[0511 11:42:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 11:42:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 11:42:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:12 @base_main.py:47][0m 34170 total steps have happened
[32m[0511 11:42:12 @base_main.py:52][0m [avg_reward]: -902.3327495028825
[32m[0511 11:42:13 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:13 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:13 @base_trainer.py:216][0m Mean reward: -930.6792531528299
[32m[0511 11:42:13 @base_main.py:38][0m --------------- Iteration 35 ---------------
[32m[0511 11:42:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4293 mins
[32m[0511 11:42:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 11:42:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 11:42:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:13 @base_main.py:47][0m 35175 total steps have happened
[32m[0511 11:42:13 @base_main.py:52][0m [avg_reward]: -930.6792531528299
[32m[0511 11:42:13 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:13 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:13 @base_trainer.py:216][0m Mean reward: -1096.0509687403032
[32m[0511 11:42:14 @base_main.py:38][0m --------------- Iteration 36 ---------------
[32m[0511 11:42:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4418 mins
[32m[0511 11:42:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0511 11:42:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 11:42:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:14 @base_main.py:47][0m 36180 total steps have happened
[32m[0511 11:42:14 @base_main.py:52][0m [avg_reward]: -1096.0509687403032
[32m[0511 11:42:14 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:14 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:14 @base_trainer.py:216][0m Mean reward: -1134.4270012390948
[32m[0511 11:42:15 @base_main.py:38][0m --------------- Iteration 37 ---------------
[32m[0511 11:42:15 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4552 mins
[32m[0511 11:42:15 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 11:42:15 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 11:42:15 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:15 @base_main.py:47][0m 37185 total steps have happened
[32m[0511 11:42:15 @base_main.py:52][0m [avg_reward]: -1134.4270012390948
[32m[0511 11:42:15 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:15 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:15 @base_trainer.py:216][0m Mean reward: -1047.2682688449527
[32m[0511 11:42:15 @base_main.py:38][0m --------------- Iteration 38 ---------------
[32m[0511 11:42:15 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4677 mins
[32m[0511 11:42:15 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 11:42:15 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 11:42:15 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:15 @base_main.py:47][0m 38190 total steps have happened
[32m[0511 11:42:15 @base_main.py:52][0m [avg_reward]: -1047.2682688449527
[32m[0511 11:42:16 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:16 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:16 @base_trainer.py:216][0m Mean reward: -869.1285595556698
[32m[0511 11:42:16 @base_main.py:38][0m --------------- Iteration 39 ---------------
[32m[0511 11:42:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4802 mins
[32m[0511 11:42:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 11:42:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 11:42:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:16 @base_main.py:47][0m 39195 total steps have happened
[32m[0511 11:42:16 @base_main.py:52][0m [avg_reward]: -869.1285595556698
[32m[0511 11:42:16 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:16 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:16 @base_trainer.py:216][0m Mean reward: -1144.511082607679
[32m[0511 11:42:17 @base_main.py:38][0m --------------- Iteration 40 ---------------
[32m[0511 11:42:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.4932 mins
[32m[0511 11:42:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 11:42:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 11:42:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:17 @base_main.py:47][0m 40200 total steps have happened
[32m[0511 11:42:17 @base_main.py:52][0m [avg_reward]: -1144.511082607679
[32m[0511 11:42:17 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:17 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:17 @base_trainer.py:216][0m Mean reward: -1010.9045946673272
[32m[0511 11:42:18 @base_main.py:38][0m --------------- Iteration 41 ---------------
[32m[0511 11:42:18 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5054 mins
[32m[0511 11:42:18 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 11:42:18 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 11:42:18 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:18 @base_main.py:47][0m 41205 total steps have happened
[32m[0511 11:42:18 @base_main.py:52][0m [avg_reward]: -1010.9045946673272
[32m[0511 11:42:18 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:18 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:18 @base_trainer.py:216][0m Mean reward: -1151.4979648436326
[32m[0511 11:42:18 @base_main.py:38][0m --------------- Iteration 42 ---------------
[32m[0511 11:42:18 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5179 mins
[32m[0511 11:42:18 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0018 mins
[32m[0511 11:42:18 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 11:42:18 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:18 @base_main.py:47][0m 42210 total steps have happened
[32m[0511 11:42:18 @base_main.py:52][0m [avg_reward]: -1151.4979648436326
[32m[0511 11:42:19 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:19 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:19 @base_trainer.py:216][0m Mean reward: -1010.4399111566869
[32m[0511 11:42:19 @base_main.py:38][0m --------------- Iteration 43 ---------------
[32m[0511 11:42:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5303 mins
[32m[0511 11:42:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0511 11:42:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 11:42:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:19 @base_main.py:47][0m 43215 total steps have happened
[32m[0511 11:42:19 @base_main.py:52][0m [avg_reward]: -1010.4399111566869
[32m[0511 11:42:19 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:19 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:19 @base_trainer.py:216][0m Mean reward: -1078.8373518928167
[32m[0511 11:42:20 @base_main.py:38][0m --------------- Iteration 44 ---------------
[32m[0511 11:42:20 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5431 mins
[32m[0511 11:42:20 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 11:42:20 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 11:42:20 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:20 @base_main.py:47][0m 44220 total steps have happened
[32m[0511 11:42:20 @base_main.py:52][0m [avg_reward]: -1078.8373518928167
[32m[0511 11:42:20 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:20 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:20 @base_trainer.py:216][0m Mean reward: -952.4020049317369
[32m[0511 11:42:21 @base_main.py:38][0m --------------- Iteration 45 ---------------
[32m[0511 11:42:21 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5556 mins
[32m[0511 11:42:21 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 11:42:21 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 11:42:21 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:21 @base_main.py:47][0m 45225 total steps have happened
[32m[0511 11:42:21 @base_main.py:52][0m [avg_reward]: -952.4020049317369
[32m[0511 11:42:21 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:21 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:21 @base_trainer.py:216][0m Mean reward: -821.9495622326233
[32m[0511 11:42:21 @base_main.py:38][0m --------------- Iteration 46 ---------------
[32m[0511 11:42:21 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5679 mins
[32m[0511 11:42:21 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 11:42:21 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 11:42:21 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:21 @base_main.py:47][0m 46230 total steps have happened
[32m[0511 11:42:21 @base_main.py:52][0m [avg_reward]: -821.9495622326233
[32m[0511 11:42:22 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:22 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:22 @base_trainer.py:216][0m Mean reward: -971.4503070123317
[32m[0511 11:42:22 @base_main.py:38][0m --------------- Iteration 47 ---------------
[32m[0511 11:42:22 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5803 mins
[32m[0511 11:42:22 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 11:42:22 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 11:42:22 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:22 @base_main.py:47][0m 47235 total steps have happened
[32m[0511 11:42:22 @base_main.py:52][0m [avg_reward]: -971.4503070123317
[32m[0511 11:42:22 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:22 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:22 @base_trainer.py:216][0m Mean reward: -1069.7583122604024
[32m[0511 11:42:23 @base_main.py:38][0m --------------- Iteration 48 ---------------
[32m[0511 11:42:23 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.5931 mins
[32m[0511 11:42:23 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0511 11:42:23 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 11:42:23 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:23 @base_main.py:47][0m 48240 total steps have happened
[32m[0511 11:42:23 @base_main.py:52][0m [avg_reward]: -1069.7583122604024
[32m[0511 11:42:23 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:23 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:23 @base_trainer.py:216][0m Mean reward: -928.7375954289082
[32m[0511 11:42:24 @base_main.py:38][0m --------------- Iteration 49 ---------------
[32m[0511 11:42:24 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6061 mins
[32m[0511 11:42:24 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 11:42:24 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 11:42:24 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:24 @base_main.py:47][0m 49245 total steps have happened
[32m[0511 11:42:24 @base_main.py:52][0m [avg_reward]: -928.7375954289082
[32m[0511 11:42:24 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:24 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:24 @base_trainer.py:216][0m Mean reward: -1180.6003308148765
[32m[0511 11:42:24 @base_main.py:38][0m --------------- Iteration 50 ---------------
[32m[0511 11:42:24 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6186 mins
[32m[0511 11:42:24 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 11:42:24 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 11:42:24 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:24 @base_main.py:47][0m 50250 total steps have happened
[32m[0511 11:42:24 @base_main.py:52][0m [avg_reward]: -1180.6003308148765
[32m[0511 11:42:25 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:25 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:25 @base_trainer.py:216][0m Mean reward: -1187.7243254299008
[32m[0511 11:42:25 @base_main.py:38][0m --------------- Iteration 51 ---------------
[32m[0511 11:42:25 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6309 mins
[32m[0511 11:42:25 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 11:42:25 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0511 11:42:25 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:25 @base_main.py:47][0m 51255 total steps have happened
[32m[0511 11:42:25 @base_main.py:52][0m [avg_reward]: -1187.7243254299008
[32m[0511 11:42:25 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:25 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:25 @base_trainer.py:216][0m Mean reward: -959.1839191329973
[32m[0511 11:42:26 @base_main.py:38][0m --------------- Iteration 52 ---------------
[32m[0511 11:42:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6429 mins
[32m[0511 11:42:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 11:42:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 11:42:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:26 @base_main.py:47][0m 52260 total steps have happened
[32m[0511 11:42:26 @base_main.py:52][0m [avg_reward]: -959.1839191329973
[32m[0511 11:42:26 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:26 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:26 @base_trainer.py:216][0m Mean reward: -970.0744582833406
[32m[0511 11:42:27 @base_main.py:38][0m --------------- Iteration 53 ---------------
[32m[0511 11:42:27 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6550 mins
[32m[0511 11:42:27 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 11:42:27 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 11:42:27 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:27 @base_main.py:47][0m 53265 total steps have happened
[32m[0511 11:42:27 @base_main.py:52][0m [avg_reward]: -970.0744582833406
[32m[0511 11:42:27 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:27 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:27 @base_trainer.py:216][0m Mean reward: -976.9734251672569
[32m[0511 11:42:27 @base_main.py:38][0m --------------- Iteration 54 ---------------
[32m[0511 11:42:27 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6681 mins
[32m[0511 11:42:27 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 11:42:27 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 11:42:27 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:27 @base_main.py:47][0m 54270 total steps have happened
[32m[0511 11:42:27 @base_main.py:52][0m [avg_reward]: -976.9734251672569
[32m[0511 11:42:28 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:28 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:28 @base_trainer.py:216][0m Mean reward: -954.7081448096608
[32m[0511 11:42:28 @base_main.py:38][0m --------------- Iteration 55 ---------------
[32m[0511 11:42:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6805 mins
[32m[0511 11:42:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 11:42:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 11:42:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:28 @base_main.py:47][0m 55275 total steps have happened
[32m[0511 11:42:28 @base_main.py:52][0m [avg_reward]: -954.7081448096608
[32m[0511 11:42:28 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:28 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:28 @base_trainer.py:216][0m Mean reward: -884.4948267928269
[32m[0511 11:42:29 @base_main.py:38][0m --------------- Iteration 56 ---------------
[32m[0511 11:42:29 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.6933 mins
[32m[0511 11:42:29 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0028 mins
[32m[0511 11:42:29 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 11:42:29 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:29 @base_main.py:47][0m 56280 total steps have happened
[32m[0511 11:42:29 @base_main.py:52][0m [avg_reward]: -884.4948267928269
[32m[0511 11:42:29 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:29 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:29 @base_trainer.py:216][0m Mean reward: -990.1495732352184
[32m[0511 11:42:30 @base_main.py:38][0m --------------- Iteration 57 ---------------
[32m[0511 11:42:30 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7064 mins
[32m[0511 11:42:30 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 11:42:30 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 11:42:30 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:30 @base_main.py:47][0m 57285 total steps have happened
[32m[0511 11:42:30 @base_main.py:52][0m [avg_reward]: -990.1495732352184
[32m[0511 11:42:30 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:30 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:30 @base_trainer.py:216][0m Mean reward: -1301.1844905877092
[32m[0511 11:42:31 @base_main.py:38][0m --------------- Iteration 58 ---------------
[32m[0511 11:42:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7193 mins
[32m[0511 11:42:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 11:42:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 11:42:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:31 @base_main.py:47][0m 58290 total steps have happened
[32m[0511 11:42:31 @base_main.py:52][0m [avg_reward]: -1301.1844905877092
[32m[0511 11:42:31 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:31 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:31 @base_trainer.py:216][0m Mean reward: -946.9741946172842
[32m[0511 11:42:31 @base_main.py:38][0m --------------- Iteration 59 ---------------
[32m[0511 11:42:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7320 mins
[32m[0511 11:42:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 11:42:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 11:42:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:31 @base_main.py:47][0m 59295 total steps have happened
[32m[0511 11:42:31 @base_main.py:52][0m [avg_reward]: -946.9741946172842
[32m[0511 11:42:31 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:31 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:31 @base_trainer.py:216][0m Mean reward: -1145.8088978888106
[32m[0511 11:42:32 @base_main.py:38][0m --------------- Iteration 60 ---------------
[32m[0511 11:42:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7447 mins
[32m[0511 11:42:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 11:42:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0090 mins
[32m[0511 11:42:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:32 @base_main.py:47][0m 60300 total steps have happened
[32m[0511 11:42:32 @base_main.py:52][0m [avg_reward]: -1145.8088978888106
[32m[0511 11:42:32 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:32 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:32 @base_trainer.py:216][0m Mean reward: -996.6784883735094
[32m[0511 11:42:33 @base_main.py:38][0m --------------- Iteration 61 ---------------
[32m[0511 11:42:33 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7558 mins
[32m[0511 11:42:33 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 11:42:33 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 11:42:33 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:33 @base_main.py:47][0m 61305 total steps have happened
[32m[0511 11:42:33 @base_main.py:52][0m [avg_reward]: -996.6784883735094
[32m[0511 11:42:33 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:33 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:33 @base_trainer.py:216][0m Mean reward: -1131.8176596223825
[32m[0511 11:42:33 @base_main.py:38][0m --------------- Iteration 62 ---------------
[32m[0511 11:42:33 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7681 mins
[32m[0511 11:42:33 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 11:42:33 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0511 11:42:33 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:33 @base_main.py:47][0m 62310 total steps have happened
[32m[0511 11:42:33 @base_main.py:52][0m [avg_reward]: -1131.8176596223825
[32m[0511 11:42:34 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:34 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:34 @base_trainer.py:216][0m Mean reward: -1121.4380742152066
[32m[0511 11:42:34 @base_main.py:38][0m --------------- Iteration 63 ---------------
[32m[0511 11:42:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7800 mins
[32m[0511 11:42:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 11:42:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 11:42:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:34 @base_main.py:47][0m 63315 total steps have happened
[32m[0511 11:42:34 @base_main.py:52][0m [avg_reward]: -1121.4380742152066
[32m[0511 11:42:34 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:34 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:34 @base_trainer.py:216][0m Mean reward: -1086.765823715126
[32m[0511 11:42:35 @base_main.py:38][0m --------------- Iteration 64 ---------------
[32m[0511 11:42:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.7926 mins
[32m[0511 11:42:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 11:42:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0107 mins
[32m[0511 11:42:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:35 @base_main.py:47][0m 64320 total steps have happened
[32m[0511 11:42:35 @base_main.py:52][0m [avg_reward]: -1086.765823715126
[32m[0511 11:42:35 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:35 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:35 @base_trainer.py:216][0m Mean reward: -951.2792996769527
[32m[0511 11:42:36 @base_main.py:38][0m --------------- Iteration 65 ---------------
[32m[0511 11:42:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8056 mins
[32m[0511 11:42:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 11:42:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 11:42:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:36 @base_main.py:47][0m 65325 total steps have happened
[32m[0511 11:42:36 @base_main.py:52][0m [avg_reward]: -951.2792996769527
[32m[0511 11:42:36 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:36 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:36 @base_trainer.py:216][0m Mean reward: -1318.4698094822938
[32m[0511 11:42:36 @base_main.py:38][0m --------------- Iteration 66 ---------------
[32m[0511 11:42:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8177 mins
[32m[0511 11:42:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 11:42:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 11:42:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:36 @base_main.py:47][0m 66330 total steps have happened
[32m[0511 11:42:36 @base_main.py:52][0m [avg_reward]: -1318.4698094822938
[32m[0511 11:42:37 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:37 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:37 @base_trainer.py:216][0m Mean reward: -1151.2463769259207
[32m[0511 11:42:37 @base_main.py:38][0m --------------- Iteration 67 ---------------
[32m[0511 11:42:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8307 mins
[32m[0511 11:42:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 11:42:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 11:42:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:37 @base_main.py:47][0m 67335 total steps have happened
[32m[0511 11:42:37 @base_main.py:52][0m [avg_reward]: -1151.2463769259207
[32m[0511 11:42:37 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:37 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:37 @base_trainer.py:216][0m Mean reward: -1408.7297897768601
[32m[0511 11:42:38 @base_main.py:38][0m --------------- Iteration 68 ---------------
[32m[0511 11:42:38 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8432 mins
[32m[0511 11:42:38 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0511 11:42:38 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 11:42:38 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:38 @base_main.py:47][0m 68340 total steps have happened
[32m[0511 11:42:38 @base_main.py:52][0m [avg_reward]: -1408.7297897768601
[32m[0511 11:42:38 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:38 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:38 @base_trainer.py:216][0m Mean reward: -1034.8083314520852
[32m[0511 11:42:39 @base_main.py:38][0m --------------- Iteration 69 ---------------
[32m[0511 11:42:39 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8559 mins
[32m[0511 11:42:39 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 11:42:39 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 11:42:39 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:39 @base_main.py:47][0m 69345 total steps have happened
[32m[0511 11:42:39 @base_main.py:52][0m [avg_reward]: -1034.8083314520852
[32m[0511 11:42:39 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:39 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:39 @base_trainer.py:216][0m Mean reward: -1090.6991132956778
[32m[0511 11:42:39 @base_main.py:38][0m --------------- Iteration 70 ---------------
[32m[0511 11:42:39 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8684 mins
[32m[0511 11:42:39 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 11:42:39 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 11:42:39 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:39 @base_main.py:47][0m 70350 total steps have happened
[32m[0511 11:42:39 @base_main.py:52][0m [avg_reward]: -1090.6991132956778
[32m[0511 11:42:40 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:40 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:40 @base_trainer.py:216][0m Mean reward: -1198.3284032899312
[32m[0511 11:42:40 @base_main.py:38][0m --------------- Iteration 71 ---------------
[32m[0511 11:42:40 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8807 mins
[32m[0511 11:42:40 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 11:42:40 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 11:42:40 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:40 @base_main.py:47][0m 71355 total steps have happened
[32m[0511 11:42:40 @base_main.py:52][0m [avg_reward]: -1198.3284032899312
[32m[0511 11:42:40 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:40 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:40 @base_trainer.py:216][0m Mean reward: -1038.2656070989399
[32m[0511 11:42:41 @base_main.py:38][0m --------------- Iteration 72 ---------------
[32m[0511 11:42:41 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.8934 mins
[32m[0511 11:42:41 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 11:42:41 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 11:42:41 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:41 @base_main.py:47][0m 72360 total steps have happened
[32m[0511 11:42:41 @base_main.py:52][0m [avg_reward]: -1038.2656070989399
[32m[0511 11:42:41 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:41 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:41 @base_trainer.py:216][0m Mean reward: -878.9975018391063
[32m[0511 11:42:42 @base_main.py:38][0m --------------- Iteration 73 ---------------
[32m[0511 11:42:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9056 mins
[32m[0511 11:42:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 11:42:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 11:42:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:42 @base_main.py:47][0m 73365 total steps have happened
[32m[0511 11:42:42 @base_main.py:52][0m [avg_reward]: -878.9975018391063
[32m[0511 11:42:42 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:42 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:42 @base_trainer.py:216][0m Mean reward: -1145.2156829482806
[32m[0511 11:42:42 @base_main.py:38][0m --------------- Iteration 74 ---------------
[32m[0511 11:42:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9180 mins
[32m[0511 11:42:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 11:42:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 11:42:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:42 @base_main.py:47][0m 74370 total steps have happened
[32m[0511 11:42:42 @base_main.py:52][0m [avg_reward]: -1145.2156829482806
[32m[0511 11:42:43 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:43 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:43 @base_trainer.py:216][0m Mean reward: -1128.003139381688
[32m[0511 11:42:43 @base_main.py:38][0m --------------- Iteration 75 ---------------
[32m[0511 11:42:43 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9307 mins
[32m[0511 11:42:43 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 11:42:43 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 11:42:43 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:43 @base_main.py:47][0m 75375 total steps have happened
[32m[0511 11:42:43 @base_main.py:52][0m [avg_reward]: -1128.003139381688
[32m[0511 11:42:43 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:43 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:43 @base_trainer.py:216][0m Mean reward: -1020.1409004655567
[32m[0511 11:42:44 @base_main.py:38][0m --------------- Iteration 76 ---------------
[32m[0511 11:42:44 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9429 mins
[32m[0511 11:42:44 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 11:42:44 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 11:42:44 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:44 @base_main.py:47][0m 76380 total steps have happened
[32m[0511 11:42:44 @base_main.py:52][0m [avg_reward]: -1020.1409004655567
[32m[0511 11:42:44 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:44 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:44 @base_trainer.py:216][0m Mean reward: -981.0835000422119
[32m[0511 11:42:45 @base_main.py:38][0m --------------- Iteration 77 ---------------
[32m[0511 11:42:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9550 mins
[32m[0511 11:42:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 11:42:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 11:42:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:45 @base_main.py:47][0m 77385 total steps have happened
[32m[0511 11:42:45 @base_main.py:52][0m [avg_reward]: -981.0835000422119
[32m[0511 11:42:45 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:45 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:45 @base_trainer.py:216][0m Mean reward: -1037.3462723861978
[32m[0511 11:42:45 @base_main.py:38][0m --------------- Iteration 78 ---------------
[32m[0511 11:42:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9677 mins
[32m[0511 11:42:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 11:42:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 11:42:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:45 @base_main.py:47][0m 78390 total steps have happened
[32m[0511 11:42:45 @base_main.py:52][0m [avg_reward]: -1037.3462723861978
[32m[0511 11:42:46 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:46 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:46 @base_trainer.py:216][0m Mean reward: -927.1189039951478
[32m[0511 11:42:46 @base_main.py:38][0m --------------- Iteration 79 ---------------
[32m[0511 11:42:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9798 mins
[32m[0511 11:42:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 11:42:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 11:42:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:46 @base_main.py:47][0m 79395 total steps have happened
[32m[0511 11:42:46 @base_main.py:52][0m [avg_reward]: -927.1189039951478
[32m[0511 11:42:46 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:46 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:46 @base_trainer.py:216][0m Mean reward: -935.5484708508477
[32m[0511 11:42:47 @base_main.py:38][0m --------------- Iteration 80 ---------------
[32m[0511 11:42:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 0.9923 mins
[32m[0511 11:42:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 11:42:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 11:42:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:47 @base_main.py:47][0m 80400 total steps have happened
[32m[0511 11:42:47 @base_main.py:52][0m [avg_reward]: -935.5484708508477
[32m[0511 11:42:47 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:47 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:47 @base_trainer.py:216][0m Mean reward: -1444.4258168163535
[32m[0511 11:42:48 @base_main.py:38][0m --------------- Iteration 81 ---------------
[32m[0511 11:42:48 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0046 mins
[32m[0511 11:42:48 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 11:42:48 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 11:42:48 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:48 @base_main.py:47][0m 81405 total steps have happened
[32m[0511 11:42:48 @base_main.py:52][0m [avg_reward]: -1444.4258168163535
[32m[0511 11:42:48 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:48 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:48 @base_trainer.py:216][0m Mean reward: -1145.6252204960542
[32m[0511 11:42:48 @base_main.py:38][0m --------------- Iteration 82 ---------------
[32m[0511 11:42:48 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0173 mins
[32m[0511 11:42:48 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 11:42:48 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 11:42:48 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:48 @base_main.py:47][0m 82410 total steps have happened
[32m[0511 11:42:48 @base_main.py:52][0m [avg_reward]: -1145.6252204960542
[32m[0511 11:42:49 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:49 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:49 @base_trainer.py:216][0m Mean reward: -919.5276559962758
[32m[0511 11:42:49 @base_main.py:38][0m --------------- Iteration 83 ---------------
[32m[0511 11:42:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0302 mins
[32m[0511 11:42:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0018 mins
[32m[0511 11:42:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 11:42:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:49 @base_main.py:47][0m 83415 total steps have happened
[32m[0511 11:42:49 @base_main.py:52][0m [avg_reward]: -919.5276559962758
[32m[0511 11:42:49 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:49 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:49 @base_trainer.py:216][0m Mean reward: -1270.0929800837885
[32m[0511 11:42:50 @base_main.py:38][0m --------------- Iteration 84 ---------------
[32m[0511 11:42:50 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0425 mins
[32m[0511 11:42:50 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 11:42:50 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 11:42:50 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:50 @base_main.py:47][0m 84420 total steps have happened
[32m[0511 11:42:50 @base_main.py:52][0m [avg_reward]: -1270.0929800837885
[32m[0511 11:42:50 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:50 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:50 @base_trainer.py:216][0m Mean reward: -1058.440950407406
[32m[0511 11:42:51 @base_main.py:38][0m --------------- Iteration 85 ---------------
[32m[0511 11:42:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0554 mins
[32m[0511 11:42:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 11:42:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 11:42:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:51 @base_main.py:47][0m 85425 total steps have happened
[32m[0511 11:42:51 @base_main.py:52][0m [avg_reward]: -1058.440950407406
[32m[0511 11:42:51 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:51 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:51 @base_trainer.py:216][0m Mean reward: -954.1888826178258
[32m[0511 11:42:51 @base_main.py:38][0m --------------- Iteration 86 ---------------
[32m[0511 11:42:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0674 mins
[32m[0511 11:42:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 11:42:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 11:42:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:51 @base_main.py:47][0m 86430 total steps have happened
[32m[0511 11:42:51 @base_main.py:52][0m [avg_reward]: -954.1888826178258
[32m[0511 11:42:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:52 @base_trainer.py:216][0m Mean reward: -1209.300733145572
[32m[0511 11:42:52 @base_main.py:38][0m --------------- Iteration 87 ---------------
[32m[0511 11:42:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0803 mins
[32m[0511 11:42:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 11:42:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 11:42:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:52 @base_main.py:47][0m 87435 total steps have happened
[32m[0511 11:42:52 @base_main.py:52][0m [avg_reward]: -1209.300733145572
[32m[0511 11:42:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:52 @base_trainer.py:216][0m Mean reward: -990.9897138385395
[32m[0511 11:42:53 @base_main.py:38][0m --------------- Iteration 88 ---------------
[32m[0511 11:42:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.0931 mins
[32m[0511 11:42:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0511 11:42:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 11:42:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:53 @base_main.py:47][0m 88440 total steps have happened
[32m[0511 11:42:53 @base_main.py:52][0m [avg_reward]: -990.9897138385395
[32m[0511 11:42:53 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:53 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:53 @base_trainer.py:216][0m Mean reward: -998.8133256982549
[32m[0511 11:42:54 @base_main.py:38][0m --------------- Iteration 89 ---------------
[32m[0511 11:42:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1060 mins
[32m[0511 11:42:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 11:42:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 11:42:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:54 @base_main.py:47][0m 89445 total steps have happened
[32m[0511 11:42:54 @base_main.py:52][0m [avg_reward]: -998.8133256982549
[32m[0511 11:42:54 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:54 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:54 @base_trainer.py:216][0m Mean reward: -1253.1713961025653
[32m[0511 11:42:54 @base_main.py:38][0m --------------- Iteration 90 ---------------
[32m[0511 11:42:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1189 mins
[32m[0511 11:42:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 11:42:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 11:42:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:54 @base_main.py:47][0m 90450 total steps have happened
[32m[0511 11:42:54 @base_main.py:52][0m [avg_reward]: -1253.1713961025653
[32m[0511 11:42:55 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:55 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:55 @base_trainer.py:216][0m Mean reward: -1272.5357386158794
[32m[0511 11:42:55 @base_main.py:38][0m --------------- Iteration 91 ---------------
[32m[0511 11:42:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1313 mins
[32m[0511 11:42:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 11:42:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 11:42:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:55 @base_main.py:47][0m 91455 total steps have happened
[32m[0511 11:42:55 @base_main.py:52][0m [avg_reward]: -1272.5357386158794
[32m[0511 11:42:55 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:55 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:55 @base_trainer.py:216][0m Mean reward: -1016.8298551049077
[32m[0511 11:42:56 @base_main.py:38][0m --------------- Iteration 92 ---------------
[32m[0511 11:42:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1434 mins
[32m[0511 11:42:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 11:42:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 11:42:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:56 @base_main.py:47][0m 92460 total steps have happened
[32m[0511 11:42:56 @base_main.py:52][0m [avg_reward]: -1016.8298551049077
[32m[0511 11:42:56 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:56 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:56 @base_trainer.py:216][0m Mean reward: -1216.5667274912453
[32m[0511 11:42:57 @base_main.py:38][0m --------------- Iteration 93 ---------------
[32m[0511 11:42:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1565 mins
[32m[0511 11:42:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 11:42:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 11:42:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:57 @base_main.py:47][0m 93465 total steps have happened
[32m[0511 11:42:57 @base_main.py:52][0m [avg_reward]: -1216.5667274912453
[32m[0511 11:42:57 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:57 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:57 @base_trainer.py:216][0m Mean reward: -992.7334570579184
[32m[0511 11:42:58 @base_main.py:38][0m --------------- Iteration 94 ---------------
[32m[0511 11:42:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1694 mins
[32m[0511 11:42:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 11:42:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 11:42:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:58 @base_main.py:47][0m 94470 total steps have happened
[32m[0511 11:42:58 @base_main.py:52][0m [avg_reward]: -992.7334570579184
[32m[0511 11:42:58 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:58 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:58 @base_trainer.py:216][0m Mean reward: -1136.208511849983
[32m[0511 11:42:58 @base_main.py:38][0m --------------- Iteration 95 ---------------
[32m[0511 11:42:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1819 mins
[32m[0511 11:42:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 11:42:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 11:42:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:58 @base_main.py:47][0m 95475 total steps have happened
[32m[0511 11:42:58 @base_main.py:52][0m [avg_reward]: -1136.208511849983
[32m[0511 11:42:58 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:58 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:58 @base_trainer.py:216][0m Mean reward: -1060.646023602721
[32m[0511 11:42:59 @base_main.py:38][0m --------------- Iteration 96 ---------------
[32m[0511 11:42:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.1945 mins
[32m[0511 11:42:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 11:42:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 11:42:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:42:59 @base_main.py:47][0m 96480 total steps have happened
[32m[0511 11:42:59 @base_main.py:52][0m [avg_reward]: -1060.646023602721
[32m[0511 11:42:59 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:42:59 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:42:59 @base_trainer.py:216][0m Mean reward: -1192.3998581876292
[32m[0511 11:43:00 @base_main.py:38][0m --------------- Iteration 97 ---------------
[32m[0511 11:43:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2069 mins
[32m[0511 11:43:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 11:43:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 11:43:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:00 @base_main.py:47][0m 97485 total steps have happened
[32m[0511 11:43:00 @base_main.py:52][0m [avg_reward]: -1192.3998581876292
[32m[0511 11:43:00 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:00 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:00 @base_trainer.py:216][0m Mean reward: -1127.8244149666175
[32m[0511 11:43:01 @base_main.py:38][0m --------------- Iteration 98 ---------------
[32m[0511 11:43:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2193 mins
[32m[0511 11:43:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 11:43:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 11:43:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:01 @base_main.py:47][0m 98490 total steps have happened
[32m[0511 11:43:01 @base_main.py:52][0m [avg_reward]: -1127.8244149666175
[32m[0511 11:43:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:01 @base_trainer.py:216][0m Mean reward: -1161.6757723334965
[32m[0511 11:43:01 @base_main.py:38][0m --------------- Iteration 99 ---------------
[32m[0511 11:43:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2322 mins
[32m[0511 11:43:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 11:43:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 11:43:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:01 @base_main.py:47][0m 99495 total steps have happened
[32m[0511 11:43:01 @base_main.py:52][0m [avg_reward]: -1161.6757723334965
[32m[0511 11:43:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:01 @base_trainer.py:216][0m Mean reward: -987.6159757009758
[32m[0511 11:43:02 @base_main.py:38][0m --------------- Iteration 100 ---------------
[32m[0511 11:43:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2450 mins
[32m[0511 11:43:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 11:43:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 11:43:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:02 @base_main.py:47][0m 100500 total steps have happened
[32m[0511 11:43:02 @base_main.py:52][0m [avg_reward]: -987.6159757009758
[32m[0511 11:43:02 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:02 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:02 @base_trainer.py:216][0m Mean reward: -976.6345469515596
[32m[0511 11:43:03 @base_main.py:38][0m --------------- Iteration 101 ---------------
[32m[0511 11:43:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2572 mins
[32m[0511 11:43:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 11:43:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 11:43:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:03 @base_main.py:47][0m 101505 total steps have happened
[32m[0511 11:43:03 @base_main.py:52][0m [avg_reward]: -976.6345469515596
[32m[0511 11:43:03 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:03 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:03 @base_trainer.py:216][0m Mean reward: -1176.1484632984211
[32m[0511 11:43:04 @base_main.py:38][0m --------------- Iteration 102 ---------------
[32m[0511 11:43:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2701 mins
[32m[0511 11:43:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 11:43:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 11:43:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:04 @base_main.py:47][0m 102510 total steps have happened
[32m[0511 11:43:04 @base_main.py:52][0m [avg_reward]: -1176.1484632984211
[32m[0511 11:43:04 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:04 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:04 @base_trainer.py:216][0m Mean reward: -960.8081853945894
[32m[0511 11:43:04 @base_main.py:38][0m --------------- Iteration 103 ---------------
[32m[0511 11:43:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2823 mins
[32m[0511 11:43:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 11:43:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 11:43:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:04 @base_main.py:47][0m 103515 total steps have happened
[32m[0511 11:43:04 @base_main.py:52][0m [avg_reward]: -960.8081853945894
[32m[0511 11:43:04 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:04 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:04 @base_trainer.py:216][0m Mean reward: -1002.9034886593041
[32m[0511 11:43:05 @base_main.py:38][0m --------------- Iteration 104 ---------------
[32m[0511 11:43:05 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.2955 mins
[32m[0511 11:43:05 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 11:43:05 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 11:43:05 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:05 @base_main.py:47][0m 104520 total steps have happened
[32m[0511 11:43:05 @base_main.py:52][0m [avg_reward]: -1002.9034886593041
[32m[0511 11:43:05 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:05 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:05 @base_trainer.py:216][0m Mean reward: -1125.62384170024
[32m[0511 11:43:06 @base_main.py:38][0m --------------- Iteration 105 ---------------
[32m[0511 11:43:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3081 mins
[32m[0511 11:43:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 11:43:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0511 11:43:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:06 @base_main.py:47][0m 105525 total steps have happened
[32m[0511 11:43:06 @base_main.py:52][0m [avg_reward]: -1125.62384170024
[32m[0511 11:43:06 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:06 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:06 @base_trainer.py:216][0m Mean reward: -995.9905635401083
[32m[0511 11:43:07 @base_main.py:38][0m --------------- Iteration 106 ---------------
[32m[0511 11:43:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3200 mins
[32m[0511 11:43:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 11:43:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 11:43:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:07 @base_main.py:47][0m 106530 total steps have happened
[32m[0511 11:43:07 @base_main.py:52][0m [avg_reward]: -995.9905635401083
[32m[0511 11:43:07 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:07 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:07 @base_trainer.py:216][0m Mean reward: -1080.088846975654
[32m[0511 11:43:07 @base_main.py:38][0m --------------- Iteration 107 ---------------
[32m[0511 11:43:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3322 mins
[32m[0511 11:43:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 11:43:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 11:43:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:07 @base_main.py:47][0m 107535 total steps have happened
[32m[0511 11:43:07 @base_main.py:52][0m [avg_reward]: -1080.088846975654
[32m[0511 11:43:07 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:07 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:07 @base_trainer.py:216][0m Mean reward: -1022.3833594390547
[32m[0511 11:43:08 @base_main.py:38][0m --------------- Iteration 108 ---------------
[32m[0511 11:43:08 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3444 mins
[32m[0511 11:43:08 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 11:43:08 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 11:43:08 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:08 @base_main.py:47][0m 108540 total steps have happened
[32m[0511 11:43:08 @base_main.py:52][0m [avg_reward]: -1022.3833594390547
[32m[0511 11:43:08 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:08 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:08 @base_trainer.py:216][0m Mean reward: -954.7626953007084
[32m[0511 11:43:09 @base_main.py:38][0m --------------- Iteration 109 ---------------
[32m[0511 11:43:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3571 mins
[32m[0511 11:43:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 11:43:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 11:43:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:09 @base_main.py:47][0m 109545 total steps have happened
[32m[0511 11:43:09 @base_main.py:52][0m [avg_reward]: -954.7626953007084
[32m[0511 11:43:09 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:09 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:09 @base_trainer.py:216][0m Mean reward: -1024.9860423171726
[32m[0511 11:43:10 @base_main.py:38][0m --------------- Iteration 110 ---------------
[32m[0511 11:43:10 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3695 mins
[32m[0511 11:43:10 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 11:43:10 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 11:43:10 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:10 @base_main.py:47][0m 110550 total steps have happened
[32m[0511 11:43:10 @base_main.py:52][0m [avg_reward]: -1024.9860423171726
[32m[0511 11:43:10 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:10 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:10 @base_trainer.py:216][0m Mean reward: -958.8330659216638
[32m[0511 11:43:10 @base_main.py:38][0m --------------- Iteration 111 ---------------
[32m[0511 11:43:10 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3818 mins
[32m[0511 11:43:10 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 11:43:10 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 11:43:10 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:10 @base_main.py:47][0m 111555 total steps have happened
[32m[0511 11:43:10 @base_main.py:52][0m [avg_reward]: -958.8330659216638
[32m[0511 11:43:10 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:10 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:10 @base_trainer.py:216][0m Mean reward: -1143.5182361629468
[32m[0511 11:43:11 @base_main.py:38][0m --------------- Iteration 112 ---------------
[32m[0511 11:43:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.3948 mins
[32m[0511 11:43:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0511 11:43:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 11:43:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:11 @base_main.py:47][0m 112560 total steps have happened
[32m[0511 11:43:11 @base_main.py:52][0m [avg_reward]: -1143.5182361629468
[32m[0511 11:43:11 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:11 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:11 @base_trainer.py:216][0m Mean reward: -1034.964149845046
[32m[0511 11:43:12 @base_main.py:38][0m --------------- Iteration 113 ---------------
[32m[0511 11:43:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4077 mins
[32m[0511 11:43:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 11:43:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 11:43:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:12 @base_main.py:47][0m 113565 total steps have happened
[32m[0511 11:43:12 @base_main.py:52][0m [avg_reward]: -1034.964149845046
[32m[0511 11:43:12 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:12 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:12 @base_trainer.py:216][0m Mean reward: -1041.5357372291278
[32m[0511 11:43:13 @base_main.py:38][0m --------------- Iteration 114 ---------------
[32m[0511 11:43:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4200 mins
[32m[0511 11:43:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 11:43:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 11:43:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:13 @base_main.py:47][0m 114570 total steps have happened
[32m[0511 11:43:13 @base_main.py:52][0m [avg_reward]: -1041.5357372291278
[32m[0511 11:43:13 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:13 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:13 @base_trainer.py:216][0m Mean reward: -1057.647241932009
[32m[0511 11:43:13 @base_main.py:38][0m --------------- Iteration 115 ---------------
[32m[0511 11:43:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4321 mins
[32m[0511 11:43:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 11:43:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0108 mins
[32m[0511 11:43:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:13 @base_main.py:47][0m 115575 total steps have happened
[32m[0511 11:43:13 @base_main.py:52][0m [avg_reward]: -1057.647241932009
[32m[0511 11:43:13 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:13 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:13 @base_trainer.py:216][0m Mean reward: -1164.3684641900513
[32m[0511 11:43:14 @base_main.py:38][0m --------------- Iteration 116 ---------------
[32m[0511 11:43:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4453 mins
[32m[0511 11:43:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 11:43:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 11:43:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:14 @base_main.py:47][0m 116580 total steps have happened
[32m[0511 11:43:14 @base_main.py:52][0m [avg_reward]: -1164.3684641900513
[32m[0511 11:43:14 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:14 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:14 @base_trainer.py:216][0m Mean reward: -941.0495410948924
[32m[0511 11:43:15 @base_main.py:38][0m --------------- Iteration 117 ---------------
[32m[0511 11:43:15 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4579 mins
[32m[0511 11:43:15 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 11:43:15 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 11:43:15 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:15 @base_main.py:47][0m 117585 total steps have happened
[32m[0511 11:43:15 @base_main.py:52][0m [avg_reward]: -941.0495410948924
[32m[0511 11:43:15 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:15 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:15 @base_trainer.py:216][0m Mean reward: -945.3082622574213
[32m[0511 11:43:16 @base_main.py:38][0m --------------- Iteration 118 ---------------
[32m[0511 11:43:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4700 mins
[32m[0511 11:43:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 11:43:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 11:43:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:16 @base_main.py:47][0m 118590 total steps have happened
[32m[0511 11:43:16 @base_main.py:52][0m [avg_reward]: -945.3082622574213
[32m[0511 11:43:16 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:16 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:16 @base_trainer.py:216][0m Mean reward: -1041.27869193615
[32m[0511 11:43:16 @base_main.py:38][0m --------------- Iteration 119 ---------------
[32m[0511 11:43:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4824 mins
[32m[0511 11:43:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 11:43:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 11:43:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:16 @base_main.py:47][0m 119595 total steps have happened
[32m[0511 11:43:16 @base_main.py:52][0m [avg_reward]: -1041.27869193615
[32m[0511 11:43:16 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:16 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:16 @base_trainer.py:216][0m Mean reward: -1025.6249894990892
[32m[0511 11:43:17 @base_main.py:38][0m --------------- Iteration 120 ---------------
[32m[0511 11:43:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.4947 mins
[32m[0511 11:43:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 11:43:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 11:43:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:17 @base_main.py:47][0m 120600 total steps have happened
[32m[0511 11:43:17 @base_main.py:52][0m [avg_reward]: -1025.6249894990892
[32m[0511 11:43:17 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:17 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:17 @base_trainer.py:216][0m Mean reward: -1062.7089733806065
[32m[0511 11:43:18 @base_main.py:38][0m --------------- Iteration 121 ---------------
[32m[0511 11:43:18 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5071 mins
[32m[0511 11:43:18 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 11:43:18 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 11:43:18 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:18 @base_main.py:47][0m 121605 total steps have happened
[32m[0511 11:43:18 @base_main.py:52][0m [avg_reward]: -1062.7089733806065
[32m[0511 11:43:18 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:18 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:18 @base_trainer.py:216][0m Mean reward: -1056.1027452465355
[32m[0511 11:43:19 @base_main.py:38][0m --------------- Iteration 122 ---------------
[32m[0511 11:43:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5200 mins
[32m[0511 11:43:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 11:43:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 11:43:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:19 @base_main.py:47][0m 122610 total steps have happened
[32m[0511 11:43:19 @base_main.py:52][0m [avg_reward]: -1056.1027452465355
[32m[0511 11:43:19 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:19 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:19 @base_trainer.py:216][0m Mean reward: -1160.3875747137358
[32m[0511 11:43:19 @base_main.py:38][0m --------------- Iteration 123 ---------------
[32m[0511 11:43:19 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5323 mins
[32m[0511 11:43:19 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 11:43:19 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 11:43:19 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:19 @base_main.py:47][0m 123615 total steps have happened
[32m[0511 11:43:19 @base_main.py:52][0m [avg_reward]: -1160.3875747137358
[32m[0511 11:43:19 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:19 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:19 @base_trainer.py:216][0m Mean reward: -997.0860894500813
[32m[0511 11:43:20 @base_main.py:38][0m --------------- Iteration 124 ---------------
[32m[0511 11:43:20 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5447 mins
[32m[0511 11:43:20 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0511 11:43:20 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 11:43:20 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:20 @base_main.py:47][0m 124620 total steps have happened
[32m[0511 11:43:20 @base_main.py:52][0m [avg_reward]: -997.0860894500813
[32m[0511 11:43:20 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:20 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:20 @base_trainer.py:216][0m Mean reward: -1040.3133542627024
[32m[0511 11:43:21 @base_main.py:38][0m --------------- Iteration 125 ---------------
[32m[0511 11:43:21 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5578 mins
[32m[0511 11:43:21 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 11:43:21 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 11:43:21 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:21 @base_main.py:47][0m 125625 total steps have happened
[32m[0511 11:43:21 @base_main.py:52][0m [avg_reward]: -1040.3133542627024
[32m[0511 11:43:21 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:21 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:21 @base_trainer.py:216][0m Mean reward: -889.5847737582868
[32m[0511 11:43:22 @base_main.py:38][0m --------------- Iteration 126 ---------------
[32m[0511 11:43:22 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5708 mins
[32m[0511 11:43:22 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 11:43:22 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 11:43:22 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:22 @base_main.py:47][0m 126630 total steps have happened
[32m[0511 11:43:22 @base_main.py:52][0m [avg_reward]: -889.5847737582868
[32m[0511 11:43:22 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:22 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:22 @base_trainer.py:216][0m Mean reward: -901.828376642381
[32m[0511 11:43:22 @base_main.py:38][0m --------------- Iteration 127 ---------------
[32m[0511 11:43:22 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5835 mins
[32m[0511 11:43:22 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 11:43:22 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 11:43:22 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:22 @base_main.py:47][0m 127635 total steps have happened
[32m[0511 11:43:22 @base_main.py:52][0m [avg_reward]: -901.828376642381
[32m[0511 11:43:23 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:23 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:23 @base_trainer.py:216][0m Mean reward: -892.4952324855165
[32m[0511 11:43:23 @base_main.py:38][0m --------------- Iteration 128 ---------------
[32m[0511 11:43:23 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.5961 mins
[32m[0511 11:43:23 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 11:43:23 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 11:43:23 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:23 @base_main.py:47][0m 128640 total steps have happened
[32m[0511 11:43:23 @base_main.py:52][0m [avg_reward]: -892.4952324855165
[32m[0511 11:43:23 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:23 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:23 @base_trainer.py:216][0m Mean reward: -964.0661503369914
[32m[0511 11:43:24 @base_main.py:38][0m --------------- Iteration 129 ---------------
[32m[0511 11:43:24 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6087 mins
[32m[0511 11:43:24 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 11:43:24 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 11:43:24 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:24 @base_main.py:47][0m 129645 total steps have happened
[32m[0511 11:43:24 @base_main.py:52][0m [avg_reward]: -964.0661503369914
[32m[0511 11:43:24 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:24 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:24 @base_trainer.py:216][0m Mean reward: -968.2169960226241
[32m[0511 11:43:25 @base_main.py:38][0m --------------- Iteration 130 ---------------
[32m[0511 11:43:25 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6214 mins
[32m[0511 11:43:25 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 11:43:25 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 11:43:25 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:25 @base_main.py:47][0m 130650 total steps have happened
[32m[0511 11:43:25 @base_main.py:52][0m [avg_reward]: -968.2169960226241
[32m[0511 11:43:25 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:25 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:25 @base_trainer.py:216][0m Mean reward: -870.7329136183668
[32m[0511 11:43:25 @base_main.py:38][0m --------------- Iteration 131 ---------------
[32m[0511 11:43:25 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6339 mins
[32m[0511 11:43:25 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 11:43:25 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 11:43:25 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:25 @base_main.py:47][0m 131655 total steps have happened
[32m[0511 11:43:25 @base_main.py:52][0m [avg_reward]: -870.7329136183668
[32m[0511 11:43:26 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:26 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:26 @base_trainer.py:216][0m Mean reward: -985.7664195825748
[32m[0511 11:43:26 @base_main.py:38][0m --------------- Iteration 132 ---------------
[32m[0511 11:43:26 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6464 mins
[32m[0511 11:43:26 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 11:43:26 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 11:43:26 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:26 @base_main.py:47][0m 132660 total steps have happened
[32m[0511 11:43:26 @base_main.py:52][0m [avg_reward]: -985.7664195825748
[32m[0511 11:43:26 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:26 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:26 @base_trainer.py:216][0m Mean reward: -1025.73962142058
[32m[0511 11:43:27 @base_main.py:38][0m --------------- Iteration 133 ---------------
[32m[0511 11:43:27 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6593 mins
[32m[0511 11:43:27 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 11:43:27 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 11:43:27 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:27 @base_main.py:47][0m 133665 total steps have happened
[32m[0511 11:43:27 @base_main.py:52][0m [avg_reward]: -1025.73962142058
[32m[0511 11:43:27 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:27 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:27 @base_trainer.py:216][0m Mean reward: -1025.2754967769945
[32m[0511 11:43:28 @base_main.py:38][0m --------------- Iteration 134 ---------------
[32m[0511 11:43:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6714 mins
[32m[0511 11:43:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 11:43:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 11:43:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:28 @base_main.py:47][0m 134670 total steps have happened
[32m[0511 11:43:28 @base_main.py:52][0m [avg_reward]: -1025.2754967769945
[32m[0511 11:43:28 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:28 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:28 @base_trainer.py:216][0m Mean reward: -1086.0211673377703
[32m[0511 11:43:28 @base_main.py:38][0m --------------- Iteration 135 ---------------
[32m[0511 11:43:28 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6843 mins
[32m[0511 11:43:28 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 11:43:28 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 11:43:28 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:28 @base_main.py:47][0m 135675 total steps have happened
[32m[0511 11:43:28 @base_main.py:52][0m [avg_reward]: -1086.0211673377703
[32m[0511 11:43:29 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:29 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:29 @base_trainer.py:216][0m Mean reward: -896.7952492634246
[32m[0511 11:43:29 @base_main.py:38][0m --------------- Iteration 136 ---------------
[32m[0511 11:43:29 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.6970 mins
[32m[0511 11:43:29 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 11:43:29 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0095 mins
[32m[0511 11:43:29 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:29 @base_main.py:47][0m 136680 total steps have happened
[32m[0511 11:43:29 @base_main.py:52][0m [avg_reward]: -896.7952492634246
[32m[0511 11:43:29 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:29 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:29 @base_trainer.py:216][0m Mean reward: -838.6342565200712
[32m[0511 11:43:30 @base_main.py:38][0m --------------- Iteration 137 ---------------
[32m[0511 11:43:30 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7087 mins
[32m[0511 11:43:30 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 11:43:30 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 11:43:30 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:30 @base_main.py:47][0m 137685 total steps have happened
[32m[0511 11:43:30 @base_main.py:52][0m [avg_reward]: -838.6342565200712
[32m[0511 11:43:30 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:30 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:30 @base_trainer.py:216][0m Mean reward: -837.4604400338494
[32m[0511 11:43:31 @base_main.py:38][0m --------------- Iteration 138 ---------------
[32m[0511 11:43:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7216 mins
[32m[0511 11:43:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 11:43:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 11:43:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:31 @base_main.py:47][0m 138690 total steps have happened
[32m[0511 11:43:31 @base_main.py:52][0m [avg_reward]: -837.4604400338494
[32m[0511 11:43:31 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:31 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:31 @base_trainer.py:216][0m Mean reward: -806.1235957120483
[32m[0511 11:43:31 @base_main.py:38][0m --------------- Iteration 139 ---------------
[32m[0511 11:43:31 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7344 mins
[32m[0511 11:43:31 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 11:43:31 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 11:43:31 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0511 11:43:31 @base_main.py:47][0m 139695 total steps have happened
[32m[0511 11:43:31 @base_main.py:52][0m [avg_reward]: -806.1235957120483
[32m[0511 11:43:32 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:32 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:32 @base_trainer.py:216][0m Mean reward: -888.9975364687995
[32m[0511 11:43:32 @base_main.py:38][0m --------------- Iteration 140 ---------------
[32m[0511 11:43:32 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7468 mins
[32m[0511 11:43:32 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 11:43:32 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 11:43:32 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:32 @base_main.py:47][0m 140700 total steps have happened
[32m[0511 11:43:32 @base_main.py:52][0m [avg_reward]: -888.9975364687995
[32m[0511 11:43:32 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:32 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:32 @base_trainer.py:216][0m Mean reward: -846.3728109529617
[32m[0511 11:43:33 @base_main.py:38][0m --------------- Iteration 141 ---------------
[32m[0511 11:43:33 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7592 mins
[32m[0511 11:43:33 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 11:43:33 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 11:43:33 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:33 @base_main.py:47][0m 141705 total steps have happened
[32m[0511 11:43:33 @base_main.py:52][0m [avg_reward]: -846.3728109529617
[32m[0511 11:43:33 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:33 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:33 @base_trainer.py:216][0m Mean reward: -931.6683878454903
[32m[0511 11:43:34 @base_main.py:38][0m --------------- Iteration 142 ---------------
[32m[0511 11:43:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7713 mins
[32m[0511 11:43:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 11:43:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 11:43:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:34 @base_main.py:47][0m 142710 total steps have happened
[32m[0511 11:43:34 @base_main.py:52][0m [avg_reward]: -931.6683878454903
[32m[0511 11:43:34 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:34 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:34 @base_trainer.py:216][0m Mean reward: -777.9396248407334
[32m[0511 11:43:34 @base_main.py:38][0m --------------- Iteration 143 ---------------
[32m[0511 11:43:34 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7834 mins
[32m[0511 11:43:34 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0511 11:43:34 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 11:43:34 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:34 @base_main.py:47][0m 143715 total steps have happened
[32m[0511 11:43:34 @base_main.py:52][0m [avg_reward]: -777.9396248407334
[32m[0511 11:43:35 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:35 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:35 @base_trainer.py:216][0m Mean reward: -969.5918757849395
[32m[0511 11:43:35 @base_main.py:38][0m --------------- Iteration 144 ---------------
[32m[0511 11:43:35 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.7959 mins
[32m[0511 11:43:35 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 11:43:35 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 11:43:35 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:35 @base_main.py:47][0m 144720 total steps have happened
[32m[0511 11:43:35 @base_main.py:52][0m [avg_reward]: -969.5918757849395
[32m[0511 11:43:35 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:35 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:35 @base_trainer.py:216][0m Mean reward: -838.4394685538318
[32m[0511 11:43:36 @base_main.py:38][0m --------------- Iteration 145 ---------------
[32m[0511 11:43:36 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8085 mins
[32m[0511 11:43:36 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 11:43:36 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 11:43:36 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:36 @base_main.py:47][0m 145725 total steps have happened
[32m[0511 11:43:36 @base_main.py:52][0m [avg_reward]: -838.4394685538318
[32m[0511 11:43:36 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:36 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:36 @base_trainer.py:216][0m Mean reward: -1018.8491052344161
[32m[0511 11:43:37 @base_main.py:38][0m --------------- Iteration 146 ---------------
[32m[0511 11:43:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8212 mins
[32m[0511 11:43:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 11:43:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 11:43:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:37 @base_main.py:47][0m 146730 total steps have happened
[32m[0511 11:43:37 @base_main.py:52][0m [avg_reward]: -1018.8491052344161
[32m[0511 11:43:37 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:37 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:37 @base_trainer.py:216][0m Mean reward: -837.4909746777888
[32m[0511 11:43:37 @base_main.py:38][0m --------------- Iteration 147 ---------------
[32m[0511 11:43:37 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8338 mins
[32m[0511 11:43:37 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0027 mins
[32m[0511 11:43:37 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 11:43:37 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:37 @base_main.py:47][0m 147735 total steps have happened
[32m[0511 11:43:37 @base_main.py:52][0m [avg_reward]: -837.4909746777888
[32m[0511 11:43:38 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:38 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:38 @base_trainer.py:216][0m Mean reward: -834.7036943649657
[32m[0511 11:43:38 @base_main.py:38][0m --------------- Iteration 148 ---------------
[32m[0511 11:43:38 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8465 mins
[32m[0511 11:43:38 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 11:43:38 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 11:43:38 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:38 @base_main.py:47][0m 148740 total steps have happened
[32m[0511 11:43:38 @base_main.py:52][0m [avg_reward]: -834.7036943649657
[32m[0511 11:43:38 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:38 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:38 @base_trainer.py:216][0m Mean reward: -787.7848239702683
[32m[0511 11:43:39 @base_main.py:38][0m --------------- Iteration 149 ---------------
[32m[0511 11:43:39 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8594 mins
[32m[0511 11:43:39 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 11:43:39 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 11:43:39 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:39 @base_main.py:47][0m 149745 total steps have happened
[32m[0511 11:43:39 @base_main.py:52][0m [avg_reward]: -787.7848239702683
[32m[0511 11:43:39 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:39 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:39 @base_trainer.py:216][0m Mean reward: -961.634773523132
[32m[0511 11:43:40 @base_main.py:38][0m --------------- Iteration 150 ---------------
[32m[0511 11:43:40 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8716 mins
[32m[0511 11:43:40 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 11:43:40 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 11:43:40 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:40 @base_main.py:47][0m 150750 total steps have happened
[32m[0511 11:43:40 @base_main.py:52][0m [avg_reward]: -961.634773523132
[32m[0511 11:43:40 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:40 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:40 @base_trainer.py:216][0m Mean reward: -951.3480327773759
[32m[0511 11:43:40 @base_main.py:38][0m --------------- Iteration 151 ---------------
[32m[0511 11:43:40 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8841 mins
[32m[0511 11:43:40 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 11:43:40 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 11:43:40 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:40 @base_main.py:47][0m 151755 total steps have happened
[32m[0511 11:43:40 @base_main.py:52][0m [avg_reward]: -951.3480327773759
[32m[0511 11:43:41 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:41 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:41 @base_trainer.py:216][0m Mean reward: -838.474911341356
[32m[0511 11:43:41 @base_main.py:38][0m --------------- Iteration 152 ---------------
[32m[0511 11:43:41 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.8972 mins
[32m[0511 11:43:41 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 11:43:41 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 11:43:41 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:41 @base_main.py:47][0m 152760 total steps have happened
[32m[0511 11:43:41 @base_main.py:52][0m [avg_reward]: -838.474911341356
[32m[0511 11:43:41 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:41 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:41 @base_trainer.py:216][0m Mean reward: -790.1753206073475
[32m[0511 11:43:42 @base_main.py:38][0m --------------- Iteration 153 ---------------
[32m[0511 11:43:42 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9099 mins
[32m[0511 11:43:42 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 11:43:42 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 11:43:42 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:42 @base_main.py:47][0m 153765 total steps have happened
[32m[0511 11:43:42 @base_main.py:52][0m [avg_reward]: -790.1753206073475
[32m[0511 11:43:42 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:42 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:42 @base_trainer.py:216][0m Mean reward: -894.0412376011336
[32m[0511 11:43:43 @base_main.py:38][0m --------------- Iteration 154 ---------------
[32m[0511 11:43:43 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9224 mins
[32m[0511 11:43:43 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0018 mins
[32m[0511 11:43:43 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 11:43:43 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:43 @base_main.py:47][0m 154770 total steps have happened
[32m[0511 11:43:43 @base_main.py:52][0m [avg_reward]: -894.0412376011336
[32m[0511 11:43:43 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:43 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:43 @base_trainer.py:216][0m Mean reward: -771.1957216833682
[32m[0511 11:43:43 @base_main.py:38][0m --------------- Iteration 155 ---------------
[32m[0511 11:43:43 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9348 mins
[32m[0511 11:43:43 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 11:43:43 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 11:43:43 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:43 @base_main.py:47][0m 155775 total steps have happened
[32m[0511 11:43:43 @base_main.py:52][0m [avg_reward]: -771.1957216833682
[32m[0511 11:43:44 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:44 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:44 @base_trainer.py:216][0m Mean reward: -833.8030325485634
[32m[0511 11:43:44 @base_main.py:38][0m --------------- Iteration 156 ---------------
[32m[0511 11:43:44 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9477 mins
[32m[0511 11:43:44 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0511 11:43:44 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 11:43:44 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:44 @base_main.py:47][0m 156780 total steps have happened
[32m[0511 11:43:44 @base_main.py:52][0m [avg_reward]: -833.8030325485634
[32m[0511 11:43:44 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:44 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:44 @base_trainer.py:216][0m Mean reward: -844.6728465639659
[32m[0511 11:43:45 @base_main.py:38][0m --------------- Iteration 157 ---------------
[32m[0511 11:43:45 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9605 mins
[32m[0511 11:43:45 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 11:43:45 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 11:43:45 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:45 @base_main.py:47][0m 157785 total steps have happened
[32m[0511 11:43:45 @base_main.py:52][0m [avg_reward]: -844.6728465639659
[32m[0511 11:43:45 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:45 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:45 @base_trainer.py:216][0m Mean reward: -741.7639740125211
[32m[0511 11:43:46 @base_main.py:38][0m --------------- Iteration 158 ---------------
[32m[0511 11:43:46 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9733 mins
[32m[0511 11:43:46 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 11:43:46 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 11:43:46 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:46 @base_main.py:47][0m 158790 total steps have happened
[32m[0511 11:43:46 @base_main.py:52][0m [avg_reward]: -741.7639740125211
[32m[0511 11:43:46 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:46 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:46 @base_trainer.py:216][0m Mean reward: -877.2962364466866
[32m[0511 11:43:47 @base_main.py:38][0m --------------- Iteration 159 ---------------
[32m[0511 11:43:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9864 mins
[32m[0511 11:43:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 11:43:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 11:43:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:47 @base_main.py:47][0m 159795 total steps have happened
[32m[0511 11:43:47 @base_main.py:52][0m [avg_reward]: -877.2962364466866
[32m[0511 11:43:47 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:47 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:47 @base_trainer.py:216][0m Mean reward: -761.2654722653025
[32m[0511 11:43:47 @base_main.py:38][0m --------------- Iteration 160 ---------------
[32m[0511 11:43:47 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 1.9987 mins
[32m[0511 11:43:47 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 11:43:47 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 11:43:47 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:47 @base_main.py:47][0m 160800 total steps have happened
[32m[0511 11:43:47 @base_main.py:52][0m [avg_reward]: -761.2654722653025
[32m[0511 11:43:47 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:47 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:47 @base_trainer.py:216][0m Mean reward: -779.3826266514116
[32m[0511 11:43:48 @base_main.py:38][0m --------------- Iteration 161 ---------------
[32m[0511 11:43:48 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0114 mins
[32m[0511 11:43:48 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 11:43:48 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0092 mins
[32m[0511 11:43:48 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:48 @base_main.py:47][0m 161805 total steps have happened
[32m[0511 11:43:48 @base_main.py:52][0m [avg_reward]: -779.3826266514116
[32m[0511 11:43:48 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:48 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:48 @base_trainer.py:216][0m Mean reward: -738.7815764734726
[32m[0511 11:43:49 @base_main.py:38][0m --------------- Iteration 162 ---------------
[32m[0511 11:43:49 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0230 mins
[32m[0511 11:43:49 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 11:43:49 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 11:43:49 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:49 @base_main.py:47][0m 162810 total steps have happened
[32m[0511 11:43:49 @base_main.py:52][0m [avg_reward]: -738.7815764734726
[32m[0511 11:43:49 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:49 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:49 @base_trainer.py:216][0m Mean reward: -748.8517059028829
[32m[0511 11:43:50 @base_main.py:38][0m --------------- Iteration 163 ---------------
[32m[0511 11:43:50 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0355 mins
[32m[0511 11:43:50 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 11:43:50 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 11:43:50 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:50 @base_main.py:47][0m 163815 total steps have happened
[32m[0511 11:43:50 @base_main.py:52][0m [avg_reward]: -748.8517059028829
[32m[0511 11:43:50 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:50 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:50 @base_trainer.py:216][0m Mean reward: -833.0275014379968
[32m[0511 11:43:50 @base_main.py:38][0m --------------- Iteration 164 ---------------
[32m[0511 11:43:50 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0483 mins
[32m[0511 11:43:50 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 11:43:50 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 11:43:50 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:50 @base_main.py:47][0m 164820 total steps have happened
[32m[0511 11:43:50 @base_main.py:52][0m [avg_reward]: -833.0275014379968
[32m[0511 11:43:50 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:50 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:50 @base_trainer.py:216][0m Mean reward: -774.7065440221403
[32m[0511 11:43:51 @base_main.py:38][0m --------------- Iteration 165 ---------------
[32m[0511 11:43:51 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0610 mins
[32m[0511 11:43:51 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 11:43:51 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 11:43:51 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0511 11:43:51 @base_main.py:47][0m 165825 total steps have happened
[32m[0511 11:43:51 @base_main.py:52][0m [avg_reward]: -774.7065440221403
[32m[0511 11:43:51 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:51 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:51 @base_trainer.py:216][0m Mean reward: -838.287967073554
[32m[0511 11:43:52 @base_main.py:38][0m --------------- Iteration 166 ---------------
[32m[0511 11:43:52 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0737 mins
[32m[0511 11:43:52 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 11:43:52 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 11:43:52 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:52 @base_main.py:47][0m 166830 total steps have happened
[32m[0511 11:43:52 @base_main.py:52][0m [avg_reward]: -838.287967073554
[32m[0511 11:43:52 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:52 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:52 @base_trainer.py:216][0m Mean reward: -817.603997202088
[32m[0511 11:43:53 @base_main.py:38][0m --------------- Iteration 167 ---------------
[32m[0511 11:43:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0860 mins
[32m[0511 11:43:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 11:43:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 11:43:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:53 @base_main.py:47][0m 167835 total steps have happened
[32m[0511 11:43:53 @base_main.py:52][0m [avg_reward]: -817.603997202088
[32m[0511 11:43:53 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:53 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:53 @base_trainer.py:216][0m Mean reward: -805.8412638779753
[32m[0511 11:43:53 @base_main.py:38][0m --------------- Iteration 168 ---------------
[32m[0511 11:43:53 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.0982 mins
[32m[0511 11:43:53 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 11:43:53 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 11:43:53 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:53 @base_main.py:47][0m 168840 total steps have happened
[32m[0511 11:43:53 @base_main.py:52][0m [avg_reward]: -805.8412638779753
[32m[0511 11:43:53 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:53 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:53 @base_trainer.py:216][0m Mean reward: -879.5960481243576
[32m[0511 11:43:54 @base_main.py:38][0m --------------- Iteration 169 ---------------
[32m[0511 11:43:54 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1103 mins
[32m[0511 11:43:54 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 11:43:54 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 11:43:54 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:54 @base_main.py:47][0m 169845 total steps have happened
[32m[0511 11:43:54 @base_main.py:52][0m [avg_reward]: -879.5960481243576
[32m[0511 11:43:54 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:54 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:54 @base_trainer.py:216][0m Mean reward: -871.1393336503836
[32m[0511 11:43:55 @base_main.py:38][0m --------------- Iteration 170 ---------------
[32m[0511 11:43:55 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1235 mins
[32m[0511 11:43:55 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 11:43:55 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 11:43:55 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:55 @base_main.py:47][0m 170850 total steps have happened
[32m[0511 11:43:55 @base_main.py:52][0m [avg_reward]: -871.1393336503836
[32m[0511 11:43:55 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:55 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:55 @base_trainer.py:216][0m Mean reward: -888.5901498542678
[32m[0511 11:43:56 @base_main.py:38][0m --------------- Iteration 171 ---------------
[32m[0511 11:43:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1361 mins
[32m[0511 11:43:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 11:43:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 11:43:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:56 @base_main.py:47][0m 171855 total steps have happened
[32m[0511 11:43:56 @base_main.py:52][0m [avg_reward]: -888.5901498542678
[32m[0511 11:43:56 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:56 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:56 @base_trainer.py:216][0m Mean reward: -777.5644146271713
[32m[0511 11:43:56 @base_main.py:38][0m --------------- Iteration 172 ---------------
[32m[0511 11:43:56 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1485 mins
[32m[0511 11:43:56 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0019 mins
[32m[0511 11:43:56 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 11:43:56 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:56 @base_main.py:47][0m 172860 total steps have happened
[32m[0511 11:43:56 @base_main.py:52][0m [avg_reward]: -777.5644146271713
[32m[0511 11:43:56 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:56 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:56 @base_trainer.py:216][0m Mean reward: -819.8453333674076
[32m[0511 11:43:57 @base_main.py:38][0m --------------- Iteration 173 ---------------
[32m[0511 11:43:57 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1609 mins
[32m[0511 11:43:57 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 11:43:57 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 11:43:57 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:57 @base_main.py:47][0m 173865 total steps have happened
[32m[0511 11:43:57 @base_main.py:52][0m [avg_reward]: -819.8453333674076
[32m[0511 11:43:57 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:57 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:57 @base_trainer.py:216][0m Mean reward: -805.8622809145756
[32m[0511 11:43:58 @base_main.py:38][0m --------------- Iteration 174 ---------------
[32m[0511 11:43:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1735 mins
[32m[0511 11:43:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0511 11:43:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 11:43:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0002 mins
[32m[0511 11:43:58 @base_main.py:47][0m 174870 total steps have happened
[32m[0511 11:43:58 @base_main.py:52][0m [avg_reward]: -805.8622809145756
[32m[0511 11:43:58 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:58 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:58 @base_trainer.py:216][0m Mean reward: -864.2754598602287
[32m[0511 11:43:58 @base_main.py:38][0m --------------- Iteration 175 ---------------
[32m[0511 11:43:58 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1865 mins
[32m[0511 11:43:58 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 11:43:58 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0091 mins
[32m[0511 11:43:58 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:58 @base_main.py:47][0m 175875 total steps have happened
[32m[0511 11:43:58 @base_main.py:52][0m [avg_reward]: -864.2754598602287
[32m[0511 11:43:59 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:59 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:59 @base_trainer.py:216][0m Mean reward: -862.4060076590013
[32m[0511 11:43:59 @base_main.py:38][0m --------------- Iteration 176 ---------------
[32m[0511 11:43:59 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.1978 mins
[32m[0511 11:43:59 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 11:43:59 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 11:43:59 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:43:59 @base_main.py:47][0m 176880 total steps have happened
[32m[0511 11:43:59 @base_main.py:52][0m [avg_reward]: -862.4060076590013
[32m[0511 11:43:59 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:43:59 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:43:59 @base_trainer.py:216][0m Mean reward: -807.7470000967918
[32m[0511 11:44:00 @base_main.py:38][0m --------------- Iteration 177 ---------------
[32m[0511 11:44:00 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2108 mins
[32m[0511 11:44:00 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 11:44:00 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 11:44:00 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:44:00 @base_main.py:47][0m 177885 total steps have happened
[32m[0511 11:44:00 @base_main.py:52][0m [avg_reward]: -807.7470000967918
[32m[0511 11:44:00 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:44:00 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:44:00 @base_trainer.py:216][0m Mean reward: -783.0757227229763
[32m[0511 11:44:01 @base_main.py:38][0m --------------- Iteration 178 ---------------
[32m[0511 11:44:01 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2231 mins
[32m[0511 11:44:01 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 11:44:01 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 11:44:01 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:44:01 @base_main.py:47][0m 178890 total steps have happened
[32m[0511 11:44:01 @base_main.py:52][0m [avg_reward]: -783.0757227229763
[32m[0511 11:44:01 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:44:01 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:44:01 @base_trainer.py:216][0m Mean reward: -830.5613938983815
[32m[0511 11:44:02 @base_main.py:38][0m --------------- Iteration 179 ---------------
[32m[0511 11:44:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2355 mins
[32m[0511 11:44:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 11:44:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0103 mins
[32m[0511 11:44:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:44:02 @base_main.py:47][0m 179895 total steps have happened
[32m[0511 11:44:02 @base_main.py:52][0m [avg_reward]: -830.5613938983815
[32m[0511 11:44:02 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:44:02 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:44:02 @base_trainer.py:216][0m Mean reward: -744.5161513848907
[32m[0511 11:44:02 @base_main.py:38][0m --------------- Iteration 180 ---------------
[32m[0511 11:44:02 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2481 mins
[32m[0511 11:44:02 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0025 mins
[32m[0511 11:44:02 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 11:44:02 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:44:02 @base_main.py:47][0m 180900 total steps have happened
[32m[0511 11:44:02 @base_main.py:52][0m [avg_reward]: -744.5161513848907
[32m[0511 11:44:02 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:44:02 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:44:02 @base_trainer.py:216][0m Mean reward: -732.6009622511303
[32m[0511 11:44:03 @base_main.py:38][0m --------------- Iteration 181 ---------------
[32m[0511 11:44:03 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2611 mins
[32m[0511 11:44:03 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0024 mins
[32m[0511 11:44:03 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0101 mins
[32m[0511 11:44:03 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:44:03 @base_main.py:47][0m 181905 total steps have happened
[32m[0511 11:44:03 @base_main.py:52][0m [avg_reward]: -732.6009622511303
[32m[0511 11:44:03 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:44:03 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:44:03 @base_trainer.py:216][0m Mean reward: -692.4419941111839
[32m[0511 11:44:04 @base_main.py:38][0m --------------- Iteration 182 ---------------
[32m[0511 11:44:04 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2739 mins
[32m[0511 11:44:04 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 11:44:04 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0108 mins
[32m[0511 11:44:04 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:44:04 @base_main.py:47][0m 182910 total steps have happened
[32m[0511 11:44:04 @base_main.py:52][0m [avg_reward]: -692.4419941111839
[32m[0511 11:44:04 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:44:04 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:44:04 @base_trainer.py:216][0m Mean reward: -796.4265610712694
[32m[0511 11:44:05 @base_main.py:38][0m --------------- Iteration 183 ---------------
[32m[0511 11:44:05 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2868 mins
[32m[0511 11:44:05 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 11:44:05 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 11:44:05 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:44:05 @base_main.py:47][0m 183915 total steps have happened
[32m[0511 11:44:05 @base_main.py:52][0m [avg_reward]: -796.4265610712694
[32m[0511 11:44:05 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:44:05 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:44:05 @base_trainer.py:216][0m Mean reward: -844.0291268442136
[32m[0511 11:44:05 @base_main.py:38][0m --------------- Iteration 184 ---------------
[32m[0511 11:44:05 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.2997 mins
[32m[0511 11:44:05 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0511 11:44:05 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0102 mins
[32m[0511 11:44:05 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:44:05 @base_main.py:47][0m 184920 total steps have happened
[32m[0511 11:44:05 @base_main.py:52][0m [avg_reward]: -844.0291268442136
[32m[0511 11:44:05 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:44:05 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:44:06 @base_trainer.py:216][0m Mean reward: -857.3084036733646
[32m[0511 11:44:06 @base_main.py:38][0m --------------- Iteration 185 ---------------
[32m[0511 11:44:06 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3126 mins
[32m[0511 11:44:06 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 11:44:06 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 11:44:06 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:44:06 @base_main.py:47][0m 185925 total steps have happened
[32m[0511 11:44:06 @base_main.py:52][0m [avg_reward]: -857.3084036733646
[32m[0511 11:44:06 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:44:06 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:44:06 @base_trainer.py:216][0m Mean reward: -772.7531769351606
[32m[0511 11:44:07 @base_main.py:38][0m --------------- Iteration 186 ---------------
[32m[0511 11:44:07 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3254 mins
[32m[0511 11:44:07 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 11:44:07 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 11:44:07 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:44:07 @base_main.py:47][0m 186930 total steps have happened
[32m[0511 11:44:07 @base_main.py:52][0m [avg_reward]: -772.7531769351606
[32m[0511 11:44:07 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:44:07 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:44:07 @base_trainer.py:216][0m Mean reward: -870.3539402527213
[32m[0511 11:44:08 @base_main.py:38][0m --------------- Iteration 187 ---------------
[32m[0511 11:44:08 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3382 mins
[32m[0511 11:44:08 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 11:44:08 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 11:44:08 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:44:08 @base_main.py:47][0m 187935 total steps have happened
[32m[0511 11:44:08 @base_main.py:52][0m [avg_reward]: -870.3539402527213
[32m[0511 11:44:08 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:44:08 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:44:08 @base_trainer.py:216][0m Mean reward: -806.1117075658699
[32m[0511 11:44:08 @base_main.py:38][0m --------------- Iteration 188 ---------------
[32m[0511 11:44:08 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3507 mins
[32m[0511 11:44:08 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 11:44:08 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 11:44:08 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:44:08 @base_main.py:47][0m 188940 total steps have happened
[32m[0511 11:44:08 @base_main.py:52][0m [avg_reward]: -806.1117075658699
[32m[0511 11:44:09 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:44:09 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:44:09 @base_trainer.py:216][0m Mean reward: -752.8346794169745
[32m[0511 11:44:09 @base_main.py:38][0m --------------- Iteration 189 ---------------
[32m[0511 11:44:09 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3634 mins
[32m[0511 11:44:09 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 11:44:09 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0100 mins
[32m[0511 11:44:09 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:44:09 @base_main.py:47][0m 189945 total steps have happened
[32m[0511 11:44:09 @base_main.py:52][0m [avg_reward]: -752.8346794169745
[32m[0511 11:44:09 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:44:09 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:44:09 @base_trainer.py:216][0m Mean reward: -629.5673495967756
[32m[0511 11:44:10 @base_main.py:38][0m --------------- Iteration 190 ---------------
[32m[0511 11:44:10 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3756 mins
[32m[0511 11:44:10 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 11:44:10 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 11:44:10 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:44:10 @base_main.py:47][0m 190950 total steps have happened
[32m[0511 11:44:10 @base_main.py:52][0m [avg_reward]: -629.5673495967756
[32m[0511 11:44:10 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:44:10 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:44:10 @base_trainer.py:216][0m Mean reward: -627.2767006839257
[32m[0511 11:44:11 @base_main.py:38][0m --------------- Iteration 191 ---------------
[32m[0511 11:44:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.3885 mins
[32m[0511 11:44:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0023 mins
[32m[0511 11:44:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 11:44:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:44:11 @base_main.py:47][0m 191955 total steps have happened
[32m[0511 11:44:11 @base_main.py:52][0m [avg_reward]: -627.2767006839257
[32m[0511 11:44:11 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:44:11 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:44:11 @base_trainer.py:216][0m Mean reward: -621.5650973370821
[32m[0511 11:44:11 @base_main.py:38][0m --------------- Iteration 192 ---------------
[32m[0511 11:44:11 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4014 mins
[32m[0511 11:44:11 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 11:44:11 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 11:44:11 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:44:11 @base_main.py:47][0m 192960 total steps have happened
[32m[0511 11:44:11 @base_main.py:52][0m [avg_reward]: -621.5650973370821
[32m[0511 11:44:12 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:44:12 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:44:12 @base_trainer.py:216][0m Mean reward: -562.9934781258928
[32m[0511 11:44:12 @base_main.py:38][0m --------------- Iteration 193 ---------------
[32m[0511 11:44:12 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4136 mins
[32m[0511 11:44:12 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 11:44:12 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 11:44:12 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:44:12 @base_main.py:47][0m 193965 total steps have happened
[32m[0511 11:44:12 @base_main.py:52][0m [avg_reward]: -562.9934781258928
[32m[0511 11:44:12 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:44:12 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:44:12 @base_trainer.py:216][0m Mean reward: -629.4758630524262
[32m[0511 11:44:13 @base_main.py:38][0m --------------- Iteration 194 ---------------
[32m[0511 11:44:13 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4263 mins
[32m[0511 11:44:13 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0022 mins
[32m[0511 11:44:13 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0097 mins
[32m[0511 11:44:13 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:44:13 @base_main.py:47][0m 194970 total steps have happened
[32m[0511 11:44:13 @base_main.py:52][0m [avg_reward]: -629.4758630524262
[32m[0511 11:44:13 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:44:13 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:44:13 @base_trainer.py:216][0m Mean reward: -667.779050208714
[32m[0511 11:44:14 @base_main.py:38][0m --------------- Iteration 195 ---------------
[32m[0511 11:44:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4384 mins
[32m[0511 11:44:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0026 mins
[32m[0511 11:44:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0105 mins
[32m[0511 11:44:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:44:14 @base_main.py:47][0m 195975 total steps have happened
[32m[0511 11:44:14 @base_main.py:52][0m [avg_reward]: -667.779050208714
[32m[0511 11:44:14 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:44:14 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:44:14 @base_trainer.py:216][0m Mean reward: -573.5553898702722
[32m[0511 11:44:14 @base_main.py:38][0m --------------- Iteration 196 ---------------
[32m[0511 11:44:14 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4516 mins
[32m[0511 11:44:14 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 11:44:14 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0106 mins
[32m[0511 11:44:14 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:44:14 @base_main.py:47][0m 196980 total steps have happened
[32m[0511 11:44:14 @base_main.py:52][0m [avg_reward]: -573.5553898702722
[32m[0511 11:44:15 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:44:15 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:44:15 @base_trainer.py:216][0m Mean reward: -607.867008014223
[32m[0511 11:44:15 @base_main.py:38][0m --------------- Iteration 197 ---------------
[32m[0511 11:44:15 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4643 mins
[32m[0511 11:44:15 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 11:44:15 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0104 mins
[32m[0511 11:44:15 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:44:15 @base_main.py:47][0m 197985 total steps have happened
[32m[0511 11:44:15 @base_main.py:52][0m [avg_reward]: -607.867008014223
[32m[0511 11:44:15 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:44:15 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:44:15 @base_trainer.py:216][0m Mean reward: -602.4194256174002
[32m[0511 11:44:16 @base_main.py:38][0m --------------- Iteration 198 ---------------
[32m[0511 11:44:16 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4770 mins
[32m[0511 11:44:16 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 11:44:16 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0098 mins
[32m[0511 11:44:16 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:44:16 @base_main.py:47][0m 198990 total steps have happened
[32m[0511 11:44:16 @base_main.py:52][0m [avg_reward]: -602.4194256174002
[32m[0511 11:44:16 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:44:16 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:44:16 @base_trainer.py:216][0m Mean reward: -647.0905942623756
[32m[0511 11:44:17 @base_main.py:38][0m --------------- Iteration 199 ---------------
[32m[0511 11:44:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.4890 mins
[32m[0511 11:44:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0021 mins
[32m[0511 11:44:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0096 mins
[32m[0511 11:44:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:44:17 @base_main.py:47][0m 199995 total steps have happened
[32m[0511 11:44:17 @base_main.py:52][0m [avg_reward]: -647.0905942623756
[32m[0511 11:44:17 @singletask_sampler.py:101][0m Finished 5th episode
[32m[0511 11:44:17 @singletask_sampler.py:105][0m 1005 timesteps from 5 episodes collected
[32m[0511 11:44:17 @base_trainer.py:216][0m Mean reward: -637.4353172901086
[32m[0511 11:44:17 @base_main.py:38][0m --------------- Iteration 200 ---------------
[32m[0511 11:44:17 @base_main.py:44][0m Time elapsed for [** Program Total Time **] is 2.5008 mins
[32m[0511 11:44:17 @base_main.py:44][0m Time elapsed for [Generate Rollout] is 0.0020 mins
[32m[0511 11:44:17 @base_main.py:44][0m Time elapsed for [Train Weights] is 0.0099 mins
[32m[0511 11:44:17 @base_main.py:44][0m Time elapsed for [Assign Weights] is 0.0001 mins
[32m[0511 11:44:17 @base_main.py:47][0m 201000 total steps have happened
[32m[0511 11:44:17 @base_main.py:52][0m [avg_reward]: -637.4353172901086
[32m[0511 11:44:17 @base_worker.py:111][0m kill message for worker 12
[32m[0511 11:44:17 @base_worker.py:111][0m kill message for worker 19
[32m[0511 11:44:17 @base_worker.py:111][0m kill message for worker 11
[32m[0511 11:44:17 @base_worker.py:111][0m kill message for worker 9
[32m[0511 11:44:17 @base_worker.py:111][0m kill message for worker 6
[32m[0511 11:44:17 @base_worker.py:111][0m kill message for worker 14
[32m[0511 11:44:17 @base_worker.py:111][0m kill message for worker 8
[32m[0511 11:44:17 @base_worker.py:111][0m kill message for worker 2
[32m[0511 11:44:17 @base_worker.py:111][0m kill message for worker 5
[32m[0511 11:44:17 @base_worker.py:111][0m kill message for worker 10
[32m[0511 11:44:17 @base_worker.py:111][0m kill message for worker 1
[32m[0511 11:44:17 @base_worker.py:111][0m kill message for worker 7
[32m[0511 11:44:17 @base_worker.py:111][0m kill message for worker 4
[32m[0511 11:44:17 @base_worker.py:111][0m kill message for worker 15
[32m[0511 11:44:17 @base_worker.py:111][0m kill message for worker 0
[32m[0511 11:44:17 @base_worker.py:111][0m kill message for worker 16
[32m[0511 11:44:17 @base_worker.py:111][0m kill message for worker 3
[32m[0511 11:44:17 @base_worker.py:111][0m kill message for worker 17
[32m[0511 11:44:17 @base_worker.py:111][0m kill message for worker 13
[32m[0511 11:44:17 @base_worker.py:111][0m kill message for worker 18
